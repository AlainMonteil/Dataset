<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-14T11:36+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>Graph Neural Networks (GNNs) have exploded onto the machine learning scene in recent years owing to their capability to model and learn from graph-structured data. Such an ability has strong implications in a wide variety of fields whose data are inherently relational, for which conventional neural networks do not perform well. Indeed, as recent reviews can attest, research in the area of GNNs has grown rapidly and has lead to the development of a variety of GNN algorithm variants as well as to the exploration of ground-breaking applications in chemistry, neurology, electronics, or communication networks, among others. At the current stage research, however, the efficient processing of GNNs is still an open challenge for several reasons. Besides of their novelty, GNNs are hard to compute due to their dependence on the input graph, their combination of dense and very sparse operations, or the need to scale to huge graphs in some applications. In this context, this article aims to make two main contributions. On the one hand, a review of the field of GNNs is presented from the perspective of computing. This includes a brief tutorial on the GNN fundamentals, an overview of the evolution of the field in the last decade, and a summary of operations carried out in the multiple phases of different GNN algorithm variants. On the other hand, an in-depth analysis of current software and hardware acceleration schemes is provided, from which a hardware-software, graph-aware, and communication-centric vision for GNN accelerators is distilled. CCS Concepts: • Computing methodologies → Machine learning algorithms; • Computer systems organization → Neural networks; Data flow architectures; • Mathematics of computing → Graph algorithms; • Hardware → Hardware accelerators;Graph Neural Networks (GNNs) have exploded onto the machine learning scene in recent years owing to their capability to model and learn from graph-structured data. Such an ability has strong implications in a wide variety of fields whose data are inherently relational, for which conventional neural networks do not perform well. Indeed, as recent reviews can attest, research in the area of GNNs has grown rapidly and has lead to the development of a variety of GNN algorithm variants as well as to the exploration of ground-breaking applications in chemistry, neurology, electronics, or communication networks, among others. At the current stage research, however, the efficient processing of GNNs is still an open challenge for several reasons. Besides of their novelty, GNNs are hard to compute due to their dependence on the input graph, their combination of dense and very sparse operations, or the need to scale to huge graphs in some applications. In this context, this article aims to make two main contributions. On the one hand, a review of the field of GNNs is presented from the perspective of computing. This includes a brief tutorial on the GNN fundamentals, an overview of the evolution of the field in the last decade, and a summary of operations carried out in the multiple phases of different GNN algorithm variants. On the other hand, an in-depth analysis of current software and hardware acceleration schemes is provided, from which a hardware-software, graph-aware, and communication-centric vision for GNN accelerators is distilled. CCS Concepts: • Computing methodologies → Machine learning algorithms; • Computer systems organization → Neural networks; Data flow architectures; • Mathematics of computing → Graph algorithms; • Hardware → Hardware accelerators;</p>
        <p>Machine Learning (ML) has taken the world by storm and has become a fundamental pillar of engineering due to its capacity to solve extremely complex problems, to detect intricate 191:2 S. Abadal et al. features in oceans of data, or to automatically generate alternatives that outperform wellengineered, well-known, carefully optimized solutions. As a result, the last decade has witnessed an explosive growth in the use of Deep Neural Networks (DNNs) in pursuit of exploiting the advantages of ML in virtually every aspect of our lives [92]: computer vision [67], natural language processing [171], medicine [43], or economics [62] are just a few examples.Machine Learning (ML) has taken the world by storm and has become a fundamental pillar of engineering due to its capacity to solve extremely complex problems, to detect intricate 191:2 S. Abadal et al. features in oceans of data, or to automatically generate alternatives that outperform wellengineered, well-known, carefully optimized solutions. As a result, the last decade has witnessed an explosive growth in the use of Deep Neural Networks (DNNs) in pursuit of exploiting the advantages of ML in virtually every aspect of our lives [92]: computer vision [67], natural language processing [171], medicine [43], or economics [62] are just a few examples.</p>
        <p>However, and in spite of its all-pervasive applicability and potential, it is well known that not all neural network architectures fit to all problems [11]. DNNs take the input data and attempt to extract knowledge taking into account the inductive bias that the connection architecture of the DNN generates. This, in essence, means that the number of DNN layers and their pre-assumed connections determines its suitability to certain tasks. For instance, by not making any assumption on the structure of the data, conventional fully connected neural networks are able to master a wide range of tasks at the cost of being less efficient in general than other DNNs [14]. In contrast, techniques such as Convolutional Neural Networks (CNNs) or Recursive Neural Networks (RNNs) are biased toward extracting knowledge from the locality and temporal sequentiality of data. This makes them a better fit for specific tasks such as image recognition or treatment of temporal signals, yet incapable of efficiently handling data with arbitrary structures [149].However, and in spite of its all-pervasive applicability and potential, it is well known that not all neural network architectures fit to all problems [11]. DNNs take the input data and attempt to extract knowledge taking into account the inductive bias that the connection architecture of the DNN generates. This, in essence, means that the number of DNN layers and their pre-assumed connections determines its suitability to certain tasks. For instance, by not making any assumption on the structure of the data, conventional fully connected neural networks are able to master a wide range of tasks at the cost of being less efficient in general than other DNNs [14]. In contrast, techniques such as Convolutional Neural Networks (CNNs) or Recursive Neural Networks (RNNs) are biased toward extracting knowledge from the locality and temporal sequentiality of data. This makes them a better fit for specific tasks such as image recognition or treatment of temporal signals, yet incapable of efficiently handling data with arbitrary structures [149].</p>
        <p>In light of the above, there has been a recent interest in deep learning techniques able to model graph-structured data [2,11,16,49,54,181]. This structure is inherent to a plethora of problems in the field of complex systems in general, and applicable to particular fields such as communication networks where the topology and routing decisions determine its performance [126], synthetic chemistry where molecular structures determine the compound properties [56], social networks where emergent behavior can arise through personal relations [116], or neuroscience where specific connections between neuron types and brain areas determine brain function [100], among many others.In light of the above, there has been a recent interest in deep learning techniques able to model graph-structured data [2,11,16,49,54,181]. This structure is inherent to a plethora of problems in the field of complex systems in general, and applicable to particular fields such as communication networks where the topology and routing decisions determine its performance [126], synthetic chemistry where molecular structures determine the compound properties [56], social networks where emergent behavior can arise through personal relations [116], or neuroscience where specific connections between neuron types and brain areas determine brain function [100], among many others.</p>
        <p>Graph Neural Networks (GNNs) are a set of connectivity-driven models that, since the late 2000s, have been addressing the need for geometric deep learning [57,130]. In essence, GNN adapt their structure to that of an input graph and, through an iterative process of aggregation of information across vertices, capture the complex dependencies of the underlying system. This allows to predict properties for specific nodes, connections, or the graph as a whole, and generalize to unseen graphs. Due to these powerful features, many relevant applications such as molecule property prediction [47], recommender systems [44], natural language processing [171], traffic speed prediction [161], critical data classification [170], computer vision [152], particle physics [80], and resource allocation in computer networks [125] already utilize GNNs to accomplish their tasks.Graph Neural Networks (GNNs) are a set of connectivity-driven models that, since the late 2000s, have been addressing the need for geometric deep learning [57,130]. In essence, GNN adapt their structure to that of an input graph and, through an iterative process of aggregation of information across vertices, capture the complex dependencies of the underlying system. This allows to predict properties for specific nodes, connections, or the graph as a whole, and generalize to unseen graphs. Due to these powerful features, many relevant applications such as molecule property prediction [47], recommender systems [44], natural language processing [171], traffic speed prediction [161], critical data classification [170], computer vision [152], particle physics [80], and resource allocation in computer networks [125] already utilize GNNs to accomplish their tasks.</p>
        <p>For all these reasons, recent years have seen a rapid increase in research activity in the field of GNNs (see Figure 6). Intense efforts are being directed toward improving the efficiency of Computing Graph Neural Networks: A Survey from Algorithms to Accelerators 191:3 Table 1. Background Literature: Surveys about GNNs (First Block) and Including GNNs (Second Block)For all these reasons, recent years have seen a rapid increase in research activity in the field of GNNs (see Figure 6). Intense efforts are being directed toward improving the efficiency of Computing Graph Neural Networks: A Survey from Algorithms to Accelerators 191:3 Table 1. Background Literature: Surveys about GNNs (First Block) and Including GNNs (Second Block)</p>
        <p>Relational Inductive Biases, Deep Learning, and Graph Networks [11] (2018)Relational Inductive Biases, Deep Learning, and Graph Networks [11] (2018)</p>
        <p>• Presents the idea of a graph network as a generalization of GNNs with building blocks • Encompasses well-known models, such as fully connected, convolutional and recurrent networks.• Presents the idea of a graph network as a generalization of GNNs with building blocks • Encompasses well-known models, such as fully connected, convolutional and recurrent networks.</p>
        <p>Graph Neural Networks: A Review of Methods and Applications [185] (2018)Graph Neural Networks: A Review of Methods and Applications [185] (2018)</p>
        <p>• Presents a survey of the various GNN models • Discusses the applications where GNNs can be utilized and provides a taxonomy • Proposes open research problems, such as dynamicity and scalability in GNNs A Comprehensive Survey on Graph Neural Networks [160] (2021)• Presents a survey of the various GNN models • Discusses the applications where GNNs can be utilized and provides a taxonomy • Proposes open research problems, such as dynamicity and scalability in GNNs A Comprehensive Survey on Graph Neural Networks [160] (2021)</p>
        <p>• Overviews of GNNs in data mining and machine learning areas • Provisions a taxonomy for GNN models • Details the application areas of GNNs • Presents potential research directions, such as in scalability, dynamicity of GNNs, and so on.• Overviews of GNNs in data mining and machine learning areas • Provisions a taxonomy for GNN models • Details the application areas of GNNs • Presents potential research directions, such as in scalability, dynamicity of GNNs, and so on.</p>
        <p>A Survey [181] (2020)A Survey [181] (2020)</p>
        <p>• Provides a discussion on graph versions of recurrent and convolutional networks, autoencoders, reinforcement-learning and adversarial methods • Presents the application areas and future research directions for deep learning on graphs Machine Learning on Graphs: A Model and Comprehensive Taxonomy [19] (2020)• Provides a discussion on graph versions of recurrent and convolutional networks, autoencoders, reinforcement-learning and adversarial methods • Presents the application areas and future research directions for deep learning on graphs Machine Learning on Graphs: A Model and Comprehensive Taxonomy [19] (2020)</p>
        <p>• Presents a taxonomy to classify graph learning methods, from graph embeddings to GNNs • Proposes an encoder-decoder model that unifies all methods in a single approach • Expresses 30+ graph learning techniques using the proposed model Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and Perspective [91] (2020)• Presents a taxonomy to classify graph learning methods, from graph embeddings to GNNs • Proposes an encoder-decoder model that unifies all methods in a single approach • Expresses 30+ graph learning techniques using the proposed model Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and Perspective [91] (2020)</p>
        <p>• Elaborates the relationship between GNNs and Neural-Symbolic Computing • Develops multiple GNN models with the perspective of being applied to Neural-Symbolic computing Geometric Deep Learning: Going beyond Euclidean data [16] (2017)• Elaborates the relationship between GNNs and Neural-Symbolic Computing • Develops multiple GNN models with the perspective of being applied to Neural-Symbolic computing Geometric Deep Learning: Going beyond Euclidean data [16] (2017)</p>
        <p>• Proposes Geometric Deep Learning as an umbrella term for models that operate on non-euclidean dataset representations, including GNNs. • Within GNNs, provides a thorough review of convolutional models Representation Learning on Graphs: Methods and Applications [66] (2017)• Proposes Geometric Deep Learning as an umbrella term for models that operate on non-euclidean dataset representations, including GNNs. • Within GNNs, provides a thorough review of convolutional models Representation Learning on Graphs: Methods and Applications [66] (2017)</p>
        <p>• Reviews the advancements in the area of representation learning on graphs • Primary focus is on the network embedding methods algorithms, especially for large graphs, and toward demonstrating their efficacy for the aforementioned application areas. The interested reader will find multiple reviews of the state of the art in GNN algorithms and applications in the literature [11,16,19,66,91,160,181,185], most of which we briefly analyze in Table 1. Other key aspects relevant or adjacent to GNNs such as network embedding [31], graph attention models [93], or network structure inference [17] have also received a comprehensive review.• Reviews the advancements in the area of representation learning on graphs • Primary focus is on the network embedding methods algorithms, especially for large graphs, and toward demonstrating their efficacy for the aforementioned application areas. The interested reader will find multiple reviews of the state of the art in GNN algorithms and applications in the literature [11,16,19,66,91,160,181,185], most of which we briefly analyze in Table 1. Other key aspects relevant or adjacent to GNNs such as network embedding [31], graph attention models [93], or network structure inference [17] have also received a comprehensive review.</p>
        <p>As we will see along this article, however, less attention has been placed on the efficient processing of such new type of neural networks. While the issue has already been investigated in significant depth for CNNs or RNNs [24,25,39,68,90,111], GNN processing remains largely unexplored. This is because GNNs are relatively novel and pose unique computing challenges, including the need to (i) support both dense and extremely sparse operations, (ii) adapt the computation to the specific GNN algorithm variant and the structure of the graph at hand, and (iii) scale to very large graphs to realize its potential in certain applications. Even though advances in sparse/irregular tensor processing [34] and graph processing [63,154] may prove useful in accelerating GNNs, addressing their unique computing challenges requires more specialized proposals. Some attempts have been done from a software perspective, i.e., adapting the GNN operations to better match the capabilities of CPUs or GPUs [106,144,155]; and from a hardware perspective, i.e., designing custom processors tailored to the demands of GNNs [7,53,103,164]. However, recent surveys and reviews [11,16,19,66,91,160,181,185] lack a comprehensive analysis of such advances.As we will see along this article, however, less attention has been placed on the efficient processing of such new type of neural networks. While the issue has already been investigated in significant depth for CNNs or RNNs [24,25,39,68,90,111], GNN processing remains largely unexplored. This is because GNNs are relatively novel and pose unique computing challenges, including the need to (i) support both dense and extremely sparse operations, (ii) adapt the computation to the specific GNN algorithm variant and the structure of the graph at hand, and (iii) scale to very large graphs to realize its potential in certain applications. Even though advances in sparse/irregular tensor processing [34] and graph processing [63,154] may prove useful in accelerating GNNs, addressing their unique computing challenges requires more specialized proposals. Some attempts have been done from a software perspective, i.e., adapting the GNN operations to better match the capabilities of CPUs or GPUs [106,144,155]; and from a hardware perspective, i.e., designing custom processors tailored to the demands of GNNs [7,53,103,164]. However, recent surveys and reviews [11,16,19,66,91,160,181,185] lack a comprehensive analysis of such advances.</p>
        <p>This article aims to bridge this gap by presenting, for the first time, a review of the field of GNNs from the perspective of computing. To that end, we make the following contributions as summarized in Figure 2: We start by providing a comprehensive and tutorial-like description of the fundamentals of GNNs, trying to unify notation. Then, using a Knowledge Graph (KG) approach, we chart the evolution of the field from its inception to the time of this writing, delving into the duality between GNN algorithms (seeing them as learning systems) and their associated computation (seeing them as sets of matrix multiplications and non-linear operations). From that analysis, we identify GNN computing as a nascent field. We finally focus on the computation aspect and provide an in-depth analysis of current software and hardware acceleration schemes, from which we also outline new potential research lines in GNN computing. To the best of the authors' knowledge, this is the first work providing a thorough review of GNN research from the perspective of computation, charting the evolution of the research area and analyzing existing libraries and accelerators.This article aims to bridge this gap by presenting, for the first time, a review of the field of GNNs from the perspective of computing. To that end, we make the following contributions as summarized in Figure 2: We start by providing a comprehensive and tutorial-like description of the fundamentals of GNNs, trying to unify notation. Then, using a Knowledge Graph (KG) approach, we chart the evolution of the field from its inception to the time of this writing, delving into the duality between GNN algorithms (seeing them as learning systems) and their associated computation (seeing them as sets of matrix multiplications and non-linear operations). From that analysis, we identify GNN computing as a nascent field. We finally focus on the computation aspect and provide an in-depth analysis of current software and hardware acceleration schemes, from which we also outline new potential research lines in GNN computing. To the best of the authors' knowledge, this is the first work providing a thorough review of GNN research from the perspective of computation, charting the evolution of the research area and analyzing existing libraries and accelerators.</p>
        <p>The rest of this article is organized as follows: In Section 2, we discuss the basics of the GNNs. Section 3 presents the evolution of the research area from multiple perspectives. In Section 4, we expose the emergent area of GNN accelerators, summarizing recent works and elaborating upon the existing challenges and opportunities. Next, in Section 5, we present our vision for the architectural design of GNN accelerators with a focus on internal communication requirements. We conclude this article in Section 6.The rest of this article is organized as follows: In Section 2, we discuss the basics of the GNNs. Section 3 presents the evolution of the research area from multiple perspectives. In Section 4, we expose the emergent area of GNN accelerators, summarizing recent works and elaborating upon the existing challenges and opportunities. Next, in Section 5, we present our vision for the architectural design of GNN accelerators with a focus on internal communication requirements. We conclude this article in Section 6.</p>
        <p>In this section, we discuss the basics of GNNs through a description of their building blocks and their role during the computation, both in inference and training.In this section, we discuss the basics of GNNs through a description of their building blocks and their role during the computation, both in inference and training.</p>
        <p>Computing Graph Neural Networks: A Survey from Algorithms to Accelerators 191:5 Input, hidden, output feature vector of edge e N (v) Set of neigbours of vertex v ρ (l ) V , ρ (l )Computing Graph Neural Networks: A Survey from Algorithms to Accelerators 191:5 Input, hidden, output feature vector of edge e N (v) Set of neigbours of vertex v ρ (l ) V , ρ (l )</p>
        <p>Node and edge aggregation functions of layer l L Number of GNN layers ϕ (l ) V , ϕ (l )Node and edge aggregation functions of layer l L Number of GNN layers ϕ (l ) V , ϕ (l )</p>
        <p>Node and edge combination functions of layer l y Output global vectorNode and edge combination functions of layer l y Output global vector</p>
        <p>Node and edge weight matrices of layer lNode and edge weight matrices of layer l</p>
        <p>We first describe the main notation for GNNs as summarized in Table 2. Let a graph G = (V , E) be defined by a set of vertices V , and a set of edges E that connect some of the vertices in V together. In particular, each vertex v ∈ V has a neighbourhood set N (v) determined by the edges connecting it to other vertices or the sampling set imposed by the GNN algorithm. Further, each vertex v contains a vertex feature representation h v , and each edge e ∈ E contains an edge feature representation д e . The vertex or edge feature representations are generally one-dimensional vectors containing the scalar attributes that define them. Similarly, the graph may be associated to a global feature representation y containing graphwide attributes. For example, in a social networking graph, vertices might be users with attributes such as encoded name or location, whereas the edges might be the interaction between two users such as comments/likes on a picture. Graphwide features may be the number of users living a certain area or voting a certain political party. GNNs essentially calculate a set of output feature representations for the vertices h v , edges д e , and complete graph y, respectively. Following with the example above, for targeting ads in a social network, output features of a vertex could be the probability of being interested in cars. It can thus be observed that, as in any other neural network, the dimensionality of the output feature vectors will be generally different than that of the input.We first describe the main notation for GNNs as summarized in Table 2. Let a graph G = (V , E) be defined by a set of vertices V , and a set of edges E that connect some of the vertices in V together. In particular, each vertex v ∈ V has a neighbourhood set N (v) determined by the edges connecting it to other vertices or the sampling set imposed by the GNN algorithm. Further, each vertex v contains a vertex feature representation h v , and each edge e ∈ E contains an edge feature representation д e . The vertex or edge feature representations are generally one-dimensional vectors containing the scalar attributes that define them. Similarly, the graph may be associated to a global feature representation y containing graphwide attributes. For example, in a social networking graph, vertices might be users with attributes such as encoded name or location, whereas the edges might be the interaction between two users such as comments/likes on a picture. Graphwide features may be the number of users living a certain area or voting a certain political party. GNNs essentially calculate a set of output feature representations for the vertices h v , edges д e , and complete graph y, respectively. Following with the example above, for targeting ads in a social network, output features of a vertex could be the probability of being interested in cars. It can thus be observed that, as in any other neural network, the dimensionality of the output feature vectors will be generally different than that of the input.</p>
        <p>As we will see in Section 2.2, a GNN is divided in multiple layers. In each layer l ∈ [1, L], there is an edge aggregation function ρ (l ) E and a node aggregation function ρ (l ) V , as well as an edge combination function ϕ (l ) E and a node combination function ϕ (l ) V . The combination functions may be neural networks involving matrices of weights W (l ) E and W (l ) V that are generally common to all edges and nodes, respectively. The outputs of an arbitrary intermediate layer l, given by its combination function, are hidden feature vectors h (l ) v and д (l ) e . At the end of the GNN, besides obtaining the output node and edge feature vectors, h L v and д L e , there are global aggregation and combination functions ρ G and ϕ G , respectively, that provide final global output vector ŷ. Although most works assume that the graph is static, the computation may be repeated several times with evolving weight matrices to adapt to dynamic graphs [120].As we will see in Section 2.2, a GNN is divided in multiple layers. In each layer l ∈ [1, L], there is an edge aggregation function ρ (l ) E and a node aggregation function ρ (l ) V , as well as an edge combination function ϕ (l ) E and a node combination function ϕ (l ) V . The combination functions may be neural networks involving matrices of weights W (l ) E and W (l ) V that are generally common to all edges and nodes, respectively. The outputs of an arbitrary intermediate layer l, given by its combination function, are hidden feature vectors h (l ) v and д (l ) e . At the end of the GNN, besides obtaining the output node and edge feature vectors, h L v and д L e , there are global aggregation and combination functions ρ G and ϕ G , respectively, that provide final global output vector ŷ. Although most works assume that the graph is static, the computation may be repeated several times with evolving weight matrices to adapt to dynamic graphs [120].</p>
        <p>We finally note that, due to the emergence of GNNs, aggregation and combination functions have taken different names in the literature. In an attempt to unify the notation, some equivalences are listed in Table 3.We finally note that, due to the emergence of GNNs, aggregation and combination functions have taken different names in the literature. In an attempt to unify the notation, some equivalences are listed in Table 3.</p>
        <p>Fundamentally, a GNN is an algorithm that leverages the graph connectivity to learn and model the relationships between nodes. Through an iterative process that depends on the graph structure, the GNN takes the input edge, vertex, and graph feature vectors (representing their known attributes) and transforms them into output feature vectors (representing the target predictions). In general, the GNN operation contains the steps illustrated in Figure 3: (1) Pre-processing: This is an initial and optional step generally done offline that can transform the input feature vectors and graph structure representation through a precoding process. This may be used to sample the graph, to re-order the graph toward reducing the algorithm complexity and its processing, or to encode the feature vectors, among others [23,28,65,77,141,176,181]. (2) Iterative updates: After the pre-processing, the feature vectors of each edge and vertex are updated via the aggregate-combine functions iteratively. To update the edges, attributes from the edge itself, the connected vertices, and the graph are aggregated into a single set and combined to yield a new edge feature vector. Similarly, updating the vertices implies aggregating the feature vectors from neighboring vertices N (v) and combining them to obtain a new feature vector. Note that each step or layer updates each edge and vertex with information coming from neighbours located at a single hop. Thus, the iterative process allows to gradually account for relations of increasingly distant nodes and edges. Additionally, in each successive layer, the graph may be coarsened by means of pooling [168] or the neighbourhood set changed by means of layer sampling [65]. (3) Decoding or readout: If the graph has a global feature vector, then it is updated once after the edge and node updates are completed. The final output is either an edge/node embedding, which is a low-dimensional feature vector that represents edge-or node-specific information, or a graph embedding summarizing the information about the entire output graph instead.Fundamentally, a GNN is an algorithm that leverages the graph connectivity to learn and model the relationships between nodes. Through an iterative process that depends on the graph structure, the GNN takes the input edge, vertex, and graph feature vectors (representing their known attributes) and transforms them into output feature vectors (representing the target predictions). In general, the GNN operation contains the steps illustrated in Figure 3: (1) Pre-processing: This is an initial and optional step generally done offline that can transform the input feature vectors and graph structure representation through a precoding process. This may be used to sample the graph, to re-order the graph toward reducing the algorithm complexity and its processing, or to encode the feature vectors, among others [23,28,65,77,141,176,181]. (2) Iterative updates: After the pre-processing, the feature vectors of each edge and vertex are updated via the aggregate-combine functions iteratively. To update the edges, attributes from the edge itself, the connected vertices, and the graph are aggregated into a single set and combined to yield a new edge feature vector. Similarly, updating the vertices implies aggregating the feature vectors from neighboring vertices N (v) and combining them to obtain a new feature vector. Note that each step or layer updates each edge and vertex with information coming from neighbours located at a single hop. Thus, the iterative process allows to gradually account for relations of increasingly distant nodes and edges. Additionally, in each successive layer, the graph may be coarsened by means of pooling [168] or the neighbourhood set changed by means of layer sampling [65]. (3) Decoding or readout: If the graph has a global feature vector, then it is updated once after the edge and node updates are completed. The final output is either an edge/node embedding, which is a low-dimensional feature vector that represents edge-or node-specific information, or a graph embedding summarizing the information about the entire output graph instead.</p>
        <p>As in any other neural network, the GNN processing depends on its architecture. GNNs are basically divided into layers, with each layer corresponding to one of the iterations in the update process described above. This means that each layer allows information from nodes to propagate further away from it. Hence, the precise number of required layers will depend on how relevant are the relations among distant nodes in a given application. The most widespread GNN algorithms have 1-5 layers [65,87,124,146,162] as an excessive amount of layers typically lead to the problems of feature oversmoothing, vanishing gradients, or overfitting [97]. A few works have proposed techniques to alleviate these issues and enable deep GNNs of up to 100 layers [22,95], yet these proposals are in their infancy.As in any other neural network, the GNN processing depends on its architecture. GNNs are basically divided into layers, with each layer corresponding to one of the iterations in the update process described above. This means that each layer allows information from nodes to propagate further away from it. Hence, the precise number of required layers will depend on how relevant are the relations among distant nodes in a given application. The most widespread GNN algorithms have 1-5 layers [65,87,124,146,162] as an excessive amount of layers typically lead to the problems of feature oversmoothing, vanishing gradients, or overfitting [97]. A few works have proposed techniques to alleviate these issues and enable deep GNNs of up to 100 layers [22,95], yet these proposals are in their infancy.</p>
        <p>In each of the layers, information flows between vertices using an aggregation function and feature vectors are updated via the combination function after aggregation in a process similar to that of the classic Weisfeiler-Lehman (WL) test for graph isomorphism [157]. The size of aggregation depends on the number of vertices and edges (ranging from hundreds to billions) whereas the size of combination depends on the length of the feature vectors (ranging from dozens of features to tens of thousands). The aggregation and combination functions for both edges and vertices are crucial design decisions as they determine the expressive power of the GNN, which has been demonstrated to be at most equal to the WL test in distinguishing graph structures [162]. As we will see in Section 3.2, Table 6, there is a wide variety of such functions ranging from simple averaging to weighted sums with learnable attention coefficients, different types of neural networks, from MLPs to LSTMs with their own weighted sums and non-linear activations, whose suitability depends on the relation to be learnt. The operations may vary across layers and differ between edges, vertices, or global updates. However, the structure is often simplified by (i) sharing the same operation across layers and (ii) removing or considering trivial combination functions for the updates of edges or nodes.In each of the layers, information flows between vertices using an aggregation function and feature vectors are updated via the combination function after aggregation in a process similar to that of the classic Weisfeiler-Lehman (WL) test for graph isomorphism [157]. The size of aggregation depends on the number of vertices and edges (ranging from hundreds to billions) whereas the size of combination depends on the length of the feature vectors (ranging from dozens of features to tens of thousands). The aggregation and combination functions for both edges and vertices are crucial design decisions as they determine the expressive power of the GNN, which has been demonstrated to be at most equal to the WL test in distinguishing graph structures [162]. As we will see in Section 3.2, Table 6, there is a wide variety of such functions ranging from simple averaging to weighted sums with learnable attention coefficients, different types of neural networks, from MLPs to LSTMs with their own weighted sums and non-linear activations, whose suitability depends on the relation to be learnt. The operations may vary across layers and differ between edges, vertices, or global updates. However, the structure is often simplified by (i) sharing the same operation across layers and (ii) removing or considering trivial combination functions for the updates of edges or nodes.</p>
        <p>The fundamental structure here explained and depicted in Figure 3 can be complemented with sampling and pooling operations that help to reduce the computational complexity of GNNs [65,168,176], and/or augmented with support for dynamic graphs [120]. Sampling refers to the pruning of either the graph or the neighbourhood set of each node, and it is used to limit or harmonize the resources and runtime of the aggregation process, whereas pooling refers to the coarsening of the graph from one layer to the next, thus reducing the amount of nodes to process in both aggregation and combination. To add support for dynamic graphs, whose structure and input feature vectors may evolve over time, recurrent units are generally used to adapt the weight matrices in each timestep.The fundamental structure here explained and depicted in Figure 3 can be complemented with sampling and pooling operations that help to reduce the computational complexity of GNNs [65,168,176], and/or augmented with support for dynamic graphs [120]. Sampling refers to the pruning of either the graph or the neighbourhood set of each node, and it is used to limit or harmonize the resources and runtime of the aggregation process, whereas pooling refers to the coarsening of the graph from one layer to the next, thus reducing the amount of nodes to process in both aggregation and combination. To add support for dynamic graphs, whose structure and input feature vectors may evolve over time, recurrent units are generally used to adapt the weight matrices in each timestep.</p>
        <p>In summary, we can understand GNNs as a collection of neural networks working over a graph's connectivity. In the scope of each layer, we have up to two neural networks with learnable weights that determine the combination of edges and vertices, respectively. In the scope of the whole GNN, we have a neural network with learnable weights that determines the global update. The way these operations take place for inference and training is depicted next.In summary, we can understand GNNs as a collection of neural networks working over a graph's connectivity. In the scope of each layer, we have up to two neural networks with learnable weights that determine the combination of edges and vertices, respectively. In the scope of the whole GNN, we have a neural network with learnable weights that determines the global update. The way these operations take place for inference and training is depicted next.</p>
        <p>Algorithm 1 shows a pseudo-code describing GNN inference. The algorithm may take as inputs the feature vectors of the edges, vertices, and graph or initialize them. We can see how the execution is divided into layers (line 9) and, within each layer, each and every edge is updated in parallel by aggregating its own feature vector with those of the connected vertices (line 11). Each and every vertex is also updated in parallel by aggregating the feature vectors of its neighbours withAlgorithm 1 shows a pseudo-code describing GNN inference. The algorithm may take as inputs the feature vectors of the edges, vertices, and graph or initialize them. We can see how the execution is divided into layers (line 9) and, within each layer, each and every edge is updated in parallel by aggregating its own feature vector with those of the connected vertices (line 11). Each and every vertex is also updated in parallel by aggregating the feature vectors of its neighbours with</p>
        <p>for e ∈ E do 8:for e ∈ E do 8:</p>
        <p>д 0 e ← [z v , 0, . . . , 0] GNN Layered processing:д 0 e ← [z v , 0, . . . , 0] GNN Layered processing:</p>
        <p>for l = 1 to L do Edge processing: // Order of edge and node processing may be interchanged or even interspersed.for l = 1 to L do Edge processing: // Order of edge and node processing may be interchanged or even interspersed.</p>
        <p>for e ∈ E do // Order of aggregation and combination may be interchanged if aggregation is linear.for e ∈ E do // Order of aggregation and combination may be interchanged if aggregation is linear.</p>
        <p>12:12:</p>
        <p>e Node processing: // Order of edge and node processing may be interchanged or even interspersed.e Node processing: // Order of edge and node processing may be interchanged or even interspersed.</p>
        <p>13:13:</p>
        <p>for v ∈ V do // Order of aggregation and combination may be interchanged if aggregation is linear.for v ∈ V do // Order of aggregation and combination may be interchanged if aggregation is linear.</p>
        <p>14:14:</p>
        <p>15:15:</p>
        <p>v Readout:v Readout:</p>
        <p>itself (line 15). The aggregated edges and vertices are transformed via combination functions (lines 13 and 17), which can be neural networks as we see in Section 3.2. Following the completion of the iterative process, a readout is performed using the corresponding function, which may again possibly be a neural network (line 18). For an arbitrary layer l ∈ [1, L], edge transformation occurs asitself (line 15). The aggregated edges and vertices are transformed via combination functions (lines 13 and 17), which can be neural networks as we see in Section 3.2. Following the completion of the iterative process, a readout is performed using the corresponding function, which may again possibly be a neural network (line 18). For an arbitrary layer l ∈ [1, L], edge transformation occurs as</p>
        <p>COMBINATION:COMBINATION:</p>
        <p>so that the aggregation of edges ρ E takes the feature vector д e of the edge itself e, as well as the feature vectors of the vertices at its endpoints, h u with u ∈ N (e), for the previous layer l -1. The combination ϕ E uses this aggregation as input [162]. A similar reasoning applies to the aggregation and combination of verticesso that the aggregation of edges ρ E takes the feature vector д e of the edge itself e, as well as the feature vectors of the vertices at its endpoints, h u with u ∈ N (e), for the previous layer l -1. The combination ϕ E uses this aggregation as input [162]. A similar reasoning applies to the aggregation and combination of vertices</p>
        <p>COMBINATION:COMBINATION:</p>
        <p>The equations describe how a (l ) v is calculated as the aggregation of the feature vectors from the nodes that are neighbours to v, from the previous layer l -1, and how the feature vector of layer l is calculated using the aggregation a (l ) v as input. Last, a final readout function is applied, which may involve the aggregation and combination of feature vectors from edges and vertices of the entire graph, and from the last iteration L, hence obtaining the output feature vector ŷ asThe equations describe how a (l ) v is calculated as the aggregation of the feature vectors from the nodes that are neighbours to v, from the previous layer l -1, and how the feature vector of layer l is calculated using the aggregation a (l ) v as input. Last, a final readout function is applied, which may involve the aggregation and combination of feature vectors from edges and vertices of the entire graph, and from the last iteration L, hence obtaining the output feature vector ŷ as</p>
        <p>Algorithm 1 hinges on the general assumption that aggregation and combination functions are (i) invariant to permutation of nodes and edges, since there does not exist any implicit order in a graph structure, unless some node feature indicates such an order, and (ii) invariant to the number of input nodes, since the degree of nodes may vary widely across the graph [11]. This implies that the functions within a layer can be applied to all edges and all vertices in parallel, following any order. Further, the order between aggregation and combination can be switched if the aggregation function is linear [103]. However, it is important that the order of layers is preserved to avoid violating data dependencies, which implies that all edge and node operations of layer l shall finish before starting those of l + 1.Algorithm 1 hinges on the general assumption that aggregation and combination functions are (i) invariant to permutation of nodes and edges, since there does not exist any implicit order in a graph structure, unless some node feature indicates such an order, and (ii) invariant to the number of input nodes, since the degree of nodes may vary widely across the graph [11]. This implies that the functions within a layer can be applied to all edges and all vertices in parallel, following any order. Further, the order between aggregation and combination can be switched if the aggregation function is linear [103]. However, it is important that the order of layers is preserved to avoid violating data dependencies, which implies that all edge and node operations of layer l shall finish before starting those of l + 1.</p>
        <p>To exemplify the computation occurring in inference, top charts of Figure 4 represent the layers of a simple GNN with vertex aggregation and combination only. We show the operations from the perspective of node 1, although all nodes would be realizing the same computations concurrently. We illustrate how the graph connectivity drives the aggregation from nodes 2, 3, and 6 into node 1, and that combination reduces the length of the feature vector through the weight matrices W (1) . We note, however, that combination functions do not necessarily reduce the length of the feature vectors; that depends on the actual GNN architecture. The second layer repeats the exact same sequence, again reducing the length of the feature vector, this time through a different weight matrix W (2) .To exemplify the computation occurring in inference, top charts of Figure 4 represent the layers of a simple GNN with vertex aggregation and combination only. We show the operations from the perspective of node 1, although all nodes would be realizing the same computations concurrently. We illustrate how the graph connectivity drives the aggregation from nodes 2, 3, and 6 into node 1, and that combination reduces the length of the feature vector through the weight matrices W (1) . We note, however, that combination functions do not necessarily reduce the length of the feature vectors; that depends on the actual GNN architecture. The second layer repeats the exact same sequence, again reducing the length of the feature vector, this time through a different weight matrix W (2) .</p>
        <p>Extended notation for sampling, pooling, and dynamic graphs: As described above, sampling and pooling might impact the length aggregation and combination stages, whereas dealing with evolving graphs may require extra computation steps. Following the notation above, sampling essentially modifies either the input graph, G s [176], or the neighbourhood operator making it dependent on the layer being computed N (l ) s (v). Pooling can be seen as a graph transformation across layers, thus making the set of nodes and edges to vary as well E (l ) , V (l ) . Finally, supportExtended notation for sampling, pooling, and dynamic graphs: As described above, sampling and pooling might impact the length aggregation and combination stages, whereas dealing with evolving graphs may require extra computation steps. Following the notation above, sampling essentially modifies either the input graph, G s [176], or the neighbourhood operator making it dependent on the layer being computed N (l ) s (v). Pooling can be seen as a graph transformation across layers, thus making the set of nodes and edges to vary as well E (l ) , V (l ) . Finally, support</p>
        <p>Aggregation at a layer or epoch with M t (•) and ρ (l ) (•) as aggregation functionsAggregation at a layer or epoch with M t (•) and ρ (l ) (•) as aggregation functions</p>
        <p>Combination with functions U t (•) and ϕ (l ) (•) in a given layer or epoch for dynamic graphs G t requires the entire GNN to be time-dependent, introducing time in the notation. Neighbourhood sets, feature vectors, and most importantly, weight matrices would evolve over time,Combination with functions U t (•) and ϕ (l ) (•) in a given layer or epoch for dynamic graphs G t requires the entire GNN to be time-dependent, introducing time in the notation. Neighbourhood sets, feature vectors, and most importantly, weight matrices would evolve over time,</p>
        <p>We note that notation relative to GNN algorithms is diverse in the literature. A notable example is that of Message Passing Neural Network (MPNN) [11], which describes the aggregations as message passing functions M (•), the combinations as update functions U (•), or the layers as time steps. Table 4 illustrates the equivalence between the MPNN formulations and the corresponding generic formulations from Equations ( 1)- (5).We note that notation relative to GNN algorithms is diverse in the literature. A notable example is that of Message Passing Neural Network (MPNN) [11], which describes the aggregations as message passing functions M (•), the combinations as update functions U (•), or the layers as time steps. Table 4 illustrates the equivalence between the MPNN formulations and the corresponding generic formulations from Equations ( 1)- (5).</p>
        <p>Matrix multiplication notation: GNNs are typically expressed in matrix notation that helps understanding the underlying computation. An example for node classification with sum aggregation function is as follows. Let A be the normalized adjacency matrix of the input graph, H (l ) the matrix of features for layer l, and W (l ) = W (l ) V the weight matrix for the vertex combination function. Then, the forward propagation to layer l + 1 can be expressed asMatrix multiplication notation: GNNs are typically expressed in matrix notation that helps understanding the underlying computation. An example for node classification with sum aggregation function is as follows. Let A be the normalized adjacency matrix of the input graph, H (l ) the matrix of features for layer l, and W (l ) = W (l ) V the weight matrix for the vertex combination function. Then, the forward propagation to layer l + 1 can be expressed as</p>
        <p>where σ (•) is the non-linear activation function, e.g., a ReLU. For more complex GNNs and aggregation-combination functions, the forward propagation equation may change.where σ (•) is the non-linear activation function, e.g., a ReLU. For more complex GNNs and aggregation-combination functions, the forward propagation equation may change.</p>
        <p>Aggregation, combination, and readout functions can be neural networks that may need to be trained before deployment. Training is performed via modifications of the traditional backpropagation algorithms, which take into account the unique traits of a GNN. Since a GNN unfolds into L layers similarly to a RNN, most GNNs employ Back-Propagation-Through-Time (BPTT) schemes or variants of it. A popular variant of BPTT is the Pineda-Almeida algorithm [5,122], which relaxes the memory requirements as already mentioned in the seminal work by Scarselli et al. [130]. Specifically, in BPTT, a forward pass is first performed on the unfolded version of the GNN with its L layers. The loss function ε is then computed and the necessary gradient is backpropagated across layers. Since the weights are shared among all L layers, they are updated accordingly. This process is carried out recurrently with multiple samples, often grouped in batches, until some target accuracy is reached. Depending on the problem, a sample can refer to the entire graph (e.g., representing a specific molecule) or a portion of it (e.g., a set of users in a recommendation system).Aggregation, combination, and readout functions can be neural networks that may need to be trained before deployment. Training is performed via modifications of the traditional backpropagation algorithms, which take into account the unique traits of a GNN. Since a GNN unfolds into L layers similarly to a RNN, most GNNs employ Back-Propagation-Through-Time (BPTT) schemes or variants of it. A popular variant of BPTT is the Pineda-Almeida algorithm [5,122], which relaxes the memory requirements as already mentioned in the seminal work by Scarselli et al. [130]. Specifically, in BPTT, a forward pass is first performed on the unfolded version of the GNN with its L layers. The loss function ε is then computed and the necessary gradient is backpropagated across layers. Since the weights are shared among all L layers, they are updated accordingly. This process is carried out recurrently with multiple samples, often grouped in batches, until some target accuracy is reached. Depending on the problem, a sample can refer to the entire graph (e.g., representing a specific molecule) or a portion of it (e.g., a set of users in a recommendation system).</p>
        <p>To exemplify the computation occurring during training, bottom charts of Figure 4 represent backpropagation in a two-layer GNN. Again, we show the operations from the perspective of node Computing Graph Neural Networks: A Survey from Algorithms to Accelerators 191: 111, although all nodes would be realizing similar computations at the same time. The backward pass implies calculating the gradient of the loss function with respect to the weights first, via partial derivative over W (2) , and then with respect to each vertex's feature vector. The operation is then repeated for the first layer, via its own weight matrix W (1) and each vertex's feature vector. The derivatives of the loss function are, eventually, used to update the weight matrices.To exemplify the computation occurring during training, bottom charts of Figure 4 represent backpropagation in a two-layer GNN. Again, we show the operations from the perspective of node Computing Graph Neural Networks: A Survey from Algorithms to Accelerators 191: 111, although all nodes would be realizing similar computations at the same time. The backward pass implies calculating the gradient of the loss function with respect to the weights first, via partial derivative over W (2) , and then with respect to each vertex's feature vector. The operation is then repeated for the first layer, via its own weight matrix W (1) and each vertex's feature vector. The derivatives of the loss function are, eventually, used to update the weight matrices.</p>
        <p>The computation of the loss function depends on the type of learning. While graph-centric approaches tend to be trained using supervised learning, node-centric approaches are usually trained by means of semi-supervised learning, wherein information of the node features from a portion of the graph, and not the whole graph, is utilized. An example of the former method can be learning if a specific new molecule (graph) has a certain property, using a GNN trained with molecules (graphs) whose properties are known beforehand and used as ground truth [56]. For the latter method, an example can be a recommender system. In such a system, a graph represents a store with nodes being shopping items and their features, and edges being relations among items. The output feature vector could describe how likely a given user will be satisfied with a particular item. In this case, a priori complete information is not available and semi-supervised learning from past purchases by this and other users (a subgraph) is used instead [167].The computation of the loss function depends on the type of learning. While graph-centric approaches tend to be trained using supervised learning, node-centric approaches are usually trained by means of semi-supervised learning, wherein information of the node features from a portion of the graph, and not the whole graph, is utilized. An example of the former method can be learning if a specific new molecule (graph) has a certain property, using a GNN trained with molecules (graphs) whose properties are known beforehand and used as ground truth [56]. For the latter method, an example can be a recommender system. In such a system, a graph represents a store with nodes being shopping items and their features, and edges being relations among items. The output feature vector could describe how likely a given user will be satisfied with a particular item. In this case, a priori complete information is not available and semi-supervised learning from past purchases by this and other users (a subgraph) is used instead [167].</p>
        <p>Matrix multiplication notation: To express backpropagation in a compact manner, we adapt the formulation in Reference [144] to the notation introduced in the previous section. Let Z (l ) = AH (l ) W (l ) so that H (l +1) = σ (Z (l ) ). Then, the backpropagation starts by calculating the gradient of the loss function ε, which we denote as Y , with respect to the weight matrix of the last layer. For an arbitrary layer l, this operation yieldsMatrix multiplication notation: To express backpropagation in a compact manner, we adapt the formulation in Reference [144] to the notation introduced in the previous section. Let Z (l ) = AH (l ) W (l ) so that H (l +1) = σ (Z (l ) ). Then, the backpropagation starts by calculating the gradient of the loss function ε, which we denote as Y , with respect to the weight matrix of the last layer. For an arbitrary layer l, this operation yields</p>
        <p>where G (l ) is the gradient with respect to Z (l ) and T denotes a transpose matrix. Therefore, G (l ) refers to the propagation of the error back to each particular aggregated feature vector, yieldingwhere G (l ) is the gradient with respect to Z (l ) and T denotes a transpose matrix. Therefore, G (l ) refers to the propagation of the error back to each particular aggregated feature vector, yielding</p>
        <p>where σ is the derivative of the non-linear activation function.where σ is the derivative of the non-linear activation function.</p>
        <p>In this section, we aim to demonstrate that GNN computing is in an early yet rising stage as compared to the rest of GNN disciplines. We also observe that there is a wide variety of GNN algorithms that, as we will see in Section 4, complicate the task of designing accelerators. To these ends, we present the evolution of the body of knowledge in the area of GNNs from a general perspective in Section 3.1 and from an algorithm perspective in Section 3.2.In this section, we aim to demonstrate that GNN computing is in an early yet rising stage as compared to the rest of GNN disciplines. We also observe that there is a wide variety of GNN algorithms that, as we will see in Section 4, complicate the task of designing accelerators. To these ends, we present the evolution of the body of knowledge in the area of GNNs from a general perspective in Section 3.1 and from an algorithm perspective in Section 3.2.</p>
        <p>The study uses a KG approach that naturally exposes the confluence of multiple interrelated sub-fields in the GNN landscape. To generate the KG, a repository of annotated papers has been created. The papers are classified by their year of publication and are manually given a single tag using the title and keywords as main reference. Further, the references of each paper are extracted by means of the CERMINE library [142]. The generated database is introduced into the 
            <rs type="software">Neo4j</rs> graph tool [156], which allows to visualize the KG with nodes and edges representing papers and their citation relations, respectively. To highlight the category and importance of papers, vertices are color-coded depending on the paper category and sized proportionally to the number of citations.
        </p>
        <p>This tag encompasses the papers that explore the complexity within the GNN structure and its operations.This tag encompasses the papers that explore the complexity within the GNN structure and its operations.</p>
        <p>The exploration of the complexity of GNN execution may have started with Reference [131] in 2009, which analyzed the complexity for the most common GNNs at that moment. After this, we have to wait until 2017 to find more works that take into account complexity, as datasets become more resource demanding and large-scale applications become apparent.The exploration of the complexity of GNN execution may have started with Reference [131] in 2009, which analyzed the complexity for the most common GNNs at that moment. After this, we have to wait until 2017 to find more works that take into account complexity, as datasets become more resource demanding and large-scale applications become apparent.</p>
        <p>[ 13,18,21,26,38,82,117,122,131,148,159,169,188] 14.29%[ 13,18,21,26,38,82,117,122,131,148,159,169,188] 14.29%</p>
        <p>This tag refers to papers that introduce new algorithm variants to the GNN family, including aspects such as attention, isomorphism, sampling, or new operations at the aggregate-combine phases.This tag refers to papers that introduce new algorithm variants to the GNN family, including aspects such as attention, isomorphism, sampling, or new operations at the aggregate-combine phases.</p>
        <p>We consider [130] as the first unification of multiple similar prior approaches. Others have attempted to do similar generalizations, such as the MPNN from Gilmer et al. [56] or the GN from Battaglia et al. [11].We consider [130] as the first unification of multiple similar prior approaches. Others have attempted to do similar generalizations, such as the MPNN from Gilmer et al. [56] or the GN from Battaglia et al. [11].</p>
        <p>[[</p>
        <p>GNN HW/SWGNN HW/SW</p>
        <p>This tag gathers works that, with the increasing popularity of GNNs as well as the complexity of the data-sets, analyzed the actual computational needs required to address these challenges.This tag gathers works that, with the increasing popularity of GNNs as well as the complexity of the data-sets, analyzed the actual computational needs required to address these challenges.</p>
        <p>2018. This specific sub-field started to gain traction in 2018, with the first work leading to Reference [106] where the hardware and software efficiencies in executing GNNs were studied.2018. This specific sub-field started to gain traction in 2018, with the first work leading to Reference [106] where the hardware and software efficiencies in executing GNNs were studied.</p>
        <p>[8, 76, 77, 106, 141, 144, 163, 182] 8.79%[8, 76, 77, 106, 141, 144, 163, 182] 8.79%</p>
        <p>Dataflow refers to the movement of data within the processing engine, which becomes crucial for the design of custom accelerators. Hence, under this tag we categorize the papers that formally describe possible dataflow solutions.Dataflow refers to the movement of data within the processing engine, which becomes crucial for the design of custom accelerators. Hence, under this tag we categorize the papers that formally describe possible dataflow solutions.</p>
        <p>2018. Two primary works, i.e., Reference [106], which covers scalability in the training, and Reference [104], which covers efficiency for partitioning of the graph data, emerged.2018. Two primary works, i.e., Reference [106], which covers scalability in the training, and Reference [104], which covers efficiency for partitioning of the graph data, emerged.</p>
        <p>[84, 104, 106] 3.30%[84, 104, 106] 3.30%</p>
        <p>Our first treatment of the GNN literature consists in classifying the papers by discipline. Concretely, we define the following taxonomy with topics ranging from formal mathematical aspects, to the algorithms, applications, and computing aspects: GNN modeling, GNN applications, GNN complexity, GNN algorithms, GNN accelerators, GNN HW/SW requirements, and GNN dataflow. The description of each topic, together with a discussion of its first works and the list of its references is given in Table 5. We also show the percentage of papers that pertain to a given category. An important finding from our analysis is that the percentage of papers being categorized for GNN accelerators, GNN HW/SW requirements, and GNN dataflow are 10.99%, 8.79%, and 3.30%, respectively. These categories mostly relate to the computing side of GNNs as they concern the analysis of computational requirements of GNNs, optimization of GNNs via software, and development of hardware accelerators. We thus observe that a very small percentage of the existing research has approached GNNs from the perspective of computing. We further note that the first works to deal with these topics date back from 2017, when the very first specific paper on GNN acceleration was published. It can be therefore concluded that GNN processing is in its nascent stages of development. This is the main reason for computing aspects not being analyzed in depth in recent GNN surveys [11,16,19,66,91,160,181,185], which we aim to address in this work, and also represents an opportunity to make an early impact in the GNN research field.Our first treatment of the GNN literature consists in classifying the papers by discipline. Concretely, we define the following taxonomy with topics ranging from formal mathematical aspects, to the algorithms, applications, and computing aspects: GNN modeling, GNN applications, GNN complexity, GNN algorithms, GNN accelerators, GNN HW/SW requirements, and GNN dataflow. The description of each topic, together with a discussion of its first works and the list of its references is given in Table 5. We also show the percentage of papers that pertain to a given category. An important finding from our analysis is that the percentage of papers being categorized for GNN accelerators, GNN HW/SW requirements, and GNN dataflow are 10.99%, 8.79%, and 3.30%, respectively. These categories mostly relate to the computing side of GNNs as they concern the analysis of computational requirements of GNNs, optimization of GNNs via software, and development of hardware accelerators. We thus observe that a very small percentage of the existing research has approached GNNs from the perspective of computing. We further note that the first works to deal with these topics date back from 2017, when the very first specific paper on GNN acceleration was published. It can be therefore concluded that GNN processing is in its nascent stages of development. This is the main reason for computing aspects not being analyzed in depth in recent GNN surveys [11,16,19,66,91,160,181,185], which we aim to address in this work, and also represents an opportunity to make an early impact in the GNN research field.</p>
        <p>A second order analysis stems from the careful observation of the KG, which we show in Figure 5. In the left plot, the size of the node represents the aggregated number of papers in a category, whereas the thickness of the edge between two nodes illustrates the relative amount of citations between the papers of a given pair of categories. In the right plot, we can also analyze the connections between the papers within the same category. Several observations can be made:A second order analysis stems from the careful observation of the KG, which we show in Figure 5. In the left plot, the size of the node represents the aggregated number of papers in a category, whereas the thickness of the edge between two nodes illustrates the relative amount of citations between the papers of a given pair of categories. In the right plot, we can also analyze the connections between the papers within the same category. Several observations can be made:</p>
        <p>(i) The categories related to computing are small yet well connected to the theoretical side of GNNs, corroborating our earlier observation from Table 5. (ii) The algorithms sub-field is large as many papers have appeared implementing multiple variants in the heterogeneous group of methods that GNN is. We review the evolution of GNN algorithms later in Section 3.2. (iii) The applications sub-field is large but sparsely connected internally, which means that application papers are generally not aware of other applications, unless reusing some specific common mechanism. This may be due to the wide variety of application fields for GNNs, ranging from social networks to chemistry, computer networks, or even material science as analyzed in previous sections. (iv) The algorithm and application categories have a strong inter-connectivity, as each application paper shall at least mention the algorithms used to implement the proposed system. (v) The connection from application papers to computing papers is weak. This may be due to the relative immaturity of the GNN computing field and this may change in upcoming years, especially if applications clearly benefiting from specialized accelerators arise (akin to the appearance of CNN accelerators for computer vision).(i) The categories related to computing are small yet well connected to the theoretical side of GNNs, corroborating our earlier observation from Table 5. (ii) The algorithms sub-field is large as many papers have appeared implementing multiple variants in the heterogeneous group of methods that GNN is. We review the evolution of GNN algorithms later in Section 3.2. (iii) The applications sub-field is large but sparsely connected internally, which means that application papers are generally not aware of other applications, unless reusing some specific common mechanism. This may be due to the wide variety of application fields for GNNs, ranging from social networks to chemistry, computer networks, or even material science as analyzed in previous sections. (iv) The algorithm and application categories have a strong inter-connectivity, as each application paper shall at least mention the algorithms used to implement the proposed system. (v) The connection from application papers to computing papers is weak. This may be due to the relative immaturity of the GNN computing field and this may change in upcoming years, especially if applications clearly benefiting from specialized accelerators arise (akin to the appearance of CNN accelerators for computer vision).</p>
        <p>To further understand the state of things in GNNs, we visualize the evolution of the field over time. Specifically, we plot the growth of the KG and of the amount of published papers over the years in Figure 6. First works started to appear as soon as 2005 [57] and, at that point, most research efforts were centered around new algorithms and possible applications. Evolution was rather slow for a decade, which we attribute to the lack of a killer application and the modest popularity of deep learning methods at that time. The field exploded around 2016, when CNNs and RNNs were already well established. Such a dramatic growth coincides with the introduction of the Graph Convolutional Networks (GCN) [86], one of the first and most popular models for GNNs, later followed by the introduction of the message passing notation and quantum chemistry application in Reference [56]. We further observe that research on GNN computing started in 2017 and, since then, attained a similar growth to that of the field. This trend may be an indicator of a strong increase of related works in the near future. Hence, it can be concluded that the area of GNN accelerator design and development is emerging and, thus, necessitates deeper insights that we provide in upcoming sections.To further understand the state of things in GNNs, we visualize the evolution of the field over time. Specifically, we plot the growth of the KG and of the amount of published papers over the years in Figure 6. First works started to appear as soon as 2005 [57] and, at that point, most research efforts were centered around new algorithms and possible applications. Evolution was rather slow for a decade, which we attribute to the lack of a killer application and the modest popularity of deep learning methods at that time. The field exploded around 2016, when CNNs and RNNs were already well established. Such a dramatic growth coincides with the introduction of the Graph Convolutional Networks (GCN) [86], one of the first and most popular models for GNNs, later followed by the introduction of the message passing notation and quantum chemistry application in Reference [56]. We further observe that research on GNN computing started in 2017 and, since then, attained a similar growth to that of the field. This trend may be an indicator of a strong increase of related works in the near future. Hence, it can be concluded that the area of GNN accelerator design and development is emerging and, thus, necessitates deeper insights that we provide in upcoming sections.</p>
        <p>GNNs are a set of models with a vast amount of possible configurations and design decisions that allow to modulate the inductive bias of the algorithm. We have seen how, due to their flexibility and potential applicability, the family of GNN algorithms has grown rapidly in recent years. Since different algorithms may be more or less amenable to certain acceleration techniques, here we briefly summarize the progress in this sub-field from graph kernels to modern GNN algorithms. Note that a deep review of existing GNN algorithms is not the main focus of this work. For such an analysis, we refer the reader to more specific surveys [11,19,160,181,185].GNNs are a set of models with a vast amount of possible configurations and design decisions that allow to modulate the inductive bias of the algorithm. We have seen how, due to their flexibility and potential applicability, the family of GNN algorithms has grown rapidly in recent years. Since different algorithms may be more or less amenable to certain acceleration techniques, here we briefly summarize the progress in this sub-field from graph kernels to modern GNN algorithms. Note that a deep review of existing GNN algorithms is not the main focus of this work. For such an analysis, we refer the reader to more specific surveys [11,19,160,181,185].</p>
        <p>Pre-GNN techniques. Prior to the advent of GNNs, relational information extraction from graphs was based on graph embeddings, i.e., the pre-processing of the graph to condense the information in a low-dimensional space thus making it amenable to traditional ML algorithms [16,31]. Similarly, Graph Kernels (GK) are a family of methods that, after extracting graph-level embeddings Fig. 7. GNN algorithm taxonomy based on model architectures and training strategies, adapted from [181] and [160].Pre-GNN techniques. Prior to the advent of GNNs, relational information extraction from graphs was based on graph embeddings, i.e., the pre-processing of the graph to condense the information in a low-dimensional space thus making it amenable to traditional ML algorithms [16,31]. Similarly, Graph Kernels (GK) are a family of methods that, after extracting graph-level embeddings Fig. 7. GNN algorithm taxonomy based on model architectures and training strategies, adapted from [181] and [160].</p>
        <p>of two or more graphs, compare them for classification tasks [55,70]. An example of such approach is the random walk kernel, wherein random walks are performed on the graphs while simultaneously counting the matching walks [52]. As compared to GNNs, GKs are easier to train, because they have less hyperparameters, which on the other hand limits their performance. The main reason stems in the loss of potential information incurred by the process of graph embedding. Thus, to achieve acceptable performance, GKs require handcrafted (not learned) feature maps, whilst GNNs do not. GNNs retain the inherent graph structure as a powerful and expressive form of defining the neural network, instead of distilling the essence of the graph to feed a conventional neural network.of two or more graphs, compare them for classification tasks [55,70]. An example of such approach is the random walk kernel, wherein random walks are performed on the graphs while simultaneously counting the matching walks [52]. As compared to GNNs, GKs are easier to train, because they have less hyperparameters, which on the other hand limits their performance. The main reason stems in the loss of potential information incurred by the process of graph embedding. Thus, to achieve acceptable performance, GKs require handcrafted (not learned) feature maps, whilst GNNs do not. GNNs retain the inherent graph structure as a powerful and expressive form of defining the neural network, instead of distilling the essence of the graph to feed a conventional neural network.</p>
        <p>Since the seminal work by Scarselli et al. [130], multiple approaches have been published with the aim of elaborating and complementing the GNN concept [6,37,69,118] and many classifications can be carried out. A common distinction relates to the fundamental model upon which the GNN is built, for which a few taxonomies can be found in existing surveys [11,19,160,181,185]. As a reference, Figure 7 reproduces the classification made in Reference [185], which mostly differentiates between recurrent-based GNNs, convolutional-based GNNs, graph autoencoders, graph reinforcement learning, and graph adversarial networks. We added the remark made in Reference [160], where combinations of recurrent and convolutional approaches are termed as spatial-temporal.Since the seminal work by Scarselli et al. [130], multiple approaches have been published with the aim of elaborating and complementing the GNN concept [6,37,69,118] and many classifications can be carried out. A common distinction relates to the fundamental model upon which the GNN is built, for which a few taxonomies can be found in existing surveys [11,19,160,181,185]. As a reference, Figure 7 reproduces the classification made in Reference [185], which mostly differentiates between recurrent-based GNNs, convolutional-based GNNs, graph autoencoders, graph reinforcement learning, and graph adversarial networks. We added the remark made in Reference [160], where combinations of recurrent and convolutional approaches are termed as spatial-temporal.</p>
        <p>On the one hand, recurrent-based GNNs refer to the initial GNN models including that of Scarselli [130], which employ recurrent units as the combination function. Other examples are CommNet [137], which operates over simple aggregations without edge transformations, or Gated Graph Neural Networks (GG-NN) [102], which use gated recurrent units [30] as the update function to improve convergence. On the other hand, convolutional-based GNNs expand the idea of convolution in the graph space [27] and can be divided into spectral-based [69] and spatial-based GNNs [186]. On the one hand, spectral-based models are built on spectral graph theory using graph signal processing techniques such as eigenvalue decomposition and filtering. However, they are computationally expensive methods, since the entire graph must be considered at once. On the other hand, spatial-based GNNs are much more computationally affordable, flexible, and scalable, since they only need to perform convolutions to the aggregation of features from neighbouring vertices [186]. Finally, spatial-temporal GNNs use both the spatial approach of the convolutions with the temporal approach of the recurrent units. An example is the network in gated graph convolutional network (G-GCN) from Reference [15].On the one hand, recurrent-based GNNs refer to the initial GNN models including that of Scarselli [130], which employ recurrent units as the combination function. Other examples are CommNet [137], which operates over simple aggregations without edge transformations, or Gated Graph Neural Networks (GG-NN) [102], which use gated recurrent units [30] as the update function to improve convergence. On the other hand, convolutional-based GNNs expand the idea of convolution in the graph space [27] and can be divided into spectral-based [69] and spatial-based GNNs [186]. On the one hand, spectral-based models are built on spectral graph theory using graph signal processing techniques such as eigenvalue decomposition and filtering. However, they are computationally expensive methods, since the entire graph must be considered at once. On the other hand, spatial-based GNNs are much more computationally affordable, flexible, and scalable, since they only need to perform convolutions to the aggregation of features from neighbouring vertices [186]. Finally, spatial-temporal GNNs use both the spatial approach of the convolutions with the temporal approach of the recurrent units. An example is the network in gated graph convolutional network (G-GCN) from Reference [15].</p>
        <p>Due to their flexibility and scalability, spatial-based convolutional GNNs are arguably the most popular model [20,29,48,71,99,133,143,158,165,172]. In this paradigm, basic algorithms use a mean function as aggregation, sometimes also taking the degree of neighboring into account [87], after which many variants followed. 
            <rs type="software">GraphSAGE</rs> incorporated information of self-node features from previous layers in the update function and also pioneered the concept of sampling in GNNs to reduce the computational cost of aggregation [65]. FastGCN [20] also uses the sampling idea and integrates other strategies to speed up computations, such as evaluating integral formulations using Monte Carlo sampling. Another simplifying operation is the differential pooling of DiffPool [168], which forms hierarchical clusters so that later layers operate on coarser graphs. On a different approach, Graph Isomorphism Network (GIN) [159,162] proved that the conditions needed for a GNN to achieve the maximum expressive power in capturing the structure of a graph are to emulate a WL test [157]. The particularity occurs at the graph output feature vector, which is obtained by concatenating the readout vectors of all layers. We finally highlight Graph Attention Networks (GAT) as the enabler of multiple works in Natural Language Processing [145] and a particular case of the popular transformers approach. GATs update the node features through a pairwise function between the nodes with learnable weights [146]. This allows to operate with a learnt attention mechanism that describes the utility of the edges.
        </p>
        <p>Another branch of GNNs are the so-called Graph Autoencoders (GAE) [86]. These GNNs are generative, which means that they convert a graph into a latent representation (i.e., encoding) that can be later expanded to generate to a new graph close in structure to the original one (i.e., decoding). What make these techniques unique in the graph domain is that GCNs may be used to generate the low-dimensional vectors in the encoding process [127]. GAEs are also typically trained using adversarial techniques, giving rise to graph adversarial networks such as NetRA [173].Another branch of GNNs are the so-called Graph Autoencoders (GAE) [86]. These GNNs are generative, which means that they convert a graph into a latent representation (i.e., encoding) that can be later expanded to generate to a new graph close in structure to the original one (i.e., decoding). What make these techniques unique in the graph domain is that GCNs may be used to generate the low-dimensional vectors in the encoding process [127]. GAEs are also typically trained using adversarial techniques, giving rise to graph adversarial networks such as NetRA [173].</p>
        <p>We finally highlight that GNNs can be combined with reinforcement learning to give rise to novel graph learning techniques. For instance, 
            <rs type="software">MolGAN</rs> [35] generates molecular graphs with a certain end goal (reward). Another example is 
            <rs type="software">MINERVA</rs>, where reinforcement learning helps to predict the next node in the reasoning path of a KG [33].
        </p>
        <p>Comprehensive frameworks. An aspect worth mentioning is that, within this multitude of algorithms, several groups have attempted to unify methods. One of the most popular ones is the message passing scheme [56,183], whose operation and description are amenable to convolutional networks for learning molecular fingerprints [41], the classification methodology with GCN from [87], the interactive networks utilized for learning relationships and features [12], or also different flavours of Gated GNNs, to name a few. A further approach is that of the Non-Local Neural Networks (NLNN) [152] aimed at unifying various attention approaches including GATs. These generally do not include edges features or aggregations and, instead, just involve pairwise scalar attention weights between nodes. Both MPNN and NLNN are also included into a further approach to unification referred to as Graph Networks and proposed in Reference [11]. There, update functions applied to nodes, edges, or the complete graph are treated as differentiated blocks. The combination or repetition of several of these blocks gives rise to the different types of GNN found in the literature. Finally, Chami et al. propose an encoder-decoder model to express different graph embedding, graph regularization, graph auto-encoder, and GNN techniques [19].Comprehensive frameworks. An aspect worth mentioning is that, within this multitude of algorithms, several groups have attempted to unify methods. One of the most popular ones is the message passing scheme [56,183], whose operation and description are amenable to convolutional networks for learning molecular fingerprints [41], the classification methodology with GCN from [87], the interactive networks utilized for learning relationships and features [12], or also different flavours of Gated GNNs, to name a few. A further approach is that of the Non-Local Neural Networks (NLNN) [152] aimed at unifying various attention approaches including GATs. These generally do not include edges features or aggregations and, instead, just involve pairwise scalar attention weights between nodes. Both MPNN and NLNN are also included into a further approach to unification referred to as Graph Networks and proposed in Reference [11]. There, update functions applied to nodes, edges, or the complete graph are treated as differentiated blocks. The combination or repetition of several of these blocks gives rise to the different types of GNN found in the literature. Finally, Chami et al. propose an encoder-decoder model to express different graph embedding, graph regularization, graph auto-encoder, and GNN techniques [19].</p>
        <p>Programming models. From the perspective of computation, several programming abstractions are considered to support all possible operations within any GNN, generally compatible with the aggregate-combine model. These models are useful when the matrix multiplication notation cannot be employed, because the aggregation or combination operations are not amenable to it or because the adjacency matrix is extremely sparse and suggests the use of other representations such as compressed sparse row or column. In fact, as we will see in the next section, multiple accelerators implement GNN-oriented programming models.Programming models. From the perspective of computation, several programming abstractions are considered to support all possible operations within any GNN, generally compatible with the aggregate-combine model. These models are useful when the matrix multiplication notation cannot be employed, because the aggregation or combination operations are not amenable to it or because the adjacency matrix is extremely sparse and suggests the use of other representations such as compressed sparse row or column. In fact, as we will see in the next section, multiple accelerators implement GNN-oriented programming models.</p>
        <p>Among the different possible models, we highlight the Scatter-ApplyEdge-Gather-ApplyVertex with Neural Networks (SAGA-NN) from Reference [106], which is followed implicitly in most modern libraries [182]. SAGA-NN augments classical scatter-gather approaches with two operations and works as follows: Scatter sends the nodes' feature vectors through their edges and 
            <rs type="software">ApplyEdge</rs> performs edge combination with the scattered vectors. Then, 
            <rs type="software">Gather</rs> allows each vertex to aggregate the vectors from its neighbours, and ApplyVertex performs the vertex combination after the gather operation. Another proposed model is that of Gather-Reduce-Transform-Activate (GReTA) from Reference [84]. In this case, the four operations are userdefined and can be modified to implement any GNN. Aggregation is performed through gather and reduce, which allow each vertex to obtain the features from their neighbours and accumulate them into a single value. Combination is then performed through transform and activate, which typically do the matrix multiplication and non-linear activation of the aggregated data. More recently, Wang et al. proposed the NeighborSelection-Aggregation-Update model, which adds a flexible neighbor selection layer to the more conventional aggregate-update [150].
        </p>
        <p>The optimization of ML algorithms and the building of custom hardware for high performance and efficiency has experienced an explosive growth in recent years [25,67]. This has come shortly after academia and industry have unveiled the outstanding potential of DNN algorithms and their all-pervasive applicability. As evidenced in previous sections, the field of GNNs is arriving at a similar turning point. At the time of this writing, research in GNN methods is already extensive and keeps refining the algorithms and investigating new applications with high potential impact. Therefore, a key research aspect in the years ahead will be how to compute GNNs efficiently to realize their full potential.The optimization of ML algorithms and the building of custom hardware for high performance and efficiency has experienced an explosive growth in recent years [25,67]. This has come shortly after academia and industry have unveiled the outstanding potential of DNN algorithms and their all-pervasive applicability. As evidenced in previous sections, the field of GNNs is arriving at a similar turning point. At the time of this writing, research in GNN methods is already extensive and keeps refining the algorithms and investigating new applications with high potential impact. Therefore, a key research aspect in the years ahead will be how to compute GNNs efficiently to realize their full potential.</p>
        <p>
            <rs type="software">GNN</rs> computing presents a set of unique challenges [163,182] that have rendered existing libraries and hardware platforms inefficient, including:
        </p>
        <p>(i) The existence of multiple GNN variants, which may include edge, vertex, and graphwide updates, with a variety of aggregation and combination functions as illustrated in Table 6, and possibly incorporating pooling and graph/layer sampling operations as well [28,176]. These functions affect aspects such as the choice of operations to accelerate, the relative computational complexity of aggregation and combination, or the ordering constraints among them and across layers. Hence, instead of using a single general acceleration technique, GNN may require finding the right combination of techniques that works for a particular GNN variant. (ii) The dependence of computation on the characteristics of the input graph in terms of size, sparsity, clustering, or the length of the associated feature vectors. Graph connectivity may follow a power-law distribution, be evenly distributed, or be bipartite. Since the computation fundamentally depends on the input graph, decisions such as the use of dense or sparse logic, the dataflow to implement, the partitioning strategy, or the partitions' mapping and scheduling may need to be changed within and across graphs to maximize performance [51,77,141]. The challenge is, therefore, to develop accelerators that can dynamically adapt to the graph characteristics. (iii) A unique combination of computing characteristics from deep learning and graph processing, leading to alternate execution patterns. More specifically, combination often implies MLP-like operations over a dense weight matrix, which is generally computation-bound [138]. In contrast, aggregation involves, among other operations, fetching groups of vertices that often lead to irregular memory patterns [59]. Optimizations in(i) The existence of multiple GNN variants, which may include edge, vertex, and graphwide updates, with a variety of aggregation and combination functions as illustrated in Table 6, and possibly incorporating pooling and graph/layer sampling operations as well [28,176]. These functions affect aspects such as the choice of operations to accelerate, the relative computational complexity of aggregation and combination, or the ordering constraints among them and across layers. Hence, instead of using a single general acceleration technique, GNN may require finding the right combination of techniques that works for a particular GNN variant. (ii) The dependence of computation on the characteristics of the input graph in terms of size, sparsity, clustering, or the length of the associated feature vectors. Graph connectivity may follow a power-law distribution, be evenly distributed, or be bipartite. Since the computation fundamentally depends on the input graph, decisions such as the use of dense or sparse logic, the dataflow to implement, the partitioning strategy, or the partitions' mapping and scheduling may need to be changed within and across graphs to maximize performance [51,77,141]. The challenge is, therefore, to develop accelerators that can dynamically adapt to the graph characteristics. (iii) A unique combination of computing characteristics from deep learning and graph processing, leading to alternate execution patterns. More specifically, combination often implies MLP-like operations over a dense weight matrix, which is generally computation-bound [138]. In contrast, aggregation involves, among other operations, fetching groups of vertices that often lead to irregular memory patterns [59]. Optimizations in</p>
        <p>Combination (h l +1 ) GCN [87] mean(N (h l )) ReLU (W l • a) GIN [162] mean(N (h l )) MLP (W • ((1+ϵ l ) •h l +a) GS-mean [65] mean(N (h l ))Combination (h l +1 ) GCN [87] mean(N (h l )) ReLU (W l • a) GIN [162] mean(N (h l )) MLP (W • ((1+ϵ l ) •h l +a) GS-mean [65] mean(N (h l ))</p>
        <p>Notation: σ is a nonlinear function, α j is the attention coefficient, b is the bias, is a dot-product, Concat is matrix concatenation, M LP is a multi-layer perceptron, GRU a gated recurrent unit, and LST M is Long short-term memory.Notation: σ is a nonlinear function, α j is the attention coefficient, b is the bias, is a dot-product, Concat is matrix concatenation, M LP is a multi-layer perceptron, GRU a gated recurrent unit, and LST M is Long short-term memory.</p>
        <p>aggregation can be done via sparse GEMM of the adjacency matrix [163], but they are not generalizable to all graphs/GNNs and typically not enough to combat the extreme sparsity of adjacency matrices. Therefore, the challenge is to develop architectures that accelerate such distinct phases and their intertwining at runtime. (iv) A wide pool of applications with not only different graph characteristics, but also different performance targets. For example, recommendation systems need to scale to extremely large graphs of up to billions of edges and target high computational throughput.aggregation can be done via sparse GEMM of the adjacency matrix [163], but they are not generalizable to all graphs/GNNs and typically not enough to combat the extreme sparsity of adjacency matrices. Therefore, the challenge is to develop architectures that accelerate such distinct phases and their intertwining at runtime. (iv) A wide pool of applications with not only different graph characteristics, but also different performance targets. For example, recommendation systems need to scale to extremely large graphs of up to billions of edges and target high computational throughput.</p>
        <p>In contrast, applications such as object detection in point clouds [134] or fraud detection [153] rather need to focus on latency and energy efficiency. This highlights the need for acceleration techniques that address not only the challenging GNN computation at relatively small scales and in real time, but also the storage and multi-GPU coordination issues at larger scales.In contrast, applications such as object detection in point clouds [134] or fraud detection [153] rather need to focus on latency and energy efficiency. This highlights the need for acceleration techniques that address not only the challenging GNN computation at relatively small scales and in real time, but also the storage and multi-GPU coordination issues at larger scales.</p>
        <p>A direct consequence of the aforementioned aspects is that the bottleneck or the critical operation/kernel may vary across GNNs or applications, as shown in References [10,163,182]. In light of these challenges, GNNs call for new solutions both in software and hardware. On the software side, several libraries have been proposed to improve the support for GNNs and efficiently compute its multiple variants both in inference and training. The extensions of popular libraries such as 
            <rs type="software">PyTorch</rs> or 
            <rs type="software">Tensorflow</rs> (
            <rs type="software">TF</rs>) [1,45,58] are clear examples of this. On the hardware side, new accelerator architectures have been surfacing recently [53,85,103] that attempt to deal with the flexibility and scalability challenges of GNNs mostly in inference thus far. In the next subsections, we provide an exhaustive overview of existing techniques.
        </p>
        <p>The challenges of GNN processing rendered both traditional DNN libraries and graph processing frameworks [63,154] inefficient. The reason is the alternating computing phases of GNNs. DNN libraries would be good at speeding up combination operations within vertices and edges, but perform poorly during aggregation. Graph processing libraries, instead, do a good job at managing irregular memory accesses when traversing the graph. However, these libraries assume trivial operations at the vertices, which is not the case in GNNs. To bridge this gap, recent works have started investigating how to adapt the libraries to (i) provide easy to program interfaces to implement multiple GNN variants, (ii) handle the variety of potentially sparse GNN operations efficiently in widespread GPU hardware, and (iii) scale computations to large-scale graphs and multiple GPUs.The challenges of GNN processing rendered both traditional DNN libraries and graph processing frameworks [63,154] inefficient. The reason is the alternating computing phases of GNNs. DNN libraries would be good at speeding up combination operations within vertices and edges, but perform poorly during aggregation. Graph processing libraries, instead, do a good job at managing irregular memory accesses when traversing the graph. However, these libraries assume trivial operations at the vertices, which is not the case in GNNs. To bridge this gap, recent works have started investigating how to adapt the libraries to (i) provide easy to program interfaces to implement multiple GNN variants, (ii) handle the variety of potentially sparse GNN operations efficiently in widespread GPU hardware, and (iii) scale computations to large-scale graphs and multiple GPUs.</p>
        <p>In the following, we review a comprehensive selection of software frameworks and accelerators, listed in Table 7. The analysis does not include 
            <rs type="software">GunRock</rs> [154] or 
            <rs type="software">GE-SpMM</rs> [74] for different reasons. 
            <rs type="software">GunRock</rs>, despite implementing 
            <rs type="software">GraphSAGE</rs> in its latest versions, is a graph processing library that does not exploit intra-vertex parallelism. In fact, two works detailed below [73,155] achieve speedups of 30-200× with respect to 
            <rs type="software">GunRock</rs>. 
            <rs type="software">GE-SpMM</rs>, although claiming to be tailored to GNNs, is an acceleration method for general-purpose sparse matrix multiplication in GPUs.
        </p>
        <p>A first observation from Table 7 is that software frameworks have been tested for a wide variety of GNN algorithms and relevant datasets. Around 20 different GNN variants have been evaluated, being GCN, GS, and GIN the most common. Even though Amazon, Reddit, Protein, Cora, or CiteSeer datasets are popular in the community, a lack of a widely adopted benchmark suite [72] makes the datasets to vary widely. It is worth noting, however, that graphs can range from hundreds of edges in chemistry applications to billions of edges in large-scale recommendation systems. As we see next, performance comparisons are scarce, but generally take 
            <rs type="software">PyTorch Geometric (PyG)</rs>, TF, and 
            <rs type="software">Deep Graph Library (DGL</rs>) as baselines and often report between one and two orders of magnitude improvement typically in CPU+GPU platforms, with some exceptions on multi-GPU systems [76,106] or distributed computing clusters with up to 32K cores [150,178]. Most of the tested frameworks provide optimizations that could work for both acceleration of both training and inference, yet the evaluation is unequal. Training is evaluated in References [45,73,76,105,106,141,150,151,178,187], whereas inference time is only measured in References [73,76,77,84,155,178].
        </p>
        <p>
            <rs type="software">PyTorch Geometric. PyG</rs> [45] is a widespread library that is built upon 
            <rs type="software">PyTorch</rs> and that provides support for relational learning, illustrated in a myriad of algorithms. The key aspect is the definition of a message passing interface with definition of message and update functions for neighbourhood aggregation and combination, respectively, and multiple pooling operations. To accelerate GNN processing, 
            <rs type="software">PyG</rs> handles sparsity via dedicated GPU scatter and gather kernels that operate in all edges and nodes in parallel, instead of using sparse matrix multiplication kernels. Relevantly, Facebook released 
            <rs type="software">Pytorch-BigGraph</rs> [94], a library that allows to process arbitrarily large graphs by introducing partitioning and distributed processing and that could complement 
            <rs type="software">PyG</rs>.
        </p>
        <p>
            <rs type="software">Deep Graph Library</rs>. 
            <rs type="software">DGL</rs> [151] is a recent library that works on top of TF, 
            <rs type="software">PyTorch</rs>, or 
            <rs type="software">MXNet</rs>, and provides plenty of examples and code for multiple GNNs. The library defines three functions: message for edge aggregation and update and reduce and update for aggregation and combination at the nodes. To boost performance, 
            <rs type="software">DGL</rs> takes a matrix multiplication approach and leverages specialized kernels for GPUs or TPUs. In particular, both sampled dense-dense and sparse matrix multiplications are considered together with node, edge or feature parallelization. As discussed in their work [151], 
            <rs type="software">DGL</rs> uses heuristics to choose among the different options as the optimal parallelization scheme depends on multiple factors including the input graph. Thanks to this approach, 
            <rs type="software">DGL</rs> claims to achieve an order of magnitude faster training than 
            <rs type="software">PyG</rs>. Recently, researchers at Amazon have released a DistDGL, a system based on DGL for distributed mini-batch training scalable to billion-edge graphs [184]. To achieve it, 
            <rs type="software">DistDGL</rs> uses min-cut graph partitioning via a lightweight algorithm.
        </p>
        <p>
            <rs type="software">NeuGraph</rs>. 
            <rs type="creator">Microsoft</rs> Research led one of the first specialized frameworks for parallel processing of GNNs in GPUs, 
            <rs type="software">NeuGraph</rs> [106]. Although it is built on top of TF, 
            <rs type="software">NeuGraph</rs> is not open source at the time of this writing. The framework implements a programming model, SAGA-NN, based on the functions 
            <rs type="software">Scatter</rs> for edge aggregation, ApplyEdge for edge combination, 
            <rs type="software">Gather</rs> for node aggregation, and ApplyVertex for node combination. Scatter-gather kernels are used in the • Library compatible with TF, 
            <rs type="software">PyTorch</rs> and 
            <rs type="software">MXNet</rs>.
        </p>
        <p>• Deep documentation and support, tutorials.• Deep documentation and support, tutorials.</p>
        <p>• Based on matrix-mul kernels. Evaluation in CPU and GPU.• Based on matrix-mul kernels. Evaluation in CPU and GPU.</p>
        <p>• Augmented with 
            <rs type="software">DistDGL</rs> [184] for distributed computing.
        </p>
        <p>GCN, GAT, SGC, GS, GIN, R-GCN, GCMC Reddit, OGB (Arxiv, Protein, Product, Citation, PPA), Movielens 
            <rs type="software">PyG NeuGraph</rs> [106] • Implementation and evaluation for scaling to multiple GPUs.
        </p>
        <p>• Four-function model allowing for updates at edges and nodes.• Four-function model allowing for updates at edges and nodes.</p>
        <p>• Optimized partitioning, scheduling, pipelining, transfers. • Targeting large-scale graphs and distributed systems.• Optimized partitioning, scheduling, pipelining, transfers. • Targeting large-scale graphs and distributed systems.</p>
        <p>• Emphasis on distributed storage and partitioning • Only work with heterogeneous and dynamic GNNs, and huge datasets (up to 483M edges, 6.5B edges). Built on top of TF.• Emphasis on distributed storage and partitioning • Only work with heterogeneous and dynamic GNNs, and huge datasets (up to 483M edges, 6.5B edges). Built on top of TF.</p>
        <p>Amazon, Taobao N/A FlexGraph [150] • Uses NAU programming model for flexible aggregation.Amazon, Taobao N/A FlexGraph [150] • Uses NAU programming model for flexible aggregation.</p>
        <p>• Hierarchical aggregation with dynamic sparse-dense logic.• Hierarchical aggregation with dynamic sparse-dense logic.</p>
        <p>• Supports distributed computing, tested in 1500-core system. -GCN, PinSage, MAGNN Reddit, FB91, Twitter, IMDB PyG, DGL, DistDGL, Euler AGL [178] • Aiming for scalability, fault tolerance, and integrality.• Supports distributed computing, tested in 1500-core system. -GCN, PinSage, MAGNN Reddit, FB91, Twitter, IMDB PyG, DGL, DistDGL, Euler AGL [178] • Aiming for scalability, fault tolerance, and integrality.</p>
        <p>• Uses 
            <rs type="software">MapReduce</rs> to scale, tested in 32000-core system. GCN, GS, GAT Cora, PPI, UUG, PyG, DGL ROC [76] • Implemented on top of 
            <rs type="software">FlexFlow</rs> [78].
        </p>
        <p>• Optimizations: dynamic partitioning, memory management.• Optimizations: dynamic partitioning, memory management.</p>
        <p>• Evaluated with single and multiple GPUs via 
            <rs type="software">NVLink</rs>.
        </p>
        <p>Pubmed, PPI, 
            <rs type="software">Reddit</rs>, 
            <rs type="creator">Amazon</rs> TF, 
            <rs type="software">DGL</rs>, 
            <rs type="software">PyG</rs>, 
            <rs type="software">NeuGraph GNN Advisor</rs> [155] • Unique runtime profiling of graph information (degree, feature size, communities) to guide GPU processing • Motivated by power-law distribution of node degrees.
        </p>
        <p>• Optimized partitioning to generate dense matrices.• Optimized partitioning to generate dense matrices.</p>
        <p>• Dual execution mode depending on sparsity of each partition.• Dual execution mode depending on sparsity of each partition.</p>
        <p>• Built on top of TF, evaluated in single GPU.• Built on top of TF, evaluated in single GPU.</p>
        <p>Pubmed, Blog, Youtube, C1000-9, MANN-a81, Reddit, synthetic (RMAT) TF, DGL, PyG HAG [77] • Removes redundant sums in aggregation by fusing nodes.Pubmed, Blog, Youtube, C1000-9, MANN-a81, Reddit, synthetic (RMAT) TF, DGL, PyG HAG [77] • Removes redundant sums in aggregation by fusing nodes.</p>
        <p>• Runtime algorithm to fuse nodes only if predicted beneficial.• Runtime algorithm to fuse nodes only if predicted beneficial.</p>
        <p>• The impact on operation reduction is independent of hardware, but the impact on execution speed is not.• The impact on operation reduction is independent of hardware, but the impact on execution speed is not.</p>
        <p>GCN, GIN, SGC BZR, PPI, Reddit, IMDB, 
            <rs type="software">COLLAB</rs> N/A 
            <rs type="software">FeatGraph</rs> [73] • Optimized matmul kernels for aggregation and combination.
        </p>
        <p>• User-defined combination functions and optimizations. GCN, GS, GAT OGB (Proteins), Reedit, sythetic graphs GunRock G 3 [105] • Brings together graph processing frameworks and GNNs.• User-defined combination functions and optimizations. GCN, GS, GAT OGB (Proteins), Reedit, sythetic graphs GunRock G 3 [105] • Brings together graph processing frameworks and GNNs.</p>
        <p>• Offers APIs over C/C++ for ease of programming.• Offers APIs over C/C++ for ease of programming.</p>
        <p>• Uses 
            <rs type="software">GunRock</rs> [154] to provide GPU runtime optimizations.
        </p>
        <p>
            <rs type="software">GReTA</rs> [84] • Programming abstraction with user-defined functions, similar to SAGA, targeting accelerators and any GNN variant. • Evaluation based on GRIP (see Table 8) in ASIC.
        </p>
        <p>Youtube, Livejournal, Pokec, Reddit N/A functions of the same name, whereas matrix multiplication primitives are used in the combination functions. 
            <rs type="software">NeuGraph</rs> also features a number of optimizations to accelerate GNN computing. First, the partitioning of large graphs performed via the Kernighan-Lin algorithm to make partitions denser and minimize the transfers between partitions, which harm performance. Second, scheduling of partitions to the GPU is optimized by batching together small sparse partitions that can be computed together [115], and also profiling transfer and computation times in first GNN layer to later pipeline different chunks perfectly. Third, 
            <rs type="software">NeuGraph</rs> also eliminates redundant computation by fusing multiple edges together. Finally, it allow to scale GNN to multiple GPUs by distributing the computation, and optimizes the transfer of information by using a ring-based dataflow that minimizes contention at the interconnect. 
            <rs type="software">AliGraph</rs>. Developed by the AliBaba group and open-sourced with the name of graph-learn, 
            <rs type="software">AliGraph</rs> is a GNN framework built on top of TF [187]. The framework is thought for the processing of very large and dynamic graphs in large-scale computing systems, and is currently used
        </p>
        <p>Computing Graph Neural Networks: A Survey from Algorithms to Accelerators 191:21Computing Graph Neural Networks: A Survey from Algorithms to Accelerators 191:21</p>
        <p>in recommendation services at 
            <rs type="software">AliBaba</rs>. It implements three layers, namely storage, which implements partitioning with four different algorithms, but in this case to store the graph in a distributed way; sampling, which, unlike other frameworks, allows us to define custom sampling of a nodes' neighbourhood relevant to algorithms such as 
            <rs type="software">GraphSAGE</rs>; and operator, which implements the aggregation and combination functions. In overall, the 
            <rs type="software">AliGraph</rs> is unique due to its distributed approach and the many optimizations made at the storage layer to minimize data movement, such as the use of four different partitioning algorithms depending on the characteristics of the graph, or caching important vertices in multiple machines to reduce long misses.
        </p>
        <p>
            <rs type="software">FlexGraph</rs>. The AliBaba group also leads the development of 
            <rs type="software">FlexGraph</rs> [150], a distributed framework for GNN training whose distinct features are their flexible definitions of neighbourhood and the hierarchical aggregation schemes. To this end, 
            <rs type="software">FlexGraph</rs> uses the NAU programming model described in Section 3.2. To speedup training, 
            <rs type="software">FlexGraph</rs> combines hierarchical aggregation with a hybrid execution strategy combining sparse and dense logic. It also accelerates distributed execution through an application-driven workload balancing strategy and a pipeline processing strategy to overlap computations and communications.
        </p>
        <p>AGL. AGL [178] is a framework created specifically for industral deployments of massive GNNs.AGL. AGL [178] is a framework created specifically for industral deployments of massive GNNs.</p>
        <p>To that end, the authors emphasize their scalability, fault tolerance, and use of existing widespread methods for distributing the computation. In particular, AGL uses 
            <rs type="software">MapReduce</rs> [36] to that end and tests the proposed system in CPU clusters. The framework has three modules: one for creating independent neighbourhoods that can be processed in parallel, one for optimizing training, and one for the slicing of the graph and calculation of inference. Numerous optimizations are proposed in the sampling and indexing of the graph, partitioning and pruning, and pipelining of computation during training.
        </p>
        <p>ROC [76] is another GNN framework targeting multi-GPU systems, in this case built on top of 
            <rs type="software">FlexFlow</rs> [78]. Similarly to 
            <rs type="software">AliGraph</rs> or 
            <rs type="software">AGL</rs>, ROC is able to distribute large graphs to multiple machines. However, this framework differs from others in that the partitioning method and memory management is performed with dynamic methods providing extra acceleration. First, ROC uses an online linear regression model to approach partitioning optimally. This model uses the training iterations to learn the best strategy of a specific graph, outperforming static methods significantly. Second, memory management is treated as a cost minimization problem and solved via an online algorithm that finds where to best store each partition. The authors demonstrate that such acceleration methods provide better scalability than 
            <rs type="software">DGL</rs> and 
            <rs type="software">PyG</rs> in single GPUs, and better scaling to multiple GPUs than 
            <rs type="software">NeuGraph</rs>.
        </p>
        <p>
            <rs type="software">GNNAdvisor</rs>. The work by Wang et al. [155] presents a runtime system that aims to systematically accelerate GNNs on GPUs. Instead of treating this problem via abstract models as done in ROC, 
            <rs type="software">GNNAdvisor</rs> does an online profiling of the input graph and GNN operations to guide the memory and workload management agents at the GPU. In particular, it leverages (i) the node degree to fine-tune the group-based workload management of the GPU, (ii) the size of the node embedding to optimize workload sharing, and (iii) the existing of communities within the graph to guide partitioning and scheduling. While the two first features are trivial to obtain, community detection is generally harder. In this case, the authors use a combination of node renumbering and Reverse Cuthill-McKee algorithm to reorder the adjacency matrix in a way that dense partitions are available. Thanks to all these techniques, the authors claim 3-4× speedup over DGL, 
            <rs type="software">PyG</rs>, and 
            <rs type="software">NeuGraph</rs> in a high-end GPU.
        </p>
        <p>
            <rs type="software">PCGCN</rs>. The paper by Tian and co-authors [141] present a partition-centric approach to acceleration of GNNs in GPUs, which they implement on top of TF. The contribution is motivated by the power-law distribution of the node degrees in a graph, which largely affects partitioning. 
            <rs type="software">PCGCN</rs> applies a locality-aware partitioning, METIS [81], that helps obtaining dense sub-matrices. That, however, does not prevent sparse partitions to appear. To combat this, 
            <rs type="software">PCGCN</rs> profiles the partitions at runtime and applies a dual-mode of operation: dense matrix representation and multiplication kernels when dense, and column-sparse representation and sparse kernels otherwise. In the paper, the authors compare their implementation with vanilla TF, and also 
            <rs type="software">DGL</rs> and 
            <rs type="software">PyG</rs>, and report the lowest speedup across libraries. Even in this case, 
            <rs type="software">PCGCN</rs> always speeds up execution and achieves up to 8.8× in highly clustered graphs.
        </p>
        <p>HAG. This work presents the concept of Hierarchically Aggregated computation Graph (HAG) [77]. The authors make the observation that many of the operations made during the aggregation stage are repeated multiple times when nodes share similar neighbourhoods. In response to this, HAGs are presented as an alternative representation that proactively "fuses" nodes with common neighbourhoods, removing redundant aggregations during the execution of any GNN. Since the search of similarly connected nodes can be expensive, HAG employs a cost function to estimate the cost of certain node fusions, to then adopt a search algortihm affordable for runtime. With only 0.1% of memory overhead, HAG reduces the amount of aggregations by 6.3×.HAG. This work presents the concept of Hierarchically Aggregated computation Graph (HAG) [77]. The authors make the observation that many of the operations made during the aggregation stage are repeated multiple times when nodes share similar neighbourhoods. In response to this, HAGs are presented as an alternative representation that proactively "fuses" nodes with common neighbourhoods, removing redundant aggregations during the execution of any GNN. Since the search of similarly connected nodes can be expensive, HAG employs a cost function to estimate the cost of certain node fusions, to then adopt a search algortihm affordable for runtime. With only 0.1% of memory overhead, HAG reduces the amount of aggregations by 6.3×.</p>
        <p>
            <rs type="software">FeatGraph</rs>. Developed in collaboration with 
            <rs type="creator">Amazon</rs>, 
            <rs type="software">FeatGraph</rs> [73] proposes to optimize kernels of aggregation and combination separately. Different from other frameworks, here the user can define the combination function and ways to parallelize it, so that the scheduler can take it into account. As optimizations, 
            <rs type="software">FeatGraph</rs> also proposes to combine graph partitioning with feature dimension tiling and to adopt a hybrid partitioning scheme for GPUs.
        </p>
        <p>G 3 . Liu et al. [105] propose a framework for the training of GNNs in GPU systems. G 3 facilitates the task of GNN creation by providing a set of flexible APIs over C/C++ 
            <rs type="software">code</rs> that implement widespread layers and models. G 3 also incorporates a set of graph-centric optimizations based on 
            <rs type="software">GunRock</rs> for aggregation [154] dealing with memory management, workload mapping, and load balancing. In training, G 3 shows up to 100× speedup over 
            <rs type="software">PyG</rs> and 
            <rs type="software">TF</rs> in a high-end GPU.
        </p>
        <p>GReTA GReTA [84] is a processing abstraction for GNNs aiming at simplifying their representation for hardware implementations. To this end, 
            <rs type="software">GReTA</rs> consists of four user-defined functions: Gather and Reduce to describe the aggregation, and Transform and Activate to describe the combination. These functions enable certain flexibility to accommodate different GNN types. GReTA also discusses partitioning briefly and exemplifies it in a hardware accelerator called GRIP [85], which is described in the next section.
        </p>
        <p>Paddle Graph Learning. Developed by Baidu Research, Paddle Graph Learning [3] is a graph learning framework based on 
            <rs type="software">PaddlePaddle</rs> [109] that supports both walk-based and message passing models in heterogeneous graphs. Moreover, it integrates a Model Zoo supporting many GNN models to foster adoption, as well as support for distributed computing.
        </p>
        <p>In this work, the authors compare multiple parallelization algorithms that partition and distribute the GNN in multiple GPU clusters, i.e., 1D, 1.5D, 2D, and 3D algorithms, and model the tradeoff between inter-GPU communication and memory requirements of these setups analytically and for training. The model takes a large adjacency matrix and breaks it down to a fixed amount of processes depending on the algorithm. Then, an analysis is made on the amount of effectual operations and results to be communicated across the GPUs. Their implementation overIn this work, the authors compare multiple parallelization algorithms that partition and distribute the GNN in multiple GPU clusters, i.e., 1D, 1.5D, 2D, and 3D algorithms, and model the tradeoff between inter-GPU communication and memory requirements of these setups analytically and for training. The model takes a large adjacency matrix and breaks it down to a fixed amount of processes depending on the algorithm. Then, an analysis is made on the amount of effectual operations and results to be communicated across the GPUs. Their implementation over</p>
        <p>Computing Graph Neural Networks: A Survey from Algorithms to Accelerators 
            <rs type="software">PyG</rs> shows promising scalability and nominates the 1.5D algorithm as a promising and balanced alternative, although the best algorithm depends on the characteristics of the input graph.
        </p>
        <p>We have seen above that software accelerators streamline the execution of GNNs in CPU-GPU platforms present in most computing systems, achieving significant speedups both in inference and training. Fewer works [8,182] have tested GNN training in the TPUs typically used in dense DNNs, showing similar performance than in GPUs.We have seen above that software accelerators streamline the execution of GNNs in CPU-GPU platforms present in most computing systems, achieving significant speedups both in inference and training. Fewer works [8,182] have tested GNN training in the TPUs typically used in dense DNNs, showing similar performance than in GPUs.</p>
        <p>In this context, a pertinent question is whether custom hardware accelerators can tackle the unique challenges of GNN computing and live up to the promise of order-of-magnitude improvements that, to cite an example, have been already achieved in CNNs [25]. Pursuing this goal, several hardware accelerators have emerged that attempt to handle the extreme density and alternating computing requirements of GNNs. We next discuss all the designs published to date, using as reference the schematic diagrams of their architecture shown in Figure 8. The figure also tries to classify the architectures in two axes: unified versus tiled (to assess whether the computing phases are physically separated and how tightly coupled they are) and general (to specific to assess how easy is to adapt the accelerator to multiple GNN variants).In this context, a pertinent question is whether custom hardware accelerators can tackle the unique challenges of GNN computing and live up to the promise of order-of-magnitude improvements that, to cite an example, have been already achieved in CNNs [25]. Pursuing this goal, several hardware accelerators have emerged that attempt to handle the extreme density and alternating computing requirements of GNNs. We next discuss all the designs published to date, using as reference the schematic diagrams of their architecture shown in Figure 8. The figure also tries to classify the architectures in two axes: unified versus tiled (to assess whether the computing phases are physically separated and how tightly coupled they are) and general (to specific to assess how easy is to adapt the accelerator to multiple GNN variants).</p>
        <p>A summary of the main features of the accelerators and evaluated algorithms and datasets is given in Table 8. We observe that most works revolve around the GCN algorithm, which is popular and easy to illustrate. Datasets are generally smaller than in software acceleration works, mainly because of the memory limitations of hardware accelerators in inference and the cost of simulating hardware architectures. Cora, CiteSeer, and Reddit are the most common ones. While performance comparisons are difficult due to the many variables involved, most works use CPUs and GPUs as baselines and, in some cases, even 
            <rs type="software">HyGCN</rs> [164] and Autotuning-Workload-Balancing GCN • Unified architecture with dense hardware, single dataflow, generalizable to many GNN variants. • Aggregation via RER.
        </p>
        <p>• Optimizations: edge reordering, degree-aware vertex cache, scheduling.• Optimizations: edge reordering, degree-aware vertex cache, scheduling.</p>
        <p>GCN, GS, GG-NN, GRN, R-GCN Cora, PubMed, Nell, Reddit, Enwiki, Amazon, synthetic (RMAT), AIFB, MUTAG, BGS, AM CPU-DGL, GPU-DGL, CPU-PyG, GPU-PyG, 
            <rs type="software">HyGCN</rs>
        </p>
        <p>HyGCN [164] • Hybrid architecture with separate aggregate/combine phases.HyGCN [164] • Hybrid architecture with separate aggregate/combine phases.</p>
        <p>• Fine-grained pipelining via inter-phase coordinator.• Fine-grained pipelining via inter-phase coordinator.</p>
        <p>• Eliminates sparsity with window sliding/shrinking approach.• Eliminates sparsity with window sliding/shrinking approach.</p>
        <p>• Focused on GCNs, unclear how to generalize (no edge updates).• Focused on GCNs, unclear how to generalize (no edge updates).</p>
        <p>GCN, GSC, GIN, DiffPool IMDB, Cora, CiteSeer, COLLAB, PubMed, Reddit CPU-PyG, GPU-PyGGCN, GSC, GIN, DiffPool IMDB, Cora, CiteSeer, COLLAB, PubMed, Reddit CPU-PyG, GPU-PyG</p>
        <p>• Adapts to varying GNN workloads via three load balancing techniques, chosen based on the sparsity of each partition. • Processes combination first to reduce the number of operations.• Adapts to varying GNN workloads via three load balancing techniques, chosen based on the sparsity of each partition. • Processes combination first to reduce the number of operations.</p>
        <p>• Fine-grained pipelining of aggregation and combination.• Fine-grained pipelining of aggregation and combination.</p>
        <p>• Focused on GCNs, unclear how to generalize.• Focused on GCNs, unclear how to generalize.</p>
        <p>Cora, CiteSeer, PubMed, Reddit, Nell CPU-PyG, GPU-PyG, FPGA, HyGCN GRIP [85] • Uses the GReTA abstraction [84], generalizable to any GNN.Cora, CiteSeer, PubMed, Reddit, Nell CPU-PyG, GPU-PyG, FPGA, HyGCN GRIP [85] • Uses the GReTA abstraction [84], generalizable to any GNN.</p>
        <p>• Actual implementation with techniques similar to HyGCN.• Actual implementation with techniques similar to HyGCN.</p>
        <p>Youtube, Livejournal, Pokec, Reddit CPU-TF, GPU-TF, TPU, HyGCN Auten et al. [7] • Tiled architecture, ready for scale-out via Network-on-Chip. (AWB-GCN) [53] as early works on hardware acceleration. In general, the proposed accelerators are around two and three orders of magnitude faster and more energy efficient than GPU and CPU platforms, respectively, often occupying less than 10 mm 2 . There is no consensus on which software framework shall be used in the baselines. Finally, all accelerator proposals except 
            <rs type="software">GraphACT</rs> are designed and evaluated for inference.
        </p>
        <p>EnGN. Among the first accelerators to appear, EnGN [103] presents a unified architecture heavily inspired by CNN accelerators. The GNN is fundamentally treated as concatenated matrix multiplication of feature vectors, adjacency matrices, and weights-all scheduled in a single dataflow. An array of clustered Processing Elements (PEs) is fed by independent banks for the features, edges, and weights to compute the combination function. To perform the aggregation, each column of PEs is interconnected through a ring and results are passed along and added according to the adjacency matrix in a process the authors call Ring-Edge Reduce (RER). Within this architecture, sparsity is handled with several optimizations. First, the RER aggregation may lead to multiple ineffectual computations for sparsely connected nodes. To avoid this, EnGN reorders edges on the fly in each step of the RER. Second, PE clusters are attached to a degree-aware vertex cache that holds data regarding high-degree vertices. The reasoning is that well-connected vertices will appear multiple times during the computation and caching them will provide high benefit at modest cost. Other optimized design decisions relate to the order of the matrix multiplications when the aggregation function is sum, which affects the total number of operations, or the tiling strategy, which affects data reuse and I/O cost.EnGN. Among the first accelerators to appear, EnGN [103] presents a unified architecture heavily inspired by CNN accelerators. The GNN is fundamentally treated as concatenated matrix multiplication of feature vectors, adjacency matrices, and weights-all scheduled in a single dataflow. An array of clustered Processing Elements (PEs) is fed by independent banks for the features, edges, and weights to compute the combination function. To perform the aggregation, each column of PEs is interconnected through a ring and results are passed along and added according to the adjacency matrix in a process the authors call Ring-Edge Reduce (RER). Within this architecture, sparsity is handled with several optimizations. First, the RER aggregation may lead to multiple ineffectual computations for sparsely connected nodes. To avoid this, EnGN reorders edges on the fly in each step of the RER. Second, PE clusters are attached to a degree-aware vertex cache that holds data regarding high-degree vertices. The reasoning is that well-connected vertices will appear multiple times during the computation and caching them will provide high benefit at modest cost. Other optimized design decisions relate to the order of the matrix multiplications when the aggregation function is sum, which affects the total number of operations, or the tiling strategy, which affects data reuse and I/O cost.</p>
        <p>HyGCN. The authors of HyGCN [164] build upon the observation that GNNs present two main alternating phases of opposed computation needs and introduce a hybrid architecture for GCNs.HyGCN. The authors of HyGCN [164] build upon the observation that GNNs present two main alternating phases of opposed computation needs and introduce a hybrid architecture for GCNs.</p>
        <p>
            <rs type="software">HyGCN</rs> is composed of separate dedicated engines for the aggregation and the combination stages, plus a control mechanism that coordinates the pipelined execution of both functions. Being dense, the combination stage is computed via a conventional systolic array approach. The aggregation stage has a more elaborated architecture featuring a sampler, an edge scheduler, and a sparsity eliminator that feeds a set of SIMD cores. Within this architecture, sparsity is handled at the aggregation engine thanks to efficient scheduling and the sparsity eliminator. The latter takes a window-based sliding and shrinking approach to dynamically adapt to varying degrees of sparse multiplications.
        </p>
        <p>To further adapt to the workloads, 
            <rs type="software">HyGCN</rs> allows to group the SIMD cores in aggregation and the PEs in combination in different ways depending on the size of feature vectors. Finally, special attention is placed to the design of the inter-engine coordinator to optimize memory accesses and allow fine-grained pipelining of the execution toward maximizing parallelism dynamically.
        </p>
        <p>The AWB-GCN accelerator [53] advocates for an aggressive adaptation to the structural sparsity of the GNN. The authors motivate their design by analyzing the power-law distribution of most graphs, arguing that some parts of the computation will be dense and others extraordinarily sparse, creating unbalances. To address the imbalance, the architecture develops a custom matrix multiplication engine with efficient support of skipping zeros. To that end, data from memory is fed via a task distributor and queue (TDQ) to a set of PEs and accumulators.The AWB-GCN accelerator [53] advocates for an aggressive adaptation to the structural sparsity of the GNN. The authors motivate their design by analyzing the power-law distribution of most graphs, arguing that some parts of the computation will be dense and others extraordinarily sparse, creating unbalances. To address the imbalance, the architecture develops a custom matrix multiplication engine with efficient support of skipping zeros. To that end, data from memory is fed via a task distributor and queue (TDQ) to a set of PEs and accumulators.</p>
        <p>The TDQ takes two designs adapted to when sparsity is moderate or high. Since AWB-GCN focuses on GCNs that have linear aggregation functions, the authors propose to process combination first as this generally reduces the amount of features and, thus, the amount of operations performed in aggregation. Furthermore, AWB-GCN provides a fine-grained pipelining mechanism to overlap the execution of combination and aggregation even within the same layer. However, the key of AWB-GCN are its three workload balancing functions. The first one is local and tries to balance the load among neighboring PEs. The second one is remote and attempts to pour overflowing computation from a busy PE to a single remote underutilized PE. The third one takes the load of extremely busy PEs processing very dense node clusters and divides across multiple idle PEs. To support that, AWB-GCN provisions hardware at the TDQ and the connections to the PEs to allow the remapping of nodes to remote PEs and to take them back for coherent aggregation. Moreover, all decisions are taken based on information extracted from simple counting at the queues.The TDQ takes two designs adapted to when sparsity is moderate or high. Since AWB-GCN focuses on GCNs that have linear aggregation functions, the authors propose to process combination first as this generally reduces the amount of features and, thus, the amount of operations performed in aggregation. Furthermore, AWB-GCN provides a fine-grained pipelining mechanism to overlap the execution of combination and aggregation even within the same layer. However, the key of AWB-GCN are its three workload balancing functions. The first one is local and tries to balance the load among neighboring PEs. The second one is remote and attempts to pour overflowing computation from a busy PE to a single remote underutilized PE. The third one takes the load of extremely busy PEs processing very dense node clusters and divides across multiple idle PEs. To support that, AWB-GCN provisions hardware at the TDQ and the connections to the PEs to allow the remapping of nodes to remote PEs and to take them back for coherent aggregation. Moreover, all decisions are taken based on information extracted from simple counting at the queues.</p>
        <p>A key aspect of most existing accelerators is that they focus on GCNs as a relevant GNN algorithm. In contrast, the GRIP accelerator [85] leverages the abstraction of GReTA [84] to develop a general accelerator for any GNN variant, allowing to perform edge and node updates with user-defined functions. The GRIP architecture reflects this by having separated and custom units and accumulators for both edges (gather, reduce) and vertices (transform, activate). A control unit orchestrates data movement between the different units and respective buffers. In the sample implementation, GRIP divides the edge update unit into lanes to execute vertices simultaneously and takes an input-stationary dataflow for the vertex update unit. Among the optimizations made, we found pipelining and tiling adapted to the particularities of the implemented dataflows, similar to that of other accelerators.A key aspect of most existing accelerators is that they focus on GCNs as a relevant GNN algorithm. In contrast, the GRIP accelerator [85] leverages the abstraction of GReTA [84] to develop a general accelerator for any GNN variant, allowing to perform edge and node updates with user-defined functions. The GRIP architecture reflects this by having separated and custom units and accumulators for both edges (gather, reduce) and vertices (transform, activate). A control unit orchestrates data movement between the different units and respective buffers. In the sample implementation, GRIP divides the edge update unit into lanes to execute vertices simultaneously and takes an input-stationary dataflow for the vertex update unit. Among the optimizations made, we found pipelining and tiling adapted to the particularities of the implemented dataflows, similar to that of other accelerators.</p>
        <p>Unlike most other accelerators, this work [7] proposes a modular architecture for convolutional GNNs. The basic unit of the accelerator is a tile composed by an aggregator module (AGG), a DNN accelerator module (DNA), a DNN queue (DNQ), and a graph PE (GPE), all of them connected to an on-chip router. Thus, the architecture can be scaled out by interconnecting multiple tiles among them and with memory. Within each tile, the architecture has a similar structure than HyGCN, with the DNA being an array for dense multiplication, the AGG an edge-controlled adder, the DNQ taking the role of inter-engine buffer, and the GPE controlling execution. In this case, however, the GPE is a lightweight CPU managing multiple threads rather than an optimized controller.Unlike most other accelerators, this work [7] proposes a modular architecture for convolutional GNNs. The basic unit of the accelerator is a tile composed by an aggregator module (AGG), a DNN accelerator module (DNA), a DNN queue (DNQ), and a graph PE (GPE), all of them connected to an on-chip router. Thus, the architecture can be scaled out by interconnecting multiple tiles among them and with memory. Within each tile, the architecture has a similar structure than HyGCN, with the DNA being an array for dense multiplication, the AGG an edge-controlled adder, the DNQ taking the role of inter-engine buffer, and the GPE controlling execution. In this case, however, the GPE is a lightweight CPU managing multiple threads rather than an optimized controller.</p>
        <p>The work by Zhang and co-authors [177] presents a combination of software and hardware acceleration for GCNs. On the one hand, the graph is pre-processed via a redundancy elimination mechanism similar to that of Reference [77] and a node reordering similar to that of Reference [155]. Pre-processing is done offline and is justified for the repeated benefits that it can provide to multiple inferences to static graphs. The processed graph is then fed to a hardware accelerator implemented in a FPGA consisting of differentiated pipelined modules for aggregation (sparse array) and combination (dense systolic array and non-linear activation module). As differentiating elements with respect to other designs, we find that the aggregator module uses a double-buffering technique to hide latency of additions and exploits both node-level and featurelevel parallelism. We also observe that the accelerator implements two modes of operation depending on the order of the matrix multiplications, which leads to different strategies for pipelining. To accommodate them, the modules are interconnected both from the aggregate module to the combination modules and vice versa.The work by Zhang and co-authors [177] presents a combination of software and hardware acceleration for GCNs. On the one hand, the graph is pre-processed via a redundancy elimination mechanism similar to that of Reference [77] and a node reordering similar to that of Reference [155]. Pre-processing is done offline and is justified for the repeated benefits that it can provide to multiple inferences to static graphs. The processed graph is then fed to a hardware accelerator implemented in a FPGA consisting of differentiated pipelined modules for aggregation (sparse array) and combination (dense systolic array and non-linear activation module). As differentiating elements with respect to other designs, we find that the aggregator module uses a double-buffering technique to hide latency of additions and exploits both node-level and featurelevel parallelism. We also observe that the accelerator implements two modes of operation depending on the order of the matrix multiplications, which leads to different strategies for pipelining. To accommodate them, the modules are interconnected both from the aggregate module to the combination modules and vice versa.</p>
        <p>
            <rs type="software">Rubik</rs>. Similarly to the case above, Rubik [23] proposes a hardware accelerator assisted by some pre-processing in software. On the hardware side, 
            <rs type="software">Rubik</rs> presents a hierarchical PE array design, wherein each PE contains a number of MAC units plus instruction and data queues to feed them. The design is unified because aggregations and combinations are scheduled across all PEs. Moreover, each PE includes two small private caches that store recently accessed vertices and partial aggregations. Each PE is connected to the rest of PEs and two memory controllers placed on the side via a meshed NoC. On the software side, 
            <rs type="software">Rubik</rs> proposes lightweight graph reordering (once per graph) to put together nodes that are connected with each other, similarly to Reference [155], but here to improve the performance of the private PE caches.
        </p>
        <p>The work in Reference [96] points out the load imbalance, execution order, and loop optimization inefficiencies from other accelerators, whose impact varies across workloads. To address them, the authors propose GCNAX as a flexible accelerator whose dataflow is reconfigurable in terms of loop order and loop fusion strategy. To find the most effective dataflows for each particular dataset, the authors perform a design space exploration of dataflow design decisions. Therefore, in inference, GCNAX is reconfigured based on the characteristics of the problem at hand. Finally, GCNAX uses the outer product to mitigate the effect of unbalanced presence of zeros, unlike other accelerators. Thanks to these techniques, GCNAX is around 10× and 2× faster and more efficient than HyGCN and AWB-GCN, respectively.The work in Reference [96] points out the load imbalance, execution order, and loop optimization inefficiencies from other accelerators, whose impact varies across workloads. To address them, the authors propose GCNAX as a flexible accelerator whose dataflow is reconfigurable in terms of loop order and loop fusion strategy. To find the most effective dataflows for each particular dataset, the authors perform a design space exploration of dataflow design decisions. Therefore, in inference, GCNAX is reconfigured based on the characteristics of the problem at hand. Finally, GCNAX uses the outer product to mitigate the effect of unbalanced presence of zeros, unlike other accelerators. Thanks to these techniques, GCNAX is around 10× and 2× faster and more efficient than HyGCN and AWB-GCN, respectively.</p>
        <p>
            <rs type="software">GraphACT</rs>. While all other accelerators focused on inference, 
            <rs type="software">GraphACT</rs> [175] explores how to efficiently perform GNN training in an heterogeneous CPU+FPGA platform. The main design decision relates to determining which parts are computed where and which data to store in memory. To address these questions, the authors argue that CPU performs graph sampling and the calculation of the loss gradients, while and the FPGA does forward and backward propagation passes. The FPGA, thus implements aggregation and combination. The authors present optimizations based on the scheduling of the different operations taking into consideration that backpropagation can be performed after batching of multiple layers or batching different parts of the graph. Moreover, similarly to in Reference [177], redundant operations at aggregation are eliminated via searching of edges common to multiple vertices.
        </p>
        <p>The analysis of the state of the art performed in previous sections leads to several conclusions. First, we observe that a quantitative comparison among systems is very difficult due to the lack of a common baseline system and a GNN benchmark suite with a representative set of algorithms, datasets, and design targets. To bridge this gap, initiatives such as the Open Graph Benchmark (OGB) [72] or 
            <rs type="software">GNNmark</rs> [10] aim to provide a representative set of graphs and GNNs to use as benchmarks. In hardware accelerators, comparing multiple recent architectures is difficult and some works have compared their fundamental dataflows instead [96]. In this direction, Garg et al. perfomed a dataflow classification that includes multiple operation orders, and whose analysis that may guide further developments in the field [51].
        </p>
        <p>A second reflection is that the desirable one approach fits all does not apply to GNNs, and distinct design approaches will probably be required for different applications. For example, the extreme scale and high throughput demands of recommendation systems is well in line with the targets of software frameworks: programmability and scalability. In contrast, for applications that need to focus on real-time operation and energy efficiency, custom hardware acceleration solutions may be the only way to go. Moreover, the wide variety of problems with their different graph and feature vector sizes renders the acceleration problem more difficult to tackle with a single approach [103,163,182].A second reflection is that the desirable one approach fits all does not apply to GNNs, and distinct design approaches will probably be required for different applications. For example, the extreme scale and high throughput demands of recommendation systems is well in line with the targets of software frameworks: programmability and scalability. In contrast, for applications that need to focus on real-time operation and energy efficiency, custom hardware acceleration solutions may be the only way to go. Moreover, the wide variety of problems with their different graph and feature vector sizes renders the acceleration problem more difficult to tackle with a single approach [103,163,182].</p>
        <p>Finally, we identify a few outstanding challenges for acceleration. Support for dynamic graphs is a pending issue only evaluated in 
            <rs type="software">AliGraph</rs> [187]. Learning over dynamic graphs implies not only processing the GNN in each timestep but also updating the weight matrices as the graph evolves, factors that might be amenable to software or hardware optimization. At the frontier of software and hardware, another challenge resides in how to approach the GNN acceleration problem with a co-design strategy, i.e., which tasks can be offloaded to software and which ones should stay in hardware, taking into consideration the related overheads. On the hardware side, how to best accelerate training remains as an important open question as all proposals except 
            <rs type="software">GraphACT</rs> [175] have targeted inference. Beyond that, another challenge in hardware accelerators is finding the right balance between performance and generalization in light of the multitude of graph types and GNN variants, including techniques such as pooling, sampling, or skip connections.
        </p>
        <p>Previous sections have discussed how GNNs can be understood as a set of classical NNs working symbiotically over graph-structured data. We have seen that, to extract specific knowledge from the graphs, different NN layers may be employed leading to a wide variety of GNN flavours. This, plus the fundamental dependence of GNNs on the input graph (which may be extremely large) complicate the task of streamlining their execution. As a result, works on GNN acceleration have implicitly made a choice upon either providing an extremely efficient acceleration scheme for a specific GNN variant, or being general or flexible enough to serve multiple types of GNNs less efficiently.Previous sections have discussed how GNNs can be understood as a set of classical NNs working symbiotically over graph-structured data. We have seen that, to extract specific knowledge from the graphs, different NN layers may be employed leading to a wide variety of GNN flavours. This, plus the fundamental dependence of GNNs on the input graph (which may be extremely large) complicate the task of streamlining their execution. As a result, works on GNN acceleration have implicitly made a choice upon either providing an extremely efficient acceleration scheme for a specific GNN variant, or being general or flexible enough to serve multiple types of GNNs less efficiently.</p>
        <p>The key challenge in GNN acceleration is thus to provide a framework that is able to both maximize performance and efficiency while maintaining a degree of flexibility that caters to the different graph sizes, characteristics, and GNN algorithms. Albeit a daunting task, in this section we aim to leverage the analysis of existing acceleration works to hypothesize that would be the main characteristics that future GNN accelerators should feature. In particular, our envisaged architectural approach shall be driven by (i) software-hardware co-design, (ii) graph awareness, and (iii) an much-needed emphasis on communications. We next discuss these aspects qualitatively, using Figure 9 as reference.The key challenge in GNN acceleration is thus to provide a framework that is able to both maximize performance and efficiency while maintaining a degree of flexibility that caters to the different graph sizes, characteristics, and GNN algorithms. Albeit a daunting task, in this section we aim to leverage the analysis of existing acceleration works to hypothesize that would be the main characteristics that future GNN accelerators should feature. In particular, our envisaged architectural approach shall be driven by (i) software-hardware co-design, (ii) graph awareness, and (iii) an much-needed emphasis on communications. We next discuss these aspects qualitatively, using Figure 9 as reference.</p>
        <p>The analysis of prior work has shown that both software and hardware approaches can provide significant speedups. In some occasions, one might argue that both strategies attack the problem similarly, e.g., node reordering in software [141] and workload balancing in hardware [53]. However, a few works have also started to realize that both approaches are not mutually exclusive and that their benefits can add up, or one can simplify the other. For instance, 
            <rs type="software">Rubik</rs> improves performance by reordering the graph in software [23]. Also, the design from Zhang et al. [177] eliminates redundant operations via software pre-processing and then optimizes execution with specialized aggregation and combination modules. The software side allows to avoid having specialized hardware structures to eliminate redundant operations.
        </p>
        <p>Building upon this observation, our first proposed pillar is software-hardware co-design as a strategy for handling different GNNs and graphs efficiently while retaining some hardware simplicity. We advocate for a control-data plane model where, in general, the control plane will be implemented entirely in software providing the flexibility and the data plane will be implemented in custom hardware providing the efficiency. While conceptually separated (see Figure 9), the operation of both planes will be tightly coupled.Building upon this observation, our first proposed pillar is software-hardware co-design as a strategy for handling different GNNs and graphs efficiently while retaining some hardware simplicity. We advocate for a control-data plane model where, in general, the control plane will be implemented entirely in software providing the flexibility and the data plane will be implemented in custom hardware providing the efficiency. While conceptually separated (see Figure 9), the operation of both planes will be tightly coupled.</p>
        <p>On the one hand, the control plane manages the actions of the accelerator by having a global view of the complete GNN structure and input graph. The control plane is responsible for dictating the dataflow running in the data plane, by (i) partitioning the GNN computation into manageable computational segments, (ii) mapping the different vertices and edges to the hardware resources of the data plane, and (iii) scheduling the different executions toward balancing the workload, maximize the benefits of pipelining, and so on. Finally, we also consider part of the control plane to (iv) drive pre-processing (and possibly offline) steps such as the removal of redundant operations [77] or the detection of certain graph aspects such as cliques [155]. By being implemented in software, all these functions can deliver the required flexibility to accelerate any GNN workload. However, given that certain pre-processing steps may take minutes or hours in very large graphs [28], care must be taken in not turning the software side into the bottleneck of the system. To this end, one may resort to lightweight heuristics or limit software techniques to specific cases such as deep GNNs or training, where the result of pre-processing may be reused multiple times.On the one hand, the control plane manages the actions of the accelerator by having a global view of the complete GNN structure and input graph. The control plane is responsible for dictating the dataflow running in the data plane, by (i) partitioning the GNN computation into manageable computational segments, (ii) mapping the different vertices and edges to the hardware resources of the data plane, and (iii) scheduling the different executions toward balancing the workload, maximize the benefits of pipelining, and so on. Finally, we also consider part of the control plane to (iv) drive pre-processing (and possibly offline) steps such as the removal of redundant operations [77] or the detection of certain graph aspects such as cliques [155]. By being implemented in software, all these functions can deliver the required flexibility to accelerate any GNN workload. However, given that certain pre-processing steps may take minutes or hours in very large graphs [28], care must be taken in not turning the software side into the bottleneck of the system. To this end, one may resort to lightweight heuristics or limit software techniques to specific cases such as deep GNNs or training, where the result of pre-processing may be reused multiple times.</p>
        <p>However, the data plane consists of the processing and memory elements that work as per the control plane instructions to execute a GNN. As we have seen in Section 4.2, we could adopt many strategies for architecting the data plane, e.g., unified, phased, modular, homogenenous, heterogeneous, to name a few. However, we find particularly interesting the use of architectures similar to that of MAERI [90], where an homogeneous array of PEs and a specialized memory hierarchy are put together via a lightweight reconfigurable interconnect fabric. This architecture could adapt the dataflow according to the control plane commands, thus allowing to give service to the multiple execution stages of an algorithm or different algorithms.However, the data plane consists of the processing and memory elements that work as per the control plane instructions to execute a GNN. As we have seen in Section 4.2, we could adopt many strategies for architecting the data plane, e.g., unified, phased, modular, homogenenous, heterogeneous, to name a few. However, we find particularly interesting the use of architectures similar to that of MAERI [90], where an homogeneous array of PEs and a specialized memory hierarchy are put together via a lightweight reconfigurable interconnect fabric. This architecture could adapt the dataflow according to the control plane commands, thus allowing to give service to the multiple execution stages of an algorithm or different algorithms.</p>
        <p>Most accelerators have attempted to provide methods that adapt to runtime conditions while being largely unaware of the input graph characteristics [76,103]. However, it has been also realized that aspects such as the size of the graph, the relative size of the feature vectors, the clustering factor of the graph, or the average degree of the same can be extremely relevant in accelerating the GNN [45,141,164]. In fact, 
            <rs type="software">GNNAdvisor</rs> [155] seeks to exploit this information explicitly to improve the performance in GPUs, while others have based the order of operations or the mapping of PEs on characterstics of the graph [53,103,164]. Other characterization works have shown that the impact of loop ordering or dataflow design decisions on performance certainly depends on the input graph [10,51,96].
        </p>
        <p>This leads to the second pillar of our envisaged architecture: graph awareness. If the GNN depends on the input graph, then maximizing performance needs to be aware of the main features of that graph. Offline or online methods shall be used to extract useful information from the graph that, in our case, will be leveraged by the control plane. This will thus affect aspects such as the graph partitioning [141], which may be more or less aggressive depending on the degree distribution; the ordering and pipelining of the different aggregate-combine phases, which may vary across layers and across graphs; or the scheduling process to minimize inter-partition communication. A good example of this approach is community detection, whose efficient implementation [46,110] or prediction [26] may allow for the partition of the graph in densely connected graphlets at runtime. This is relevant to efficient pooling [168], redundancy elimination [77], and optimal scheduling [155]. Again, it is critical to minimize the overhead of techniques providing graph awareness, either via heuristics, reuse of prior analyses, or its use only in certain occasions where the pre-processing can be done in advance or its benefit maximized, i.e., training.This leads to the second pillar of our envisaged architecture: graph awareness. If the GNN depends on the input graph, then maximizing performance needs to be aware of the main features of that graph. Offline or online methods shall be used to extract useful information from the graph that, in our case, will be leveraged by the control plane. This will thus affect aspects such as the graph partitioning [141], which may be more or less aggressive depending on the degree distribution; the ordering and pipelining of the different aggregate-combine phases, which may vary across layers and across graphs; or the scheduling process to minimize inter-partition communication. A good example of this approach is community detection, whose efficient implementation [46,110] or prediction [26] may allow for the partition of the graph in densely connected graphlets at runtime. This is relevant to efficient pooling [168], redundancy elimination [77], and optimal scheduling [155]. Again, it is critical to minimize the overhead of techniques providing graph awareness, either via heuristics, reuse of prior analyses, or its use only in certain occasions where the pre-processing can be done in advance or its benefit maximized, i.e., training.</p>
        <p>Data movement is the enemy of efficient architectures. Hardware accelerators aim to minimize it by adapting its resources to the execution dataflow but, surprisingly, traditional DNN accelerators [39,138] have generally given a relatively low importance to the sub-system handling data movement: the interconnect fabric. This is also true for GNN accelerators, which are generally computingcentric with few exceptions [144,175]. However, GNNs pose the additional challenge of not having a single optimal dataflow given the input graph dependence and the many algorithm variants. Thus, data movement continues to be a crucial aspect [60].Data movement is the enemy of efficient architectures. Hardware accelerators aim to minimize it by adapting its resources to the execution dataflow but, surprisingly, traditional DNN accelerators [39,138] have generally given a relatively low importance to the sub-system handling data movement: the interconnect fabric. This is also true for GNN accelerators, which are generally computingcentric with few exceptions [144,175]. However, GNNs pose the additional challenge of not having a single optimal dataflow given the input graph dependence and the many algorithm variants. Thus, data movement continues to be a crucial aspect [60].</p>
        <p>For this reason, the third pillar of our envisaged architecture is taking a communication-centric design approach. This is a philosophy that has been applied to endow DNN accelerators with certain flexibility [88][89][90] or to optimize distributed learning [139]. In our case, we propose the use of a reconfigurable interconnect fabric among the PEs to adapt the hardware to the underlying graph connectivity or, in other words, to the optimal dataflow that may vary across layers, partitions, or graphs. In an extreme case, one could adopt the approach of recent DNN accelerators that orchestrate all data movement at compilation time [4,75]. GNNs and their extreme size might discourage the use of this strategy and, instead, advocate for a compilation that provides hints for the interconnect to adapt to the varying needs of the graph and its most optimal dataflow. The compilation and reconfiguration could be complemented by the analysis of the input graph. Assuming it can be done in advance or with little overhead, graph profiling may allow us to predict the prevalent communication patterns and, thus, the most appropriate interconnect topology.For this reason, the third pillar of our envisaged architecture is taking a communication-centric design approach. This is a philosophy that has been applied to endow DNN accelerators with certain flexibility [88][89][90] or to optimize distributed learning [139]. In our case, we propose the use of a reconfigurable interconnect fabric among the PEs to adapt the hardware to the underlying graph connectivity or, in other words, to the optimal dataflow that may vary across layers, partitions, or graphs. In an extreme case, one could adopt the approach of recent DNN accelerators that orchestrate all data movement at compilation time [4,75]. GNNs and their extreme size might discourage the use of this strategy and, instead, advocate for a compilation that provides hints for the interconnect to adapt to the varying needs of the graph and its most optimal dataflow. The compilation and reconfiguration could be complemented by the analysis of the input graph. Assuming it can be done in advance or with little overhead, graph profiling may allow us to predict the prevalent communication patterns and, thus, the most appropriate interconnect topology.</p>
        <p>The recent interest in geometric deep learning, or methods able to model and predict graphstructured data, have led to an explosion of research around GNNs. As we have seen in our analysis of the current state of the art, most of the works focus on the algorithms and their applications, rendering the topic of GNN computing a less beaten path. However, we anticipate that the area of software and hardware support for GNNs will grow at a fast pace, continuing an upwards trend that we observed from 2018 to today.The recent interest in geometric deep learning, or methods able to model and predict graphstructured data, have led to an explosion of research around GNNs. As we have seen in our analysis of the current state of the art, most of the works focus on the algorithms and their applications, rendering the topic of GNN computing a less beaten path. However, we anticipate that the area of software and hardware support for GNNs will grow at a fast pace, continuing an upwards trend that we observed from 2018 to today.</p>
        <p>The reasons for the probable increase in research delving into more efficient computing means for GNNs are several. First, the field is maturing and the more theoretical algorithm-driven research gives way to the most application-oriented development. A clear example of this trend is the advent of efforts to unify aspects such as benchmarking [72]. Second, GNNs are the key to many disruptive applications in multiple fields, thus creating a clear application pull driving the need for better processing. Third, GNNs present multiple unique challenges such as the wide variety of algorithm variants, their dependence on the graph characteristics, or their massive scale in some applications. This makes the field of GNN processing unlikely to saturate in the foreseeable future and calls for an in-depth discussion of not only the challenges associated to GNN processing, but also of possible ways to tackle them.The reasons for the probable increase in research delving into more efficient computing means for GNNs are several. First, the field is maturing and the more theoretical algorithm-driven research gives way to the most application-oriented development. A clear example of this trend is the advent of efforts to unify aspects such as benchmarking [72]. Second, GNNs are the key to many disruptive applications in multiple fields, thus creating a clear application pull driving the need for better processing. Third, GNNs present multiple unique challenges such as the wide variety of algorithm variants, their dependence on the graph characteristics, or their massive scale in some applications. This makes the field of GNN processing unlikely to saturate in the foreseeable future and calls for an in-depth discussion of not only the challenges associated to GNN processing, but also of possible ways to tackle them.</p>
        <p>Finally, we highlight the rising popularity of software frameworks and the recent appearance of hardware accelerators for GNNs. On the software side, libraries such as DGL or 
            <rs type="software">NeuGraph</rs> aim to speed up and add features to widespread frameworks such as TF or 
            <rs type="software">PyTorch</rs>. Interesting contributions are acceleration of GNNs via graph analysis or pre-coding, as well as the distribution of computation in large-scale systems, much needed for huge recommendation systems. On the hardware side, we did not observe a clear architectural trend and existing proposals are debating between being specific or applicable to multiple GNN variants, and between unified architectures or more hierarchical, tiled organizations. Building on this observation, we envision that future accelerators shall adopt a hardware-software co-design approach to maximize performance, keep graph awareness as a profitable optimization opportunity, and tackle workload variability via a reconfigurable interconnect.
        </p>
        <p>e , д L ee , д L e</p>
        <p>ACM Computing Surveys, Vol. 54, No. 9, Article 191. Publication date: October 2021.ACM Computing Surveys, Vol. 54, No. 9, Article 191. Publication date: October 2021.</p>
        <p>Received November 2020; revised July 2021; accepted July 2021 ACM Computing Surveys, Vol. 54, No. 9, Article 191. Publication date: October 2021.Received November 2020; revised July 2021; accepted July 2021 ACM Computing Surveys, Vol. 54, No. 9, Article 191. Publication date: October 2021.</p>
        <p>The authors thank the anonymous reviewers and the editorial team for their constructive criticism, which has helped improve the quality of the article. We are also grateful to Albert Cabellos-Aparicio, Tushar Krishna, José L. Abellán, and Manuel E. Acacio for the countless discussions on the topic.The authors thank the anonymous reviewers and the editorial team for their constructive criticism, which has helped improve the quality of the article. We are also grateful to Albert Cabellos-Aparicio, Tushar Krishna, José L. Abellán, and Manuel E. Acacio for the countless discussions on the topic.</p>
        <p>This work is possible thanks to funding from the European Union's Horizon 2020 research and innovation programme under Grant No. 863337 (WiPLASH project) and the Spanish Ministry of Economy and Competitiveness under contract TEC2017-90034-C2-1-R (ALLIANCE project) that receives funding from FEDER.This work is possible thanks to funding from the European Union's Horizon 2020 research and innovation programme under Grant No. 863337 (WiPLASH project) and the Spanish Ministry of Economy and Competitiveness under contract TEC2017-90034-C2-1-R (ALLIANCE project) that receives funding from FEDER.</p>
    </text>
</tei>
