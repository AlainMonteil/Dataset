<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-14T07:11+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>Neuromorphic computing aims at the realization of intelligent systems able to process information similarly to our brain. Brain-inspired computing paradigms have been implemented in crossbar arrays of memristive devices, however this approach does not emulate the topology and the emergent behavior of biological neuronal circuits, where the principle of self-organization regulates both structure and functions. Here, we report on in-materia reservoir computing in a fully-memristive architecture based on self-organized nanowire networks. Thanks to the functional synaptic connectivity with nonlinear dynamics and fading memory properties, the designless nanowire complex network acts as a network-wide physical reservoir able to map spatio-temporal inputs into a feature space that can be analyzed by a memristive ReRAM readout layer. Computing capabilities, including recognition of spatiotemporal patterns and time series prediction, show that the emergent memristive behavior of nanowire networks allows in-materia implementation of brain-inspired computing paradigms characterized by a reduced training cost.Neuromorphic computing aims at the realization of intelligent systems able to process information similarly to our brain. Brain-inspired computing paradigms have been implemented in crossbar arrays of memristive devices, however this approach does not emulate the topology and the emergent behavior of biological neuronal circuits, where the principle of self-organization regulates both structure and functions. Here, we report on in-materia reservoir computing in a fully-memristive architecture based on self-organized nanowire networks. Thanks to the functional synaptic connectivity with nonlinear dynamics and fading memory properties, the designless nanowire complex network acts as a network-wide physical reservoir able to map spatio-temporal inputs into a feature space that can be analyzed by a memristive ReRAM readout layer. Computing capabilities, including recognition of spatiotemporal patterns and time series prediction, show that the emergent memristive behavior of nanowire networks allows in-materia implementation of brain-inspired computing paradigms characterized by a reduced training cost.</p>
        <p>In parallel with the progress in neuroscience, a growing interest has been devoted to electronic neuromorphic systems aimed at emulating the human brain functionality and effectiveness. 1 To fulfil this goal, memristive devices capable of adaptation in response to electrical stimuli have been recently adopted as artificial synapses for hardware implementation of non-von Neumann computing. [2][3][4][5] In this framework, memristive circuits realized with a top-down approach and organized into rigid gridlike crossbar arrays have been proposed for the hardware demonstration of artificial neural networks (ANN). 6,7 A key issue of top-down topologies that emphasize the role of individual elements is the lack of similarity with respect to biological neural systems, where the principle of self-organization governs both structure and functions and the high synaptic connectivity in between neurons provides adaptability, fault tolerance and robustness. 8 Indeed, learning, memory and intelligence in the human brain arise from the complexity of neuronal systems and the interplay between its structure and function. 9,10 Inspired by the recurrent connectivity of biological neural networks, nanoarchitectures based on many interacting nano-parts have been proposed as alternatives for biologically-plausible computing hardware. 11,12,[21][22][23][24][13][14][15][16][17][18][19][20] By emphasizing the network architecture as a whole, these selforganized systems appear as the most promising platform for in-materia implementation of braininspired reservoir computing (RC) by exploiting the emergent dynamics of the whole system with no need for fine tuning of its constituent elements. In this unconventional computing framework derived from recurrent neural network models such as echo state networks (ESNs) 25 and liquid state machines (LSMs) 26 , the reservoir usually consists of a massive network of coupled nonlinear elements that map the input signals into a feature space that is then analyzed by a readout function. Since training is limited at the readout, the RC system benefits from low-cost training, high versatility and fast learning. 27,28 RC has been recently implemented in hardware by exploiting complex dynamics of spintronic oscillators, 29 magnetic skyrmions, 30 photonic systems 31,32 and top-down memristive cells. [33][34][35][36][37] Although physical reservoirs based on self-organized nanonetworks have been experimentally realized, 16,20,24 in-materia implementation of RC in fully memristive systems based on self-organized nano-objects emulating the neuromorphic-type of data processing of our brain still represents a challenge.In parallel with the progress in neuroscience, a growing interest has been devoted to electronic neuromorphic systems aimed at emulating the human brain functionality and effectiveness. 1 To fulfil this goal, memristive devices capable of adaptation in response to electrical stimuli have been recently adopted as artificial synapses for hardware implementation of non-von Neumann computing. [2][3][4][5] In this framework, memristive circuits realized with a top-down approach and organized into rigid gridlike crossbar arrays have been proposed for the hardware demonstration of artificial neural networks (ANN). 6,7 A key issue of top-down topologies that emphasize the role of individual elements is the lack of similarity with respect to biological neural systems, where the principle of self-organization governs both structure and functions and the high synaptic connectivity in between neurons provides adaptability, fault tolerance and robustness. 8 Indeed, learning, memory and intelligence in the human brain arise from the complexity of neuronal systems and the interplay between its structure and function. 9,10 Inspired by the recurrent connectivity of biological neural networks, nanoarchitectures based on many interacting nano-parts have been proposed as alternatives for biologically-plausible computing hardware. 11,12,[21][22][23][24][13][14][15][16][17][18][19][20] By emphasizing the network architecture as a whole, these selforganized systems appear as the most promising platform for in-materia implementation of braininspired reservoir computing (RC) by exploiting the emergent dynamics of the whole system with no need for fine tuning of its constituent elements. In this unconventional computing framework derived from recurrent neural network models such as echo state networks (ESNs) 25 and liquid state machines (LSMs) 26 , the reservoir usually consists of a massive network of coupled nonlinear elements that map the input signals into a feature space that is then analyzed by a readout function. Since training is limited at the readout, the RC system benefits from low-cost training, high versatility and fast learning. 27,28 RC has been recently implemented in hardware by exploiting complex dynamics of spintronic oscillators, 29 magnetic skyrmions, 30 photonic systems 31,32 and top-down memristive cells. [33][34][35][36][37] Although physical reservoirs based on self-organized nanonetworks have been experimentally realized, 16,20,24 in-materia implementation of RC in fully memristive systems based on self-organized nano-objects emulating the neuromorphic-type of data processing of our brain still represents a challenge.</p>
        <p>Here, we experimentally demonstrate in-materia RC in a fully-memristive architecture based on selforganized nanowire (NW) networks exploited as network-type physical reservoirs with random connections among multiple nonlinear memristive elements, to mimic the core principle of RC. The NW network with nonlinear dynamics and fading memory properties allows spatio-temporal processing of multi-terminal inputs thanks to the functional synaptic connectivity of the system with mutual electrochemical interactions among memristive NW junctions. The emergent dynamics of the physical reservoir state, represented by the conductivity map of the NW network, can project a spatiotemporal input pattern in a feature space that can be analyzed by a memristive readout based on resistive switching memory (ReRAM) devices. We show that such versatile, bio-inspired and lowcost training architecture is able to perform recognition of spatio-temporal patterns and to predict chaotic time series. Similar to the human brain, the proposed fully-memristive architecture is capable of processing the temporal and spatial nature of the input signal, paving the way to intelligent systems based on the combination of different neuromorphic hardware technologies.Here, we experimentally demonstrate in-materia RC in a fully-memristive architecture based on selforganized nanowire (NW) networks exploited as network-type physical reservoirs with random connections among multiple nonlinear memristive elements, to mimic the core principle of RC. The NW network with nonlinear dynamics and fading memory properties allows spatio-temporal processing of multi-terminal inputs thanks to the functional synaptic connectivity of the system with mutual electrochemical interactions among memristive NW junctions. The emergent dynamics of the physical reservoir state, represented by the conductivity map of the NW network, can project a spatiotemporal input pattern in a feature space that can be analyzed by a memristive readout based on resistive switching memory (ReRAM) devices. We show that such versatile, bio-inspired and lowcost training architecture is able to perform recognition of spatio-temporal patterns and to predict chaotic time series. Similar to the human brain, the proposed fully-memristive architecture is capable of processing the temporal and spatial nature of the input signal, paving the way to intelligent systems based on the combination of different neuromorphic hardware technologies.</p>
        <p>A conceptual schematization of the RC paradigm is reported in Figure 1a. Here, the role of the reservoir is to nonlinearly map an input u(t) into a feature space represented by the reservoir internal state x(t), such that the input features can be recognized by a simple classification algorithm in the readout, where output weights are the only ones to be trained by comparing the output y(t) with the desired output yd(t). 27,28 The RC hardware implementation is schematized in Figure 1b, where the memristive NW network dynamics is exploited for the realization of a physical reservoir able to process time-dependent inputs, and reservoir outputs are then analyzed by a memristive neural network readout. The physical reservoir consisting of a highly-interconnected and designless memristive NW network (Figure 1c) was realized with a low-cost bottom-up approach by dropcasting Ag NWs in suspension on an insulating substrate (Supplementary Figure S1 and Methods).A conceptual schematization of the RC paradigm is reported in Figure 1a. Here, the role of the reservoir is to nonlinearly map an input u(t) into a feature space represented by the reservoir internal state x(t), such that the input features can be recognized by a simple classification algorithm in the readout, where output weights are the only ones to be trained by comparing the output y(t) with the desired output yd(t). 27,28 The RC hardware implementation is schematized in Figure 1b, where the memristive NW network dynamics is exploited for the realization of a physical reservoir able to process time-dependent inputs, and reservoir outputs are then analyzed by a memristive neural network readout. The physical reservoir consisting of a highly-interconnected and designless memristive NW network (Figure 1c) was realized with a low-cost bottom-up approach by dropcasting Ag NWs in suspension on an insulating substrate (Supplementary Figure S1 and Methods).</p>
        <p>The emergent NW network dynamics upon electrical stimulation arises from the mutual interaction of a multitude of memristive NW cross-point junctions. Indeed, an electrochemical potential difference across intersecting NWs induces anodic dissolution of Ag to form Ag + ions that migrate in the polyvinylpyrrolidone (PVP) insulating NW shell layer to form a conductive bridge that regulates the junction conductivity (Figure 1d). 12 The memristive neural network readout is implemented in hardware by mapping synaptic weights associated with each output neuron in the analogue conductance levels of an array of TaOx ReRAM cross-point devices (Figure 1e, Supplementary Figure S2), where resistive switching relies on the formation/rupture of a substoichiometric conductive filament (Figure 1f, Supplementary Note 1, Supplementary Figure S3).The emergent NW network dynamics upon electrical stimulation arises from the mutual interaction of a multitude of memristive NW cross-point junctions. Indeed, an electrochemical potential difference across intersecting NWs induces anodic dissolution of Ag to form Ag + ions that migrate in the polyvinylpyrrolidone (PVP) insulating NW shell layer to form a conductive bridge that regulates the junction conductivity (Figure 1d). 12 The memristive neural network readout is implemented in hardware by mapping synaptic weights associated with each output neuron in the analogue conductance levels of an array of TaOx ReRAM cross-point devices (Figure 1e, Supplementary Figure S2), where resistive switching relies on the formation/rupture of a substoichiometric conductive filament (Figure 1f, Supplementary Note 1, Supplementary Figure S3).</p>
        <p>The formation upon electrical stimulation and the subsequent spontaneous dissolution of the conductive bridges at NW junctions are responsible for emergent non-linear dynamics and fading memory properties (short-term memory) of the physical reservoir. Indeed, as can be observed in Figure 2a, stimulation of the network in between two terminals upon constant voltage bias leads to the progressive potentiation (facilitation) of the effective network conductance (Figure 2a). After stimulation, the network spontaneously relaxes back to the ground state, as a consequence of the volatile behavior of memristive junctions (Supplementary Note 2). 12 These non-linear network dynamics with fading memory properties can be modelled by mapping the NW network into a weighted grid graph (Supplementary Figure S4, Supplementary Note 3), where the transient behavior of each memristive edge is regulated by short-term memory effects described by a potentiationdepression rate balance equation (Supplementary Note 4). The here proposed model allows: i) to interpolate the evolution over time of the network effective conductance (Figure 2a), and ii) to visualize the resulting spatio-temporal evolution of the conductive pathway when electrically stimulated in different spatial locations (Figure 2b and Supplementary Movie 1). As can be observed, simulations evidence the growth of a conductive pathway connecting the two stimulated areas of the network, followed by the gradual relaxation to the conductance ground state (Figure 2b), in accordance with experimental observations of the formation of a localized conductive pathway connecting stimulated NW network areas. 38,39 Importantly, experimental data show that the change of the effective conductance (Δw) after pulse stimulation and the following relaxation behavior can be controlled by properly adjusting the pulse width and amplitude. Figure 2c reports the change in the effective conductance at the end of a single pulse stimulation with pulses of different lengths and amplitudes and after 500 μs from the end of the pulse. Pulses with higher amplitude and longer duration are responsible for stronger potentiation of the effective conductance of the network and slower relaxation dynamics, as evidenced by the less pronounced relaxation after 500 μs (details in Supplementary Note 5, Supplementary Figures S5 andS6).The formation upon electrical stimulation and the subsequent spontaneous dissolution of the conductive bridges at NW junctions are responsible for emergent non-linear dynamics and fading memory properties (short-term memory) of the physical reservoir. Indeed, as can be observed in Figure 2a, stimulation of the network in between two terminals upon constant voltage bias leads to the progressive potentiation (facilitation) of the effective network conductance (Figure 2a). After stimulation, the network spontaneously relaxes back to the ground state, as a consequence of the volatile behavior of memristive junctions (Supplementary Note 2). 12 These non-linear network dynamics with fading memory properties can be modelled by mapping the NW network into a weighted grid graph (Supplementary Figure S4, Supplementary Note 3), where the transient behavior of each memristive edge is regulated by short-term memory effects described by a potentiationdepression rate balance equation (Supplementary Note 4). The here proposed model allows: i) to interpolate the evolution over time of the network effective conductance (Figure 2a), and ii) to visualize the resulting spatio-temporal evolution of the conductive pathway when electrically stimulated in different spatial locations (Figure 2b and Supplementary Movie 1). As can be observed, simulations evidence the growth of a conductive pathway connecting the two stimulated areas of the network, followed by the gradual relaxation to the conductance ground state (Figure 2b), in accordance with experimental observations of the formation of a localized conductive pathway connecting stimulated NW network areas. 38,39 Importantly, experimental data show that the change of the effective conductance (Δw) after pulse stimulation and the following relaxation behavior can be controlled by properly adjusting the pulse width and amplitude. Figure 2c reports the change in the effective conductance at the end of a single pulse stimulation with pulses of different lengths and amplitudes and after 500 μs from the end of the pulse. Pulses with higher amplitude and longer duration are responsible for stronger potentiation of the effective conductance of the network and slower relaxation dynamics, as evidenced by the less pronounced relaxation after 500 μs (details in Supplementary Note 5, Supplementary Figures S5 andS6).</p>
        <p>Notably, the NW network can be successfully stimulated by means of low voltage pulse amplitude (&lt; 5 V) and down to the μs timescale. Moreover, the effective conductance gradually increases when a pulse closely follows a prior pulse emulating paired-pulse facilitation (PPF), a process that regulates temporal processing of information in biological neural circuits. 3,40 As a consequence, multiple pulses applied within short time intervals lead to a frequency-dependent gradual increase of conductivity, with accumulation effect due to the competition between conductive path formation and spontaneous relaxation (Figure 2d, Supplementary Figure S7). Since the influence of distant-past inputs asymptotically fades out over time due to short-term memory effect, the NW network reservoir state depends mostly on recent-past inputs (echo state property) 27 .Notably, the NW network can be successfully stimulated by means of low voltage pulse amplitude (&lt; 5 V) and down to the μs timescale. Moreover, the effective conductance gradually increases when a pulse closely follows a prior pulse emulating paired-pulse facilitation (PPF), a process that regulates temporal processing of information in biological neural circuits. 3,40 As a consequence, multiple pulses applied within short time intervals lead to a frequency-dependent gradual increase of conductivity, with accumulation effect due to the competition between conductive path formation and spontaneous relaxation (Figure 2d, Supplementary Figure S7). Since the influence of distant-past inputs asymptotically fades out over time due to short-term memory effect, the NW network reservoir state depends mostly on recent-past inputs (echo state property) 27 .</p>
        <p>Non-linear dynamics, fading memory and temporal processing of multiple spatial inputs with multiterminal configuration provide the basis for the implementation as physical reservoir. RC was demonstrated in a fully memristive architecture based on a NW physical reservoir by solving a pattern recognition task. For this purpose, 4 × 4 patterns with white (1) or black (0) pixels were converted into a spatio-temporal input by dividing the pattern in 4 spatial inputs (pattern rows) each containing a 4-timeframe input stream (pattern columns), as schematized in Figure 3a. Each timeframe (width of 11 ms) is composed of a 10 ms pulse of 5 V if corresponding to a white pixel, or 0 V (no pulse) if corresponding to a black pixel, followed by a 1 ms biased at 0 V. Each input stream was applied to different pads of the multiterminal NW network reservoir. The reservoir state is represented by the collective state of the 3 independent output voltages (Vout) measured on terminal B of resistances R in series for each input channel under small DC bias stimulation (100 mV) of a selected channel (Figure 3b). During classification, the output signals of the final reservoir state (after the termination of the pulse stream) are fed into the 3 × 4 neural network of ReRAM for readout (Methods). The readout output consists of the input voltages multiplied by the conductance weights stored in the cross-point array of ReRAMs obtained by matrix-vector multiplication in the analogue domain with physical multiplication by Ohm's law and physical summation by Kirchhoff's law (Supplementary Figure S8 andS9). 41 The output neuron with the maximum dot product corresponds to the predicted pattern. Note that the advantage of this configuration is that the same network terminals are used both to stimulate and probe the internal reservoir state, limiting the number of required electrodes if compared to a reservoir based on crossbar architecture (Supplementary Figure S10). Also, the NWbased reservoir allows high scalability, high synapse density and minimization of wiring costs (Supplementary Note 6, Supplementary Figure S11). Experimental and modeling studies of the time evolution of the reservoir output voltages are detailed in Supplementary Figures S12 andS13, Supplementary Table 1 and Supplementary Movie 2. Since the multiterminal NW network reservoir behavior is regulated by spatio-temporal dynamics with fading memory properties, the reservoir state depends on both spatial location and temporal sequence of input stimuli (Supplementary Figure S14 and S15). This results in temporal information processing capability of multiple spatial inputs of the NW network reservoir.Non-linear dynamics, fading memory and temporal processing of multiple spatial inputs with multiterminal configuration provide the basis for the implementation as physical reservoir. RC was demonstrated in a fully memristive architecture based on a NW physical reservoir by solving a pattern recognition task. For this purpose, 4 × 4 patterns with white (1) or black (0) pixels were converted into a spatio-temporal input by dividing the pattern in 4 spatial inputs (pattern rows) each containing a 4-timeframe input stream (pattern columns), as schematized in Figure 3a. Each timeframe (width of 11 ms) is composed of a 10 ms pulse of 5 V if corresponding to a white pixel, or 0 V (no pulse) if corresponding to a black pixel, followed by a 1 ms biased at 0 V. Each input stream was applied to different pads of the multiterminal NW network reservoir. The reservoir state is represented by the collective state of the 3 independent output voltages (Vout) measured on terminal B of resistances R in series for each input channel under small DC bias stimulation (100 mV) of a selected channel (Figure 3b). During classification, the output signals of the final reservoir state (after the termination of the pulse stream) are fed into the 3 × 4 neural network of ReRAM for readout (Methods). The readout output consists of the input voltages multiplied by the conductance weights stored in the cross-point array of ReRAMs obtained by matrix-vector multiplication in the analogue domain with physical multiplication by Ohm's law and physical summation by Kirchhoff's law (Supplementary Figure S8 andS9). 41 The output neuron with the maximum dot product corresponds to the predicted pattern. Note that the advantage of this configuration is that the same network terminals are used both to stimulate and probe the internal reservoir state, limiting the number of required electrodes if compared to a reservoir based on crossbar architecture (Supplementary Figure S10). Also, the NWbased reservoir allows high scalability, high synapse density and minimization of wiring costs (Supplementary Note 6, Supplementary Figure S11). Experimental and modeling studies of the time evolution of the reservoir output voltages are detailed in Supplementary Figures S12 andS13, Supplementary Table 1 and Supplementary Movie 2. Since the multiterminal NW network reservoir behavior is regulated by spatio-temporal dynamics with fading memory properties, the reservoir state depends on both spatial location and temporal sequence of input stimuli (Supplementary Figure S14 and S15). This results in temporal information processing capability of multiple spatial inputs of the NW network reservoir.</p>
        <p>The experimental evolution of the reservoir outputs during stimulation with the pattern reported in Figure 3a is reported in Figure 3c (working principles are detailed in Supplementary Note 6 and Supplementary Figure S16, experimental and simulated reservoir outputs and conductance maps are detailed in Supplementary Figure S17 andS18). Figure 3d shows simulation results for the same input signal, indicating a good agreement with the experimental results. Depending on the stimulation pattern, the effect of each stimulation timeframe is to induce a peculiar modification of the local conductivity map that depends also on short-term changes induced by the stimulation during previous timeframes (accumulation effect), as can be observed by direct visualization of spatio-temporal dynamics of the internal reservoir state (Figure 3e, Supplementary Movie S3).The experimental evolution of the reservoir outputs during stimulation with the pattern reported in Figure 3a is reported in Figure 3c (working principles are detailed in Supplementary Note 6 and Supplementary Figure S16, experimental and simulated reservoir outputs and conductance maps are detailed in Supplementary Figure S17 andS18). Figure 3d shows simulation results for the same input signal, indicating a good agreement with the experimental results. Depending on the stimulation pattern, the effect of each stimulation timeframe is to induce a peculiar modification of the local conductivity map that depends also on short-term changes induced by the stimulation during previous timeframes (accumulation effect), as can be observed by direct visualization of spatio-temporal dynamics of the internal reservoir state (Figure 3e, Supplementary Movie S3).</p>
        <p>Thanks to the spatio-temporal information processing capabilities, the NW network was employed for the classification of patterns reported in Figure 4a. Note that after each pattern stimulation, the reservoir spontaneously relaxes back to the ground state due to short-term memory (Supplementary Figure S19). The corresponding experimental and simulated reservoir outputs after stimulation with each pattern are reported in Figure 4e-h andi-l, respectively. The reproducibility of the network response is detailed in Supplementary Figure S20. The results show that the reservoir output voltages and corresponding conductance maps reported in Figure 4m-p are significantly different depending on the specific stimulation pattern, highlighting the reservoir ability to separate these inputs (separability property). Details on the time evolution of reservoir output voltages and conductance maps are reported in Supplementary Figure S21 and S22, respectively. The experimental reservoir states were used as input of the memristive readout function for training and classification, where the accuracy of the fully memristive architecture was evaluated by considering 100 patterns for training and 20 for testing. The experimental synaptic weights mapped on the TaOx ReRAM cross-point array after offline training are reported in Figure 4q. Figure 4r shows the correlation between programmed ReRAM conductance weights and target ones, supporting the accuracy of the readout network. This is further supported by Figure 4s that shows the correlation between the measured readout current and the simulated one. The experimental inference result is reported in Figure 4t. The results indicate that the fully memristive architecture correctly classifies the vast majority of input patterns, with an accuracy of 90.0 % compared with a software readout baseline of 95.0 % (additional data in Supplementary Figure S23).Thanks to the spatio-temporal information processing capabilities, the NW network was employed for the classification of patterns reported in Figure 4a. Note that after each pattern stimulation, the reservoir spontaneously relaxes back to the ground state due to short-term memory (Supplementary Figure S19). The corresponding experimental and simulated reservoir outputs after stimulation with each pattern are reported in Figure 4e-h andi-l, respectively. The reproducibility of the network response is detailed in Supplementary Figure S20. The results show that the reservoir output voltages and corresponding conductance maps reported in Figure 4m-p are significantly different depending on the specific stimulation pattern, highlighting the reservoir ability to separate these inputs (separability property). Details on the time evolution of reservoir output voltages and conductance maps are reported in Supplementary Figure S21 and S22, respectively. The experimental reservoir states were used as input of the memristive readout function for training and classification, where the accuracy of the fully memristive architecture was evaluated by considering 100 patterns for training and 20 for testing. The experimental synaptic weights mapped on the TaOx ReRAM cross-point array after offline training are reported in Figure 4q. Figure 4r shows the correlation between programmed ReRAM conductance weights and target ones, supporting the accuracy of the readout network. This is further supported by Figure 4s that shows the correlation between the measured readout current and the simulated one. The experimental inference result is reported in Figure 4t. The results indicate that the fully memristive architecture correctly classifies the vast majority of input patterns, with an accuracy of 90.0 % compared with a software readout baseline of 95.0 % (additional data in Supplementary Figure S23).</p>
        <p>The NW network reservoir represents a generic computational platform for multiple tasks, since a readout associated to a new task can be learned independently from the readout that was learned in previous tasks. The scalability and versatility of our in-materia RC approach was assessed by simulating an extended NW network for the classification of the complete MNIST handwritten digit dataset and for time series prediction (Figure 5a). Since training occurs only at the readout, the same NW network reservoir can be exploited for solving multiple tasks, each associated to different parallel readouts (Figure 5b). Also, the same reservoir outputs can be analyzed by multiple readouts, in principle allowing the network with multitasking capability.The NW network reservoir represents a generic computational platform for multiple tasks, since a readout associated to a new task can be learned independently from the readout that was learned in previous tasks. The scalability and versatility of our in-materia RC approach was assessed by simulating an extended NW network for the classification of the complete MNIST handwritten digit dataset and for time series prediction (Figure 5a). Since training occurs only at the readout, the same NW network reservoir can be exploited for solving multiple tasks, each associated to different parallel readouts (Figure 5b). Also, the same reservoir outputs can be analyzed by multiple readouts, in principle allowing the network with multitasking capability.</p>
        <p>For the MNIST task, each handwritten digit with 28 × 28 pixels was first binarized, then chopped into 7 columns and merged in a spatio-temporal 196 × 4 pattern (Supplementary Note 7). Then, the obtained pattern was transformed in 196 pulse streams with 4 timeframes that were applied to 14 × 14 NW network pads. Finally, reservoir outputs were exploited as readout input for digit classification (Methods, Supplementary Figure S24). The spatio-temporal evolution of the reservoir state upon stimulation with digit "6" of Figure 5a is reported in Figure 5c, while final reservoir output voltages after stimulation are reported in the histogram of Figure 5d (details in Supplementary Movie 4, additional data in Supplementary Figures S25 andS26). After training the readout with the 60000 handwritten digits from the MNIST training dataset (Supplementary Figure S27), the system can correctly classify ≈ 90.4 % of the 10000 MNIST digits from the test set. Note that the memristive NW network reservoir outperforms the static network (Supplementary Note 8, Supplementary Figure S28), although its accuracy decreases if the final reservoir state loses information from the initial stimulation timeframes (Supplementary Figure S29). The confusion matrix is reported in Figure 5e and detailed in Supplementary Table 2. Misclassifications were mainly related to digits that are hardly distinguishable due to low pixel resolution and to the partial loss of information during the binarization of grayscale images (Supplementary Figure S30). Since the spatial information is encoded in the spatio-temporal domain and the physical reservoir does not require training, the main advantage of this nanoarchitecture is the reduction of network size and training cost (Supplementary Note 9). Note that the accuracy is notably higher than previously presented one-shot memristor-based RC systems, 36 while accuracy can be further increased with multiple reads during the reservoir computation 34 , at the cost of a quadratic increase in computational complexity (Supplementary Note 10).For the MNIST task, each handwritten digit with 28 × 28 pixels was first binarized, then chopped into 7 columns and merged in a spatio-temporal 196 × 4 pattern (Supplementary Note 7). Then, the obtained pattern was transformed in 196 pulse streams with 4 timeframes that were applied to 14 × 14 NW network pads. Finally, reservoir outputs were exploited as readout input for digit classification (Methods, Supplementary Figure S24). The spatio-temporal evolution of the reservoir state upon stimulation with digit "6" of Figure 5a is reported in Figure 5c, while final reservoir output voltages after stimulation are reported in the histogram of Figure 5d (details in Supplementary Movie 4, additional data in Supplementary Figures S25 andS26). After training the readout with the 60000 handwritten digits from the MNIST training dataset (Supplementary Figure S27), the system can correctly classify ≈ 90.4 % of the 10000 MNIST digits from the test set. Note that the memristive NW network reservoir outperforms the static network (Supplementary Note 8, Supplementary Figure S28), although its accuracy decreases if the final reservoir state loses information from the initial stimulation timeframes (Supplementary Figure S29). The confusion matrix is reported in Figure 5e and detailed in Supplementary Table 2. Misclassifications were mainly related to digits that are hardly distinguishable due to low pixel resolution and to the partial loss of information during the binarization of grayscale images (Supplementary Figure S30). Since the spatial information is encoded in the spatio-temporal domain and the physical reservoir does not require training, the main advantage of this nanoarchitecture is the reduction of network size and training cost (Supplementary Note 9). Note that the accuracy is notably higher than previously presented one-shot memristor-based RC systems, 36 while accuracy can be further increased with multiple reads during the reservoir computation 34 , at the cost of a quadratic increase in computational complexity (Supplementary Note 10).</p>
        <p>The RC architecture is also suitable for the prediction of purely time-dependent tasks such as Mackey-Glass time series, a chaotic system that has a deterministic form, but is considered difficult to predict with conventional machine-learning algorithms. 42,43 The Mackey-Glass task has been implemented by presenting an initial teacher signal generated by the Mackey-Glass equation, followed by the prediction by the trained system of the time-series some steps ahead. Figure 5f and g reports the results of autonomous time-series prediction, which was performed by considering multiple reservoir output nodes and the virtual node method for delayed feedback systems 17,34,44 (details in Methods and Supplementary Figure S31). In Figure 5f, it can be observed that the target and the predicted value during the training process match accurately (accuracy ≈ 100 %), showing that the trained readout weights are able to calculate the next time-step signal based on the reservoir outputs. After initialization, the network was used to predict the time series autonomously (Figure 5g). After time step 900, the readout output (the predicted signal) is fed as the new input to the reservoir state in a closed feedback loop. As a result, the system can autonomously and continuously produce the time series that was observed to well match with the expected ground truth, which is shown in the plot as a reference (trace plots in the phase space in Supplementary Figure S32). After few hundreds time steps of accurate time series prediction (accuracy of ~ 90.6 % over 100 timesteps), deviations from the ground truth start to occur due to the accumulation of small errors in the autonomous prediction, with consequent phase shift. Despite the loss of accuracy, the predicted signal still maintains the main features and temporal dynamics of the Mackey-Glass time series. Long-term prediction can be achieved by periodically updating the NW network reservoir, avoiding divergence of the system to the chaotic ground truth (Supplementary Figure S33).The RC architecture is also suitable for the prediction of purely time-dependent tasks such as Mackey-Glass time series, a chaotic system that has a deterministic form, but is considered difficult to predict with conventional machine-learning algorithms. 42,43 The Mackey-Glass task has been implemented by presenting an initial teacher signal generated by the Mackey-Glass equation, followed by the prediction by the trained system of the time-series some steps ahead. Figure 5f and g reports the results of autonomous time-series prediction, which was performed by considering multiple reservoir output nodes and the virtual node method for delayed feedback systems 17,34,44 (details in Methods and Supplementary Figure S31). In Figure 5f, it can be observed that the target and the predicted value during the training process match accurately (accuracy ≈ 100 %), showing that the trained readout weights are able to calculate the next time-step signal based on the reservoir outputs. After initialization, the network was used to predict the time series autonomously (Figure 5g). After time step 900, the readout output (the predicted signal) is fed as the new input to the reservoir state in a closed feedback loop. As a result, the system can autonomously and continuously produce the time series that was observed to well match with the expected ground truth, which is shown in the plot as a reference (trace plots in the phase space in Supplementary Figure S32). After few hundreds time steps of accurate time series prediction (accuracy of ~ 90.6 % over 100 timesteps), deviations from the ground truth start to occur due to the accumulation of small errors in the autonomous prediction, with consequent phase shift. Despite the loss of accuracy, the predicted signal still maintains the main features and temporal dynamics of the Mackey-Glass time series. Long-term prediction can be achieved by periodically updating the NW network reservoir, avoiding divergence of the system to the chaotic ground truth (Supplementary Figure S33).</p>
        <p>Depending on the specific task, the accuracy of the system can be further improved by optimizing the stimulating parameters that regulates the NW network nonlinear response such as pulse amplitude, width, and rates. Also, the physical reservoir can be further simplified by compensating the reduction of physical nodes (number of electrodes) by introducing virtual nodes. 44 Note also that the RC capabilities are not hindered by non-idealities including local variations of the NW density that lead to a non-homogeneous conductivity map over the NW network 45 and/or by the junction-to-junction variability of the memristive behavior 12 . Indeed, these effects that lead to a different nonlinear response of different areas of the network can enhance the extraction of relevant features from the reservoir, resulting even beneficial for the computing performances. 34,46 This opens the possibility of locally controlling the topology and memristive response of the network to optimize computing performances on specific tasks. Also, the number of reservoir input/outputs is limited only by the number of contacts that can be realized, which supports the possibility of designing cost-effective neuromorphic nanoarchitectures able to process a large number of spatio-temporal inputs. Although the power consumption of our NW-based physical reservoir is higher than state-of-the-art of topdown memristive RC systems, the energy efficiency can be largely optimized by properly engineering the NW core-shell structure to reduce the switching/operating currents (Supplementary Note 11).Depending on the specific task, the accuracy of the system can be further improved by optimizing the stimulating parameters that regulates the NW network nonlinear response such as pulse amplitude, width, and rates. Also, the physical reservoir can be further simplified by compensating the reduction of physical nodes (number of electrodes) by introducing virtual nodes. 44 Note also that the RC capabilities are not hindered by non-idealities including local variations of the NW density that lead to a non-homogeneous conductivity map over the NW network 45 and/or by the junction-to-junction variability of the memristive behavior 12 . Indeed, these effects that lead to a different nonlinear response of different areas of the network can enhance the extraction of relevant features from the reservoir, resulting even beneficial for the computing performances. 34,46 This opens the possibility of locally controlling the topology and memristive response of the network to optimize computing performances on specific tasks. Also, the number of reservoir input/outputs is limited only by the number of contacts that can be realized, which supports the possibility of designing cost-effective neuromorphic nanoarchitectures able to process a large number of spatio-temporal inputs. Although the power consumption of our NW-based physical reservoir is higher than state-of-the-art of topdown memristive RC systems, the energy efficiency can be largely optimized by properly engineering the NW core-shell structure to reduce the switching/operating currents (Supplementary Note 11).</p>
        <p>However, it is important to remark that this network-type reservoir based on NW networks is able to process multiple inputs by experiencing synaptic plasticity at many spatial and temporal scales from μs up to hundreds of seconds depending on input stimuli, as required to reach the potential of brainderived computing. 47 For this reason, this low-cost physical reservoir can be explored for a wide range of applications including speech recognition, natural language analysis, motion identification and processing of multiple sensorial inputs for robotics. For all these challenging computing tasks, a versatile implementation design of a large-scale NW-based fully memristive system is proposed in Supplementary Figure S34.However, it is important to remark that this network-type reservoir based on NW networks is able to process multiple inputs by experiencing synaptic plasticity at many spatial and temporal scales from μs up to hundreds of seconds depending on input stimuli, as required to reach the potential of brainderived computing. 47 For this reason, this low-cost physical reservoir can be explored for a wide range of applications including speech recognition, natural language analysis, motion identification and processing of multiple sensorial inputs for robotics. For all these challenging computing tasks, a versatile implementation design of a large-scale NW-based fully memristive system is proposed in Supplementary Figure S34.</p>
        <p>In conclusion, a fully memristive RC architecture was implemented in hardware by using a memristive NW network acting as a network-wide reservoir. Similar to biological organisms, computational properties of the network emerge as a collective property of the self-organizing and highly connected system, having a large number of interacting components (memristive elements).In conclusion, a fully memristive RC architecture was implemented in hardware by using a memristive NW network acting as a network-wide reservoir. Similar to biological organisms, computational properties of the network emerge as a collective property of the self-organizing and highly connected system, having a large number of interacting components (memristive elements).</p>
        <p>The recognition of spatio-temporal patterns was demonstrated by coupling the NW network with a memristive readout network of ReRAM devices, where data processing in both reservoir and readout was performed in hardware. In particular, the computing capabilities of the NW network physical reservoir was demonstrated by classification of the MNIST handwritten digit dataset and Mackey-Glass time series prediction. These results pave the way for the in-materia implementation of braininspired unconventional computing paradigms thanks to the exploitation of emergent memristive behavior in self-organizing NW networks combined with conventional top-down ReRAM devices, towards the realization of general-purpose intelligent systems that combines different neuromorphic hardware technologies aiming to general intelligence.The recognition of spatio-temporal patterns was demonstrated by coupling the NW network with a memristive readout network of ReRAM devices, where data processing in both reservoir and readout was performed in hardware. In particular, the computing capabilities of the NW network physical reservoir was demonstrated by classification of the MNIST handwritten digit dataset and Mackey-Glass time series prediction. These results pave the way for the in-materia implementation of braininspired unconventional computing paradigms thanks to the exploitation of emergent memristive behavior in self-organizing NW networks combined with conventional top-down ReRAM devices, towards the realization of general-purpose intelligent systems that combines different neuromorphic hardware technologies aiming to general intelligence.</p>
        <p>Fig. 1 | Physical RC based on memristive NW networks. a. Schematic representation of the RC paradigm where the reservoir maps the input into a higher dimensional space that is then analyzed by a readout function. The readout weights (Wout) are the only ones to be trained by comparing the output y(t) with the desired output yd(t). b. Schematic representation of RC implementation in a fullymemristive nanoarchitecture where an input encoded in pulse streams is processed by the NW network physical reservoir. Then, the physical reservoir state is analyzed by the memristive readout neural network, implemented in hardware with ReRAM devices. c. SEM image of a highly interconnected memristive NW network reservoir (scale bar, 2 μm). d. Schematic representation of the resistive switching mechanism occurring at the NW junctions, where the conductivity can be modulated by the formation/rupture of a metallic Ag conductive path across the NW shell layer, under the action of the applied electric field. e. SEM image of a TaOx ReRAM cell at the cross-point between top and bottom electrodes (scale bar, 2 μm). f. Schematic representation of the working principle of the TaOx ReRAM cell based on the formation/rupture of a sub stoichiometric conductive filament rich of oxygen vacancies. Yellow spheres represent the metal oxide in a reduced valence state, while red spheres represent oxygen vacancies. Fig. 2 | Non-linear dynamics and fading memory properties of the memristive NW network reservoir. a. Experimental and simulated potentiation and subsequent spontaneous relaxation of the effective conductance upon voltage pulse stimulation (2V, 100 s) in two-terminal configuration, as schematized in the inset. b. Spatio-temporal evolution of the conductive path formation and following dissolution according to the grid graph network model where short-term conductance dynamics of each edge is modelled through a potentiation-depression rate balance equation. Red intensity of edges is proportional to the edge conductance, blue intensity of each node is proportional to the node voltage, while arrows indicate the current direction and black nodes represent input pads. The left electrode was biased while the right one was kept as ground. c. Change in the conductance weight of the network in two-terminal configuration at the end of a single pulse stimulus and after 500 µs, for stimulation pulse length (tp) of 10 µs, 100 µs and 1 ms with different pulse amplitudes (Vp). d. Gradual increase of the network effective conductance under stimulation with a train of pulses (1 ms, 5V) showing paired-pulse facilitation (PPF). Higher pulse frequencies resulted in a more pronounced increase of the network effective conductance. 1) and black (0) pixels converted into a spatio-temporal input; the spatio-temporal input is fed to the network reservoir in the form of voltage pulses applied to different locations of the network (spatial domain) at different times (temporal domain). b. Conceptual schematic representation of the experimental implementation of RC in a fully memristive nanoarchitecture where each temporal pattern is applied to different spatial locations of the network. The reservoir state after stimulation is represented by the output voltage drop (Vout) on a series resistance (R = 82 Ω) that was monitored over time by applying a small DC voltage bias (Vread = 100 mV) to an arbitrary pad (pad 4) in addition to the pulse stream. The reservoir output is then passed to the input of a one-layer feedforward neural network implemented with a cross-point circuit of ReRAM elements (blue cylinders) that are located at the cross-point positions between rows (grey bars) and columns (yellow bars). This ReRAM circuit performs matrix-vector multiplication of the input to obtain the desired output. c. Experimental and d. simulated evolution of output voltages after each stimulation timeframe of pattern reported in panel a. The timeframe 0 represents output voltages of the reservoir state before stimulation (ground state). In panels c, experimental data represent the mean and standard deviation of output voltages obtained by stimulating the NW network 30 times with the same pattern. e. Direct visualization by modeling of the evolution of the reservoir state represented by the network conductivity map after each stimulation timeframe. Red intensity of edges is proportional to the edge conductance, blue intensity of each node is proportional to the node voltage, while arrows indicate the current direction and black nodes represent input pads. a. Versatility of the NW network to solve N tasks including MNIST handwritten digit classification (here the original image with 28 × 28 pixels is binarized, then divided into 7 columns and merged in a 196 × 4 pattern that is converted in 196 pulse streams with 4 timeframes) and Mackey-Glass time series prediction. b. Different tasks can be solved with the same NW network by associating to each task a readout that can be trained independently, without interfering with what was learned in previous tasks. A NW network with a 14 × 14 grid of electrodes was considered. c. Direct visualization of the evolution of the reservoir state after each timeframe stimulation of digit "6" reported in panel a and d. corresponding reservoir output voltages. In panel c, red intensity of edges is proportional to the edge conductance, blue intensity of each node is proportional to the node voltage, while arrows indicate the current direction and black nodes represent input pads. e. Confusion matrix from inference results on classifying the MNIST test set of 10000 handwritten digits, after training the readout with the MNIST training set of 60000 handwritten digits. The color bar represents the occurrence of a given predicted output. f. Training and g. autonomous forecasting of the Mackey-Glass time series with the NW network. The ground truth is represented in grey, while the predicted output in red.Fig. 1 | Physical RC based on memristive NW networks. a. Schematic representation of the RC paradigm where the reservoir maps the input into a higher dimensional space that is then analyzed by a readout function. The readout weights (Wout) are the only ones to be trained by comparing the output y(t) with the desired output yd(t). b. Schematic representation of RC implementation in a fullymemristive nanoarchitecture where an input encoded in pulse streams is processed by the NW network physical reservoir. Then, the physical reservoir state is analyzed by the memristive readout neural network, implemented in hardware with ReRAM devices. c. SEM image of a highly interconnected memristive NW network reservoir (scale bar, 2 μm). d. Schematic representation of the resistive switching mechanism occurring at the NW junctions, where the conductivity can be modulated by the formation/rupture of a metallic Ag conductive path across the NW shell layer, under the action of the applied electric field. e. SEM image of a TaOx ReRAM cell at the cross-point between top and bottom electrodes (scale bar, 2 μm). f. Schematic representation of the working principle of the TaOx ReRAM cell based on the formation/rupture of a sub stoichiometric conductive filament rich of oxygen vacancies. Yellow spheres represent the metal oxide in a reduced valence state, while red spheres represent oxygen vacancies. Fig. 2 | Non-linear dynamics and fading memory properties of the memristive NW network reservoir. a. Experimental and simulated potentiation and subsequent spontaneous relaxation of the effective conductance upon voltage pulse stimulation (2V, 100 s) in two-terminal configuration, as schematized in the inset. b. Spatio-temporal evolution of the conductive path formation and following dissolution according to the grid graph network model where short-term conductance dynamics of each edge is modelled through a potentiation-depression rate balance equation. Red intensity of edges is proportional to the edge conductance, blue intensity of each node is proportional to the node voltage, while arrows indicate the current direction and black nodes represent input pads. The left electrode was biased while the right one was kept as ground. c. Change in the conductance weight of the network in two-terminal configuration at the end of a single pulse stimulus and after 500 µs, for stimulation pulse length (tp) of 10 µs, 100 µs and 1 ms with different pulse amplitudes (Vp). d. Gradual increase of the network effective conductance under stimulation with a train of pulses (1 ms, 5V) showing paired-pulse facilitation (PPF). Higher pulse frequencies resulted in a more pronounced increase of the network effective conductance. 1) and black (0) pixels converted into a spatio-temporal input; the spatio-temporal input is fed to the network reservoir in the form of voltage pulses applied to different locations of the network (spatial domain) at different times (temporal domain). b. Conceptual schematic representation of the experimental implementation of RC in a fully memristive nanoarchitecture where each temporal pattern is applied to different spatial locations of the network. The reservoir state after stimulation is represented by the output voltage drop (Vout) on a series resistance (R = 82 Ω) that was monitored over time by applying a small DC voltage bias (Vread = 100 mV) to an arbitrary pad (pad 4) in addition to the pulse stream. The reservoir output is then passed to the input of a one-layer feedforward neural network implemented with a cross-point circuit of ReRAM elements (blue cylinders) that are located at the cross-point positions between rows (grey bars) and columns (yellow bars). This ReRAM circuit performs matrix-vector multiplication of the input to obtain the desired output. c. Experimental and d. simulated evolution of output voltages after each stimulation timeframe of pattern reported in panel a. The timeframe 0 represents output voltages of the reservoir state before stimulation (ground state). In panels c, experimental data represent the mean and standard deviation of output voltages obtained by stimulating the NW network 30 times with the same pattern. e. Direct visualization by modeling of the evolution of the reservoir state represented by the network conductivity map after each stimulation timeframe. Red intensity of edges is proportional to the edge conductance, blue intensity of each node is proportional to the node voltage, while arrows indicate the current direction and black nodes represent input pads. a. Versatility of the NW network to solve N tasks including MNIST handwritten digit classification (here the original image with 28 × 28 pixels is binarized, then divided into 7 columns and merged in a 196 × 4 pattern that is converted in 196 pulse streams with 4 timeframes) and Mackey-Glass time series prediction. b. Different tasks can be solved with the same NW network by associating to each task a readout that can be trained independently, without interfering with what was learned in previous tasks. A NW network with a 14 × 14 grid of electrodes was considered. c. Direct visualization of the evolution of the reservoir state after each timeframe stimulation of digit "6" reported in panel a and d. corresponding reservoir output voltages. In panel c, red intensity of edges is proportional to the edge conductance, blue intensity of each node is proportional to the node voltage, while arrows indicate the current direction and black nodes represent input pads. e. Confusion matrix from inference results on classifying the MNIST test set of 10000 handwritten digits, after training the readout with the MNIST training set of 60000 handwritten digits. The color bar represents the occurrence of a given predicted output. f. Training and g. autonomous forecasting of the Mackey-Glass time series with the NW network. The ground truth is represented in grey, while the predicted output in red.</p>
        <p>was used to generate input signal and connected to terminals A of 4 input resistance R = 82 Ω whose terminal B was directly connected to the NW network pads (refer to Figure 3b). The AWG was programmed such that the output impedance is fixed to 50 Ω and comparable to R. A Tektronix MSO58 8-channel oscilloscope was used to monitor the circuit voltages by means of high-impedance probes connected to the B terminals of the input resistances. For each resistance, 2 probes were connected for being able of monitoring the voltage developed across the NW network both during the set operation, which usually shows relatively large currents, and read operation, which drains typically a lower current. The read of the reservoir output voltages for each timeframe during pattern classification was performed according to Supplementary Figure S9, where the final reservoir state after stimulation to be passed to the readout for classification corresponds to the reservoir output voltages at timeframe t4. Note that for n input channels only n-1 output voltages are independent according to the Kirchhoff's law.was used to generate input signal and connected to terminals A of 4 input resistance R = 82 Ω whose terminal B was directly connected to the NW network pads (refer to Figure 3b). The AWG was programmed such that the output impedance is fixed to 50 Ω and comparable to R. A Tektronix MSO58 8-channel oscilloscope was used to monitor the circuit voltages by means of high-impedance probes connected to the B terminals of the input resistances. For each resistance, 2 probes were connected for being able of monitoring the voltage developed across the NW network both during the set operation, which usually shows relatively large currents, and read operation, which drains typically a lower current. The read of the reservoir output voltages for each timeframe during pattern classification was performed according to Supplementary Figure S9, where the final reservoir state after stimulation to be passed to the readout for classification corresponds to the reservoir output voltages at timeframe t4. Note that for n input channels only n-1 output voltages are independent according to the Kirchhoff's law.</p>
        <p>The memristive readout function for spatio-termporal pattern recognition was offline trained through supervised learning by minimizing the categorical cross-entropy loss function (𝐿):The memristive readout function for spatio-termporal pattern recognition was offline trained through supervised learning by minimizing the categorical cross-entropy loss function (𝐿):</p>
        <p>where N is the dimension of the output size, 𝑤 the model parameters, 𝑦 ! the desired target and 𝑦 -! the readout model prediction. The minimization of the loss function performed in a Python environment has been achieved according to the Adam algorithm, 4 which relies on the optimization of stochastic gradient-descent method by the adaptive tuning of the learning rates for the different parameters to train. The parameters vector is updated at each step 𝑡 according to:where N is the dimension of the output size, 𝑤 the model parameters, 𝑦 ! the desired target and 𝑦 -! the readout model prediction. The minimization of the loss function performed in a Python environment has been achieved according to the Adam algorithm, 4 which relies on the optimization of stochastic gradient-descent method by the adaptive tuning of the learning rates for the different parameters to train. The parameters vector is updated at each step 𝑡 according to:</p>
        <p>with 𝜂 % the adaptive learning rate and 𝐿 ! the loss function associated to a random subset of training dataset. For each epoch, eq. ( 2) is iterated over the whole train dataset subsets. Typically, the epochs number to obtain a good convergence of the model has been set to 2000. The readout was trained with linear regression for Mackey-Glass time-series prediction.with 𝜂 % the adaptive learning rate and 𝐿 ! the loss function associated to a random subset of training dataset. For each epoch, eq. ( 2) is iterated over the whole train dataset subsets. Typically, the epochs number to obtain a good convergence of the model has been set to 2000. The readout was trained with linear regression for Mackey-Glass time-series prediction.</p>
        <p>The reservoir state has been classified by means of a simple one-layer neural network readout function implemented in hardware in a ReRAM array. The one-layer neural network readout is fully connected, whose neurons are activated through the softmax (𝑆 2 ) non-linear function. The model prediction results to be:The reservoir state has been classified by means of a simple one-layer neural network readout function implemented in hardware in a ReRAM array. The one-layer neural network readout is fully connected, whose neurons are activated through the softmax (𝑆 2 ) non-linear function. The model prediction results to be:</p>
        <p>where A is the neural network weights matrix and b the bias vector that were implemented in hardware in the TaOx ReRAM cross-point array while 𝑥 ! are the readout inputs. As readout inputs, the standardized reservoir outputs (by removing the mean value and scaling to the unit variance) were passed as voltage inputs to the readout function. In the readout memristive circuit, the synaptic weight W is mapped by a pair of conductance G + and G -biased at positive and negative voltages, respectively, and the synaptic weight is described by the equivalent conductance G + -G -. 5 Synaptic weights were linearly mapped in the range 45 -100 μS to ensure device stability, while the input readout voltage amplitude was linearly mapped in the range 0.01 -0.31 V. The ReRAM devices in each column were first formed, then they were connected to the external pads of a package by wire bonding, and finally they were operated in a crosspoint fashion, for example, the top electrodes of the first cell in each column were all short-circuited to form the first row of the ReRAM array. The crosspoint operation was executed by a switch matrix enabling the reconfigurable connection of all terminal. The weights Gij were then programmed in the crosspoint array in differential mode, where a synaptic weight was obtained by programming a positive conductance G + in a cell and a negative conductance G -in another cell, to obtain the desired weight Gij = G + -G -. Finally, the voltage signal was applied at the row terminals and the column currents were collected to enable physical summation according to the Kirchhoff's law. An Agilent B1500 semiconductor parameter analyzer was used for programming the ReRAM devices in the desired weights via quasi-static programming pulse. A program and verify algorithm was used to correctly program the analog weights, by targeting a conductance Gtarget and applying set/reset pulses until convergence upon a given tolerance ± 5%. A Keithley 707 switch matrix was used to access to any device in a random fashion and connect the cross-point array with common rows/columns in a crossbar. A TTI TGA1252 4-channel AWG was used to generate analog vectors corresponding to the output of the reservoir layer, to apply to the cross-point array columns, while the rows were kept at ground through a low impedance input of an Tektronix MSO58 8-channel oscilloscope, that was used also for monitoring the currents.where A is the neural network weights matrix and b the bias vector that were implemented in hardware in the TaOx ReRAM cross-point array while 𝑥 ! are the readout inputs. As readout inputs, the standardized reservoir outputs (by removing the mean value and scaling to the unit variance) were passed as voltage inputs to the readout function. In the readout memristive circuit, the synaptic weight W is mapped by a pair of conductance G + and G -biased at positive and negative voltages, respectively, and the synaptic weight is described by the equivalent conductance G + -G -. 5 Synaptic weights were linearly mapped in the range 45 -100 μS to ensure device stability, while the input readout voltage amplitude was linearly mapped in the range 0.01 -0.31 V. The ReRAM devices in each column were first formed, then they were connected to the external pads of a package by wire bonding, and finally they were operated in a crosspoint fashion, for example, the top electrodes of the first cell in each column were all short-circuited to form the first row of the ReRAM array. The crosspoint operation was executed by a switch matrix enabling the reconfigurable connection of all terminal. The weights Gij were then programmed in the crosspoint array in differential mode, where a synaptic weight was obtained by programming a positive conductance G + in a cell and a negative conductance G -in another cell, to obtain the desired weight Gij = G + -G -. Finally, the voltage signal was applied at the row terminals and the column currents were collected to enable physical summation according to the Kirchhoff's law. An Agilent B1500 semiconductor parameter analyzer was used for programming the ReRAM devices in the desired weights via quasi-static programming pulse. A program and verify algorithm was used to correctly program the analog weights, by targeting a conductance Gtarget and applying set/reset pulses until convergence upon a given tolerance ± 5%. A Keithley 707 switch matrix was used to access to any device in a random fashion and connect the cross-point array with common rows/columns in a crossbar. A TTI TGA1252 4-channel AWG was used to generate analog vectors corresponding to the output of the reservoir layer, to apply to the cross-point array columns, while the rows were kept at ground through a low impedance input of an Tektronix MSO58 8-channel oscilloscope, that was used also for monitoring the currents.</p>
        <p>Classification of the MNIST handwritten digit dataset was performed by modelling the NW network as a grid graph with 29 × 29 nodes, where the properties of memristive edges were extrapolated from experimental measurements (refer to Supplementary Figure S4).Classification of the MNIST handwritten digit dataset was performed by modelling the NW network as a grid graph with 29 × 29 nodes, where the properties of memristive edges were extrapolated from experimental measurements (refer to Supplementary Figure S4).</p>
        <p>..</p>
        <p>Time-series prediction was demonstrated by considering the Mackey-Glass time series described by the time-delayed differential equation:Time-series prediction was demonstrated by considering the Mackey-Glass time series described by the time-delayed differential equation:</p>
        <p>The support by Mauro Raimondo in helping with SEM measurements is acknowledged. Device fabrication was performed at "Nanofacility Piemonte", a facility supported by the "Compagnia di San Paolo" foundation. Part of this work was supported by the European project 
            <rs type="software">MEMQuD</rs>, code 20FUN06. This project (EMPIR 20FUN06 MEMQuD) has received funding from the EMPIR programme co-financed by the Participating States and from the European Union's Horizon 2020 research and innovation programme.
        </p>
        <p>The data that support the findings of this study are available on Zenodo (DOI: 10.5281/zenodo.5153335). All other data are available from the authors.The data that support the findings of this study are available on Zenodo (DOI: 10.5281/zenodo.5153335). All other data are available from the authors.</p>
        <p>The codes used to generate datasets of simulations can be found on 
            <rs type="software">GitHub</rs> (
            <rs type="url">https://github.com/MilanoGianluca/Nanowire_Network_Reservoir_Computing)</rs>.
        </p>
        <p>The device configuration and implementation method of reservoir computing are currently under patent filing (Italian priority application number 102021000019277).The device configuration and implementation method of reservoir computing are currently under patent filing (Italian priority application number 102021000019277).</p>
        <p>NW networks were realized by drop casting Ag NWs with diameter of 115 nm and length of 20-50 μm in isopropyl suspension (from Sigma-Aldrich) on a SiO2 (1 μm)/ Si commercial substrate (Supplementary Figure S1). The structural topology of the network was characterized by means of scanning electron microscopy (FESEM; Zeiss Merlin). Structural and chemical characterization of Ag NWs, performed in our previous work 1 by means of transmission electron microscopy (TEM) and X-ray photoelectron spectroscopy (XPS), revealed that these NWs are characterized by the presence of a polyvinylpyrrolidone (PVP) shell layer of ~ 1-2 nm surrounding the Ag NW core. The presence of this shell layer is a direct consequence of the polyol synthesis process, where this polymer is used as surfactant to control the morphology of these nanostructures. Besides acting as a memristive shell, the PVP layer contributes also to the chemical stability of the Ag NW inner core preventing its direct contact with the surrounding atmosphere. Memristive NW networks with areal mass density (AMD) of 41 mg/m 2 were realized by controlling the concentration of Ag NWs in the suspension and by fixing the drop volume deposited on a 12 × 12 mm 2 to 20 μl in order to ensure homogeneous distribution of NWs all over the sample. 2 Electrical contacts on the NW network were realized by deposition of Au pads by sputtering and shadow mask (thickness of 250 nm, approximate size of 1.2 x 0.3 mm).NW networks were realized by drop casting Ag NWs with diameter of 115 nm and length of 20-50 μm in isopropyl suspension (from Sigma-Aldrich) on a SiO2 (1 μm)/ Si commercial substrate (Supplementary Figure S1). The structural topology of the network was characterized by means of scanning electron microscopy (FESEM; Zeiss Merlin). Structural and chemical characterization of Ag NWs, performed in our previous work 1 by means of transmission electron microscopy (TEM) and X-ray photoelectron spectroscopy (XPS), revealed that these NWs are characterized by the presence of a polyvinylpyrrolidone (PVP) shell layer of ~ 1-2 nm surrounding the Ag NW core. The presence of this shell layer is a direct consequence of the polyol synthesis process, where this polymer is used as surfactant to control the morphology of these nanostructures. Besides acting as a memristive shell, the PVP layer contributes also to the chemical stability of the Ag NW inner core preventing its direct contact with the surrounding atmosphere. Memristive NW networks with areal mass density (AMD) of 41 mg/m 2 were realized by controlling the concentration of Ag NWs in the suspension and by fixing the drop volume deposited on a 12 × 12 mm 2 to 20 μl in order to ensure homogeneous distribution of NWs all over the sample. 2 Electrical contacts on the NW network were realized by deposition of Au pads by sputtering and shadow mask (thickness of 250 nm, approximate size of 1.2 x 0.3 mm).</p>
        <p>The ReRAM cross-point array for hardware implementation of the memristive readout is fabricated by e-beam evaporation of a TaOx active layer (3 nm, RMS roughness &lt; 0.3 nm) sandwiched between a Pt bottom electrode and a Ta/Ti top electrode, again realized by e-beam evaporation. The oxide layer and the top electrode are evaporated without breaking the vacuum. The ReRAM array was composed of different columns of single cross-point cells that were wirebonded to recreate a fully connected crosspoint array (Supplementary Figure S2).The ReRAM cross-point array for hardware implementation of the memristive readout is fabricated by e-beam evaporation of a TaOx active layer (3 nm, RMS roughness &lt; 0.3 nm) sandwiched between a Pt bottom electrode and a Ta/Ti top electrode, again realized by e-beam evaporation. The oxide layer and the top electrode are evaporated without breaking the vacuum. The ReRAM array was composed of different columns of single cross-point cells that were wirebonded to recreate a fully connected crosspoint array (Supplementary Figure S2).</p>
        <p>Electrical measurements in two-terminal configuration reported in Figure 2 were performed by contacting Au pads separated by ≈ 7 mm with electrical probes in a SemiProbe probe station coupled with a Keithley 4200 semiconductor device analyzer equipped with pulse measuring units (PMUs).Electrical measurements in two-terminal configuration reported in Figure 2 were performed by contacting Au pads separated by ≈ 7 mm with electrical probes in a SemiProbe probe station coupled with a Keithley 4200 semiconductor device analyzer equipped with pulse measuring units (PMUs).</p>
        <p>The conductance weight change reported in Figure 2c was evaluated as Δw = [G2 - G1]/G1, where G2 is the effective conductance evaluated at the end of stimulation or 500 μs after stimulation while G1 is the effective conductance before stimulation as schematized in Supplementary Figure S4. In order to monitor the spontaneous relaxation process of the network after stimulation, stress voltages in the range of 10-50 mV were applied to minimize the influence of the bias voltage on the relaxation process ensuring at the same time recording of a high signal-to-noise current time trace. All measurements were performed in air at room temperature.The conductance weight change reported in Figure 2c was evaluated as Δw = [G2 - G1]/G1, where G2 is the effective conductance evaluated at the end of stimulation or 500 μs after stimulation while G1 is the effective conductance before stimulation as schematized in Supplementary Figure S4. In order to monitor the spontaneous relaxation process of the network after stimulation, stress voltages in the range of 10-50 mV were applied to minimize the influence of the bias voltage on the relaxation process ensuring at the same time recording of a high signal-to-noise current time trace. All measurements were performed in air at room temperature.</p>
        <p>Modeling of the spatio-temporal evolution of the memristive NW network was performed in Python exploiting the 
            <rs type="software">NetworkX package</rs>. For this purpose the NW network was modelled as a regular grid graph with random diagonals where the edge dynamics with short-term memory effect is described with a physics-based potentiation-depression rate balance equation according to the Miranda's model. 3 Pads were disposed on the grid graph according to the geometry of the considered experimental NW network sample. Details of NW network representation with a grid graph model are reported in Figure S3 and Supplementary Note 2, while the state equation regulating edge dynamics is described in Supplementary Note 3. Parameters of the model extrapolated from experimental data are reported in Supplementary Table 1.
        </p>
        <p>The NW network device was bonded on a custom package and connected to a printed circuit board (PCB). A TTI TGA1242 4-channel arbitrary waveform generator (AWG) acting as a voltage bufferThe NW network device was bonded on a custom package and connected to a printed circuit board (PCB). A TTI TGA1242 4-channel arbitrary waveform generator (AWG) acting as a voltage buffer</p>
        <p>This equation can display a wide range of chaotic behaviors, depending on the values of parameters.This equation can display a wide range of chaotic behaviors, depending on the values of parameters.</p>
        <p>The Mackey-Glass time series was normalized and transformed to an input voltage signal (in the range 1 -6 V) to be presented to the NW network reservoir system by using a chessboard scheme, as schematized in Supplementary Figure S26. To increase the accuracy prediction of the system, the reservoir dynamics was expanded i) by considering the response of multiple reservoir output nodes that result in qualitatively similar but quantitatively different responses to the same input (refer to Supplementary Figure S26), and ii) by using the virtual node method for delayed feedback systems 6 . Autonomous time-series prediction using the NW network-based system was obtained by considering the output of 98 reservoir outputs and 20 virtual nodes, by setting the parameters 𝛽 = 0.2, 𝛾 = 0.9, 𝑛 = 10 and 𝜏 = 18 that correspond to chaotic dynamics (chaotic behaviors can be observed for 𝜏 &gt; 16.8). Before autonomous prediction, since the chaotic time series strongly depends on the initial conditions, the network (initially in the pristine state) was excited during an initialization step by sending the true input without training. The performance accuracy of the Mackey-Glass time series prediction was evaluated as 1-RMSE, where RMSE represents the root mean square error.The Mackey-Glass time series was normalized and transformed to an input voltage signal (in the range 1 -6 V) to be presented to the NW network reservoir system by using a chessboard scheme, as schematized in Supplementary Figure S26. To increase the accuracy prediction of the system, the reservoir dynamics was expanded i) by considering the response of multiple reservoir output nodes that result in qualitatively similar but quantitatively different responses to the same input (refer to Supplementary Figure S26), and ii) by using the virtual node method for delayed feedback systems 6 . Autonomous time-series prediction using the NW network-based system was obtained by considering the output of 98 reservoir outputs and 20 virtual nodes, by setting the parameters 𝛽 = 0.2, 𝛾 = 0.9, 𝑛 = 10 and 𝜏 = 18 that correspond to chaotic dynamics (chaotic behaviors can be observed for 𝜏 &gt; 16.8). Before autonomous prediction, since the chaotic time series strongly depends on the initial conditions, the network (initially in the pristine state) was excited during an initialization step by sending the true input without training. The performance accuracy of the Mackey-Glass time series prediction was evaluated as 1-RMSE, where RMSE represents the root mean square error.</p>
    </text>
</tei>
