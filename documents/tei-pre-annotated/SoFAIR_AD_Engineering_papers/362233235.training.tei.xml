<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-14T07:10+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>To support the large and various applications generated by the Internet of Things (IoT), Fog Computing was introduced to complement the Cloud Computing and offer Cloud-like services at the edge of the network with low latency and real-time responses. Large-scale, geographical distribution and heterogeneity of edge computational nodes make service placement in such infrastructure a challenging issue. Diversity of user expectations and IoT devices characteristics also complexify the deployment problem. This paper presents a survey of current research conducted on Service Placement Problem (SPP) in the Fog/Edge Computing. Based on a new classification scheme, a categorization of current proposals is given and identified issues and challenges are discussed.To support the large and various applications generated by the Internet of Things (IoT), Fog Computing was introduced to complement the Cloud Computing and offer Cloud-like services at the edge of the network with low latency and real-time responses. Large-scale, geographical distribution and heterogeneity of edge computational nodes make service placement in such infrastructure a challenging issue. Diversity of user expectations and IoT devices characteristics also complexify the deployment problem. This paper presents a survey of current research conducted on Service Placement Problem (SPP) in the Fog/Edge Computing. Based on a new classification scheme, a categorization of current proposals is given and identified issues and challenges are discussed.</p>
        <p>In recent years, the Internet of Things (IoT) becomes ingrained in our society by transforming objects of everyday life like wearable, transportation, augmented reality, etc., in communicating devices, and thus introduces new challenges and opportunities. With more than 50 billion devices connected to the network by 2020 according to Cisco [39], it is clear that the current infrastructures will not be able to support all the data that will be generated. Indeed, the current Cloud infrastructure alone can not support a large number of the current IoT applications and those essentially for three main reasons: First, the huge amount of generated data makes their transfer from where they are created (end-devices), to where they are processed (Cloud servers), impractical due to bandwidth limitations, processing overhead, and transmission costs. Second, the significant end-to-end delay from end-devices to the Cloud servers that are often too far from end-users can deter the performance of applications that require real-time analysis, such as online gaming, video applications, etc. Finally, some data may have implications in terms of privacy and security and it is advisable or even forbidden for this data to cross the entire Internet [159].In recent years, the Internet of Things (IoT) becomes ingrained in our society by transforming objects of everyday life like wearable, transportation, augmented reality, etc., in communicating devices, and thus introduces new challenges and opportunities. With more than 50 billion devices connected to the network by 2020 according to Cisco [39], it is clear that the current infrastructures will not be able to support all the data that will be generated. Indeed, the current Cloud infrastructure alone can not support a large number of the current IoT applications and those essentially for three main reasons: First, the huge amount of generated data makes their transfer from where they are created (end-devices), to where they are processed (Cloud servers), impractical due to bandwidth limitations, processing overhead, and transmission costs. Second, the significant end-to-end delay from end-devices to the Cloud servers that are often too far from end-users can deter the performance of applications that require real-time analysis, such as online gaming, video applications, etc. Finally, some data may have implications in terms of privacy and security and it is advisable or even forbidden for this data to cross the entire Internet [159].</p>
        <p>To cope with these issues, a promising paradigm able to avoids network bottlenecks, overcome communication overheads and reduce the delay of data transfer has been identified [24]. This new conceptual approach that combines the benefits of Cloud and the decentralized processing of services on edge devices is known as Fog or Edge Computing [24]. The community has not yet converged against crisp definitions of these terms [21,38,51,74]. In the following, we use the term Fog Computing for simplicity.To cope with these issues, a promising paradigm able to avoids network bottlenecks, overcome communication overheads and reduce the delay of data transfer has been identified [24]. This new conceptual approach that combines the benefits of Cloud and the decentralized processing of services on edge devices is known as Fog or Edge Computing [24]. The community has not yet converged against crisp definitions of these terms [21,38,51,74]. In the following, we use the term Fog Computing for simplicity.</p>
        <p>Fog Computing [41] extends Cloud Computing and services to the edge of the network, bringing processing, analysis, and storage closer to where requests are created and used. The objective is to reduce the amount of data sent to the Cloud, reduce latency and computation costs. As a new paradigm, Fog Computing poses old and new challenges, and one of the main open issues is service management and 1 more precisely the service placement problem. Indeed, one of the major barriers to the adoption of Fog is "how to efficiently deploy services on available Fog nodes". Unlike Cloud data centers, Fog devices are geographically distributed, resource-constrained, and highly dynamic, which makes the problem quite challenging. Therefore, the definition of an efficient, effective, and fair provisioning for the IoT applications will be important to provide and hence ensure end-to-end guaranteed services to end-users. Moreover, depending on the context and the interest, different aspects may come into focus: resource utilization [140], Quality of Service (QoS) [29,134,137], Quality of Experience (QoE) [96], etc. These last few years, several works have been carried out and attempt to address this issue. Different assumptions, characteristics, and strategies have been considered to propose an efficient service placement. In this paper, we review a wide range of works that studied this issue in Fog environments and explore the methodologies and the strategies proposed in the literature. We underline that the survey goes beyond just describing the main approaches developed in the literature. It first identifies five main scenarios, based on user expectations, problem descriptions, and deployment objectives. Second, it provides a new classification scheme where the different variants of SPP, and the various solutions coming from the research community are classified. The following aspects are considered: problem statement, placement characteristics, technical formulation, problem objectives, optimization strategies, and experimental tools.Fog Computing [41] extends Cloud Computing and services to the edge of the network, bringing processing, analysis, and storage closer to where requests are created and used. The objective is to reduce the amount of data sent to the Cloud, reduce latency and computation costs. As a new paradigm, Fog Computing poses old and new challenges, and one of the main open issues is service management and 1 more precisely the service placement problem. Indeed, one of the major barriers to the adoption of Fog is "how to efficiently deploy services on available Fog nodes". Unlike Cloud data centers, Fog devices are geographically distributed, resource-constrained, and highly dynamic, which makes the problem quite challenging. Therefore, the definition of an efficient, effective, and fair provisioning for the IoT applications will be important to provide and hence ensure end-to-end guaranteed services to end-users. Moreover, depending on the context and the interest, different aspects may come into focus: resource utilization [140], Quality of Service (QoS) [29,134,137], Quality of Experience (QoE) [96], etc. These last few years, several works have been carried out and attempt to address this issue. Different assumptions, characteristics, and strategies have been considered to propose an efficient service placement. In this paper, we review a wide range of works that studied this issue in Fog environments and explore the methodologies and the strategies proposed in the literature. We underline that the survey goes beyond just describing the main approaches developed in the literature. It first identifies five main scenarios, based on user expectations, problem descriptions, and deployment objectives. Second, it provides a new classification scheme where the different variants of SPP, and the various solutions coming from the research community are classified. The following aspects are considered: problem statement, placement characteristics, technical formulation, problem objectives, optimization strategies, and experimental tools.</p>
        <p>The paper is organized as follows. Section 2 summarizes existing surveys and tutorials on Fog Computing and resource management in the related area and highlights the contributions of our paper. Section 3 gives an overview of Fog systems: definition, architecture, main characteristics and advantages. Section 4 introduces the service placement problem and summarizes the most common formulations, optimization strategies, major design objectives, and evaluation tools proposed in the literature to address this issue. The provided classification for the SPP approaches is presented in Section 5. Section 6 outlines the open challenges and highlights emerging research directions. Finally, Section 7 concludes this survey.The paper is organized as follows. Section 2 summarizes existing surveys and tutorials on Fog Computing and resource management in the related area and highlights the contributions of our paper. Section 3 gives an overview of Fog systems: definition, architecture, main characteristics and advantages. Section 4 introduces the service placement problem and summarizes the most common formulations, optimization strategies, major design objectives, and evaluation tools proposed in the literature to address this issue. The provided classification for the SPP approaches is presented in Section 5. Section 6 outlines the open challenges and highlights emerging research directions. Finally, Section 7 concludes this survey.</p>
        <p>There are several surveys that address different aspects of Fog Computing and the related challenges [25,30,38,41,74,82,91,95,106,117,120,123,142,158,160]. Indeed different works have been proposed to discuss the concept and the role of Fog computing [25,38,40,117,138,146,155,158]. For instance, Bonomi et al. [25] investigate the role of Fog Computing in the IoTs domain, its characteristics, and its applications. Saharan and Vaquero et al. [146] give an overview of the concept in terms of enabling technologies and emerging trends. Chiang and Zhang [38] discuss, in the context of IoT, the need for a new architecture for computing, and storage. In [158], the authors give the definition of Fog Computing and closely related concepts and present three motivating applications: augmented reality, Content delivery, and Mobile Data Analytics. Many other papers discuss the Fog Computing characteristics, application domains, and related research challenges as [40,138,155], however they do not investigate and discuss the problem of service placement is such geo-distributed and large scale environments. Indeed, these studies do not provide insights into how IoT applications are deployed over the network (what are the applications requirements, infrastructures characteristics, domain constraints; mapping strategies; metrics to optimize, etc.).There are several surveys that address different aspects of Fog Computing and the related challenges [25,30,38,41,74,82,91,95,106,117,120,123,142,158,160]. Indeed different works have been proposed to discuss the concept and the role of Fog computing [25,38,40,117,138,146,155,158]. For instance, Bonomi et al. [25] investigate the role of Fog Computing in the IoTs domain, its characteristics, and its applications. Saharan and Vaquero et al. [146] give an overview of the concept in terms of enabling technologies and emerging trends. Chiang and Zhang [38] discuss, in the context of IoT, the need for a new architecture for computing, and storage. In [158], the authors give the definition of Fog Computing and closely related concepts and present three motivating applications: augmented reality, Content delivery, and Mobile Data Analytics. Many other papers discuss the Fog Computing characteristics, application domains, and related research challenges as [40,138,155], however they do not investigate and discuss the problem of service placement is such geo-distributed and large scale environments. Indeed, these studies do not provide insights into how IoT applications are deployed over the network (what are the applications requirements, infrastructures characteristics, domain constraints; mapping strategies; metrics to optimize, etc.).</p>
        <p>Recent surveys attempt to fill the resource management and service placement problems, among them we quote the work of Yousefpour et al. [160], that provides a tutorial on Fog Computing, compares the Fog to the related computing paradigms, and discusses the resource management and service deployment (orchestration and migration) in Fog environment. In [95], the authors present a taxonomy of Fog Computing, its related challenges, and features, and discuss briefly the problem of service management. Nath et al. [109] focus on the architectures and features of Fog Computing systems, applications of Fog, security and privacy of Fog, and discuss the future scopes and open research. In their survey, the authors briefly discuss challenges related to resource management, orchestration between fog nodes and the cloud, and give some comparison of different QoS aspects of Fog computing. In [105], Mouradian et al. present a detailed review on Fog architectures and algorithms and illustrate two application domains namely IoT and Content Delivery Networks (CDN). Li et al. [91,142] provide a survey on Edge Computing architecture and system management. They propose to characterize Edge Computing by considering the following aspects: architecture characteristics, management approaches, and design objectives. Brogi et al. [30] propose also to review the existing SPP proposals. They pursue three main objectives: elaborate an overview of the current algorithms, available prototypes, and experiments; classify the works based on the application and Fog infrastructure characteristics; And, identify and discuss some open challenges.Recent surveys attempt to fill the resource management and service placement problems, among them we quote the work of Yousefpour et al. [160], that provides a tutorial on Fog Computing, compares the Fog to the related computing paradigms, and discusses the resource management and service deployment (orchestration and migration) in Fog environment. In [95], the authors present a taxonomy of Fog Computing, its related challenges, and features, and discuss briefly the problem of service management. Nath et al. [109] focus on the architectures and features of Fog Computing systems, applications of Fog, security and privacy of Fog, and discuss the future scopes and open research. In their survey, the authors briefly discuss challenges related to resource management, orchestration between fog nodes and the cloud, and give some comparison of different QoS aspects of Fog computing. In [105], Mouradian et al. present a detailed review on Fog architectures and algorithms and illustrate two application domains namely IoT and Content Delivery Networks (CDN). Li et al. [91,142] provide a survey on Edge Computing architecture and system management. They propose to characterize Edge Computing by considering the following aspects: architecture characteristics, management approaches, and design objectives. Brogi et al. [30] propose also to review the existing SPP proposals. They pursue three main objectives: elaborate an overview of the current algorithms, available prototypes, and experiments; classify the works based on the application and Fog infrastructure characteristics; And, identify and discuss some open challenges.</p>
        <p>Although these surveys explore the resource management and service placement problem in Fog/Edge Computing, we note that these works are limited in at least one of the following: 1) limited review, and discussion on SPP in Fog/Edge Computing; 2) lack of comprehensive descriptions of the problem; stateof-the-art efforts regarding problem taxonomy, resolution approaches, evaluation environments; concrete research directions; 3) do not provide an in-depth comparison, classification or some useful insights regarding the existing works (e.g., how we can evaluate/compare the different proposals).Although these surveys explore the resource management and service placement problem in Fog/Edge Computing, we note that these works are limited in at least one of the following: 1) limited review, and discussion on SPP in Fog/Edge Computing; 2) lack of comprehensive descriptions of the problem; stateof-the-art efforts regarding problem taxonomy, resolution approaches, evaluation environments; concrete research directions; 3) do not provide an in-depth comparison, classification or some useful insights regarding the existing works (e.g., how we can evaluate/compare the different proposals).</p>
        <p>Our paper is different in the content and research issues. Mainly dedicated to achieving an exhaustive and very clear overview of SPP in the Fog environment, our survey aims at simplifying the user's access to references and identify a flavor of challenges. It is characterized by the following contributions.Our paper is different in the content and research issues. Mainly dedicated to achieving an exhaustive and very clear overview of SPP in the Fog environment, our survey aims at simplifying the user's access to references and identify a flavor of challenges. It is characterized by the following contributions.</p>
        <p>The main contributions of our paper can be summarized as follows:The main contributions of our paper can be summarized as follows:</p>
        <p>1. Provide an exhaustive and very clear description and overview of the SPP in the Fog environment.1. Provide an exhaustive and very clear description and overview of the SPP in the Fog environment.</p>
        <p>2. Provide a taxonomy of the problem in the area of large-scale, geo-distributed and heterogeneous systems.2. Provide a taxonomy of the problem in the area of large-scale, geo-distributed and heterogeneous systems.</p>
        <p>3. Propose a classification of surveyed works based on the identified scenarios, provided taxonomy and optimization strategies.3. Propose a classification of surveyed works based on the identified scenarios, provided taxonomy and optimization strategies.</p>
        <p>, highlight the open challenges and discusses future research directions., highlight the open challenges and discusses future research directions.</p>
        <p>In this section, we provide a brief overview of Fog Computing: definition, architecture, main characteristics and advantages.In this section, we provide a brief overview of Fog Computing: definition, architecture, main characteristics and advantages.</p>
        <p>Fog Computing (FC) is a highly virtualized platform, that offers computational resources, storage and control between end-users and Cloud servers. Introduced by Cisco in 2012 [25], FC is a new paradigm in which centralized Cloud coexists with distributed edge nodes and where the local and global analysis are performed at the edge devices or forwarded to the Cloud.Fog Computing (FC) is a highly virtualized platform, that offers computational resources, storage and control between end-users and Cloud servers. Introduced by Cisco in 2012 [25], FC is a new paradigm in which centralized Cloud coexists with distributed edge nodes and where the local and global analysis are performed at the edge devices or forwarded to the Cloud.</p>
        <p>Several architectures have been provided for FC. Mostly derived from the fundamental three-layers structure (as depicted in Fig. 1), a Fog infrastructure consists of IoT devices (End layer), one or more layers of Fog Nodes, and at least one Cloud Data Center (Cloud layer).Several architectures have been provided for FC. Mostly derived from the fundamental three-layers structure (as depicted in Fig. 1), a Fog infrastructure consists of IoT devices (End layer), one or more layers of Fog Nodes, and at least one Cloud Data Center (Cloud layer).</p>
        <p>• End layer: Bottom-most layer and closest to the end-users. It comprises various IoT devices (e.g., cameras, mobile phones, smart cars, smoke detectors, . . . ). Widely geographically distributed, these devices enable sensing events and forwarding them to their immediate upper layer in the hierarchy for analysis and storage.• End layer: Bottom-most layer and closest to the end-users. It comprises various IoT devices (e.g., cameras, mobile phones, smart cars, smoke detectors, . . . ). Widely geographically distributed, these devices enable sensing events and forwarding them to their immediate upper layer in the hierarchy for analysis and storage.</p>
        <p>• Fog layer: Middle layer, consists of a set of devices that are able to process, and store the received requests. Denoted by Fog Nodes (FNs), these devices that include access points, routers, gateways, switches, base stations, laptops, specific Fog servers, etc., are connected to the Cloud servers and are able to send requests to data centers. Distributed between the end-users and DCs, these resources can be fixed devices (static) at some location or mobile (like smartphones, vehicles, intelligent transportation systems, Drones . . . ).• Fog layer: Middle layer, consists of a set of devices that are able to process, and store the received requests. Denoted by Fog Nodes (FNs), these devices that include access points, routers, gateways, switches, base stations, laptops, specific Fog servers, etc., are connected to the Cloud servers and are able to send requests to data centers. Distributed between the end-users and DCs, these resources can be fixed devices (static) at some location or mobile (like smartphones, vehicles, intelligent transportation systems, Drones . . . ).</p>
        <p>Figure 1: Generic Fog computing architecture [152].Figure 1: Generic Fog computing architecture [152].</p>
        <p>Considered as the future of Cloud systems and the Internet of Things, the Fog Computing involves a number of characteristics and advantages where the main ones are mentioned below:Considered as the future of Cloud systems and the Internet of Things, the Fog Computing involves a number of characteristics and advantages where the main ones are mentioned below:</p>
        <p>1. Location awareness and low latency. Most latency-sensitive applications such as augmented reality, gaming, or video streaming, require sub-second processing time and do not necessarily need to be sent across long routes to data centers or Cloud services to be processed. With the Fog Computing, the support of these aspects is provided through the geo-distribution of the various Fog nodes in different locations and their proximity to end-users. Sarkar and Misra [124] proved by theoretical modeling that the service latency in FC is significantly lower than that with Cloud Computing.1. Location awareness and low latency. Most latency-sensitive applications such as augmented reality, gaming, or video streaming, require sub-second processing time and do not necessarily need to be sent across long routes to data centers or Cloud services to be processed. With the Fog Computing, the support of these aspects is provided through the geo-distribution of the various Fog nodes in different locations and their proximity to end-users. Sarkar and Misra [124] proved by theoretical modeling that the service latency in FC is significantly lower than that with Cloud Computing.</p>
        <p>2. Save bandwidth. FC helps to unclog the network and speed up the processing of certain tasks by performing locally some computation tasks and sending only part of useful data or those that require significant analysis to the Cloud.2. Save bandwidth. FC helps to unclog the network and speed up the processing of certain tasks by performing locally some computation tasks and sending only part of useful data or those that require significant analysis to the Cloud.</p>
        <p>Scalability. The number of connected devices grows rapidly, and the IoT data and application generated by these trillions of things [92] increases also exponentially. Given this large amount of data, processing the whole IoT applications in the Cloud is neither efficient nor feasible, so Fog intervenes as a complementary paradigm able to support all these requests and help the scalability of such systems.Scalability. The number of connected devices grows rapidly, and the IoT data and application generated by these trillions of things [92] increases also exponentially. Given this large amount of data, processing the whole IoT applications in the Cloud is neither efficient nor feasible, so Fog intervenes as a complementary paradigm able to support all these requests and help the scalability of such systems.</p>
        <p>4. Support for mobility. Having a widely distributed fog devices that providing computational and storage capabilities over the network, the Fog Computing is more suited to support the mobility of end-users than the traditional centralized Cloud servers and thus will allow to provide service guarantees for the mobile end-users without interruptions. The service placement problem has been highly discussed in the literature and several proposals have emerged. Based on different application descriptions, network assumptions, and expected outcomes, these solutions are generally difficult to compare with each other. In this section, we propose to describe the methodology usually employed to address the SPP and give an overview of the following aspects: problem statement, placement taxonomy, optimization strategies, and evaluation tools (as depicted in Figure 2). These elements will allow us to clearly describe the problem, and define the different aspects on which we will base our comparison and classification of the surveyed works.4. Support for mobility. Having a widely distributed fog devices that providing computational and storage capabilities over the network, the Fog Computing is more suited to support the mobility of end-users than the traditional centralized Cloud servers and thus will allow to provide service guarantees for the mobile end-users without interruptions. The service placement problem has been highly discussed in the literature and several proposals have emerged. Based on different application descriptions, network assumptions, and expected outcomes, these solutions are generally difficult to compare with each other. In this section, we propose to describe the methodology usually employed to address the SPP and give an overview of the following aspects: problem statement, placement taxonomy, optimization strategies, and evaluation tools (as depicted in Figure 2). These elements will allow us to clearly describe the problem, and define the different aspects on which we will base our comparison and classification of the surveyed works.</p>
        <p>The statement of the SPP problem goes through the description of the following three parts: the infrastructure model, the application model, and the deployment pattern with its related constraints.The statement of the SPP problem goes through the description of the following three parts: the infrastructure model, the application model, and the deployment pattern with its related constraints.</p>
        <p>The physical Fog infrastructure (see Fig. 1) consists respectively of a set of devices with no computational capabilities (sensors, and actuators), and a set of resources that possess computational power and/or storage capacity (Fog nodes, and Cloud data centers). Due to their physical structure [97], the fog nodes are resource-constrained and heterogeneous to each other. And, any devices equipped with computational resources (in terms of CPU, memory, storage, bandwidth, . . . .) can be considered as potential FNs, such as routers, small servers, access points, laptops, or gateway, etc. The infrastructure network is generally abstracted as a connected graph where the vertices denote the set of IoT devices, Fog nodes, and Cloud servers, and the edges denote the links between the nodes. We mention hereafter the most common resources type and characteristics depicted in the literature to describe the Fog infrastructure.The physical Fog infrastructure (see Fig. 1) consists respectively of a set of devices with no computational capabilities (sensors, and actuators), and a set of resources that possess computational power and/or storage capacity (Fog nodes, and Cloud data centers). Due to their physical structure [97], the fog nodes are resource-constrained and heterogeneous to each other. And, any devices equipped with computational resources (in terms of CPU, memory, storage, bandwidth, . . . .) can be considered as potential FNs, such as routers, small servers, access points, laptops, or gateway, etc. The infrastructure network is generally abstracted as a connected graph where the vertices denote the set of IoT devices, Fog nodes, and Cloud servers, and the edges denote the links between the nodes. We mention hereafter the most common resources type and characteristics depicted in the literature to describe the Fog infrastructure.</p>
        <p>• Resources type. Computing: servers, PCs, cloudlets [8,125], etc. Networking: gateways, routers, switches, base stations, etc. Storage: every node that can provide storage. Mobile: vehicles, smartphones, etc. Endpoint abstraction: sensors, actuators (e.g., GPS devices, wireless sensors, cameras, voice collector, radar, . . . ).• Resources type. Computing: servers, PCs, cloudlets [8,125], etc. Networking: gateways, routers, switches, base stations, etc. Storage: every node that can provide storage. Mobile: vehicles, smartphones, etc. Endpoint abstraction: sensors, actuators (e.g., GPS devices, wireless sensors, cameras, voice collector, radar, . . . ).</p>
        <p>• Characteristics. Computing: CPU power, number of cores, RAM, battery life, etc. Networking: Type: wireless, wired; Capabilities: latency, bandwidth, error rate, etc. Storage: Disk, etc. Virtualization: VMs, containers, unikernel, etc. Hardware: GPU, NUMA, FPGA, etc.• Characteristics. Computing: CPU power, number of cores, RAM, battery life, etc. Networking: Type: wireless, wired; Capabilities: latency, bandwidth, error rate, etc. Storage: Disk, etc. Virtualization: VMs, containers, unikernel, etc. Hardware: GPU, NUMA, FPGA, etc.</p>
        <p>Several abstractions and model definitions are used in the literature to characterize the applications generated by the IoT devices and treated at Fog resources and Cloud servers. According to the surveyed papers, we identify the following main descriptions: a) a monolithic service, b) a set of inter-dependent components, and c) a connected graph.Several abstractions and model definitions are used in the literature to characterize the applications generated by the IoT devices and treated at Fog resources and Cloud servers. According to the surveyed papers, we identify the following main descriptions: a) a monolithic service, b) a set of inter-dependent components, and c) a connected graph.</p>
        <p>a) Monolithic service The application sent by end-users or IoT devices is represented in the form of a single component (monolithic service). As an example, we can mention the case of an image processing application or data instance that needs to be proceeded or stored in a single physical node. The application can be defined in this case as a monolithic service.a) Monolithic service The application sent by end-users or IoT devices is represented in the form of a single component (monolithic service). As an example, we can mention the case of an image processing application or data instance that needs to be proceeded or stored in a single physical node. The application can be defined in this case as a monolithic service.</p>
        <p>b) Set of inter-dependent services This case assumes that the application is pre-partitioned into a set of components (services), each performs some specific operation (functionality) in the application.b) Set of inter-dependent services This case assumes that the application is pre-partitioned into a set of components (services), each performs some specific operation (functionality) in the application.</p>
        <p>In that case, dependencies between the application components are not considered.In that case, dependencies between the application components are not considered.</p>
        <p>c) A connected graph The application, in this case, is composed of a set of inter-dependent components represented as a connected graph. The vertices represent the processing/computational components of the application, and edges represent the inter-dependencies and communication demand between nodes [64].c) A connected graph The application, in this case, is composed of a set of inter-dependent components represented as a connected graph. The vertices represent the processing/computational components of the application, and edges represent the inter-dependencies and communication demand between nodes [64].</p>
        <p>Different topologies of a graph can be identified and among them, we have respectively: line graph, tree application graph, and Directed Acyclic Graph (DAG). The DAG application topology is the most often used because it models a large range of realistic IoT applications like Video processing [14,22,127], gaming [165], or healthcare [59] applications. Figure 3.a) illustrates an example of DAG application (cognitive assistance application).Different topologies of a graph can be identified and among them, we have respectively: line graph, tree application graph, and Directed Acyclic Graph (DAG). The DAG application topology is the most often used because it models a large range of realistic IoT applications like Video processing [14,22,127], gaming [165], or healthcare [59] applications. Figure 3.a) illustrates an example of DAG application (cognitive assistance application).</p>
        <p>Regarding the application requirements, we can summarize some of them in the following: Computing: CPU power, number of cores, RAM, etc. Network-oriented: Bandwidth, Latency, Error-rate, Jitter (per link, end-to-end). Task-oriented: Deadline. Location-oriented: the application must run in a specific geographical location (for instance in Paris); the application can run only at some Fog node, etc.Regarding the application requirements, we can summarize some of them in the following: Computing: CPU power, number of cores, RAM, etc. Network-oriented: Bandwidth, Latency, Error-rate, Jitter (per link, end-to-end). Task-oriented: Deadline. Location-oriented: the application must run in a specific geographical location (for instance in Paris); the application can run only at some Fog node, etc.</p>
        <p>The application placement problem defines a mapping pattern by which applications components and links are mapped onto an infrastructure graph (i.e., computing devices, and physical edges). Figure 3 shows a mapping example of an application modeled as a DAG (Fig. 3.a) to available Fog nodes (Fig.The application placement problem defines a mapping pattern by which applications components and links are mapped onto an infrastructure graph (i.e., computing devices, and physical edges). Figure 3 shows a mapping example of an application modeled as a DAG (Fig. 3.a) to available Fog nodes (Fig.</p>
        <p>Typically, application placement involves finding the available resources in the network (nodes and links) that satisfy the application(s) requirements, satisfy the constraints, and optimize the objective (if any). For instance, respect the applications (services) requirements, not exceed the resource capacities, satisfy the locality constraints, minimize the energy consumed, etc. Service providers have to take into account these constraints to first, limit the research space and second, provide an optimum or near optimum placement. We propose hereafter to depict some of the constraints mostly considered in the literature.Typically, application placement involves finding the available resources in the network (nodes and links) that satisfy the application(s) requirements, satisfy the constraints, and optimize the objective (if any). For instance, respect the applications (services) requirements, not exceed the resource capacities, satisfy the locality constraints, minimize the energy consumed, etc. Service providers have to take into account these constraints to first, limit the research space and second, provide an optimum or near optimum placement. We propose hereafter to depict some of the constraints mostly considered in the literature.</p>
        <p>Resource constraints (CR). An infrastructure node is limited by finite capabilities in term of CPU, RAM, storage, bandwidth, etc. Therefore, when placing application(s) (service components), we need to respect the resource requirements, i.e., ensures that the resources of the components deployed on the infrastructure nodes do not exceed their capabilities.Resource constraints (CR). An infrastructure node is limited by finite capabilities in term of CPU, RAM, storage, bandwidth, etc. Therefore, when placing application(s) (service components), we need to respect the resource requirements, i.e., ensures that the resources of the components deployed on the infrastructure nodes do not exceed their capabilities.</p>
        <p>Network constraints (CN ). A network link can also be bounded by constraints like latency, bandwidth, etc., and these constraints need to be satisfied when deploying applications.Network constraints (CN ). A network link can also be bounded by constraints like latency, bandwidth, etc., and these constraints need to be satisfied when deploying applications.</p>
        <p>Application constraints: We highlight here two kind of application constraints:Application constraints: We highlight here two kind of application constraints:</p>
        <p>-Locality requirement (CL). Locality requirement typically restricts certain services' executions to specific locations. Due to specific hardware, privacy requirements or given policy, some components can be restricted to be deployed on specific areas (zone) or devices. Locality constraints can be based on: a set of Fog nodes [154,164]; a specific geo-spatial location using GPS for instance [124], impose a co-localization of components [3], etc.-Locality requirement (CL). Locality requirement typically restricts certain services' executions to specific locations. Due to specific hardware, privacy requirements or given policy, some components can be restricted to be deployed on specific areas (zone) or devices. Locality constraints can be based on: a set of Fog nodes [154,164]; a specific geo-spatial location using GPS for instance [124], impose a co-localization of components [3], etc.</p>
        <p>-Delay sensitivity (CD). Some applications can specify a deadline for processing operation, or deploying the whole application in the network. This constraint is generally specified by defining a threshold to not exceed.-Delay sensitivity (CD). Some applications can specify a deadline for processing operation, or deploying the whole application in the network. This constraint is generally specified by defining a threshold to not exceed.</p>
        <p>Addressing the SPP involves considering some specificities and criteria when designing the deployment strategies. Denoted as a service placement taxonomy, we propose in this paper to pay attention to the following four main aspects as depicted in Figure 4. As such, the first specificity considers whether the mapping coordination is done in a centralized or distributed manner. The second is based on whether the problem is tackled as an offline or online deployment. The third proposes to observe whether the dynamicity of the system is handled or not (i.e., handle the changes in the system, or not). Finally, the fourth characteristic describes whether the mobility of end-users and/or Fog devices is supported by the provided solution or not.Addressing the SPP involves considering some specificities and criteria when designing the deployment strategies. Denoted as a service placement taxonomy, we propose in this paper to pay attention to the following four main aspects as depicted in Figure 4. As such, the first specificity considers whether the mapping coordination is done in a centralized or distributed manner. The second is based on whether the problem is tackled as an offline or online deployment. The third proposes to observe whether the dynamicity of the system is handled or not (i.e., handle the changes in the system, or not). Finally, the fourth characteristic describes whether the mobility of end-users and/or Fog devices is supported by the provided solution or not.</p>
        <p>These eight characteristics described hereafter are used in Section 5.1 to classify the SPP proposals coming from the literature.These eight characteristics described hereafter are used in Section 5.1 to classify the SPP proposals coming from the literature.</p>
        <p>The development of a placement strategy and service management starts first by selecting the coordination strategy to adopt. Two common control plane models are presented in this paper: centralized and Distributed coordination. Relevant for multi-layered and geo-distributed systems, these approaches are relatively different and each has its own advantages and inconveniences as presented in the following. a) Centralized. A centralized control plane requires global information about application demands and infrastructure resources to take and disseminate global deployment decisions. The advantage of centralized placement algorithms is to potentially find a globally optimal solution, however, they are vulnerable regarding the scalability and the computational complexity issue.The development of a placement strategy and service management starts first by selecting the coordination strategy to adopt. Two common control plane models are presented in this paper: centralized and Distributed coordination. Relevant for multi-layered and geo-distributed systems, these approaches are relatively different and each has its own advantages and inconveniences as presented in the following. a) Centralized. A centralized control plane requires global information about application demands and infrastructure resources to take and disseminate global deployment decisions. The advantage of centralized placement algorithms is to potentially find a globally optimal solution, however, they are vulnerable regarding the scalability and the computational complexity issue.</p>
        <p>When surveying papers, we observed that a large number of works considers a centralized control plane when addressing the SPP. Among these works, we mention the work of Hong et al. [71] that considers a central coordinator to make deployment decisions of IoT applications over Fog infrastructure.When surveying papers, we observed that a large number of works considers a centralized control plane when addressing the SPP. Among these works, we mention the work of Hong et al. [71] that considers a central coordinator to make deployment decisions of IoT applications over Fog infrastructure.</p>
        <p>Unlike centralized solution, a distributed approach considers multiple authority and orchestrator nodes to control the services mapping. Generally distributed in the network (as illustrated in Fig. 5), the management elements compute placement decisions based on local resources and information. This control plane is more flexible and can be more efficient to handle the dynamic changes of infrastructure like a Fog Computing without resorting to network-wide computations. The distributed approach helps to address the scalability and the locality awareness issues and allows providing services that best fit with the local context, however, no guarantees are provided regarding the global optimality of the computed solutions.Unlike centralized solution, a distributed approach considers multiple authority and orchestrator nodes to control the services mapping. Generally distributed in the network (as illustrated in Fig. 5), the management elements compute placement decisions based on local resources and information. This control plane is more flexible and can be more efficient to handle the dynamic changes of infrastructure like a Fog Computing without resorting to network-wide computations. The distributed approach helps to address the scalability and the locality awareness issues and allows providing services that best fit with the local context, however, no guarantees are provided regarding the global optimality of the computed solutions.</p>
        <p>Among the works that considered a distributed control plane, we quote the work of Wang et al. [150] that considers a fog-based architecture composed of fog nodes and fog nodes coordination. The FNs sub-layer deals with the tasks that need real-time processing. The complex tasks that require more computational capabilities are transmitted to the FNs coordination sub-layer or forwarded to the Cloud.Among the works that considered a distributed control plane, we quote the work of Wang et al. [150] that considers a fog-based architecture composed of fog nodes and fog nodes coordination. The FNs sub-layer deals with the tasks that need real-time processing. The complex tasks that require more computational capabilities are transmitted to the FNs coordination sub-layer or forwarded to the Cloud.</p>
        <p>The service placement problem can be tackled in an offline or online manner. More precisely, we say that the placement is offline if it takes a deployment decision at the compile-time, where all required information are available. It needs complete information about the system activities and provides solutions that satisfy the given requirements. For online placement, the deployment decisions are made during the run-time of the system. The decisions are based on both process characteristics and the current state of the system. In most real use-cases, the SPP has to be addressed as an online problem. That is, the related algorithms have to consider the services as they arrive, rather than computing the placement in advance before their execution. We notice that an online placement can accommodate dynamic behavior (changes) of the system but it cannot make the best use of system resources (provide optimal placement decision).The service placement problem can be tackled in an offline or online manner. More precisely, we say that the placement is offline if it takes a deployment decision at the compile-time, where all required information are available. It needs complete information about the system activities and provides solutions that satisfy the given requirements. For online placement, the deployment decisions are made during the run-time of the system. The decisions are based on both process characteristics and the current state of the system. In most real use-cases, the SPP has to be addressed as an online problem. That is, the related algorithms have to consider the services as they arrive, rather than computing the placement in advance before their execution. We notice that an online placement can accommodate dynamic behavior (changes) of the system but it cannot make the best use of system resources (provide optimal placement decision).</p>
        <p>As an example of offline placement algorithms provided in the literature, we mention [113,137] that assumes full information knowledge for the Fog network. For the online placement, we have for instance the work of Lee et al. [87] that proposes an online placement strategy that minimizes the computational latency for Fog system under uncertainty of available FNs. The provided online optimization framework proposes to sequentially observe the information on the network.As an example of offline placement algorithms provided in the literature, we mention [113,137] that assumes full information knowledge for the Fog network. For the online placement, we have for instance the work of Lee et al. [87] that proposes an online placement strategy that minimizes the computational latency for Fog system under uncertainty of available FNs. The provided online optimization framework proposes to sequentially observe the information on the network.</p>
        <p>This criterion tackles the fact that proposals handle or not the dynamicity of the system. We can identify respectively two aspects: the dynamicity of Fog infrastructure and the dynamicity of applications. The Fog network is highly dynamic where entities join and leave network due to instability of network links or failures. Resources capabilities can also vary over time. From an application point of view, the application graph structure can evolve over time in response to changes in real-life conditions. New sources or devices may appear or existing ones may disappear (adding new cameras, breakdown of certain components, user's can decide at any time to start or stop sending their data for a service, etc.). In addition, changes in the application information can also be observed (e.g., on the amount of data, component requirements, etc.).This criterion tackles the fact that proposals handle or not the dynamicity of the system. We can identify respectively two aspects: the dynamicity of Fog infrastructure and the dynamicity of applications. The Fog network is highly dynamic where entities join and leave network due to instability of network links or failures. Resources capabilities can also vary over time. From an application point of view, the application graph structure can evolve over time in response to changes in real-life conditions. New sources or devices may appear or existing ones may disappear (adding new cameras, breakdown of certain components, user's can decide at any time to start or stop sending their data for a service, etc.). In addition, changes in the application information can also be observed (e.g., on the amount of data, component requirements, etc.).</p>
        <p>To deal with the dynamic nature of Fog infrastructure and/or applications, it is required to define reactive strategies able to determine when adaptation is required, provide a transparent mechanism, and deliver the satisfying QoS. Thus, an approach is said to be dynamic if the provided placement strategy is able to deploy new services, replace or release services already deployed, in order to meet the QoS constraints and optimize a given objective (if any).To deal with the dynamic nature of Fog infrastructure and/or applications, it is required to define reactive strategies able to determine when adaptation is required, provide a transparent mechanism, and deliver the satisfying QoS. Thus, an approach is said to be dynamic if the provided placement strategy is able to deploy new services, replace or release services already deployed, in order to meet the QoS constraints and optimize a given objective (if any).</p>
        <p>By surveying the literature, we identified a number of works that propose to manage the dynamic nature of Fog environment, among them we mention the work of Yousefpour et al. [163] that proposes a dynamic provisioning of services in Fog infrastructure that satisfies the QoS requirements and the Service Level Agreements (SLA), and minimizes the resources cost. To handle the dynamicity of IoT applications, Mahmud et al. [97] propose a policy that dynamically determines host nodes for the deployed components and handle sudden changes in frequencies of the received services.By surveying the literature, we identified a number of works that propose to manage the dynamic nature of Fog environment, among them we mention the work of Yousefpour et al. [163] that proposes a dynamic provisioning of services in Fog infrastructure that satisfies the QoS requirements and the Service Level Agreements (SLA), and minimizes the resources cost. To handle the dynamicity of IoT applications, Mahmud et al. [97] propose a policy that dynamically determines host nodes for the deployed components and handle sudden changes in frequencies of the received services.</p>
        <p>Manage mobility is a major challenge in Fog Computing. Provide a solution that supports the mobility of end-users and/or fog devices and ensures that the users always receive the associated services and desired performance without interruptions is a complex issue in Fog Computing. Frequent changes in locations for end nodes (or fog nodes, e.g., smartphone, smart car) can lead to excessive delays or to packet loss. In such a situation, the system manager (coordinator) should be able to move the service transparently from the previous devices to the new ones so as to ensure its continuity.Manage mobility is a major challenge in Fog Computing. Provide a solution that supports the mobility of end-users and/or fog devices and ensures that the users always receive the associated services and desired performance without interruptions is a complex issue in Fog Computing. Frequent changes in locations for end nodes (or fog nodes, e.g., smartphone, smart car) can lead to excessive delays or to packet loss. In such a situation, the system manager (coordinator) should be able to move the service transparently from the previous devices to the new ones so as to ensure its continuity.</p>
        <p>In [17,73,114,122,126,145,147,149,150], for instance, the authors attempt to address the problem of end-user mobility by providing dynamic placement approaches. In [126], Saurez et al. propose to handle the mobility of end-users by providing strategy based on the following decisions: "When-to-Migrate" based on the latency parameter; and "Where-to-Migrate" based on the proximity of a FN to the mobile devices and the current processing node.In [17,73,114,122,126,145,147,149,150], for instance, the authors attempt to address the problem of end-user mobility by providing dynamic placement approaches. In [126], Saurez et al. propose to handle the mobility of end-users by providing strategy based on the following decisions: "When-to-Migrate" based on the latency parameter; and "Where-to-Migrate" based on the proximity of a FN to the mobile devices and the current processing node.</p>
        <p>Optimizing the service placement problem in a Fog infrastructure has been tackled from several different objectives, with different formulations and diverse algorithm proposals. This section discusses the possible objectives that may pursue in such systems, the metrics considered to evaluate the provided deployment, the problem formulation used by existing proposals, the resolution strategies, and algorithms used to solve the SPP.Optimizing the service placement problem in a Fog infrastructure has been tackled from several different objectives, with different formulations and diverse algorithm proposals. This section discusses the possible objectives that may pursue in such systems, the metrics considered to evaluate the provided deployment, the problem formulation used by existing proposals, the resolution strategies, and algorithms used to solve the SPP.</p>
        <p>We propose to present first a global classification of optimization strategies proposed in the literature. On one hand, we distinguish the following two categories: mono-objective and multi-objective optimization. On the other hand, we present the metrics most often considered during optimization. a) Mono vs. Multi-objective optimization Mono-objective optimization proposes to optimize only one objective function. While multi-objective proposes to optimize simultaneously a collection of objective functions [99]. A first classification of SPP solutions regarding these two optimizations is given in Table 1. Works that have studied both aspects (mono-objective and multi-objective) are marked with an asterisk (*).We propose to present first a global classification of optimization strategies proposed in the literature. On one hand, we distinguish the following two categories: mono-objective and multi-objective optimization. On the other hand, we present the metrics most often considered during optimization. a) Mono vs. Multi-objective optimization Mono-objective optimization proposes to optimize only one objective function. While multi-objective proposes to optimize simultaneously a collection of objective functions [99]. A first classification of SPP solutions regarding these two optimizations is given in Table 1. Works that have studied both aspects (mono-objective and multi-objective) are marked with an asterisk (*).</p>
        <p>Mono-objective [10,12,14,16,17,19,20,43,44] • Latency Low latency for delay-sensitive applications. Achieving lower latency has attracted attention in several surveyed papers. Indeed, several works aim at minimizing services latency deployed on available resources while satisfying the set of requirements and constraints. For instance, in [161,162], the authors propose to minimize the service delay of deploying IoT applications on the IoT-Fog-Cloud framework.Mono-objective [10,12,14,16,17,19,20,43,44] • Latency Low latency for delay-sensitive applications. Achieving lower latency has attracted attention in several surveyed papers. Indeed, several works aim at minimizing services latency deployed on available resources while satisfying the set of requirements and constraints. For instance, in [161,162], the authors propose to minimize the service delay of deploying IoT applications on the IoT-Fog-Cloud framework.</p>
        <p>• Resource utilization An important issue in Fog Computing is how to optimize resource utilization while deploying the maximum number of service over appropriate fog nodes. Among the works found in the literature that investigate this goal, we can cite the work of Hong et al. [71] that provides deployment decisions while maximizing the number of satisfied IoT analytics requests. Skarlat et al. in [133] propose also to maximize the number of satisfied application requests by prioritizing the applications with the closest deadline.• Resource utilization An important issue in Fog Computing is how to optimize resource utilization while deploying the maximum number of service over appropriate fog nodes. Among the works found in the literature that investigate this goal, we can cite the work of Hong et al. [71] that provides deployment decisions while maximizing the number of satisfied IoT analytics requests. Skarlat et al. in [133] propose also to maximize the number of satisfied application requests by prioritizing the applications with the closest deadline.</p>
        <p>• Cost Cost-related factors become very influential in Fog service management, from the service provider's point of view or from the users' point of view. We can identify two main types of costs: the networking cost for the data transmission charges and associated expenses; execution cost related to the computational expenses of Fog nodes. Other expenses can also be identified: costs related to storage, deployment, security safeguards, migration, and so on.• Cost Cost-related factors become very influential in Fog service management, from the service provider's point of view or from the users' point of view. We can identify two main types of costs: the networking cost for the data transmission charges and associated expenses; execution cost related to the computational expenses of Fog nodes. Other expenses can also be identified: costs related to storage, deployment, security safeguards, migration, and so on.</p>
        <p>In [163], the authors propose to minimize a total cost that includes the cost of processing and storage in Cloud and Fog, the cost of communication between Fog and Cloud and between Fog nodes, and the communication cost of service deployment from the Fog service controller to FNs.In [163], the authors propose to minimize a total cost that includes the cost of processing and storage in Cloud and Fog, the cost of communication between Fog and Cloud and between Fog nodes, and the communication cost of service deployment from the Fog service controller to FNs.</p>
        <p>• Energy consumption Energy efficiency is one of the main concerns in IoT systems and a significant performance metric that several works attempt to investigate within the Fog context. The energy consumption encompasses mostly two things. The type of service to process, and the energy consumption at the service level that includes three main aspects: when the service is sent by the end-user to the fog device; when the service is processed by the FN; and when the Fog needs the Cloud. For instance, Sarkar et al. [123,124], and Nishio et al. [113] investigate the energy consumption issue in the Fog environment by considering energy consumption in both the network and the device side.• Energy consumption Energy efficiency is one of the main concerns in IoT systems and a significant performance metric that several works attempt to investigate within the Fog context. The energy consumption encompasses mostly two things. The type of service to process, and the energy consumption at the service level that includes three main aspects: when the service is sent by the end-user to the fog device; when the service is processed by the FN; and when the Fog needs the Cloud. For instance, Sarkar et al. [123,124], and Nishio et al. [113] investigate the energy consumption issue in the Fog environment by considering energy consumption in both the network and the device side.</p>
        <p>• Other metrics Other metrics can be considered when addressing the service placement problem. Some of these metrics are quality of experience, congestion ratio, blocking probability, failed requests, etc. Accepted as the user-centric measurement, QoE encapsulates the user's requirements, perceptions, and intentions when deploying services [84]. As an example study, we mention the work done by Mahmud et al. [96] that provides a QoE-aware application placement strategy by which the deployment prioritizes the user expectations. Regarding the congestion ratio, Yu et al. [164] propose to consider the minimum ratio between the flow and the capacity of link to address the service placement and data routing of real-time processing applications in IoT.• Other metrics Other metrics can be considered when addressing the service placement problem. Some of these metrics are quality of experience, congestion ratio, blocking probability, failed requests, etc. Accepted as the user-centric measurement, QoE encapsulates the user's requirements, perceptions, and intentions when deploying services [84]. As an example study, we mention the work done by Mahmud et al. [96] that provides a QoE-aware application placement strategy by which the deployment prioritizes the user expectations. Regarding the congestion ratio, Yu et al. [164] propose to consider the minimum ratio between the flow and the capacity of link to address the service placement and data routing of real-time processing applications in IoT.</p>
        <p>The SPP is generally formalized using one of these two main categories: Integer programming or Constrained optimization. Table 3 groups the surveyed works according to the identified problem formulation briefly described below. that some decision variables are not discrete. In [16], to study the latency-critical services management in an Edge-Cloud, the authors formulate the problem as a MILP that minimizes the number of failed requests. Mixed Integer NonLinear Programming (MINLP) considers continuous and discrete variables and nonlinear objective function and/or constraints. Due to the high computational complexity for solving this class of problems, most of the work proposes to linearize it into a MILP. As an example, to investigate the cost-efficient service deployment problem in the Fog architecture, Arkian et al. [14] first formulate the cost minimization problem as an MINLP, and then linearize it into MILP to solve it more easily.The SPP is generally formalized using one of these two main categories: Integer programming or Constrained optimization. Table 3 groups the surveyed works according to the identified problem formulation briefly described below. that some decision variables are not discrete. In [16], to study the latency-critical services management in an Edge-Cloud, the authors formulate the problem as a MILP that minimizes the number of failed requests. Mixed Integer NonLinear Programming (MINLP) considers continuous and discrete variables and nonlinear objective function and/or constraints. Due to the high computational complexity for solving this class of problems, most of the work proposes to linearize it into a MILP. As an example, to investigate the cost-efficient service deployment problem in the Fog architecture, Arkian et al. [14] first formulate the cost minimization problem as an MINLP, and then linearize it into MILP to solve it more easily.</p>
        <p>• Mixed Integer Quadratic Programming (MIQP) This problem refers to optimization problems with quadratic objective function in the integer and in the continuous variables, and linear constraints in the variables of both types. As an example, in [164], the authors formulate the problem of real-time processing applications provisioning in IoT as a MIQP. To overcome the high complexity of solving such a problem, the authors propose to relax some of the constraints and present an approximation scheme.• Mixed Integer Quadratic Programming (MIQP) This problem refers to optimization problems with quadratic objective function in the integer and in the continuous variables, and linear constraints in the variables of both types. As an example, in [164], the authors formulate the problem of real-time processing applications provisioning in IoT as a MIQP. To overcome the high complexity of solving such a problem, the authors propose to relax some of the constraints and present an approximation scheme.</p>
        <p>b) Constrained optimization Constrained optimization is a set of methods designed to find out the best possible values of certain variables (i.e., optimizing process) in the presence of some restrictions (constraints). It uses a set of constraints that can easily be extended further to involve more aspects. For instance, in [9], Ait-Salaht et al. propose to handle the SPP problem by provided a generic and easy-to-upgrade constraint programming model. Brogi et al. [29,31] propose a constrained model to determine the feasible deployments (if any) of an application in the Fog infrastructure.b) Constrained optimization Constrained optimization is a set of methods designed to find out the best possible values of certain variables (i.e., optimizing process) in the presence of some restrictions (constraints). It uses a set of constraints that can easily be extended further to involve more aspects. For instance, in [9], Ait-Salaht et al. propose to handle the SPP problem by provided a generic and easy-to-upgrade constraint programming model. Brogi et al. [29,31] propose a constrained model to determine the feasible deployments (if any) of an application in the Fog infrastructure.</p>
        <p>As other formulations found in the literature we quote: Matching Game [63], Markov Decision Process (MDP) [121], stochastic optimization [111], petri nets [4], potential games [104], quadratic assignment problem [32], general convex optimization [27].As other formulations found in the literature we quote: Matching Game [63], Markov Decision Process (MDP) [121], stochastic optimization [111], petri nets [4], potential games [104], quadratic assignment problem [32], general convex optimization [27].</p>
        <p>For instance, in [50], a matching game is employed to formulate the task placement problem in Mobile Edge Computing systems while minimizing the computation latency. In [145], Urgaonkar et al. model the migration problem as an MDP (also known as reinforcement learning). In [112], the authors use priced timed Petri nets (PTPNs) to study the service placement in Fog Computing while optimizing price and time costs for completing a task.For instance, in [50], a matching game is employed to formulate the task placement problem in Mobile Edge Computing systems while minimizing the computation latency. In [145], Urgaonkar et al. model the migration problem as an MDP (also known as reinforcement learning). In [112], the authors use priced timed Petri nets (PTPNs) to study the service placement in Fog Computing while optimizing price and time costs for completing a task.</p>
        <p>Compute optimal application scheduling in Fog infrastructure is an NP-hard problem [23,49,83]. Indeed, several issues complicate the compute of effective services placement in such a context. First, the heterogeneous nature and the limited capacities of most Fog nodes (resource-constrained). Second, the dynamicity of the environment, resources may appear and disappear, others are moving, infrastructure and application information may change over time (e.g., the variation of the workload). Third, the geographical distribution of fog devices over a large-scale infrastructure. Several specificities and constraints that make the SPP problem in Fog environment a challenging task. In the literature, we identify four main approaches used to solve such a problem: exact resolution, approximation strategies, heuristic or meta-heuristic policies. We briefly describe these procedures in the following.Compute optimal application scheduling in Fog infrastructure is an NP-hard problem [23,49,83]. Indeed, several issues complicate the compute of effective services placement in such a context. First, the heterogeneous nature and the limited capacities of most Fog nodes (resource-constrained). Second, the dynamicity of the environment, resources may appear and disappear, others are moving, infrastructure and application information may change over time (e.g., the variation of the workload). Third, the geographical distribution of fog devices over a large-scale infrastructure. Several specificities and constraints that make the SPP problem in Fog environment a challenging task. In the literature, we identify four main approaches used to solve such a problem: exact resolution, approximation strategies, heuristic or meta-heuristic policies. We briefly describe these procedures in the following.</p>
        <p>The definition of an exact solution is often computed by using an ILP solver, or by performing exhaustive research (by enumerating all solutions). Among the works that attempted to solve the SPP in an exact way, we mention the works [102,122,133,141,147], that use ILP formulation and exact optimization solver to define an optimal solution, and [167] that uses exhaustive placement research.The definition of an exact solution is often computed by using an ILP solver, or by performing exhaustive research (by enumerating all solutions). Among the works that attempted to solve the SPP in an exact way, we mention the works [102,122,133,141,147], that use ILP formulation and exact optimization solver to define an optimal solution, and [167] that uses exhaustive placement research.</p>
        <p>However, it is important to notice that performing an exact resolution requires long processing time before reaching the optimal solutions and can only be used for small problem instances. Indeed, finding an exact solution can be extremely time-consuming and not appropriate for large problems such as Fog environments. Thus, the main focus of works within the research community is based on providing an effective approximation, heuristic or meta-heuristic approaches where suboptimal solutions can be computed in a short time.However, it is important to notice that performing an exact resolution requires long processing time before reaching the optimal solutions and can only be used for small problem instances. Indeed, finding an exact solution can be extremely time-consuming and not appropriate for large problems such as Fog environments. Thus, the main focus of works within the research community is based on providing an effective approximation, heuristic or meta-heuristic approaches where suboptimal solutions can be computed in a short time.</p>
        <p>b) Approximations Approximation techniques are used to compute solutions with provable guarantees regarding their distance to the optimal one. Approximations are efficient algorithms that allow to compute suboptimal solutions of NP-hard optimization problems. For example, in [164], the authors propose to use a fully polynomial-time approximation algorithm to address the problem of IoT application provisioning. This approach allows computing a suboptimal solution and bounds for SPP in a relatively small time.b) Approximations Approximation techniques are used to compute solutions with provable guarantees regarding their distance to the optimal one. Approximations are efficient algorithms that allow to compute suboptimal solutions of NP-hard optimization problems. For example, in [164], the authors propose to use a fully polynomial-time approximation algorithm to address the problem of IoT application provisioning. This approach allows computing a suboptimal solution and bounds for SPP in a relatively small time.</p>
        <p>c) Heuristics Because of the scale, the dynamic and mobile aspects of Fog infrastructures, that make exact analysis almost inapplicable, heuristics are often investigated. Designed to obtain a solution in a reasonable time frame, a heuristic is a set of rules and methods that aim at finding a feasible solution for a given problem. However, with heuristic-based solutions, no performance guarantees are provided. As heuristic approaches we can find for instance fail-first/fail-last heuristics used by Brogi et al. in [29,31]. The authors in this work propose to adopt these two strategies to determine in a relatively short time, a feasible deployment for an application in the FC. The fail-first heuristic is used in that case to selects the undeployed component that has fewer compatible nodes. The fail-last policy sorts the candidate nodes by decreasing the number of end-devices required by a software component, and their hardware capabilities. To guarantee that all requests are satisfied, these heuristics compute the best resource in terms of spatial proximity and the most powerful devices that can support them. d) Meta-heuristics Typically inspired by nature, the meta-heuristic solutions aim at providing the best solution by iteratively improving the quality of the result and helping the search process to escape from local optima within a reasonable time (unlike heuristics that can be stuck in a local optimum). Several meta-heuristic algorithms are provided in the literature, like Genetic Algorithms [70], Ant Colony Optimization [47], Particle Swarm Optimization [80], or 
            <rs type="software">Tabu Search</rs> [61]. These algorithms are based on population evolution where, at each evolution, the best-founded population (solution) is kept into the next evolution, in order to define at the end the best solution regarding a given objective (metric).
        </p>
        <p>As an example, we mention the work of Skarlat et al. [133] that uses a Genetic Algorithm (GA) to solve the SPP in FC. A GA [153] is an evolutionary algorithm that mimics the process of a natural evolution of chromosome. In their work, the authors assume that each gene in a chromosome denotes a service placement decision. The placement is iteratively improved according to a fitness function based on the principle of encouragement.As an example, we mention the work of Skarlat et al. [133] that uses a Genetic Algorithm (GA) to solve the SPP in FC. A GA [153] is an evolutionary algorithm that mimics the process of a natural evolution of chromosome. In their work, the authors assume that each gene in a chromosome denotes a service placement decision. The placement is iteratively improved according to a fitness function based on the principle of encouragement.</p>
        <p>To evaluate the performance of their proposals, the research community uses different programming tools to perform extensive experiments and test their solutions in relevant environments and preferably in realistic setups. We depict thereafter, the most common tools used in the surveyed papers. Table 4 summarizes the programming environment adopted in the literature. Table 4: A Summary of evaluation environments.To evaluate the performance of their proposals, the research community uses different programming tools to perform extensive experiments and test their solutions in relevant environments and preferably in realistic setups. We depict thereafter, the most common tools used in the surveyed papers. Table 4 summarizes the programming environment adopted in the literature. Table 4: A Summary of evaluation environments.</p>
        <p>Analytical tool is one of the common approaches used to compute and evaluate the performance of the formulated strategies. The most frequently mentioned tools are: Java [29,163], C++ [126,164], 
            <rs type="software">Matlab</rs> [79]. For instance, Brogi et al. [29] prototype a proof-of-concept Java tool named 
            <rs type="software">FogTorch</rs>
            <rs type="version">1</rs> that implements and solve the SPP. These tools are sometimes associated with other tools or APIs such as ILP solvers. As solvers frequently mentioned in the literature we have 
            <rs type="creator">IBM</rs>
            <rs type="software">CPLEX</rs>
            <rs type="version">2</rs> ([133], [108]), the commercial solver 
            <rs type="software">Gorubi3</rs> ([62]), or 
            <rs type="software">Choco-Solver</rs>
            <rs type="version">4</rs> ([9]).
        </p>
        <p>Another commonly used approach is performing simulation. Among the simulators cited in the literature, we find a simulator CloudSim [33] designed for regular cloud environments, most often used with some extensions. A 
            <rs type="software">SimGrid5</rs> framework designed for large-scale distributed systems. A simulator 
            <rs type="software">iFogSim</rs> [64] designed for Fog Computing, which extends CloudSim. 
            <rs type="software">iFogSim</rs> is a simulation toolkit proposed by Gupta et al. [64] for evaluating application design and resource management techniques in Fog systems. The simulator performs discrete event simulation and allows users to run applications over Fog infrastructure and measure metrics like latency, energy consumption, and network usage. Other simulators are also cited like network generic simulator 
            <rs type="software">OMNeT++</rs>
            <rs type="version">6</rs> (used of instance in [12]); 
            <rs type="software">FogTorchΠ</rs> provided by [31] that employs the Monte Carlo method [48] to estimate the QoS-assurance of output deployments; Event-driven simulator based on 
            <rs type="software">SimPy 7</rs> performed by Borylo et al. [26], etc.
        </p>
        <p>Finally, we have physical testbeds. As realistic environments, we can cite FIT/IoT-LAB [5] and Grid5000 [18]Finally, we have physical testbeds. As realistic environments, we can cite FIT/IoT-LAB [5] and Grid5000 [18]</p>
        <p>This section describes the SPP and summarizes the most common formulations, resolution strategies, and evaluation tools used in the literature to address this issue. Next, we propose to categorize the surveyed works based on a new classification scheme that allows to simplifying access to references in the category of interest and identifying more easily the challenges and emerging research directions.This section describes the SPP and summarizes the most common formulations, resolution strategies, and evaluation tools used in the literature to address this issue. Next, we propose to categorize the surveyed works based on a new classification scheme that allows to simplifying access to references in the category of interest and identifying more easily the challenges and emerging research directions.</p>
        <p>In this section, we use the taxonomy developed in Section 4.2 to provide a new classification scheme and categorize the works provided on the SPP by the research community. First, we propose to categorize the problem on two main scenarios according to the problem description. Then, we provide the classification we perform. The idea is to group the works addressing the same issues to better understand the needs of each problem, and facilitate the user's access to references.In this section, we use the taxonomy developed in Section 4.2 to provide a new classification scheme and categorize the works provided on the SPP by the research community. First, we propose to categorize the problem on two main scenarios according to the problem description. Then, we provide the classification we perform. The idea is to group the works addressing the same issues to better understand the needs of each problem, and facilitate the user's access to references.</p>
        <p>When surveying the literature, we found that depending on the problem's features, we can identify two main scenarios. Scenario 1 that aims at deploying services in Fog while satisfying the QoS requirements and Scenario 2, slightly different from the first one, that in order to ensure minimum latency and satisfactory quality of service must disseminate and deploy services (replicate some services and place them) over Fog infrastructure. The description of these scenarios is given hereafter. In this scenario, we remark that according to how we characterize the services, we can identify the following sub-scenarios: assignment of set of monolithic applications, assignment of continuous request sent from IoT node to the Fog/Cloud layer, assignment of set of applications each composed by a set of inter-dependant components, assignment of set of applications each having a DAG topology.When surveying the literature, we found that depending on the problem's features, we can identify two main scenarios. Scenario 1 that aims at deploying services in Fog while satisfying the QoS requirements and Scenario 2, slightly different from the first one, that in order to ensure minimum latency and satisfactory quality of service must disseminate and deploy services (replicate some services and place them) over Fog infrastructure. The description of these scenarios is given hereafter. In this scenario, we remark that according to how we characterize the services, we can identify the following sub-scenarios: assignment of set of monolithic applications, assignment of continuous request sent from IoT node to the Fog/Cloud layer, assignment of set of applications each composed by a set of inter-dependant components, assignment of set of applications each having a DAG topology.</p>
        <p>• Scenario 1.1: Deploy a set of monolithic applications. This scenario addresses the problem of defining the best storage/process location for set of services that are assumed to be monolithic.• Scenario 1.1: Deploy a set of monolithic applications. This scenario addresses the problem of defining the best storage/process location for set of services that are assumed to be monolithic.</p>
        <p>• Scenario 1.2: Deploy applications that receives continuous request from a data source. This scenario deals with the assignment of service flows between service producer (i.e., sensors) and service consumers (i.e., Fog resources). Application placement here involves both determining the host devices and routing path that satisfies requirements and optimize objective (if any).• Scenario 1.2: Deploy applications that receives continuous request from a data source. This scenario deals with the assignment of service flows between service producer (i.e., sensors) and service consumers (i.e., Fog resources). Application placement here involves both determining the host devices and routing path that satisfies requirements and optimize objective (if any).</p>
        <p>• Scenario 1.3: Deploy applications each abstracted as a set of interdependent services. This scenario assumes that each application is composed of a set of independent components, i.e., without networking dependencies (requirements in terms of latency, bandwidth, etc., between services are not considered).• Scenario 1.3: Deploy applications each abstracted as a set of interdependent services. This scenario assumes that each application is composed of a set of independent components, i.e., without networking dependencies (requirements in terms of latency, bandwidth, etc., between services are not considered).</p>
        <p>• Scenario 1.4: Deploy applications each abstracted as a Directed Acyclic Graph (DAG). The application here is defined through a DAG topology, where each node represents an operational service of the application and the links describe the networking requirements between components (refer to Section 4.1.2.b for more details).• Scenario 1.4: Deploy applications each abstracted as a Directed Acyclic Graph (DAG). The application here is defined through a DAG topology, where each node represents an operational service of the application and the links describe the networking requirements between components (refer to Section 4.1.2.b for more details).</p>
        <p>ii) Scenario 2: Ensure minimum latency and a satisfactory QoS when deploying services Fog Computing allows bringing computational power to the edge of the network, reduce latency and overheads. However, when applications need access to data that are centrally stored (which is the case of many services like video streaming, video on demand, gaming, etc.), the benefits of the Fog can be quickly affected (deterioration of latency, presence of bottlenecks). To avoid these situations, one solution consists to disseminate data in a Fog environment. Offloading data to the Edge involves the use of data replication and place the replicas on critical network nodes to provide a more cost-effective solution.ii) Scenario 2: Ensure minimum latency and a satisfactory QoS when deploying services Fog Computing allows bringing computational power to the edge of the network, reduce latency and overheads. However, when applications need access to data that are centrally stored (which is the case of many services like video streaming, video on demand, gaming, etc.), the benefits of the Fog can be quickly affected (deterioration of latency, presence of bottlenecks). To avoid these situations, one solution consists to disseminate data in a Fog environment. Offloading data to the Edge involves the use of data replication and place the replicas on critical network nodes to provide a more cost-effective solution.</p>
        <p>This scenario tackles the service placement problem in a slightly different context compared to scenario 1. Indeed, where to place the service replicas involves satisfying additional and specific requirements and constraints such as: do not place an identical service in the same place or region, which service replica to select, and so on. Moreover, addressing the SPP here is connect to others issues such as: "Which application components to replicate?", "How many replicas for each service should we create?", "When to create and destroy a copy?", etc. So many factors that make this problem and scenario a very challenging task.This scenario tackles the service placement problem in a slightly different context compared to scenario 1. Indeed, where to place the service replicas involves satisfying additional and specific requirements and constraints such as: do not place an identical service in the same place or region, which service replica to select, and so on. Moreover, addressing the SPP here is connect to others issues such as: "Which application components to replicate?", "How many replicas for each service should we create?", "When to create and destroy a copy?", etc. So many factors that make this problem and scenario a very challenging task.</p>
        <p>Based on the identified scenarios and service placement taxonomy presented in Section 4.2, we propose to categorize some approaches elaborated in the literature. The provided classification are depicted in Table 6. A more detailed classification is depicted in Tables 7, 8, 9, 10, and 11. In these tables, we propose to outline the placement requirements considered (based on those mentioned in Section 4.1.3), and describe the individual contributions of each work. Table 7 (resp. Table 8, Table 9, and Table 10,11) is dedicated to approaches dealing with Scenario 1.1 (resp. Scenario 1.2, Scenario 1.3, and Scenario 1.4, and Scenario 2). The following syntax is introduced to associate each work to the related taxonomy:Based on the identified scenarios and service placement taxonomy presented in Section 4.2, we propose to categorize some approaches elaborated in the literature. The provided classification are depicted in Table 6. A more detailed classification is depicted in Tables 7, 8, 9, 10, and 11. In these tables, we propose to outline the placement requirements considered (based on those mentioned in Section 4.1.3), and describe the individual contributions of each work. Table 7 (resp. Table 8, Table 9, and Table 10,11) is dedicated to approaches dealing with Scenario 1.1 (resp. Scenario 1.2, Scenario 1.3, and Scenario 1.4, and Scenario 2). The following syntax is introduced to associate each work to the related taxonomy:</p>
        <p>The first parameter denotes whether the considered control plan is Centralized or Distributed. The second parameter denotes whether the scheduling is performed in Off line or Online manner. The third one denotes whether the placement is Static (i.e., considers unchanging infrastructure and applications topologies and information), or Dynamic (i.e., handles the dynamicity of the system). Finally, the fourth parameter denotes whether the provided strategy supports the mobility (M) of end-users and/or Fog devices or not (nM). So, an approach denoted as C/On/Dy/nM will be a centralized, online, dynamic, and do not support mobility. This description allows categorizing quickly any given proposals and proper compare with similar approaches. We note that each of these categories is mutually independent. Proposes a latency-aware application management policy to achieve improvements in network conditions and service QoS. [127] C R , C N Designs a score-based scheduling framework for latency-sensitive applications that maximize the end-users service quality experienced.The first parameter denotes whether the considered control plan is Centralized or Distributed. The second parameter denotes whether the scheduling is performed in Off line or Online manner. The third one denotes whether the placement is Static (i.e., considers unchanging infrastructure and applications topologies and information), or Dynamic (i.e., handles the dynamicity of the system). Finally, the fourth parameter denotes whether the provided strategy supports the mobility (M) of end-users and/or Fog devices or not (nM). So, an approach denoted as C/On/Dy/nM will be a centralized, online, dynamic, and do not support mobility. This description allows categorizing quickly any given proposals and proper compare with similar approaches. We note that each of these categories is mutually independent. Proposes a latency-aware application management policy to achieve improvements in network conditions and service QoS. [127] C R , C N Designs a score-based scheduling framework for latency-sensitive applications that maximize the end-users service quality experienced.</p>
        <p>[139][139]</p>
        <p>C R , C N Introduces an online optimization scheme for the task distribution under uncertainties in Fog network.C R , C N Introduces an online optimization scheme for the task distribution under uncertainties in Fog network.</p>
        <p>Provides an online placement approach that attempts to fairly satisfy all web applications.Provides an online placement approach that attempts to fairly satisfy all web applications.</p>
        <p>Designs a dynamic and mobility-aware service placement framework to provide a desirable performance-cost trade-off in Mobile Edge Computing. [135] C R , C N Presents a conceptual framework for Fog resource provisioning.Designs a dynamic and mobility-aware service placement framework to provide a desirable performance-cost trade-off in Mobile Edge Computing. [135] C R , C N Presents a conceptual framework for Fog resource provisioning.</p>
        <p>[132] C R , C D Proposes a security and deadline aware tasks scheduling algorithm. Provides latency-Aware deployment policy combined with anycast strategies for Fog and Cloud service provisioning. [43] C R , C N C D Minimizes power costs when distributing workload in Cloud/Fog systems. [44] C R , C N C D Defines a workload allocation policy for the Fog-Cloud Computing services and investigates the tradeoff between power consumption and delay. [45] C R Investigates the problem of service deployment while minimizing carbon footprint for video streaming service in Fog architecture.[132] C R , C D Proposes a security and deadline aware tasks scheduling algorithm. Provides latency-Aware deployment policy combined with anycast strategies for Fog and Cloud service provisioning. [43] C R , C N C D Minimizes power costs when distributing workload in Cloud/Fog systems. [44] C R , C N C D Defines a workload allocation policy for the Fog-Cloud Computing services and investigates the tradeoff between power consumption and delay. [45] C R Investigates the problem of service deployment while minimizing carbon footprint for video streaming service in Fog architecture.</p>
        <p>[50] C R , C N , C L , C D Provides a proactive tasks placement in Fog networks under latency and reliability constraints. [55] C R , C N , C D Provides data placement policy in context of incidental disasters. [62] C R ,[50] C R , C N , C L , C D Provides a proactive tasks placement in Fog networks under latency and reliability constraints. [55] C R , C N , C D Provides data placement policy in context of incidental disasters. [62] C R ,</p>
        <p>Proposes a heuristic algorithm to address the task distribution, and virtual machine placement problem toward cost-efficient Fog computation and medical cyber-physical systems. [77] C R , C D Provides a mathematical service placement model in Fog architecture.Proposes a heuristic algorithm to address the task distribution, and virtual machine placement problem toward cost-efficient Fog computation and medical cyber-physical systems. [77] C R , C D Provides a mathematical service placement model in Fog architecture.</p>
        <p>[88] C R Elaborates a data placement policy in Fog architectures that aims to reduce network usage.[88] C R Elaborates a data placement policy in Fog architectures that aims to reduce network usage.</p>
        <p>[101] C R , C N , C D Proposes a balanced energy-delay solution for IoT applications placement and energy consumption problem in Fog Computing. [107,108] C R , C N Provides a framework called 
            <rs type="software">iFogStor</rs> for IoT data placement in a Fog infrastructure.
        </p>
        <p>[129] C R Provides a placement mechanism that models the competition between IoT users and the efficient service deployment over a hierarchical Fog-Cloud computing system.[129] C R Provides a placement mechanism that models the competition between IoT users and the efficient service deployment over a hierarchical Fog-Cloud computing system.</p>
        <p>Proposes provisioning schemes for real-time processing applications in Fog Computing.Proposes provisioning schemes for real-time processing applications in Fog Computing.</p>
        <p>Proposes a set of strategies for service placement in Edge-Cloud environment. [163] C R , C D Introduces a dynamic Fog service provisioning policy that meets QoS constraints.Proposes a set of strategies for service placement in Edge-Cloud environment. [163] C R , C D Introduces a dynamic Fog service provisioning policy that meets QoS constraints.</p>
        <p>C R , C N Designs an online control algorithm that provides where and when services should be migrated according to demand variation and user mobility in Edge-Clouds networks.C R , C N Designs an online control algorithm that provides where and when services should be migrated according to demand variation and user mobility in Edge-Clouds networks.</p>
        <p>[149] C R , C L Proposes a strategy that dynamically route data to proper fog nodes in the context of real-time surveillance applications.[149] C R , C L Proposes a strategy that dynamically route data to proper fog nodes in the context of real-time surveillance applications.</p>
        <p>Di/On/S/nMDi/On/S/nM</p>
        <p>Proposes an algorithm to distribute workload in Fog Computing environment that minimize the response time and costs. [10] C R , C N , C D Elaborate an approach for service mapping and service delegation between Fog and Cloud Computing. [78] C R , C D Proposes a QoS-aware service deployment technique in Fog Computing to reduce latency and network congestion.Proposes an algorithm to distribute workload in Fog Computing environment that minimize the response time and costs. [10] C R , C N , C D Elaborate an approach for service mapping and service delegation between Fog and Cloud Computing. [78] C R , C D Proposes a QoS-aware service deployment technique in Fog Computing to reduce latency and network congestion.</p>
        <p>[86] C R , C N Proposes an online optimization framework to perform efficient task distribution over hybrid Fog-Cloud architecture.[86] C R , C N Proposes an online optimization framework to perform efficient task distribution over hybrid Fog-Cloud architecture.</p>
        <p>[87] C R , C N Provides an online dispatching and scheduling mechanism of tasks to distributed Edge-Clouds system.[87] C R , C N Provides an online dispatching and scheduling mechanism of tasks to distributed Edge-Clouds system.</p>
        <p>[143] C R Develops workload placement algorithms to efficiently execute mobile programs in the Edge-Cloud network.[143] C R Develops workload placement algorithms to efficiently execute mobile programs in the Edge-Cloud network.</p>
        <p>[162] C R , C D Proposes a delay-minimizing policy for IoT applications placement over IoT-Fog-Cloud network.[162] C R , C D Proposes a delay-minimizing policy for IoT applications placement over IoT-Fog-Cloud network.</p>
        <p>[161] C R Proposes a delay-minimizing tasks offloading scheme for IoT applications in Fog Computing.[161] C R Proposes a delay-minimizing tasks offloading scheme for IoT applications in Fog Computing.</p>
        <p>Proposes a new model to coordinate service deployment and migration that includes latency, location awareness, and mobility support in the smart grid. C R , C N Designs an algorithm for traffic-aware VM placement and determine the maximum number of accepted VMs in the cloudlet mesh.Proposes a new model to coordinate service deployment and migration that includes latency, location awareness, and mobility support in the smart grid. C R , C N Designs an algorithm for traffic-aware VM placement and determine the maximum number of accepted VMs in the cloudlet mesh.</p>
        <p>[112] C R Proposes a dynamic service mapping strategy that optimize resource utilization and satisfy the users' QoS requirements in Fog Computing.[112] C R Proposes a dynamic service mapping strategy that optimize resource utilization and satisfy the users' QoS requirements in Fog Computing.</p>
        <p>Evaluates resource provisioning in Smart City scenarios by providing an IoT application service placement mechanism. [126] C R , C N , C L , C D Proposes an application deployment and migration mechanism for geodistributed systems. [147] C R Proposes a service placement architecture for the IoT that continuously adapt (migrate) services according to the network changing conditions and users status.Evaluates resource provisioning in Smart City scenarios by providing an IoT application service placement mechanism. [126] C R , C N , C L , C D Proposes an application deployment and migration mechanism for geodistributed systems. [147] C R Proposes a service placement architecture for the IoT that continuously adapt (migrate) services according to the network changing conditions and users status.</p>
        <p>Di/On/S/nMDi/On/S/nM</p>
        <p>Provides a service placement policy that leveraging context-aware information (location, time, and QoS) in Fog landscapes. [133,134] C R , C N , C D Proposes provisioning and service placement approach to enable the exploitation of Fog-based computational resources. [148] C R , C D Provides a mapping strategy of IoT applications that optimizes resource utilization and satisfies QoS services requirements.Provides a service placement policy that leveraging context-aware information (location, time, and QoS) in Fog landscapes. [133,134] C R , C N , C D Proposes provisioning and service placement approach to enable the exploitation of Fog-based computational resources. [148] C R , C D Provides a mapping strategy of IoT applications that optimizes resource utilization and satisfies QoS services requirements.</p>
        <p>Table 9: Taxonomy dedicated to Scenario 1.3.Table 9: Taxonomy dedicated to Scenario 1.3.</p>
        <p>Proposes a QoS-aware deployment strategy for multi-components IoT applications in Fog infrastructure. [98] C R , C N , C L Designs a tasks deployment framework for Mobile Edge Cloud Offloading that achieves a trade-off between applications' runtime, mobile device battery lifetime and cost for the user. [57] C R , C N Provides a set of heuristics to address the service placement problem in Cloud-Fog network.Proposes a QoS-aware deployment strategy for multi-components IoT applications in Fog infrastructure. [98] C R , C N , C L Designs a tasks deployment framework for Mobile Edge Cloud Offloading that achieves a trade-off between applications' runtime, mobile device battery lifetime and cost for the user. [57] C R , C N Provides a set of heuristics to address the service placement problem in Cloud-Fog network.</p>
        <p>[71][71]</p>
        <p>C R , C N , C L Designs, implements, and evaluates a Fog Computing platform that runs analytics on multiple devices. [75] C R , C N Evaluates a set of heuristic algorithms for solving the service placement problem in the context of next-generation network architectures.C R , C N , C L Designs, implements, and evaluates a Fog Computing platform that runs analytics on multiple devices. [75] C R , C N Evaluates a set of heuristic algorithms for solving the service placement problem in the context of next-generation network architectures.</p>
        <p>[79] C R , C N Addresses the task assignment problem for the virtual Fog access point.[79] C R , C N Addresses the task assignment problem for the virtual Fog access point.</p>
        <p>[103] C R , C N Proposes a tasks deployment policy that assigns the processing tasks to nodes which provide the optimal processing time and near optimal networking costs in Edge-Fog Cloud system.[103] C R , C N Proposes a tasks deployment policy that assigns the processing tasks to nodes which provide the optimal processing time and near optimal networking costs in Edge-Fog Cloud system.</p>
        <p>[118] C R , C N Provides a scheduling algorithm that guarantees application performance and reduces the cost of using Cloud resources.[118] C R , C N Provides a scheduling algorithm that guarantees application performance and reduces the cost of using Cloud resources.</p>
        <p>[140] C R Proposes a service mapping solution for efficient resources utilization in the Fog infrastructure.[140] C R Proposes a service mapping solution for efficient resources utilization in the Fog infrastructure.</p>
        <p>[[</p>
        <p>Proposes a mechanism for placing IoT applications in Fog infrastructure while minimizing the services response time.Proposes a mechanism for placing IoT applications in Fog infrastructure while minimizing the services response time.</p>
        <p>Provides an optimization placement framework of data stream processing applications that minimise end-to-end latency in Edge-Cloud Computing. [19] C R , C N , C D Designs an IoT service placement strategy for IoT-Cloud infrastructure that satisfies end user demands and minimizes overall operational cost. [34] C R , C N Proposes a solution for the distributed data stream application placement in a geographically distributed environment.Provides an optimization placement framework of data stream processing applications that minimise end-to-end latency in Edge-Cloud Computing. [19] C R , C N , C D Designs an IoT service placement strategy for IoT-Cloud infrastructure that satisfies end user demands and minimizes overall operational cost. [34] C R , C N Proposes a solution for the distributed data stream application placement in a geographically distributed environment.</p>
        <p>[46] C R , C N Proposes an orchestration mechanisms for service provisioning in Fog network that minimizes the provisioning cost of IoT applications.[46] C R , C N Proposes an orchestration mechanisms for service provisioning in Fog network that minimizes the provisioning cost of IoT applications.</p>
        <p>[64] C R , C N Proposes a transfer-time aware service scheduling policy for IoT-Fog-Cloud Computing environments.[64] C R , C N Proposes a transfer-time aware service scheduling policy for IoT-Fog-Cloud Computing environments.</p>
        <p>Proposes a policy for service placement in Fog devices based on communities and transitive closures notions. [94] C R Proposes an energy-aware algorithm for mapping application components on Fog devices.Proposes a policy for service placement in Fog devices based on communities and transitive closures notions. [94] C R Proposes an energy-aware algorithm for mapping application components on Fog devices.</p>
        <p>[[</p>
        <p>Addresses the multi-Component application placement problem in Edge environments and develop algorithms with provable performance bounds. [157] C R , C N Builts the Latency-Aware Video Edge Analytics system to investigate task placement schemes.Addresses the multi-Component application placement problem in Edge environments and develop algorithms with provable performance bounds. [157] C R , C N Builts the Latency-Aware Video Edge Analytics system to investigate task placement schemes.</p>
        <p>C/On/Dy/nM [15] C R , C L Proposes a decision-making strategy for virtual machine placement considering multiple optimization objectives.C/On/Dy/nM [15] C R , C L Proposes a decision-making strategy for virtual machine placement considering multiple optimization objectives.</p>
        <p>[58] C R Proposes adaptive scheduling strategies for dynamic event analytic dataflows placement in Edge-Cloud devices that support Smart City applications emerging needs.[58] C R Proposes adaptive scheduling strategies for dynamic event analytic dataflows placement in Edge-Cloud devices that support Smart City applications emerging needs.</p>
        <p>[97] C R , C D Refines the service provisioning algorithm to guarantee the application deadlines and optimize Edge resource exploitation.[97] C R , C D Refines the service provisioning algorithm to guarantee the application deadlines and optimize Edge resource exploitation.</p>
        <p>Proposes an online mobile application placement algorithm that minimizes the services computational cost.Proposes an online mobile application placement algorithm that minimizes the services computational cost.</p>
        <p>[114] C R , C N , C D Proposes a service placement and migration policy for mobile event processing applications in Cloud and Fog resources.[114] C R , C N , C D Proposes a service placement and migration policy for mobile event processing applications in Cloud and Fog resources.</p>
        <p>Di/On/S/nM [131] C R , C N Introduces a collaborative approach of executing applications components in a distributed manner between fog devices.Di/On/S/nM [131] C R , C N Introduces a collaborative approach of executing applications components in a distributed manner between fog devices.</p>
        <p>Table 10: Taxonomy dedicated to Scenarios 1.4.Table 10: Taxonomy dedicated to Scenarios 1.4.</p>
        <p>C/Off/S/nM [11] C R , C N Proposes an efficient cache placement strategy based on content popularity to reduce energy consumption in Fog networks.C/Off/S/nM [11] C R , C N Proposes an efficient cache placement strategy based on content popularity to reduce energy consumption in Fog networks.</p>
        <p>[167] C R ,C N Proposes a placement algorithm for virtual machine replica in Mobile Edge Computing that minimizes the average data traffic in the network.[167] C R ,C N Proposes a placement algorithm for virtual machine replica in Mobile Edge Computing that minimizes the average data traffic in the network.</p>
        <p>C/On/S/nMC/On/S/nM</p>
        <p>Provides two request-routing strategies to tackle the problem of energy-efficient and latency-aware data placement in geo-distributed Cloud data centers. [100] C R Provides a Fog-aware replica placement algorithm based on the definition of failure groups.Provides two request-routing strategies to tackle the problem of energy-efficient and latency-aware data placement in geo-distributed Cloud data centers. [100] C R Provides a Fog-aware replica placement algorithm based on the definition of failure groups.</p>
        <p>[166] C R , C N Designs a task scheduling strategy that minimizes tasks completion time for promoting the user experience.[166] C R , C N Designs a task scheduling strategy that minimizes tasks completion time for promoting the user experience.</p>
        <p>Di/On/Dy/nMDi/On/Dy/nM</p>
        <p>Elaborates a dynamic placement (creation/replacement/removal) of data replicas across IaaS providers. [128] C R , C N , C L Provides a bandwidth and availability-aware policy for service deployment on Micro-Cloud infrastructures that maximizes user QoS and QoE.Elaborates a dynamic placement (creation/replacement/removal) of data replicas across IaaS providers. [128] C R , C N , C L Provides a bandwidth and availability-aware policy for service deployment on Micro-Cloud infrastructures that maximizes user QoS and QoE.</p>
        <p>Table 11: Taxonomy dedicated to Scenarios 2.Table 11: Taxonomy dedicated to Scenarios 2.</p>
        <p>We propose now to similar works based on the used resolution approach. Some solutions along with their objectives are detailed in Tables 12, 13, 14, 15, and 16. Each table refers to the aforementioned scenarios (see Section 5.1).We propose now to similar works based on the used resolution approach. Some solutions along with their objectives are detailed in Tables 12, 13, 14, 15, and 16. Each table refers to the aforementioned scenarios (see Section 5.1).</p>
        <p>Objective and a brief description of the resolution technique.Objective and a brief description of the resolution technique.</p>
        <p>C/Off/S/nM Exact [141] Minimizes the number of Fog nodes. Exact resolution of the ILP using CPLEX solver.C/Off/S/nM Exact [141] Minimizes the number of Fog nodes. Exact resolution of the ILP using CPLEX solver.</p>
        <p>[69] Minimizes the overall communication cost. Uses linear programming solver.[69] Minimizes the overall communication cost. Uses linear programming solver.</p>
        <p>C/On/S/nM Approximation [139] Minimizes the total response time over all the deployed tasks. Uses a Dual-fitting algorithm to find a feasible solution.C/On/S/nM Approximation [139] Minimizes the total response time over all the deployed tasks. Uses a Dual-fitting algorithm to find a feasible solution.</p>
        <p>Heuristic [81] Maximizes the utilization of residual computing capabilities of terminals. Provides two heuristics: 1) Prioritize the task with the earliest deadline. 2) Choose the device with the minimum remaining computation capacity.Heuristic [81] Maximizes the utilization of residual computing capabilities of terminals. Provides two heuristics: 1) Prioritize the task with the earliest deadline. 2) Choose the device with the minimum remaining computation capacity.</p>
        <p>[127] Maximizes the QoE. Computes a quality score that combines connectivity, bandwidth, and resource scores to deploy a service on the most suitable VM.[127] Maximizes the QoE. Computes a quality score that combines connectivity, bandwidth, and resource scores to deploy a service on the most suitable VM.</p>
        <p>Maximizes QoE-gain of the user. Uses a Fuzzy logic based reasoning.Maximizes QoE-gain of the user. Uses a Fuzzy logic based reasoning.</p>
        <p>C/On/Dy/nM Heuristic [35] Equally satisfies the applications. Uses utility-driven application placement policy.C/On/Dy/nM Heuristic [35] Equally satisfies the applications. Uses utility-driven application placement policy.</p>
        <p>C/On/Dy/M Heuristic [115] Minimizes the average service latency under cost budget constraints. Uses Lyapunov optimization to decompose the problem into a set of problems that do not require a priory knowledge of user mobility.C/On/Dy/M Heuristic [115] Minimizes the average service latency under cost budget constraints. Uses Lyapunov optimization to decompose the problem into a set of problems that do not require a priory knowledge of user mobility.</p>
        <p>Machine Learning [36] Minimizes the service costs, meantime and improve the QoE. Uses Q-learning method [76] to determine for each service request, the host (node) that provides the optimal migration.Machine Learning [36] Minimizes the service costs, meantime and improve the QoE. Uses Q-learning method [76] to determine for each service request, the host (node) that provides the optimal migration.</p>
        <p>Di/Off/S/nM Exact [137] Minimizes the service latencies in a Fog, while satisfying the QoS requirements. Uses Gurobi optimizer [66] to solve the ILP provided model.Di/Off/S/nM Exact [137] Minimizes the service latencies in a Fog, while satisfying the QoS requirements. Uses Gurobi optimizer [66] to solve the ILP provided model.</p>
        <p>Di/On/S/nM Heuristic [132] Minimizes the cost of the user job. Sorts the jobs in increasing order of deadlines.Di/On/S/nM Heuristic [132] Minimizes the cost of the user job. Sorts the jobs in increasing order of deadlines.</p>
        <p>[135] Maximizes the utilization of Fog resources. Uses a fog colonies notion and simulation approach to perform provisioning plan of requested services.[135] Maximizes the utilization of Fog resources. Uses a fog colonies notion and simulation approach to perform provisioning plan of requested services.</p>
        <p>[54] Maximizes the application deployment revenue. Operates an iterative application deployment by region. Finds the minimum congestion ratio. Uses fully polynomial-time approximation that in order to reduce the resolution complexity of IoT application provisioning proposes to decompose the initial problem into two sub-problems to be solved separately.[54] Maximizes the application deployment revenue. Operates an iterative application deployment by region. Finds the minimum congestion ratio. Uses fully polynomial-time approximation that in order to reduce the resolution complexity of IoT application provisioning proposes to decompose the initial problem into two sub-problems to be solved separately.</p>
        <p>[129] Each user maximize its own QoE. Uses -Nash equilibrium and offloading game to model the competition between end-users and provides near-optimal service mapping.[129] Each user maximize its own QoE. Uses -Nash equilibrium and offloading game to model the competition between end-users and provides near-optimal service mapping.</p>
        <p>Heuristic [43,44] Minimizes the power consumption in the Cloud-Fog Computing.Heuristic [43,44] Minimizes the power consumption in the Cloud-Fog Computing.</p>
        <p>Decomposes the initial problem into three sub-problems that can be independently solved, and uses convex optimization techniques, Generalized Benders' Decomposition, and Hungarian method to find feasible solution.Decomposes the initial problem into three sub-problems that can be independently solved, and uses convex optimization techniques, Generalized Benders' Decomposition, and Hungarian method to find feasible solution.</p>
        <p>[55][55]</p>
        <p>Minimizes service delay and expensive resource over provisioning. Computes the shortest path that satisfies application QoS constraints.Minimizes service delay and expensive resource over provisioning. Computes the shortest path that satisfies application QoS constraints.</p>
        <p>[77][77]</p>
        <p>Minimizes the blocking probability (ratio between a number of rejected workloads and the total number of workloads). Proposes three resolution approaches: Random, Lowest latency, and Maximum available capacity policies.Minimizes the blocking probability (ratio between a number of rejected workloads and the total number of workloads). Proposes three resolution approaches: Random, Lowest latency, and Maximum available capacity policies.</p>
        <p>[88][88]</p>
        <p>Optimizes the network usage. Determines the Fog device with the closest and most evenly distance to the data sources. The placement decision considers the FN with the highest centrality value. [107,108] Minimizes the overall latency of storing and retrieving data in a Fog. Provides a geographical partition to decreases the problemsolving time. [14,26,45,50,62] Metaheuristic [101] Minimizes the total energy consumption of mobile applications.Optimizes the network usage. Determines the Fog device with the closest and most evenly distance to the data sources. The placement decision considers the FN with the highest centrality value. [107,108] Minimizes the overall latency of storing and retrieving data in a Fog. Provides a geographical partition to decreases the problemsolving time. [14,26,45,50,62] Metaheuristic [101] Minimizes the total energy consumption of mobile applications.</p>
        <p>Uses a modified genetic algorithm.Uses a modified genetic algorithm.</p>
        <p>C/On/Dy/nM Heuristic [16] Minimizes failed requests. Proposes two heuristics: strictest deadline first, and first in first out policies.C/On/Dy/nM Heuristic [16] Minimizes failed requests. Proposes two heuristics: strictest deadline first, and first in first out policies.</p>
        <p>[163] Minimizes overall cost (processing, storage, and communication).[163] Minimizes overall cost (processing, storage, and communication).</p>
        <p>Proposes Two heuristics: 1) Min-Viol: aims at minimizing the deadline violations. 2) Min-Cost: aims at minimizing the total cost.Proposes Two heuristics: 1) Min-Viol: aims at minimizing the deadline violations. 2) Min-Cost: aims at minimizing the total cost.</p>
        <p>C/On/Dy/M Heuristic [145] Minimizes the cost of execution, delays, and location constraints.C/On/Dy/M Heuristic [145] Minimizes the cost of execution, delays, and location constraints.</p>
        <p>Decouples the initial Markov Decision Process (MDP) into two independent MDPs and solves the problems using a Lyapunov optimization.Decouples the initial Markov Decision Process (MDP) into two independent MDPs and solves the problems using a Lyapunov optimization.</p>
        <p>[149] Minimizes the average cost over time. When emergency event happens, computes reconfiguration and reallocation only on the impacted zone.[149] Minimizes the average cost over time. When emergency event happens, computes reconfiguration and reallocation only on the impacted zone.</p>
        <p>Di/On/S/nM Heuristic [7] Minimizes the response time and maximize the throughput. Schedules jobs on VMs based on service level agreement.Di/On/S/nM Heuristic [7] Minimizes the response time and maximize the throughput. Schedules jobs on VMs based on service level agreement.</p>
        <p>[10] Meets SLA and QoS. Prioritizes the mapping based on a linearized decision composed by services size, completion time, and VMs capacity. Component with higher priority are mapped first and the one with lower priority are deployed last.[10] Meets SLA and QoS. Prioritizes the mapping based on a linearized decision composed by services size, completion time, and VMs capacity. Component with higher priority are mapped first and the one with lower priority are deployed last.</p>
        <p>[143] Minimizes the cumulative delay of executing mobile services. Solves the MNIP problem as follows: first transforms the mixed nonlinear integer program to a convex optimization problem, and then solves the problem that only contains the integer variables.[143] Minimizes the cumulative delay of executing mobile services. Solves the MNIP problem as follows: first transforms the mixed nonlinear integer program to a convex optimization problem, and then solves the problem that only contains the integer variables.</p>
        <p>[162] Reduces the service delay for IoT applications. Compares the estimated waiting time of task at a given FN with their deadline. If it is smaller, accept the task, if not, the FN offloads the service to one of its neighbors, or to the Cloud. [78,86,87,161] Di/On/Dy/M Heuristic [150] Reduces the application delay of IoT applications in the Smart Grid. Chooses the best nodes from the set of nodes that satisfy QoS of end-nodes and having the nearest deadline. Optimizes multiple objectives: maximize number of accepted IoT application requests, maximize service bandwidth, minimize service migrations between iterations, minimize number of active computational nodes, minimize the number of active gateways, minimize hop count between computational nodes and end devices, and minimize of path loss. Computes iteratively the solution so that in every iteration refines the previous obtained solution by improving the model with an additional optimization objective.[162] Reduces the service delay for IoT applications. Compares the estimated waiting time of task at a given FN with their deadline. If it is smaller, accept the task, if not, the FN offloads the service to one of its neighbors, or to the Cloud. [78,86,87,161] Di/On/Dy/M Heuristic [150] Reduces the application delay of IoT applications in the Smart Grid. Chooses the best nodes from the set of nodes that satisfy QoS of end-nodes and having the nearest deadline. Optimizes multiple objectives: maximize number of accepted IoT application requests, maximize service bandwidth, minimize service migrations between iterations, minimize number of active computational nodes, minimize the number of active gateways, minimize hop count between computational nodes and end devices, and minimize of path loss. Computes iteratively the solution so that in every iteration refines the previous obtained solution by improving the model with an additional optimization objective.</p>
        <p>[126][126]</p>
        <p>Optimizes tasks mapping by saving bandwidth and reducing latency.Optimizes tasks mapping by saving bandwidth and reducing latency.</p>
        <p>Determines incrementally the fog nodes that match the capacity constraints and handle the application dynamism.Determines incrementally the fog nodes that match the capacity constraints and handle the application dynamism.</p>
        <p>[147] Minimizes: the hop count between end-nodes and hosting nodes, the hop count between communication nodes, and the number of service migrations. Deploys the services in random locations, and later adapts to the network and applications constraints and requirements.[147] Minimizes: the hop count between end-nodes and hosting nodes, the hop count between communication nodes, and the number of service migrations. Deploys the services in random locations, and later adapts to the network and applications constraints and requirements.</p>
        <p>Di/On/S/nM Exact [102] Maximizes the number of deployed applications. Uses ILP solver.Di/On/S/nM Exact [102] Maximizes the number of deployed applications. Uses ILP solver.</p>
        <p>[134] Maximizes the number of services deployed on Fog landscape. Uses ILP solver.[134] Maximizes the number of services deployed on Fog landscape. Uses ILP solver.</p>
        <p>Heuristic [134] Maximizes the number of deployed services to Fog infrastructure.Heuristic [134] Maximizes the number of deployed services to Fog infrastructure.</p>
        <p>Prioritizes the applications having the minimum value between their deadline and their deployment time.Prioritizes the applications having the minimum value between their deadline and their deployment time.</p>
        <p>Metaheuristic [133] Maximizes the number of deployed services to Fog devices rather than to Cloud ones. Uses a genetic Algorithm.Metaheuristic [133] Maximizes the number of deployed services to Fog devices rather than to Cloud ones. Uses a genetic Algorithm.</p>
        <p>Table 14: Classification according to resolution approaches dedicated to Scenarios 1.3.Table 14: Classification according to resolution approaches dedicated to Scenarios 1.3.</p>
        <p>Objective and a brief description of the resolution techniques.Objective and a brief description of the resolution techniques.</p>
        <p>C/Off/S/nM Exact [9] Provides feasible (resp. optimal) service placement solutions in Fog environment. Uses the constraint programming Choco-solver.C/Off/S/nM Exact [9] Provides feasible (resp. optimal) service placement solutions in Fog environment. Uses the constraint programming Choco-solver.</p>
        <p>[20] Minimizes the overall latency and ensures the QoS requirements.[20] Minimizes the overall latency and ensures the QoS requirements.</p>
        <p>Uses ILP-solver 
            <rs type="software">CPLEX</rs>.
        </p>
        <p>Heuristic [29] Determines eligible deployments of composite applications. Performs pre-processing plus backtracking to determine an eligible deployment.Heuristic [29] Determines eligible deployments of composite applications. Performs pre-processing plus backtracking to determine an eligible deployment.</p>
        <p>[31] Determines eligible deployments of composite applications. Exploits Monte Carlo simulations [48] to handle the communication links variations, and performs pre-processing plus backtracking to determine the final eligible deployment.[31] Determines eligible deployments of composite applications. Exploits Monte Carlo simulations [48] to handle the communication links variations, and performs pre-processing plus backtracking to determine the final eligible deployment.</p>
        <p>[98][98]</p>
        <p>Optimizes the following objectives: minimize runtime and user cost, and maximize battery lifetime. Computes the local optimum solution for each objective, and then, selects the one with the lowest score (calculated according to a given equation).Optimizes the following objectives: minimize runtime and user cost, and maximize battery lifetime. Computes the local optimum solution for each objective, and then, selects the one with the lowest score (calculated according to a given equation).</p>
        <p>[57] Minimizes the overall cost (placement and link costs). Provides six heuristics: 1) Limits the deployment of an application component to a subset of nodes; 2) Restricts the placement of a component to one particular node; 3) Applies the co-location of some components to one node; Accelerate the previous heuristics by 4) Combines heuristics 2 and 1; 5) Combine heuristics 2 and 3; and 6) Combines heuristics 1 and 3.[57] Minimizes the overall cost (placement and link costs). Provides six heuristics: 1) Limits the deployment of an application component to a subset of nodes; 2) Restricts the placement of a component to one particular node; 3) Applies the co-location of some components to one node; Accelerate the previous heuristics by 4) Combines heuristics 2 and 1; 5) Combine heuristics 2 and 3; and 6) Combines heuristics 1 and 3.</p>
        <p>[71] Maximizes the number of satisfied IoT analytics. Prioritizes the scarcest resource first and the closer to source device next.[71] Maximizes the number of satisfied IoT analytics. Prioritizes the scarcest resource first and the closer to source device next.</p>
        <p>[75][75]</p>
        <p>Minimizes end-to-end delay. Elaborates a layered graph placement algorithm that proposes to find a lowest cost path that includes communication cost and processing cost.Minimizes end-to-end delay. Elaborates a layered graph placement algorithm that proposes to find a lowest cost path that includes communication cost and processing cost.</p>
        <p>[79] Minimizes maximum cost service node. Selects the mapping with the minimum total cost by iterating on the set of all possible mappings.[79] Minimizes maximum cost service node. Selects the mapping with the minimum total cost by iterating on the set of all possible mappings.</p>
        <p>[103] Minimizes network cost. Minimizes processing cost first and then optimizes the network cost.[103] Minimizes network cost. Minimizes processing cost first and then optimizes the network cost.</p>
        <p>[140] Optimizes utilization of network resources. Prioritizes the components placement based on the resource expectation.[140] Optimizes utilization of network resources. Prioritizes the components placement based on the resource expectation.</p>
        <p>[154] Minimises the average response time. Proposes three heuristics based on backtracking solution and the notion of anchor.[154] Minimises the average response time. Proposes three heuristics based on backtracking solution and the notion of anchor.</p>
        <p>C/On/S/nM Exact [19] Minimizes overall operational cost. Uses the linear programming solver 
            <rs type="software">Xpress-MP</rs>.
        </p>
        <p>[34] the application end-to-end latency. Uses the ILP solver.[34] the application end-to-end latency. Uses the ILP solver.</p>
        <p>Appro. [151] Minimizes the maximum weighted cost on network nodes and links.Appro. [151] Minimizes the maximum weighted cost on network nodes and links.</p>
        <p>Provides polynomial-logarithmic worst-case optimality bound. Splits the application graph into simple branches, and solve the problem recursively.Provides polynomial-logarithmic worst-case optimality bound. Splits the application graph into simple branches, and solve the problem recursively.</p>
        <p>Heuristic [12] Minimizes end-to-end latency. Breakdowns the latency calculation into computational latency and network transfer latency, and minimizes the sum.Heuristic [12] Minimizes end-to-end latency. Breakdowns the latency calculation into computational latency and network transfer latency, and minimizes the sum.</p>
        <p>[46] Minimizes the provisioning cost. Adopts a divide and conquer approach and incrementally computes the best solution.[46] Minimizes the provisioning cost. Adopts a divide and conquer approach and incrementally computes the best solution.</p>
        <p>[65] Determines an eligible application placement. Prioritizes interdependent components based on the computation cost and communication time.[65] Determines an eligible application placement. Prioritizes interdependent components based on the computation cost and communication time.</p>
        <p>[89] Minimizes the network delays between interrelated services while optimizing the QoS and the service availability for the users. Uses a first fit decreasing approach to place applications in device communities, and then prioritizes the applications with the shortest deadlines.[89] Minimizes the network delays between interrelated services while optimizing the QoS and the service availability for the users. Uses a first fit decreasing approach to place applications in device communities, and then prioritizes the applications with the shortest deadlines.</p>
        <p>[94] Minimizes energy consumption. Deploys the incoming application components to Fog resources based on the remaining CPU, energy consumption, and related deadline.[94] Minimizes energy consumption. Deploys the incoming application components to Fog resources based on the remaining CPU, energy consumption, and related deadline.</p>
        <p>[157] Minimizes the response time. Performs sequential quadratic programming and divides the problem into two sub-problems to minimize computational complexity.[157] Minimizes the response time. Performs sequential quadratic programming and divides the problem into two sub-problems to minimize computational complexity.</p>
        <p>C/On/Dy/nM Heuristic [97] Minimizes the network cost during the task assignment. Proposes to minimize first the processing cost and then optimizes the network cost.C/On/Dy/nM Heuristic [97] Minimizes the network cost during the task assignment. Proposes to minimize first the processing cost and then optimizes the network cost.</p>
        <p>Optimizes a multi-objectives function: Minimize cost, maximize user support, minimize latency, and maximize user footprint. Converts the multi-objective optimization problem to a single objective problem by using a scalarization method. And provides Pareto optimal solution.Optimizes a multi-objectives function: Minimize cost, maximize user support, minimize latency, and maximize user footprint. Converts the multi-objective optimization problem to a single objective problem by using a scalarization method. And provides Pareto optimal solution.</p>
        <p>[58] Minimizes the total makespan while meeting energy and QoS constraints. Proposes two prior GA meta-heuristics (GA-Incremental and GA-Global) to support dynamically the multiple dataflows arriving and departing.[58] Minimizes the total makespan while meeting energy and QoS constraints. Proposes two prior GA meta-heuristics (GA-Incremental and GA-Global) to support dynamically the multiple dataflows arriving and departing.</p>
        <p>C/On/Dy/M Heuristic [17] Minimizes the cost to run the application. Performs an iterative matching process and local search phase to compute the best solution.C/On/Dy/M Heuristic [17] Minimizes the cost to run the application. Performs an iterative matching process and local search phase to compute the best solution.</p>
        <p>[114] Minimizes the costs of migration and placement of a single component. Creates time-graph model and considers the shortest path from data source to identify possible migration nodes.[114] Minimizes the costs of migration and placement of a single component. Creates time-graph model and considers the shortest path from data source to identify possible migration nodes.</p>
        <p>Di/On/S/nM Heuristic [131] Minimizes the cost to run the application. Prioritizes the placement according to dependencies between the components and computational power of edge devices. Minimizes the average data traffic in the Edge environment. Exhaustive research is performed, i.e., enumerates all placements of service replica and selects the solution that minimizes the objective among all computed placement solutions.Di/On/S/nM Heuristic [131] Minimizes the cost to run the application. Prioritizes the placement according to dependencies between the components and computational power of edge devices. Minimizes the average data traffic in the Edge environment. Exhaustive research is performed, i.e., enumerates all placements of service replica and selects the solution that minimizes the objective among all computed placement solutions.</p>
        <p>Heuristic [167] Minimizes the overall latency of storing and retrieving data in a Fog. Splits the original service placement problem into set of subproblems each performing an optimal placement solution for one components.Heuristic [167] Minimizes the overall latency of storing and retrieving data in a Fog. Splits the original service placement problem into set of subproblems each performing an optimal placement solution for one components.</p>
        <p>[11] Maximizes the energy efficiency while maintaining the successful delivery. The provided algorithm proposes to categorize the services into three popularity levels and strategically cache them in Fog resources. Heuristic [166] Minimizes the maximum average task completion time. First, partition the problem on two sub-problems and optimize each of them. Then, re-couple the two solutions in order to optimize the main objective.[11] Maximizes the energy efficiency while maintaining the successful delivery. The provided algorithm proposes to categorize the services into three popularity levels and strategically cache them in Fog resources. Heuristic [166] Minimizes the maximum average task completion time. First, partition the problem on two sub-problems and optimize each of them. Then, re-couple the two solutions in order to optimize the main objective.</p>
        <p>[100] Achieves minimal latency in between the replicas and between the replicas and the data sources and sink. Exploits end-users and service locality in Fog network when deploying.[100] Achieves minimal latency in between the replicas and between the replicas and the data sources and sink. Exploits end-users and service locality in Fog network when deploying.</p>
        <p>Di/On/Dy/nM Heuristic [13] Defines a trade-off between cost and latency. Evaluates cost of storing replicas and expected latency improvement, to make a migration or duplication decision.Di/On/Dy/nM Heuristic [13] Defines a trade-off between cost and latency. Evaluates cost of storing replicas and expected latency improvement, to make a migration or duplication decision.</p>
        <p>[128][128]</p>
        <p>Maximizes the end-to-end performance. Provides bandwidth and availability-aware service placement policy. Based on the provided tables, we propose in the next section to discuss the open research directions and the challenges related to SPP in Fog Computing.Maximizes the end-to-end performance. Provides bandwidth and availability-aware service placement policy. Based on the provided tables, we propose in the next section to discuss the open research directions and the challenges related to SPP in Fog Computing.</p>
        <p>This section discusses the current limitations and highlights the challenges related to service placement problem in the Fog Computing. Three main directions that need attention in the near future are identified: challenges related to the problem statement, optimization strategies, and evaluation environment.This section discusses the current limitations and highlights the challenges related to service placement problem in the Fog Computing. Three main directions that need attention in the near future are identified: challenges related to the problem statement, optimization strategies, and evaluation environment.</p>
        <p>Despite the recent research efforts outlined on SPP, many challenges still remain open, and one of them concerns the "problem statement" i.e., which problematic we try to address (fits which scenario), which important information needs to be considered (infrastructure information, application description, mapping requirements), and under which aspects to address it (taxonomy). Here we present some of the identified open problems.Despite the recent research efforts outlined on SPP, many challenges still remain open, and one of them concerns the "problem statement" i.e., which problematic we try to address (fits which scenario), which important information needs to be considered (infrastructure information, application description, mapping requirements), and under which aspects to address it (taxonomy). Here we present some of the identified open problems.</p>
        <p>Based on the surveyed papers, we identified two main scenarios considered by the research community (see section 5.1), however, we noticed that for the most works that fit into the aforementioned scenarios, an important use-case was not really (and marginally) considered in SPP. It corresponds to "computation placement with data dependencies" that represents one of the problems that motivate the Fog since the goal of the Fog Computing is to keep the services close to the devices that produce and act on the data. Thus, when deploying services, the mapping must consider the dependencies at the data level, either in terms of locality (e.g., if a service is deployed in a particular zone, the related components must also be deployed in the same area for security reasons for instance) or in term of minimizing the flow of data exchanged, etc. Marginally addressed in the literature (to the best of our knowledge), the application placement with data dependencies represents real challenges that need to be more considered and studied.Based on the surveyed papers, we identified two main scenarios considered by the research community (see section 5.1), however, we noticed that for the most works that fit into the aforementioned scenarios, an important use-case was not really (and marginally) considered in SPP. It corresponds to "computation placement with data dependencies" that represents one of the problems that motivate the Fog since the goal of the Fog Computing is to keep the services close to the devices that produce and act on the data. Thus, when deploying services, the mapping must consider the dependencies at the data level, either in terms of locality (e.g., if a service is deployed in a particular zone, the related components must also be deployed in the same area for security reasons for instance) or in term of minimizing the flow of data exchanged, etc. Marginally addressed in the literature (to the best of our knowledge), the application placement with data dependencies represents real challenges that need to be more considered and studied.</p>
        <p>As mentioned earlier in the paper, distributing the making decisions to multiple substrate nodes instead of relying the mapping on a single central node helps to spread the load and possibly increasing scalability. With infrastructure such as Fog Computing, there is a tendency to believe that most works are based on this process. However, according to Tables 6, 7, 8, 9, 10, and 11 we observe that there is a lack of solutions proposed in the literature that address the SPP in distributed way. This is mainly due to that distributed algorithms are difficult to construct and their implementations are often non-trivial to achieve in a real environment due to the complexity of the inter-process communication and synchronization. Moreover, the lack of knowledge of the global state makes difficult to compute optimal solutions and even to reach near-optimal placement. We remark also that only a few approaches perform SPP in a distributed and dynamic way [13,73,128,150]. And still less that considers distributed solutions that handle dynamicity of the system and support mobility of end-users/FNs ( [73,150] for scenario 1.2). Thus, research in these directions is still open.As mentioned earlier in the paper, distributing the making decisions to multiple substrate nodes instead of relying the mapping on a single central node helps to spread the load and possibly increasing scalability. With infrastructure such as Fog Computing, there is a tendency to believe that most works are based on this process. However, according to Tables 6, 7, 8, 9, 10, and 11 we observe that there is a lack of solutions proposed in the literature that address the SPP in distributed way. This is mainly due to that distributed algorithms are difficult to construct and their implementations are often non-trivial to achieve in a real environment due to the complexity of the inter-process communication and synchronization. Moreover, the lack of knowledge of the global state makes difficult to compute optimal solutions and even to reach near-optimal placement. We remark also that only a few approaches perform SPP in a distributed and dynamic way [13,73,128,150]. And still less that considers distributed solutions that handle dynamicity of the system and support mobility of end-users/FNs ( [73,150] for scenario 1.2). Thus, research in these directions is still open.</p>
        <p>We detail hereafter some of the challenges and opportunities worth further research in terms of optimization strategies point of view.We detail hereafter some of the challenges and opportunities worth further research in terms of optimization strategies point of view.</p>
        <p>Depending on the studied problem and considered use-case, different metrics can be observed: Latency/bandwidth between end-user, robustness in case of failures, energy consumption/battery life cycle of the sensors, cost, application-specific metric (frame/packet loss, end-to-end delay in processing some data), etc. According to Table 1, we can easily observe that the performance metrics are usually taken as individual objectives (minimize latency, maximize the number of satisfied applications, minimize energy consumption, etc.). However, to improve QoS and QoE, these metrics should be simultaneously considered in the objective function, instead of integrating them into the model as constraints functions. Considering multiple objectives at the same time has not received significant attention so far. Due to the complexity of such problems, only a few works have attempted to address such issues [15,36,45,98,118,122,166]. Indeed, conduct multi-objective optimization and derive effective solutions requires a huge computational effort [37]. Multiobjective metaheuristics can be explored to solve such a problem, like MOPSO [68] and NSGA-II [42], or scheduling approaches like [53].Depending on the studied problem and considered use-case, different metrics can be observed: Latency/bandwidth between end-user, robustness in case of failures, energy consumption/battery life cycle of the sensors, cost, application-specific metric (frame/packet loss, end-to-end delay in processing some data), etc. According to Table 1, we can easily observe that the performance metrics are usually taken as individual objectives (minimize latency, maximize the number of satisfied applications, minimize energy consumption, etc.). However, to improve QoS and QoE, these metrics should be simultaneously considered in the objective function, instead of integrating them into the model as constraints functions. Considering multiple objectives at the same time has not received significant attention so far. Due to the complexity of such problems, only a few works have attempted to address such issues [15,36,45,98,118,122,166]. Indeed, conduct multi-objective optimization and derive effective solutions requires a huge computational effort [37]. Multiobjective metaheuristics can be explored to solve such a problem, like MOPSO [68] and NSGA-II [42], or scheduling approaches like [53].</p>
        <p>Due to the high mobility of some end-users and Fog devices, the elaborated solutions must ensure the continuity of the services and that the users always receive the desired requests. For this, the services must follow this mobility and perform some migrations across different Fog instances. When reviewing the literature, we observed that only a few works propose to provide a solution that supports the mobility of end-users/FNs (see Table 6). Moreover, most of the dynamic application migration approaches elaborated consider a restricted application topology (monolithic, line or tree graph), support only the mobility of end-users (not those of FNs), and developed dynamic solutions based on complex techniques and algorithms. In view of that, it is clear that the definition of standard algorithmic techniques appropriate for implementation in real Fog systems is a real need for the community. Moreover, we have observed that currently, most of the placement techniques that support mobility are reactive. Thus, addressing the problem from a proactive point of view by predicting the mobility pattern of users' and devices' could be more suitable in the Fog context. Indeed, understanding the movement behavior of end devices (or FN) may be helpful for an efficient service placement and service management in Fog Computing.Due to the high mobility of some end-users and Fog devices, the elaborated solutions must ensure the continuity of the services and that the users always receive the desired requests. For this, the services must follow this mobility and perform some migrations across different Fog instances. When reviewing the literature, we observed that only a few works propose to provide a solution that supports the mobility of end-users/FNs (see Table 6). Moreover, most of the dynamic application migration approaches elaborated consider a restricted application topology (monolithic, line or tree graph), support only the mobility of end-users (not those of FNs), and developed dynamic solutions based on complex techniques and algorithms. In view of that, it is clear that the definition of standard algorithmic techniques appropriate for implementation in real Fog systems is a real need for the community. Moreover, we have observed that currently, most of the placement techniques that support mobility are reactive. Thus, addressing the problem from a proactive point of view by predicting the mobility pattern of users' and devices' could be more suitable in the Fog context. Indeed, understanding the movement behavior of end devices (or FN) may be helpful for an efficient service placement and service management in Fog Computing.</p>
        <p>Regarding the energy consumption in Fog service management, we found that research is less prevalent in some aspects of energy consumption in the Fog environment. We identify the following factors: a model that considers the carbon footprint, uses renewable energy sources like wind turbines or solar panels, etc., take into account the energy-constrained of end devices (sensors) in terms of residual battery lifetime, the energy of communication links; etc. The use of Follow the Sun and Follow the Moon strategies in these cases could be helpful to manage efficiently the energy consumption, for instance by controlling the devices in terms of intelligent lighting, ventilation, and air conditioning, etc.Regarding the energy consumption in Fog service management, we found that research is less prevalent in some aspects of energy consumption in the Fog environment. We identify the following factors: a model that considers the carbon footprint, uses renewable energy sources like wind turbines or solar panels, etc., take into account the energy-constrained of end devices (sensors) in terms of residual battery lifetime, the energy of communication links; etc. The use of Follow the Sun and Follow the Moon strategies in these cases could be helpful to manage efficiently the energy consumption, for instance by controlling the devices in terms of intelligent lighting, ventilation, and air conditioning, etc.</p>
        <p>It is clearly seen in Section 4.3 that many formulation and solutions are developed to address the SPP for a specific application. These placement policies, given in the literature (mainly heuristics), consider different assumptions (infrastructure information, application topology, QoS attributes and metrics, . . . ), different objectives, that make them not easily comparable. Indeed, given the diversity of criteria, handling all these parameters is practically impossible. So, the questions arising today are: which criteria are most significant and should be considered in order to develop an effective solution? according to these criteria can we compare the existing proposals and identify the relevant approaches? or should we make a clean sweep and propose a new generic and easy to upgrade methodology?. Many open issues that deserve to be deepened.It is clearly seen in Section 4.3 that many formulation and solutions are developed to address the SPP for a specific application. These placement policies, given in the literature (mainly heuristics), consider different assumptions (infrastructure information, application topology, QoS attributes and metrics, . . . ), different objectives, that make them not easily comparable. Indeed, given the diversity of criteria, handling all these parameters is practically impossible. So, the questions arising today are: which criteria are most significant and should be considered in order to develop an effective solution? according to these criteria can we compare the existing proposals and identify the relevant approaches? or should we make a clean sweep and propose a new generic and easy to upgrade methodology?. Many open issues that deserve to be deepened.</p>
        <p>We propose to describe here one of the challenges that in our opinion is the most important regarding the evaluation environments' point of view.We propose to describe here one of the challenges that in our opinion is the most important regarding the evaluation environments' point of view.</p>
        <p>Through Table 4, we can easily observe that different tools are used by the research community to test and perform their experiments. Each tool has its own specificities and is adapted to a given problem (use-case) as described in Section 4.4. While there are a number of works that have addressed the SPP challenge, we notice that there does not yet a generic development environment that handles a large range of standardized IoT applications and allows considering various network topologies. So, there is a requirement of making a uniform platform involving most of the concepts, easy to take in hand and that favors the realization of extensive experiences. Based on the classification scheme and the scenarios provided in Section 5.1, our contribution through this paper consists to bring some basics on which we can rely to design a generic and extensible model that will take over the different Fog Computing use cases.Through Table 4, we can easily observe that different tools are used by the research community to test and perform their experiments. Each tool has its own specificities and is adapted to a given problem (use-case) as described in Section 4.4. While there are a number of works that have addressed the SPP challenge, we notice that there does not yet a generic development environment that handles a large range of standardized IoT applications and allows considering various network topologies. So, there is a requirement of making a uniform platform involving most of the concepts, easy to take in hand and that favors the realization of extensive experiences. Based on the classification scheme and the scenarios provided in Section 5.1, our contribution through this paper consists to bring some basics on which we can rely to design a generic and extensible model that will take over the different Fog Computing use cases.</p>
        <p>This paper focuses on the Service Placement Problem (SPP) in a Fog environment, which is currently an open issue that calls for extensive discussions and solutions. This paper gives a survey of current works. A description of the SPP was provided. Five scenarios related to this issue were identified. A categorization of solutions along four distinct dimensions (centralized vs. distributed control plan, offline vs. online scheduling, static vs. dynamic system, not support vs. support mobility of endusers/fog nodes) was elaborated. A number of algorithmic proposals to the SPP were discussed. Finally, these aspects were used to create a classification of SPP solutions elaborated in the literature based on placement taxonomy. More precisely and compared to existing surveys, our work highlights a new classification scheme which aims to simplify the user's access to references in a specific context and identify more easily the placement-related challenges.This paper focuses on the Service Placement Problem (SPP) in a Fog environment, which is currently an open issue that calls for extensive discussions and solutions. This paper gives a survey of current works. A description of the SPP was provided. Five scenarios related to this issue were identified. A categorization of solutions along four distinct dimensions (centralized vs. distributed control plan, offline vs. online scheduling, static vs. dynamic system, not support vs. support mobility of endusers/fog nodes) was elaborated. A number of algorithmic proposals to the SPP were discussed. Finally, these aspects were used to create a classification of SPP solutions elaborated in the literature based on placement taxonomy. More precisely and compared to existing surveys, our work highlights a new classification scheme which aims to simplify the user's access to references in a specific context and identify more easily the placement-related challenges.</p>
        <p>,,</p>
        <p>[45][45]</p>
        <p>* ,* ,</p>
        <p>[46, 50, 57, 58, 62, 69, 71, 72, 75, 77, 79, 81, 86-89, 93, 94, 96, 97, 101-103, 107, 108, 115, 117, 127, 129, 132-135, 137, 139- 141, 143, 145, 147-151, 154, 157, 161-164][46, 50, 57, 58, 62, 69, 71, 72, 75, 77, 79, 81, 86-89, 93, 94, 96, 97, 101-103, 107, 108, 115, 117, 127, 129, 132-135, 137, 139- 141, 143, 145, 147-151, 154, 157, 161-164]</p>
        <p>,,</p>
        <p>[166][166]</p>
        <p>* ,* ,</p>
        <p>[167][167]</p>
        <p>Multi-ObjectivesMulti-Objectives</p>
        <p>[15,36][15,36]</p>
        <p>, [45] * , [98, 118, 122], [166] * Metrics References Latency [7, 12, 13, 15, 20, 26, 43, 50, 55, 58, 75, 85-87, 89, 98, 107, 108, 113, 115, 118, 119, 124, 137, 139, 140, 143, 147, 150, 154, 157, 161, 162, 166], [45] * , [98, 118, 122], [166] * Metrics References Latency [7, 12, 13, 15, 20, 26, 43, 50, 55, 58, 75, 85-87, 89, 98, 107, 108, 113, 115, 118, 119, 124, 137, 139, 140, 143, 147, 150, 154, 157, 161, 162, 166]</p>
        <p>Resource utilizationResource utilization</p>
        <p>[10,15,16,71,72,81,88,88,102,117,122,[133][134][135]148][10,15,16,71,72,81,88,88,102,117,122,[133][134][135]148]</p>
        <p>CostCost</p>
        <p>[13-15, 17, 19, 28, 34, 36, 46, 57, 62, 69, 71, 79, 98, 103, 112, 114, 118, 132, 145, 149, 151, 156, 163, 168][13-15, 17, 19, 28, 34, 36, 46, 57, 62, 69, 71, 79, 98, 103, 112, 114, 118, 132, 145, 149, 151, 156, 163, 168]</p>
        <p>Energy consumptionEnergy consumption</p>
        <p>[11, 15, 26, 43-45, 94, 94, 98, 101, 113, 122-124, 141][11, 15, 26, 43-45, 94, 94, 98, 101, 113, 122-124, 141]</p>
        <p>• Integer NonLinear Programming (INLP) An integer nonlinear program is an ILP which present nonlinear constraints. For instance, in [163], Yousefpour et al. formulate the dynamic Fog service provisioning problem as an INLP. • Mixed Integer Linear Programming (MILP) / Mixed Integer NonLinear Programming (MINLP) The class of a problem known as a Mixed Integer Programming Problem assumes• Integer NonLinear Programming (INLP) An integer nonlinear program is an ILP which present nonlinear constraints. For instance, in [163], Yousefpour et al. formulate the dynamic Fog service provisioning problem as an INLP. • Mixed Integer Linear Programming (MILP) / Mixed Integer NonLinear Programming (MINLP) The class of a problem known as a Mixed Integer Programming Problem assumes</p>
        <p>A classification of SPP according to service placement taxonomy. The mark means that the criterion is met; otherwise the criterion is not met or not considered.A classification of SPP according to service placement taxonomy. The mark means that the criterion is met; otherwise the criterion is not met or not considered.</p>
        <p>https://github.com/di-unipi-socc/FogTorchhttps://github.com/di-unipi-socc/FogTorch</p>
        <p>https://www-01.ibm.com/software/commerce/optimization/ cplex-optimizer/.https://www-01.ibm.com/software/commerce/optimization/ cplex-optimizer/.</p>
        <p>http://www.gurobi.comhttp://www.gurobi.com</p>
        <p>http://www.choco-solver.orghttp://www.choco-solver.org</p>
        <p>https://github.com/simgrid/simgridhttps://github.com/simgrid/simgrid</p>
        <p>https://omnetpp.org/https://omnetpp.org/</p>
    </text>
</tei>
