<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-13T09:37+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>Context-dependent biological variation presents a unique challenge to the reproducibility of results in experimental animal research, because organisms' responses to experimental treatments can vary with both genotype and environmental conditions. In March 2019, experts in animal biology, experimental design and statistics convened in Blonay, Switzerland, to discuss strategies addressing this challenge. In contrast to the current gold standard of rigorous standardization in experimental animal research, we recommend the use of systematic heterogenization of study samples and conditions by actively incorporating biological variation into study design through diversifying study samples and conditions. Here we provide the scientific rationale for this approach in the hope that researchers, regulators, funders and editors can embrace this paradigm shift. We also present a road map towards better practices in view of improving the reproducibility of animal research.Context-dependent biological variation presents a unique challenge to the reproducibility of results in experimental animal research, because organisms' responses to experimental treatments can vary with both genotype and environmental conditions. In March 2019, experts in animal biology, experimental design and statistics convened in Blonay, Switzerland, to discuss strategies addressing this challenge. In contrast to the current gold standard of rigorous standardization in experimental animal research, we recommend the use of systematic heterogenization of study samples and conditions by actively incorporating biological variation into study design through diversifying study samples and conditions. Here we provide the scientific rationale for this approach in the hope that researchers, regulators, funders and editors can embrace this paradigm shift. We also present a road map towards better practices in view of improving the reproducibility of animal research.</p>
        <p>Since the seventeenth century, the ability to reproduce research findings has been the acid test by which scientists distinguish facts from mere anecdotes 1 . Reproducibilitydefined here as the ability to produce similar results by independent replicate studies -is thus a cornerstone of the scientific method. Recent investigations, however, have shown that the reproducibility of research findings is poor across virtually all disciplines of research [2][3][4][5][6][7][8][9] . It is crucial to identify the causes of poor reproducibility and implement effective strategies for improvement for scientific, economic and ethical reasons.Since the seventeenth century, the ability to reproduce research findings has been the acid test by which scientists distinguish facts from mere anecdotes 1 . Reproducibilitydefined here as the ability to produce similar results by independent replicate studies -is thus a cornerstone of the scientific method. Recent investigations, however, have shown that the reproducibility of research findings is poor across virtually all disciplines of research [2][3][4][5][6][7][8][9] . It is crucial to identify the causes of poor reproducibility and implement effective strategies for improvement for scientific, economic and ethical reasons.</p>
        <p>The reproducibility of preclinical research involving animal models is deemed to be especially poor 10 . More than half of the published findings in this area are considered irreproducible, representing a cost of US$28 billion per year in the USA alone 11 . Additional resources are used on often fruitless follow-up studies, which in turn generate opportunity costs by preventing researchers from following more promising research avenues or leading to time lost in scientific dead ends. These economic and scientific costs are associated with significant ethical issues. In biomedicalThe reproducibility of preclinical research involving animal models is deemed to be especially poor 10 . More than half of the published findings in this area are considered irreproducible, representing a cost of US$28 billion per year in the USA alone 11 . Additional resources are used on often fruitless follow-up studies, which in turn generate opportunity costs by preventing researchers from following more promising research avenues or leading to time lost in scientific dead ends. These economic and scientific costs are associated with significant ethical issues. In biomedical</p>
        <p>Sources of biological variation. Variation is ubiquitous in nature, and even casual observations reveal that individual organisms differ in numerous phenotypic traits. Such phenotypic variation reflects the combined effects of the organisms' genotypes and their responses to the environment, integrated over their lifetimes [13][14][15][16] . Phenotypic variation covers all levels of organization from molecular mechanisms to behaviour. There are many biological causes of phenotypic variation besides genetic differences, including developmental stage or age, early experience and social status. Variation owing to the environment is complex and varies with time, spatial scale (for example, climate) and the nature of environmental factors (for example, food, predators, mates and environmental toxins). The norm of reaction describes the relationship between one or more environmental factors and the phenotype for a given genotype 17,18 , and such norms of reaction may differ among genotypes (Box 1). Thus, it is not uncommon for different genotypes to respond differently to environmental factors 19 . The effects of environmental factors accumulated over a lifetime may not be easily detectable by morphological, physiological or behavioural analysis, although they may leave a unique fingerprint on gene and protein expression levels, thereby contributing to the finetuning of the phenotype 20 . Recent advances in the study of epigenetics have added a layer of complexity to our understanding of the interactions between genotype and environment in the expression of phenotypic plasticity 21,22 .Sources of biological variation. Variation is ubiquitous in nature, and even casual observations reveal that individual organisms differ in numerous phenotypic traits. Such phenotypic variation reflects the combined effects of the organisms' genotypes and their responses to the environment, integrated over their lifetimes [13][14][15][16] . Phenotypic variation covers all levels of organization from molecular mechanisms to behaviour. There are many biological causes of phenotypic variation besides genetic differences, including developmental stage or age, early experience and social status. Variation owing to the environment is complex and varies with time, spatial scale (for example, climate) and the nature of environmental factors (for example, food, predators, mates and environmental toxins). The norm of reaction describes the relationship between one or more environmental factors and the phenotype for a given genotype 17,18 , and such norms of reaction may differ among genotypes (Box 1). Thus, it is not uncommon for different genotypes to respond differently to environmental factors 19 . The effects of environmental factors accumulated over a lifetime may not be easily detectable by morphological, physiological or behavioural analysis, although they may leave a unique fingerprint on gene and protein expression levels, thereby contributing to the finetuning of the phenotype 20 . Recent advances in the study of epigenetics have added a layer of complexity to our understanding of the interactions between genotype and environment in the expression of phenotypic plasticity 21,22 .</p>
        <p>In experimental animal research, the effect of a treatment is typically measured at the level of the phenotype. It can be thought of as the plastic response of some phenotype (the animal model) to the experimental treatment. Without plasticity in response to a treatment (for example, the administration of a drug or a genetic manipulation), there would be no treatment effect (that is, an effect size of zero). However, the direction and magnitude of a treatment effect depend not only on the nature, duration and intensity of the treatment but also on the animal's current phenotype and the experimental context 23,24 . research, poor reproducibility not only attenuates medical progress but also harms animals subjected to inconclusive studies and potentially puts patients who are enrolled in clinical trials at risk.In experimental animal research, the effect of a treatment is typically measured at the level of the phenotype. It can be thought of as the plastic response of some phenotype (the animal model) to the experimental treatment. Without plasticity in response to a treatment (for example, the administration of a drug or a genetic manipulation), there would be no treatment effect (that is, an effect size of zero). However, the direction and magnitude of a treatment effect depend not only on the nature, duration and intensity of the treatment but also on the animal's current phenotype and the experimental context 23,24 . research, poor reproducibility not only attenuates medical progress but also harms animals subjected to inconclusive studies and potentially puts patients who are enrolled in clinical trials at risk.</p>
        <p>Current discussions about the causes of poor reproducibility in animal research focus mainly on violations of good research practice, including a lack of scientific rigour, low statistical power, analytical flexibility (for example, P-hacking) and publication bias 2,5,12 . In this Perspective, we argue that, besides violations of good research practice, a major cause of poor reproducibility in animal research is a persistent disregard for the nature of biological variation in study design. We explain where biological variation comes from, how it differs from random noise and why it causes issues with reproducibility. We then discuss why current research practice is inadequate for dealing with biological variation and call for a paradigm shift in experimental design to improve reproducibility in animal research. Specifically, we propose diversification of study subjects through deliberate heterogenization of environmental factors as a measure of good experimental design.Current discussions about the causes of poor reproducibility in animal research focus mainly on violations of good research practice, including a lack of scientific rigour, low statistical power, analytical flexibility (for example, P-hacking) and publication bias 2,5,12 . In this Perspective, we argue that, besides violations of good research practice, a major cause of poor reproducibility in animal research is a persistent disregard for the nature of biological variation in study design. We explain where biological variation comes from, how it differs from random noise and why it causes issues with reproducibility. We then discuss why current research practice is inadequate for dealing with biological variation and call for a paradigm shift in experimental design to improve reproducibility in animal research. Specifically, we propose diversification of study subjects through deliberate heterogenization of environmental factors as a measure of good experimental design.</p>
        <p>As phenotypes are complex and influenced by many interacting factors, the effect of the independent variable (for example, the experimental treatment) on an outcome variable (the dependent variable) is also context dependent. Thus, experimental results vary with both the internal state of animals (determined by genotype and experiences throughout development) and the external environmental factors (the environment in which the experiment is conducted). Environmental factors may interact additively or synergistically with the internal state of the animals, shaping their responses to the experimental treatment in specific ways (Fig. 1).As phenotypes are complex and influenced by many interacting factors, the effect of the independent variable (for example, the experimental treatment) on an outcome variable (the dependent variable) is also context dependent. Thus, experimental results vary with both the internal state of animals (determined by genotype and experiences throughout development) and the external environmental factors (the environment in which the experiment is conducted). Environmental factors may interact additively or synergistically with the internal state of the animals, shaping their responses to the experimental treatment in specific ways (Fig. 1).</p>
        <p>In laboratory animal research, current best practice for dealing with biological variation is strict standardization of both the animals and their environment [25][26][27] . Standardization in animal experimentation has been described as "the defining of the properties of any given animal (or animal population) and its environment, together with the subsequent task of keeping the properties constant" 25 . It is intended, first, to reduce within-experiment variability so as to increase statistical power and, second, to reduce between-experiment variability so as to "increase the reproducibility of group mean results from one experiment to another", thereby "improv[ing] comparability of results within and between laboratories" 25 . "The defining of Phenotypic variation among and within individuals typically reflects the combined effects of genetic differences and environmentally induced variation [13][14][15][16] . When there is no plasticity (that is, the norms of reaction are flat), phenotypic differences among genotypes are robust across environmental conditions (see the figure, part a; the blue, purple and red lines in parts a-c represent distinct genotypes). However, the relative importance of environmentally induced phenotypic variation is highly context dependent and typically varies among populations, traits and genotypes.In laboratory animal research, current best practice for dealing with biological variation is strict standardization of both the animals and their environment [25][26][27] . Standardization in animal experimentation has been described as "the defining of the properties of any given animal (or animal population) and its environment, together with the subsequent task of keeping the properties constant" 25 . It is intended, first, to reduce within-experiment variability so as to increase statistical power and, second, to reduce between-experiment variability so as to "increase the reproducibility of group mean results from one experiment to another", thereby "improv[ing] comparability of results within and between laboratories" 25 . "The defining of Phenotypic variation among and within individuals typically reflects the combined effects of genetic differences and environmentally induced variation [13][14][15][16] . When there is no plasticity (that is, the norms of reaction are flat), phenotypic differences among genotypes are robust across environmental conditions (see the figure, part a; the blue, purple and red lines in parts a-c represent distinct genotypes). However, the relative importance of environmentally induced phenotypic variation is highly context dependent and typically varies among populations, traits and genotypes.</p>
        <p>When the norms of reaction for different genotypes have parallel positive or negative slopes (see the figure, part b), the plastic responses induced by the environment are shared and phenotypic distributions reflect the combined effects of genetic and environmental variation. The sensitivity or responsiveness of phenotypic expression can vary among environmental components. A given phenotypic trait may show a plastic response to some environmental factors while being insensitive to others. Similarly, a given environmental factor may induce a plastic response in some phenotypic trait or traits, while the development of other traits may be robust and independent of the same factor. The phenotypic response induced by an environ mental factor can also be genotype specific, in which case the phenotypic variation in a population depends on the joint effects of genetic variation, phenotypic plasticity and genetic variation in plasticity. When the reaction norms vary among genotypes, there is genetic variation in plasticity (that is, gene × environment interactions (G×e)), meaning that the plastic response induced by the environmental factor varies according to genotype (see the figure ,part c).When the norms of reaction for different genotypes have parallel positive or negative slopes (see the figure, part b), the plastic responses induced by the environment are shared and phenotypic distributions reflect the combined effects of genetic and environmental variation. The sensitivity or responsiveness of phenotypic expression can vary among environmental components. A given phenotypic trait may show a plastic response to some environmental factors while being insensitive to others. Similarly, a given environmental factor may induce a plastic response in some phenotypic trait or traits, while the development of other traits may be robust and independent of the same factor. The phenotypic response induced by an environ mental factor can also be genotype specific, in which case the phenotypic variation in a population depends on the joint effects of genetic variation, phenotypic plasticity and genetic variation in plasticity. When the reaction norms vary among genotypes, there is genetic variation in plasticity (that is, gene × environment interactions (G×e)), meaning that the plastic response induced by the environmental factor varies according to genotype (see the figure ,part c).</p>
        <p>The norm of reaction describes, for a specific genotype, how the distribution of an environmental factor is translated into a phenotypic distribution. This means that even in genetically homogeneous populations, such as inbred laboratory strains, the patterns of phenotypic variation can vary depending on the environment. A con tinuous,normallydistributedenvironmentalvariationcangenerate, for example, a continuous, skewed phenotype distribution (see the figure, part d). However, for threshold traits with a step-shaped reaction norm, continuous environmental distributions can also generate discrete (categorical) or bimodal phenotypic trait distributions for a single genotype (see the figure ,part e). Here the expression of a phenotypic trait changes from one state to another at some critical level, dosage, intensity or concentration in the environment. The critical level that induces the phenotypic shift from one state to another (for example, response or no response) may vary among genotypes. In other cases, bimodal or multimodal trait distributions may manifest themselves in populations that comprise different genotypes, regardless of whether they show or do not show plasticity (see the figure, part f). Furthermore, a given phenotypic trait may display a discrete or bimodal frequency distribution if the genotype or genetically homogeneous strain is exposed to a discrete or bimodally distributed environment (see the figure, part g). A practical implication of such context-dependent responsiveness is that the phenotypic responses induced by a specific experimental treatment (for example, intervention studies designed to evaluate drug responsiveness) may vary between trials conducted in different laboratories. The importance and consequences of developmental plasticity, phenotypic flexibility and genotype-environment interactions are well established in quantitative genetics and evolutionary ecology, and can explain why different studies may generate conflicting outcomes. the properties" does not necessarily imply identical environmental conditions for all animals of a study population, and other definitions of standardization exist that refer to "the setting of, and compliance with, standards" rather than making everything the same (for example, see ReF. 28 ). However, in laboratory animal experimentation, standardization is generally equated with such homogenization [29][30][31][32] , and throughout this article the term 'standardization' refers to the homogenization of study populations. As a result, standardization renders animals within experiments more homogenous and thus less variable. Reduced variation in the results increases statistical power and allows a reduction of sample size (to detect a given effect size). Therefore, standardization has been advocated also for ethical reasons as a means of reducing animal use as required by the 3Rs principles (replace, reduce, refine) 31,[33][34][35][36] .The norm of reaction describes, for a specific genotype, how the distribution of an environmental factor is translated into a phenotypic distribution. This means that even in genetically homogeneous populations, such as inbred laboratory strains, the patterns of phenotypic variation can vary depending on the environment. A con tinuous,normallydistributedenvironmentalvariationcangenerate, for example, a continuous, skewed phenotype distribution (see the figure, part d). However, for threshold traits with a step-shaped reaction norm, continuous environmental distributions can also generate discrete (categorical) or bimodal phenotypic trait distributions for a single genotype (see the figure ,part e). Here the expression of a phenotypic trait changes from one state to another at some critical level, dosage, intensity or concentration in the environment. The critical level that induces the phenotypic shift from one state to another (for example, response or no response) may vary among genotypes. In other cases, bimodal or multimodal trait distributions may manifest themselves in populations that comprise different genotypes, regardless of whether they show or do not show plasticity (see the figure, part f). Furthermore, a given phenotypic trait may display a discrete or bimodal frequency distribution if the genotype or genetically homogeneous strain is exposed to a discrete or bimodally distributed environment (see the figure, part g). A practical implication of such context-dependent responsiveness is that the phenotypic responses induced by a specific experimental treatment (for example, intervention studies designed to evaluate drug responsiveness) may vary between trials conducted in different laboratories. The importance and consequences of developmental plasticity, phenotypic flexibility and genotype-environment interactions are well established in quantitative genetics and evolutionary ecology, and can explain why different studies may generate conflicting outcomes. the properties" does not necessarily imply identical environmental conditions for all animals of a study population, and other definitions of standardization exist that refer to "the setting of, and compliance with, standards" rather than making everything the same (for example, see ReF. 28 ). However, in laboratory animal experimentation, standardization is generally equated with such homogenization [29][30][31][32] , and throughout this article the term 'standardization' refers to the homogenization of study populations. As a result, standardization renders animals within experiments more homogenous and thus less variable. Reduced variation in the results increases statistical power and allows a reduction of sample size (to detect a given effect size). Therefore, standardization has been advocated also for ethical reasons as a means of reducing animal use as required by the 3Rs principles (replace, reduce, refine) 31,[33][34][35][36] .</p>
        <p>There are two main problems with this conception of standardization as applied to laboratory animal research. It is based on the confusion of biological variation with extraneous noise and on the myth of a pure treatment effect that 'emerges' as more sources of variation are eliminated. Whereas standardization can be an effective means to reduce extraneous noise (for example, measurement error and undesirable environmental effects), it fails to address biological variation. Since variation is a fundamental property of any population of organisms, treatment effects can be assessed and interpreted meaningfully only against biological variation -including gene × environment interactions. Owing to context-dependent variability in responses to treatment (Box 1), there is no such thing as a pure treatment effect for a population of living organisms. Any definition of a target population, therefore, needs to consider the range of genotypic and environmental variation for which the inferences of a study should be valid (the inference space). Studies that are too narrowly defined cannot reliably be generalized: if only males are included, the results may differ in meaningful ways in females 37,38 ; the responses of a single inbred strain may not hold for other strains 39,40 ; and mice housed in isolation might respond differently to certain drug treatments than individuals housed in groups 41 . Although extension of the inference space has been discussed specifically with regard to genetic variation and the inclusion of both sexes in preclinical animal studies (Box 2,Box 3), here we argue that this discussion should be extended to diversification of environmental conditions.There are two main problems with this conception of standardization as applied to laboratory animal research. It is based on the confusion of biological variation with extraneous noise and on the myth of a pure treatment effect that 'emerges' as more sources of variation are eliminated. Whereas standardization can be an effective means to reduce extraneous noise (for example, measurement error and undesirable environmental effects), it fails to address biological variation. Since variation is a fundamental property of any population of organisms, treatment effects can be assessed and interpreted meaningfully only against biological variation -including gene × environment interactions. Owing to context-dependent variability in responses to treatment (Box 1), there is no such thing as a pure treatment effect for a population of living organisms. Any definition of a target population, therefore, needs to consider the range of genotypic and environmental variation for which the inferences of a study should be valid (the inference space). Studies that are too narrowly defined cannot reliably be generalized: if only males are included, the results may differ in meaningful ways in females 37,38 ; the responses of a single inbred strain may not hold for other strains 39,40 ; and mice housed in isolation might respond differently to certain drug treatments than individuals housed in groups 41 . Although extension of the inference space has been discussed specifically with regard to genetic variation and the inclusion of both sexes in preclinical animal studies (Box 2,Box 3), here we argue that this discussion should be extended to diversification of environmental conditions.</p>
        <p>Outcomes, both the main effects of treatments and treatment × environment interactions, that are stable under large biological variation are considered to be robust 42 and may be characterized by the same flat norm of reaction for all genotypes and all variants of environmental factors (Box 1; Fig. 1). However, such cases of universal robustness are probably rare exceptions rather than the rule. In most cases, treatment effects will vary depending on a set of both genetic and environmental factors. Such modulating effects can be highly specific and unexpected. For example, a change from open cages to individually ventilated cages altered outcomes in a mouse model of infection-mediated neurodevelopmental disorders 43 , the behavioural sensitivity of wild-type mice 44,45 and the behavioural phenotype of a validated mutant neuregulin 1 mouse model for schizophrenia 46 but not the behavioural phenotypes of three commonly used inbred mouse strains 47 . Knowledge of context-dependent variation of treatment effects is a crucial aspect of scientific evidence. It is necessary for identifying the target population, as well as the conditions under which a finding is likely to be reproducible 24 . It is also key for translational research and the very basis of precision medicine 23,[48][49][50] .Outcomes, both the main effects of treatments and treatment × environment interactions, that are stable under large biological variation are considered to be robust 42 and may be characterized by the same flat norm of reaction for all genotypes and all variants of environmental factors (Box 1; Fig. 1). However, such cases of universal robustness are probably rare exceptions rather than the rule. In most cases, treatment effects will vary depending on a set of both genetic and environmental factors. Such modulating effects can be highly specific and unexpected. For example, a change from open cages to individually ventilated cages altered outcomes in a mouse model of infection-mediated neurodevelopmental disorders 43 , the behavioural sensitivity of wild-type mice 44,45 and the behavioural phenotype of a validated mutant neuregulin 1 mouse model for schizophrenia 46 but not the behavioural phenotypes of three commonly used inbred mouse strains 47 . Knowledge of context-dependent variation of treatment effects is a crucial aspect of scientific evidence. It is necessary for identifying the target population, as well as the conditions under which a finding is likely to be reproducible 24 . It is also key for translational research and the very basis of precision medicine 23,[48][49][50] .</p>
        <p>Reproducibility is assessed by comparing the results of independent replicate studies 12,51 . The conditions of any two studies are never exactly the same, even when researchers go to great lengths to harmonize the characteristics of animals, housing conditions, experimental protocols and test conditions 24,[51][52][53] . Differences are unavoidable since the animals, the personnel interacting with the animals, the animals' microbiome and many other factors resist standardization 39,[54][55][56][57][58][59][60] . Different laboratories, therefore, inevitably standardize these variables to different local study contexts, producing increasingly distinct study populations as standardization gets more rigorous. With every additional variable that is standardized, one risks that the inference space of a study (and with it the external validity of its results) decreases 29,61,62 . This misguided attempt to enhance reproducibility at the expense of external validity is referred to as the 'standardization fallacy' 63 . Although direct evidence for the standardization fallacy is currently limited to simulations across replicate studies 29,62,64 and only a few dedicated experimental studies 65,66 , there is indirect evidence showing, for example, that the experimenter or the laboratory may account for most of the variation in outcome measures across replicate studies within or between laboratories, respectively 23,52 .Reproducibility is assessed by comparing the results of independent replicate studies 12,51 . The conditions of any two studies are never exactly the same, even when researchers go to great lengths to harmonize the characteristics of animals, housing conditions, experimental protocols and test conditions 24,[51][52][53] . Differences are unavoidable since the animals, the personnel interacting with the animals, the animals' microbiome and many other factors resist standardization 39,[54][55][56][57][58][59][60] . Different laboratories, therefore, inevitably standardize these variables to different local study contexts, producing increasingly distinct study populations as standardization gets more rigorous. With every additional variable that is standardized, one risks that the inference space of a study (and with it the external validity of its results) decreases 29,61,62 . This misguided attempt to enhance reproducibility at the expense of external validity is referred to as the 'standardization fallacy' 63 . Although direct evidence for the standardization fallacy is currently limited to simulations across replicate studies 29,62,64 and only a few dedicated experimental studies 65,66 , there is indirect evidence showing, for example, that the experimenter or the laboratory may account for most of the variation in outcome measures across replicate studies within or between laboratories, respectively 23,52 .</p>
        <p>Results can be reproduced successfully only if they are robust against the variation that exists between independent replicate studies. It is therefore not surprising that standardization has invariably been found to be a cause of, rather than a cure for, poor reproducibility [65][66][67][68] (but see ReFs 69,70 for a critical analysis of ReF. 66 ). Eliminating biological variation through the use of standardization to narrow the inference space of a specific animal phenotype may, therefore, be a highly inefficient strategy for generating scientific evidence. It is akin to the atomization of animal research by investigating each specific gene × environment interaction in a separate experiment, thereby minimizing the information gain per experiment to virtually zero. The detection of robust and reproducible effects of interventions would thus require a very large number of independent replicate studies and rely entirely on meta-analysis. The other extreme, however, is not an efficient strategy either. Incorporating the full range of both genetic and environmental variation into the design of every experiment would render experiments unmanageable. A key challenge for future research is thus to find the right balance between biological complexity and experimental tractability. The following section presents approaches to account for biological variation in view of the limitations set by these two extremes.Results can be reproduced successfully only if they are robust against the variation that exists between independent replicate studies. It is therefore not surprising that standardization has invariably been found to be a cause of, rather than a cure for, poor reproducibility [65][66][67][68] (but see ReFs 69,70 for a critical analysis of ReF. 66 ). Eliminating biological variation through the use of standardization to narrow the inference space of a specific animal phenotype may, therefore, be a highly inefficient strategy for generating scientific evidence. It is akin to the atomization of animal research by investigating each specific gene × environment interaction in a separate experiment, thereby minimizing the information gain per experiment to virtually zero. The detection of robust and reproducible effects of interventions would thus require a very large number of independent replicate studies and rely entirely on meta-analysis. The other extreme, however, is not an efficient strategy either. Incorporating the full range of both genetic and environmental variation into the design of every experiment would render experiments unmanageable. A key challenge for future research is thus to find the right balance between biological complexity and experimental tractability. The following section presents approaches to account for biological variation in view of the limitations set by these two extremes.</p>
        <p>In contrast to the current practice of dogmatic standardization, we advocate systematic heterogenization of animal subjects by deliberately incorporating known sources of biological variation in study designs. Heterogenization may be based on controlled variation, for instance by systematically varying the genotype (for example, both sexes or several inbred strains), the state and history of the individual (for example, different housing conditions or different age classes), or the test condition (for example, different test times or alternative test systems). Alternatively, heterogenization may be based on uncontrolled variation, for example by using outbred study populations, by splitting experiments into multiple independent batches of animals or by conducting multilaboratory studies. These different types of heterogenization, as well as rigorous standardization, have their place in research, as outlined in more detail next.In contrast to the current practice of dogmatic standardization, we advocate systematic heterogenization of animal subjects by deliberately incorporating known sources of biological variation in study designs. Heterogenization may be based on controlled variation, for instance by systematically varying the genotype (for example, both sexes or several inbred strains), the state and history of the individual (for example, different housing conditions or different age classes), or the test condition (for example, different test times or alternative test systems). Alternatively, heterogenization may be based on uncontrolled variation, for example by using outbred study populations, by splitting experiments into multiple independent batches of animals or by conducting multilaboratory studies. These different types of heterogenization, as well as rigorous standardization, have their place in research, as outlined in more detail next.</p>
        <p>Study design is often taught as if each experiment were a fully independent and conclusive study. However, most experiments are part of research programmes including a series of experiments, each providing incremental gains of knowledge that guide the next steps in the programme 71,72 . Ideally, research into new and unexplored areas begins with exploratory studies that can be used to generate and select hypotheses worthy of further investigation 73,74 . Such hypotheses may then be tested in confirmatory studies to establish proof of concept, followed by studies assessing the generalizability of the findings. However, often there is no clear distinction between exploratory and confirmatory studies 49 . This can cause problems as different types of study and different stages of research require different study designs, sample sizes, analysis plans and interpretation of outcomes.Study design is often taught as if each experiment were a fully independent and conclusive study. However, most experiments are part of research programmes including a series of experiments, each providing incremental gains of knowledge that guide the next steps in the programme 71,72 . Ideally, research into new and unexplored areas begins with exploratory studies that can be used to generate and select hypotheses worthy of further investigation 73,74 . Such hypotheses may then be tested in confirmatory studies to establish proof of concept, followed by studies assessing the generalizability of the findings. However, often there is no clear distinction between exploratory and confirmatory studies 49 . This can cause problems as different types of study and different stages of research require different study designs, sample sizes, analysis plans and interpretation of outcomes.</p>
        <p>Initial exploratory studies tend to be small, limited to a single strain of animals and often only of one sex (predominantly males in animal experiments [75][76][77] ), and they are usually conducted under rigorously standardized conditions. Given their aim to generate new hypotheses or identify BoxInitial exploratory studies tend to be small, limited to a single strain of animals and often only of one sex (predominantly males in animal experiments [75][76][77] ), and they are usually conducted under rigorously standardized conditions. Given their aim to generate new hypotheses or identify Box</p>
        <p>Soon after the creation of inbred strains of rodents, researchers began to debate the advantages and disadvantages of their use as models for human medical conditions. Proponents for the use of inbred strains mainly emphasize the advantage of working with a genetically well-defined and standardized model 35,87,98 . A stringent breeding regime over 20 or more generations will lead to an inbreeding coefficient larger than 0.99 and homozygosity in more than 98% of all loci 99 , making animalsofonestrainfromonebreedinglinealmostgeneticallyidentical(althoughafewde novo mutations, tandem repeats and transposon insertions always add marginal variability 16 ). It has been noted that reliance on a single genotype can be risky as a sample of a single inbred strain will not reflect the genetic diversity of natural populations to which the insights should be applied in the end 100 . Furthermore, homozygosity as a result of inbreeding might render inbred mice poor models for outbred populations of heterozygous organisms. Five different approaches for genetic diversification within an experiment have been suggested: use of outbred strains 100 , use of F1 hybrids 101 , use of diversity outbred strains 102 , use of multiple inbred strains 35 and use of both sexes 79,103,104 . The choice of the heterogenization strategy will depend on whether one aims exclusively for variation within individuals (that is, re-establishing heterozygosity through hybridization), variation between subgroups of individuals (use of both sexes or multiple strains) or variation between individuals (use of outbred strains).Soon after the creation of inbred strains of rodents, researchers began to debate the advantages and disadvantages of their use as models for human medical conditions. Proponents for the use of inbred strains mainly emphasize the advantage of working with a genetically well-defined and standardized model 35,87,98 . A stringent breeding regime over 20 or more generations will lead to an inbreeding coefficient larger than 0.99 and homozygosity in more than 98% of all loci 99 , making animalsofonestrainfromonebreedinglinealmostgeneticallyidentical(althoughafewde novo mutations, tandem repeats and transposon insertions always add marginal variability 16 ). It has been noted that reliance on a single genotype can be risky as a sample of a single inbred strain will not reflect the genetic diversity of natural populations to which the insights should be applied in the end 100 . Furthermore, homozygosity as a result of inbreeding might render inbred mice poor models for outbred populations of heterozygous organisms. Five different approaches for genetic diversification within an experiment have been suggested: use of outbred strains 100 , use of F1 hybrids 101 , use of diversity outbred strains 102 , use of multiple inbred strains 35 and use of both sexes 79,103,104 . The choice of the heterogenization strategy will depend on whether one aims exclusively for variation within individuals (that is, re-establishing heterozygosity through hybridization), variation between subgroups of individuals (use of both sexes or multiple strains) or variation between individuals (use of outbred strains).</p>
        <p>Given the genetic uniformity of inbred strains, one might expect to find less between-animal variation of phenotypes in inbred strains than in stocks of outbred or wild-derived mice. The empirical evidence for this assertion is mixed, and some empirical studies 105,106 and a recent meta-analysis of 241 data sets 107 report no overall difference in phenotype variability between inbred and outbred strains. Furthermore, groups of inbred mice kept under the same standardized conditions show sometimes surprisingly large phenotypic variation 40 . The reasons for high variability in inbred strains are poorly understood, although it was suggested that heterozygosity might have stabilizing effects, buffering the development and ensuring robust phenotypes. The loss of heterozygosity due to inbreeding might then disrupt these buffering mechanisms, leading to unstable phenotypes highly susceptible to fluctuations of the internal and external milieu 40,[107][108][109] .Given the genetic uniformity of inbred strains, one might expect to find less between-animal variation of phenotypes in inbred strains than in stocks of outbred or wild-derived mice. The empirical evidence for this assertion is mixed, and some empirical studies 105,106 and a recent meta-analysis of 241 data sets 107 report no overall difference in phenotype variability between inbred and outbred strains. Furthermore, groups of inbred mice kept under the same standardized conditions show sometimes surprisingly large phenotypic variation 40 . The reasons for high variability in inbred strains are poorly understood, although it was suggested that heterozygosity might have stabilizing effects, buffering the development and ensuring robust phenotypes. The loss of heterozygosity due to inbreeding might then disrupt these buffering mechanisms, leading to unstable phenotypes highly susceptible to fluctuations of the internal and external milieu 40,[107][108][109] .</p>
        <p>Age affects many physiological and behavioural processes [110][111][112] and has been suggested as a feasible factor for heterogenization 53,65,79,83 . In addition to age, reproductive experience has been shown to influence diverse physiological parameters and epigenetic marks [113][114][115][116] . Furthermore, seasonal changes, differences in the light regime and differences in the timing of experiments have been shown to affect study outcomes 52,68,117,118 . These environmental factors could be considered as further heterogenization factors. An experimental study showed that co-housing laboratory mice with feral and pet store mice profoundly affected the immune system of the mice, instigating memoryT celldifferentiationandleadingtosubstantialdifferencesinimmuneresponsesto bacterial infection 119 . Heterogenizing the microbial environment of laboratory mice was suggested as a tool for producing models with immune responses resembling those of adult humans more closely. only a few studies have used different housing conditions for heterogenization, such as cage size or environmental enrichment 65,66 , possibly because this is logistically more demanding. However, an earlier study found that memory deficits in mice deficient in hippocampal NmDAtype glutamate receptors were overcome by environmental enrichment, possibly as a result of enrichment-induced NmDA receptor-independent synaptogenesis 120 . In this case, systematic variation of environmental complexity facilitated the detection of a biologically relevant gene × environment interaction. hypotheses worthy of further investigation, this is a highly inefficient strategy, more likely to generate 'findings' that are context specific. Exploratory studies based on carefully heterogenized designs, however, may provide considerable knowledge of how the effect of the experimental intervention (the effect size) is modified by the heterogeneous features (including both genetic and environmental factors) being incorporated in the experimental design. Knowing whether effect sizes are likely to be robust or context dependent permits a much more targeted approach to follow-up studies testing for proof of concept and generalizability 49 .Age affects many physiological and behavioural processes [110][111][112] and has been suggested as a feasible factor for heterogenization 53,65,79,83 . In addition to age, reproductive experience has been shown to influence diverse physiological parameters and epigenetic marks [113][114][115][116] . Furthermore, seasonal changes, differences in the light regime and differences in the timing of experiments have been shown to affect study outcomes 52,68,117,118 . These environmental factors could be considered as further heterogenization factors. An experimental study showed that co-housing laboratory mice with feral and pet store mice profoundly affected the immune system of the mice, instigating memoryT celldifferentiationandleadingtosubstantialdifferencesinimmuneresponsesto bacterial infection 119 . Heterogenizing the microbial environment of laboratory mice was suggested as a tool for producing models with immune responses resembling those of adult humans more closely. only a few studies have used different housing conditions for heterogenization, such as cage size or environmental enrichment 65,66 , possibly because this is logistically more demanding. However, an earlier study found that memory deficits in mice deficient in hippocampal NmDAtype glutamate receptors were overcome by environmental enrichment, possibly as a result of enrichment-induced NmDA receptor-independent synaptogenesis 120 . In this case, systematic variation of environmental complexity facilitated the detection of a biologically relevant gene × environment interaction. hypotheses worthy of further investigation, this is a highly inefficient strategy, more likely to generate 'findings' that are context specific. Exploratory studies based on carefully heterogenized designs, however, may provide considerable knowledge of how the effect of the experimental intervention (the effect size) is modified by the heterogeneous features (including both genetic and environmental factors) being incorporated in the experimental design. Knowing whether effect sizes are likely to be robust or context dependent permits a much more targeted approach to follow-up studies testing for proof of concept and generalizability 49 .</p>
        <p>There are various ways to heterogenize a study population. For example, we may want to estimate an average effect without exploring the impact of each heterogenization factor (for example, strain or environmental condition). In this case, we may split the study sample into groups or 'blocks' , using a randomized complete block 78 design (Box 4). This usually does not require increase of the sample size compared with a completely standardized study design to achieve the same power 79 . In many cases, there is already a blocking factor present in the study design, for example to account for batch, cage or pen effects. In such cases, heterogenization may be achieved by deliberately adding additional heterogeneity between blocks, which improves external validity without sacrificing the internal validity achieved by within-block standardization. Such block heterogenization is suitable to determine whether a treatment effect is robust over a range of conditions, in which case it is also more likely to be reproducible across studies than an effect that interacts strongly with a blocking factor.There are various ways to heterogenize a study population. For example, we may want to estimate an average effect without exploring the impact of each heterogenization factor (for example, strain or environmental condition). In this case, we may split the study sample into groups or 'blocks' , using a randomized complete block 78 design (Box 4). This usually does not require increase of the sample size compared with a completely standardized study design to achieve the same power 79 . In many cases, there is already a blocking factor present in the study design, for example to account for batch, cage or pen effects. In such cases, heterogenization may be achieved by deliberately adding additional heterogeneity between blocks, which improves external validity without sacrificing the internal validity achieved by within-block standardization. Such block heterogenization is suitable to determine whether a treatment effect is robust over a range of conditions, in which case it is also more likely to be reproducible across studies than an effect that interacts strongly with a blocking factor.</p>
        <p>Sometimes we are interested in identifying the sources of biological variation modulating the response to the treatment and assessing the magnitude of the influences of specific factors (for example, sex, age or specific environmental parameters) rather than just maximizing external validity. In such cases, these factors need to be included as fixed effects (differences in the means owing to the influence of independent variables) in the experimental design and analysis. The inclusion of fixed effects as factors in the study design, especially if they are varied across multiple factor levels (that is, values), may require larger sample sizes than standardization or heterogenization using a random blocking factor (a factor increasing variability). Therefore, this should be considered for cases only where the estimation of these effects is scientifically warranted, for example to assess the effects of sex -which we generally recommend -or other relevant biological variables (for example, specific co-morbidities in animal models of diseases) on the outcome variable.Sometimes we are interested in identifying the sources of biological variation modulating the response to the treatment and assessing the magnitude of the influences of specific factors (for example, sex, age or specific environmental parameters) rather than just maximizing external validity. In such cases, these factors need to be included as fixed effects (differences in the means owing to the influence of independent variables) in the experimental design and analysis. The inclusion of fixed effects as factors in the study design, especially if they are varied across multiple factor levels (that is, values), may require larger sample sizes than standardization or heterogenization using a random blocking factor (a factor increasing variability). Therefore, this should be considered for cases only where the estimation of these effects is scientifically warranted, for example to assess the effects of sex -which we generally recommend -or other relevant biological variables (for example, specific co-morbidities in animal models of diseases) on the outcome variable.</p>
        <p>Heterogenized study designs, which incorporate biological variables either as random or fixed effects, should become the default option for almost all study types of experimental animal researchincluding exploratory studies. Rigorous standardization of study animals to a single genotype and a single sex and to being kept under one specific environmental condition can be justified only on the grounds that either the outcome of interest was previously shown to be robust against variation in these factors (albeit absence of evidence should not be mistaken for evidence of absence) or the research question is truly limited to that specific context (for example, as in the study of sex-specific diseases). In all other cases, systematic heterogenization will be scientifically more valid and -especially when considering single studies as parts of a larger research programme -will also be economically beneficial and ethically preferable.Heterogenized study designs, which incorporate biological variables either as random or fixed effects, should become the default option for almost all study types of experimental animal researchincluding exploratory studies. Rigorous standardization of study animals to a single genotype and a single sex and to being kept under one specific environmental condition can be justified only on the grounds that either the outcome of interest was previously shown to be robust against variation in these factors (albeit absence of evidence should not be mistaken for evidence of absence) or the research question is truly limited to that specific context (for example, as in the study of sex-specific diseases). In all other cases, systematic heterogenization will be scientifically more valid and -especially when considering single studies as parts of a larger research programme -will also be economically beneficial and ethically preferable.</p>
        <p>To assess the scientific, economic and ethical implications of heterogenization, it is important to take a perspective that extends beyond the individual experiment 80 . By reduction of within-experiment variation, standardization can increase test sensitivity for a specific standardized study context, which in turn allows reduction of the sample size as required by the 3Rs principles 34 . However, as standardization produces results with a validity that may be limited to that specific context, it generates a greater need for follow-up studies, thus requiring the use of additional animals. If we seek to minimize the use of animals to achieve our research goals, we should focus on maximizing the amount of knowledge gain per animal and/or per study rather than minimizing the number of animals per study. The scenarios presented above demonstrate how scientific evidence can be generated more efficiently and, as a consequence, more ethically ifTo assess the scientific, economic and ethical implications of heterogenization, it is important to take a perspective that extends beyond the individual experiment 80 . By reduction of within-experiment variation, standardization can increase test sensitivity for a specific standardized study context, which in turn allows reduction of the sample size as required by the 3Rs principles 34 . However, as standardization produces results with a validity that may be limited to that specific context, it generates a greater need for follow-up studies, thus requiring the use of additional animals. If we seek to minimize the use of animals to achieve our research goals, we should focus on maximizing the amount of knowledge gain per animal and/or per study rather than minimizing the number of animals per study. The scenarios presented above demonstrate how scientific evidence can be generated more efficiently and, as a consequence, more ethically if</p>
        <p>About three decades ago, an imbalance in clinical research, with female participants being under-represented, led to a series of policy changes to encourage or enforce the inclusion of women in medical studies 121,122 . Although those initiatives were originally restricted to late-phase (phase III) clinical studies, more recently the uS National Institutes of Health, the Canadian Institutes of Health Research and the european Commission extended their recommendation for the inclusion of both sexes to preclinical animal studies 77,123,124 . Sex-based differences in basic biological function, disease processes and treatment responses have been found in many animal models 79,[125][126][127][128][129][130][131][132] . There are marked differences in global gene expression patterns between male and female animals. In mice, the majority (50-75%) of genes have been shown to be sex-biased (that is, expressed at different levels in the two sexes) even in non-reproductive tissues such as liver, fat, muscle and brain 133 . Cell-culture studies have demonstrated that neurons from male and female mice respond differently to various stimuli. Neurons from male mice were more sensitive to stress from reactive oxygen species and excitatory neurotransmitter, whereas neurons from female mice were more sensitive to some stimuli that prompt apoptosis 38,134 . These differences could have potential implications in treatments for stroke, traumatic brain injury, cerebral ischaemia and other neurological and psychiatric conditions, such as Parkinson disease and schizophrenia. Apart from sex differences likely stemming from differences in X and y chromosomal genes, sex-specific responses can also be mediated through hormones acting directly on genes throughout the genome 125,133 . As a consequence, researchers have started to diversify their study samples by including female animals, although parity has not been reached and specifically in neuroscience males are still predominant 75,76 . one of the most common concerns regarding inclusion of female animals in research is the fear that this will require larger sample sizes. This would increase not only the costs but also the workload for research and, consequently, slow scientific progress [135][136][137] . Furthermore, owing to hormonal fluctuations across the reproductive cycle, female animals are believed to be more variable and therefore their use would inherently require larger sample sizes. However, recent meta-analyses that examined variability among male and female mice 41 and rats 138 showed that males were equally or even more variable in all measured parameters. Whether inclusion of both sexes requires a substantial increase in the sample size depends on the specific aim of the study. If separate subgroup analyses for the sexes are planned, a balanced factorial design can ensure that the sample size need not be doubled but that a moderate increase of the required sample size will suffice 103,104 . otherwise, if sex is added merely as a heterogenization factor without the aim to test for sex-specific effects, then this does not require a larger sample size (or only a minimally larger sample size) than in a single-sex experiment 79 . biological variation is accounted for in the study design from very early on 81,82 . It is time to update the textbooks of laboratory animal science and establish systematic heterogenization of study populations as a new standard. As this implies a true paradigm shift, change management towards better practice is needed.About three decades ago, an imbalance in clinical research, with female participants being under-represented, led to a series of policy changes to encourage or enforce the inclusion of women in medical studies 121,122 . Although those initiatives were originally restricted to late-phase (phase III) clinical studies, more recently the uS National Institutes of Health, the Canadian Institutes of Health Research and the european Commission extended their recommendation for the inclusion of both sexes to preclinical animal studies 77,123,124 . Sex-based differences in basic biological function, disease processes and treatment responses have been found in many animal models 79,[125][126][127][128][129][130][131][132] . There are marked differences in global gene expression patterns between male and female animals. In mice, the majority (50-75%) of genes have been shown to be sex-biased (that is, expressed at different levels in the two sexes) even in non-reproductive tissues such as liver, fat, muscle and brain 133 . Cell-culture studies have demonstrated that neurons from male and female mice respond differently to various stimuli. Neurons from male mice were more sensitive to stress from reactive oxygen species and excitatory neurotransmitter, whereas neurons from female mice were more sensitive to some stimuli that prompt apoptosis 38,134 . These differences could have potential implications in treatments for stroke, traumatic brain injury, cerebral ischaemia and other neurological and psychiatric conditions, such as Parkinson disease and schizophrenia. Apart from sex differences likely stemming from differences in X and y chromosomal genes, sex-specific responses can also be mediated through hormones acting directly on genes throughout the genome 125,133 . As a consequence, researchers have started to diversify their study samples by including female animals, although parity has not been reached and specifically in neuroscience males are still predominant 75,76 . one of the most common concerns regarding inclusion of female animals in research is the fear that this will require larger sample sizes. This would increase not only the costs but also the workload for research and, consequently, slow scientific progress [135][136][137] . Furthermore, owing to hormonal fluctuations across the reproductive cycle, female animals are believed to be more variable and therefore their use would inherently require larger sample sizes. However, recent meta-analyses that examined variability among male and female mice 41 and rats 138 showed that males were equally or even more variable in all measured parameters. Whether inclusion of both sexes requires a substantial increase in the sample size depends on the specific aim of the study. If separate subgroup analyses for the sexes are planned, a balanced factorial design can ensure that the sample size need not be doubled but that a moderate increase of the required sample size will suffice 103,104 . otherwise, if sex is added merely as a heterogenization factor without the aim to test for sex-specific effects, then this does not require a larger sample size (or only a minimally larger sample size) than in a single-sex experiment 79 . biological variation is accounted for in the study design from very early on 81,82 . It is time to update the textbooks of laboratory animal science and establish systematic heterogenization of study populations as a new standard. As this implies a true paradigm shift, change management towards better practice is needed.</p>
        <p>The path to implementation. Gene × environ ment interactions, phenotypic plasticity and reaction norms are fundamental biological concepts and standard knowledge taught in undergraduate genetics and biology classes (Box 1). The same applies to block experimental designs to incorporate and control for heterogeneity when one is studying the effect of one or more independent factors on an outcome variable (Box 4). Moreover, the limitations of standardization for external validity and reproducibility of results from animal experiments have long been known 53,61,63,83 . Why then do laboratory animal scientists persist in promoting a principle of experimental design -rigorous standardization -that is incompatible with these insights? Answering this question requires a consideration of the forces encouraging change and the resisting forces that hinder researchers from embracing biological variation as part of their experimental paradigms and thus maintain the status quo (standardization).The path to implementation. Gene × environ ment interactions, phenotypic plasticity and reaction norms are fundamental biological concepts and standard knowledge taught in undergraduate genetics and biology classes (Box 1). The same applies to block experimental designs to incorporate and control for heterogeneity when one is studying the effect of one or more independent factors on an outcome variable (Box 4). Moreover, the limitations of standardization for external validity and reproducibility of results from animal experiments have long been known 53,61,63,83 . Why then do laboratory animal scientists persist in promoting a principle of experimental design -rigorous standardization -that is incompatible with these insights? Answering this question requires a consideration of the forces encouraging change and the resisting forces that hinder researchers from embracing biological variation as part of their experimental paradigms and thus maintain the status quo (standardization).</p>
        <p>Box 5 lists forces impacting researchers' engagement with changing practice. Understanding these forces and considering the interplay highlights that resisting forces dominate, which explains the challenge for our community to achieve the paradigm shift that is needed. A closer look at these factors will highlight how we can unfreeze the status quo by strengthening the driving forces and weakening the resisting forces, allowing the paradigm shift to occur 84 .Box 5 lists forces impacting researchers' engagement with changing practice. Understanding these forces and considering the interplay highlights that resisting forces dominate, which explains the challenge for our community to achieve the paradigm shift that is needed. A closer look at these factors will highlight how we can unfreeze the status quo by strengthening the driving forces and weakening the resisting forces, allowing the paradigm shift to occur 84 .</p>
        <p>Our current research culture is made up of the beliefs, values and norms of behaviour (protocols and systems) of the community of researchers. A central belief determining current research practice is the conviction that standardization is a universal means to improve the validity of animal experiments and meet our ethical obligations to use as few animals as possible. As we have outlined already, this assertion does not hold if standardization is removing relevant biological variation. Although this problem was identified previously,Our current research culture is made up of the beliefs, values and norms of behaviour (protocols and systems) of the community of researchers. A central belief determining current research practice is the conviction that standardization is a universal means to improve the validity of animal experiments and meet our ethical obligations to use as few animals as possible. As we have outlined already, this assertion does not hold if standardization is removing relevant biological variation. Although this problem was identified previously,</p>
        <p>Blocking is an effective means of exploiting the benefits of both standardization and heterogenization. Within blocks of subjects, the experimental conditions can be standardized as rigorously as possible (for example, use of same genotype, same age and same experimental context), so that any differences in response to the experimental treatments will most likely be attributable to the treatment. However, the blocks themselves can be heterogeneous and vary in one or several aspects. In the classic randomized complete block (RCB) design experiment, each treatment is assigned randomly to a single animal within each block (see the figure ,part a). Such data can be analysed by a paired t test between treatment and control that are paired within blocks (B1 to B6) when there are only two treatments (treatment (T) and control (C) in part a of the figure), or in a linear (mixed-effect) model where block is treated as a fixed orrandomeffectwhentherearemoretreatments.Thelattermodels have the advantage of being adaptable to more complex experimental designs; for example, blocks of time that are nested within blocks of laboratories.Blocking is an effective means of exploiting the benefits of both standardization and heterogenization. Within blocks of subjects, the experimental conditions can be standardized as rigorously as possible (for example, use of same genotype, same age and same experimental context), so that any differences in response to the experimental treatments will most likely be attributable to the treatment. However, the blocks themselves can be heterogeneous and vary in one or several aspects. In the classic randomized complete block (RCB) design experiment, each treatment is assigned randomly to a single animal within each block (see the figure ,part a). Such data can be analysed by a paired t test between treatment and control that are paired within blocks (B1 to B6) when there are only two treatments (treatment (T) and control (C) in part a of the figure), or in a linear (mixed-effect) model where block is treated as a fixed orrandomeffectwhentherearemoretreatments.Thelattermodels have the advantage of being adaptable to more complex experimental designs; for example, blocks of time that are nested within blocks of laboratories.</p>
        <p>The strength of the RCB design is that the treatment effect can be estimated within each block, and therefore it is independent of the block-to-block heterogeneity. Hence, any context-general treatment effect will be unaffected by heterogeneity among blocks. moreover, the same design can be used to explore context dependencies. We can include fixed effects that describe differences among blocks and their effects can be estimated. We can, therefore, determine treatment effects that are consistent across blocks (and hence are likely to be generalizable to more heterogeneous settings) as well as those that differ among blocks. one problem with the classic RCB design is that treatments that have a consistent effect in only a subset of the blocks may not be identified if the estimated effects are highly variable between the remaining blocks. This can be mitigated in two ways. If there is prior knowledge of the sources of context dependencies, heterogeneity across candidate contexts can be built into the experiment. This can be analysed by fitting additional fixed effects for these factors using a split plot design where these factors are whole plot factors. If there is no prior knowledge of context dependencies, these can be explored and mitigated by replication within blocks (for example, B1 and B2 in part b of the figure), thus yielding a measure of within block variability which can be used to assess whether treatment effects vary among blocks. Replication within blocks might be specifically of interest for late-phase studies, in which we do not want to get only a generalproofofconceptbutinwhichwealsowanttogaininsights into thedifferentsourcesofvariationandtheirmagnitude.Replication within blocks is much less effective in increasing the power to detect context-independent effects (main effects) than use of additional blocks, but it is required to test for interactions between the factors of interest and thecontextfactors.The strength of the RCB design is that the treatment effect can be estimated within each block, and therefore it is independent of the block-to-block heterogeneity. Hence, any context-general treatment effect will be unaffected by heterogeneity among blocks. moreover, the same design can be used to explore context dependencies. We can include fixed effects that describe differences among blocks and their effects can be estimated. We can, therefore, determine treatment effects that are consistent across blocks (and hence are likely to be generalizable to more heterogeneous settings) as well as those that differ among blocks. one problem with the classic RCB design is that treatments that have a consistent effect in only a subset of the blocks may not be identified if the estimated effects are highly variable between the remaining blocks. This can be mitigated in two ways. If there is prior knowledge of the sources of context dependencies, heterogeneity across candidate contexts can be built into the experiment. This can be analysed by fitting additional fixed effects for these factors using a split plot design where these factors are whole plot factors. If there is no prior knowledge of context dependencies, these can be explored and mitigated by replication within blocks (for example, B1 and B2 in part b of the figure), thus yielding a measure of within block variability which can be used to assess whether treatment effects vary among blocks. Replication within blocks might be specifically of interest for late-phase studies, in which we do not want to get only a generalproofofconceptbutinwhichwealsowanttogaininsights into thedifferentsourcesofvariationandtheirmagnitude.Replication within blocks is much less effective in increasing the power to detect context-independent effects (main effects) than use of additional blocks, but it is required to test for interactions between the factors of interest and thecontextfactors.</p>
        <p>Although the RCB design is a highly efficient means of combining rigorous standardization with heterogenization, it requires that blocks are sufficientlylargetoincludeatleastonereplicateofeachtreatment. When this cannot be done for technical reasons or when a larger number of blocking factors are considered, incomplete block designs 139 are available that provide much of the same advantage with a small cost to the poweroftestingthetreatmentmaineffects. standardization is culturally embedded in our community as the norm and best practice. It is done without questioning its validity. Consequently, more advocacy will be needed to convey the Janus-faced nature of standardization to the wider research community. One roadblock is conflicting evidence from other scientific disciplines such as physics, in which standardization is indeed an effective measure to reduce measurement error of technical replicates and, hence, to improve both the internal and the external validity of study results. However, heterogenization is commonly accepted practice in many other biological disciplines, particularly those dealing with whole organisms, including quantitative genetics, animal and plant breeding, ecology and evolutionary biology. To overcome this resistance, we need to challenge the underlying beliefs that standardization is best practice and to promote awareness that biological variation of the phenotype differs fundamentally from random noise (as exemplified in Box 1).Although the RCB design is a highly efficient means of combining rigorous standardization with heterogenization, it requires that blocks are sufficientlylargetoincludeatleastonereplicateofeachtreatment. When this cannot be done for technical reasons or when a larger number of blocking factors are considered, incomplete block designs 139 are available that provide much of the same advantage with a small cost to the poweroftestingthetreatmentmaineffects. standardization is culturally embedded in our community as the norm and best practice. It is done without questioning its validity. Consequently, more advocacy will be needed to convey the Janus-faced nature of standardization to the wider research community. One roadblock is conflicting evidence from other scientific disciplines such as physics, in which standardization is indeed an effective measure to reduce measurement error of technical replicates and, hence, to improve both the internal and the external validity of study results. However, heterogenization is commonly accepted practice in many other biological disciplines, particularly those dealing with whole organisms, including quantitative genetics, animal and plant breeding, ecology and evolutionary biology. To overcome this resistance, we need to challenge the underlying beliefs that standardization is best practice and to promote awareness that biological variation of the phenotype differs fundamentally from random noise (as exemplified in Box 1).</p>
        <p>The designs recommended here intro uce challenges through changes in the way we practically run the experiments and analyse the data. A significant blocker for our community to embrace such changes is the current norm to publish studies with a narrow inference space with no acknowledgement of the limitations of the study findings. This approach has a significant impact on our research culture, as we are rewarded for publications regardless of the robustness of our findings. A further obstacle to change is the argument that heterogenization increases the complexity of the experiment and, thereby, complicates the analysis and increases the required sample size and economic costs of the experiment. Although it is true that heterogenized study designs are more complex, this does not hinder analysis, because statistical tools to deal with the added complexity are readily available (see Box 3). Here, scientists might need more encouragement to engage with those statistical concepts and apply them in their research practices 85 .The designs recommended here intro uce challenges through changes in the way we practically run the experiments and analyse the data. A significant blocker for our community to embrace such changes is the current norm to publish studies with a narrow inference space with no acknowledgement of the limitations of the study findings. This approach has a significant impact on our research culture, as we are rewarded for publications regardless of the robustness of our findings. A further obstacle to change is the argument that heterogenization increases the complexity of the experiment and, thereby, complicates the analysis and increases the required sample size and economic costs of the experiment. Although it is true that heterogenized study designs are more complex, this does not hinder analysis, because statistical tools to deal with the added complexity are readily available (see Box 3). Here, scientists might need more encouragement to engage with those statistical concepts and apply them in their research practices 85 .</p>
        <p>Despite a general understanding of the problem, researchers who wish to implement heterogenization face several unknowns. Which factors will have the strongest effects on the overall variation? How strong will the effects be? Within which range should we vary environmental factors? How different should the experiments be to be considered independent replicates? When does this require replication in a different laboratory, and when are sequential batches within the same laboratory sufficient?Despite a general understanding of the problem, researchers who wish to implement heterogenization face several unknowns. Which factors will have the strongest effects on the overall variation? How strong will the effects be? Within which range should we vary environmental factors? How different should the experiments be to be considered independent replicates? When does this require replication in a different laboratory, and when are sequential batches within the same laboratory sufficient?</p>
        <p>For some well-researched treatments or compounds we might have information about the effect of some of the more common heterogenization factors such as sex or strain, but in most cases we will lack this information and cannot answer those questions upfront. Some answers can be gleaned from the literature on the evolutionary biology and ecology of related animals, which provides a rich source of information on phenotypic and genetic heterogeneity. Educated guesses and rules of thumb for certain groups of interventions might give some guidance, but in the end we have to accept intrinsic uncertainties that can be resolved only empirically. Further research is therefore essential to explore these issues and provide guidance to the community in practical steps that can be taken.For some well-researched treatments or compounds we might have information about the effect of some of the more common heterogenization factors such as sex or strain, but in most cases we will lack this information and cannot answer those questions upfront. Some answers can be gleaned from the literature on the evolutionary biology and ecology of related animals, which provides a rich source of information on phenotypic and genetic heterogeneity. Educated guesses and rules of thumb for certain groups of interventions might give some guidance, but in the end we have to accept intrinsic uncertainties that can be resolved only empirically. Further research is therefore essential to explore these issues and provide guidance to the community in practical steps that can be taken.</p>
        <p>Given the uncertainties with regard to heterogenization factors that will prove effective for any specific treatment, we do not think that the way forward should be a list of compulsory factors to be heterogenized in every study. Instead, weGiven the uncertainties with regard to heterogenization factors that will prove effective for any specific treatment, we do not think that the way forward should be a list of compulsory factors to be heterogenized in every study. Instead, we</p>
        <p>The variation of phenotypes in a population of organisms. it is the result of genetic variation, environmental influences on the organism and gene × environment interactions.The variation of phenotypes in a population of organisms. it is the result of genetic variation, environmental influences on the organism and gene × environment interactions.</p>
        <p>studies designed to test specific hypotheses about the existence of a relationship or effect, its direction and magnitude using inferential statistical methods. The hypotheses are based on previous knowledge of the study system.studies designed to test specific hypotheses about the existence of a relationship or effect, its direction and magnitude using inferential statistical methods. The hypotheses are based on previous knowledge of the study system.</p>
        <p>studies designed to probe for relationships or treatment effects of novel interventions without specific hypotheses about the direction and size of effects. The outcome of an exploratory study is a descriptive account of the observed effects.studies designed to probe for relationships or treatment effects of novel interventions without specific hypotheses about the direction and size of effects. The outcome of an exploratory study is a descriptive account of the observed effects.</p>
        <p>The extent to which findings can be generalized to the desired inference space of animals (including humans) and/or other environmental conditions.The extent to which findings can be generalized to the desired inference space of animals (including humans) and/or other environmental conditions.</p>
        <p>These subsume the non-additive joint effect of genetic and environmental influences on the development of the phenotype. As a consequence, environmental influences can have different effects on the phenotype depending on the organism's genotype or genes can have differential effects depending on features of the environment.These subsume the non-additive joint effect of genetic and environmental influences on the development of the phenotype. As a consequence, environmental influences can have different effects on the phenotype depending on the organism's genotype or genes can have differential effects depending on features of the environment.</p>
        <p>organisms' hereditary information as encoded in the genome.organisms' hereditary information as encoded in the genome.</p>
        <p>The deliberate augmentation of systematic or random biological variation in the study population.The deliberate augmentation of systematic or random biological variation in the study population.</p>
        <p>The range of organisms and environmental contexts for which the inference of an experiment is valid.The range of organisms and environmental contexts for which the inference of an experiment is valid.</p>
        <p>Refers to whether the effects observed in a study are due to manipulation of the independent variables and not some other, unknown factors.Refers to whether the effects observed in a study are due to manipulation of the independent variables and not some other, unknown factors.</p>
        <p>A property of a genotype describing how an environmental factor affects the development of the phenotype. it can be conceptualized as a function mapping expected phenotypic trait values onto environmental parameter values.A property of a genotype describing how an environmental factor affects the development of the phenotype. it can be conceptualized as a function mapping expected phenotypic trait values onto environmental parameter values.</p>
        <p>The sum of an organism's observable characteristics or traits, including its morphological, biochemical and physiological processes, behaviour and responses to external stimulation and treatments.The sum of an organism's observable characteristics or traits, including its morphological, biochemical and physiological processes, behaviour and responses to external stimulation and treatments.</p>
        <p>The extent to which an organism changes its phenotype in response to environmental influences.The extent to which an organism changes its phenotype in response to environmental influences.</p>
        <p>Also known as measurement error, refers to unexplained variability in the data. it affects the variation but not the size of an experimental treatment effect.Also known as measurement error, refers to unexplained variability in the data. it affects the variation but not the size of an experimental treatment effect.</p>
        <p>The ability to produce similar results by an independent replicate experiment using the same methodology in the same or a different laboratory.The ability to produce similar results by an independent replicate experiment using the same methodology in the same or a different laboratory.</p>
        <p>The ability of an organism to maintain a functioning phenotype under varying environmental conditions. it also refers to the stability of a response to an experimental treatment in the face of variation in environmental conditions.The ability of an organism to maintain a functioning phenotype under varying environmental conditions. it also refers to the stability of a response to an experimental treatment in the face of variation in environmental conditions.</p>
        <p>The guiding principles for a responsible approach to experimental animal research. They imply that a study involving the use of animals should be conducted only if the intended outcome cannot be achieved by use of no or non-sentient animals (replace), fewer animals (reduce) or procedures that are less harmful or improve animal well-being (refine).The guiding principles for a responsible approach to experimental animal research. They imply that a study involving the use of animals should be conducted only if the intended outcome cannot be achieved by use of no or non-sentient animals (replace), fewer animals (reduce) or procedures that are less harmful or improve animal well-being (refine).</p>
        <p>As defined by the Us National institutes of Health, this means "the strict application of the scientific method to ensure robust and unbiased experimental design, methodology, analysis, interpretation and reporting of results. This includes full transparency in reporting experimental details so that others may reproduce and extend the findings".As defined by the Us National institutes of Health, this means "the strict application of the scientific method to ensure robust and unbiased experimental design, methodology, analysis, interpretation and reporting of results. This includes full transparency in reporting experimental details so that others may reproduce and extend the findings".</p>
        <p>The practice of minimizing both technical and biological variation in the study outcomes by identifying and controlling sources of variation that are believed to be putative confounders. standardization can aim at aspects of the environment in which a study is conducted (environmental standardization), aspects of the study subjects (phenotype standardization) or aspects of how procedures and interventions are conducted and how measurements are taken (operational standardization).The practice of minimizing both technical and biological variation in the study outcomes by identifying and controlling sources of variation that are believed to be putative confounders. standardization can aim at aspects of the environment in which a study is conducted (environmental standardization), aspects of the study subjects (phenotype standardization) or aspects of how procedures and interventions are conducted and how measurements are taken (operational standardization).</p>
        <p>recommend that heterogenization of sex, genotype, age and environmental conditions should be recommended in general terms and that experimenters should be asked to discuss their choice of heterogenization measures -or the lack of such measureswith respect to the intended inference space.recommend that heterogenization of sex, genotype, age and environmental conditions should be recommended in general terms and that experimenters should be asked to discuss their choice of heterogenization measures -or the lack of such measureswith respect to the intended inference space.</p>
        <p>Besides counteracting factors inhibiting change, there is also a need to strengthen those factors motivating and driving change. Arguably the most compelling one is the reproducibility crisis in biomedical research. Reports pointing out issues with reproducibility have accumulated over the years, and the desire to solve this crisis should be a very strong motivation for driving change. Improving reproducibility can reduce long-term research costs, increase efficiency of drug development and reduce suffering of animals used for inconclusive research.Besides counteracting factors inhibiting change, there is also a need to strengthen those factors motivating and driving change. Arguably the most compelling one is the reproducibility crisis in biomedical research. Reports pointing out issues with reproducibility have accumulated over the years, and the desire to solve this crisis should be a very strong motivation for driving change. Improving reproducibility can reduce long-term research costs, increase efficiency of drug development and reduce suffering of animals used for inconclusive research.</p>
        <p>Connected to poor reproducibility, there is a related and very compelling issue: it is the reputation of research itself -and of animal research in particular -that is at stake 4,86 . The public funds research on the principal understanding that researchers use funding resources judiciously and efficiently. If the research community fails to resolve the current reproducibility crisis, then the public might legitimately question whether researchers adhere to this societal contract and whether investment in this kind of research should continue. Along the same lines, the right to use animals for research that might inflict pain and suffering on the animals is a privilege granted to researchers by society on the understanding that their research benefits humanity and that researchers use the animal resources responsibly, avoiding unnecessary harm and suffering. Again, a failure of the scientific community to resolve the current crisis might instigate a discussion as to whether this privilege should be revoked. Here, we believe that it is important to communicate that ignoring or denying the existence of a major reproducibility problem is not a solution and that only an honest and serious attempt by the entire scientific community to solve this problem can secure continued trust in science by the general public.Connected to poor reproducibility, there is a related and very compelling issue: it is the reputation of research itself -and of animal research in particular -that is at stake 4,86 . The public funds research on the principal understanding that researchers use funding resources judiciously and efficiently. If the research community fails to resolve the current reproducibility crisis, then the public might legitimately question whether researchers adhere to this societal contract and whether investment in this kind of research should continue. Along the same lines, the right to use animals for research that might inflict pain and suffering on the animals is a privilege granted to researchers by society on the understanding that their research benefits humanity and that researchers use the animal resources responsibly, avoiding unnecessary harm and suffering. Again, a failure of the scientific community to resolve the current crisis might instigate a discussion as to whether this privilege should be revoked. Here, we believe that it is important to communicate that ignoring or denying the existence of a major reproducibility problem is not a solution and that only an honest and serious attempt by the entire scientific community to solve this problem can secure continued trust in science by the general public.</p>
        <p>With respect to sample size, recent studies indicated that heterogenization can be introduced without a need to increase the overall sample size 53,67,87 . Larger sample sizes are needed only when multiple factors are heterogenized; however, the increase in economic and ethical costs of larger experiments should be more than outweighed in the long run, as fewer follow-up studies will be required and fewer dead ends will be pursued. Promises for long-term benefits are, by their very nature, vague, which means that they are rather weak arguments for implementing change. However, if the focus is shifted from the costs of an individual study (both financial and ethical in terms of the numbers of animals used) to the amount of knowledge gained per study or per animal (Box 5), then it becomes immediately apparent that heterogenized studies can deliver a better benefit-cost ratio than narrowly standardized studies. This change of focus from the number of animals within single experiments to the value delivered by these experiments is also reflected in the recent change in the definition of 'reduction' by the UK National Centre for the Replacement, Refinement and Reduction of Animals in Research (NC3Rs), which now includes "experiments that are robust, reproducible and truly add to the knowledge base" 88 . Researchers, regulators, funders and editors need to understand that studies allowing inferences about both sexes, genetically diverse populations or a variety of environmental conditions will add more richly to the knowledge base, and that standardization of animal subjects inevitably reduces the inference space. A promising way forward might be insistence by editors, reviewers and funders that authors have to specify the inference space of their studies; that is, the population -and the biological variation within that population -about which they will be able to draw inferences. Some funders are already requiring some forms of heterogenization (Box 2 and Box 3). For example, both the US National Institutes of Health 89 and the Organisation for Economic Co-operation and Development 90 recommend that studies in preclinical biomedical research should comprise both sexes, and the European Medicines Agency requires that animal toxicity tests for compounds have to be done in at least two different species before translation to humans 91 . We therefore propose that reporting guidelines (for example, the ARRIVE guidelines 92 and Nature Research's Reporting Summary 93 ) request that experimenters explicitly state the intended inference space and discuss their results with respect to the measures taken (for example, the factors that were heterogenized) to cover that inference space.With respect to sample size, recent studies indicated that heterogenization can be introduced without a need to increase the overall sample size 53,67,87 . Larger sample sizes are needed only when multiple factors are heterogenized; however, the increase in economic and ethical costs of larger experiments should be more than outweighed in the long run, as fewer follow-up studies will be required and fewer dead ends will be pursued. Promises for long-term benefits are, by their very nature, vague, which means that they are rather weak arguments for implementing change. However, if the focus is shifted from the costs of an individual study (both financial and ethical in terms of the numbers of animals used) to the amount of knowledge gained per study or per animal (Box 5), then it becomes immediately apparent that heterogenized studies can deliver a better benefit-cost ratio than narrowly standardized studies. This change of focus from the number of animals within single experiments to the value delivered by these experiments is also reflected in the recent change in the definition of 'reduction' by the UK National Centre for the Replacement, Refinement and Reduction of Animals in Research (NC3Rs), which now includes "experiments that are robust, reproducible and truly add to the knowledge base" 88 . Researchers, regulators, funders and editors need to understand that studies allowing inferences about both sexes, genetically diverse populations or a variety of environmental conditions will add more richly to the knowledge base, and that standardization of animal subjects inevitably reduces the inference space. A promising way forward might be insistence by editors, reviewers and funders that authors have to specify the inference space of their studies; that is, the population -and the biological variation within that population -about which they will be able to draw inferences. Some funders are already requiring some forms of heterogenization (Box 2 and Box 3). For example, both the US National Institutes of Health 89 and the Organisation for Economic Co-operation and Development 90 recommend that studies in preclinical biomedical research should comprise both sexes, and the European Medicines Agency requires that animal toxicity tests for compounds have to be done in at least two different species before translation to humans 91 . We therefore propose that reporting guidelines (for example, the ARRIVE guidelines 92 and Nature Research's Reporting Summary 93 ) request that experimenters explicitly state the intended inference space and discuss their results with respect to the measures taken (for example, the factors that were heterogenized) to cover that inference space.</p>
        <p>Accumulating evidence of poor reproducibility of research has stimulated heated debate about possible causes and remedies of irreproducibility leading to the so-called reproducibility crisis. Suggested causes of poor reproducibility include lack of scientific rigour, low statistical power, publication bias, analytical flexibility (for example, P-hacking), pseudoreplication and outright fraud 6,12,[94][95][96] . These causes are all thought to be promoted by a system that rewards novel and spectacular findings -even if they are spurious -more than robust, reproducible evidence 97 . However, we contend that this list is incomplete for research involving living organisms as an important source of replication failure has been ignored: standardization of the animals, leading to unrealistically low estimates of biological variation and, as a consequence, to study-specific, idiosyncratic results. As biological variation differs from random noise and variation of technical replicates -as clearly demonstrated by the reaction norm framework -its removal through standardization generates overconfident and biased estimates. Here we have outlined the rationale for our claim, as well as its scientific, ethical and economic implications, and presented targeted scenarios for improvement. We maintain that unless researchers take the context dependency of their animals' treatment responses into account, reproducibility of animal research will remain limited despite efforts to avoid other causes that affect reproducibility. We call on the community (researchers, publishers, policymakers, professional bodies, funders and so on) to engage and explore how they can support the paradigm shift that is needed to deliver robust research.Accumulating evidence of poor reproducibility of research has stimulated heated debate about possible causes and remedies of irreproducibility leading to the so-called reproducibility crisis. Suggested causes of poor reproducibility include lack of scientific rigour, low statistical power, publication bias, analytical flexibility (for example, P-hacking), pseudoreplication and outright fraud 6,12,[94][95][96] . These causes are all thought to be promoted by a system that rewards novel and spectacular findings -even if they are spurious -more than robust, reproducible evidence 97 . However, we contend that this list is incomplete for research involving living organisms as an important source of replication failure has been ignored: standardization of the animals, leading to unrealistically low estimates of biological variation and, as a consequence, to study-specific, idiosyncratic results. As biological variation differs from random noise and variation of technical replicates -as clearly demonstrated by the reaction norm framework -its removal through standardization generates overconfident and biased estimates. Here we have outlined the rationale for our claim, as well as its scientific, ethical and economic implications, and presented targeted scenarios for improvement. We maintain that unless researchers take the context dependency of their animals' treatment responses into account, reproducibility of animal research will remain limited despite efforts to avoid other causes that affect reproducibility. We call on the community (researchers, publishers, policymakers, professional bodies, funders and so on) to engage and explore how they can support the paradigm shift that is needed to deliver robust research.</p>
        <p>www.nature.com/nrnwww.nature.com/nrn</p>
        <p>The Swiss National Science Foundation (IZSEZ0_184010) provided funding to B.V. for the workshop 'Variation in in vivo experiments: the norm of reaction and reproducibility' . B.V., H.W. and M.J.K. were funded by the European Union Horizon 2020 research and innovation programme and the European Federation of Pharmaceutical Industries and Associations (Innovative Medicines Initiative, IMI2, grant agreement no. 777364, European Quality in Preclinical Data). A.F. thanks Linnaeus University for funding. H.S. was supported by the German Research Foundation (INST 215/543-1, 396782608). I.J. was funded by the Swiss National Science Foundation (310030_179254).The Swiss National Science Foundation (IZSEZ0_184010) provided funding to B.V. for the workshop 'Variation in in vivo experiments: the norm of reaction and reproducibility' . B.V., H.W. and M.J.K. were funded by the European Union Horizon 2020 research and innovation programme and the European Federation of Pharmaceutical Industries and Associations (Innovative Medicines Initiative, IMI2, grant agreement no. 777364, European Quality in Preclinical Data). A.F. thanks Linnaeus University for funding. H.S. was supported by the German Research Foundation (INST 215/543-1, 396782608). I.J. was funded by the Swiss National Science Foundation (310030_179254).</p>
        <p>The authors contributed equally to all aspects of the article.The authors contributed equally to all aspects of the article.</p>
        <p>The authors declare no competing interests.The authors declare no competing interests.</p>
        <p>Nature Reviews Neuroscience thanks S. C. Stanford and F. J. van der Staay for their contribution to the peer review of this work.Nature Reviews Neuroscience thanks S. C. Stanford and F. J. van der Staay for their contribution to the peer review of this work.</p>
        <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </text>
</tei>
