<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-13T09:41+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>Recently, deep learned enabled end-to-end (E2E) communication systems have been developed to merge all physical layer blocks in the traditional communication systems, which make joint transceiver optimization possible. Powered by deep learning, natural language processing (NLP) has achieved great success in analyzing and understanding a large amount of language texts. Inspired by research results in both areas, we aim to provide a new view on communication systems from the semantic level. Particularly, we propose a deep learning based semantic communication system, named DeepSC, for text transmission. Based on the Transformer, the DeepSC aims at maximizing the system capacity and minimizing the semantic errors by recovering the meaning of sentences, rather than bit-or symbol-errors in traditional communications. Moreover, transfer learning is used to ensure the DeepSC applicable to different communication environments and to accelerate the model training process. To justify the performance of semantic communications accurately, we also initialize a new metric, named sentence similarity. Compared with the traditional communication system without considering semantic information exchange, the proposed DeepSC is more robust to channel variation and is able to achieve better performance, especially in the low signal-to-noise (SNR) regime, as demonstrated by the extensive simulation results.Recently, deep learned enabled end-to-end (E2E) communication systems have been developed to merge all physical layer blocks in the traditional communication systems, which make joint transceiver optimization possible. Powered by deep learning, natural language processing (NLP) has achieved great success in analyzing and understanding a large amount of language texts. Inspired by research results in both areas, we aim to provide a new view on communication systems from the semantic level. Particularly, we propose a deep learning based semantic communication system, named DeepSC, for text transmission. Based on the Transformer, the DeepSC aims at maximizing the system capacity and minimizing the semantic errors by recovering the meaning of sentences, rather than bit-or symbol-errors in traditional communications. Moreover, transfer learning is used to ensure the DeepSC applicable to different communication environments and to accelerate the model training process. To justify the performance of semantic communications accurately, we also initialize a new metric, named sentence similarity. Compared with the traditional communication system without considering semantic information exchange, the proposed DeepSC is more robust to channel variation and is able to achieve better performance, especially in the low signal-to-noise (SNR) regime, as demonstrated by the extensive simulation results.</p>
        <p>bits) from the transmitter to the receiver. In such systems, biterror rate (BER) or symbol-error rate (SER) is usually taken as the performance metrics [2]. With the development from the first generation (1G) to the fifth generation (5G), the achieved transmission rate has been improved tens of thousands of times and the system capacity is gradually approaching to the Shannon limit. Recently, various new applications appear, such as autonomous transportation, consumer robotics, environmental monitoring, and tele-health [3], [4]. The interconnection of these applications will generate a staggering amount of data in the order of zetta-bytes. Besides, these applications need to support massive connectivity over limited spectrum resources but require lower latency, which poses critical challenges to traditional source-channel coding. Semantic communications can process data in the semantic domain by extracting the meanings of data and filtering out the useless, irrelevant, and unessential information, which further compresses data while reserving the meanings. Moreover, semantic communication is expected to be robust to terrible channel environments, i.e., low signal-to-noise ratio (SNR) region, which fits well the applications requiring high reliability. These factors motivate us to develop intelligent communication systems by considering the semantic meaning behind digital bits to enhance the accuracy and efficiency of communications.bits) from the transmitter to the receiver. In such systems, biterror rate (BER) or symbol-error rate (SER) is usually taken as the performance metrics [2]. With the development from the first generation (1G) to the fifth generation (5G), the achieved transmission rate has been improved tens of thousands of times and the system capacity is gradually approaching to the Shannon limit. Recently, various new applications appear, such as autonomous transportation, consumer robotics, environmental monitoring, and tele-health [3], [4]. The interconnection of these applications will generate a staggering amount of data in the order of zetta-bytes. Besides, these applications need to support massive connectivity over limited spectrum resources but require lower latency, which poses critical challenges to traditional source-channel coding. Semantic communications can process data in the semantic domain by extracting the meanings of data and filtering out the useless, irrelevant, and unessential information, which further compresses data while reserving the meanings. Moreover, semantic communication is expected to be robust to terrible channel environments, i.e., low signal-to-noise ratio (SNR) region, which fits well the applications requiring high reliability. These factors motivate us to develop intelligent communication systems by considering the semantic meaning behind digital bits to enhance the accuracy and efficiency of communications.</p>
        <p>Different from the conventional communications, semantic communications aim to transmit the information relevant to the transmission goal. For example, for text transmission, the meaning is thereby essential information and the expression, i.e., is expression of word, are unnecessary. By doing so, the data traffic would be reduced significantly. Such a system could be particularly useful when the bandwidth is limited, the SNR is low, or the BER/SER is high in typical communication systems.Different from the conventional communications, semantic communications aim to transmit the information relevant to the transmission goal. For example, for text transmission, the meaning is thereby essential information and the expression, i.e., is expression of word, are unnecessary. By doing so, the data traffic would be reduced significantly. Such a system could be particularly useful when the bandwidth is limited, the SNR is low, or the BER/SER is high in typical communication systems.</p>
        <p>Historically, the concept of semantic communication was developed several decades ago. Inspired by Shannon and Weaver [1], Carnap et al. [5] were the first to introduce the semantic information theory (SIT) based on logical probabilities ranging over the contents. Afterwards, a generic model of semantic communication (GMSC) was proposed as an extension of the SIT, where the concepts of semantic noise and semantic channel were first defined [6]. As pointed out in [7], the analysis and design of a communication system for optimal transmission of intelligence are faced with several challenges. For instance, how to define error in the intelligence transmission? In [8], a lossless semantic data compression theory by applying the GMSC was developed, which means that data can be compressed at semantic level so that the size of the data to be transmitted can be reduced significantly. Recently, an end-to-end (E2E) semantic communication framework integrates the semantic inference and physical layer communication problems, where the transceiver is optimized to reach the Nash equilibrium while minimizing the average semantic errors [9]. However, the semantic error in [9] measures the meaning of each word rather than the whole sentence. These aforementioned works provide some insights and remarks for the design of semantic communications, but many issues remain unexplored.Historically, the concept of semantic communication was developed several decades ago. Inspired by Shannon and Weaver [1], Carnap et al. [5] were the first to introduce the semantic information theory (SIT) based on logical probabilities ranging over the contents. Afterwards, a generic model of semantic communication (GMSC) was proposed as an extension of the SIT, where the concepts of semantic noise and semantic channel were first defined [6]. As pointed out in [7], the analysis and design of a communication system for optimal transmission of intelligence are faced with several challenges. For instance, how to define error in the intelligence transmission? In [8], a lossless semantic data compression theory by applying the GMSC was developed, which means that data can be compressed at semantic level so that the size of the data to be transmitted can be reduced significantly. Recently, an end-to-end (E2E) semantic communication framework integrates the semantic inference and physical layer communication problems, where the transceiver is optimized to reach the Nash equilibrium while minimizing the average semantic errors [9]. However, the semantic error in [9] measures the meaning of each word rather than the whole sentence. These aforementioned works provide some insights and remarks for the design of semantic communications, but many issues remain unexplored.</p>
        <p>Recent advancements on deep learning (DL) based natural language processing (NLP) and communication systems inspire us to investigate semantic communication to realize the second level communications as aforementioned [10]- [15]. The considered semantic communication system mainly focuses on the joint semantic-channel coding and decoding, which aims to extract and encode the semantic information of sentences rather than simply a sequence of bits or a word. For the semantic communication system, we face the following questions:Recent advancements on deep learning (DL) based natural language processing (NLP) and communication systems inspire us to investigate semantic communication to realize the second level communications as aforementioned [10]- [15]. The considered semantic communication system mainly focuses on the joint semantic-channel coding and decoding, which aims to extract and encode the semantic information of sentences rather than simply a sequence of bits or a word. For the semantic communication system, we face the following questions:</p>
        <p>Question 1: How to define the meaning behind the bits? Question 2: How to measure the semantic error of sentences? Question 3: How to jointly design the semantic and channel coding?Question 1: How to define the meaning behind the bits? Question 2: How to measure the semantic error of sentences? Question 3: How to jointly design the semantic and channel coding?</p>
        <p>In this paper, we investigate the semantic communication system by applying machine translation techniques in NLP to physical layer communications. Specifically, we propose a DL enabled semantic communication system (DeepSC) to address the aforementioned challenges. The main contributions of this paper are summarized as follows:In this paper, we investigate the semantic communication system by applying machine translation techniques in NLP to physical layer communications. Specifically, we propose a DL enabled semantic communication system (DeepSC) to address the aforementioned challenges. The main contributions of this paper are summarized as follows:</p>
        <p>• Based on the Transformer [16], a novel framework for the DeepSC is proposed, which can effectively extract the semantic information from texts with robustness to noise.• Based on the Transformer [16], a novel framework for the DeepSC is proposed, which can effectively extract the semantic information from texts with robustness to noise.</p>
        <p>In the proposed DeepSC, a joint semantic-channel coding is designed to cope with channel noise and semantic distortion, which addresses aforementioned Question 3. • The transceiver of the DeepSC is composed of semantic encoder, channel encoder, channel decoder, and semantic decoder. To understand the semantic meaning as well as maximize the system capacity at the same time, the receiver is optimized with two loss functions: crossentropy and mutual information. Moreover, a new metric is proposed to accurately reflect the performance of the DeepSC at the semantic level. These address the aforementioned Questions 1 and 2. • To make the DeepSC applicable to various communication scenarios, deep transfer learning is adopted to accelerate the model re-training. With the re-trained model, the DeepSC can recognise various knowledge input and recover semantic information from distortion. • Based on extensive simulation results, the proposed DeepSC outperforms the traditional communication system and improves the system robustness at the low SNR regime. The rest of this paper is organized as follows. Related work is briefly reviewed in Section II. The framework of a seman-tic communication system is presented and a corresponding problem is formulated in Section III. Section IV details the proposed DeepSC and extends it to dynamic environments. Numerical results are presented in Section VI to show the performance of the DeepSC. Finally, Section VII concludes this paper.In the proposed DeepSC, a joint semantic-channel coding is designed to cope with channel noise and semantic distortion, which addresses aforementioned Question 3. • The transceiver of the DeepSC is composed of semantic encoder, channel encoder, channel decoder, and semantic decoder. To understand the semantic meaning as well as maximize the system capacity at the same time, the receiver is optimized with two loss functions: crossentropy and mutual information. Moreover, a new metric is proposed to accurately reflect the performance of the DeepSC at the semantic level. These address the aforementioned Questions 1 and 2. • To make the DeepSC applicable to various communication scenarios, deep transfer learning is adopted to accelerate the model re-training. With the re-trained model, the DeepSC can recognise various knowledge input and recover semantic information from distortion. • Based on extensive simulation results, the proposed DeepSC outperforms the traditional communication system and improves the system robustness at the low SNR regime. The rest of this paper is organized as follows. Related work is briefly reviewed in Section II. The framework of a seman-tic communication system is presented and a corresponding problem is formulated in Section III. Section IV details the proposed DeepSC and extends it to dynamic environments. Numerical results are presented in Section VI to show the performance of the DeepSC. Finally, Section VII concludes this paper.</p>
        <p>N otation: C n×m and R n×m represent sets of complex and real matrices of size n × m, respectively. Bold-font variables denote matrices or vectors. x ∼ CN (µ, σ 2 ) means variable x follows a circularly-symmetric complex Gaussian distribution with mean µ and covariance σ 2 . (•) T and (•) H denote the transpose and Hermitian, respectively. {•} and {•} refer to the real and imaginary parts of a complex number. Finally, a ⊗ b indicates the inner product of vectors a and b.N otation: C n×m and R n×m represent sets of complex and real matrices of size n × m, respectively. Bold-font variables denote matrices or vectors. x ∼ CN (µ, σ 2 ) means variable x follows a circularly-symmetric complex Gaussian distribution with mean µ and covariance σ 2 . (•) T and (•) H denote the transpose and Hermitian, respectively. {•} and {•} refer to the real and imaginary parts of a complex number. Finally, a ⊗ b indicates the inner product of vectors a and b.</p>
        <p>This section provides a brief review of the related work on the E2E physical layer communication systems and the deep neural network (DNN) techniques adopted in NLP.This section provides a brief review of the related work on the E2E physical layer communication systems and the deep neural network (DNN) techniques adopted in NLP.</p>
        <p>DL techniques have shown great potential in processing various intelligent tasks, i.e., computer vision and NLP. Meanwhile, it is possible to train neural networks and run them on mobile devices due to the increasing hardware computing capability. In the communication area, some pioneering works have been carried on DL based E2E physical layer communication systems, which merge the blocks in traditional communication systems [17]- [23]. By adopting the structure of autoencoder in DL and removing block structure, the transmitter and receiver in the E2E system are optimized jointly as an E2E reconstruction task. It has been demonstrated that such an E2E system outperforms uncoded binary phase shift keying (BPSK) and Hamming coded BPSK in terms of BER [17]. Besides, there are several initial works on dealing with the missing channel gradient during training. A DNN based two-phase of training processing has been proposed, where the transceiver is trained by an stochastic channel model and the receiver is fine-tuned under real channels [18]. Reinforcement learning has been exploited in [19] to acquire the channel gradient under an unknown channel model, which achieves better performance than the differential quadrature phase-shift keying (DQPSK) over real channels. A conditional generative adversarial net (GAN) has been applied in [20] to use a DNN to represent the channel distortion so that the gradients can pass through a unknown channel to the transmitter DNN during the training of the E2E communication system. Metalearning combined with a limited number of pilots has been developed for training the transceiver and enables the fast training of network with less amount of data [21].DL techniques have shown great potential in processing various intelligent tasks, i.e., computer vision and NLP. Meanwhile, it is possible to train neural networks and run them on mobile devices due to the increasing hardware computing capability. In the communication area, some pioneering works have been carried on DL based E2E physical layer communication systems, which merge the blocks in traditional communication systems [17]- [23]. By adopting the structure of autoencoder in DL and removing block structure, the transmitter and receiver in the E2E system are optimized jointly as an E2E reconstruction task. It has been demonstrated that such an E2E system outperforms uncoded binary phase shift keying (BPSK) and Hamming coded BPSK in terms of BER [17]. Besides, there are several initial works on dealing with the missing channel gradient during training. A DNN based two-phase of training processing has been proposed, where the transceiver is trained by an stochastic channel model and the receiver is fine-tuned under real channels [18]. Reinforcement learning has been exploited in [19] to acquire the channel gradient under an unknown channel model, which achieves better performance than the differential quadrature phase-shift keying (DQPSK) over real channels. A conditional generative adversarial net (GAN) has been applied in [20] to use a DNN to represent the channel distortion so that the gradients can pass through a unknown channel to the transmitter DNN during the training of the E2E communication system. Metalearning combined with a limited number of pilots has been developed for training the transceiver and enables the fast training of network with less amount of data [21].</p>
        <p>Considering the types of sources, the joint source-channel coding for texts [22] and images [23] aims to recover the source information at the receiver directly rather than the digital bits. Meanwhile, traditional metrics, such as BER, cannot reflect the performance for such systems well. Therefore, word-error rate and peak signal-to-noise ratio (PSNR) are adopted for measuring the accuracy of source information recovery.Considering the types of sources, the joint source-channel coding for texts [22] and images [23] aims to recover the source information at the receiver directly rather than the digital bits. Meanwhile, traditional metrics, such as BER, cannot reflect the performance for such systems well. Therefore, word-error rate and peak signal-to-noise ratio (PSNR) are adopted for measuring the accuracy of source information recovery.</p>
        <p>NLP makes machines understand human languages, with the main goal to understand the syntax and text. Initially, natural language can be described by the joint probability model according to the context [24]. Thus, language models provide context to distinguish words and phrases that have similar semantic meaning. Although such NLP technologies based on statistical model are developed to describe the probability of a certain word coming after another in a sentence, it is hard to deal with long sentences, i.e. the ones over 15 words, and the syntax. To understand long sentences, the word2vec model in [25] captures the relationship among words, which makes similar words ending up with a closer distance in the vector space. Even if these dense word vectors can capture the relationship among words, they fail to describe syntax information. In order to solve such problems, the underlying meaning of texts is represented by using various DL techniques, which is able to extract the semantic information in long sentences and their syntax. A deep contextualized word representation has been proposed in [26], which models both complex characteristics of word usages, e.g., syntax and semantics, and how these usages vary across linguistic contexts (i.e., to model polysemy). However, the above word representation approaches are designed for specific tasks and may need to be redesigned whenever the task changes. In [27], a general word representation model, named bidirectional encoder representations from transformers (BERT), has been developed to provide word vectors for various NLP tasks without requiring redesign of word representations.NLP makes machines understand human languages, with the main goal to understand the syntax and text. Initially, natural language can be described by the joint probability model according to the context [24]. Thus, language models provide context to distinguish words and phrases that have similar semantic meaning. Although such NLP technologies based on statistical model are developed to describe the probability of a certain word coming after another in a sentence, it is hard to deal with long sentences, i.e. the ones over 15 words, and the syntax. To understand long sentences, the word2vec model in [25] captures the relationship among words, which makes similar words ending up with a closer distance in the vector space. Even if these dense word vectors can capture the relationship among words, they fail to describe syntax information. In order to solve such problems, the underlying meaning of texts is represented by using various DL techniques, which is able to extract the semantic information in long sentences and their syntax. A deep contextualized word representation has been proposed in [26], which models both complex characteristics of word usages, e.g., syntax and semantics, and how these usages vary across linguistic contexts (i.e., to model polysemy). However, the above word representation approaches are designed for specific tasks and may need to be redesigned whenever the task changes. In [27], a general word representation model, named bidirectional encoder representations from transformers (BERT), has been developed to provide word vectors for various NLP tasks without requiring redesign of word representations.</p>
        <p>There are three types of neural networks used for NLP tasks, including recurrent neural networks (RNNs), convolutional neural networks (CNNs) and fully-connected neural networks (FCNs) [28]. By introducing RNNs, language models can learn the whole sentences and capture the syntax information effectively [29]. However, for long sentences, particularly, the distance between subject and predicate is more than 10 words, RNNs cannot find the correct subject and predicate. For example, for sentence "the person who works in the new post office is walking to the store", RNNs fail to recognise the relationship between "the person" and "is". Besides, because of linear sequence structure, RNNs lack of parallel computing capability, which means that RNNs are time-consuming. CNNs were born with the capability of parallel computing [30]. However, even if CNNs can use deeper network to extract semantic information in long sentences, its performance is not as good as that of RNNs because the kernel size in CNNs is small to guarantee the computational efficiency. By combining with the attention mechanism, language models based on FCNs, such as Transformer [16], pay more attention to the useful semantic information for performance improvement on various NLP tasks. It is worth noting that the Transformer has the advantages of both RNNs and CNNs [16]. Particularly, the self-attention mechanism is adopted, which enables the models to understand sentences regardless of their lengths.There are three types of neural networks used for NLP tasks, including recurrent neural networks (RNNs), convolutional neural networks (CNNs) and fully-connected neural networks (FCNs) [28]. By introducing RNNs, language models can learn the whole sentences and capture the syntax information effectively [29]. However, for long sentences, particularly, the distance between subject and predicate is more than 10 words, RNNs cannot find the correct subject and predicate. For example, for sentence "the person who works in the new post office is walking to the store", RNNs fail to recognise the relationship between "the person" and "is". Besides, because of linear sequence structure, RNNs lack of parallel computing capability, which means that RNNs are time-consuming. CNNs were born with the capability of parallel computing [30]. However, even if CNNs can use deeper network to extract semantic information in long sentences, its performance is not as good as that of RNNs because the kernel size in CNNs is small to guarantee the computational efficiency. By combining with the attention mechanism, language models based on FCNs, such as Transformer [16], pay more attention to the useful semantic information for performance improvement on various NLP tasks. It is worth noting that the Transformer has the advantages of both RNNs and CNNs [16]. Particularly, the self-attention mechanism is adopted, which enables the models to understand sentences regardless of their lengths.</p>
        <p>The considered system model consists of two levels: semantic level and transmission level, as shown in Fig. 1. The semantic level addresses semantic information processing for encoding and decoding to extract the semantic information. The transmission level guarantees that semantic information can be exchanged correctly over the transmission medium. Overall, we consider an intelligent E2E communication system with the stochastic physical channel, where the transmitter and the receiver have certain background knowledge, i.e., different training data. The background knowledge could be various for different application scenarios.The considered system model consists of two levels: semantic level and transmission level, as shown in Fig. 1. The semantic level addresses semantic information processing for encoding and decoding to extract the semantic information. The transmission level guarantees that semantic information can be exchanged correctly over the transmission medium. Overall, we consider an intelligent E2E communication system with the stochastic physical channel, where the transmitter and the receiver have certain background knowledge, i.e., different training data. The background knowledge could be various for different application scenarios.</p>
        <p>Definition 1: Semantic noise is a type of disturbance in the exchange of a message that interferes with the interpretation of the message due to ambiguity in words, a sentence or symbols used in the message transmission.Definition 1: Semantic noise is a type of disturbance in the exchange of a message that interferes with the interpretation of the message due to ambiguity in words, a sentence or symbols used in the message transmission.</p>
        <p>Definition 2: Physical channel noise is caused by the physical channel impairment, such as, additive white Gaussian noise (AWGN), fading channel, and multiple path, which incurs the signal attenuation and distortion.Definition 2: Physical channel noise is caused by the physical channel impairment, such as, additive white Gaussian noise (AWGN), fading channel, and multiple path, which incurs the signal attenuation and distortion.</p>
        <p>As in Fig. 1, the transmitter maps a sentence, s, into a complex symbol stream, x, and then passes it through the physical channel with transmission impairments, such as distortion and noise. The received, y, is decoded at the receiver to estimate the original sentence, s. We jointly design the transmitter and receiver with DNNs since DL enables us to train a model with inputting variable-length sentences and different languages.As in Fig. 1, the transmitter maps a sentence, s, into a complex symbol stream, x, and then passes it through the physical channel with transmission impairments, such as distortion and noise. The received, y, is decoded at the receiver to estimate the original sentence, s. We jointly design the transmitter and receiver with DNNs since DL enables us to train a model with inputting variable-length sentences and different languages.</p>
        <p>Particularly, we assume that the input of the DeepSC isParticularly, we assume that the input of the DeepSC is</p>
        <p>where w l represents the l-th word in the sentence. As shown in Fig. 1, the transmitter consists of two parts, named semantic encoder and channel encoder, to extract the semantic information from s and guarantee successful transmission of semantic information over the physical channel. The encoded symbol stream can be represented bywhere w l represents the l-th word in the sentence. As shown in Fig. 1, the transmitter consists of two parts, named semantic encoder and channel encoder, to extract the semantic information from s and guarantee successful transmission of semantic information over the physical channel. The encoded symbol stream can be represented by</p>
        <p>where x ∈ C M ×1 , S β (•) is the semantic encoder network with the parameter set β and C α (•) is the channel encoder with the parameter set α. In order to simplify the analysis, we assume the coherent time is M . If x is sent, the signal received at the receiver will bewhere x ∈ C M ×1 , S β (•) is the semantic encoder network with the parameter set β and C α (•) is the channel encoder with the parameter set α. In order to simplify the analysis, we assume the coherent time is M . If x is sent, the signal received at the receiver will be</p>
        <p>where y ∈ C M ×1 , h represents the Rayleigh fading channel with CN (0, 1) and n ∼ CN 0, σ 2 n . For E2E training of the encoder and the decoder, the channel must allow backpropagation. Physical channels can be formulated by neural networks. For example, simple neural networks could be used to model the AWGN channel, multiplicative Gaussian noise channel, and the erasure channel [22]. While for the fading channels, more complicated neural networks are required [20]. In this paper, we mainly consider the AWGN channels and Rayleigh fading channels for simplicity while focus on semantic coding and decoding.where y ∈ C M ×1 , h represents the Rayleigh fading channel with CN (0, 1) and n ∼ CN 0, σ 2 n . For E2E training of the encoder and the decoder, the channel must allow backpropagation. Physical channels can be formulated by neural networks. For example, simple neural networks could be used to model the AWGN channel, multiplicative Gaussian noise channel, and the erasure channel [22]. While for the fading channels, more complicated neural networks are required [20]. In this paper, we mainly consider the AWGN channels and Rayleigh fading channels for simplicity while focus on semantic coding and decoding.</p>
        <p>As shown in Fig. 1, the receiver includes channel decoder and semantic decoder to recover the transmitted symbols and then transmitted sentences, respectively. The decoded signal can be represented asAs shown in Fig. 1, the receiver includes channel decoder and semantic decoder to recover the transmitted symbols and then transmitted sentences, respectively. The decoded signal can be represented as</p>
        <p>where the ŝ is the recovered sentence, C -1 δ (•) is the channel decoder with the parameter set δ and S -1 χ (•) is the semantic decoder network with the parameter set χ.where the ŝ is the recovered sentence, C -1 δ (•) is the channel decoder with the parameter set δ and S -1 χ (•) is the semantic decoder network with the parameter set χ.</p>
        <p>The goal of the system is to minimize the semantic errors while reducing the number of symbols to be transmitted. However, we face two challenges in the considered system. The first challenge is how to design joint semantic-channel coding. The other one is semantic transmission, which has not been considered in the traditional communication system. Even if the existing communication system can achieve a low BER, several bits, distorted by the noise and beyond error correction capability, could lead to understanding difficulty as the partial semantic information of the whole sentence might be missed. In order to achieve successful recovery at semantic level, we design semantic and channel coding jointly in order to keep the meaning between ŝ and s unchanged, which is enabled by a new DNN framework. The cross-entropy (CE) is used as the loss function to measure the difference between s and ŝ, which can be formulated asThe goal of the system is to minimize the semantic errors while reducing the number of symbols to be transmitted. However, we face two challenges in the considered system. The first challenge is how to design joint semantic-channel coding. The other one is semantic transmission, which has not been considered in the traditional communication system. Even if the existing communication system can achieve a low BER, several bits, distorted by the noise and beyond error correction capability, could lead to understanding difficulty as the partial semantic information of the whole sentence might be missed. In order to achieve successful recovery at semantic level, we design semantic and channel coding jointly in order to keep the meaning between ŝ and s unchanged, which is enabled by a new DNN framework. The cross-entropy (CE) is used as the loss function to measure the difference between s and ŝ, which can be formulated as</p>
        <p>where q(w l ) is the real probability that the l-th word, w l , appears in estimated sentence s, and p(w l ) is the predicted probability that the i-th word, w i , appears in sentence ŝ. The CE can measure the difference between two probability distributions. Through reducing the loss value of CE, the network can learn the word distribution, q(w l ), in the source sentence, s, which indicates that the syntax, phrase, the meaning of words in context can be learnt by the network. Besides, jointly designing and training semantic-channel coding can make the whole network learning the knowledge for the specific goal. In other words, the channel coding can pay more attention in protecting the semantic information related to transmission goal while neglecting other irrelevant information. Separately designing will make channel coding addressing all information equally.where q(w l ) is the real probability that the l-th word, w l , appears in estimated sentence s, and p(w l ) is the predicted probability that the i-th word, w i , appears in sentence ŝ. The CE can measure the difference between two probability distributions. Through reducing the loss value of CE, the network can learn the word distribution, q(w l ), in the source sentence, s, which indicates that the syntax, phrase, the meaning of words in context can be learnt by the network. Besides, jointly designing and training semantic-channel coding can make the whole network learning the knowledge for the specific goal. In other words, the channel coding can pay more attention in protecting the semantic information related to transmission goal while neglecting other irrelevant information. Separately designing will make channel coding addressing all information equally.</p>
        <p>One important goal on designing a communication system is to maximize the capacity or the data transmission rate. Compared with BER, the mutual information can provide extra information to train a receiver. The mutual information of the transmitted symbols, x, and the received symbols, y, can be computed byOne important goal on designing a communication system is to maximize the capacity or the data transmission rate. Compared with BER, the mutual information can provide extra information to train a receiver. The mutual information of the transmitted symbols, x, and the received symbols, y, can be computed by</p>
        <p>where (x, y) is a pair of random variables with values over the space X × Y, where X and Y are the spaces for x and y. p(x) and p(y) are the marginal probability of sending x and received y, respectively, and p(x, y) is the joint probability of x and y. The mutual information is equivalent to the Kullback-Leibler (KL) divergence between the marginal probabilities and the joint probability, which is given bywhere (x, y) is a pair of random variables with values over the space X × Y, where X and Y are the spaces for x and y. p(x) and p(y) are the marginal probability of sending x and received y, respectively, and p(x, y) is the joint probability of x and y. The mutual information is equivalent to the Kullback-Leibler (KL) divergence between the marginal probabilities and the joint probability, which is given by</p>
        <p>From [31], we have the following theorem, Theorem 1: The KL divergence admits the following dual representationFrom [31], we have the following theorem, Theorem 1: The KL divergence admits the following dual representation</p>
        <p>where the supremum is taken over all functions T such that the two expectations are finite.where the supremum is taken over all functions T such that the two expectations are finite.</p>
        <p>According to Theorem 1, the KL divergence can also be represented asAccording to Theorem 1, the KL divergence can also be represented as</p>
        <p>(8) Thus, the lower bound of I (x; y) can be obtained from ( 6) and (8). In order to find a tight bound on the I (x; y), an unsupervised method is used to train the network T , where T can be approximated by neural network. Meanwhile, the expectation in (8) can be computed by sampling, which converges to the true value as the number of samples increases. Then, we can optimize the encoder by maximizing the mutual information defined in (8) and the related loss function can be given by(8) Thus, the lower bound of I (x; y) can be obtained from ( 6) and (8). In order to find a tight bound on the I (x; y), an unsupervised method is used to train the network T , where T can be approximated by neural network. Meanwhile, the expectation in (8) can be computed by sampling, which converges to the true value as the number of samples increases. Then, we can optimize the encoder by maximizing the mutual information defined in (8) and the related loss function can be given by</p>
        <p>where f T is composed by a neural network, in which the inputs are samples from p(x, y), p(x), and p(y). In our proposed design, x is generated by the function C α and S β , thus the loss function can be represented by L MI (x, y; T, α, β) withwhere f T is composed by a neural network, in which the inputs are samples from p(x, y), p(x), and p(y). In our proposed design, x is generated by the function C α and S β , thus the loss function can be represented by L MI (x, y; T, α, β) with</p>
        <p>From (10), the loss function can be used to train neural networks to get α, β, and T . For example, the mutual information can be estimated by training network T when the encoders α and β are fixed. Similarly, the encoder can be optimized by training α and β when the mutual information is obtained.From (10), the loss function can be used to train neural networks to get α, β, and T . For example, the mutual information can be estimated by training network T when the encoders α and β are fixed. Similarly, the encoder can be optimized by training α and β when the mutual information is obtained.</p>
        <p>Fig. 2. The proposed neural network structure for the semantic communication system.Fig. 2. The proposed neural network structure for the semantic communication system.</p>
        <p>Performance criteria are important to the system design. In the E2E communication system, the BER is usually taken as the training target by the transmitter and receiver, which sometimes neglects the other aspect goals of communication. For text transmission, BER cannot reflect performance well. Except from human judgement to establish the similarity between sentences, bilingual evaluation understudy (BLEU) score is usually used to measure the results in machine translation [32], which will be used as one of the performance metrics in this paper. However, the BLEU score can only compare the difference between words in two sentences rather than their semantic information. Therefore, we initialize a new metric, named sentence similarity, to describe the similarity level of two sentences in terms of their semantic information, which is introduced in the following. This provides a solution to Question 2.Performance criteria are important to the system design. In the E2E communication system, the BER is usually taken as the training target by the transmitter and receiver, which sometimes neglects the other aspect goals of communication. For text transmission, BER cannot reflect performance well. Except from human judgement to establish the similarity between sentences, bilingual evaluation understudy (BLEU) score is usually used to measure the results in machine translation [32], which will be used as one of the performance metrics in this paper. However, the BLEU score can only compare the difference between words in two sentences rather than their semantic information. Therefore, we initialize a new metric, named sentence similarity, to describe the similarity level of two sentences in terms of their semantic information, which is introduced in the following. This provides a solution to Question 2.</p>
        <p>1) BLEU Score: Through counting the difference of ngrams between transmitted and received texts, where n-grams means that the size of a word group. For example, for sentence "weather is good today", 1-gram: "weather", "is", "good" and "today", 2-grams: "weather is", "is good" and "good today". The same rule applies for the rest.1) BLEU Score: Through counting the difference of ngrams between transmitted and received texts, where n-grams means that the size of a word group. For example, for sentence "weather is good today", 1-gram: "weather", "is", "good" and "today", 2-grams: "weather is", "is good" and "good today". The same rule applies for the rest.</p>
        <p>For the transmitted sentence s with length l s and the decoded sentence ŝ with length l ŝ, the BLEU can be expressed asFor the transmitted sentence s with length l s and the decoded sentence ŝ with length l ŝ, the BLEU can be expressed as</p>
        <p>where u n is the weights of n-grams and p n is the n-grams score, which iswhere u n is the weights of n-grams and p n is the n-grams score, which is</p>
        <p>where C k (•) is the frequency count function for the k-th elements in n-th grams.where C k (•) is the frequency count function for the k-th elements in n-th grams.</p>
        <p>The output of BLEU is a number between 0 and 1, which indicates how similar the decoded text is to the transmitted text, with 1 representing highest similarity. However, few human translations will attain the score of 1 since word error may not make the meaning of a sentence different. For instance, the two sentences, "my car was parked there" and "my automobile was parked there", have the same meaning but with different BLEU scores since they use different words.The output of BLEU is a number between 0 and 1, which indicates how similar the decoded text is to the transmitted text, with 1 representing highest similarity. However, few human translations will attain the score of 1 since word error may not make the meaning of a sentence different. For instance, the two sentences, "my car was parked there" and "my automobile was parked there", have the same meaning but with different BLEU scores since they use different words.</p>
        <p>To characterize such a feature, we propose a new metric, the sentence similarity, at the sentence level in addition to the BLEU score.To characterize such a feature, we propose a new metric, the sentence similarity, at the sentence level in addition to the BLEU score.</p>
        <p>2) Sentence Similarity: A word can take different meanings in different contexts. For instance, the meanings of mouse in biology and machine are different. The traditional method, such as word2vec [25], cannot recognise the polysemy, of which the problem is how to use an numerical vector to express the word while the numerical vector varies in different contexts. According to the semantic similarity, we propose to calculate the sentence similarity between the original sentence, s, and the recovered sentence, ŝ, as2) Sentence Similarity: A word can take different meanings in different contexts. For instance, the meanings of mouse in biology and machine are different. The traditional method, such as word2vec [25], cannot recognise the polysemy, of which the problem is how to use an numerical vector to express the word while the numerical vector varies in different contexts. According to the semantic similarity, we propose to calculate the sentence similarity between the original sentence, s, and the recovered sentence, ŝ, as</p>
        <p>where B Φ , representing BERT [27], is a huge pre-trained model including billions of parameters used for extracting the semantic information. The sentence similarity defined in ( 13) is a number between 0 and 1, which indicates how similar the decoded sentence is to the transmitted sentence, with 1 representing highest similarity and 0 representing no similarity between s and ŝ.where B Φ , representing BERT [27], is a huge pre-trained model including billions of parameters used for extracting the semantic information. The sentence similarity defined in ( 13) is a number between 0 and 1, which indicates how similar the decoded sentence is to the transmitted sentence, with 1 representing highest similarity and 0 representing no similarity between s and ŝ.</p>
        <p>Compared with BLEU score, BERT has been fed by billions of sentences. Therefore, it has already learnt the semantic information from these sentences and can generate different semantic vectors in different contexts effectively. With the BERT, the semantic information behind a transmitted sentence, s, can be expressed as c. Meanwhile, the semantic information conveyed by the estimated sentence is expressed as ĉ. For c and ĉ, we can compute the sentence similarity by match(c, ĉ).Compared with BLEU score, BERT has been fed by billions of sentences. Therefore, it has already learnt the semantic information from these sentences and can generate different semantic vectors in different contexts effectively. With the BERT, the semantic information behind a transmitted sentence, s, can be expressed as c. Meanwhile, the semantic information conveyed by the estimated sentence is expressed as ĉ. For c and ĉ, we can compute the sentence similarity by match(c, ĉ).</p>
        <p>SYSTEMS In this section, we propose a DNN for the considered semantic communication system, named as DeepSC, of which the Transformer is adopted for text understanding. Then, transfer learning is adopted to make the DeepSC applicable to different background knowledge and dynamic communication environments. This provides the solutions to Question 1,3.SYSTEMS In this section, we propose a DNN for the considered semantic communication system, named as DeepSC, of which the Transformer is adopted for text understanding. Then, transfer learning is adopted to make the DeepSC applicable to different background knowledge and dynamic communication environments. This provides the solutions to Question 1,3.</p>
        <p>The proposed DeepSC is as shown in Fig 2 . Particularly, the transmitter consists of a semantic encoder to extract the semantic features from the texts to be transmitted and a channel encoder to generate symbols to facilitate the transmission subsequently. The semantic encoder includes multiple Transformer encoder layers and the channel encoder uses dense layers with different units. The AWGN channel is interpreted as one layer in the model. Accordingly, the DeepSC receiver is composited with a channel decoder for symbol detection and a semantic decoder for text estimation, the channel decoder includes dense layers with different units and the semantic decoder includes multiple Transformer decoder layers. The loss function can be expressed as (14) where the first term is the loss function considering the sentence similarity, which aims to minimize the semantic difference between s and ŝ by training the whole system. The second one is the loss function for mutual information, which maximize the achieved data rate during the transmitter training. The parameter λ (0 ≤ λ ≤ 1) is the weight for the second term.The proposed DeepSC is as shown in Fig 2 . Particularly, the transmitter consists of a semantic encoder to extract the semantic features from the texts to be transmitted and a channel encoder to generate symbols to facilitate the transmission subsequently. The semantic encoder includes multiple Transformer encoder layers and the channel encoder uses dense layers with different units. The AWGN channel is interpreted as one layer in the model. Accordingly, the DeepSC receiver is composited with a channel decoder for symbol detection and a semantic decoder for text estimation, the channel decoder includes dense layers with different units and the semantic decoder includes multiple Transformer decoder layers. The loss function can be expressed as (14) where the first term is the loss function considering the sentence similarity, which aims to minimize the semantic difference between s and ŝ by training the whole system. The second one is the loss function for mutual information, which maximize the achieved data rate during the transmitter training. The parameter λ (0 ≤ λ ≤ 1) is the weight for the second term.</p>
        <p>The core of Transformer is the multi-head self-attention mechanism, which enables the Transformer to view the previous predicted word in the sequence, thereby better predicting the next word. Fig. 3 gives an example of the self-attention mechanism for the word 'it'. From Fig. 3, attention attend to a distant dependency of the pronoun, 'it', completing pronoun reference "the animal", which demonstrates that the selfattention mechanism can learn the semantic and therefore solve aforementioned Question 1. Train the mutual information estimated model.The core of Transformer is the multi-head self-attention mechanism, which enables the Transformer to view the previous predicted word in the sequence, thereby better predicting the next word. Fig. 3 gives an example of the self-attention mechanism for the word 'it'. From Fig. 3, attention attend to a distant dependency of the pronoun, 'it', completing pronoun reference "the animal", which demonstrates that the selfattention mechanism can learn the semantic and therefore solve aforementioned Question 1. Train the mutual information estimated model.</p>
        <p>Train the whole network. 6: end while 7: Output: The whole networkTrain the whole network. 6: end while 7: Output: The whole network</p>
        <p>As shown in Algorithm 1, the training process of the DeepSC consists of two phases due to different loss functions. After initializing the weights, W, bias, b, and using embedding vector to represent the input words, the first phase is to train the mutual information model by unsupervised learning to estimate the achieved data rate for the second phase. The second phase is to train the whole system with ( 14) as the loss function. Each phase aims to minimize the loss by gradient descent with mini-batch until the stop criterion is met, the max number of iteration is reached, or none of terms in the loss function is decreased any more. Different from performing semantic coding and channel coding separately, where the channel encoder/decoder will deal with the digital bits rather than the semantic information, the joint semantic-channel coding can preserve semantic information when compressing data, which provides the detailed solution for aforementioned Question 3. The two training phases are described in the following:As shown in Algorithm 1, the training process of the DeepSC consists of two phases due to different loss functions. After initializing the weights, W, bias, b, and using embedding vector to represent the input words, the first phase is to train the mutual information model by unsupervised learning to estimate the achieved data rate for the second phase. The second phase is to train the whole system with ( 14) as the loss function. Each phase aims to minimize the loss by gradient descent with mini-batch until the stop criterion is met, the max number of iteration is reached, or none of terms in the loss function is decreased any more. Different from performing semantic coding and channel coding separately, where the channel encoder/decoder will deal with the digital bits rather than the semantic information, the joint semantic-channel coding can preserve semantic information when compressing data, which provides the detailed solution for aforementioned Question 3. The two training phases are described in the following:</p>
        <p>1) Training of mutual information estimation model: The mutual information estimation model training process is illustrated in Fig. 4 and the pseudocode is given in Algorithm 2. First, the knowledge set K generates a minibatch of sentences S ∈ B×L×1 , where B is the batch size, L is the length of sentences. Through the embedding layer, the sentences can be represented as a dense word vector E ∈ B×L×E , where E is the dimension of the word vector. Then, pass the semantic encoder layer to obtain M ∈ B×L×V , the semantic information conveyed by S, where V is the dimension of Transformer encoder's output. Then, M is encoded into symbols X to cope with the effects from the physical channel, where X ∈ B×N L×2 . After passing through the channel, the receiver obtains signal Y distorted by the channel noise. Based on (9), the loss, L MI (X, Y; T, α, β), can be computed based on the transmitted symbols, X, and the received symbols, Y, under the AWGN channels. Finally, according to computed L MI , the stochastic gradient descent (SGD) is exploited to optimize the weights and bias of f T (•).1) Training of mutual information estimation model: The mutual information estimation model training process is illustrated in Fig. 4 and the pseudocode is given in Algorithm 2. First, the knowledge set K generates a minibatch of sentences S ∈ B×L×1 , where B is the batch size, L is the length of sentences. Through the embedding layer, the sentences can be represented as a dense word vector E ∈ B×L×E , where E is the dimension of the word vector. Then, pass the semantic encoder layer to obtain M ∈ B×L×V , the semantic information conveyed by S, where V is the dimension of Transformer encoder's output. Then, M is encoded into symbols X to cope with the effects from the physical channel, where X ∈ B×N L×2 . After passing through the channel, the receiver obtains signal Y distorted by the channel noise. Based on (9), the loss, L MI (X, Y; T, α, β), can be computed based on the transmitted symbols, X, and the received symbols, Y, under the AWGN channels. Finally, according to computed L MI , the stochastic gradient descent (SGD) is exploited to optimize the weights and bias of f T (•).</p>
        <p>2) Whole network training: The whole network training process is illustrated in Algorithm 3. First, minibatch S from knowledge K is encoded into M at the semantic level, then M is encoded into symbol X for transmission over the physical channels. At the receiver, distorted symbols Y are received and then decoded by the channel decoder layer, where M ∈ B×L×V is the recovered semantic information of the sources. Afterwards, the transmitted sentences are estimated by the semantic decoder layer. Finally, the whole network is optimized by the SGD, where the loss is computed by (14). BatchSource(K) → S.2) Whole network training: The whole network training process is illustrated in Algorithm 3. First, minibatch S from knowledge K is encoded into M at the semantic level, then M is encoded into symbol X for transmission over the physical channels. At the receiver, distorted symbols Y are received and then decoded by the channel decoder layer, where M ∈ B×L×V is the recovered semantic information of the sources. Afterwards, the transmitted sentences are estimated by the semantic decoder layer. Finally, the whole network is optimized by the SGD, where the loss is computed by (14). BatchSource(K) → S.</p>
        <p>S β (S) → M.S β (S) → M.</p>
        <p>C α (M) → X.C α (M) → X.</p>
        <p>Transmit X over the channel. 7: Receiver: S β (S) → M.Transmit X over the channel. 7: Receiver: S β (S) → M.</p>
        <p>C α (M) → X.C α (M) → X.</p>
        <p>Transmit X over the channel. 7: Receiver:Transmit X over the channel. 7: Receiver:</p>
        <p>Receive Y.Receive Y.</p>
        <p>C -1 δ (Y) → M.C -1 δ (Y) → M.</p>
        <p>S -1 χ ( M) → Ŝ.S -1 χ ( M) → Ŝ.</p>
        <p>Compute loss function L total by ( 14).Compute loss function L total by ( 14).</p>
        <p>12:12:</p>
        <p>Train β, α, δ, χ → Gradient descent (β, α, δ, χ, L total ). 13: Output: The whole networkTrain β, α, δ, χ → Gradient descent (β, α, δ, χ, L total ). 13: Output: The whole network</p>
        <p>In practice, different communication scenarios result in the different channels and the training data. However, the retraining of transmitter and receiver to meet the requirements of dynamic scenarios introduces extra costs. To address this, a deep transfer learning approach is adopted, which focuses on storing knowledge gained while solving a problem and applying it to a different but related problem.In practice, different communication scenarios result in the different channels and the training data. However, the retraining of transmitter and receiver to meet the requirements of dynamic scenarios introduces extra costs. To address this, a deep transfer learning approach is adopted, which focuses on storing knowledge gained while solving a problem and applying it to a different but related problem.</p>
        <p>The training process of adopting transfer learning is illustrated in Fig. 5 Train the mutual information estimated model.The training process of adopting transfer learning is illustrated in Fig. 5 Train the mutual information estimated model.</p>
        <p>Train the whole network. 7: end while 8: Output: The adopted whole network. Train the mutual information estimated model.Train the whole network. 7: end while 8: Output: The adopted whole network. Train the mutual information estimated model.</p>
        <p>Train the whole network. 15: end while 16: Output: The re-trained network.Train the whole network. 15: end while 16: Output: The re-trained network.</p>
        <p>transmitter and receiver based on knowledge K 0 and channel N 0 . For applications with different background knowledge, we only need to redesign and train part of the semantic encoder and decoder layers and freeze the channel encoder and decoder layers. For different communication environments, we redesign and train part of the channel encoder and decoder layers and freeze the semantic encoder and decoder layers. If the knowledge and channel are totally different, the pre-trained transceiver can also reduce the time consumption because the weights of some layers in the pre-trained model can be reused in the new model even if the most layers need to redesign. After the other modules are trained, we will unfreeze them and train the whole network with few epochs to converge to the global optimum.transmitter and receiver based on knowledge K 0 and channel N 0 . For applications with different background knowledge, we only need to redesign and train part of the semantic encoder and decoder layers and freeze the channel encoder and decoder layers. For different communication environments, we redesign and train part of the channel encoder and decoder layers and freeze the semantic encoder and decoder layers. If the knowledge and channel are totally different, the pre-trained transceiver can also reduce the time consumption because the weights of some layers in the pre-trained model can be reused in the new model even if the most layers need to redesign. After the other modules are trained, we will unfreeze them and train the whole network with few epochs to converge to the global optimum.</p>
        <p>In this section, we compare the proposed DeepSC with other DNN algorithms and the traditional source coding and channel coding approaches under the AWGN channels and Rayleigh fading channels, where we assume perfect CSI for all schemes. The transfer learning aided DeepSC is also verified under the erase channel and fading channel as well as different background knowledge.In this section, we compare the proposed DeepSC with other DNN algorithms and the traditional source coding and channel coding approaches under the AWGN channels and Rayleigh fading channels, where we assume perfect CSI for all schemes. The transfer learning aided DeepSC is also verified under the erase channel and fading channel as well as different background knowledge.</p>
        <p>The adopted dataset is the proceedings of the European Parliament [33], which consists of around 2.0 million sentences and 53 million words. The dataset is pre-processed into lengths of sentences with 4 to 30 words and is split into training data and testing data.The adopted dataset is the proceedings of the European Parliament [33], which consists of around 2.0 million sentences and 53 million words. The dataset is pre-processed into lengths of sentences with 4 to 30 words and is split into training data and testing data.</p>
        <p>In the experiment, we set three Transformer encoder and decoder layer with 8 heads and the channel encoder and decoder are set as dense with 16 units and 128 units, respectively. For the mutual information estimation model, we set two dense layers with 256 units and one dense layer with 1 unit to mimic the function T in (7), where 256 units can extract full information and 1 unit can integrate information. These settings can be found in Table I. For the baselines, we adopt joint source-channel coding based on neural network and the typical methods for separate source and channel codings.In the experiment, we set three Transformer encoder and decoder layer with 8 heads and the channel encoder and decoder are set as dense with 16 units and 128 units, respectively. For the mutual information estimation model, we set two dense layers with 256 units and one dense layer with 1 unit to mimic the function T in (7), where 256 units can extract full information and 1 unit can integrate information. These settings can be found in Table I. For the baselines, we adopt joint source-channel coding based on neural network and the typical methods for separate source and channel codings.</p>
        <p>• DNN based joint source-channel coding [22]: The network consists of Bi-directional Long Short-Term Memory (BLSTM) layers. We label it as JSCC [22] in the simulation figures. • Traditional methods: To perform the source and channel coding separately, we use the following technologies respectively:• DNN based joint source-channel coding [22]: The network consists of Bi-directional Long Short-Term Memory (BLSTM) layers. We label it as JSCC [22] in the simulation figures. • Traditional methods: To perform the source and channel coding separately, we use the following technologies respectively:</p>
        <p>-Source coding: Huffman coding, fixed-length coding (5-bit), and Brotli coding, where Brotli coding uses 2nd context model to compress the context information and every 128 sentences are compressed together in the simulation. -Channel coding: Turbo coding [34] and Reed-Solomon (RS) coding [35]. We adopt turbo decoding method is log-MAP algorithm with 5 iterations. The BLEU and sentence similarity are used to measure the performance. The simulation is performed by the computer with Intel Core i7-9700 CPU@3.00GHz and NVIDIA GeForce GTX 2060.-Source coding: Huffman coding, fixed-length coding (5-bit), and Brotli coding, where Brotli coding uses 2nd context model to compress the context information and every 128 sentences are compressed together in the simulation. -Channel coding: Turbo coding [34] and Reed-Solomon (RS) coding [35]. We adopt turbo decoding method is log-MAP algorithm with 5 iterations. The BLEU and sentence similarity are used to measure the performance. The simulation is performed by the computer with Intel Core i7-9700 CPU@3.00GHz and NVIDIA GeForce GTX 2060.</p>
        <p>Fig. 6 shows the relationship between the BLEU score and the SNR under the same number of transmitted symbols over AWGN and Rayleigh fading channels, where the traditional approaches use 8-QAM, 64-QAM, and 128-QAM for the modulation. Among the traditional baselines in Fig. 6(a), Brotli coding outperforms the Huffman and fixed-length encoding over AWGN channels when the turbo coding is adopted for channel coding. The traditional approaches perform better than the DNN based method when the SNR is above 12 dB since the distortion from channel is decreased, where the Brotli with turbo coding performs better than the DeepSC. We observe that all DL enabled approaches are more competitive in the low SNR regime.Fig. 6 shows the relationship between the BLEU score and the SNR under the same number of transmitted symbols over AWGN and Rayleigh fading channels, where the traditional approaches use 8-QAM, 64-QAM, and 128-QAM for the modulation. Among the traditional baselines in Fig. 6(a), Brotli coding outperforms the Huffman and fixed-length encoding over AWGN channels when the turbo coding is adopted for channel coding. The traditional approaches perform better than the DNN based method when the SNR is above 12 dB since the distortion from channel is decreased, where the Brotli with turbo coding performs better than the DeepSC. We observe that all DL enabled approaches are more competitive in the low SNR regime.</p>
        <p>In Fig. 6(b), the DL enabled approaches outperform all traditional approaches over the Rayleigh fading channels, where RS coding is better than turbo coding in terms of 2-grams to 4-grams. This is because RS coding is linear block coding with long block-length, and can correct long series of bits, however, turbo coding is a type of convolutional coding with short block-length, so that the adjacent words have higher error rate. DeepSC is not only suitable for short block-length but also performs better in decoding adjacent words, i.e., 4-grams. Note that the BLEU score of the method with Brotil coding and turbo coding is always 0 over Rayleigh fading channels. This is because that 128 sentences are compressed together, while Brotil decoding requires error-free codes after channel decoding for the codes corresponding to the 128 sentences. However, it is almost to guarantee the error-free transmission over Rayleigh fading channels. Therefore, we fail to restore any of the 128 sentences compressed together in Brotil coding as shown in Fig. 6(b). Besides, the lower BLEU score of the DL enabled approaches may not be caused by word errors. For example, it may be due to substitutions of words using synonyms or rephrasing, which does not change the meaning of the word. Fig. 6 also demonstrates that the joint semanticchannel coding design outperforms the traditional methods, which provides solution to Question 1 and 3.In Fig. 6(b), the DL enabled approaches outperform all traditional approaches over the Rayleigh fading channels, where RS coding is better than turbo coding in terms of 2-grams to 4-grams. This is because RS coding is linear block coding with long block-length, and can correct long series of bits, however, turbo coding is a type of convolutional coding with short block-length, so that the adjacent words have higher error rate. DeepSC is not only suitable for short block-length but also performs better in decoding adjacent words, i.e., 4-grams. Note that the BLEU score of the method with Brotil coding and turbo coding is always 0 over Rayleigh fading channels. This is because that 128 sentences are compressed together, while Brotil decoding requires error-free codes after channel decoding for the codes corresponding to the 128 sentences. However, it is almost to guarantee the error-free transmission over Rayleigh fading channels. Therefore, we fail to restore any of the 128 sentences compressed together in Brotil coding as shown in Fig. 6(b). Besides, the lower BLEU score of the DL enabled approaches may not be caused by word errors. For example, it may be due to substitutions of words using synonyms or rephrasing, which does not change the meaning of the word. Fig. 6 also demonstrates that the joint semanticchannel coding design outperforms the traditional methods, which provides solution to Question 1 and 3.</p>
        <p>Fig. 7 shows that the proposed performance metric, the sentence similarity, with respect to the SNR under the same total number of symbols, where the traditional approaches use 8-QAM, 64-QAM and 128-QAM. In Fig. 7(a), the proposed metric has shown the same tendency compared with the BLEU scores. Note that for part of the traditional methods, i.e., Huffman with Turbo coding, even if it can achieve about 20% word accuracy in BLEU score (1-gram) from Fig. 6(a) when SNR = 9 dB, people are usually unable to understand the meaning of texts full of errors. Thus, the sentence similarity in Fig. 7(a) almost converges to 0. For the DeepSC, it achieves more than 90% word accuracy in BLEU score (1-gram) when SNR is higher than 6 dB in Fig. 6(a), which means people can understand the texts well. Therefore the sentence similarity tends to 1. Fig. 6(b) and Fig. 7(b) show the same tendency. The benchmark, including the DNN based JSCC method in [22] under Rayleigh fading channels, also gets much higher score than the traditional approaches in terms of the sentence similarity since it can capture the features of the syntax and the relationship of the words, as well as present texts that is easier for people to understand. Few representative results are shown in Table II.Fig. 7 shows that the proposed performance metric, the sentence similarity, with respect to the SNR under the same total number of symbols, where the traditional approaches use 8-QAM, 64-QAM and 128-QAM. In Fig. 7(a), the proposed metric has shown the same tendency compared with the BLEU scores. Note that for part of the traditional methods, i.e., Huffman with Turbo coding, even if it can achieve about 20% word accuracy in BLEU score (1-gram) from Fig. 6(a) when SNR = 9 dB, people are usually unable to understand the meaning of texts full of errors. Thus, the sentence similarity in Fig. 7(a) almost converges to 0. For the DeepSC, it achieves more than 90% word accuracy in BLEU score (1-gram) when SNR is higher than 6 dB in Fig. 6(a), which means people can understand the texts well. Therefore the sentence similarity tends to 1. Fig. 6(b) and Fig. 7(b) show the same tendency. The benchmark, including the DNN based JSCC method in [22] under Rayleigh fading channels, also gets much higher score than the traditional approaches in terms of the sentence similarity since it can capture the features of the syntax and the relationship of the words, as well as present texts that is easier for people to understand. Few representative results are shown in Table II.</p>
        <p>In brief, we can conclude that the tendency in sentence similarity is more closer to human judgment and the DeepSC achieves the best performance in terms of both BLEU score and sentence similarity. Compared to the simulation results with BLEU score as the metric, the sentence similarity score can better measure the semantic error, which solves the Question 2.In brief, we can conclude that the tendency in sentence similarity is more closer to human judgment and the DeepSC achieves the best performance in terms of both BLEU score and sentence similarity. Compared to the simulation results with BLEU score as the metric, the sentence similarity score can better measure the semantic error, which solves the Question 2.</p>
        <p>Fig. 8 illustrates that the impact of the number of symbols per word on the 1-gram BLEU score when SNR is 12 dB. As the number of symbols per word grows, the BLEU scores increase significantly due to the increasing distance between constellations gradually. Generally, people can understandFig. 8 illustrates that the impact of the number of symbols per word on the 1-gram BLEU score when SNR is 12 dB. As the number of symbols per word grows, the BLEU scores increase significantly due to the increasing distance between constellations gradually. Generally, people can understand</p>
        <p>it is an important step towards equal rights for all passengers. DeepSC it is an important step towards equal rights for all passengers. JSCC- [22] it is an essential way towards our principles for democracy. Huffman + Turbo coding rt is a imeomant step tomdrt equal rights for atp passurerrs. Huffman + RS coding it is an important step towards ewiral rlrsuo for all passengess. Bit5 + Turbo coding it is an yoportbnt ssep sowart euual qighd fkr ill passeneers. Bit5 + RS coding it iw an ymp!rdbnd stgo to!atds eq.al ryghts dkr alk passengers. the basic meaning of transmitted sentences with over 85% word accuracy in BLEU score (1-gram). For short sentences consisted of 5 to 13 words, our proposed DeepSC can achieve 85% accuracy with 4 symbols per word, which means that we can use fewer symbols to represent one word in the environment that mainly transmits short sentences. Therefore, it can achieve high speed transmission rate. For longer sentences consisted from of 21 to 30 words, the proposed DeepSC faces more difficulties to understand the complex structure of the sentences in the transmitted texts. Hence the performance is degraded with longer sentences. One way to improve the BLEU score is to increase the average number of symbols used for each word.it is an important step towards equal rights for all passengers. DeepSC it is an important step towards equal rights for all passengers. JSCC- [22] it is an essential way towards our principles for democracy. Huffman + Turbo coding rt is a imeomant step tomdrt equal rights for atp passurerrs. Huffman + RS coding it is an important step towards ewiral rlrsuo for all passengess. Bit5 + Turbo coding it is an yoportbnt ssep sowart euual qighd fkr ill passeneers. Bit5 + RS coding it iw an ymp!rdbnd stgo to!atds eq.al ryghts dkr alk passengers. the basic meaning of transmitted sentences with over 85% word accuracy in BLEU score (1-gram). For short sentences consisted of 5 to 13 words, our proposed DeepSC can achieve 85% accuracy with 4 symbols per word, which means that we can use fewer symbols to represent one word in the environment that mainly transmits short sentences. Therefore, it can achieve high speed transmission rate. For longer sentences consisted from of 21 to 30 words, the proposed DeepSC faces more difficulties to understand the complex structure of the sentences in the transmitted texts. Hence the performance is degraded with longer sentences. One way to improve the BLEU score is to increase the average number of symbols used for each word.</p>
        <p>Fig. 9 demonstrates the relationship between SNR and mutual information after training. As we can imagine, the mutual information increases with SNR. From the figure, the performance of the transceiver trained with the mutual information estimation model outperforms that without such a model. From Fig. 9, with the proposed mutual information estimation model, the obtained mutual information at SNR = 4 dB is approximately same as that without the training model at SNR = 9dB. From another point of view, the mutual information estimation model leads to better learning results, i.e., data distribution, at the encoder to achieve higher data rate. In addition, this shows that introducing (9) in loss function can improve the mutual information of the system. Fig. 10 draws the relationship between the loss value in ( 14) and the mutual information with increasing epoch. Fig. 11 indicates the relationship between BLEU score and SNR. The two figures are based on models with the same structure but different training parameters, i.e., learning rate. In Fig. 10, the obtained mutual information is different, i.e., the mutual information of model with learning rate 0.001 increases along with decreasing loss value while the other one with learning rate 0.002 stays zero although the loss values of two models gradually converge to a stable state. From Fig. 11, the BLEU score with learning rate 0.001 outperforms that with learning rate 0.002, which means that even if the neural network converges to a stable state, it is possible that gradient decreases to a local minimum instead of the global minimum. During the training process, the mutual information can be used as a tool to decide whether the model converges effectively.Fig. 9 demonstrates the relationship between SNR and mutual information after training. As we can imagine, the mutual information increases with SNR. From the figure, the performance of the transceiver trained with the mutual information estimation model outperforms that without such a model. From Fig. 9, with the proposed mutual information estimation model, the obtained mutual information at SNR = 4 dB is approximately same as that without the training model at SNR = 9dB. From another point of view, the mutual information estimation model leads to better learning results, i.e., data distribution, at the encoder to achieve higher data rate. In addition, this shows that introducing (9) in loss function can improve the mutual information of the system. Fig. 10 draws the relationship between the loss value in ( 14) and the mutual information with increasing epoch. Fig. 11 indicates the relationship between BLEU score and SNR. The two figures are based on models with the same structure but different training parameters, i.e., learning rate. In Fig. 10, the obtained mutual information is different, i.e., the mutual information of model with learning rate 0.001 increases along with decreasing loss value while the other one with learning rate 0.002 stays zero although the loss values of two models gradually converge to a stable state. From Fig. 11, the BLEU score with learning rate 0.001 outperforms that with learning rate 0.002, which means that even if the neural network converges to a stable state, it is possible that gradient decreases to a local minimum instead of the global minimum. During the training process, the mutual information can be used as a tool to decide whether the model converges effectively.</p>
        <p>In this experiment, we present the performance of transfer learning aided DeepSC for two tasks: transmitter and receiver re-training over different channels and diffident background knowledge.In this experiment, we present the performance of transfer learning aided DeepSC for two tasks: transmitter and receiver re-training over different channels and diffident background knowledge.</p>
        <p>Fig. 12 shows the training efficiency and the performance for different background knowledge, where the model will be trained and re-trained in new background knowledge with the same channel (AWGN) for different background knowledge. The models have the same structure and re-train with the same parameters in each scenario. From Fig. 12(a), the epochs are reduced from 30 to 5 to reach convergence. In Fig. 12(b), the pre-trained model can provide additional knowledge so that the corresponding model training outperforms that of re-training the whole system. This demonstrates that the transfer learning aided DeepSC can help the transceiver to accommodate the new requirements of communication environment. Fig. 13 shows the training efficiency and the performance for different channels, where the DeepSC transceiver is pretrained under the AWGAN channel, and then it is re-trained under the erasure channel and the Rician fading channel, respectively, with the same background knowledge. The models have the same structure and re-train with the same parameters in each scenario. From Fig. 13(a) and Fig. 13(b), the adoption of the pre-trained model can speed up the training process for both the erasure channel and Rician fading channel. In Fig. 13(c) and Fig. 13(d), the performance of the DeepSC with pre-trained model is similar to that without pre-trained model channel while the required complexity is reduced significantly as less number of epochs is required during the re-training process. It is further noted that the BLEU score achieved by the DeepSC is slightly degraded under the fading channel, especially in the lower SNR region, compared to that under the erasure channel.Fig. 12 shows the training efficiency and the performance for different background knowledge, where the model will be trained and re-trained in new background knowledge with the same channel (AWGN) for different background knowledge. The models have the same structure and re-train with the same parameters in each scenario. From Fig. 12(a), the epochs are reduced from 30 to 5 to reach convergence. In Fig. 12(b), the pre-trained model can provide additional knowledge so that the corresponding model training outperforms that of re-training the whole system. This demonstrates that the transfer learning aided DeepSC can help the transceiver to accommodate the new requirements of communication environment. Fig. 13 shows the training efficiency and the performance for different channels, where the DeepSC transceiver is pretrained under the AWGAN channel, and then it is re-trained under the erasure channel and the Rician fading channel, respectively, with the same background knowledge. The models have the same structure and re-train with the same parameters in each scenario. From Fig. 13(a) and Fig. 13(b), the adoption of the pre-trained model can speed up the training process for both the erasure channel and Rician fading channel. In Fig. 13(c) and Fig. 13(d), the performance of the DeepSC with pre-trained model is similar to that without pre-trained model channel while the required complexity is reduced significantly as less number of epochs is required during the re-training process. It is further noted that the BLEU score achieved by the DeepSC is slightly degraded under the fading channel, especially in the lower SNR region, compared to that under the erasure channel.</p>
        <p>The computational complexities of the proposed DeepSC, the JSCC in [22], the RS coding, Turbo coding, are compared in Table III in terms of the average processing runtime per sentence 1 . All the DL enabled approaches have lower runtime than the traditional approaches, where turbo coding costs much longer runtime in log-map iterations and the JSCC [22] requires the lowest average time due to its simple network architecture, however, it comes with poorer semantic processing capability. As a comparison, the runtime of our proposed DeepSC significantly outperforms the traditional schemes and is slight higher than JSCC [22] but with significant performance improvement. VI. CONCLUSIONS In this paper, we have proposed a semantic communication system, named DeepSC, which jointly performs the semanticchannel coding for texts transmission. With the DeepSC, the length of input texts and output symbols are variable, and the mutual information is considered as a part of the loss function to achieve higher data rate. Besides, the deep transfer learning has been adopted to meet different transmission conditions and speed up the training of new networks by exploiting the knowledge from the pre-trained model. Moreover, we initialized sentence similarity as a new performance metric for the semantic error, which is a measure closer to human judgement. The simulation results has demonstrated that the DeepSC outperforms various benchmarks, especially in the low SNR regime. The proposed transfer learning aided DeepSC has shown its ability to adapt to different channels and knowledge with fast convergence speed. Therefore, our proposed DeepSC is a good candidate for text transmission, especially in the low SNR regime, which could be very useful for cases with massive number of devices to be connected with the limited spectrum resource.The computational complexities of the proposed DeepSC, the JSCC in [22], the RS coding, Turbo coding, are compared in Table III in terms of the average processing runtime per sentence 1 . All the DL enabled approaches have lower runtime than the traditional approaches, where turbo coding costs much longer runtime in log-map iterations and the JSCC [22] requires the lowest average time due to its simple network architecture, however, it comes with poorer semantic processing capability. As a comparison, the runtime of our proposed DeepSC significantly outperforms the traditional schemes and is slight higher than JSCC [22] but with significant performance improvement. VI. CONCLUSIONS In this paper, we have proposed a semantic communication system, named DeepSC, which jointly performs the semanticchannel coding for texts transmission. With the DeepSC, the length of input texts and output symbols are variable, and the mutual information is considered as a part of the loss function to achieve higher data rate. Besides, the deep transfer learning has been adopted to meet different transmission conditions and speed up the training of new networks by exploiting the knowledge from the pre-trained model. Moreover, we initialized sentence similarity as a new performance metric for the semantic error, which is a measure closer to human judgement. The simulation results has demonstrated that the DeepSC outperforms various benchmarks, especially in the low SNR regime. The proposed transfer learning aided DeepSC has shown its ability to adapt to different channels and knowledge with fast convergence speed. Therefore, our proposed DeepSC is a good candidate for text transmission, especially in the low SNR regime, which could be very useful for cases with massive number of devices to be connected with the limited spectrum resource.</p>
        <p>We conclude the difference between semantic communication systems and conventional communication systems into the following:We conclude the difference between semantic communication systems and conventional communication systems into the following:</p>
        <p>1) Different data processing domains. The former process data in semantic domain while the latter compress data in entropy domain. 2) Different communication targets. The conventional communication systems focus on the exact data recovery while the semantic communication systems serve for the decisions or targets of the transmission. 3) Different system designs. The conventional systems only design and optimize the information transmission modules, which are contained in the traditional transceiver, however, the semantic systems jointly design the whole information processing blocks from source information to final targets of applications. Following the concept of semantic communications proposed in this paper, we have developed L-DeepSC [36] and DeepSC-S [37] for text and speech transmission.1) Different data processing domains. The former process data in semantic domain while the latter compress data in entropy domain. 2) Different communication targets. The conventional communication systems focus on the exact data recovery while the semantic communication systems serve for the decisions or targets of the transmission. 3) Different system designs. The conventional systems only design and optimize the information transmission modules, which are contained in the traditional transceiver, however, the semantic systems jointly design the whole information processing blocks from source information to final targets of applications. Following the concept of semantic communications proposed in this paper, we have developed L-DeepSC [36] and DeepSC-S [37] for text and speech transmission.</p>
        <p>The runtime of source coding and decoding are omitted in the comparison.The runtime of source coding and decoding are omitted in the comparison.</p>
    </text>
</tei>
