<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T09:33+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>The development and continuous improvement of high-throughput sequencing platforms has stimulated interest in the study of complex microbial communities. Currently, the most popular sequencing approach to study microbial community composition and dynamics is targeted 16S rRNA gene metabarcoding. To prepare samples for sequencing, there are a variety of processing steps, each with the potential to introduce bias at the data analysis stage.</p>
        <p>In this short review, key information from the literature pertaining to each processing step is described and consequently, general recommendations for future 16S rRNA gene metabarcoding experiments are made.</p>
        <p>In recent years, the emergence of high-throughput sequencing platforms has revolutionised the study of complex microbial communities. Most commonly, marker genes (e.g. 16S rRNA and 18S rRNA genes) are amplified and sequenced, providing both qualitative and quantitative (i.e. relative abundance) data. However, the variety of methodologies which can be used to carry out marker gene analysis can be overwhelming. Each methodological stage, from sampling to data analysis, can introduce biases, and such biases can skew datasets by introducing changes in the relative abundances observed and can affect the perception of community diversity. This short review includes key information from current literature on sample collection, sample storage and processing, and sequencing and data analysis; specifically for the study of bacterial communities using 16S rRNA gene metabarcoding. By collating fundamental research from each of these areas, we aim to try to ensure that scientists entering this field are better informed to make decisions on experimental design for 16S rRNA gene sequencing studies. on November 7, 2020 by guest http://aem.asm.org/</p>
        <p>Sampling method is obviously dependant on sample type and as such, the factors which may introduce bias will also vary between different types of microbiome studies. Clearly, studyspecific concerns cannot be entirely covered in this review. However, the overarching factors which should be taken into account will be briefly covered in this section.</p>
        <p>Firstly, it is important to consider the proposed sampling site. Bacterial community composition varies even within a specific environment, for example at different sites within the gastrointestinal tract (1), the respiratory tract (2) and at different soil depths (3,4). Since the magnitude of inter-individual variation is very much dependant on sampling site (5), this can have implications for experimental design, specifically when considering the number of subjects and the number of samples to be taken.</p>
        <p>Secondly, there are conflicting results in the literature with regards to the variation introduced by different sample collection methodologies. For example, there have been attempts to replace invasive sampling with less invasive methods; however, significant differences have been found in microbial populations when comparing swab and biopsy samples from human intestines (6), when comparing breath condensate and lung brushings (7) and when comparing rumen fluid samples obtained via oral stomach tubing and a fistula (8). However, other work contradicts these findings, with two studies showing no statistically significant differences when studying the rumen microbiota in cattle using a variety of sampling methods (9,10).</p>
        <p>Additionally, no significant differences were evident in microbial composition when comparing sino-nasal swabs and biopsy samples (11) and rectal swabs and stool samples (12). This kind of conflict in the literature is not uncommon, which leads to a lack of consensus and standardisation.</p>
        <p>A final consideration is whether samples should be homogenised, which appears to be most critical in studies on gut contents (8,13) and on soil (14), since varying microbial Although the literature is generally conflicting with regards to sampling methodology, it is important to consider that comparing data obtained using different approaches should be avoided.</p>
        <p>There is conflicting evidence on whether different storage conditions alone can have an impact on microbial community studies (15)(16)(17)(18). It is often not practical to extract DNA from fresh samples, therefore samples are generally stored for varying durations prior to DNA extraction. Conventionally, it is assumed that rapid freezing to -80 o C is best practice (18,19) but this is not feasible for all study designs, for example, at remote sites where low temperature storage is unavailable (20). Several studies have been carried out to assess the effects of storage conditions on study findings, which will be summarised in this section.</p>
        <p>A couple of studies showed that freezing samples appeared to cause an increase in the Firmicutes to Bacteroidetes ratio in comparison with fresh samples (15,19). Conversely, in a study by Fouhy et al, the only bacterial groups differentially expressed between fresh and snap frozen faecal samples were the Faecalibacterium and Leuconostoc genera, with no significant differences being evident at phylum or family levels (18). No significant effects on microbial composition or diversity were observed in faecal samples refrigerated for 24 hours (21) or 72 hours (20) prior to DNA extraction.</p>
        <p>on November 7, 2020 by guest http://aem.asm.org/</p>
        <p>The impact of storage duration has also been explored in various studies. Lauber et al stored soil, faeces and skin samples at various temperatures and found that storage duration had no significant impact on overall bacterial community structure or diversity (17). In samples which were stored at -80 o C for 2 years, a small number of changes in the microbial communities were observed with increased abundances of lactobacilli and bacilli, and a reduction in the total number of operational taxonomic units (OTUs) (for a definition of OTUs, please see section entitled "operational taxonomic unit picking methods").</p>
        <p>When considering the data presented in the literature, generally processing fresh samples is the best approach but when this is not possible, samples should be frozen for an unequal amount of time and processed in one batch or frozen for an equal amount of time and processed in multiple batches. The decision on how to proceed will be dependent on the duration of the sample collection phase and on study design, but regardless of processing method, storage duration and DNA extraction batch should be recorded to enable this to be taken into account during analysis.</p>
        <p>McKain et al explored the effects of using a cryoprotectant (i.e. glycerol/phosphate buffered saline) to store ruminal digesta samples and found that freezing samples without cryoprotectant caused a significant loss in Bacteroidetes when measuring 16S rRNA gene copy number by quantitative PCR (15). The authors consequently suggest that simply storing samples without a cryoprotectant and carrying out DNA extraction at a later date would impact downstream results when considering archaeal and bacterial community composition. Additionally, RNAlater has previously been shown to be unsuitable for storage of samples subject to microbial community analysis, with samples stored in RNAlater being the least similar to fresh samples and samples immediately frozen at -80 o C (22,23).</p>
        <p>Consequently, when considering the use of a cryoprotectant for storage, it is important to ensure that all samples are stored in the same manner.</p>
        <p>During DNA extraction, it is important to consider that some microbial cells may be more resistant to lysis, such as bacterial endospores (24) and Gram-positive bacteria, which will have an impact on DNA extraction efficiency. The presence of inhibitors has also been found to directly impact DNA extraction efficiency (e.g. debris in environmental samples, organic matter in soil and faeces) and can affect the efficiency of PCR downstream (reviewed in detail by Schrader et al (25)). (8,(26)(27)(28)(29)(30)(31). Specifically, variations in DNA yield and quality are obtained which can lead to different results in downstream analyses (28).</p>
        <p>One key DNA extraction step which can introduce bias is the presence or absence of a mechanical lysis step. The inclusion of a bead-beating step has been linked to a higher DNA yield (8,29,32), higher bacterial diversity (29,32) and more efficient extraction of DNA from Gram-positive and spore-forming bacteria (29,33,34). Consequently, some authors suggest that samples subject to different DNA extraction methods are not comparable (8,28,35).</p>
        <p>Ultimately, the best approach is to utilise a method which extracts the highest yield and quality of DNA as possible without biasing the method towards particular bacterial taxa. To achieve this, inclusion of a bead beating step and prior optimisation of the DNA extraction method to ensure optimal DNA yield and quality is recommended prior to carrying out 16S rRNA gene sequencing.</p>
        <p>Since the entire 16S rRNA gene cannot be sequenced using short-read second-generation sequencing platforms, a short region of the gene must be selected for PCR amplification and sequencing. There is currently no consensus on the most appropriate hypervariable region(s) and several studies have been carried out to determine the advantages and disadvantages of each. Importantly, the choice of hypervariable region(s) and the design of the "universal"</p>
        <p>PCR primers have an effect on phylogenetic resolution (36)(37)(38)(39)(40). Indeed, no primer set is truly universal, with some commonly used 16S rRNA gene primers proving ineffective at on November 7, 2020 by guest http://aem.asm.org/ Downloaded from amplifying biologically relevant bacteria (34,41). Fouhy et al explored the effects of primer choice (as well as DNA extraction and sequencing platform) on microbial composition data using a mock bacterial community and three primer sets (42), with differences in relative abundances and richness being observed.</p>
        <p>Further biases can be introduced during PCR amplification due to the presence of PCR inhibitors (described in the DNA extraction section), with the number of PCR cycles and the use of a high-fidelity polymerase (43) also having an impact on results. The formation of chimeras occurs in later PCR cycles when the highest concentration of incompletely extended primers compete with the original primers. Consequently, the potential for chimera formation can be reduced by lowering the number of PCR cycles (44). Previous work found that bacterial richness increased as the PCR cycle number increased (45,46), but that cycle number had no significant effect on community structure (46). A lower number of PCR artefacts were found when using a high-fidelity polymerase compared to a standard polymerase (43). The use of different polymerases has also been found to significantly affect PCR efficiencies for particular bacterial groups and the overall bacterial community structures (46). Finally, the quantity of input DNA into a PCR reaction has also been found</p>
        <p>to have a significant effect on observed bacterial community structure (31).</p>
        <p>In summary, there is not a "gold standard" hypervariable region for 16S sequencing but it is important to consider that PCR reagents and PCR conditions should be optimised and kept consistent across a study. low capital cost, and produce data more quickly than the MiSeq. However, the lower throughput and higher error rates mean that many researchers prefer to select the MiSeq.</p>
        <p>Whilst Illumina offers the highest quality data, there are some reported problems with the platform. Illumina error rates are often thought to be around 0.01%, however Kozich et al</p>
        <p>showed the actual error rates can be as high as 10%, and recommend a complete overlap of 250 bp reads to correct for this (48). D'Amore et al similarly showed library-dependent error rates in either read 1 or read 2 (but not the overlap) in MiSeq data, albeit at a lower rate (2-3%) (47). An improvement has been suggested to this involving a heterogeneity spacer that improves sequence diversity in the library (49).</p>
        <p>PacBio and Oxford Nanopore technologies are able to sequence the full length of the 16S gene, which is of course very powerful. However, again error rates are an issue, in the range of 5-15% for both technologies, which can cause subsequent errors in downstream analysis.</p>
        <p>Despite the high error rate of long-read single molecule sequencing systems (50)(51)(52), studies are beginning to appear to show their utility for 16S rRNA gene sequencing (53-56 (54). One of the drawbacks of the PacBio technology is throughput, which means that the number of samples that can be run on the platform simultaneously and at reasonable cost is much lower than the MiSeq.</p>
        <p>When planning a 16S sequencing study, three key considerations are the quality of sequence data, the cost of sequencing and the length of generated reads, as detailed already in this section. A final factor is the number of samples which can be analysed per sequencing run.</p>
        <p>When considering Illumina platforms specifically, it is possible to use multiplexing strategies by implementation of unique single-indexed (57) or dual-indexed (48) (or barcoded) primers for library preparation. If the number of samples per run is increased, this is associated with a lower coverage (or number of sequences generated) per sample. If the coverage per sample is too low, then the diversity of the microbial community being studied is likely to be underrepresented, as rarer members of the community are less likely to be detected. Therefore, guidance on the number of samples to be included per run should be obtained from small pilot studies (and observation of the resultant rarefaction curves) or published literature. In larger studies, more than one sequencing run may be required and Caporaso et al showed that data were highly reproducible across sequencing lanes (57).</p>
        <p>As part of 16S microbiome studies, it is useful to include a mock community control composed of pre-determined ratios of DNA from a mixture of bacterial species. This not only allows the quantification of sequencing error (58) but also allows bias introduced during the sampling and library preparation processes to be identified (42,47,59,60). For example, a mock community containing bacterial taxonomies which are of specific interest to the research group can be used to calculate whether these taxonomies are likely to be over or under represented in samples. Similar to mock communities, spike-in standards can also be used to analyse bias and the reproducibility of methodologies (61). However, unlike mock communities, these standards are added directly to samples and therefore quality control can be performed on a per sample basis. However, there is a risk of crossover between the 16S rRNA gene sequences contained in the standards and those which may be found in samples.</p>
        <p>Consequently, care must be taken to select bacteria which are highly unlikely to occur in the samples of interest (62,63) or which have been designed in silico and are dissimilar to sequences found in 16S databases (61).</p>
        <p>There are a variety of sources which provide mock bacterial communities for use in research; however some researchers choose to create their own mock communities in-house which more accurately reflect bacteria of interest and scientific importance. Pre-prepared bacterial communities are available in two different formats -DNA mock communities and whole cell mock communities. The latter is useful for establishing the efficiency of the DNA extraction step, whereas the former will only assess the efficiency of PCR, clean up, sequencing and analysis steps. At the time of writing, mock communities are available from the American Type Culture Collection (ATCC) and Zymo Research.</p>
        <p>on November 7, 2020 by guest http://aem.asm.org/</p>
        <p>When planning a 16S study, the inclusion of a mock community is strongly encouraged.</p>
        <p>The analysis of large and complex 16S rRNA gene sequencing data sets requires the use of bioinformatic tools. There are many pipelines available to process and analyse 16S rRNA gene sequencing data, including the commonly used 
            <rs type="software">QIIME</rs> (64), 
            <rs type="software">MG-RAST</rs> (65), 
            <rs type="software">UPARSE</rs> (66) (
            <rs type="url">URL</rs>: 
            <rs type="url">https://www.drive5.com/usearch/manual/uparse_pipeline.html)</rs> and 
            <rs type="software">mothur</rs> (67).
        </p>
        <p>These packages contain sets of tools which facilitate the complete analysis of 16S rRNA gene data, from quality control to operational taxonomic unit (OTU) clustering. Where they differ is predominantly in their accessibility to those with limited computational knowledge and in the availability of documentation.</p>
        <p>Nilakanta et al compared seven different packages (
            <rs type="software">mothur</rs>, 
            <rs type="software">QIIME</rs>, 
            <rs type="software">WATERS</rs>, 
            <rs type="software">RDPipeline</rs>, 
            <rs type="software">VAMPS</rs>, 
            <rs type="software">Genboree</rs>, and 
            <rs type="software">SnoWMan</rs>) and concluded that while all of these packages provide effective pipelines for 16S rRNA gene analysis, the extensive documentation which accompanies 
            <rs type="software">mothur</rs> and 
            <rs type="software">QIIME</rs> provides them with an advantage over the other packages (68). Plummer and Twin analysed a single data set using 
            <rs type="software">QIIME</rs>, 
            <rs type="software">mothur</rs> and 
            <rs type="software">MG-RAST</rs> and found that there were few differences in the results when considering taxonomic classification and diversity (69). However, there were differences in the ease of use of each of these packages and the time required for analysis, with 
            <rs type="software">QIIME</rs> being the quickest analysis package (approximately 1 hour) and 
            <rs type="software">MG-RAST</rs> being the slowest (approximately 2 days, due to the need for manual quality control to remove multiple annotations of reads). The authors do state that although 
            <rs type="software">MG-RAST</rs> is the slowest analysis method, it is perhaps the most suitable package for users with no command line experience.
        </p>
        <p>on November 7, 2020 by guest http://aem.asm.org/</p>
        <p>Ultimately, the choice of analysis package will be made on the basis of the user's level of experience in bioinformatics and on the available resources at the user's host institution.</p>
        <p>It is essential to carry out quality filtering to remove DNA sequences which are of unexpected length, have long homopolymers, contain ambiguous bases or do not align to the correct 16S rRNA gene region. Critically, sequences should then be screened for chimeras, as the presence of chimeric sequences can affect the interpretation of the final dataset and could, for example, over-inflate perception of community diversity (70). A variety of tools have been developed to remove chimeric sequences such as UCHIME (66) and 
            <rs type="software">Chimera Slayer</rs> (70). By including a mock bacterial community in a sequencing run, since the true sequences in these are known, the number of chimeric sequences can be calculated (58).
        </p>
        <p>Sequences should then be aligned to a reference alignment, or assigned to a suitable reference using a sequence classifier such as the RDP classifier which uses a naïve Bayesian approach based on 8-mers (71). Schloss showed that alignment quality can significantly impact diversity and can artificially inflate the number of bacterial OTUs, and advised against using alignments which do not take into account the secondary structure of the 16S gene (72).</p>
        <p>Of the three most commonly used alignments which are guided by secondary structure (i.e.</p>
        <p>greengenes (73), RDP (74) and SILVA ( 75)), the greengenes alignment was observed to be of poor quality, leading to significantly greater richness and diversity estimates.</p>
        <p>Post-alignment, sequences and OTUs are assigned taxonomies based upon their similarity to training sets, most commonly constructed from the greengenes, RDP and SILVA databases.</p>
        <p>Errors within these databases, caused by sequencing/PCR errors (76) or by the incorrect on November 7, 2020 by guest http://aem.asm.org/ Downloaded from labelling of sequences (77), may lead to the misidentification of sequences. Another issue when relying on databases for taxonomic assignment is their bias towards bacteria which are clinically relevant in humans, meaning that researchers investigating non-human hosts or environmental samples may struggle to assign taxonomy to their sequences. For example, in a study of the honey bee gut microbiota, disagreement was found between the three databases listed above upon carrying out taxonomic assignments (78). At genus level, the three databases concurred in their assignments for only 13% of sequences. The classification of sequences was improved by including bee-specific full length 16S rRNA gene sequences in the training set, highlighting the need to include more representative sequences from a greater number of habitats.</p>
        <p>This has been highlighted by Werner et al who advised using the largest and most diverse database possible (79). This group also found that trimming the reference sequences to the primer region of interest improved classification depth. However, in a more extensively studied environment such as the human intestine, Ritari et al found that making a personalised reference database containing only bacterial species which were known to inhabit that niche led to an increase in lower taxonomic level assignments, probably due to less competition among sequences compared to large databases (80).</p>
        <p>Operational taxonomic units, or OTUs, are the common currency of 16S or marker gene studies of microbiomes. The term was originally coined by Sokal and Sneath (81), and in its more general usage refers simply to groups of organisms that are closely related. There are two major methods for defining OTUsreference-based and de novo. In reference-based clustering, sequences from a community are clustered against a known reference database, and in de novo clustering, the sequences are clustered according to pairwise distance on November 7, 2020 by guest http://aem.asm.org/ Downloaded from measures. Reference-based OTUs are sometimes referred to as "phylotypes" (82). As with many areas of microbiome analysis, the evidence is mixed as to which of the two approaches is best. It has been found that de novo methods perform better when considering the quality of OTU assignments (83), with another study showing that de novo OTUs were unstable (84). However, Westcott and Schloss argued that OTUs can be stable yet still incorrect, and in particular showed that some reference-based techniques were sensitive to the order of sequences in the database. Sul et al found that reference-based techniques produced similar results to de novo, with the added benefit of low computational overheads and the ability to compare datasets from different variable regions (85). Indeed, perhaps the major difference between reference-and de novo based methods is that the latter has a significantly greater computational overhead, with the need to compare every sequence to every other sequence in its most naïve form.</p>
        <p>Even within clustering tools, the choice of parameters has been shown to have a critical impact on the results. Whilst a threshold of 97% has become standard, Patin et al have shown that 16S rRNA gene sequences as similar as 99% can represent functionally distinct microorganisms, which means that functionally diverse species would be clustered at the 97% threshold (86). However, that may rely on accurate sequences, and if those don't exist, the 97% threshold can help avoid over-estimation of biodiversity (87). Susceptibility to differing parameters may also be pipeline-dependent (88). Given the controversy and potential biases of clustering sequences, some have suggested methods and models for using individual sequences to represent OTUs (i.e. remove the clustering step entirely) (89)(90)(91)(92).</p>
        <p>Different bacterial species also have varying copy numbers of the 16S rRNA gene (93,94) which can lead to misinterpretations when comparing the abundance of bacterial OTUs or on November 7, 2020 by guest http://aem.asm.org/ Downloaded from attempting to construct a "true" description of the microbial community within a sample (95).</p>
        <p>It is unusual in 16S rRNA gene studies to accurately know the copy numbers for all identified OTUs. Therefore, tools have been developed which seek to correct for copy number variation using sequence databases and phylogenetic information to give a more accurate picture of the relative abundances of these OTUs. These include Copyrighter (96), 
            <rs type="software">rrNDB</rs> (93), functions in the 
            <rs type="software">picante</rs>
            <rs type="software">R</rs> package and 
            <rs type="software">pplacer</rs> (97) and part of the 
            <rs type="software">PICRUSt</rs> package (98).
        </p>
        <p>As these techniques are reliant on databases the same problems are present as for taxonomic identification. Principally, lesser studied bacterial taxonomies are less likely to be represented. It is also important to note that when comparing OTUs between samples rather than within a sample (e.g. when comparing treatment effects), the impact of copy number variation is reduced as the under or over representation of OTUs would be consistent across samples as long as the same methodology had been used.</p>
        <p>Microbial What should be done with sequencing data from reagent-only controls is still under debate. It is often not appropriate to simply remove all of the bacterial OTUs found in controls as these may overlap with OTUs which can genuinely be found in samples (108). Other methods have been suggested which take into account the abundance of OTUs to predict the likelihood of sequence reads having originated from contamination. These include an adaptation of the neutral community model (12) and combining qPCR data with OTU relative abundance data to compare the absolute abundance of contaminating OTUs in controls and samples (113).</p>
        <p>However, the field is rapidly reaching consensus that, due to contamination issues, not including reagent-only controls can negatively impact the quality control of sequence data.</p>
        <p>The study of complex microbial communities using high-throughput sequencing platforms has allowed better understanding of a variety of biological systems and the impact of various conditions (e.g. disease states) on the host microbiome. When considering the literature, it is clear that bias can be introduced into microbiota studies at all methodological stages, from sampling to bioinformatic analysis. While the variety of different 16S rRNA gene metabarcoding methodologies might seem overwhelming, the main factor to keep in mind when designing a microbiota study is consistency. It is paramount to use consistent methodology throughout a study to minimise potential biases which could lead to spurious results.</p>
        <p>The volume of studies attempting to define best practice for various stages of the microbiome experimental process is large, and we cover only some of the literature in this review.</p>
        <p>Unfortunately, as can be seen, there is little consensus, and further studies are unlikely to find any. The reality is that many of the biases described in this review are context-and environment-specific, and whilst individual studies may be true within their context, their conclusions may not be transferable to other studies. Clearly, with biases possible at every step, a good experimental design is essential. Recording and publication of all experimental metadata is essential for understanding microbiome studies, and unfortunately many currently published studies lack these data.</p>
        <p>Trying to find consensus in the literature is challenging, with many studies producing conflicting evidence about the effects of various steps in the experimental process. It is therefore essential that consistency is maintained within a study, and there must be an acceptance that comparison between studies may not be possible.</p>
        <p>on November 7, 2020 by guest http://aem.asm.org/</p>
        <p>In summary, we recommend extracting DNA from fresh samples if possible; if not, samples should be stored in a consistent manner (i.e. at the same temperature, for the same duration and with or without cryprotectant) with appropriate metadata being recorded. The use of a mechanical lysis step is recommended to minimise potential biases due to some microbial cells being more resistant to lysis. The selection of appropriate primers should be made after careful consideration of the literature, but it is important to note that even universal primers will not amplify all bacteria in a given sample. Sequencing both mock bacterial communities and "negative"/reagent-only controls is important for determining background contamination and sequencing error rate, and should at least be included for each sequencing run and even better, for every batch of commercial reagents/kits. To reduce the chance of OTU inflation caused by sequencing errors, consider complete overlap of MiSeq reads, which translates as targeting a single hypervariable region. Finally, and to re-iteraterecord every aspect of your experiment and report it in the methods section and remember that the critical consideration is consistency in methodology at each stage.</p>
        <p>D'Amore et al have studied the choice of sequencing platform most recently (47) and we would refer the reader to that manuscript for a more in depth analysis. Illumina technology on November 7, 2020 by guest http://aem.asm.org/ Downloaded from (</p>
        <p>). For example, Schloss et al were able to reduce the observed error rate for the V1-V9 region from on November 7, 2020 by guest http://aem.asm.org/ Downloaded from 0</p>
        <p>contamination 2 density gradient centrifugation</p>
        <p>(111)</p>
        <p>and bleach/CoPA solution treatment</p>
        <p>(105)</p>
        <p>. These methods have shown variable effects on contamination levels and PCR sensitivity and the inclusion of reagent-only controls alongside these decontamination measures is still recommended.</p>
        <p>on November 7, 2020 by guest http://aem.asm.org/ Downloaded from</p>
        <p>This project was supported by the Biotechnology and Biological Sciences Research Council (BBSRC: BB/N016742/1 (PI: Prof. Mick Watson), BB/N01720X/1 (PI: Prof. Mick Watson), BB/K501591/1 (PI: Prof. Jos Houdijk, SRUC), BB/J01446X/1 (PI: Dr. Gerry McLachlan, The Roslin Institute), including institute strategic programme and national capability awards to The Roslin Institute (BBSRC: BB/P013732/1, BB/J004235/1, BB/J004243/1). SRUC receives support from Scottish Government's Rural and Environment Science and Analytical Services Division (RESAS). on November 7, 2020 by guest http://aem.asm.org/ Downloaded from</p>
    </text>
</tei>
