<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-13T16:18+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>A point contact/Coulomb coupling technique is generally used for visualizing the ultrasonic waves in Lead Zirconate Titanate (PZT) ceramics. The point contact and delta pulse excitation produce a broadband frequency spectrum and wide directional wave vector. In ultrasonic, the signal is corrupted with several types of noises such as speckle, Gaussian, Poisson, and salt and pepper noise. Consequently, the resolution and quality of the images are degraded. The reliability of the health assessment of any civil or mechanical structures highly depends on the ultrasonic signals acquired from the sensors. Recently, deep learning (DL) has been implemented for the reduction of noises from the signals and in images. Here, we have implemented deep learning-based convolutional autoencoders for suitable noise modeling and subsequently denoising the ultrasonic images. Two different metrics, PSNR and SSIM are calculated for quantitative analysis of ultrasonic images. PSNR provides higher visual interpretation, whereas the SSIM can be used to measure much finer similarities. Based upon these parameters speckle-noise demonstrated better than other noise models.A point contact/Coulomb coupling technique is generally used for visualizing the ultrasonic waves in Lead Zirconate Titanate (PZT) ceramics. The point contact and delta pulse excitation produce a broadband frequency spectrum and wide directional wave vector. In ultrasonic, the signal is corrupted with several types of noises such as speckle, Gaussian, Poisson, and salt and pepper noise. Consequently, the resolution and quality of the images are degraded. The reliability of the health assessment of any civil or mechanical structures highly depends on the ultrasonic signals acquired from the sensors. Recently, deep learning (DL) has been implemented for the reduction of noises from the signals and in images. Here, we have implemented deep learning-based convolutional autoencoders for suitable noise modeling and subsequently denoising the ultrasonic images. Two different metrics, PSNR and SSIM are calculated for quantitative analysis of ultrasonic images. PSNR provides higher visual interpretation, whereas the SSIM can be used to measure much finer similarities. Based upon these parameters speckle-noise demonstrated better than other noise models.</p>
        <p>Piezoelectric materials, such as Lead Zirconate Titanate Pb (Zr 𝑥 Ti 1-𝑥 O 3 ) (PZT) and Lithium Niobate (LiNbO 3 ) are well known for their superior electromechanical conversion since it has the larger piezoelectric coefficients. These piezoelectric materials play a vital role in several industrial and military applications, such as optoelectronics, telecommunication, biomedical devices, actuators, structural health monitoring (SHM), and energy harvesting devices [1][2][3][4]. PZT ceramics are widely used as transducers in SHM applications as they possess several inherent advantages such as broad-band operational frequency, better electromechanical coupling, low power consumption, easy integration's on the sample surface, and impedance matching with various substrates [5][6][7]. SHM is a broader path of study for enhancing the reliability and operational life of various civil and mechanical structures. The ultrasonic-based non-destructive testing (NDT) is one of the most significant, reliable, and common methods used in NDT technologies. The reliability of the assessment of the structures highly depends on the ultrasonic signals acquired from the PZT sensors. The problem of denoising the signal or image is an important challenge in the field of signal processing. Image denoising is one of the most important key factors of image processing workflows. In the last several decades, a tremendous effort has been devoted to process or denoise the ultrasonic signals or images [8][9][10][11][12].Piezoelectric materials, such as Lead Zirconate Titanate Pb (Zr 𝑥 Ti 1-𝑥 O 3 ) (PZT) and Lithium Niobate (LiNbO 3 ) are well known for their superior electromechanical conversion since it has the larger piezoelectric coefficients. These piezoelectric materials play a vital role in several industrial and military applications, such as optoelectronics, telecommunication, biomedical devices, actuators, structural health monitoring (SHM), and energy harvesting devices [1][2][3][4]. PZT ceramics are widely used as transducers in SHM applications as they possess several inherent advantages such as broad-band operational frequency, better electromechanical coupling, low power consumption, easy integration's on the sample surface, and impedance matching with various substrates [5][6][7]. SHM is a broader path of study for enhancing the reliability and operational life of various civil and mechanical structures. The ultrasonic-based non-destructive testing (NDT) is one of the most significant, reliable, and common methods used in NDT technologies. The reliability of the assessment of the structures highly depends on the ultrasonic signals acquired from the PZT sensors. The problem of denoising the signal or image is an important challenge in the field of signal processing. Image denoising is one of the most important key factors of image processing workflows. In the last several decades, a tremendous effort has been devoted to process or denoise the ultrasonic signals or images [8][9][10][11][12].</p>
        <p>Denoising methods can be broadly classified into spatial domain methods and transform domain methods. Spatial filters which are further categorized into linear and non-linear filters utilizes low pass filtering on image pixel values as the noise tends to occupy higher regions in the frequency spectrum [13]. Generally, spatial filters reduce noise to a reasonable extent but often end up blurring the image. In the Transform domain, a wide range of signal processing methodologies have been employed such as wavelet decomposition and empirical mode decomposition (EMD). In addition, there are other methods such as principal component analysis (PCA) and singular value decomposition (SVD) to achieve reconstruction and restoration of signals. In the same time, to accomplish signal reconstruction and restoration, techniques such as block-matching and 3D filtering (BM3D) deployed too [14].Denoising methods can be broadly classified into spatial domain methods and transform domain methods. Spatial filters which are further categorized into linear and non-linear filters utilizes low pass filtering on image pixel values as the noise tends to occupy higher regions in the frequency spectrum [13]. Generally, spatial filters reduce noise to a reasonable extent but often end up blurring the image. In the Transform domain, a wide range of signal processing methodologies have been employed such as wavelet decomposition and empirical mode decomposition (EMD). In addition, there are other methods such as principal component analysis (PCA) and singular value decomposition (SVD) to achieve reconstruction and restoration of signals. In the same time, to accomplish signal reconstruction and restoration, techniques such as block-matching and 3D filtering (BM3D) deployed too [14].</p>
        <p>Wang et al. performed a hybrid method combining wave packet decomposition and EMD to denoise the signals [15]. Finally, the various faults in the engine were classified using Support Vector Machine (SVM). C-PCASVD [17]. Such a technique can identify the corresponding singular values of interference, which could achieve an optimum trade-off between the denoised Free Induction Decay (FID) and noise reduction efficiency. The above-mentioned algorithms need to formulate a targeted processing scheme based on signal characteristics, such as parameters, the number of decomposition layers, wavelet basis functions, contribution rate, and the number of main frequencies. Currently, an algorithm of signal denoising with strong adaptability and robustness is quite challenging to achieve.Wang et al. performed a hybrid method combining wave packet decomposition and EMD to denoise the signals [15]. Finally, the various faults in the engine were classified using Support Vector Machine (SVM). C-PCASVD [17]. Such a technique can identify the corresponding singular values of interference, which could achieve an optimum trade-off between the denoised Free Induction Decay (FID) and noise reduction efficiency. The above-mentioned algorithms need to formulate a targeted processing scheme based on signal characteristics, such as parameters, the number of decomposition layers, wavelet basis functions, contribution rate, and the number of main frequencies. Currently, an algorithm of signal denoising with strong adaptability and robustness is quite challenging to achieve.</p>
        <p>Recently, artificial intelligence (AI) and, more specifically, deep learning (DL), approaches have achieved state-of-the-art results for many denoising algorithms. Convolutional neural network (CNN) is a well-known dimension reduction technique and has proven to be highly effective in extracting useful features from an image. CNNderived autoencoder is a specific type of feed-forward neural network that compresses the input image into a lower-dimensional representation and reconstructs the output from the same. This leads us to use the autoencoder in our problem and is discussed in detail in further sections.Recently, artificial intelligence (AI) and, more specifically, deep learning (DL), approaches have achieved state-of-the-art results for many denoising algorithms. Convolutional neural network (CNN) is a well-known dimension reduction technique and has proven to be highly effective in extracting useful features from an image. CNNderived autoencoder is a specific type of feed-forward neural network that compresses the input image into a lower-dimensional representation and reconstructs the output from the same. This leads us to use the autoencoder in our problem and is discussed in detail in further sections.</p>
        <p>Over the years, our group has improved the point contact excitation and detection method for broadband ultrasonic wave excitation in piezoelectric materials [18][19][20][21][22][23]. This method is based on the Coulomb coupling excitation and detection principle, where electromagnetic fields are converted to mechanical energy to excite phonon vibration in piezoelectric materials. This method of excitation and detection is one of the most versatile for generating and detecting ultrasonic waves in piezoelectric materials. Coulomb coupling method and spectral decomposition technique have been used for detecting surface defects/damages in piezo-ceramic structures with signal processing carried out using Fast Fourier Transform. Wideband excitation and detection in the absence of mechanical, geometrical, and electrical resonances are the key advantages of the point excitation method. It also needs a low dynamical force via mechanical contact for successful acoustic coupling without surface distortion or damage, and it does not require photolithography.Over the years, our group has improved the point contact excitation and detection method for broadband ultrasonic wave excitation in piezoelectric materials [18][19][20][21][22][23]. This method is based on the Coulomb coupling excitation and detection principle, where electromagnetic fields are converted to mechanical energy to excite phonon vibration in piezoelectric materials. This method of excitation and detection is one of the most versatile for generating and detecting ultrasonic waves in piezoelectric materials. Coulomb coupling method and spectral decomposition technique have been used for detecting surface defects/damages in piezo-ceramic structures with signal processing carried out using Fast Fourier Transform. Wideband excitation and detection in the absence of mechanical, geometrical, and electrical resonances are the key advantages of the point excitation method. It also needs a low dynamical force via mechanical contact for successful acoustic coupling without surface distortion or damage, and it does not require photolithography.</p>
        <p>In ultrasonic, the image is normally considered as an accumulation of signals and the existence of noises degrade the image quality. So that, the noisy image reduces the image contrast, edges, textures, object details, and resolution, thereby decreasing the performance of post-processing algorithms. To achieve the problem, we propose a physics-based modeling of noise and generates training samples combined with a deep autoencoder for denoising. In Fig. 1, a flowchart of the data acquisition for point contact excitation and detection and denoising process of the ultrasound images have been shown. We have shown that the proposed method can effectively reduce the noise in experimental data.In ultrasonic, the image is normally considered as an accumulation of signals and the existence of noises degrade the image quality. So that, the noisy image reduces the image contrast, edges, textures, object details, and resolution, thereby decreasing the performance of post-processing algorithms. To achieve the problem, we propose a physics-based modeling of noise and generates training samples combined with a deep autoencoder for denoising. In Fig. 1, a flowchart of the data acquisition for point contact excitation and detection and denoising process of the ultrasound images have been shown. We have shown that the proposed method can effectively reduce the noise in experimental data.</p>
        <p>A detailed description of the excitation and detection principle, working principle, probe fabrication, and the experimental setup has been published before by our group [18][19][20][21][22][23]. This novel experimental technique for point contact excitation and detection based on Coulomb coupling, is developed for the excitation and detection of ultrasonic waves in a piezo-electric material [22,24,25]. In piezoelectric materials, the gradient of the electric field and the gradient of the piezoelectric properties control the transfer of electromagnetic energy to acoustic energy through Coulomb coupling. This technique is based on the generation of an electric field that induces stress waves by electro-mechanical excitation [20].A detailed description of the excitation and detection principle, working principle, probe fabrication, and the experimental setup has been published before by our group [18][19][20][21][22][23]. This novel experimental technique for point contact excitation and detection based on Coulomb coupling, is developed for the excitation and detection of ultrasonic waves in a piezo-electric material [22,24,25]. In piezoelectric materials, the gradient of the electric field and the gradient of the piezoelectric properties control the transfer of electromagnetic energy to acoustic energy through Coulomb coupling. This technique is based on the generation of an electric field that induces stress waves by electro-mechanical excitation [20].</p>
        <p>The experimental technique was optimized for efficient coupling of the electric field with elastic modulus and permittivity of piezoceramics. Fig. 2 illustrated the experimental setup for point contact excitation and detection in PZT ceramic samples. A default noiseadding option from oscilloscope (Agilent 3024A) was employed for adding noise in the excitation signal.The experimental technique was optimized for efficient coupling of the electric field with elastic modulus and permittivity of piezoceramics. Fig. 2 illustrated the experimental setup for point contact excitation and detection in PZT ceramic samples. A default noiseadding option from oscilloscope (Agilent 3024A) was employed for adding noise in the excitation signal.</p>
        <p>The excited signal (Dirac delta pulse of 70 ns time width) was delivered to a radio frequency (RF) amplifier (Electronics &amp; Innovation: 403LA, New York, USA) for signal amplification. These amplified signals were then supplied to the excitation steel probe. This steel sphere was gently in contact with the surface of the piezo-ceramic sample. The excited signal generates the acoustic waves in the PZT ceramic specimen. On the opposite side of the PZT ceramic specimen, a similar steel sphere was used for the acquisition of the propagated signal which was then amplified by a trans-impedance amplifier (DHPCA-100). Finally, the amplified signal was acquired using an oscilloscope (Agilent 3024A) capable of digitizing with up to 12 bits. The sampling interval of the data acquisition was 25 ns. This oscilloscope performs averaging of 256 pulse shootings and digitizes the signal which is then recorded in a personal computer (PC) via a USB connection. The PC also controls the mechanical scanner in the XY plane i.e. the step size is 50 μ m in both directions and the scanning area is 10 × 10 mm 2The excited signal (Dirac delta pulse of 70 ns time width) was delivered to a radio frequency (RF) amplifier (Electronics &amp; Innovation: 403LA, New York, USA) for signal amplification. These amplified signals were then supplied to the excitation steel probe. This steel sphere was gently in contact with the surface of the piezo-ceramic sample. The excited signal generates the acoustic waves in the PZT ceramic specimen. On the opposite side of the PZT ceramic specimen, a similar steel sphere was used for the acquisition of the propagated signal which was then amplified by a trans-impedance amplifier (DHPCA-100). Finally, the amplified signal was acquired using an oscilloscope (Agilent 3024A) capable of digitizing with up to 12 bits. The sampling interval of the data acquisition was 25 ns. This oscilloscope performs averaging of 256 pulse shootings and digitizes the signal which is then recorded in a personal computer (PC) via a USB connection. The PC also controls the mechanical scanner in the XY plane i.e. the step size is 50 μ m in both directions and the scanning area is 10 × 10 mm 2</p>
        <p>The proposed method consists of 4 modules as shown in Fig. 3. First, a noise module is used to synthesize different noise and generate noise-free and noisy image pairs for training.The proposed method consists of 4 modules as shown in Fig. 3. First, a noise module is used to synthesize different noise and generate noise-free and noisy image pairs for training.</p>
        <p>Next, a deep autoencoder is designed and trained using the synthetic training data. Finally, the trained module is used to denoise experimental noisy data. Next, we discuss each module in detail.Next, a deep autoencoder is designed and trained using the synthetic training data. Finally, the trained module is used to denoise experimental noisy data. Next, we discuss each module in detail.</p>
        <p>The first and most important step is to generate large volume training data for the proposed deep learning framework. The procedure starts by preparing the dataset. The ultrasonic images acquired by point contact excitation in PZT ceramic samples were used for the task. Desired clean images of size 199 × 199 were extracted from ultrasonic data by manually inspecting the time-series images near the peaks indicating excitation signal in the voltage vs time plot in Fig. 4.The first and most important step is to generate large volume training data for the proposed deep learning framework. The procedure starts by preparing the dataset. The ultrasonic images acquired by point contact excitation in PZT ceramic samples were used for the task. Desired clean images of size 199 × 199 were extracted from ultrasonic data by manually inspecting the time-series images near the peaks indicating excitation signal in the voltage vs time plot in Fig. 4.</p>
        <p>The ground truth image pixels were normalized in the range [0,1] using min-max normalization, followed by random cropping the images into smaller image tiles of size 64 × 64. 60,000 such tiles were extracted and considered as noise-free. Next, the noise module is used to synthetically add different noises. In Fig. 5, we have demonstrated 5 different types of noises namely Gaussian, speckle, Poisson, saltpepper, and combination of all the four noise types. Each type of noise is added separately with 30% noise levels that produced 5 different datasets of size 60,000 each, one corresponding to each noise type. The noise parameters and description have been provided in the appendix section.The ground truth image pixels were normalized in the range [0,1] using min-max normalization, followed by random cropping the images into smaller image tiles of size 64 × 64. 60,000 such tiles were extracted and considered as noise-free. Next, the noise module is used to synthetically add different noises. In Fig. 5, we have demonstrated 5 different types of noises namely Gaussian, speckle, Poisson, saltpepper, and combination of all the four noise types. Each type of noise is added separately with 30% noise levels that produced 5 different datasets of size 60,000 each, one corresponding to each noise type. The noise parameters and description have been provided in the appendix section.</p>
        <p>The excitation signal, which occurs at 0.06 μs, is represented by the 1st peak in Fig. 4. The 2nd peak, occurring at 0.7 μs, is designated as 𝐿 1 and represents the 1st longitudinal wave signal. The 𝐿 2 mode, which corresponds to the 2nd longitudinal wave mode, is represented by the 3rd peak, at 1.64 μs. The reflection and mode conversion contribute to the wave mode that arrives after 𝐿 1 and interferes with 𝐿 2 . The acquisition took 4 s in total. The spatial and temporal imaging of wave propagation helps identify individual wave modes.The excitation signal, which occurs at 0.06 μs, is represented by the 1st peak in Fig. 4. The 2nd peak, occurring at 0.7 μs, is designated as 𝐿 1 and represents the 1st longitudinal wave signal. The 𝐿 2 mode, which corresponds to the 2nd longitudinal wave mode, is represented by the 3rd peak, at 1.64 μs. The reflection and mode conversion contribute to the wave mode that arrives after 𝐿 1 and interferes with 𝐿 2 . The acquisition took 4 s in total. The spatial and temporal imaging of wave propagation helps identify individual wave modes.</p>
        <p>Autoencoder introduced by Vincent [26], is an unsupervised deep learning algorithm that leverages deep neural networks for dimensionality reduction and feature extraction. It learns to crops the input representation and learns the subsequent reconstruction of the input. It consists of an encoding function, a decoding function, and a loss function which computes the amount of information loss between the compressed and the decompressed representation of the input.Autoencoder introduced by Vincent [26], is an unsupervised deep learning algorithm that leverages deep neural networks for dimensionality reduction and feature extraction. It learns to crops the input representation and learns the subsequent reconstruction of the input. It consists of an encoding function, a decoding function, and a loss function which computes the amount of information loss between the compressed and the decompressed representation of the input.</p>
        <p>Convolutional autoencoder: Convolutional autoencoder (CA) is an extension of classical autoencoder which is meant to remove noises from the input image. The convolutional encoding and decoding layers, unlike in conventional autoencoders, share the weights among all input locations, which help in parameter reduction and translationally invariant recognition. Nishio et al. [27] has shown Computed Tomography (CT) image denoising using CA and achieved state-of-the-art results with better performance compared to popular denoising algorithms like LNLM and BM3D.Convolutional autoencoder: Convolutional autoencoder (CA) is an extension of classical autoencoder which is meant to remove noises from the input image. The convolutional encoding and decoding layers, unlike in conventional autoencoders, share the weights among all input locations, which help in parameter reduction and translationally invariant recognition. Nishio et al. [27] has shown Computed Tomography (CT) image denoising using CA and achieved state-of-the-art results with better performance compared to popular denoising algorithms like LNLM and BM3D.</p>
        <p>Proposed Architecture: The encoding block is a modified version of VGG net [28]. VGG net despite its very simple architecture is one of the most powerful and efficient convolutional neural network (CNN) models. With a limited dataset, very deep CNN models tend to overfit the training set and result in poor test performance. In our study, in order to develop the encoder, the initial two layers having 64 filters of size 3 × 3 , three layers having 512 filters of size 3 × 3 and all the fully connected layers at the end in the original VGG-16 architecture were removed. In addition, two additional layers having 1024 filters each (filter size 3 × 3 ) are added at the end of the encoder to give a bottleneck structure to the autoencoder. Max pooling is applied after every convolution block 𝐵𝑖(𝑖 = 1, 2, 3) to downsample the input feature maps and carries forward the largest information amplitudewise, which effectively reduces the number of weight parameters to be learned thereby reducing the computational cost.Proposed Architecture: The encoding block is a modified version of VGG net [28]. VGG net despite its very simple architecture is one of the most powerful and efficient convolutional neural network (CNN) models. With a limited dataset, very deep CNN models tend to overfit the training set and result in poor test performance. In our study, in order to develop the encoder, the initial two layers having 64 filters of size 3 × 3 , three layers having 512 filters of size 3 × 3 and all the fully connected layers at the end in the original VGG-16 architecture were removed. In addition, two additional layers having 1024 filters each (filter size 3 × 3 ) are added at the end of the encoder to give a bottleneck structure to the autoencoder. Max pooling is applied after every convolution block 𝐵𝑖(𝑖 = 1, 2, 3) to downsample the input feature maps and carries forward the largest information amplitudewise, which effectively reduces the number of weight parameters to be learned thereby reducing the computational cost.</p>
        <p>The decoder is built by inverting the encoder in order to preserve the symmetry in the model. The max pooling layer is replaced by upsampling layers to scale up the dimension of input by a factor of 2. At the end of the decoder, a single layer having 1 filter of size 3 × 3 is added to produce an output image of shape (64, 64, 1).The decoder is built by inverting the encoder in order to preserve the symmetry in the model. The max pooling layer is replaced by upsampling layers to scale up the dimension of input by a factor of 2. At the end of the decoder, a single layer having 1 filter of size 3 × 3 is added to produce an output image of shape (64, 64, 1).</p>
        <p>Rectified linear unit (ReLu) activation function [29] is used after each convolution operation to introduce nonlinearity into the network and enable it to learn more complex relationships in the data. The ReLu function outputs the input directly if it is positive otherwise returns zero.Rectified linear unit (ReLu) activation function [29] is used after each convolution operation to introduce nonlinearity into the network and enable it to learn more complex relationships in the data. The ReLu function outputs the input directly if it is positive otherwise returns zero.</p>
        <p>Other traditional activation functions like tanh and sigmoid suffer the disadvantage of minimal gradients at small input values (vanishing gradients), which slows down the training. The ReLu activation function overcomes this vanishing gradient problem, allowing models to learn faster and perform better (see Fig. 6).Other traditional activation functions like tanh and sigmoid suffer the disadvantage of minimal gradients at small input values (vanishing gradients), which slows down the training. The ReLu activation function overcomes this vanishing gradient problem, allowing models to learn faster and perform better (see Fig. 6).</p>
        <p>To overcome this issue, the sliding window technique has been used in this paper. A sliding window of size 64 × 64 traverses over the noisy image with a constant stride. Each window image is fed into the network. The overlapped region in two consecutive window locations are pixel-wise averaged and the process is continued till the complete image is retrieved.To overcome this issue, the sliding window technique has been used in this paper. A sliding window of size 64 × 64 traverses over the noisy image with a constant stride. Each window image is fed into the network. The overlapped region in two consecutive window locations are pixel-wise averaged and the process is continued till the complete image is retrieved.</p>
        <p>The 5 datasets each of size 60,000 corresponding to each noise type obtained in sec. 3.1 has been divided into training and validation datasets. This way, 5 different training sets and validation sets, each of size 48,000 and 12,000 respectively, were obtained. 5 different CA models are trained separately on these 5 training sets and simultaneously validated over the respective validation set. For testing all the CA models, we used original noisy images obtained from the experiment containing 30% noise of unknown distribution. The images originally of size 199 × 199 were first normalized on the range [0,1] as done for the training set images. Image fragments of size 64 × 64 were then sequentially cropped from the larger image in order to feed into the network for denoising. All the fragments after denoising were stitched back together using the sliding window technique with a stride equal to 8. Fig. 7 shows the denoising performance of all the 5 noise models for 3 different images taken at different time frames. The images are compared against the ground truth image for assessing the denoising performance qualitatively.The 5 datasets each of size 60,000 corresponding to each noise type obtained in sec. 3.1 has been divided into training and validation datasets. This way, 5 different training sets and validation sets, each of size 48,000 and 12,000 respectively, were obtained. 5 different CA models are trained separately on these 5 training sets and simultaneously validated over the respective validation set. For testing all the CA models, we used original noisy images obtained from the experiment containing 30% noise of unknown distribution. The images originally of size 199 × 199 were first normalized on the range [0,1] as done for the training set images. Image fragments of size 64 × 64 were then sequentially cropped from the larger image in order to feed into the network for denoising. All the fragments after denoising were stitched back together using the sliding window technique with a stride equal to 8. Fig. 7 shows the denoising performance of all the 5 noise models for 3 different images taken at different time frames. The images are compared against the ground truth image for assessing the denoising performance qualitatively.</p>
        <p>The model is trained with MSE loss over 500 epochs using stochastic gradient descent optimizer. To ensure the model does not overfit, early stopping criteria has been applied to stop the training when the PSNR calculated on validation dataset, observed over a certain number of epochs (10 in this case) stops improving. We have used different learning rates for each training set, ranging between 0.05-0.13. The final MSE and Mean Absolute Error (MAE) values achieved on training and validation datasets for all 5 noise models is shown in Table 1 The module is implemented in Python using tensor-flow framework. The training is executed in HP Z4 G4 workstation with 4 GHz, W-2125 CPU, 128 GB RAM, and NVIDIA Quadro RTX 4000 8 GB Graphics.The model is trained with MSE loss over 500 epochs using stochastic gradient descent optimizer. To ensure the model does not overfit, early stopping criteria has been applied to stop the training when the PSNR calculated on validation dataset, observed over a certain number of epochs (10 in this case) stops improving. We have used different learning rates for each training set, ranging between 0.05-0.13. The final MSE and Mean Absolute Error (MAE) values achieved on training and validation datasets for all 5 noise models is shown in Table 1 The module is implemented in Python using tensor-flow framework. The training is executed in HP Z4 G4 workstation with 4 GHz, W-2125 CPU, 128 GB RAM, and NVIDIA Quadro RTX 4000 8 GB Graphics.</p>
        <p>In this paper, we have used peak-signal-to-noise-ratio (PSNR) [30] and structural similarity index measure (SSIM) [31] to quantify the image denoising performance of the autoencoder. For a given reference (true) image 𝑦 and a denoised image ŷ, the PSNR is defined by: 𝑃 𝑆𝑁𝑅( ŷ, 𝑦) = 10 log 10 (1 2 ∕𝑀𝑆𝐸( ŷ, 𝑦))In this paper, we have used peak-signal-to-noise-ratio (PSNR) [30] and structural similarity index measure (SSIM) [31] to quantify the image denoising performance of the autoencoder. For a given reference (true) image 𝑦 and a denoised image ŷ, the PSNR is defined by: 𝑃 𝑆𝑁𝑅( ŷ, 𝑦) = 10 log 10 (1 2 ∕𝑀𝑆𝐸( ŷ, 𝑦))</p>
        <p>(2)(2)</p>
        <p>A higher PSNR value implies higher image quality and can be inferred from the above equation as PSNR approaches infinity as MSE approaches zero. SSIM, on the other hand, measures the similarity between two images based on the degradation of structural information. Unlike traditional error summation methods, SSIM models the image distortion by three factors, i.e., loss of correlation, luminance distortion, and contrast distortion, and is defined by:A higher PSNR value implies higher image quality and can be inferred from the above equation as PSNR approaches infinity as MSE approaches zero. SSIM, on the other hand, measures the similarity between two images based on the degradation of structural information. Unlike traditional error summation methods, SSIM models the image distortion by three factors, i.e., loss of correlation, luminance distortion, and contrast distortion, and is defined by:</p>
        <p>The luminance comparison function 𝑙( ŷ, 𝑦) measures the closeness of the two images' mean luminance (𝜇 𝑦 , 𝜇 ŷ). The contrast comparison function c( ŷ,y) measures the closeness of the contrast of the two images by their respective standard deviation 𝜎 𝑦 and 𝜎 ŷ. The structure comparison function s( ŷ,y) measures the correlation coefficient between the two images, where 𝜎 𝑦 ŷ is the covariance between 𝑦 and ŷ. The positive constants C1, C2, and C3 ensure that the denominator is always nonzero. All these functions range from [0,1], and so is the SSIM. SSIM value of 0 corresponds to two uncorrelated images, and 1 corresponds to the same images.The luminance comparison function 𝑙( ŷ, 𝑦) measures the closeness of the two images' mean luminance (𝜇 𝑦 , 𝜇 ŷ). The contrast comparison function c( ŷ,y) measures the closeness of the contrast of the two images by their respective standard deviation 𝜎 𝑦 and 𝜎 ŷ. The structure comparison function s( ŷ,y) measures the correlation coefficient between the two images, where 𝜎 𝑦 ŷ is the covariance between 𝑦 and ŷ. The positive constants C1, C2, and C3 ensure that the denominator is always nonzero. All these functions range from [0,1], and so is the SSIM. SSIM value of 0 corresponds to two uncorrelated images, and 1 corresponds to the same images.</p>
        <p>We present the results of the proposed deep autoencoder trained with 5 different noise types as discussed in the previous section. The choice of different noises is inspired by the different types of noise presents during scanning the sample. Our main aim was to determine a suitable noise model for our acoustic images. We have used two different metrics for evaluating the method namely PSNR and SSIM. Both metric provides different aspects of the requirement. PSNR provides higher visual interpretation, whereas the SSIM can be used to measure much finer similarities. Fig. 7 presents results taken from 3 different depth. We have tested using the pre-trained model trained using 5 different noises.We present the results of the proposed deep autoencoder trained with 5 different noise types as discussed in the previous section. The choice of different noises is inspired by the different types of noise presents during scanning the sample. Our main aim was to determine a suitable noise model for our acoustic images. We have used two different metrics for evaluating the method namely PSNR and SSIM. Both metric provides different aspects of the requirement. PSNR provides higher visual interpretation, whereas the SSIM can be used to measure much finer similarities. Fig. 7 presents results taken from 3 different depth. We have tested using the pre-trained model trained using 5 different noises.</p>
        <p>In Table 2 (a), we found that the Poisson noise model performs best in terms of PSNR (28.37) and SSIM (0.90). We found that the standard deviation of PSNR is 2.65 and SSIM is 0.05. In Table 1 (a) and (b) we found the standard deviation of SSIM is 1.85 and 0.38, PSNR is 0.06 and 0.06. It is noted that in all the cases, the standard deviation of the PSNR is not large.In Table 2 (a), we found that the Poisson noise model performs best in terms of PSNR (28.37) and SSIM (0.90). We found that the standard deviation of PSNR is 2.65 and SSIM is 0.05. In Table 1 (a) and (b) we found the standard deviation of SSIM is 1.85 and 0.38, PSNR is 0.06 and 0.06. It is noted that in all the cases, the standard deviation of the PSNR is not large.</p>
        <p>Table 2 shows the PSNR and SSIM values of 12 representative images corresponding to the two peaks (Fig. 4) with 50 ns intervals. The average PSNR and SSIM for each noise model is reported in Table 3.Table 2 shows the PSNR and SSIM values of 12 representative images corresponding to the two peaks (Fig. 4) with 50 ns intervals. The average PSNR and SSIM for each noise model is reported in Table 3.</p>
        <p>We note that the Gaussian noise model (GNM) shows better performance compared to the other 4 models, followed by the Poisson noise model (PNM) and Speckle noise model (SNM). The GNM however tends to over smooth the edges which make the image a little blurry. PNM on the other hand produces a coarse-textured image, as can be seen in image. SNM however produces qualitatively good results with negligible blurriness and better visibility of edges and boundaries.We note that the Gaussian noise model (GNM) shows better performance compared to the other 4 models, followed by the Poisson noise model (PNM) and Speckle noise model (SNM). The GNM however tends to over smooth the edges which make the image a little blurry. PNM on the other hand produces a coarse-textured image, as can be seen in image. SNM however produces qualitatively good results with negligible blurriness and better visibility of edges and boundaries.</p>
        <p>The point source technique based on Coulomb coupling is employed for the excitation and detection of ultrasonic waves in PZT ceramics. The two-dimensional spatial-temporal evolution of waves in the PZT is imaged for denoising ultrasonic images in the PZT ceramic. In this paper, we have shown that the deep learning-based convolutional autoencoders can be highly efficient for denoising ultrasonic images. We propose an architecture of the convolutional autoencoder capable of denoising ultrasonic images effectively. A modified version of VGG-16 architecture is employed for the encoder due to its simple yet robust structure, which is least likely to over-lift even a smaller data set. The decoder is the inverted version of the encoder, derived by replacing max-pooling with up-sampling layers. Model training has been carried out on a data-set created by degrading the noise-free images with four different noise types, namely speckle, Gaussian, Poisson, and salt and pepper, followed by testing on the data set containing noise of unknown type.The point source technique based on Coulomb coupling is employed for the excitation and detection of ultrasonic waves in PZT ceramics. The two-dimensional spatial-temporal evolution of waves in the PZT is imaged for denoising ultrasonic images in the PZT ceramic. In this paper, we have shown that the deep learning-based convolutional autoencoders can be highly efficient for denoising ultrasonic images. We propose an architecture of the convolutional autoencoder capable of denoising ultrasonic images effectively. A modified version of VGG-16 architecture is employed for the encoder due to its simple yet robust structure, which is least likely to over-lift even a smaller data set. The decoder is the inverted version of the encoder, derived by replacing max-pooling with up-sampling layers. Model training has been carried out on a data-set created by degrading the noise-free images with four different noise types, namely speckle, Gaussian, Poisson, and salt and pepper, followed by testing on the data set containing noise of unknown type.</p>
        <p>Quantitative analysis based on PSNR, SSIM, and visual inspection show that the convolutional autoencoder trained on speckle noise performed exceptionally well compared to other noise models. However, a gradual decline in the PSNR and SSIM values occurs as the ultrasonic waves propagate further in time. This is due to the reduction in the wave intensity, which causes the noise to dominate, making the image reconstruction onerous. Nonetheless, as long as the wave intensityQuantitative analysis based on PSNR, SSIM, and visual inspection show that the convolutional autoencoder trained on speckle noise performed exceptionally well compared to other noise models. However, a gradual decline in the PSNR and SSIM values occurs as the ultrasonic waves propagate further in time. This is due to the reduction in the wave intensity, which causes the noise to dominate, making the image reconstruction onerous. Nonetheless, as long as the wave intensity</p>
        <p>https://doi.org/10.1016/j.ultras.2022.106834 Received 16 September 2021; Received in revised form 10 May 2022; Accepted 17 August 2022https://doi.org/10.1016/j.ultras.2022.106834 Received 16 September 2021; Received in revised form 10 May 2022; Accepted 17 August 2022</p>
        <p>This work was supported by the Research Council of Norway, International Partnerships for Excellent Education, Research and Innovation (INTPART) Project, under Grant 309802 and Cristin Project, Norway,This work was supported by the Research Council of Norway, International Partnerships for Excellent Education, Research and Innovation (INTPART) Project, under Grant 309802 and Cristin Project, Norway,</p>
        <p>Table 2 (a) Represents the PSNR and (b) SSIM of 12 representative images.Table 2 (a) Represents the PSNR and (b) SSIM of 12 representative images.</p>
        <p>Average PSNR and SSIM for 12 representative images. lies in the vicinity of the peak signals, the proposed model yields remarkable results comparable to other state-of-the-art techniques like BM3D.Average PSNR and SSIM for 12 representative images. lies in the vicinity of the peak signals, the proposed model yields remarkable results comparable to other state-of-the-art techniques like BM3D.</p>
        <p>The authors declare the following financial interests/personal relationships which may be considered as potential competing interests: Anowarul Habib reports a relationship with UiT The Arctic University of Norway that includes: employment. Gaussian noise or additive white Gaussian noise (AWGN) is assumed to be zero mean in various image denoising literatures [32][33][34]. A noisy image 𝐴(𝑖, 𝑗) corrupted with AWGN 𝑁(𝑖, 𝑗) can be represented using Eq. ( 4).The authors declare the following financial interests/personal relationships which may be considered as potential competing interests: Anowarul Habib reports a relationship with UiT The Arctic University of Norway that includes: employment. Gaussian noise or additive white Gaussian noise (AWGN) is assumed to be zero mean in various image denoising literatures [32][33][34]. A noisy image 𝐴(𝑖, 𝑗) corrupted with AWGN 𝑁(𝑖, 𝑗) can be represented using Eq. ( 4).</p>
        <p>Where 𝐴 0 (𝑖, 𝑗) is the original image and the amplitude of 𝑁(𝑖, 𝑗) is drawn from a normal distribution with mean zero and standard deviation 𝜎 and is given by:Where 𝐴 0 (𝑖, 𝑗) is the original image and the amplitude of 𝑁(𝑖, 𝑗) is drawn from a normal distribution with mean zero and standard deviation 𝜎 and is given by:</p>
        <p>Here, the standard deviation is chosen to be 0.3 in order to keep the noise level close to that of the test images, obtained from the experiment described in the previous section.Here, the standard deviation is chosen to be 0.3 in order to keep the noise level close to that of the test images, obtained from the experiment described in the previous section.</p>
        <p>Unlike AWGN, speckle noise is known to behave as multiplicative noise with the obtained signal being a product of the original signal and the speckle noise added as defined in Eq. (6).Unlike AWGN, speckle noise is known to behave as multiplicative noise with the obtained signal being a product of the original signal and the speckle noise added as defined in Eq. (6).</p>
        <p>𝐴(𝑖, 𝑗) = 𝐴 0 (𝑖, 𝑗) ⋅ 𝑆(𝑖, 𝑗) (6) where, 𝑆(𝑖, 𝑗) is the speckle noise which is modeled using gamma distribution [35] given by Eq. (7).𝐴(𝑖, 𝑗) = 𝐴 0 (𝑖, 𝑗) ⋅ 𝑆(𝑖, 𝑗) (6) where, 𝑆(𝑖, 𝑗) is the speckle noise which is modeled using gamma distribution [35] given by Eq. (7).</p>
        <p>𝛼 and 𝛽 are the distribution parameters that relates to the mean and standard deviation by the following equation:𝛼 and 𝛽 are the distribution parameters that relates to the mean and standard deviation by the following equation:</p>
        <p>Mean and standard deviation are taken as 1 and 0.3 respectively.Mean and standard deviation are taken as 1 and 0.3 respectively.</p>
        <p>Among several non-Gaussian noises, Poisson noise is particularly known [36] for modeling the counting processes associated to many imaging modalities such as positron emission tomography (PET), singlephoton emission computerized tomography (SPECT), and fluorescent confocal microscopy imaging.The Poisson can be added using Eq. (9).Among several non-Gaussian noises, Poisson noise is particularly known [36] for modeling the counting processes associated to many imaging modalities such as positron emission tomography (PET), singlephoton emission computerized tomography (SPECT), and fluorescent confocal microscopy imaging.The Poisson can be added using Eq. (9).</p>
        <p>𝑃 (𝑖, 𝑗) is the poison noise with expectation value equal to 1, drawn from the Poisson distribution given by:𝑃 (𝑖, 𝑗) is the poison noise with expectation value equal to 1, drawn from the Poisson distribution given by:</p>
        <p>Where 𝜆 is the expected noise value and k is a random number accounting for the randomness in the samples drawn. 𝜎 is set to 0.3, which restricts the noise to be less than 30% of the original pixel value at coordinate (𝑖, 𝑗).Where 𝜆 is the expected noise value and k is a random number accounting for the randomness in the samples drawn. 𝜎 is set to 0.3, which restricts the noise to be less than 30% of the original pixel value at coordinate (𝑖, 𝑗).</p>
        <p>Salt and pepper noise is a type of impulse noise usually caused by malfunctioning pixels in camera sensors, faulty memory locations in hardware, or transmission in a noisy channel. The noise can be visualized like sprinkled white and black dots over the image. 30% of the pixels in the image are randomly chosen in the image and set either to 1 (salt) or 0 (pepper) with 50% probability.Salt and pepper noise is a type of impulse noise usually caused by malfunctioning pixels in camera sensors, faulty memory locations in hardware, or transmission in a noisy channel. The noise can be visualized like sprinkled white and black dots over the image. 30% of the pixels in the image are randomly chosen in the image and set either to 1 (salt) or 0 (pepper) with 50% probability.</p>
        <p>Supplementary material related to this article can be found online at https://doi.org/10.1016/j.ultras.2022.106834.Supplementary material related to this article can be found online at https://doi.org/10.1016/j.ultras.2022.106834.</p>
    </text>
</tei>
