<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T12:01+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>Classical ocean acoustic experiments involve the use of synchronized arrays of sensors. However, the need to cover large areas and/or the use of small robotic platforms has evoked interest in single-hydrophone processing methods for localizing a source or characterizing the propagation environment. One such processing method is "warping," a non-linear, physics-based signal processing tool dedicated to decomposing multipath features of low-frequency transient signals (frequency f &lt; 500 Hz), after their propagation through shallow water (depth D &lt; 200 m) and their reception on a distant single hydrophone (range r &gt; 1 km). Since its introduction to the underwater acoustics community in 2010, warping has been adopted in the ocean acoustics literature, mostly as a pre-processing method for single receiver geoacoustic inversion. Warping also has potential applications in other specialties, including bioacoustics; however, the technique can be daunting to many potential users unfamiliar with its intricacies. Consequently, this tutorial article covers basic warping theory, presents simulation examples, and provides practical experimental strategies. Accompanying supplementary material provides 
            <rs type="software">MATLAB</rs> code and simulated and experimental datasets for easy implementation of warping on both impulsive and frequency-modulated signals from both biotic and man-made sources. This combined material should provide interested readers with user-friendly resources for implementing warping methods into their own research. V
        </p>
        <p>The notations are organized into five subsections. In each subsection, notations are ordered alphabetically. The development of underwater acoustic signal processing was originally driven by military applications that require advanced sonar processing (Ainslie, 2010) to detect and localize quiet sources in an uncertain environment (Dosso and Wilmut, 2011). These days, acoustic signal processing also provides a major avenue for conducting oceanographic research. For example, active acoustics allows estimation of fish populations (Makris et al., 2006;Stanton et al., 2018) while passive acoustic monitoring (PAM) permits study of marine mammal seasonality and regional presence (Mellinger et al., 2007). One factor common to all of these applications, civilian and military, is the need for robust algorithms that incorporate the complexity of the ocean environment, whose properties are only partially known and variable in time and space. Numerous attempts to adapt more advanced signal processing or beamforming methods to underwater acoustic data [e.g., matched-field processing methods (Baggeroer et al., 1993)] have met with limited success, because most methods require incorporating more knowledge about the oceanic propagation environment than is typically available. Furthermore, most advanced signal processing methods require the use of extended time-synchronized array hydrophones to perform spatial and temporal filtering. The deployment of such systems is awkward and expensive.</p>
        <p>In this tutorial, we describe a relatively recent nonlinear signal processing method-termed warping-that is dedicated to the study of low-frequency (f &lt; 500 Hz) transient sounds recorded in coastal environments (water depth D &lt; 200 m) after propagation over at least several kilometers (range r &gt; 1 km). Numerous underwater sounds of interest fit into this category, including baleen whale vocalizations, airgun signals, or sounds from scientific tomography experiments. The objective of warping is to extract normally hidden features from the received signal that can then be used by other algorithms to localize the transient sound source, and/or to infer environmental information along the propagation track.</p>
        <p>One probably knows the warping word from a certain famous science fiction TV show, in which warping is used to bend space, such that ships can travel faster than light. While this concept has been repudiated by the National Aeronautics and Space Administration (NASA, 2015), it nonetheless has concrete applications in signal processing, where space (or time) can be warped virtually, using a computer. What differentiates warping from other underwater signal processing methods is that it requires only a single hydrophone, and has proven robust to environmental uncertainty: it usually works even without detailed prior information about the environment. As will be seen shortly, the method works well in real ocean environments, even though the basic algorithm is derived from a simple idealized model of a shallow ocean.</p>
        <p>The fact that this method requires only a single hydrophone has profound implications, particularly for bioacoustic studies. Passive acoustic recording systems are now routinely used to detect the seasonal and regional presence of whale species all over the world, including shallow continental shelf waters in the arctic and along the U.S. eastern seaboard. This is most often accomplished by deploying single-hydrophone recording packages over wide regions. The presence of baleen whale species in these data sets is identified by either manual or automated review of spectrograms, and then species-specific sounds are flagged (Leroy et al., 2018;Moore et al., 2006;Thode et al., 2012). Subsequent localization of animal sounds from these data sets is often desirable, because source localization is a key step in establishing population density estimates and evaluating subtle responses to anthropogenic activities. However, this is rarely implemented, because most traditional source localization methods require the deployment of multiple hydrophones over wide spatial regions, and complex measurements of relative arrival times between sensors. In this tutorial, we demonstrate how localization information can be extracted from both baleen whale impulsive and frequency-modulated sounds from single-hydrophone recordings in shallow water. Although source localization is not the end goal of this tutorial, we will nonetheless illustrate how baleen whale sounds can be localized using warping methods. The conclusion of this demonstration is that hundreds of existing data sets may have exploitable baleen whale localization (and environmental) information embedded inside their recordings.</p>
        <p>Bioacoustics is not the only application for warping. Traditional ocean acoustic experiments typically involve the use of array(s) of synchronized receivers. Hydrophone arrays are useful as they improve the signal-to-noise ratio (SNR), as well as increase the spatial diversity of the sampled field. Arrays, and particularly vertical line arrays have been extensively used for water column tomography and/or geoacoustic inversion (Caiti et al., 2006;Chapman, 2012). However, in shallow water, single hydrophone deployments also provide valuable data if the sources involved are sufficiently intense and broadband, because the frequency diversity of the signal can substitute for the spatial diversity normally sampled by a typical acoustic array (Hermand, 1999;Jesus et al., 2000). The warping method presented in this tutorial further enables extraction of high resolution information that can be used as the core of singlehydrophone inversion schemes. To illustrate this, we will demonstrate how propagation information can be extracted from a tomographic source, and then used to localize it. More complex inverse problems, such as tomography or geoacoustic inversion, will be ignored to keep the focus of this tutorial manageable, but relevant key references will be provided.</p>
        <p>While warping has demonstrated its utility and practicality, its learning curve can be steep. Warping is applicable to specific situations and does require expertise and some judgment in order to be used properly, as automated methods for bulk warping do not yet exist. Hence, the objective of this tutorial is to make warping understandable and available to any researcher that is interested in its application. To meet this objective, this tutorial includes extensive supplementary material 1 that provides both 
            <rs type="software">MATLAB</rs> code and data from several walk-through examples of biotic and abiotic sound sources. The aim is to provide the reader with the opportunity to easily try warping, to confirm they are using the technique properly, and to facilitate their application of the method on their own datasets.
        </p>
        <p>This tutorial assumes that the reader has basic knowledge about time-frequency (TF) analysis. In particular, we assume that the reader knows how to generate and interpret a spectrogram, a basic TF representation that is widely used in ocean acoustics. We also mention that an additional nontechnical overview of most of the concepts presented in this tutorial is provided in Bonnel (2018).</p>
        <p>The tutorial is arranged so that most sections can be read separately. This introduces some redundancy, but overall should make the tutorial most useful to readers that are interested in specific topics. The remainder of the tutorial is organized as follows:</p>
        <p>Section II covers the basic background required to understand the received signal, including the single receiver context (Sec. II A), modal propagation (Sec. II B), the Pekeris waveguide model (a simple model for coastal environments, Sec. II C), and time-frequency analysis (Sec. II D).</p>
        <p>Section III details the warping theory. It starts with simple explanations (Sec. III A), introduces the warping general concepts (Sec. III B), and then details a specific warping adapted to our modal dispersion concept (Sec. III C).</p>
        <p>Section IV presents the detailed warping algorithm-it is intended for readers with preliminary knowledge about warping, and can be skipped on a first reading. First, the numerical implementation of warping is presented (Sec. IV A). An example is then given, and remarks on the importance of time origin for warping are given (Sec. IV B).</p>
        <p>Section V probably constitutes the heart of the tutorial for beginners. It presents practical uses of warping, serving as a template for using warping in specific scenarios. It starts with a quick explanation on warping parameters (Sec. V A). It continues with warping use for impulsive sources (Sec. V B), and emphasizes the importance of correctly choosing the time origin. It then presents warping use for sources that are not impulsive, but whose waveform is known (Sec. V C). Finally, the section ends by showing how warping can be used when the source is an unknown frequency modulation (Sec. V D), a typical situation for baleen whale calls.</p>
        <p>Applications of warping are then covered in Sec VI. First, modal filtering and dispersion curve estimation are presented (Sec. VI A). Then, source localization is quickly reviewed (Sec. VI B).</p>
        <p>Last but not least, Sec. VII presents experimental examples that cover both warping and source localization. The first example is an impulsive vocalization by a right whale (Sec. VII A). The second example is a non-impulsive controlled tomography source, whose waveform is known (Sec. VII B). The last example is an unknown frequency modulation by a bowhead whale (Sec. VII C). The various steps of the analysis are shown, and the data used are provided in the supplementary material, 1 so that readers can process the data and confirm that their results match those shown in the tutorial.</p>
        <p>The tutorial ends with concluding remarks in Sec. VIII and three Appendixes. A first Appendix delves into the difference between time and frequency warpings, which may be of interest to specialist readers. A second Appendix reviews the development of warping theory through the literature, to act as a guide for readers seeking further references. A third and final Appendix details the derivations that lead to numerical warping formulas.</p>
        <p>Figure 1 shows the entire warping process as a flowchart, which provides a useful roadmap for the reader as the tutorial progresses. kilometers. This low-frequency/shallow water requirement ensures that acoustic propagation can be accurately modeled using modal propagation, which lies at the heart of the warping technique. While modes will be defined more precisely below, one can envision them as frequency-dependent arrivals generated from energy arriving along different routes between source and receiver. As a result, a signal received at a hydrophone will actually contain several distinct modal (arrivals) components. If these components can be isolated, one can use them to estimate the range and depth of the source (e.g., by comparing the relative arrival times and amplitudes of the arrivals) or infer details of the sound speed profile or ocean bottom composition (e.g., by measuring how the relative arrival times and amplitudes change with frequency). Extracting individual modes from a received signal is called modal filtering, and has been done historically by spatially filtering data on vertical line arrays (Buck et al., 1998;Neilsen and Westwood, 2002;Tindle et al., 1978).</p>
        <p>The key point of this tutorial is that under most lowfrequency shallow water environments, nonlinear signal processing (warping) and TF analysis can be used to conduct modal filtering on a single hydrophone. Once modes have been filtered, the fact that one has used a single receiver or an array becomes unimportant, and the source can be localized and/or the environment estimated using any previously developed modal based inversion scheme. The most popular method to do so is matched mode processing. It was originally proposed for array data (Wilson et al., 1988;Yang, 1987), and was later extended to single receiver scenarios (Le Touz e et al., 2008;Thode et al., 2017).</p>
        <p>This section describes modal propagation in shallow water. Readers uninterested by further technical details can go directly to Sec. II C. Readers who want to learn more about it are referred to Frisk (1994) and/or Jensen et al. (2011).</p>
        <p>Acoustic propagation in shallow water is highly impacted by interactions with the sea surface and the seabed. This environment acts as an acoustic waveguide, which effectively operates on the signal as a linear time-invariant system. In other words, if one considers a source signal s(f) emitted at depth z s , the signal yðf ; z s ; z r Þ received at depth z r and range r appears to have been filtered by the environment, yðf ; z s ; z r Þ ¼ sðf Þgðf ; z s ; z r ; rÞ;</p>
        <p>(1)</p>
        <p>where gðf ; z s ; z r ; rÞ is the environmental filtering effect. The quantity g has been assigned various names, including the transfer function or Green's function. Note that the inverse Fourier transform of g is usually called the impulse response. This term arises from the fact that if the source is a perfect impulse at time t ¼ 0, then the received signal will simply become yðt; z s ; z r Þ ¼ gðt; z r ; rÞ, or the "response" of the medium to the impulse.</p>
        <p>In the context considered here, shallow water (water depth D &lt; 200 m) and low-frequencies (f &lt; 500 Hz), the propagation is conveniently described by normal mode theory, provided that the ocean conditions (e.g., bathymetry, bottom composition) vary little with distance from the origin (the "range-independent" assumption). At ranges greater than a few acoustic wavelengths, the resulting acoustic field can then be interpreted as the sum of several modal components, with each mode propagating dispersively (i.e., the effective propagation speed varies with frequency). Formally stated, gðf ; z s ; z r ; rÞ ¼ X M m¼1 a m ðf ; z s ; z r Þe j/ m ðf ;rÞ ;</p>
        <p>(2) with M being the number of distinct propagating modes, with each mode having a unique amplitude a m ðf ; z s ; z r Þ and a phase / m ðf ; rÞ. This equation is derived from the acoustic wave equation using the classic separation of variables method in environments that are azimuthally symmetric and range-independent. Before continuing, note that modal amplitude primarily depends on source/receiver depth, but not range, whereas the modal phase (and thus modal travel time) depends primarily on range, but not on source/receiver depth.</p>
        <p>Of particular interest here is the modal phase</p>
        <p>where k m ðf Þ represents the real part of the horizontal wavenumber of mode m. In other words, k m ðf Þ is the spatial frequency of mode m. It solely depends on the environment (water depth, sound speed profile, seabed geoacoustic properties, etc.), but not on the experimental geometry. As a result, the modal travel time</p>
        <p>depends only on the range r and the environment. This environmental dependence is expressed through the modal group speed</p>
        <p>On the other hand, the modal amplitude is given by</p>
        <p>with W m ðf ; zÞ being the modal depth function of mode m, b m ðf Þ the imaginary part of the modal wavenumber, and Q a constant unimportant for our purposes here. The modal amplitude clearly depends on both the environment and on source/receiver depth through the modal depth function W m ðf ; zÞ. It also weakly depends on range through, but this is often ignored (Jensen et al., 2011). The modal travel time [Eq (4)] and amplitude [Eq (5)] have been given for the impulse response only. Let us now consider a source signal sðf Þ ¼ jsðf Þje / s ðf Þ . Equation (1) shows that the received signal is a sum of modal components, which are all similarly impacted by the source amplitude and phase. The received amplitudes become jsðf Þja m ðf ; z s ; z r Þ and the received phase becomes / s ðf Þ þ / m ðf ; rÞ. As a result, the modal travel times for a general received signal become</p>
        <p>where t s ðf Þ ¼ ð1=2pÞ½@/ s ðf Þ=@f is the source timefrequency law. Note that if the source is impulsive, all the frequencies are emitted at a single time t 0 and t s ðf Þ ¼ t 0 . The quantity t s ðf Þ is properly defined from a signal processing point of view as the source "group delay." In the same manner, s m ðf Þ is defined as the group delay of the received mode m. Because it marks a given mode's location in the time-frequency (TF) domain (e.g., on a spectrogram, see Sec. II D), Eq. ( 6) is also called the TF dispersion curve. Note that the derivations presented above assume that a m ðf ; z s ; z r Þ is effectively an amplitude while / m ðf ; rÞ is effectively a phase. In other words, we assume that a m ðf ; z s ; z r Þand thus W m ðf ; zÞ-varies slowly with f, while e j/ m ðf ;rÞ oscillates more rapidly with respect to f. This is largely true for the context considered here (low-frequency propagation in shallow water). This decomposition may be questionable in other contexts, such as deep water (Emmetie `re et al., 2018).</p>
        <p>In this section, we present a simple model of a coastal environment. It will be used to illustrate modal propagation and to generate simulated signals to be used throughout the tutorial.</p>
        <p>A straightforward way to acoustically model coastal environments is to consider an isovelocity fluid layer (the water), between a perfectly reflecting surface (the sea surface) and a semi-infinite isovelocity fluid basement (the seabed). This model is called the Pekeris waveguide, it carries the name of C. L. Pekeris, who first derived the associated equations (Pekeris, 1948). The model does not include any realistic range/depth dependence of the environment (e.g., water column stratification, seabed layers, etc.). Nonetheless, it produces realistic modal features. It can thus be used as an educational example. We will see later in the tutorial that it can also be used as the core of many localization algorithms.</p>
        <p>A Pekeris waveguide is fully defined by the parameters of its water column and seabed. The following notations and nominal values will be used throughout the paper:</p>
        <p>• water column: depth D ¼ 100 m, sound speed c w ¼ 1500 m/s, density q w ¼ 1000 kg/m 3 ; • basement (sediment): sound speed c b ¼ 1600 m/s, density q b ¼ 1500 kg/m 3 .</p>
        <p>Using these parameters, one can use simple numerical solvers (Jensen et al., 2011) to find modal wavenumbers k m ðf Þ, group speeds v m ðf Þ, and depth functions W m ðf ; zÞ. These can be further combined to simulate a propagated signal in the frequency domain [using Eqs. (2), (3), and (5)] as well as in the time domain (going from the frequency domain to time domain with an inverse Fourier transform), or to directly predict modal travel time [using Eq. ( 6)].</p>
        <p>Further details are not provided here. Rather, a 
            <rs type="software">MATLAB</rs>
            <rs type="software">code</rs> to simulate propagation in a Pekeris waveguide is provided as supplementary material. 1 Figure 2 illustrates the propagation of a pulse in a Pekeris waveguide. Please note that some sediment attenuation (0.2 dB=k) has been added in the seabed. This does not change the general propagation features, but slightly increases the modal separation, which makes the figure easier to understand.
        </p>
        <p>The source signal considered here is a short broadband pulse. It lasts less than 0.1 s, and most of its frequency content is within 25 and 75 Hz. Because modal group speed depends on frequency, the duration of the pulse arrival increases with range. This can be understood by thinking about a marathon. All runners start at the same time, but the gap between runners increases as the race progresses, because their individual speeds are different. This can be seen on Fig. 2 after propagation over 5 km: the duration of the received pulse has nearly doubled. This effect, due to a frequency dependent speed, is called dispersion.</p>
        <p>However, two different dispersions co-exist for modal propagation. For a given mode m 0 , the group speed v m 0 ðf Þ changes with frequency f, which is called intra-modal dispersion. As a result, the duration of a given mode increases with increasing range. On the other hand, for a given frequency f 0 , the group speed v m ðf 0 Þ changes with mode number m, which is called inter-modal dispersion. As a result, the gap between modes also increases with increasing range. We can further develop the racing analogy by considering several groups of runners (e.g., age classes), with runners within the same age class displaying similar speeds, but with different age classes displaying relatively larger differences in speed (with older age classes generally slower than younger age classes). If all the runners/groups start the race at the same time, one will not be able to distinguish the different age classes at the beginning. However, as the race continues, the different age classes will separate along the course. If the race lasts long enough, then the age classes may end up being completely separated in time, arriving past the finish line in distinct waves. Since runners within a given age class do not have exactly the same speed, timing gaps between runners in the same age class will also appear, causing a time spread in the finishing time within an age class. From a modal perspective, a running age class represents a given mode arrival, the time spread between runners within an age-class represents intra-modal dispersion, and the timing spread between age classes represents intermodal dispersion. These concepts are further illustrated in Fig. 2. At 15 km range, one can see two modes that are nearly separated: mode 1 arrives between t ' 0 to t ' 0:20 s, while mode 2 arrives between t ' 0:15 to t ' 0:40 s. There is also a third mode, barely visible after t ' 0:35 s. At 30 km, the first two modes have become fully separated in time. This example also nicely illustrates how the duration (spread) of an individual mode arrival increases with range. This is particularly evident for mode 2, which lasts more than 0.4 s when r ¼ 30 km. While mode duration/travel time changes with range, one can also see from the right column of Fig. 2 that the relative mode amplitudes depend on source/receiver depth. This is particularly evident for mode 2, as can be seen on the second column of Fig. 2. This phenomenon, mentioned in Sec. II B, is due to the oscillations of the modal depth functions (and thus the mode amplitudes) with depth. It will not be further explored in this tutorial.</p>
        <p>The example shown in Fig. 2 provides a first illustration of modal propagation. However, modal dispersion becomes easier to understand when the signal is plotted in the TF domain. Indeed, by using TF representation, one can directly visualize the modal dispersion. This is illustrated in Fig. 3, which presents idealized TF representations of underwater signals. The right part of the figure (with the warped signal) can be ignored for now.</p>
        <p>The first line of Fig. 3 illustrates the propagation of an impulsive source. Such a source is a vertical line in the TF domain, because all frequencies are emitted at the same time. After propagation, one can see several structures in the TF domain, because several modes are propagating. Each mode is a curve with high frequencies arriving before low frequencies. This is because in general, for shallow water environments, group velocity is higher for high frequencies, and thus travel time is smaller. Note that warping is based on the hypothesis that low order modes arrive first and that modes do not cross in the TF domain, a situation representative of most shallow-water modal propagation. Specific cases where the hypothesis is severely violated (and thus warping does not work at all) are discussed in the conclusion of the article. The remainder of the article assumes that this hypothesis (conventional shallow-water modal propagation) is verified, at least over the frequency band of interest. As a reminder, the formula for dispersion curves (the blue lines in Fig. 3) is given by Eq. ( 6).</p>
        <p>The second line of Fig. 3 illustrates the propagation of a frequency modulated source. In the example considered here, the source signal is a linear downsweep: the frequency gradually decreases with time. The interpretation of the received signal is the same as for the impulsive source. If one goes back to the race analogy, the impulsive source case is a race where all runners start together. On the other hand, the FM source context represents a race where runners have a staggered start. The delayed departure effectively delays their arrival time, which globally shifts the arrival pattern.</p>
        <p>Figure 3 is an ideal TF representation, which is impossible to obtain in reality. Any true TF representation is contaminated by TF uncertainty (Boashash, 2015), which makes it impossible to perfectly isolate a signal both in time and frequency. As a result, one cannot obtain infinitesimally thin lines-as in Fig. 3-to represent modes. Also, one will have to deal with interferences between modes, particularly at short ranges where mode time separations are small.</p>
        <p>The spectrogram is one of the easiest TF representations to generate, and is the default choice for most practical applications. The spectogram's main feature is that it minimizes the interferences between signal components (in our context, modes), and thus we will use the spectrogram in this tutorial. The trade-off is that a spectogram provides a really poor TF resolution of these components (i.e., the mode dispersion curves). The dispersion curve estimation issue will be dealt with later (see Sec. VI A).</p>
        <p>It is beyond the scope of this tutorial to detail how spectrograms are computed. Readers who want more background on it are referred to Boashash (2015). For practical matters, a 
            <rs type="software">MATLAB</rs>
            <rs type="software">code</rs> to compute spectrograms is provided as supplementary material. 1,2 Examples of spectrograms simulated in a Pekeris waveguide are presented in Fig. 4. The figure shows the time signal in the upper panels, and the spectrograms in the middle panels. As explained before, modal time separations increase with range. At large ranges (i.e., 30 km), modes are well timeseparated and thus barely interfere. At intermediate ranges (i.e., 15 km), one can still easily distinguish between modes, although there is some interference between them. However, at short ranges (i.e., 5 km), it becomes impossible to clearly distinguish between modes. Nonetheless, the strong, regular fluctuation in intensity vs frequency on the short-range spectrogram provides a clear indication that several modes exist in the signal, even if they are not distinctively separated in time. One may look at Crance et al. (2015) (their Fig. 3) for an experimental example of this phenomenon, where the considered signal is a fin whale vocalization recorded in the Arctic.
        </p>
        <p>The main objective of warping is to facilitate modal separation of ocean waveguide signals, particularly for those produced at short-to mid-ranges. In a single receiver context, it is reasonable to resort to TF analysis to separate the modes. However, classical methods are not adapted to represent signals with non-linear time dependence, such as normal mode arrivals. As a result, warping can be used to "linearize" the modes, so that the transformed signal can then be conveniently processed using standard TF methods, such as the spectrogram.</p>
        <p>Warping is either a compression or stretching of a signal over time. In our context, the signal is recorded on a single hydrophone as a function of time. As a result, the only way to compress/stretch the signal is to warp the time axisor, equivalently, the frequency axis. If the signal were recorded on an array, one could also warp a spatial (or wavenumber) axis. Mathematically, space and time warping are equivalent, but in this tutorial we only present time warping.</p>
        <p>Before delving into the math, the warping effect on a continuous tone is illustrated in Fig. 5. The considered signal is color-coded, to better visualize the warping effect: the original signal contains an homogeneous ratio of colors. Figure 5(a) presents the original continuous tone signal. because the signal has been stretched non-uniformly over time. In the example presented here, the beginning of the signal has been stretched more than its end. This non-linear effect is further illustrated by the signal colors. Indeed, color ratio is homogeneous on the original signal [Fig. 5(a)] but becomes inhomogeneous after non-linear warping [Fig. 5(d) and5(e)]. As an example, blue dominates the warped signal in Fig. 5(e).</p>
        <p>One can also see from Fig. 5 that warping modifies the signal's amplitude [note that the scale of the vertical axis is the same for all panels but Fig. 5(d)]. As discussed below, the warping operation is designed so that it does not modify the overall energy of the signal. As a result, if a signal is shortened (compressed in time), its amplitude must increase in order to conserve energy. Consequently, the signal that has been linearly compressed [Fig. 5(b)] has a higher amplitude than the original signal [Fig. 5(a)]. For the same reason, the signal that has been linearly stretched [Fig. 5(c)] has a smaller amplitude than the original signal. For non-linear warping, the situation is more complex, and the amplitude must be adjusted over time, depending on the amount of compression/stretching that is occurring at that instant. One can see that the amplitude of the signal in Fig. 5(e) (non-linear stretching) is increasing with time. This is consistent with the previous observation, since the beginning of the signal has been stretched more than its end. In the same way, the amplitude of the signal in Fig. 5(d) (non-linear compression) is decreasing with time. This is because the beginning of the signal has been more compressed than its end.</p>
        <p>Mathematically, warping is a substitution. One replaces time t by something else, say h(t), which is called a warping function. Considering an original signal y(t), the warped signal y w ðtÞ is obtained through</p>
        <p>where h 0 ðtÞ is the time derivative of the warping function.</p>
        <p>The factor ffiffiffiffiffiffiffiffiffiffiffi ffi jh 0 ðtÞj p ensures energy conservation between y w and y, it arises from integration by substitution while equating the energy of y with the energy of y w . As a reminder, energy conservation has been discussed in Sec. III A, and can be visually observed in Fig. 5.</p>
        <p>An important property of the warping function h(t) is that it must be bijective (i.e., all points in a function are uniquely matched to all points in a second function). As a result, its (functional) inverse h À1 ðtÞ can be defined, and so warping can be reversed. Any signal warped with h(t) can then be unwarped using h À1 ðtÞ as the new warping function. In other words, there is a one-to-one correspondence between all points in y and y w , so that it is possible to go from one to the other using either warping or inverse warping. In practice, warping (and inverse warping) are applied as a non-linear resampling, as detailed in Sec. IV.</p>
        <p>The warping definition, Eq. ( 7), shows that the basic requirement for warping is to choose an appropriate warping function. To do so, one must remember the warping objective (see the introduction of Sec. III), which is to "linearize modes," or more generally, to linearize a signal. This is a shortcut for saying that we actually want to linearize the phase of the signal.</p>
        <p>To understand this, let us consider a signal yðtÞ ¼ aðtÞe j2pf 0 UðtÞ , with a(t) its amplitude, UðtÞ its (non-linear) phase, and f 0 a constant. To linearize the phase of y(t) one must choose hðtÞ ¼ U À1 ðtÞ as the warping function. The warped signal becomes y w ðtÞ ¼ bðtÞe j2pf 0 t , with bðtÞ ¼ ffiffiffiffiffiffiffiffiffiffiffi ffi jh 0 ðtÞj p a½hðtÞ the amplitude of the warped signal, and 2pf 0 t its phase which is now linear. Going back to Fig. 5, one can imagine that the original signal with a non-linear phase is shown in Fig. 5(d) [or, equivalently, Fig. 5(e)], while the warped signal with a linear phase is shown in Fig. 5(a).</p>
        <p>Before going further, note that our focus has been warping in time. However, one may also consider warping in frequency. In this case, one takes a signal in the frequency domain (i.e., after a Fourier transform), and then compresses/ stretches the frequency axis (which is now the independent variable). This is not useful for the remainder of the tutorial, and thus will not be discussed further. However, an Appendix provides a comparison between time and frequency warping.</p>
        <p>In Sec. III B, we showed that an adequate choice of the warping function allows reaching the warping objective: linearizing the phase of the signal. However, to do so, one needs to know the phase of the signal [UðtÞ] in order to choose the correct warping function [hðtÞ ¼ U À1 ðtÞ]. This, unfortunately, is a chicken and egg problem. One needs to know the expression of the phase to warp the signal. But if the phase is perfectly known, one usually does not need warping.</p>
        <p>One way to circumvent the issue is to use an approximate model of UðtÞ, knowing it is not perfect, but hoping it will be good enough for real-life applications. To do so in our underwater acoustics context, one needs to use knowledge about the underlying physics driving modal propagation.</p>
        <p>However, our modal propagation context brings an extra complication. Several modes are propagating, and the phase of the modes is different from one mode to the next. As a result, one needs to either find a warping function that is adapted to every mode at once, or to define a different warping function for each mode.</p>
        <p>As stated in the introduction of Sec. III, this tutorial focuses on the first option. We want to warp all the modes at once, so that the warped signal can be conveniently studied using a conventional spectrogram. The ideal results of warping are illustrated on the right side of Fig. 3. All the modes have been transformed into continuous tones and appear as horizontal lines in the TF domain.</p>
        <p>The simplest model of shallow water propagation that captures the basic physics of dispersion is the so-called "ideal isovelocity" waveguide. It is a range-independent waveguide with a perfectly reflecting surface, a constant water sound speed c w , and a perfectly rigid seabed. In other words, the sea-surface is a perfect acoustic mirror, the water column is acoustically homogeneous, and the sound does not penetrate in the seabed.</p>
        <p>The isovelocity waveguide is simpler than the Pekeris waveguide that was presented in Sec. II C, but less realistic. Its main interest here is that closed-form equations can be obtained for all the modal quantities. Of particular interest for us is the equation for modal phase, whose expression shows all modes can be warped using the same non-linear transform in time.</p>
        <p>As a first step, let us write the received signal in the time domain as</p>
        <p>a m iso ðtÞe j/ m iso ðtÞ ;</p>
        <p>with M iso the number of propagating modes in the ideal waveguide, a m iso ðtÞ the modal amplitude, and / m iso ðtÞ the modal phase.</p>
        <p>For a source/receiver range r, the modal phase is given by</p>
        <p>with t r ¼ r=c w (the earliest time at which any signal energy can reach the sensor), and f c;m ¼ ð2m À 1Þc w =4D (the cutoff frequency of mode m in the waveguide), and D the water depth. Note that Eqs. ( 8) and (9) are given in the time domain, while the classical modal equations ( 2) and (3) are given in the frequency domain. Equation ( 8) is obtained from Eq. ( 2) using an inverse Fourier transform. The specific terms a m iso ðtÞ and / m iso ðtÞ can be analytically derived using a stationary phase approximation.</p>
        <p>The interesting feature of the modal phase [Eq. ( 9)] is that it can be separated into a term (2pf c;m ) that depends on modal number m only, and a term nðtÞ ¼ ffiffiffiffiffiffiffiffiffiffiffiffi ffi t 2 À t 2 r p that depends on time t only. This specific separation of variables allows all modes to share the same warping transformation.</p>
        <p>To define the warping function let us assume propagation in an isovelocity waveguide and that the source is impulsive. In this case, the modal phase Eq. ( 9) can be used directly to define the warping function.</p>
        <p>Following the derivation in Sec. III B, we will use the warping function hðtÞ ¼ n À1 ðtÞ, or</p>
        <p>The function for inverse warping is obtained as h À1 ðtÞ ¼ nðtÞ, or</p>
        <p>Using h(t) as the warping function, the warped signal becomes y w iso ðtÞ ¼ X M iso m¼1 b m iso ðtÞe j2pf c;m t ; (12) with b m iso ðtÞ ¼ ffiffiffiffiffiffiffiffiffiffiffi ffi jh 0 ðtÞj p a m iso ½hðtÞ. Each warped mode is thus transformed into a continuous tone of frequency f c;m , with amplitude b m iso ðtÞ. What began as a series of frequencymodulated swept tones now appears as a set of parallel horizontal lines in the TF domain, as illustrated on the right side of Fig. 3.</p>
        <p>Obviously, warped modes will be perfectly horizontal only if the signal under study has propagated within an actual ideal waveguide, which is never the case in reality. However, we have empirically observed that Eq. ( 10) is robust enough that when it is applied to real modes propagating in much more complex environments, the resulting transformed modes are still relatively tonal. This property is illustrated in the lower panels of Fig. 4 for propagation in a Pekeris waveguide. One can see that the warped modes are not the theoretically predicted pure tones (i.e., perfectly horizontal lines), but instead are tilted and slightly curved. Nonetheless, each warped mode is still separable using simple filtering methods. This robust behavior is characteristic of most shallow water experimental data, which will be illustrated through several examples below.</p>
        <p>This section gives technical details about warping implementation. An important detail is that warping theoretically requires the knowledge of the source emission time, which is used as the time origin. Readers encountering warping for the first time can skip this section and go directly to Sec. V.</p>
        <p>This section summarizes all the formulas that enable a practical implementation of warping. A thorough derivation for these formulas is provided in Appendix C.</p>
        <p>Let us consider a signal y(t), with t min &lt; t &lt; t max . Its discrete version, sampled at frequency f s , is denoted y½n, with n 2 v0; N À 1b. The continuous warped signal, y w ðtÞ, is obtained through Eq. ( 7). We are interested here in its discrete version, denoted y w ½k, with k 2 v0; K À 1b.</p>
        <p>A convenient sampling frequency for the warped signal is f h s ¼ 2=Dt N , with</p>
        <p>The corresponding number of samples is</p>
        <p>with ceil(x) the nearest integer greater than or equal to x.</p>
        <p>Finally, the kth sample of the warped signal is</p>
        <p>, and the quantity y½hðt k Þ is obtained from the original discrete signal y through interpolation.</p>
        <p>Inverse warping can be seen as forward warping using h À1 ðtÞ as the warping function. However, the sampling frequency and the number of samples of the signal after inverse warping are already known: they are the same as for the original signal: f s and N.</p>
        <p>Let y w denote the warped signal and y u the unwarped signal, recovered from y w using inverse warping. The nth sample of the unwarped signal is</p>
        <p>, and the quantity y w ½h À1 ðt n Þ obtained via interpolation of the warped discrete signal y w .</p>
        <p>As a simple example, let us consider a continuous tone and try warping. A 5 Hz sine wave, sampled at f s ¼ 100 Hz and lasting 2 s (N ¼ 201) is plotted in Fig. 6. It is warped using the method presented above, using t r ¼ r=c w , where r ¼ 10 km and c w ¼ 1500 m/s. The warped signal, as well as the signal recovered after forward and inverse warping, are also plotted in Fig. 6. One sees the perfect match between the original signal and the recovered signal, illustrating the reversibility of the warping operation.</p>
        <p>Note that the time axis shown in Fig. 6(a) starts at t ¼ 0 s. This is in violation of warping theory, which states that the signal of interest exists only for time t &gt; r=c [see Eq. ( 9) which shows that the signal phase is not defined for t t r ]. However, in practice, one rarely knows the absolute time origin. A common practice is to set t ¼ 0 as the initial sample of the signal of interest, as has been plotted here (and will be done for all the warping examples in this tutorial).</p>
        <p>Nonetheless, the correct time origin needs to be used in the warping code. The algorithm provided as a supplementary material 1 uses a mathematically correct time axis, in that it assigns a time t ¼ r=c þ 1=f s to the first time sample. The accompanying plotting scripts, however, always plot the first sample as t ¼ 0.</p>
        <p>The warping function, hðtÞ ¼ ffiffiffiffiffiffiffiffiffiffiffiffi ffi</p>
        <p>, requires the choice of a single parameter t r ¼ r=c. Since we will later be interested in source localization, one may think this involves circular reasoning, since range is something we eventually want to estimate, but the warping process needs an estimate of t r , which in turn requires a range estimate. However, warping is always followed by inverse warping, which effectively removes any effect of the warping parameter t r ¼ r=c. As a result, any source localization result obtained with the extracted modes (which have been warped and unwarped) will be independent of t r , and thus to the trial range chosen as a warping parameter.</p>
        <p>In practice, warping results are only weakly sensitive to the choice of t r , and it is not required to know the range nor the water sound speed to apply warping. All the signals presented in this tutorial, including the experimental ones, have been warped using r ¼ 10 km and c ¼ 1500 m/s (while true ranges are between 5 and 15 km). However, warping is much more sensitive to other factors, such as the choice of the time origin. This will be detailed below.</p>
        <p>If the signal is impulsive, warping is straightforward, because the warping function has been defined with this assumption (see Sec. III C 2). An important step, though, is identifying the appropriate time origin.</p>
        <p>As explained in Sec. IV B, one does not use the true time origin of the data. Rather, one identifies a time sample that corresponds to t ¼ r=c w þ 1=f s and uses that as the start of the target signal. All the previous samples corresponding to t r=c w are thus dropped before applying warping.</p>
        <p>In an ideal waveguide without noise, no signal can exist before t ¼ r=c w . The acoustic energy only starts to arrive at t ¼ r=c w , and slowly decays for time t &gt; r=c w . In this case, identifying the appropriate sample to denote time origin of warping is trivial: simply mark the time that the signal becomes non-zero.</p>
        <p>However, real life is more complex, even if we still consider a noiseless environment. For example, the water column usually has a depth-dependent sound speed, so that c w is not uniquely defined. Furthermore, acoustic energy also penetrates the seabed, which usually has a larger speed than the water column. As a result, even if the water column is isovelocity, acoustic energy will arrive at the receiver before t ¼ r=c w . This is illustrated in Fig. 7, which shows an impulsive signal simulated in a noisy Pekeris waveguide (see Sec. II C), with SNR ¼ 20 dB. Time t ¼ r=c w ' 6:67 s and t ¼ r=c b ¼ 6:25 s are identified with vertical lines. One can see acoustic energy before t ¼ r=c w , which corresponds to sound traveling through the seabed. These bottom arrivals are particularly visible for mode 1, with energy between 5 and 15 Hz at times between 6.3 and 6.75 s. The specific TF point where a dispersion curve bends is called the Airy phase (Jensen et al., 2011, pp. 124-126). It is the last modal arrival, and thus corresponds to the group speed minimum. The acoustic energy at frequencies below the Airy phase mostly propagates within the seabed and is usually called a ground wave. It is thus highly attenuated and usually difficult to see in real data. However, in this case Airy phase and ground waves of mode 1 are clearly visible, they are respectively denoted by a black cross and a black ellipse in Fig. 7(b).</p>
        <p>Regardless of these complications, when warping a signal one needs to make a guess and pick a time origin that is as close to t ¼ r=c w as possible. We suggest using an iterative trial and error process. First, look at the original signal (both time domain and spectrogram) and try to assess the time of arrival of the highest frequencies, which tend to experience the least dispersion and thus approach t r . Then, warp the signal using this time origin estimate. Last, verify the warping results by looking at the spectrogram of the warped signal. If needed, change the time origin and iterate. Usually, a few iterations are enough to obtain a "adequate" warped signal Bonnel et al. (2017). By "adequate" we mean that the warped modes are relatively horizontal and cleanly separated on the warped spectrogram, and can thus be identified and filtered (see Sec. VI A).</p>
        <p>The influence of time origin on warping is illustrated in Fig. 8. The signal considered here is the one shown in Fig. 7. Three different time origins are considered here: an accurate one which corresponds to t ¼ r=c w , an early one (t ¼ r=c w À dt), and a late one (t ¼ r=c w þ dt), where dt ¼ 0.1 s, which is about 10 samples. Such a large dt is probably too extreme for a realistic mistake, but it nonetheless provides intuitive insight. Even when using the correct time origin [Fig. 8(b)], one can see that the modes are not perfectly horizontal, due to the mismatch between the waveguide environment (a Pekeris waveguide), and the idealized analytical model used for warping (an ideal waveguide with a rigid bottom). However, the warped modes have become well-separated, when compared to the spectrogram in Fig. 7. When using a time origin that is too early [Fig. 8(d)], the modes are definitely not horizontal tones, but span a wider bandwidth across the warped spectrum. They thus overlap and interfere with each other, which will negatively impact further filtering. Finally, when the time origin is later than t r [Fig. 8(f)], the modes become virtually horizontal. In this specific case, delaying the time origin helps compensate for the mismatch between the environment and the warping model, and is an ideal choice for separating modes 2 and higher. However, this improved separation comes at a price: mode 1 has vanished in the warped spectrogram. In shallow water propagation the first mode is generally the least impacted by dispersion, and as a result most of its energy arrival is close to t r . It is thus typically removed from the signal if a late time origin is chosen. In a real life scenario, we advise choosing the latest time origin that provides a decent modal separation without clipping mode 1. In certain cases, it may be useful to warp twice: the first using an early time origin for mode 1, and second using a later time origin for the other modes. When doing this though, one must be careful to time-align the recovered modes correctly.</p>
        <p>If the signal is not originally impulsive, it is necessary to compensate for the signal structure. In principle, if one had a very good knowledge of the source signal, one could perform source deconvolution. The basic idea is to divide Eq. (2) by s(f) in order to completely cancel frequencydependent variations arising from the source signal.</p>
        <p>When s(f) is well known, source deconvolution is straightforward. The only concern is to prevent division by zero (or small values), at frequencies where s(f) is (near) null. The easiest and most classical deconvolution method is probably (Clayton and Wiggins, 1976)</p>
        <p>with e a small number, which is usually chosen as a small percentage of maxfjsðf Þj 2 g. This method is often called "water-level deconvolution", with the water level parameter.</p>
        <p>The importance of source deconvolution is illustrated below, using our noisy Pekeris waveguide from Fig. 7. However, here we incorporate a more complex source signal: a set of three perfect impulses with decreasing amplitude, and a separation of 75 ms between pulses. Although not fully realistic, this model captures key features of several controlled sources that are used for acoustical oceanography, such as light-bulbs (Heard et al., 1997), combustive sound sources (CSS) (McNeese et al., 2010), or explosives (Chapman, 1985). All these source systems produce an important impulsive signal that is often followed by secondary weaker impulsive signal(s), usually called bubble pulse(s).</p>
        <p>The simulation results are illustrated in Fig. 9. The noisy impulse response and the corresponding warped signal are shown in the first column. Note that Fig. 9(b) is exactly the same as Fig. 8(b), in that we are using an accurate time origin, which allows us to visually assess the effect of source deconvolution.</p>
        <p>The simulation that takes into account the source signal is shown in the second column of Fig. 9. One can see in the original spectrogram that modal dispersion is barely visible. This is because modes from the main impulse are mixed with modes from the bubble pulses. This is further confirmed by the spectrogram of the warped signal, where modes cannot be identified.</p>
        <p>As a last step, source deconvolution is applied, and results are illustrated in the third column of Fig. 9. One can now clearly see the modes, with spectrograms that are virtually equivalent to those obtained when working on the impulse response.</p>
        <p>For in situ signals, source deconvolution requires a good measurement (or model) of the source signal. In a warping context, it has been successfully applied on lightbulb (Duan et al., 2016) and CSS data (Bonnel et al., 2019;Bonnel et al., 2018), with 2 ½0:01; 0:1.</p>
        <p>Source deconvolution is a powerful tool but it requires an accurate knowledge about the source signal structure, which is often not the case for bioacoustic signals. Here, we present an alternative deconvolution approach for frequency modulated (FM) source signals, where the precise nature of the FM signal is unknown. We find, practically speaking, that only a rough estimate of modulation phase is needed and often can be estimated from the received signal. This rough estimate can subsequently be used to perform phase compensation, and then warping.</p>
        <p>Even if one does not know the true frequencydependent amplitude of the source signal, if one knows the source phase / s ðf Þ or, equivalently, its time-frequency law s s ðf Þ ¼ ð1=2pÞ½@/ s ðf Þ=@f , then it is possible to compensate for the source phase in the received signal by computing (Bonnel et al., 2014)</p>
        <p>Such a process is not a true source deconvolution, as the amplitude of the received signal has not been corrected. However, the phase of y pc ðf Þ has become the same as the phase of the channel impulse response. Warping can thus be applied on y pc ðf Þ.</p>
        <p>In a real-life scenario where the source phase is unknown, the important point is to estimate / s ðf Þ from the data. It is actually done by estimating the source TF law s s ðf Þ, which is later converted to / s ðf Þ so that phase compensation can be performed.</p>
        <p>To do so, a rough estimate of s s ðf Þ can be obtained by manually tracing the arrival of mode 1 (or the lowest-order mode) on the received spectrogram. Since mode 1 is generally the least affected by dispersion, its TF shape on the received signal usually provides a good initial estimate of the source TF law. In practice, s s ðf Þ is usually approximated by a piecewise linear function, which is defined by manually selecting several TF points on the spectrogram, and then linearly interpolating between them.</p>
        <p>A 
            <rs type="software">MATLAB</rs>
            <rs type="software">code</rs> to perform this procedure is provided in the supplementary material. 1 Its use is illustrated here on a simple example. Once again, we re-use the noisy Pekeris waveguide model. The spectrogram of the environmental impulse response, as well as the spectrogram of the corresponding warped signal are presented in Figs. 10(a) and 10(b). These spectrograms are the same as those presented earlier, serving as a reference to visually assess the efficacy of phase compensation.
        </p>
        <p>The source signal considered here is a non-linear FM sweep of constant amplitude. The source time-frequency law s s ðf Þ is shown in Fig. 10(c) as a red curve. The spectrogram of the received signal, which combines both environmental dispersion and the source sweep, is shown in Fig. 10(c). The source s s ðf Þ effectively tilts the whole TF pattern, as was explained in Sec. II D. The spectrogram of the corresponding warped signal is unusable [Fig. 10(d)].</p>
        <p>As explained above, to perform phase compensation, we assume that the source TF law can be approximated by a piecewise linear function. In this case, we show that a single linear piece is (nearly) enough to filter the modes. To perform phase compensation, we assume that the source TF law is a linear frequency modulation that goes from 100 to 0 Hz in 0.8 s, as illustrated by the black line in Fig. 10(c). The spectrogram of the signal after phase compensation is shown in Fig. 10(e), which one can see is qualitatively similar to the spectrogram of the impulse response [Fig. 10(a)]. The spectrogram of the corresponding warped signal is shown in Fig. 10(f), which demonstrates how the modes have been really well separated, although mode 3 is less tonal than in Fig. 10(b).</p>
        <p>This result illustrates that warping is robust to uncertainty in the source signal, provided that the source signal has a relatively simple frequency-dependent phase. It can be used to separate modes when little information is available about the source, apart from the fact that it is frequency modulated. Warping is thus perfectly adapted to the study of signals like those of baleen whale vocalizations in shallow water. It has notably been applied to localize bowhead whale calls in the Arctic (Bonnel et al., 2014;Warner et al., 2016), which are frequency modulated signals with an unknown TF law (and thus an unknown phase).</p>
        <p>Section V explained how to practically apply warping in various scenarios. In this section, we assume that warping has been correctly applied and we present some examples of post-processing applications. We show how warping can be used to filter modes and/or estimate a dispersion curve. Then we illustrate how estimated dispersion curves can be used for source ranging in a waveguide.</p>
        <p>We once again consider our favorite signal simulated in the noisy Pekeris waveguide, as in Sec. V. Choosing the time origin as best as possible, we thus reproduce the scenario presented in Fig. 8(a) (although the noise realization is not identical).</p>
        <p>Because we want to illustrate the whole processing chain, we reproduce the warping steps presented earlier. The time series of the signal under study is presented in Fig. 11(a). The corresponding spectrogram is shown in Fig. 11(b). This spectrogram is not useful for modal filtering, but it will be used later to visually assess the quality of the filtering result. The received time series is then warped, and the result is shown in Fig. 11(c), along with its spectrogram in Fig. 11(d).</p>
        <p>Before going further with post-processing, it is of paramount importance to obtain the best possible spectrogram for the warped signal. This can be quantified by the separation of the warped modes: it is required to have them as horizontal-or at least as separated from each other-as possible. For real life scenarios, if the source is impulsive or if source deconvolution has been used, we advise trying several time origins (cf. Sec. V B), and choosing the iteration that gives the best spectrogram for the warped signal. A few iterations ($1-5) are usually adequate.</p>
        <p>If the source has an unknown frequency modulation, then one has another degree of freedom to estimate, which is the source TF law. Once again, we advise an iterative trial-and-error process, iterating both on source TF law and time origin, until the warped modes are separated on a spectrogram. This process, while relatively cumbersome for warping beginners, can often be performed within a few minutes by experienced users. A click-and-play routine to do so is provided in the supplementary material. 1</p>
        <p>The next step is to filter a warped mode using TF filtering. TF filtering is easily done by defining a mask in the TF domain, which is 1 in an area of interest A, and 0 elsewhere. Formally, we define Mðt</p>
        <p>The TF representation under study is then multiplied by Mðt; f Þ, which effectively isolates the content of the signal that is in A (Kozek and Hlawatsch, 1992). This is similar to basic bandpass filtering performed in the frequency domain, except that a TF region is isolated instead of a simple frequency band.</p>
        <p>For this application, TF filtering is performed on the spectrogram of the warped signal. The only trick is to define a region A that isolates a warped mode. Although automatic processing can be used, we suggest initially defining the mask manually by looking at the spectrogram; a click-andplay routine to do so is provided in the supplementary material. 1 An example of a mask for filtering mode 2 is illustrated in Fig. 11(d) as a red contour: the area within the contour is the area A. When the spectrogram of the warped signal is multiplied with this mask, the spectrogram of a single warped mode is obtained, as illustrated in Fig. 11(e).</p>
        <p>The manual definition of the mask introduces another subjective operation in the modal filtering process. However, this one is relatively benign: if warping has been correctly performed, then the modes are well separated, and the exact selection of the mask does not matter. As an example, this is the case in Fig. 11(d). As long as the chosen mask is wide enough to encompass a mode, yet small enough not to overlap with another mode, then the TF filtering should be sufficient. In real life scenarios, one may still need to iterate this operation a few times. We do advise checking the quality of modal filtering by estimating the modal dispersion curve and comparing it with the original spectrogram, as illustrated in Fig. 11(b). The process to do so is explained below.</p>
        <p>After the masking process, we have a single warped mode in the TF domain. The following steps are to invert all the previous operations, except filtering. We first go from the TF domain to the time domain by computing an inverse short-time Fourier transform. The result, illustrated in Fig. 11(f), is the time series of a single warped mode. Such a warped mode can then be unwarped using inverse warping, which leads to the time series of a single mode. This is the end result of modal filtering. The whole processing chain extracts the time series of a single mode from the original signal that combines all the modes.</p>
        <p>The filtered mode 2 is presented in Fig. 11(f), which also shows the theoretical time series, obtained by direct simulation. There is an excellent match between the filtered and theoretical mode time series and their power spectral densities (PSD), as shown in Fig. 11(g). For practical applications, this match could be quantified using a normalized mean squared error, as is traditionally done in estimation theory.</p>
        <p>The filtering result presented in Fig. 11 is not perfect: the amplitude of the filtered mode is slightly oscillating and the filtered mode peaks at a frequency different from the true one. This likely results from interference with other modes that have not been completely rejected by warping. Also, the filtered mode seems to have a cutoff frequency that is slightly too high. This is because the theoretical mode contains energy between the true cutoff and the Airy phase. This part of the mode is not modeled by warping, and thus is nearly impossible to filter. However, this part of the mode is generally highly attenuated during propagation, and typically barely visible on real data (except when very powerful sound sources are used). This is unlikely to cause trouble to users that are interested in marine mammal localization, but is a known drawback for users that are interested in geoacoustic inversion.</p>
        <p>Once modes have been filtered, the game is won. As stated in the Introduction, filtered modes can be used as input data for many applications. However, one last processing step can be performed before turning to further applications: estimation of the modal dispersion curve (the TF positions of the modes). This is trivial to do once modes are filtered, as filtered modes are simple mono-component signals. The exercise is thus to estimate the instantaneous frequency (or group delay) of a mono-component signal. Many methods are available to do so (Boashash, 2015). We suggest computing the average time (first frequency moment) of the spectrogram of the filtered mode. A simple 
            <rs type="software">MATLAB</rs>
            <rs type="software">code</rs> to do so is provided in the supplementary material. 1 Going back to the previous example, the estimated dispersion curve of mode 2 is presented in Fig. 11(i) and compared to the theoretical one. The estimation has been performed over the entire signal bandwidth, but the modal dispersion curve must be restricted to a frequency band of interest. Here, we have an excellent match over 45-80 Hz, which is the band where the mode is mostly energetic.
        </p>
        <p>Restricting the dispersion curve to a frequency band of interest can be done automatically by setting a threshold on the filtered mode PSD, or manually by assessing the frequency band where there is a good match between estimated dispersion curve and spectrogram [see Fig. 11(b)]. Since warping requires several manual operations anyway, we advise doing this manually as well. In any case, even if an application does not require dispersion curve estimation, we still advise estimating the dispersion curves and comparing them with the original spectrogram. This is an easy quality check for assessing modal filtering performance for real life applications.</p>
        <p>As a technical side note, let us look further at the errors between the estimated mode and the theoretical one. Visually, it is clear that these errors are quite small [Figs. 11(g),11(h),11(i)]. However, it is also clear that the error statistics are not trivial. In particular, the errors are correlated.</p>
        <p>As an illustration, one can look at the estimated dispersion curve on Fig. 11(i). The mode arrival time is consistently over-estimated between 60 and 70 Hz, which shows the high correlation of the error, at least in this frequency band. This must be taken into account for applications that require a proper statistical uncertainty characterization, such as Bayesian geoacoustic inversion.</p>
        <p>Also, one can see that in the frequency band where the mode is energetic, the estimated dispersion curve [Fig. 11(i)] is better estimated than the mode amplitude [Fig. 11(g)], which notably peaks at a wrong frequency. This probably explains why most successful applications of warping-and particularly environmental inversion which requires accurate environmental data-are based on estimated dispersion curves, rather than on raw filtered modes. In other words, warping is successful in recovering accurate relative timing between modes (phase), less so when extracting relative or absolute modal amplitudes.</p>
        <p>Last but not least, modal filtering has been illustrated here for mode 2. To filter several modes, the process must be iterated. Usually, there is no need to warp the original signal several times, one can simply design a new mask corresponding to another mode [cf. Fig. 11(d)]. Still, on rare occasions, it may be necessary to change time origin and restart the modal filtering process from scratch (see Sec. V B).</p>
        <p>In this section, we illustrate how the modal dispersion curve, s m ðf Þ, can be used to solve an inverse problem. Because this is not the main focus of the tutorial but a mere illustration of warping capability, we keep this illustration as simple as possible. We thus focus on source localization, and more specifically the estimation of the source/receiver range. More advanced applications are covered by the citations given in Appendix B.</p>
        <p>The concept of source localization using dispersion curves is relatively easy. On one hand, we have modal dispersion curves that have been estimated from the received signal; these will be called data. On the other hand, we have a propagation model that enables the simulation of dispersion curves; these will be called replicas. To localize the source, the idea is to iterate over many candidate source positions (as well as other environmental parameters if needed), and to quantify the degree of match between data and replicas. The position of the source is estimated by selecting the position of the simulated source that provides the best match between data and replicas.</p>
        <p>Complex propagations models can (and should) be used to compute the replicas for optimal source localization. However, this is not within the scope of this tutorial, so a simple source localization will be illustrated using the Pekeris waveguide (see Sec. II C) as an environmental model. We further assume that water depth D and water sound speed c w are well-known, which is realistic for real life applications, although c w usually depends on depth. The seabed sound speed c b is unknown, and will be estimated as part of the inversion problem. The seabed density is also unknown, but it is arbitrary fixed at q b ¼ 1600 kg/m 3 to keep the inversion simple. Last, but not least, source and receiver depths are considered unknown. However, a feature of acoustic waveguide propagation is that the source/ receiver depths do not influence the modal phase term and thus do not impact the dispersion curves, so they can thus be ignored. As a result of this logic, two parameters will be estimated as part of the inversion process: source/receiver range r and seabed sound speed c b . Estimated values are noted with an underlying hat: r and ĉb . Note that it is not expected for ĉb to be realistic. As in Collins and Kuperman (1991), the idea is to adapt the environmental model to help localization, not to perform a proper seabed geoacoustic inversion.</p>
        <p>To formalize the localization method, we denote the data as s data m ðf Þ and the replicas as s rep m ðf ; r; c b Þ. Note that replicas depend on r and c b , as those are needed to compute the simulated dispersion curves. If the source is impulsive, the match between data and replicas can be directly quantified. However, the source and receiver are generally not synchronized. There is thus the need to include an unknown time shift parameter dt within the data/replicas comparison. Formally, using a simple least square fit,</p>
        <p>If the source is not impulsive but its waveform is known, then it can be localized using Eq. ( 19) after source deconvolution. If the source is an unknown frequency modulation, one cannot use Eq. ( 19) anymore. Indeed, the replicas now depend on the unknown source modulation t s ðf Þ, as shown in Eq. ( 6). One way to go around this issue is to match dispersion curve differences instead of dispersion curves, r; ĉb</p>
        <p>with s rep m ðf ; r; c b Þ replicas that are computed as if the source were impulsive, as in Eq (19).</p>
        <p>Note that Eq. ( 20) can also be used to localize impulsive sources. Its benefit is that it removes the need to invert for dt. Its drawback is that it requires that the data contain at least two modes with a common frequency band, while Eq. ( 19) can be applied to a single mode, and/or to several modes that do not overlap in frequency.</p>
        <p>The last step for source localization is to correctly perform the minimization involved in both Eqs. ( 19) and ( 20). This can be done using advanced optimization algorithms (Bonnans et al., 2006). However, this is unnecessary here, as only 2 or 3 parameters are considered. The minimization can thus be done using a grid search. A simple 
            <rs type="software">MATLAB</rs>
            <rs type="software">code</rs> to do so is given in the supplementary material. 1 Source localization (and warping) will be illustrated on experimental examples in Sec. VII.
        </p>
        <p>This section provides three examples of warping applications for experimental signals: an impulsive right whale vocalization, a controlled tomography source with known waveform, and a frequency modulated vocalization from a bowhead whale whose TF law is not known a priori. They have been chosen to illustrate warping approaches that parallel the circumstances outlined in Sec. V.</p>
        <p>The data and 
            <rs type="software">MATLAB</rs>
            <rs type="software">code</rs> associated with these examples are provided as supplementary material. 1 Note that these examples are extracted from previous publications by the authors, and thus more detailed background information about the data and scenarios are available (Bonnel et al., 2014;Bonnel et al., 2018;Thode et al., 2017).
        </p>
        <p>We first illustrate warping on a sound that is a pure impulse: the so-called "gunshot" sound (Crance and Berchok, 2016;Parks and Tyack, 2005) emitted by a North Pacific right whale. The data example used here was recorded in 2013 in the southeastern Bering Sea federally designated right whale critical habitat by the Alaska Fisheries Science Center, Marine Mammal Laboratory (Wright, 2017). This signal has been previously studied in Thode et al. (2017). It has notably been localized using single receiver matched mode processing (joint localization/ environmental inversion): its estimated range from the hydrophone on which it was recorded is 8.7 km [Thode et al. (2017), last line of their Table I].</p>
        <p>The spectrogram of the received signal is presented in Fig. 12(a). It shows modes that are quite well separated; indeed, modes could probably be filtered and isolated by a masking process applied on the original spectrogram. This is not always the case for baleen whale signals, but the call is used here to provide an easy means for a user to check that the warping process has been applied correctly. The spectrogram of the warped signal is presented in Fig. 12(b). It is interesting to see here that the warped mode 1 is widely spread in frequency, while the warped mode 4 is higher in frequency and clearly isolated from the other modes. This is a strong indication that the experimental environment differs substantially from the isovelocity waveguide assumption used for warping. Nonetheless, modes can still be filtered, and the TF masks that are used are shown in Fig. 12(b). The corresponding estimated dispersion curves are shown in Fig. 12(a). They perfectly match the underlying spectrogram, illustrating the success of the modal filtering operation.</p>
        <p>The estimated dispersion curves are then used as an input for localizing the gunshot. As the source is assumed to be impulsive, Eq. ( 19) is used for localization. The environmental model used to compute the replicas is a Pekeris waveguide with D ¼ 51 m, c w ¼ 1450 m/s, q w ¼ 1000 kg/m 3 , and q b ¼ 1600 kg/m 3 . The other parameters required to compute the replicas (r, c b and dt) are included in the inversion. The search space is as follows: r 2 ½2; 16 km with 100 m steps, c b 2 ½1550; 2000 m/s with 10 m/s steps, and dt 2 ½À7; À5 s with 0.01 s steps. Note that if time origin has been set properly for warping, then the expected value for dt is about r=c w . One can start with wide search bounds and coarse steps for dt, and gradually narrow the bounds and decrease the steps.</p>
        <p>Localization results are illustrated in Fig. 13. Figure 13(a) shows the match between the data and predicted replicas (i.e., replicas computed using the optimal localization/ environmental parameters). The match is not perfect but looks good enough. It is unlikely that a better match can be obtained, as the experimental environment is complex, and the inversion is performed with a simplistic Pekeris waveguide. A one-dimensional slice of the least square fit is presented in Fig. 13(b). It shows a smooth global minimum, which suggests that the minimization was successful. The estimated range is r ¼ 8:8 km. It is consistent with results obtained by the detailed environmental inversion in Thode et al. (2017), illustrating that the simple procedure obtained here is enough to do as well (or as poorly) as more complex methods. Such a result is obtained because dispersion curves are highly sensitive to range, and relatively less sensitive to many environmental details, which makes dispersion curve inversions relatively robust. Before going further, note that localization results should always be checked by examining the data/replica match and the error surface. If the data/replica match is very poor or the least squares fit is not smooth, or if one of the estimated parameters is found at a boundary of the search grid, then the inversion probably performed poorly, and further investigation is required. (Knobles and Wilson, 2017). The specific signal presented here has previously been studied in Bonnel et al. (2018). Its range, known through GPS measurement, is 4.8 km.</p>
        <p>The CSS source is known to be a strong impulse, preceded by a weak precursor and followed by several bubble pulses. It was monitored at close range during the experiment, and thus a source deconvolution can be performed before warping. The time series of the received signal is shown in Fig. 14(a), and the corresponding signal is shown in Fig. 14(b). The TF modal dispersion is highly contaminated by the source waveform. However, the spectrogram of the signal obtained after source deconvolution, shown in Fig. 14(c), is much cleaner. Warping can then be applied and modes can subsequently be filtered. The spectrogram of the warped signal is shown in Fig. 14(d), and the estimated dispersion curves are superimposed in Fig. 14(c). It is very interesting to see that many modes have been estimated, and that a gap exists between the low-order modes and the highorder modes. While the first nine modes are modes 1 to 9 with little doubt, it is impossible to identify the last five high-order modes without further effort. The curious reader may read Bonnel et al. (2018) to learn that the estimated high-order modes are modes 14 to 18. This example is a perfect illustration of warping's capability to filter modes, including highly dispersive high-order modes.</p>
        <p>The estimated dispersion curves are then used as an input for localizing the CSS signal. However, inversion is restricted to the first four modes and to the frequency band 100-300 Hz. Because mode 1 is not estimated in this frequency band, it is effectively excluded from the localization. As source deconvolution has been performed, Eq. ( 19) is used for localization. The environmental model used to compute the replicas is a Pekeris waveguide with D ¼ 69.5 m, c w ¼ 1464:5 m/s, q w ¼ 1000 kg/m 3 , and q b ¼ 1600 kg/m 3 . Other parameters are included in the inversion. The search space is as follows: r 2 ½3; 6 km with 100 m steps, c b 2 ½1470; 2000 m/s with 10 m/s steps, and dt 2 ½À4; À2 s with 0.01 s steps.</p>
        <p>Localization results are illustrated in Fig. 15. Figure 15(a) shows the match between the data and predicted replicas, and Fig. 15(b) shows a slice of the least square fit. Both are good, suggesting that the localization scheme is successful. The estimated range, r ¼ 4:6 km is fully consistent with the GPS ground truth.</p>
        <p>Interestingly, the data/replica match is nearly perfect [Fig. 15(a)]. This is because in the considered frequency band and for the considered modes, the experimental environment can be well-approximated with a Pekeris waveguide. Actually, the experimental environment is more complicated than that (Bonnel et al., 2019), and such a match would have been impossible over a broader frequency band, and/or for a greater number of modes. Localizing the source using all the modes would have required the use of an environmental model much more complex than the Pekeris one.</p>
        <p>The third and final example in this tutorial is a bowhead whale upsweep recorded off Deadhorse (Alaska) by Scripps Institution of Oceanography in August 2010 (Thode et al., 2012). The specific signal presented here has previously been studied in Bonnel et al. (2014). Its estimated range, measured with a distributed array of vector sensors, is 14.1 6 1.8 km (Bonnel et al., 2014, call 7 in their Table I).</p>
        <p>The signals emitted by bowhead whales are not stereotyped, and thus the exact TF structure of the original call is unknown. It is thus impossible to do source deconvolution. As an alternative, phase compensation (Sec. V D) must be used before warping.</p>
        <p>The spectrogram of the received signal is presented in Fig. 16(a). The source TF law is estimated with three linear pieces. As explained in Sec. V D, an easy way to do so is to roughly follow the TF contour of mode 1. The chosen contour is plotted as a black curve in Fig. 16(a). Phase compensation is then performed, and the resulting spectrogram is plotted in Fig. 16(b). The result is definitely not perfect, but good enough to perform warping. The warped spectrogram is presented in Fig. 16(c). The TF masks that are used to filter the modes are also shown as red polygons. The corresponding estimated The next step is source localization. Because the exact TF law of the source is unknown, Eq. ( 20) is used. The raw dispersion curves of modes 1, 2, and 3 are combined to form dispersion curve differences between modes 2-1 and modes 3-2. The corresponding data are shown on Fig. 17 Localization results are illustrated in Fig. 17. Figure 17(a) shows the match between the data and predicted replicas, and Fig. 17(b) shows a slice of the least square fit. The estimated range, r ¼ 16:4 km, is fully consistent with the independent estimates obtained with a distributed array of vector sensors.</p>
        <p>Interestingly, the data/replica match is far from perfect [Fig. 17(a)]. One dispersion curve difference is underestimated, while the other is overestimated. However, the overall behavior of the least square fit is still smooth, which suggests that the two errors are compensating to provide a decent localization result. The misfit between data and predicted replica is due to the experimental environment, which has a range-dependent bathymetry. It is thus largely different from the Pekeris waveguide used for inversion. Nonetheless, dispersion curves are so sensitive to range that the localization result is correct.</p>
        <p>This tutorial has reviewed both theoretical and practical uses of warping to study low-frequency transient sounds in shallow water. Warping can be used to filter modes from a single receiver, an operation that had traditionally been performed with dense vertical line arrays. This reduction in hardware requirements has opened the door for applying sophisticated acoustical techniques to single-hydrophone data sets, including marine mammal localization or geoacoustic inversion. The tutorial covered in detail modal filtering using warping, and presented a simple source localization algorithm as a direct application of warping.</p>
        <p>An important point of warping is that it requires a model of the sound propagation. In this tutorial, we have presented a warping operator based on an ideal isovelocity waveguide. Such a model has been widely used in the literature, and is known to enable modal filtering in various reallife scenarios. Its main advantages are that it is simple but robust, and allows warping all the modes with a single transform. While this simple transform works well in most shallow-water environments, we have noted that isovelocity warping may not work in environments dominated by strong reflection (e.g., a sharp thermocline), or situations where modal arrivals actually cross in the time-frequency domain.</p>
        <p>However, warping operators can also be based on more complex models. This has been explored in the literature. Proposed models include the beam-displacement-ray-mode theory (Niu et al., 2014a,b), an approximated Pekeris waveguide (Le Touz e et al., 2009), or a waveguide invariant approximation (Bonnel et al., 2013b;Qi et al., 2015). Although these new warping operators are interesting in theory, they have not been used extensively for concrete applications. As far as we know, no study has compared their respective performance in terms of modal filtering. The potential gain brought by these more complex operators remains an open question. Nonetheless, the waveguide invariant approach is particularly promising for studying signals in strongly refracting environments, i.e., with a negative waveguide invariant. This is yet to be demonstrated on experimental data.</p>
        <p>Interestingly, these new warping operators still warp all the modes at once. This is a feature which makes them promising candidates for advanced modal filtering. On the other hand, these operators are unable to handle specific dispersion features, such as modes crossing in the TF domain. Such a behavior may be due to a strong Airy phase, and/or to a given mode being ducted in either the water column or the seabed. A specific warping operator, based on a numerical approximation of the dispersion curves, has been proposed to handle these situations (Bonnel et al., 2017). It improves filtering performance for mode 1, but not for the other modes. Filtering modes that cross in the TF domain remains an open question. This will need to be solved for shallow water environments when the sound speed profile has a gradient strong enough to fully trap low order modes. Such a situation is classical in the Arctic during summer but also happens at lower latitudes under specific oceanographic conditions. Spectrograms of experimental data with this specific features can be found in (Michalopoulou and Pole, 2016) or (Roth et al., 2012). Last but not least, this tutorial is based on the underlying assumption that the signal under study is a transient signal (such as an impulse or a frequency-modulated sweep) recorded on a single hydrophone. If the signal is not transient, such as broadband noise by a ship, then the method cannot be applied. In this case, a solution may be to work with the autocorrelation of the signal. Indeed, warping the autocorrelation of the signal has been proposed in Qi et al. (2015) and Zhou et al. (2014). The method seems very promising but, as far as we know, it has never been applied on broadband noise signals. Here again, there is the need for an experimental study. If the method is successful, it will open a new research avenue. Potential applications include ship localization, and/or tomography using sources of opportunity.</p>
        <p>Overall, the single receiver capacity offered by warping opens the door to new experimental designs with singlehydrophone units that can be spread over an area of interest, forming a wide, non-synchronized, distributed array. In this configuration, warping may be used on each singlehydrophone unit independently, removing the need of coherent processing (and thus time synchronization) along the array. Interestingly, single hydrophone units are also easy to integrate into cheap robotic platforms. Because warping removes the need for time synchronization between sensors, robots may be used as a swarm to form a large array. However, no bulk automated algorithm yet exists for warping, and thus manual trial and error is a required procedure at present in order to obtain the best modal extractions. The automation issue will need to be solved before warping can be automatically applied on robotic platforms. Nonetheless, warping allows revisiting existing long-term datasets, and may open possibilities for localization/environmental information in situations that were previously not envisioned when the data were initially collected. This appendix quickly reviews the difference between time and frequency warping. The starting point of dispersion-based warping is the need for a model of the modal phase. Because modal propagation is conveniently defined in the frequency domain through Eq. ( 2), we usually have a frequency domain model for the phase / m ðf Þ. As a result, it is natural to consider frequency warping, with warping function / À1 m ðf Þ. However, the definition of modal travel time through group speed is a stationary phase approximation. The same approximation can also be used to obtain a time domain expression for the modal phase, / m ðtÞ.</p>
        <p>As a result, time warping also becomes a viable alternative, with warping function / À1 m ðtÞ. Note that warping that operates in the time domain is usually dubbed "time warping," although its results are conveniently displayed in the frequency domain. On the other hand, warping that operates in the frequency domain is usually dubbed "frequency warping," although its results are conveniently displayed in the time domain. In this tutorial, we consider time warping. By warping the time axis, we modify the frequency content of modes, and thus obtain a result that is conveniently described in the frequency domain.</p>
        <p>Nonetheless, the use of time warping versus frequency warping in a given context can still be questioned. As an example, Fig. 18 illustrates the time and frequency warping principles for three different signals. Time and/or frequency warping can be chosen, depending on the signal's TF distribution (i.e., dispersion curve). If, at any given instant, only one frequency exists, then the signal can be studied with time-warping (e.g., signal 1 in Fig. 18), and the TF shape of the warped signal becomes that of a continuous tone. On the other hand, if any given frequency corresponds with just a single time, then the signal can be studied with frequency-warping (e.g., signal 3 in Fig. 18), and the TF shape of the warped signal becomes an impulse. Last but not least, if the dispersion curve is bijective, then the signal can be studied with either time or frequency warping (e.g., signal 2 in Fig. 18).</p>
        <p>In an underwater acoustics context, if one ignores 3D propagation effects, then the time of arrival of each mode at a given frequency is uniquely defined (as for signals 2 and 3 in Fig. 18). As a result, frequency warping can always be defined. If a closed-form expression for the modal phase / m ðf Þ is not available, then one can resort to a numerical approximation, as obtained with a modal propagation code. This has been illustrated in Bonnel et al. (2017).</p>
        <p>On the other hand, time warping can only be applied for simple propagation models where the frequency of a mode is uniquely defined for a given time (as for signals 1 and 2 in Fig. 18). As a counter example, this condition is violated in non-ideal waveguides because of the Airy phase behavior: at a given instant, a mode can be excited at two distinct frequencies (as signal 3 in Fig. 18).</p>
        <p>Simple propagation models exist for which both time warping and frequency warping can be defined. The isovelocity model considered in this tutorial is such a model. Both time warping and frequency warping are presented in Bonnel et al. (2010). Interestingly, time warping and frequency warping defined using this model have very different properties. As shown in this paper, time warping allows warping all the modes at once. One the other hand, frequency warping must be performed mode by mode (Bonnel et al., 2010). This particular behavior does not seem particularly intuitive. It illustrates the importance of studying both time and frequency warping, because despite their analogous behavior, they may have fundamentally different properties.</p>
        <p>The central objective of separating modes with a single receiver with TF analysis is not new. A key notion here is the modal TF dispersion. This simply refers to the frequency-dependent time of arrival of the modes, which sometimes can be visualized on a simple spectrogram. Modal TF dispersion was first studied in the 1960s to understand the propagation of explosive sounds in shallow water (Barakos, 1962;Ewing et al., 1959). An interesting phenomenon-which is explained in Sec. II B-is that the modal separation naturally increases with range. As a result, at large ranges, modal arrivals become naturally separated in time, and a simple spectrogram is enough to visualize their TF dispersion. This theory was used for pioneering studies in the 1960s (Barakos, 1962;Ewing et al., 1959). In the 1980s, fundamental studies by Zhou et al. showed how the modal dispersion, as seen at long range in the time domain, could be used to infer seabed properties (Zhou, 1985;Zhou et al., 1987). Since then, with the advance of numerical signal processing and of TF analysis, the techniques have advanced further. Modal TF dispersion has notably been used for geoacoustic inversion (Potty et al., 2000;Potty et al., 2004;Rajan and Becker, 2010) and for ranging marine mammals (Abadi et al., 2014;Munger et al., 2011;Wiggins et al., 2004). However, these studies have been performed on sources at relatively distant ranges, so that modes were clearly time-separated on a conventional spectrogram. At shorter ranges, the modal arrivals blend together in time, requiring further signal processing development to extract modal information.</p>
        <p>In a sense, the topic at hand is similar to the single channel source separation problem in signal processing. A single hydrophone (i.e., channel) is available, and the received modes can be seen as different sound sources that need to be separated. For speech processing, single channel source separation is usually solved by training statistical models on existing data [e.g., Grais et al. (2014), Jang andLee (2003), andOzerov et al. (2007)]. Unfortunately, existing data with reliable labels are very sparse in ocean acoustics, notably because environmental impact and noise degradation both impede reproducibility. As a result, alternative methods must be found.</p>
        <p>Another option is to use more complex TF methods [e.g., Taroudakis and Tzagkarakis (2004)], and/or to postprocessed traditional spectrograms with further signal processing methods [e.g., Michalopoulou and Pole (2016)]. Of particular interest here, theoretical advances in TF analysis for signals with dispersive group delays (Papandreou-Suppappola et al., 2001) have led to the development of TF methods specifically adapted for modal propagation (Bonnel et al., 2013b;Chen et al., 2003;Hong et al., 2005;Le Touz e et al., 2009). Unfortunately, these methods have found very limited applications, one interesting exception being a geoacoustic inversion study by Potty et al. (2008). We believe FIG. 18. (Color online) Comparison between time-warping and frequency-warping. Signal 1 must be warped using time-warping. Signal 3 must be warped using frequency-warping. Signal 2 can be warped using either time-warping or frequency-warping. The figure is from Bonnel et al. (2017).</p>
        <p>this is because the advanced TF literature is cryptic for nonspecialists, and in turn enigmatic for the end-users who may need it.</p>
        <p>Another option to analyze modal propagation at short range is to use classical TF analysis, but to transform the signal beforehand. This is particularly useful when using invertible transforms, so that one can filter the modes in the transformed space, and then go back to the original space. This idea is similar to classical bandpass filtering in the frequency domain, except that we are now considering transforms that are more complex than the Fourier transform.</p>
        <p>Warping, the topic of this tutorial, is an example of advanced domain transform (Baraniuk and Jones, 1995). When combined with a physical model of the propagation, warping can be used to estimate modal dispersion (Bonnel et al., 2010) but also to filter modes, and thus to recover separated modal time series (Bonnel et al., 2017). 3</p>
        <p>The theoretical use of warping to filter modes (Le Touz e et al., 2009) and localize an impulsive sound source with a single receiver (Le Touz e et al., 2008) was first introduced by Le Touz e et al. The first warping applications for marine mammal localization (Bonnel et al., 2008) and geoacoustic inversion (Bonnel and Chapman, 2011) have been proposed by Bonnel et al. Since then, warping has been adopted in the underwater acoustic community, and has been used for various applications.</p>
        <p>Warping has notably been used for environmental estimation studies, mostly seabed geoacoustic inversion (Bonnel et al., 2013a;Bonnel et al., 2019;Bonnel et al., 2012;Dong et al., 2017;Duan et al., 2016;Feng-Hua et al., 2014;Petrov, 2014;Zeng et al., 2013), but also water column tomography (Ballard et al., 2014), as well as joint estimation of water column and seabed properties (Warner et al., 2015). On a more basic research point of view, it is interesting to note that warping has also been used to estimate modal depth functions (Bonnel et al., 2011;Thode and Bonnel, 2015), as well as to filter modes from noise interferometry data (Sergeev et al., 2017;Tan et al., 2018).</p>
        <p>Moreover, warping has been used for source localization in shallow water (Le Touz e et al., 2008;Qi et al., 2015;Zhou et al., 2014), and the performance of such source localization methods have been theoretically derived (Le Gall et al., 2017). The warping based localization methods have found application in bioacoustics. In particular, warping has been used to range baleen whales with a single sensor (Bonnel et al., 2014;Crance et al., 2015) and/or to estimate their calling depth (Thode et al., 2017). In the context where several non-synchronized hydrophones were available, warping has been used to estimate the latitude/ longitude position of marine mammals (Bonnel et al., 2008;Warner et al., 2016).</p>
        <p>A final application of warping is its utility as an alternative to source deconvolution to cancel the bubble pulse of a nearly impulsive source (Niu et al., 2013). It has also been applied on vertical line array data to estimate the array tilt (Thode and Bonnel, 2015;Lu et al., 2017). Although this tutorial focuses on underwater acoustics applications, it is interesting to note that warping has been applied in many other fields. It has notably been used to study ultrasonic Lamb waves (De Marchi et al., 2009;De Marchi et al., 2010;Xu et al., 2012;Xu et al., 2014) with a procedure that is very similar to the one presented here: propagation models are used to predict dispersion curves, which are later used to define warping operators. Warping is also heavily used for speech processing (Aikawa, 1991;Benzeghiba et al., 2007;Zhan and Westphal, 1997). Before performing warping on sampled data using a computer, the first practical step is correctly identifying the time domain and the frequency domain of the original signal y(t) and of the warped signal y w ðtÞ. This subsection largely reproduces a discussion that can be found in French in (Le Touz e, 2007).</p>
        <p>Let us consider a signal y(t). We further assume that the time domain of y is D t ¼ ½t min ; t max , and that its frequency domain is D f ¼ ½f min ; f max . Also, recall that warping is implemented as if the environment were an ideal waveguide, so that the signal is described by Eqs. ( 8) and ( 9). As a result, t min &gt; t r . For convenience, we now time-shift the time axis so that t min ¼ ½t r þ . In other words, we have D t ¼t r ; t max .</p>
        <p>As a next step, we will define the domains of the warped signal, y w ðtÞ. First, let us denote T the original time axis, and T the warped time axis. Because of the warping definition, Eq. ( 7), any time t in T corresponds to hð tÞ in T . Conversely, any time t in T corresponds to h À1 ðtÞ in T . Noting that h À1 ðtÞ is a monotonically increasing function, one finds that s w ðtÞ has a finite time domain</p>
        <p>The next step is to assess the frequency domain of the warped signal: D h f ¼ ½f h min ; f h max . To do so, one uses Eq. ( 12) which states that modes are warped onto their cutoff frequencies f c;m . As a result, f h min and f h max respectively correspond to the cutoff frequencies of the minimal mode number (m min ) and maximal mode number (m max ) of the original signal: f h min ¼ f c;m min and f h max ¼ f c;m max . Although they fully define the frequency domain of the warped signal, these formulas are not convenient from a signal processing point of view. They notably contain environmental features (e.g., D, through f c;m ) which are irrelevant here, as the warping function does not use them. In the following, we seek formulas for f h min and f h max that are based on signal/warping features (e.g., t max , f max ) rather than on environmental features (f c;m ).</p>
        <p>To do so, the first step is to obtain the modal dispersion curve from Eq. ( 9) by computing the mode instantaneous frequency m iso ðtÞ ¼ 1 2p @/ m iso ðtÞ @f ¼ ð2m À 1Þc w 4D t ffiffiffiffiffiffiffiffiffiffiffiffi ffi t 2 À t 2 r p : (C2)</p>
        <p>Then, Eqs. (C2) and ( 11) are combined to define a timefrequency dependent (non-integer) mode number</p>
        <p>Because m(t, f) is increasing with t and f, one finds that</p>
        <p>and</p>
        <p>Recalling that f h max ¼ f c;m max , one can define f h max using only the maximal time and maximal frequency of the original signal</p>
        <p>Similarly, one can show that f h min ¼ 0. This leads to the final definition of the frequency domain of the warped signal</p>
        <p>Equations ( C1) and (C7) fully define the time and frequency domain of the warped signal, using time and frequency features from the original signal. Because both time domain and frequency domain are finite, we can now proceed with questions related to sampling.</p>
        <p>Let us consider y½n, the discrete version of the original signal y(t). We assume it is sampled at frequency f s and has N samples. We thus have y½n ¼ yðt n Þ with t n ¼ t min þ n=f s and n 2 ½½0; N À 1.</p>
        <p>As explained in Appendix C 1, warping moves the sample at location t n in T to a new location t n ¼ h À1 ðt n Þ in T . Because h À1 is non-linear, sampling in the warped domain is irregular. The warped signal must thus be interpolated on a regular time grid. This raises the question of the minimal sampling frequency for the warped signal.</p>
        <p>If the original signal has been correctly sampled, its sampling frequency is f s &gt; 2f max . As a result, Eq. (C6) becomes f h max &lt; ½h À1 ðt max Þ=t max ðf s =2Þ, and thus the sampling frequency of the warped signal</p>
        <p>Interestingly, one can obtain this result using some intuitive thought. The time derivative ½h À1 0 ðtÞ ¼ t= ffiffiffiffiffiffiffiffiffiffiffiffi ffi t 2 À t 2 r p is decreasing and positive. As a result, the spacing of the irregular time grid in T decreases as t increases. In other words, Dt n ¼ t n À t nÀ1 decreases as n increases. The smallest spacing is thus Dt N ¼ h À1 ðt N Þ À h À1 ðt NÀ1 Þ, and it is tempting to naively use it as a regular sampling step for the warped signal.</p>
        <p>In fact,</p>
        <p>with Dt ¼ 1=f s the regular sampling period in T . Because ½h À1 0 ðt max Þ ¼ t max =h À1 ðt max Þ, then</p>
        <p>This happens to be the minimal bound of Eq. (C8), and thus Dt N can be used as a regular sampling step in the warped domain. In practice, if computation time is not an issue, one may use f h s ¼ 2=Dt N for a better visual representation of the warped signal.</p>
        <p>The number of samples K of the warped signal is obtained from its time domain D h t and sampling frequency f h s :</p>
        <p>with ceil(x) the nearest integer greater than or equal to x.</p>
        <p>As stated in Appendix C 1, one usually chooses t min ¼ ½t r þ . As a result h À1 ðt min Þ ¼ 0, and thus K ¼ ceilðh À1 ðt max Þf h s Þ.</p>
        <p>The discrete version of the warped signal y w ½k is thus sampled at frequency f h s with K samples, with t k ¼ k=f h s ; k 2 ½½0; K À 1.</p>
        <p>Remembering the discussion in Appendix C 1, any time t in T corresponds to hð tÞ in T . The value of the warped signal y w ½m is thus given by the value of the original signal at time hðk=f h s Þ. Because it is unlikely that a sample exists for the original signal at t ¼ hðk=f h s Þ, the value at this specific time is obtained by interpolation. Although linear interpolation has been used in the past and gives satisfactory results, it sometimes creates high frequency artifacts in the warped signal (Arisdakessian, 2014). Therefore, we advise using the Whittaker-Shannon interpolation (Abdul, 1977) As a last step, one must compute the multiplicative factor jh 0 ðtÞj 1=2 to conserve energy. It comes directly from Eq. (10) and compensates for the time axis stretching/compression. Because h 0 ðtÞ ¼ t=hðtÞ, this factor is given as ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi jh 0 ½k=f h s j</p>
        <p>for the kth sample of the warped signal.</p>
        <p>As a summary, the kth sample of the warped signal is</p>
        <p>, and the quantity y½hðt k Þ is obtained from the original discrete signal y through interpolation.</p>
        <p>Inverse warping can be seen as forward warping using h À1 ðtÞ as the warping function. However, for practical applications, one deals with an original sampled signal (N samples, sampling frequency f s ), warps it (K samples, sampling frequency f h s ), and then unwarps it. As a result, inverse warping does not require estimation of numbers of samples and sampling frequency. These are known a priori: they are identical to the properties of the original signal (N samples, sampling frequency f s ).</p>
        <p>The only steps that need consideration when unwarping a signal are proper interpolation and energy conservation. Let y w denote the warped signal and y u the unwarped signal, recovered from y w using inverse warping. The nth sample of the unwarped signal simply becomes [via Eq. (C13)]</p>
        <p>, and the quantity y w ½h À1 ðt n Þ obtained via interpolation of the warped discrete signal y w .</p>
        <p>d. Energy conservation</p>
        <p>J. Acoust. Soc. Am. 147 (3), March 2020 Bonnel et al.</p>
        <p>J. Acoust. Soc. Am. 147 (3), March 2020Bonnel et al.</p>
        <p>https://doi.org/10.1121/10.0000937</p>
        <p>J. Acoust. Soc. Am. 147 (3), March 2020 Bonnel et al. https://doi.org/10.1121/10.0000937</p>
        <p>J. Acoust. Soc. Am. 147 (3), March 2020</p>
        <p>See supplementary material at https://doi.org/10.1121/10.0000937 for the 
            <rs type="software">MATLAB</rs> toolbox associated with this tutorial.
        </p>
        <p>The code provided here has actually been extracted from a free online toolbox(Auger et al., 1996), and slightly modified so that it can run as a standalone 
            <rs type="software">MATLAB</rs>
            <rs type="software">routine</rs>
        </p>
        <p>Note that warping is actually a preliminary step to compute some of the adapted TF representations that have been cited earlier(Bonnel et al., 2013b;Le Touz e et al., 2009;Papandreou-Suppappola et al., 2001).</p>
        <p>This work was supported by the Office of Naval Research (Task Force Ocean, project N00014-19-1-2627) and by the North Pacific Research Board (project 1810). Original warping developments were supported by the French Delegation Generale de l'Armement.</p>
    </text>
</tei>
