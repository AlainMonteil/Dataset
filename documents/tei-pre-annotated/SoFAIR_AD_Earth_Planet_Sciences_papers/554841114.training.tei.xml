<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-13T16:08+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>Multi-Scale Diff-changed Feature Fusion Network for Hyperspectral Image Change Detection Fulin Luo, Senior Member, IEEE, Tianyuan Zhou, Jiamin Liu, Tan Guo, Member, IEEE, Xiuwen Gong, and Jinchang Ren, Senior Member, IEEE, Abstract-For hyperspectral images (HSI) change detection (CD), multi-scale features are usually used to construct the detection models. However, the existing studies only consider the multi-scale features containing changed and unchanged components, which is difficult to represent the subtle changes between bi-temporal HSIs in each scale. To address this problem, we propose a multi-scale diff-changed feature fusion network (MSDFFN) for HSI CD, which improves the ability of feature representation by learning the refined change components between bi-temporal HSIs under different scales. In this network, a temporal feature encoder-decoder sub-network, which combines a reduced inception module and a cross-layer attention module to highlight the significant features, is designed to extract the temporal features of HSIs. A bidirectional diff-changed feature representation module is proposed to learn the fine changed features of bi-temporal HSIs at various scales to enhance the discriminative performance of the subtle change. A multiscale attention fusion module is developed to adaptively fuse the changed features of various scales. The proposed method can not only discover the subtle change of bi-temporal HSIs but also improve the discriminating power for HSI CD. Experimental results on three HSI datasets show that MSDFFN outperforms a few state-of-the-art methods.Multi-Scale Diff-changed Feature Fusion Network for Hyperspectral Image Change Detection Fulin Luo, Senior Member, IEEE, Tianyuan Zhou, Jiamin Liu, Tan Guo, Member, IEEE, Xiuwen Gong, and Jinchang Ren, Senior Member, IEEE, Abstract-For hyperspectral images (HSI) change detection (CD), multi-scale features are usually used to construct the detection models. However, the existing studies only consider the multi-scale features containing changed and unchanged components, which is difficult to represent the subtle changes between bi-temporal HSIs in each scale. To address this problem, we propose a multi-scale diff-changed feature fusion network (MSDFFN) for HSI CD, which improves the ability of feature representation by learning the refined change components between bi-temporal HSIs under different scales. In this network, a temporal feature encoder-decoder sub-network, which combines a reduced inception module and a cross-layer attention module to highlight the significant features, is designed to extract the temporal features of HSIs. A bidirectional diff-changed feature representation module is proposed to learn the fine changed features of bi-temporal HSIs at various scales to enhance the discriminative performance of the subtle change. A multiscale attention fusion module is developed to adaptively fuse the changed features of various scales. The proposed method can not only discover the subtle change of bi-temporal HSIs but also improve the discriminating power for HSI CD. Experimental results on three HSI datasets show that MSDFFN outperforms a few state-of-the-art methods.</p>
        <p>Index Terms-Hyperspectral image, change detection, convolutional encoder-decoder network, multi-scale features, attention fusion.Index Terms-Hyperspectral image, change detection, convolutional encoder-decoder network, multi-scale features, attention fusion.</p>
        <p>C HANGE detection (CD) based on remote sensing data is an important technology to detect the changes of the earth's surface and has a wide range of applications in urban planning, environmental monitoring, agriculture investigation, disaster assessment, and map revision [1,2]. Remote sensing CD is to detect the land-cover changes of images at the same area under two different time periods. It is the response Tianyuan Zhou and Jiamin Liu are with the Key Laboratory of Optoelectronic Technology and Systems of the Education Ministry of China, Chongqing University, Chongqing 400044, China (e-mail: zhoutianyuan1016@163.com, liujm@cqu.edu.cn).C HANGE detection (CD) based on remote sensing data is an important technology to detect the changes of the earth's surface and has a wide range of applications in urban planning, environmental monitoring, agriculture investigation, disaster assessment, and map revision [1,2]. Remote sensing CD is to detect the land-cover changes of images at the same area under two different time periods. It is the response Tianyuan Zhou and Jiamin Liu are with the Key Laboratory of Optoelectronic Technology and Systems of the Education Ministry of China, Chongqing University, Chongqing 400044, China (e-mail: zhoutianyuan1016@163.com, liujm@cqu.edu.cn).</p>
        <p>Tan Guo is with the School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing 400065, China (e-mail: guot@cqupt.edu.cn).Tan Guo is with the School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing 400065, China (e-mail: guot@cqupt.edu.cn).</p>
        <p>Xiuwen Gong is with the Faculty of Engineering, The University of Sydney, NSW 2006, Australia (e-mail: xiuwen.gong@sydney.edu.au).Xiuwen Gong is with the Faculty of Engineering, The University of Sydney, NSW 2006, Australia (e-mail: xiuwen.gong@sydney.edu.au).</p>
        <p>Jinchang Ren is with the National Subsea Centre, Robert Gordon University, Aberdeen AB10 7AQ, U.K. (e-mail: jinchang.ren@ieee.org).Jinchang Ren is with the National Subsea Centre, Robert Gordon University, Aberdeen AB10 7AQ, U.K. (e-mail: jinchang.ren@ieee.org).</p>
        <p>of pixel-wise characteristic change to land-cover changes. With the advancement of imaging spectroscopy, bi-temporal hyperspectral images (HSIs) have been widely used for CD [3]. HSI data have the advantage of providing continuous and detailed spectral features in a large spectral range, with the characteristics of "image-spectrum merging" [4]. This characteristic is beneficial to discriminate the changed regions between two images [5]. Recently, researchers have come up with many methods to extract useful features for HSI CD [6].of pixel-wise characteristic change to land-cover changes. With the advancement of imaging spectroscopy, bi-temporal hyperspectral images (HSIs) have been widely used for CD [3]. HSI data have the advantage of providing continuous and detailed spectral features in a large spectral range, with the characteristics of "image-spectrum merging" [4]. This characteristic is beneficial to discriminate the changed regions between two images [5]. Recently, researchers have come up with many methods to extract useful features for HSI CD [6].</p>
        <p>In early research, the CD methods can be categorized as algebra-based methods, transformation-based methods and classification-based methods. Algebra-based methods mainly include image difference, image ratio, image regression, absolute distance (AD), and change vector analysis (CVA) [7,8], etc. The most representative CVA is the subtraction of two temporal images to get spectral change vectors, where the magnitude and direction of change vectors show the degree of variation, and then the change vectors can be classified by a threshold. CVA ignores the similarity between adjacent pixels, after that, Thonfeld et al. [9] proposed robust change vector analysis (RCVA) which considers the influence of neighborhood pixels. The accuracy of the radiation and geometric correction has an important impact on the results of algebra-based methods. Transformation-based methods project HSIs into another feature space to represent the changed pixels or regions. Among them, principal component analysis (PCA) [10] is the most widely used data dimensionality reduction algorithm which maps data to the direction with the largest variance [11]. PCAKM [12] uses PCA to generate lowdimensional features and perform k-means clustering on the reduced features to obtain change results. Multivariate change detection (MAD) [13] utilizes canonical correlation analysis (CCA) [14] to maximize the correlation between the features of multi-temporal images. Nielsen et al. [15] proposed an iteratively reweighted MAD (IRMAD) method which conducts the weighted iteration according to chi-square distance. Slow feature analysis (SFA) [16] extracts the most temporally invariant component from the bi-temporal images to transform the data into a new feature space. In the classificationbased methods, the post classification method first learns and classifies the bi-temporary images respectively, and then compares and analyzes the changes. The direct classification method is to combine the bi-temporal images together, and then a classifier is used to find the changing categories. The typical classifiers are K-nearest neighbors (KNN) [17], support vector machine (SVM) [18], etc. Conventional CD methods are often based on the spectral difference between corresponding bands to measure the degree of change. They do not take into account the correlation between bands, and can not fully exploit the intrinsic characteristics of complex HSIs.In early research, the CD methods can be categorized as algebra-based methods, transformation-based methods and classification-based methods. Algebra-based methods mainly include image difference, image ratio, image regression, absolute distance (AD), and change vector analysis (CVA) [7,8], etc. The most representative CVA is the subtraction of two temporal images to get spectral change vectors, where the magnitude and direction of change vectors show the degree of variation, and then the change vectors can be classified by a threshold. CVA ignores the similarity between adjacent pixels, after that, Thonfeld et al. [9] proposed robust change vector analysis (RCVA) which considers the influence of neighborhood pixels. The accuracy of the radiation and geometric correction has an important impact on the results of algebra-based methods. Transformation-based methods project HSIs into another feature space to represent the changed pixels or regions. Among them, principal component analysis (PCA) [10] is the most widely used data dimensionality reduction algorithm which maps data to the direction with the largest variance [11]. PCAKM [12] uses PCA to generate lowdimensional features and perform k-means clustering on the reduced features to obtain change results. Multivariate change detection (MAD) [13] utilizes canonical correlation analysis (CCA) [14] to maximize the correlation between the features of multi-temporal images. Nielsen et al. [15] proposed an iteratively reweighted MAD (IRMAD) method which conducts the weighted iteration according to chi-square distance. Slow feature analysis (SFA) [16] extracts the most temporally invariant component from the bi-temporal images to transform the data into a new feature space. In the classificationbased methods, the post classification method first learns and classifies the bi-temporary images respectively, and then compares and analyzes the changes. The direct classification method is to combine the bi-temporal images together, and then a classifier is used to find the changing categories. The typical classifiers are K-nearest neighbors (KNN) [17], support vector machine (SVM) [18], etc. Conventional CD methods are often based on the spectral difference between corresponding bands to measure the degree of change. They do not take into account the correlation between bands, and can not fully exploit the intrinsic characteristics of complex HSIs.</p>
        <p>Recently years, convolutional neural network (CNN) has become a research focus in CD [19] because of its stronger adaptive feature extraction ability. For example, Saha et al. [20] proposed a context-based deep CVA (DCVA), it performs semantic segmentation on a single image with the same pretrained CNN to obtain a coherent depth feature supervector. Du et al. [21] uses SFA to learn slowly changing features and enhances the discrimination of changed pixels. These methods utilize CNN to automatically extract abstract features, and then process features by traditional methods. There are also many methods that use CNN directly to find change pixels [22]. Considering the characteristics of HSIs, Wang et al. [23] proposed a general end-to-end 2D CNN (GETNET), which performs spectral unmixing on the input HSIs to obtain a mixed affinity matrix, then uses CNN to mine the feature information. Lin et al. [24] proposed a bilinear CNN (BCNN), and it finds the relationship between bi-temporal feature maps by designing a combined bilinear feature. Mou et al. [25] and Chen et al. [26] proposed two networks named ReCNN and SiamCRNN, they use recurrent neural network (RNN) and long-short term memory (LSTM) [27] to find the spatio-temporal relationship of bi-temporal HSIs, respectively. Among them, RNN is able to extract temporal features based on the cyclic hidden state of the previous time. And LSTM, as a special RNN structure, can effectively overcome the problem of gradient disappearance and gradient explosion during training. The accuracy of these networks has improved compared to traditional methods, but they still lack sufficient consideration of rich spectral data and attention to important information.Recently years, convolutional neural network (CNN) has become a research focus in CD [19] because of its stronger adaptive feature extraction ability. For example, Saha et al. [20] proposed a context-based deep CVA (DCVA), it performs semantic segmentation on a single image with the same pretrained CNN to obtain a coherent depth feature supervector. Du et al. [21] uses SFA to learn slowly changing features and enhances the discrimination of changed pixels. These methods utilize CNN to automatically extract abstract features, and then process features by traditional methods. There are also many methods that use CNN directly to find change pixels [22]. Considering the characteristics of HSIs, Wang et al. [23] proposed a general end-to-end 2D CNN (GETNET), which performs spectral unmixing on the input HSIs to obtain a mixed affinity matrix, then uses CNN to mine the feature information. Lin et al. [24] proposed a bilinear CNN (BCNN), and it finds the relationship between bi-temporal feature maps by designing a combined bilinear feature. Mou et al. [25] and Chen et al. [26] proposed two networks named ReCNN and SiamCRNN, they use recurrent neural network (RNN) and long-short term memory (LSTM) [27] to find the spatio-temporal relationship of bi-temporal HSIs, respectively. Among them, RNN is able to extract temporal features based on the cyclic hidden state of the previous time. And LSTM, as a special RNN structure, can effectively overcome the problem of gradient disappearance and gradient explosion during training. The accuracy of these networks has improved compared to traditional methods, but they still lack sufficient consideration of rich spectral data and attention to important information.</p>
        <p>Attention mechanism is proposed to focus on key information, and is widely used in the field of deep learning [28]. It is essentially a mechanism which learns a set of weighting coefficients by the network autonomously and dynamically emphasizes the regions of interest [28]. The features in the image include changing and unchanging, and the changing components are of interest and concern to us, which is just in line with the idea of attention mechanism. In CD, several methods have explored attention mechanism to improve detection performance. Marwa et al. [29] proposed a attention residual recurrent U-Net (Att R2U-Net), which combines the classical U-Net with the attention mechanism, and shows excellent performance in binary and multi-class CD of HSI. Chen et al. [30] added spatial channel double attention mechanism in their network to capture long-range correlations. Jiang et al. [31] proposed a pyramid feature-based attentionguided Siamese network (PGA-SiamNet). It improves the long-range dependencies of the features by utilizing various attention mechanisms. Qu et al. [32] proposed a multilevel encoder-decoder attention network (MLEDAN), which introduces multi-scale connection and attention mechanism to extract more effective spatial-spectral features. Then, LSTM is also used to analyze temporal dependence between multitemporal images. Gong et al. [33] proposed a spectral and spatial attention network (S2AN), which uses multiple repetitive spatial attention modules with adaptive Gaussian distributions to gradually enhance CD-related features. In summary, the attention mechanisms can help to notice the changing regions of the spatial-spectral information.Attention mechanism is proposed to focus on key information, and is widely used in the field of deep learning [28]. It is essentially a mechanism which learns a set of weighting coefficients by the network autonomously and dynamically emphasizes the regions of interest [28]. The features in the image include changing and unchanging, and the changing components are of interest and concern to us, which is just in line with the idea of attention mechanism. In CD, several methods have explored attention mechanism to improve detection performance. Marwa et al. [29] proposed a attention residual recurrent U-Net (Att R2U-Net), which combines the classical U-Net with the attention mechanism, and shows excellent performance in binary and multi-class CD of HSI. Chen et al. [30] added spatial channel double attention mechanism in their network to capture long-range correlations. Jiang et al. [31] proposed a pyramid feature-based attentionguided Siamese network (PGA-SiamNet). It improves the long-range dependencies of the features by utilizing various attention mechanisms. Qu et al. [32] proposed a multilevel encoder-decoder attention network (MLEDAN), which introduces multi-scale connection and attention mechanism to extract more effective spatial-spectral features. Then, LSTM is also used to analyze temporal dependence between multitemporal images. Gong et al. [33] proposed a spectral and spatial attention network (S2AN), which uses multiple repetitive spatial attention modules with adaptive Gaussian distributions to gradually enhance CD-related features. In summary, the attention mechanisms can help to notice the changing regions of the spatial-spectral information.</p>
        <p>From the above research work, we found that there is a great potential about how to better extract information from the input HSIs and how to more fully integrate the features of different phases for HSI CD. Firstly, shallow network structures often have difficult to extract the effective features, while complex network structures will lead to computational redundancy and may learn the irrelevant features for CD. Secondly, some current deep learning methods fuse the bi-temporal features of two HSIs by RNN or LSTM, which simultaneously combines the changed components and unchanged components. For CD task, it should significantly focus on the change components. Therefore, these methods do not separate changed and unchanged components to implement the CD tasks, which is very difficult to learn the subtle changed features of the bitemporal HSIs. And the feature fusion does not consider the importance of different features. We will pay more attention to the change components of features, so that we can more carefully explore the details of changes. In addition, the multiscale features is conducive to learning fine changes, so our research is based on multi-scale change features.From the above research work, we found that there is a great potential about how to better extract information from the input HSIs and how to more fully integrate the features of different phases for HSI CD. Firstly, shallow network structures often have difficult to extract the effective features, while complex network structures will lead to computational redundancy and may learn the irrelevant features for CD. Secondly, some current deep learning methods fuse the bi-temporal features of two HSIs by RNN or LSTM, which simultaneously combines the changed components and unchanged components. For CD task, it should significantly focus on the change components. Therefore, these methods do not separate changed and unchanged components to implement the CD tasks, which is very difficult to learn the subtle changed features of the bitemporal HSIs. And the feature fusion does not consider the importance of different features. We will pay more attention to the change components of features, so that we can more carefully explore the details of changes. In addition, the multiscale features is conducive to learning fine changes, so our research is based on multi-scale change features.</p>
        <p>Based on this, we propose a multi-scale diff-changed feature fusion network (MSDFFN) as shown in Fig. 1, it can learn fine and representative change features from bi-temporal HSIs. MSDFFN is composed of a temporal feature encoder-decoder (TFED) sub-network, a bidirectional diff-changed feature representation (BDFR) module and a multi-scale attention fusion (MSAF) module. The TFED sub-network with reduced inception and skip layer attention is designed to extract multi-scale features from the input HSI patches. the BDFR module is proposed to specifically learn and enhance the discriminating features of change components obtained by the TFED sub-network and the differential operation. Then, the MSAF module is used to fuse the multi-scale features and obtain the final features with discriminatory power. The main contributions of this paper are highlighted as follows.Based on this, we propose a multi-scale diff-changed feature fusion network (MSDFFN) as shown in Fig. 1, it can learn fine and representative change features from bi-temporal HSIs. MSDFFN is composed of a temporal feature encoder-decoder (TFED) sub-network, a bidirectional diff-changed feature representation (BDFR) module and a multi-scale attention fusion (MSAF) module. The TFED sub-network with reduced inception and skip layer attention is designed to extract multi-scale features from the input HSI patches. the BDFR module is proposed to specifically learn and enhance the discriminating features of change components obtained by the TFED sub-network and the differential operation. Then, the MSAF module is used to fuse the multi-scale features and obtain the final features with discriminatory power. The main contributions of this paper are highlighted as follows.</p>
        <p>1) We design a temporal feature encoder-decoder subnetwork to extract the features of multi-temporal HSIs, where a reduced inception module is embedded to enrich the perceptual field, and skip connections containing channel-space co-attention are added to fuse the contextual information.1) We design a temporal feature encoder-decoder subnetwork to extract the features of multi-temporal HSIs, where a reduced inception module is embedded to enrich the perceptual field, and skip connections containing channel-space co-attention are added to fuse the contextual information.</p>
        <p>2) The proposed bidirectional diff-changed feature representation module learns and fuses the refined change features, which pays special attention to the changed components in the entire features. With bidirectional representation, the subtle changes can be enhanced to improve the detection performance.2) The proposed bidirectional diff-changed feature representation module learns and fuses the refined change features, which pays special attention to the changed components in the entire features. With bidirectional representation, the subtle changes can be enhanced to improve the detection performance.</p>
        <p>3) The multi-scale attention fusion module, focusing on the fusion of key information, is proposed to mine the intrinsic information of different feature maps and generate a discriminative spatial-spectral-temporal change features. 4) By combining the above three thoughts, we propose the end-to-end multi-scale diff-changed feature fusion network, called MSDFFN, for HSI CD, which fuses the multi-scale information to extract features with strong representational power. The experimental results on three HSI datasets show that MSDFFN outperforms the several state-of-the-art methods for HSI CD. The rest of the paper is organized as follows. Section II introduces the details of the proposed MSDFFN. Section III presents three experimental datasets, experiment setting, experimental results and ablation study. In the end, section IV draws some conclusions of this paper and suggestions for future work.3) The multi-scale attention fusion module, focusing on the fusion of key information, is proposed to mine the intrinsic information of different feature maps and generate a discriminative spatial-spectral-temporal change features. 4) By combining the above three thoughts, we propose the end-to-end multi-scale diff-changed feature fusion network, called MSDFFN, for HSI CD, which fuses the multi-scale information to extract features with strong representational power. The experimental results on three HSI datasets show that MSDFFN outperforms the several state-of-the-art methods for HSI CD. The rest of the paper is organized as follows. Section II introduces the details of the proposed MSDFFN. Section III presents three experimental datasets, experiment setting, experimental results and ablation study. In the end, section IV draws some conclusions of this paper and suggestions for future work.</p>
        <p>In this section, we introduce the proposed MSDFFN for HSI CD task in Fig. 1, which is composed of TFED subnetwork, BDFR module and MSAF module. The bi-temporal HSIs are passed through the temporal feature extraction subnetwork, which combines the reduced inception (RI) module and the skip layer attention (SLA) module to obtain multiscale features. And then, the diff-changed features with fine representation power are acquired and learned by the BDFR module from these multi-scale features. After that, the MSAF module fuses the multi-scale diff-changed features adaptively with residual attention. In the following, we will explain each module of the network in detail.In this section, we introduce the proposed MSDFFN for HSI CD task in Fig. 1, which is composed of TFED subnetwork, BDFR module and MSAF module. The bi-temporal HSIs are passed through the temporal feature extraction subnetwork, which combines the reduced inception (RI) module and the skip layer attention (SLA) module to obtain multiscale features. And then, the diff-changed features with fine representation power are acquired and learned by the BDFR module from these multi-scale features. After that, the MSAF module fuses the multi-scale diff-changed features adaptively with residual attention. In the following, we will explain each module of the network in detail.</p>
        <p>Before presenting the specific network details, we constructed a basic CD network framework. The baseline model is shown in Fig. 2. Encoder-decoder network [34] is widely used in CD tasks because it can fuse image features well. In CNN, low-level features often have higher resolution and contain more details while lacking semantic information, and high-level features often have stronger semantic information while low resolution and poor perception of details [35]. The encoding and decoding network, which constructs skip connections between downsampling and upsampling layers to achieve the fusion of low-level and high-level features. Given the initial feature map E 0 ∈ R C×H×W as the input patch, the encoder stage of the TFED sub-network can be summarized as follows.Before presenting the specific network details, we constructed a basic CD network framework. The baseline model is shown in Fig. 2. Encoder-decoder network [34] is widely used in CD tasks because it can fuse image features well. In CNN, low-level features often have higher resolution and contain more details while lacking semantic information, and high-level features often have stronger semantic information while low resolution and poor perception of details [35]. The encoding and decoding network, which constructs skip connections between downsampling and upsampling layers to achieve the fusion of low-level and high-level features. Given the initial feature map E 0 ∈ R C×H×W as the input patch, the encoder stage of the TFED sub-network can be summarized as follows.</p>
        <p>where E i T represents the feature map generated by the i-th convolutional layer andwhere E i T represents the feature map generated by the i-th convolutional layer and</p>
        <p>represents the reduced inception operation on the feature map, f Conv 3×3 represent a convolution operation with the filter size of 3 × 3. All convolution layers are followed by a batch normalization layer and a rectified linear unit (ReLU) layer. ReLU (•) denotes the ReLU active function which can be described asrepresents the reduced inception operation on the feature map, f Conv 3×3 represent a convolution operation with the filter size of 3 × 3. All convolution layers are followed by a batch normalization layer and a rectified linear unit (ReLU) layer. ReLU (•) denotes the ReLU active function which can be described as</p>
        <p>where x represents the value of feature map.where x represents the value of feature map.</p>
        <p>In the encoding path, the previous feature map is passed through an RI module, a convolution operation without padding, and a ReLU function to obtain the output feature map. The RI structure is able to extract the refined features of different shapes with several different convolutional kernels, which helps to extract more effective features. The ReLU function makes the output of some neurons to be zero, which causes the sparsity of the network, reduces the interdependence of parameters, and alleviates the over-fitting. With successive downsampling operations, more abstract features can be learned from the input HSI patch step by step.In the encoding path, the previous feature map is passed through an RI module, a convolution operation without padding, and a ReLU function to obtain the output feature map. The RI structure is able to extract the refined features of different shapes with several different convolutional kernels, which helps to extract more effective features. The ReLU function makes the output of some neurons to be zero, which causes the sparsity of the network, reduces the interdependence of parameters, and alleviates the over-fitting. With successive downsampling operations, more abstract features can be learned from the input HSI patch step by step.</p>
        <p>The decoder stage of the TFED sub-network can be also summarized as follows.The decoder stage of the TFED sub-network can be also summarized as follows.</p>
        <p>T represents the output feature map after the i-th deconvolution operation, f DConv 3×3 represents a deconvolution operation with the filter size of 3×3, S a (•) and S b (•) represents the skip layer attention embedded into skip connections.T represents the output feature map after the i-th deconvolution operation, f DConv 3×3 represents a deconvolution operation with the filter size of 3×3, S a (•) and S b (•) represents the skip layer attention embedded into skip connections.</p>
        <p>In the decoding path, the attention-enhanced feature maps from the encoder and the same-scale upsampled feature maps from the deconvolution are stacked in the channel dimension, which can achieve the fusion of high-level features and lowlevel features. With such a fusion of across-layer features, a better balance between fine-grained and semantic information can be achieved. The skip connections with attention enable early encoder layers to preserve the positional relation of pixel, which can better recover the detailed structure of the input.In the decoding path, the attention-enhanced feature maps from the encoder and the same-scale upsampled feature maps from the deconvolution are stacked in the channel dimension, which can achieve the fusion of high-level features and lowlevel features. With such a fusion of across-layer features, a better balance between fine-grained and semantic information can be achieved. The skip connections with attention enable early encoder layers to preserve the positional relation of pixel, which can better recover the detailed structure of the input.</p>
        <p>2) Reduced Inception Module: The Inception module was first proposed in 
            <rs type="software">GoogleNet</rs> [36]. It uses convolutional kernels of different sizes to obtain features from different receptive fields. The specific convolution kernel size is selected by the network itself by adjusting parameters in the process of training, so the architecture is highly tunable [37]. We can appropriately choose the number of filters and kernel size to maximize the retention of features that are beneficial for CD. In the TFED sub-network, we propose a reduced inception module to improve the ability of feature extraction, as shown in Fig. 4. To reduce the calculation amount caused by multiple convolution layers, a 1 × 1 convolution is added before each convolutional layers to reduce the channel dimension. Considering the input size of the patch, we use the convolutional layers with the kernel size of 1 × 3, 3 × 1, 3 × 3 to construct the RI module. After that, we concatenate these convolutional features to obtain the feature maps with the same size as the input of RI.
        </p>
        <p>The specific process can be summarized as follows. Given an intermediate feature map X∈ R C×H×W as input, the RI can be represented asThe specific process can be summarized as follows. Given an intermediate feature map X∈ R C×H×W as input, the RI can be represented as</p>
        <p>where RI(X)∈ R C×H×W is the final output and f Conv N ×M represents the convolution operation with the filter size of N ×M . The asymmetric convolutional blocks formed by three different convolutional kernels can capture different shapes including square, horizontal and vertical features from the input feature maps, which can improve the discriminative power of the features. Embedding the above RI module into the TFED network can extend the receptive field and improve the scale adaptability.where RI(X)∈ R C×H×W is the final output and f Conv N ×M represents the convolution operation with the filter size of N ×M . The asymmetric convolutional blocks formed by three different convolutional kernels can capture different shapes including square, horizontal and vertical features from the input feature maps, which can improve the discriminative power of the features. Embedding the above RI module into the TFED network can extend the receptive field and improve the scale adaptability.</p>
        <p>3) Skip Layer Attention Module: Attention mechanism has become one of the most widely used in deep learning [38]. When dealing with information, human beings often pay attention to the more important characteristics of input. Attention mechanism simulates the mechanism of human processing information. The essence function of attention mechanism is to apply the learned weights to the original features. Different parts of the input data or feature maps have different degrees of focus, and attention mechanism ignores irrelevant noise information and focuses on key information. We design a spatial-spectral attention based on CBAM [39,40] to learn the refined features of CD tasks adaptively. The attention module is embedded into the skip connections to highlight the feature maps from the encoder, which can enhance the regions of interest for the CD task. As shown in Fig. 5, to accommodate the input feature maps of different scales, we design two attention models that are SLAa and SLAb based on channel attention and spatial attention. We use the one containing only channel attention as SLAa, and the one cascading channel attention and spatial attention as SLAb. By multiplying the input features with the attention weights, we can obtain the enhanced feature maps on channels and spatially, respectively. The channel attention module refines the weight of each feature map to emphasize the meaningful channels and suppress the useless ones. The spatial attention module refines the weight of each spatial position to highlight informative regions and compress useless ones.3) Skip Layer Attention Module: Attention mechanism has become one of the most widely used in deep learning [38]. When dealing with information, human beings often pay attention to the more important characteristics of input. Attention mechanism simulates the mechanism of human processing information. The essence function of attention mechanism is to apply the learned weights to the original features. Different parts of the input data or feature maps have different degrees of focus, and attention mechanism ignores irrelevant noise information and focuses on key information. We design a spatial-spectral attention based on CBAM [39,40] to learn the refined features of CD tasks adaptively. The attention module is embedded into the skip connections to highlight the feature maps from the encoder, which can enhance the regions of interest for the CD task. As shown in Fig. 5, to accommodate the input feature maps of different scales, we design two attention models that are SLAa and SLAb based on channel attention and spatial attention. We use the one containing only channel attention as SLAa, and the one cascading channel attention and spatial attention as SLAb. By multiplying the input features with the attention weights, we can obtain the enhanced feature maps on channels and spatially, respectively. The channel attention module refines the weight of each feature map to emphasize the meaningful channels and suppress the useless ones. The spatial attention module refines the weight of each spatial position to highlight informative regions and compress useless ones.</p>
        <p>Firstly, we generate two different spatial context descriptors, i.e., average-pooled descriptor F c avg and max-pooled descriptor F c max , by max-pooling and average-pooling operations. The spatial context descriptors can aggregate the spatial information of feature maps. After that, we input the two descriptors into the multi-layer perception (MLP) with one hidden layer to compress and extract the features. To reduce the number of parameters, the size of the hidden layer is set as C/r to reduce the number of channels, where r is the reduction ratio. Then, we merge the output features of two descriptors using element-wise summation and activate the fused features with sigmoid function. Given an intermediate feature map X ∈ R C×H×W as input, the channel attention maps are computed byFirstly, we generate two different spatial context descriptors, i.e., average-pooled descriptor F c avg and max-pooled descriptor F c max , by max-pooling and average-pooling operations. The spatial context descriptors can aggregate the spatial information of feature maps. After that, we input the two descriptors into the multi-layer perception (MLP) with one hidden layer to compress and extract the features. To reduce the number of parameters, the size of the hidden layer is set as C/r to reduce the number of channels, where r is the reduction ratio. Then, we merge the output features of two descriptors using element-wise summation and activate the fused features with sigmoid function. Given an intermediate feature map X ∈ R C×H×W as input, the channel attention maps are computed by</p>
        <p>where M c (X) ∈ R C×1×1 infers the channel attention maps, the MLP weights W 0 ∈ R C/r×C and W 1 ∈ R C×C/r are shared for inputs. σ(•) denotes the sigmoid function which can be described aswhere M c (X) ∈ R C×1×1 infers the channel attention maps, the MLP weights W 0 ∈ R C/r×C and W 1 ∈ R C×C/r are shared for inputs. σ(•) denotes the sigmoid function which can be described as</p>
        <p>where x represents a value of feature map. The attention added to the channels can adaptively adjust the feature response values of each channel to highlight the useful information. Secondly, we generate two different channel context descriptors, including average-pooled descriptor F s avg ∈ R 1×H×W and max-pooled descriptor F s max ∈ R 1×H×W , by max-pooling and average-pooling operations along the channels. The operations can aggregate the average pool features and the maximum pool features for the entire channels. Then, the two descriptors are stacked and passed through the standard convolution layer to generate the spatial attention maps. The spatial attention can be produced bywhere x represents a value of feature map. The attention added to the channels can adaptively adjust the feature response values of each channel to highlight the useful information. Secondly, we generate two different channel context descriptors, including average-pooled descriptor F s avg ∈ R 1×H×W and max-pooled descriptor F s max ∈ R 1×H×W , by max-pooling and average-pooling operations along the channels. The operations can aggregate the average pool features and the maximum pool features for the entire channels. Then, the two descriptors are stacked and passed through the standard convolution layer to generate the spatial attention maps. The spatial attention can be produced by</p>
        <p>where M S (X) ∈ R 1×H×W infers the spatial attention maps.where M S (X) ∈ R 1×H×W infers the spatial attention maps.</p>
        <p>The operation of SLA module is summarized as follows.The operation of SLA module is summarized as follows.</p>
        <p>where ⊗ denotes element-wise product. During the multiplication, the attention values are broadcasted accordingly.where ⊗ denotes element-wise product. During the multiplication, the attention values are broadcasted accordingly.</p>
        <p>In the specific TFED sub-network, SLAa is used for the deep-level features whose size of the feature maps is relatively small, and SLAb is used for the shallow-level features whose size of the feature maps is relatively large. The reason is that the smaller feature maps, such as 3 × 3, contains less spatial information. To simplify the network and reduce the computational cost, we do not focus on their spatial features.In the specific TFED sub-network, SLAa is used for the deep-level features whose size of the feature maps is relatively small, and SLAb is used for the shallow-level features whose size of the feature maps is relatively large. The reason is that the smaller feature maps, such as 3 × 3, contains less spatial information. To simplify the network and reduce the computational cost, we do not focus on their spatial features.</p>
        <p>After the input patches of bi-temporal HSIs pass through the front TFED sub-network, we can obtain feature maps with the three scale of 9, 7, 5 for each temporal features. The feature maps often contain the changed components and the unchanged components, where the changed can better find out the changes in details. Our purpose is to discover the changed pixels in the bi-temporal images, however, most of the previous studies do not focus on the learning of the changed components that can be represented by the diffchanged features. Therefore, we propose a BDFR module to learn the subtle difference features. This module makes use of the information of multi-level feature maps from the TFED sub-network. The structure is shown in Fig. 6. Differential operation can highlight difference information.After the input patches of bi-temporal HSIs pass through the front TFED sub-network, we can obtain feature maps with the three scale of 9, 7, 5 for each temporal features. The feature maps often contain the changed components and the unchanged components, where the changed can better find out the changes in details. Our purpose is to discover the changed pixels in the bi-temporal images, however, most of the previous studies do not focus on the learning of the changed components that can be represented by the diffchanged features. Therefore, we propose a BDFR module to learn the subtle difference features. This module makes use of the information of multi-level feature maps from the TFED sub-network. The structure is shown in Fig. 6. Differential operation can highlight difference information.</p>
        <p>To make the model more adaptive to bi-temporal HSIs, the multi-scale feature maps obtained from the TFED subnetwork are subtracted at the corresponding scales. The diffchanged feature maps are used as the input of the subsequent processing, and the operation can be summarized asTo make the model more adaptive to bi-temporal HSIs, the multi-scale feature maps obtained from the TFED subnetwork are subtracted at the corresponding scales. The diffchanged feature maps are used as the input of the subsequent processing, and the operation can be summarized as</p>
        <p>where B i IN is a diff-changed feature map as the input feature map of the BDFR module.where B i IN is a diff-changed feature map as the input feature map of the BDFR module.</p>
        <p>To better enhance the discriminative performance of diff-changed features, the BDFR module is composed of upsampling and downsampling paths. In the process of downsampling, the information from the high-level feature maps is brought to the smaller scale feature maps, and the operation can be described asTo better enhance the discriminative performance of diff-changed features, the BDFR module is composed of upsampling and downsampling paths. In the process of downsampling, the information from the high-level feature maps is brought to the smaller scale feature maps, and the operation can be described as</p>
        <p>where D 1 , D 2 represent the output feature maps after the convolution operation. Meanwhile, with upsampling operation, the deep features are also transferred to a large scale. The operation of upsmapling can be described aswhere D 1 , D 2 represent the output feature maps after the convolution operation. Meanwhile, with upsampling operation, the deep features are also transferred to a large scale. The operation of upsmapling can be described as</p>
        <p>where U 1 , U 2 represent the output feature map after the deconvolution operation. Now, we fuse the feature map of the middle scale by stack operation, and can get three output feature maps with different scales.where U 1 , U 2 represent the output feature map after the deconvolution operation. Now, we fuse the feature map of the middle scale by stack operation, and can get three output feature maps with different scales.</p>
        <p>where B i OUT represents the output feature maps of the BDFR module. BDFR module recombines and learns the feature maps of different scales, which maximizes the utilization of feature information and improves the discrimination of diffchanged features.where B i OUT represents the output feature maps of the BDFR module. BDFR module recombines and learns the feature maps of different scales, which maximizes the utilization of feature information and improves the discrimination of diffchanged features.</p>
        <p>After BDFR, we obtain three feature maps with different scales. Like the proposed baseline, we can unify the scale of feature maps and directly learn through the fully connection layers, and then achieve the classification results by the sigmoid function. However, the features obtained in this way may lack attention to the key change information which is not conducive to the final detection accuracy.After BDFR, we obtain three feature maps with different scales. Like the proposed baseline, we can unify the scale of feature maps and directly learn through the fully connection layers, and then achieve the classification results by the sigmoid function. However, the features obtained in this way may lack attention to the key change information which is not conducive to the final detection accuracy.</p>
        <p>As mentioned earlier, attention mechanisms focus on more important information, there are more applications in the field of CD gradually [41]. For example, the classic channel attention squeeze-excitation attention [42] generates the channel weights by global average pooling from the channel-wise level, which allows the adaptive adjustment of the feature response values for each channel. Another classic attention, i.e., CBAM, introduces two different descriptors to aggregate the features with average-pooling and max-pooling. In this section, we propose an MSAF module to adaptively focus on the areas of CD, as well as fusing the feature maps of three scales. The specific structure is shown in Fig. 7. Firstly, to facilitate follow-up processing, the feature maps of the three scales are normalized to a unified scale by convolution and deconvolution operations.As mentioned earlier, attention mechanisms focus on more important information, there are more applications in the field of CD gradually [41]. For example, the classic channel attention squeeze-excitation attention [42] generates the channel weights by global average pooling from the channel-wise level, which allows the adaptive adjustment of the feature response values for each channel. Another classic attention, i.e., CBAM, introduces two different descriptors to aggregate the features with average-pooling and max-pooling. In this section, we propose an MSAF module to adaptively focus on the areas of CD, as well as fusing the feature maps of three scales. The specific structure is shown in Fig. 7. Firstly, to facilitate follow-up processing, the feature maps of the three scales are normalized to a unified scale by convolution and deconvolution operations.</p>
        <p>where F i represents the output feature maps with the same size, F add represents the fused feature map by element-wise summation. To compute the channel attention efficiently, we squeeze the spatial dimension of the input feature map by global average pooling. A channel-wise convolutional layer with the size of 1×1 is utilized to achieve the compact features and a ReLU activation is used to control the attention coefficient. Then, we generate an initial fusion channel attention feature aswhere F i represents the output feature maps with the same size, F add represents the fused feature map by element-wise summation. To compute the channel attention efficiently, we squeeze the spatial dimension of the input feature map by global average pooling. A channel-wise convolutional layer with the size of 1×1 is utilized to achieve the compact features and a ReLU activation is used to control the attention coefficient. Then, we generate an initial fusion channel attention feature as</p>
        <p>where M 0 m (F add ) represents the initial fusion feature.where M 0 m (F add ) represents the initial fusion feature.</p>
        <p>where f c i is a fully connection operation and has the same structure without parameter share.where f c i is a fully connection operation and has the same structure without parameter share.</p>
        <p>To retain the original information, we add residual operation to build a connection between the original features and the attention features. The final output can be described asTo retain the original information, we add residual operation to build a connection between the original features and the attention features. The final output can be described as</p>
        <p>By multiplying the input feature maps with the shared channel attention weights, the obtained feature maps highlight the useful regions and suppresses the useless regions. The MSAF module adaptively selects the effective information in the multilayer features for fusion, so that the fused features achieve the complementarity of the multilayer information.By multiplying the input feature maps with the shared channel attention weights, the obtained feature maps highlight the useful regions and suppresses the useless regions. The MSAF module adaptively selects the effective information in the multilayer features for fusion, so that the fused features achieve the complementarity of the multilayer information.</p>
        <p>After the learning of previous several modules, a feature map, which contains rich changed details, is obtained. The probability estimate obtained from the fully connected layers can be used to predict the final labels of the input patches. Consistent with the processing in baseline, the final CD results can be described asAfter the learning of previous several modules, a feature map, which contains rich changed details, is obtained. The probability estimate obtained from the fully connected layers can be used to predict the final labels of the input patches. Consistent with the processing in baseline, the final CD results can be described as</p>
        <p>where y p is the predicted probability result, M out (X) is the output of the MSAF module. The f c denotes the fully connected layers to extract the features and reduce dimension.where y p is the predicted probability result, M out (X) is the output of the MSAF module. The f c denotes the fully connected layers to extract the features and reduce dimension.</p>
        <p>An appropriate loss function can optimize the designed network in model training to extract more effective features. CD task considered as a classification task, each pixel of bitemporal HSIs is divided into two categories, i.e., changed and unchanged. Therefore, the cross-entropy loss function is a popular and effective solution to optimize the network. The loss function is calculated as follows.An appropriate loss function can optimize the designed network in model training to extract more effective features. CD task considered as a classification task, each pixel of bitemporal HSIs is divided into two categories, i.e., changed and unchanged. Therefore, the cross-entropy loss function is a popular and effective solution to optimize the network. The loss function is calculated as follows.</p>
        <p>where n denotes the number of samples and y i is the ground truth label of the given sample.where n denotes the number of samples and y i is the ground truth label of the given sample.</p>
        <p>In this section, we first introduce the HSI CD datasets and the evaluation measures are used to evaluate the effect of the proposed MSDFFN method. Then, we give a brief description of the comparison algorithms and introduce the relevant experimental details. At the same time, a series of ablation experiments are provided to verify the effectiveness of the proposed modules. Finally, we compare the impact of the training samples size on the network. The second dataset, named "River", covers a river area from Jiangsu Province in China, as shown in Fig. 9, which was acquired on May 3, 2013 and December 31, 2013, respectively. They are also observed by the sensor EO-1. This dataset has a spatial size of 463×241 pixels with 198 bands available after 2) Evaluation Measures: To better quantify the performance of the proposed method, we mainly used the Overall Accuracy (OA) and Kappa Coefficient (KC) [43] as metrics, Precision (Pr), Recall (Re), and F1-score (F1) were introduced as an auxiliary evaluation.In this section, we first introduce the HSI CD datasets and the evaluation measures are used to evaluate the effect of the proposed MSDFFN method. Then, we give a brief description of the comparison algorithms and introduce the relevant experimental details. At the same time, a series of ablation experiments are provided to verify the effectiveness of the proposed modules. Finally, we compare the impact of the training samples size on the network. The second dataset, named "River", covers a river area from Jiangsu Province in China, as shown in Fig. 9, which was acquired on May 3, 2013 and December 31, 2013, respectively. They are also observed by the sensor EO-1. This dataset has a spatial size of 463×241 pixels with 198 bands available after 2) Evaluation Measures: To better quantify the performance of the proposed method, we mainly used the Overall Accuracy (OA) and Kappa Coefficient (KC) [43] as metrics, Precision (Pr), Recall (Re), and F1-score (F1) were introduced as an auxiliary evaluation.</p>
        <p>The metrics are defined as follows.The metrics are defined as follows.</p>
        <p>P recision = T P T P + F P (23)P recision = T P T P + F P (23)</p>
        <p>To evaluate the performance of the proposed architecture, we further compared our method with other CD methods. Some classic CD algorithms were implemented for comparison, including CVA [8], PCAKM [12], IRMAD [15], KNN [17]. CVA is a most commonly used method, which can provide change intensity and change direction. PCAKM uses the PCA method to project the original data into a new lower dimensional feature space, and the CD is achieved by partitioning the feature vector space into two clusters using k-means. IRMAD is a CD algorithm based on CCA that aims to maximize the variance of projection feature difference. KNN uses proximity to classify or predict the classification of data points. Some deep architecture algorithms were also implemented for comparison, including ReCNN [25], BCNN [24], SiamCRNN [26] and ML-EDAN [32]. ReCNN and SiamCRNN use LSTM units to find the change information extracted by CNN. BCNN finds the relationship between bi-temporal feature maps by combining bilinear feature. ML-EDAN learns the discriminating features by introducing multi-scale features. All the codes of the above comparison algorithms were reproduced in this paper. The mean and variance obtained from ten repeated experiments were used as the experimental results, which intuitively reflects the performance and robustness of the methods.To evaluate the performance of the proposed architecture, we further compared our method with other CD methods. Some classic CD algorithms were implemented for comparison, including CVA [8], PCAKM [12], IRMAD [15], KNN [17]. CVA is a most commonly used method, which can provide change intensity and change direction. PCAKM uses the PCA method to project the original data into a new lower dimensional feature space, and the CD is achieved by partitioning the feature vector space into two clusters using k-means. IRMAD is a CD algorithm based on CCA that aims to maximize the variance of projection feature difference. KNN uses proximity to classify or predict the classification of data points. Some deep architecture algorithms were also implemented for comparison, including ReCNN [25], BCNN [24], SiamCRNN [26] and ML-EDAN [32]. ReCNN and SiamCRNN use LSTM units to find the change information extracted by CNN. BCNN finds the relationship between bi-temporal feature maps by combining bilinear feature. ML-EDAN learns the discriminating features by introducing multi-scale features. All the codes of the above comparison algorithms were reproduced in this paper. The mean and variance obtained from ten repeated experiments were used as the experimental results, which intuitively reflects the performance and robustness of the methods.</p>
        <p>In our network, comprehensively considering the complexity of calculation and spatial-spectral information, we chose the input patch size as 9×9. In experiments, we selected 20% from the datasets as the training samples and the rest as the testing samples. Our network was trained and tested on a NVIDIA GTX A6000 GPU with 48G memory using the 
            <rs type="software">PyTorch</rs> [44] framework. In the stage of training, we used the SGD optimizer [45] with weight decay 5e-3. The initial learning rate was designed to be 5e-3 and decayed by a factor of 0.1 at every 35 epoch. The number of total epochs was 100, the batch size was set to 32. To avoid biased estimation, we conducted 10 repeated experiments and took their average values with standard deviation as the final results.
        </p>
        <p>According to the original paper, for BCNNs, we chose the input patch size as 11×11 and used the SGD optimizer with weight decay 5e-3. We trained the network for 100 epochs and the initial learning rate was designed to be 1e-4 with 0.1 times decay at every 35 epochs. For ReCNN and SiamCRNN, we used the patch size of 5, and used the SGD optimizer in training. The initial learning rate was designed to be 2e-4 with a decay of 0.1 times for every 35 epochs. The total number of epochs is 150, and the batch size was set to 64 and 32, respectively. ML-EDAN method also used the patch size of 5, and we used the Adam optimizer to train. The initial learning rate was set to 1e-4, decaying by a factor of 10 at 100 and 150 epochs. The total number of epochs is 200 and the batch size is set to 16.According to the original paper, for BCNNs, we chose the input patch size as 11×11 and used the SGD optimizer with weight decay 5e-3. We trained the network for 100 epochs and the initial learning rate was designed to be 1e-4 with 0.1 times decay at every 35 epochs. For ReCNN and SiamCRNN, we used the patch size of 5, and used the SGD optimizer in training. The initial learning rate was designed to be 2e-4 with a decay of 0.1 times for every 35 epochs. The total number of epochs is 150, and the batch size was set to 64 and 32, respectively. ML-EDAN method also used the patch size of 5, and we used the Adam optimizer to train. The initial learning rate was set to 1e-4, decaying by a factor of 10 at 100 and 150 epochs. The total number of epochs is 200 and the batch size is set to 16.</p>
        <p>1) Experimental Results on the Farmland Dataset: Table I and Fig. 11 show the results of each model on the Farmland dataset. Compared with the traditional CVA, PCAKM method, the supervised learning methods present a better precision, and have a great improvement in term of KCs. It indicates that the CVA and PCAKM algorithms misjudge a large number of invariant regions into changing regions, thus having a high Re but a low KC. Deep learning-based methods are generally more satisfactory compared to CVA, PCAKM, IRMAD, because these methods can learn more deep features through convolutional layers. After introducing the multi-scale features, ML-EDAN and the proposed MSDFFN have better performance than other deep learning methods which only consider the single scale features. This indicates that the multiscale features are conducive to the network to learn more precise features for matching different shapes of land-covers. Compared with ML-EDAN, the accuracy of our MSDFFN network is further improved due to only considering the changed components to learn the subtle changing features. Compared with all the methods, the proposed MSDFFN model has the best performance in OA, KC, F1 Score, Re, Pr metrics. From the visual observations, our proposed MSDFFN presents the fewest false positive pixels, thus achieving the best visual performance. From Fig. 11(a)-(c), the traditional CVA, PCAKM methods exhibit more misclassified pixels, with significant "salt and pepper" noise in the unchanged areas (black regions), and a large number of misclassification pixels around the edges of the changed areas and small targets. IRMAD and KNN have less pixels of misclassification than CVA, but still have some pixels of false positive in the upper right part of the image obviously. The deep learning algorithms, such as ReCNN, BCNN and SiamCRNN have better performance in distinguishing the unchanged pixels, however the areas between the rice fields, as shown in the edges of the block areas of the image, still appear some pixels of false negative. MSDFFN has fewer misclassification points and better CD details than ML-EDAN, mainly shown in the middle right small target areas of the image.1) Experimental Results on the Farmland Dataset: Table I and Fig. 11 show the results of each model on the Farmland dataset. Compared with the traditional CVA, PCAKM method, the supervised learning methods present a better precision, and have a great improvement in term of KCs. It indicates that the CVA and PCAKM algorithms misjudge a large number of invariant regions into changing regions, thus having a high Re but a low KC. Deep learning-based methods are generally more satisfactory compared to CVA, PCAKM, IRMAD, because these methods can learn more deep features through convolutional layers. After introducing the multi-scale features, ML-EDAN and the proposed MSDFFN have better performance than other deep learning methods which only consider the single scale features. This indicates that the multiscale features are conducive to the network to learn more precise features for matching different shapes of land-covers. Compared with ML-EDAN, the accuracy of our MSDFFN network is further improved due to only considering the changed components to learn the subtle changing features. Compared with all the methods, the proposed MSDFFN model has the best performance in OA, KC, F1 Score, Re, Pr metrics. From the visual observations, our proposed MSDFFN presents the fewest false positive pixels, thus achieving the best visual performance. From Fig. 11(a)-(c), the traditional CVA, PCAKM methods exhibit more misclassified pixels, with significant "salt and pepper" noise in the unchanged areas (black regions), and a large number of misclassification pixels around the edges of the changed areas and small targets. IRMAD and KNN have less pixels of misclassification than CVA, but still have some pixels of false positive in the upper right part of the image obviously. The deep learning algorithms, such as ReCNN, BCNN and SiamCRNN have better performance in distinguishing the unchanged pixels, however the areas between the rice fields, as shown in the edges of the block areas of the image, still appear some pixels of false negative. MSDFFN has fewer misclassification points and better CD details than ML-EDAN, mainly shown in the middle right small target areas of the image.</p>
        <p>2) Experimental Results on the River Dataset: Detection results of various algorithms on the River dataset are displayed in Table II. Firstly, the unsupervised methods such as CVA and PCAKM have relatively low accuracy compared to the other methods, because it is more difficult to distinguish the changes when some features are very close to the invariant pixels without any labeled samples. For KNN, it is one of classical supervised machine learning methods, and it achieves better results compared to the unsupervised algorithms. The accuracies of ML-EDAN and MSDFFN are higher than the single scale methods, which also proves the effectiveness of multi-scale features. Compared with ML-EDAN, the accuracies of the MSDFFN network are improved which shows that the different multi-scale fusion strategy has played a role. For the River dataset, as presented in Fig. 12, CVA and PCAKM have amount of pixels of false positive (green regions), which means they can not distinguish positive and negative samples well. KNN has a lot of false pixels, because it just uses the shallow features with limited discriminating performance to detect the change pixels. Meanwhile, the deep learning algorithms such as ReCNN, BCNN and SiamCRNN have many false negative pixels (red regions), which means they identify many changing places as unchanging areas. Compared with ML-EDAN that also uses the multi-scale strategies, the proposed MSDFFN has an advantage in distinguishing the small details.2) Experimental Results on the River Dataset: Detection results of various algorithms on the River dataset are displayed in Table II. Firstly, the unsupervised methods such as CVA and PCAKM have relatively low accuracy compared to the other methods, because it is more difficult to distinguish the changes when some features are very close to the invariant pixels without any labeled samples. For KNN, it is one of classical supervised machine learning methods, and it achieves better results compared to the unsupervised algorithms. The accuracies of ML-EDAN and MSDFFN are higher than the single scale methods, which also proves the effectiveness of multi-scale features. Compared with ML-EDAN, the accuracies of the MSDFFN network are improved which shows that the different multi-scale fusion strategy has played a role. For the River dataset, as presented in Fig. 12, CVA and PCAKM have amount of pixels of false positive (green regions), which means they can not distinguish positive and negative samples well. KNN has a lot of false pixels, because it just uses the shallow features with limited discriminating performance to detect the change pixels. Meanwhile, the deep learning algorithms such as ReCNN, BCNN and SiamCRNN have many false negative pixels (red regions), which means they identify many changing places as unchanging areas. Compared with ML-EDAN that also uses the multi-scale strategies, the proposed MSDFFN has an advantage in distinguishing the small details.</p>
        <p>3) Experimental Results on the Hermiston Dataset: The detection results on the Hermiston dataset are displayed in Table III. CVA and PCAKM have a bit better performance than IRMAD and KNN. This performance is inconsistent with these methods on the other two datasets. For the Hermiston dataset, the change areas, like some disks which overlap at a small part of the edge, are relatively scattered, and there is no large connected areas. The characteristics may lead to some misclassification, so the detection capability of simpler CNN structures may be marginally weaker than CVA. BCNN has higher accurate compared with ReCNN and SiamCRNN, because the combined linear features constructed by BCNN can better capture and fuse the features of the two phases than RNN and LSTM. In this scene, MSDFFN also achieves the best results than the other methods. For the Hermiston dataset, the visual observations are presented in Fig. 13. For the detection results of CVA and PCAKM, a lap of unchanged pixels around the circular change areas are misclassified into the changes, and the classification results do not show enough details. ReCNN and SiamCRNN show a lot of false negative pixels. Some large circular regions are lost in their CD results. Consistent with the performance on the above two datasets, compared with ML-EDAN, MSDFFN has fewer pixels of false negative and false positive and shows better CD details. MSDFFN detects some scattered target changed regions which ML-EDAN can not detect.3) Experimental Results on the Hermiston Dataset: The detection results on the Hermiston dataset are displayed in Table III. CVA and PCAKM have a bit better performance than IRMAD and KNN. This performance is inconsistent with these methods on the other two datasets. For the Hermiston dataset, the change areas, like some disks which overlap at a small part of the edge, are relatively scattered, and there is no large connected areas. The characteristics may lead to some misclassification, so the detection capability of simpler CNN structures may be marginally weaker than CVA. BCNN has higher accurate compared with ReCNN and SiamCRNN, because the combined linear features constructed by BCNN can better capture and fuse the features of the two phases than RNN and LSTM. In this scene, MSDFFN also achieves the best results than the other methods. For the Hermiston dataset, the visual observations are presented in Fig. 13. For the detection results of CVA and PCAKM, a lap of unchanged pixels around the circular change areas are misclassified into the changes, and the classification results do not show enough details. ReCNN and SiamCRNN show a lot of false negative pixels. Some large circular regions are lost in their CD results. Consistent with the performance on the above two datasets, compared with ML-EDAN, MSDFFN has fewer pixels of false negative and false positive and shows better CD details. MSDFFN detects some scattered target changed regions which ML-EDAN can not detect.</p>
        <p>To more clearly show the effectiveness of each proposed module, we conducted the ablation experiments for each module, including RI, SLA, BDFR and MSAF on the three datasets. Specifically, we added modules step by step and designed seven experiments. Noteworthy, the first experiment is the baseline, whose structure is shown in Fig. 2. The fourth experiment is considered to only use the TFED module for CD. In the fifth experiment, the concatenated multi-scale (CMS) operation was directly used to fuse the multi-scale features from TFED.To more clearly show the effectiveness of each proposed module, we conducted the ablation experiments for each module, including RI, SLA, BDFR and MSAF on the three datasets. Specifically, we added modules step by step and designed seven experiments. Noteworthy, the first experiment is the baseline, whose structure is shown in Fig. 2. The fourth experiment is considered to only use the TFED module for CD. In the fifth experiment, the concatenated multi-scale (CMS) operation was directly used to fuse the multi-scale features from TFED.</p>
        <p>It can be seen from the experimental results shown as Table IV, with the gradual addition of the proposed modules, the accuracies have been improved compared with the previous model in general, and the complete model has the highest accuracies. This proves the effectiveness of each module. For the Farmland dataset, the complete model presents optimal values in OA, Kappa, F1 Score, Re and Pr, respectively. For the River dataset and Hermiston dataset, the optimal values of Pr appears in "baseline+SLA" and "baseline+RI+SLA+CMS", respectively. The Pr is related to the proportion of correctly predicted samples to positive predictions. Since the proportion of positive and negative samples is not completely uniform, this may cause a high Pr. The model can not be evaluated as good or bad by Pr alone. At this time, generally, the F1-score is more appropriate to evaluate the model, and the F1-score of our proposed complete MSDFFN is still optimal. For the River dataset, noteworthy, when only adding RI, the accuracy is slightly lower than that of baseline. The inception module enriches the receptive field, while it may also introduce some data redundancy which causes some detection results with a slight decrease. For the Hermiston dataset, the complete model has the highest accuracies. To add RI module and SLA module separately can improve the accuracy, but when adding RI and SLA at the same time, there is a decline of accuracies. This may generate over learning when adding RI and SLA at the same time on the complex Hermiston dataset. In summary, although the proposed modules show side effect in a few cases for some datasets, they generally have advantage to improve the performance of CD under most conditions for all the experimental datasets.It can be seen from the experimental results shown as Table IV, with the gradual addition of the proposed modules, the accuracies have been improved compared with the previous model in general, and the complete model has the highest accuracies. This proves the effectiveness of each module. For the Farmland dataset, the complete model presents optimal values in OA, Kappa, F1 Score, Re and Pr, respectively. For the River dataset and Hermiston dataset, the optimal values of Pr appears in "baseline+SLA" and "baseline+RI+SLA+CMS", respectively. The Pr is related to the proportion of correctly predicted samples to positive predictions. Since the proportion of positive and negative samples is not completely uniform, this may cause a high Pr. The model can not be evaluated as good or bad by Pr alone. At this time, generally, the F1-score is more appropriate to evaluate the model, and the F1-score of our proposed complete MSDFFN is still optimal. For the River dataset, noteworthy, when only adding RI, the accuracy is slightly lower than that of baseline. The inception module enriches the receptive field, while it may also introduce some data redundancy which causes some detection results with a slight decrease. For the Hermiston dataset, the complete model has the highest accuracies. To add RI module and SLA module separately can improve the accuracy, but when adding RI and SLA at the same time, there is a decline of accuracies. This may generate over learning when adding RI and SLA at the same time on the complex Hermiston dataset. In summary, although the proposed modules show side effect in a few cases for some datasets, they generally have advantage to improve the performance of CD under most conditions for all the experimental datasets.</p>
        <p>1) Discuss of the Feature Fusion Scale: In the proposed MSDFFN framework, the feature fusion scale is an inevitable parameter in our MSAF module, which is related to how to set a proper scale for feature fusion. In this paper, we normalize the feature maps to the middle scale of 7, which indicates that the multi-scale features are fused at the scale of 7×7. To verify the effectiveness of fusion at the middle scale, we tried to fuse the multi-scale features at the scales of 9 and 5. To ensure the fairness of the comparison, we used the same settings in all experiments. The results are shown in Table V. According to Table V, we can see that the best accuracy can be obtained at the scale of 7. When the scale is 9, it contains more features. This may introduce many additional information causing feature redundancy, which is not conducive to the subsequent detection. When the scale is 5, the window is smaller and the less information is obtained. In this case, the features may be insufficient to discriminate the change areas, and some important details may be lost to reduce the detection accuracies. Based on the experimental results and comprehensive analysis, a suitable scale, with a larger or smaller scale both generating disadvantage for CD, is very important for the MSAF module, where we set the fusion scale as 7.1) Discuss of the Feature Fusion Scale: In the proposed MSDFFN framework, the feature fusion scale is an inevitable parameter in our MSAF module, which is related to how to set a proper scale for feature fusion. In this paper, we normalize the feature maps to the middle scale of 7, which indicates that the multi-scale features are fused at the scale of 7×7. To verify the effectiveness of fusion at the middle scale, we tried to fuse the multi-scale features at the scales of 9 and 5. To ensure the fairness of the comparison, we used the same settings in all experiments. The results are shown in Table V. According to Table V, we can see that the best accuracy can be obtained at the scale of 7. When the scale is 9, it contains more features. This may introduce many additional information causing feature redundancy, which is not conducive to the subsequent detection. When the scale is 5, the window is smaller and the less information is obtained. In this case, the features may be insufficient to discriminate the change areas, and some important details may be lost to reduce the detection accuracies. Based on the experimental results and comprehensive analysis, a suitable scale, with a larger or smaller scale both generating disadvantage for CD, is very important for the MSAF module, where we set the fusion scale as 7.</p>
        <p>2) Application of the MSAF Module: In recent years, a lot of attention mechanisms have been used in computer vision, each with its own advantages and focus. For example, ECA [46] introduced the adaptive one-dimensional convolution to replace the full connection layer, which simplifies the calculation. CBAM [39], cascading channel attention and spatial attention, using max pooling and average pooling operations to aggregate spatial and channel information. To validate the effectiveness of the attention fusion, we compared the proposed MSAF module with the other classic attention, i.e., ECA and CBAM. The results are shown in Table VI. From the results, we can see that the proposed MSAF module can yield the best accuracies, and is more suitable for the CD task based on the multi-scale features. The attention mechanisms, like ECA and CBAM which focuses on the information of channels and spaces, are directly applied to the fused feature maps. While the proposed MSAF module aims at multi-scale feature fusion, considering the information sharing between different feature maps. The MSAF module shares the attention score into the three input feature maps, and uses the residual connection to retain the original information. After stacking, the three feature maps will be better integrated and get more discriminating features.2) Application of the MSAF Module: In recent years, a lot of attention mechanisms have been used in computer vision, each with its own advantages and focus. For example, ECA [46] introduced the adaptive one-dimensional convolution to replace the full connection layer, which simplifies the calculation. CBAM [39], cascading channel attention and spatial attention, using max pooling and average pooling operations to aggregate spatial and channel information. To validate the effectiveness of the attention fusion, we compared the proposed MSAF module with the other classic attention, i.e., ECA and CBAM. The results are shown in Table VI. From the results, we can see that the proposed MSAF module can yield the best accuracies, and is more suitable for the CD task based on the multi-scale features. The attention mechanisms, like ECA and CBAM which focuses on the information of channels and spaces, are directly applied to the fused feature maps. While the proposed MSAF module aims at multi-scale feature fusion, considering the information sharing between different feature maps. The MSAF module shares the attention score into the three input feature maps, and uses the residual connection to retain the original information. After stacking, the three feature maps will be better integrated and get more discriminating features.</p>
        <p>3) Discuss of the Computational Cost: We tested the computational cost of deep learning-based methods. The computational cost of different methods on the Farmland dataset is shown in Table VII. The proposed method has fewer parameters than ML-EDAN and the most test time than the other methods. While MSDFFN achieves the best detection performance compared with all the compared algorithms. In further research, we will consider developing some more innovative model compression methods to reduce the computational cost and shorten the required time with guaranteed accuracy. With the reduced sample size, both the OAs and KCs show a downward trend in the several algorithms. This results indicate that the increased number of training samples will improve the detection results. Because more information can be utilized for training with the increasing of training samples. Furthermore, as the training sample size decreases, the accuracies of the models with multi-scale features are still higher than the models with single scale, this shows that the multi-scale learning can enhance the robustness of the features. The reason is that the multi-scale learning has advantage to adaptively match the land-covers with different shapes and extract purer features of different land-covers. The proposed method still achieves the highest accuracies than the other three algorithms under different numbers of training samples, because MDFFN can learn the subtle change features and adaptively fuse the discriminative information of different scales.3) Discuss of the Computational Cost: We tested the computational cost of deep learning-based methods. The computational cost of different methods on the Farmland dataset is shown in Table VII. The proposed method has fewer parameters than ML-EDAN and the most test time than the other methods. While MSDFFN achieves the best detection performance compared with all the compared algorithms. In further research, we will consider developing some more innovative model compression methods to reduce the computational cost and shorten the required time with guaranteed accuracy. With the reduced sample size, both the OAs and KCs show a downward trend in the several algorithms. This results indicate that the increased number of training samples will improve the detection results. Because more information can be utilized for training with the increasing of training samples. Furthermore, as the training sample size decreases, the accuracies of the models with multi-scale features are still higher than the models with single scale, this shows that the multi-scale learning can enhance the robustness of the features. The reason is that the multi-scale learning has advantage to adaptively match the land-covers with different shapes and extract purer features of different land-covers. The proposed method still achieves the highest accuracies than the other three algorithms under different numbers of training samples, because MDFFN can learn the subtle change features and adaptively fuse the discriminative information of different scales.</p>
        <p>In this paper, an end-to-end framework named MSDFFN, including TFED, BDFR, and MSAF modules, was proposed to detect the changed reigions of bi-temporal HSIs. The proposed TFED, which combines reduced inception and skip layer attention, can extract rich multi-scale features from the input patch pairs. The BDFR module with bidirectional representation can improve the discrimination performance of subtle changes, whilst MSAF adaptively fuses the features from different scales with attention mechanism. Our proposed method can better obtain and analyze the changed components, and has advantages over the others in detecting small changes. Experimental results on three HSI datasets show that the proposed method can produce more accurate CD results than the other compared methods. There are also some limitations of our proposed method, which is a supervised algorithm and can not utilize unlabeled samples. In the future work, a semisupervised algorithm [47] can be developed to utilize both labeled and unlabeled samples for further improved HSI CD.In this paper, an end-to-end framework named MSDFFN, including TFED, BDFR, and MSAF modules, was proposed to detect the changed reigions of bi-temporal HSIs. The proposed TFED, which combines reduced inception and skip layer attention, can extract rich multi-scale features from the input patch pairs. The BDFR module with bidirectional representation can improve the discrimination performance of subtle changes, whilst MSAF adaptively fuses the features from different scales with attention mechanism. Our proposed method can better obtain and analyze the changed components, and has advantages over the others in detecting small changes. Experimental results on three HSI datasets show that the proposed method can produce more accurate CD results than the other compared methods. There are also some limitations of our proposed method, which is a supervised algorithm and can not utilize unlabeled samples. In the future work, a semisupervised algorithm [47] can be developed to utilize both labeled and unlabeled samples for further improved HSI CD.</p>
        <p>This article has been accepted for publication in IEEE Transactions on Geoscience and Remote Sensing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TGRS.2023.3241097 © 2023 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.This article has been accepted for publication in IEEE Transactions on Geoscience and Remote Sensing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TGRS.2023.3241097 © 2023 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.</p>
        <p>This article has been accepted for publication in IEEE Transactions on Geoscience and Remote Sensing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TGRS.2023.3241097 © 2023 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information. LUO et al.: MSDFFN FOR HYPERSPECTRAL IMAGE CHANGE DETECTIONThis article has been accepted for publication in IEEE Transactions on Geoscience and Remote Sensing. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/TGRS.2023.3241097 © 2023 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information. LUO et al.: MSDFFN FOR HYPERSPECTRAL IMAGE CHANGE DETECTION</p>
    </text>
</tei>
