<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-13T16:18+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>During an emergency inside large buildings such as hospitals and shopping malls, the availability of up-to-date information is critical. One common source of information is the 2D layout of buildings and emergency exits. For most buildings, this information is represented as tangled floor plans, which in most cases are outdated. One solution to update the data of buildings after each renovation is to recreate 3D models of buildings in a quick and automatic approach. These 3D models provide proactively crucial building information in a digital format for first responders to be used in emergency cases. Thanks to advances in remote sensing, laser scanners can be used to generate an accurate spatial representation of buildings quickly. However, such devices provide point clouds, which are unstructured data. In this paper, we introduce a complete workflow that allows to generate 3D models from point clouds of buildings and extract fine-grained indoor navigation networks from those models, to support advanced path planning for disaster management and navigation of different types of agents. The process extracts structural elements of buildings such as walls, slabs, ceiling and openings, and reconstruct their volumetric shapes. Additionally, the furnishing elements in the input point clouds are identified and reconstructed as the obstacles. Stairs are also reconstructed to allow multistory navigation path planning. Our algorithm is fully 3D and can handle vertical and slanted structures. We test it on several real datasets, compared it to the state-of-the-art approaches and provide a process to check the consistency of the reconstruction, which allows in return to further improve its result.During an emergency inside large buildings such as hospitals and shopping malls, the availability of up-to-date information is critical. One common source of information is the 2D layout of buildings and emergency exits. For most buildings, this information is represented as tangled floor plans, which in most cases are outdated. One solution to update the data of buildings after each renovation is to recreate 3D models of buildings in a quick and automatic approach. These 3D models provide proactively crucial building information in a digital format for first responders to be used in emergency cases. Thanks to advances in remote sensing, laser scanners can be used to generate an accurate spatial representation of buildings quickly. However, such devices provide point clouds, which are unstructured data. In this paper, we introduce a complete workflow that allows to generate 3D models from point clouds of buildings and extract fine-grained indoor navigation networks from those models, to support advanced path planning for disaster management and navigation of different types of agents. The process extracts structural elements of buildings such as walls, slabs, ceiling and openings, and reconstruct their volumetric shapes. Additionally, the furnishing elements in the input point clouds are identified and reconstructed as the obstacles. Stairs are also reconstructed to allow multistory navigation path planning. Our algorithm is fully 3D and can handle vertical and slanted structures. We test it on several real datasets, compared it to the state-of-the-art approaches and provide a process to check the consistency of the reconstruction, which allows in return to further improve its result.</p>
        <p>Monitoring the changes of buildings after each renovation and auditing the compliance of the changes according to the safety standards is a known problem. For most new buildings, Building Information Models (BIM) are available at the start of the construction, but these models are no longer current after building renovation. Keeping the data of the building up-to-date and checking it against the safety regulations is problematic, although it is critical to support rapid intervention in situation of emergency. Indeed, information about building layouts and indoor objects occupancy is a game-changing support to efficient and safer emergency response in disaster management. Mobile laser scanning (MLS) systems provide such a possibility when their data is post-processed using a smart and fast workflow.Monitoring the changes of buildings after each renovation and auditing the compliance of the changes according to the safety standards is a known problem. For most new buildings, Building Information Models (BIM) are available at the start of the construction, but these models are no longer current after building renovation. Keeping the data of the building up-to-date and checking it against the safety regulations is problematic, although it is critical to support rapid intervention in situation of emergency. Indeed, information about building layouts and indoor objects occupancy is a game-changing support to efficient and safer emergency response in disaster management. Mobile laser scanning (MLS) systems provide such a possibility when their data is post-processed using a smart and fast workflow.</p>
        <p>Recently significant improvements have been made in indoor mobile laser scanning systems [1]. Using a mobile mapping system, it is possible to scan a large multistory building up to 100 rooms in one day.Recently significant improvements have been made in indoor mobile laser scanning systems [1]. Using a mobile mapping system, it is possible to scan a large multistory building up to 100 rooms in one day.</p>
        <p>However, processing the large data produced by an MLS system to reconstruct a 3D model is not a trivial task and needs sophisticated software and expert knowledge. In this article, we present an automatic approach which enables us to produce a coarse 3D model of buildings in a short time. Such models can be further improved and enriched by user interactions to keep the data of large buildings up to date. Safety authorities can use these models to see if the renovated buildings comply with the safety regulations. Moreover, the produced models can be used to support advanced processes such as fine-grained indoor path planning to facilitate efficient emergency response.However, processing the large data produced by an MLS system to reconstruct a 3D model is not a trivial task and needs sophisticated software and expert knowledge. In this article, we present an automatic approach which enables us to produce a coarse 3D model of buildings in a short time. Such models can be further improved and enriched by user interactions to keep the data of large buildings up to date. Safety authorities can use these models to see if the renovated buildings comply with the safety regulations. Moreover, the produced models can be used to support advanced processes such as fine-grained indoor path planning to facilitate efficient emergency response.</p>
        <p>The problem of creating a 3D model from cluttered point clouds attracted many researchers in different domains such as robotics, architecture, engineering and construction. The fact that buildings have varying and complex structures makes the problem challenging. Training computers to learn all types of building structures looks like an unfeasible task. During the last years, researchers developed algorithms that work for less complex buildings or buildings with a regular layout or that only create a 2.5D model [2][3][4][5]. Most of the 3D reconstructed models in the literature reflect simple room segmentation (space subdivision) and a clutter-free environment [2,3] or they rely on having the scanner positions per room [6,7]. In contrast, when a mobile laser scanner is used for data acquisition, the perception of the space is continuous and there is no separate scanning per room. Moreover, the presence of furniture causes occlusion problems, which makes the process of model reconstruction and room separation more challenging. Additionally, slanted walls, ramps and non-horizontal ceiling are other challenges that in most reconstructed indoor models are not addressed.The problem of creating a 3D model from cluttered point clouds attracted many researchers in different domains such as robotics, architecture, engineering and construction. The fact that buildings have varying and complex structures makes the problem challenging. Training computers to learn all types of building structures looks like an unfeasible task. During the last years, researchers developed algorithms that work for less complex buildings or buildings with a regular layout or that only create a 2.5D model [2][3][4][5]. Most of the 3D reconstructed models in the literature reflect simple room segmentation (space subdivision) and a clutter-free environment [2,3] or they rely on having the scanner positions per room [6,7]. In contrast, when a mobile laser scanner is used for data acquisition, the perception of the space is continuous and there is no separate scanning per room. Moreover, the presence of furniture causes occlusion problems, which makes the process of model reconstruction and room separation more challenging. Additionally, slanted walls, ramps and non-horizontal ceiling are other challenges that in most reconstructed indoor models are not addressed.</p>
        <p>In our approach, we first detect the permanent structures such as walls, floors and ceilings adapting the method presented in [8]. With further automatic processing such as undershoot correction, the connection of walls to each other and the ceiling and floor is guaranteed. Volumetric walls are reconstructed by detecting the parallel faces of a wall and merging them into one wall object which is represented by a parametric minimum rectangle. The room segmentation method is based on the correct reconstruction of walls and enclosure of the space in an early stage. We proceed to regularized Boolean operations [9] on the reconstructed permanent structures to reconstruct the room volumes.In our approach, we first detect the permanent structures such as walls, floors and ceilings adapting the method presented in [8]. With further automatic processing such as undershoot correction, the connection of walls to each other and the ceiling and floor is guaranteed. Volumetric walls are reconstructed by detecting the parallel faces of a wall and merging them into one wall object which is represented by a parametric minimum rectangle. The room segmentation method is based on the correct reconstruction of walls and enclosure of the space in an early stage. We proceed to regularized Boolean operations [9] on the reconstructed permanent structures to reconstruct the room volumes.</p>
        <p>Openings are crucial items during a disaster as well as for safety regulations. Doors which are crossed by the trajectory of the mobile laser scanner are detected and added to the model. The combination of all the reconstructed features in addition to their semantic information allows us to apply the flexible space subdivision (FSS) [10], which is a 3D navigation framework that subdivides the indoor space into occupied, functional and navigable spaces. However, in this work, we do not try to enrich the spaces with more semantics, such as room functions, automatically. Furthermore, the automatic detection of furniture type is out of the scope of our work. Some of the large pieces of furniture are selected using a connected component algorithm and an oriented bounding box is generated to present a clearance around the furniture as obstacles. To extract free space in 3D, some floating objects such as lamps are also included. Staircases are another essential element in our 3D models to test the room's connectivity on separate floors. Detecting and modeling stairs or staircases is a complex task because stairs can have versatile structure (e.g., with walls, metal bars or glasses). In our workflow, we explain how first to identify stair ramps and then detect individual steps. Finally, with several constraints, the consistency of the 3D model is evaluated. The navigation graph is generated between a pair of spaces to control the connectivity of all spaces, including doors and stairs. The final navigation graph demonstrates a connectivity network and does not show a turn by turn graph as generating a detailed graph is not the focus of our work.Openings are crucial items during a disaster as well as for safety regulations. Doors which are crossed by the trajectory of the mobile laser scanner are detected and added to the model. The combination of all the reconstructed features in addition to their semantic information allows us to apply the flexible space subdivision (FSS) [10], which is a 3D navigation framework that subdivides the indoor space into occupied, functional and navigable spaces. However, in this work, we do not try to enrich the spaces with more semantics, such as room functions, automatically. Furthermore, the automatic detection of furniture type is out of the scope of our work. Some of the large pieces of furniture are selected using a connected component algorithm and an oriented bounding box is generated to present a clearance around the furniture as obstacles. To extract free space in 3D, some floating objects such as lamps are also included. Staircases are another essential element in our 3D models to test the room's connectivity on separate floors. Detecting and modeling stairs or staircases is a complex task because stairs can have versatile structure (e.g., with walls, metal bars or glasses). In our workflow, we explain how first to identify stair ramps and then detect individual steps. Finally, with several constraints, the consistency of the 3D model is evaluated. The navigation graph is generated between a pair of spaces to control the connectivity of all spaces, including doors and stairs. The final navigation graph demonstrates a connectivity network and does not show a turn by turn graph as generating a detailed graph is not the focus of our work.</p>
        <p>Our pipeline is a combination of algorithms from generating a 3D model from point clouds of multistory buildings to presenting a flexible space subdivision for dynamic navigation. This work goes beyond the simple assumption of a Manhattan-World, vertical walls and a clutterfree environment. Modeling stairs, ramps and slanted ceilings are all integrated into our reconstruction workflow. In contrast to most of the indoor navigation work, which is based on synthetic models, our methods are tested on real complex use cases. Moreover, a consistency control method is applied to check the model correctness against several constraints. The results show that scanning a building with a mobile laser scanner and using our pipeline enables the rapid generation of a coarse 3D model, including spaces for first responders.Our pipeline is a combination of algorithms from generating a 3D model from point clouds of multistory buildings to presenting a flexible space subdivision for dynamic navigation. This work goes beyond the simple assumption of a Manhattan-World, vertical walls and a clutterfree environment. Modeling stairs, ramps and slanted ceilings are all integrated into our reconstruction workflow. In contrast to most of the indoor navigation work, which is based on synthetic models, our methods are tested on real complex use cases. Moreover, a consistency control method is applied to check the model correctness against several constraints. The results show that scanning a building with a mobile laser scanner and using our pipeline enables the rapid generation of a coarse 3D model, including spaces for first responders.</p>
        <p>The contribution of our work is as follows:The contribution of our work is as follows:</p>
        <p>1. A pipeline for 3D reconstruction from point clouds of complex multistory buildings including stairs, ramps and furniture is presented. Reconstruction of non-horizontal floors, ceilings and slanted walls is explained and tested. 2. The pipeline reconstructs both volumetric walls and rooms polyhedra from point clouds. 3. Furniture is included in the subdivision pipeline to demonstrate realistic navigation scenarios in multistory buildings. 4. Several heuristic rules are implemented to check the consistency of generated models.1. A pipeline for 3D reconstruction from point clouds of complex multistory buildings including stairs, ramps and furniture is presented. Reconstruction of non-horizontal floors, ceilings and slanted walls is explained and tested. 2. The pipeline reconstructs both volumetric walls and rooms polyhedra from point clouds. 3. Furniture is included in the subdivision pipeline to demonstrate realistic navigation scenarios in multistory buildings. 4. Several heuristic rules are implemented to check the consistency of generated models.</p>
        <p>The remainder of this article is organized as follows: Section 2 describes related work, Section 3 gives an overview of the pipeline. Section 4 explains the methodology for 3D reconstruction from point clouds, and Section 5 discusses the flexible space subdivision. In Section 6, a consistency control of the 3D model is discussed. In Section 7, our methods are tested on real data and the results are discussed. Section 8 is the future work and the conclusion.The remainder of this article is organized as follows: Section 2 describes related work, Section 3 gives an overview of the pipeline. Section 4 explains the methodology for 3D reconstruction from point clouds, and Section 5 discusses the flexible space subdivision. In Section 6, a consistency control of the 3D model is discussed. In Section 7, our methods are tested on real data and the results are discussed. Section 8 is the future work and the conclusion.</p>
        <p>The topic of indoor 3D reconstruction from point clouds, depth camera images (RGBD) have been studied from different aspects and applications. For example, in the robotic domain, the navigation and interaction of robots with the indoor environment is the goal [11]. Problems such as scene understanding, object detection and localization of robots are investigated by the researchers [11][12][13][14][15][16]. Using images for indoor scene interpretation, façade reconstruction and modeling floor plans are investigated by many researchers [17][18][19][20]. Another upcoming research is change detection in the permanent structures during different epochs of the renovation for example for indoor 3D cadaster applications [21,22]. Besides, the significant progress in wearable mobile laser scanners (WMLS) and indoor mobile mapping systems (IMMS) provides a fast-growing source of data for researches in the domain of indoor modeling [23][24][25].The topic of indoor 3D reconstruction from point clouds, depth camera images (RGBD) have been studied from different aspects and applications. For example, in the robotic domain, the navigation and interaction of robots with the indoor environment is the goal [11]. Problems such as scene understanding, object detection and localization of robots are investigated by the researchers [11][12][13][14][15][16]. Using images for indoor scene interpretation, façade reconstruction and modeling floor plans are investigated by many researchers [17][18][19][20]. Another upcoming research is change detection in the permanent structures during different epochs of the renovation for example for indoor 3D cadaster applications [21,22]. Besides, the significant progress in wearable mobile laser scanners (WMLS) and indoor mobile mapping systems (IMMS) provides a fast-growing source of data for researches in the domain of indoor modeling [23][24][25].</p>
        <p>Reconstruction of walls is an important step to create a correct 3D model. A wall representation in the model depends on the application of the model and 3D modeling standards such as IFC [26] and In-doorGML [27] and those which are not following a specific standard [4]. Volumetric representation and cellular representation of walls are close to IFC and IndoorGML standards, respectively; and suitable for scan-to-BIM applications. Studies which deal with building retrofitting [7,28], indoor navigation [29,30] and automation in construction [31][32][33] are cases based on IFC standards. In contrast, in some of the literature, a piecewise-planar representation of the model generates walls as planar objects [4,29,30,34] and rooms as the polyhedra. Accordingly, the method for room segmentation (also known as space subdivision or space partitioning) would be different. If the application of space is more important than surrounding elements, then a cell decomposition approach or voxel-based method should be suitable for applications such as indoor navigation [10,35] and perception of semantic space for robots [15]. However, if the enclosing elements such as the correct geometry of walls, doors and windows are the goal of a 3D model to be used in BIM software, then the process of reconstruction should pay more attention in generating correct walls and details such as windows [2,7,31].Reconstruction of walls is an important step to create a correct 3D model. A wall representation in the model depends on the application of the model and 3D modeling standards such as IFC [26] and In-doorGML [27] and those which are not following a specific standard [4]. Volumetric representation and cellular representation of walls are close to IFC and IndoorGML standards, respectively; and suitable for scan-to-BIM applications. Studies which deal with building retrofitting [7,28], indoor navigation [29,30] and automation in construction [31][32][33] are cases based on IFC standards. In contrast, in some of the literature, a piecewise-planar representation of the model generates walls as planar objects [4,29,30,34] and rooms as the polyhedra. Accordingly, the method for room segmentation (also known as space subdivision or space partitioning) would be different. If the application of space is more important than surrounding elements, then a cell decomposition approach or voxel-based method should be suitable for applications such as indoor navigation [10,35] and perception of semantic space for robots [15]. However, if the enclosing elements such as the correct geometry of walls, doors and windows are the goal of a 3D model to be used in BIM software, then the process of reconstruction should pay more attention in generating correct walls and details such as windows [2,7,31].</p>
        <p>In most of the literature, there are several main assumptions when detecting and reconstructing the permanent structures. One general assumption is based on vertical walls [28,32,[36][37][38] and regular room layout (Manhattan assumption) [2,23,32]. For the detection and the reconstruction of the floor or ceiling, it is presumed that the height is not changing [5,7]. There are few works which explore beyond the Manhattan World assumptions [6] and deal with the 3D environment with a high number of reflective surfaces [8,40].In most of the literature, there are several main assumptions when detecting and reconstructing the permanent structures. One general assumption is based on vertical walls [28,32,[36][37][38] and regular room layout (Manhattan assumption) [2,23,32]. For the detection and the reconstruction of the floor or ceiling, it is presumed that the height is not changing [5,7]. There are few works which explore beyond the Manhattan World assumptions [6] and deal with the 3D environment with a high number of reflective surfaces [8,40].</p>
        <p>Doors are essential for disaster management, indoor navigation and checking the regulations for safety in a building. Detection of doors is studied by [40][41][42][43] for 3D reconstruction and navigation. Experimentally, identifying open doors in the data is less complex than closed doors. Ray casting (also known as the occlusion reasoning) is one of the solutions which is used by [7,41,44] to detect openings (windows and doors). By this method, a ray is cast from the position of the laser scanner to the surface where a door or opening can be identified. If the ray intersects the surface and hits an object behind the surface, then the intersection point on the surface is labeled as an opening pixel.Doors are essential for disaster management, indoor navigation and checking the regulations for safety in a building. Detection of doors is studied by [40][41][42][43] for 3D reconstruction and navigation. Experimentally, identifying open doors in the data is less complex than closed doors. Ray casting (also known as the occlusion reasoning) is one of the solutions which is used by [7,41,44] to detect openings (windows and doors). By this method, a ray is cast from the position of the laser scanner to the surface where a door or opening can be identified. If the ray intersects the surface and hits an object behind the surface, then the intersection point on the surface is labeled as an opening pixel.</p>
        <p>However, the exact border of the opening remains unclear in ray casting method depending on the resolution of data. To detect closed doors, [43] uses images in combination with point clouds. In the absence of images and color for the data, an altered method is required to identify closed doors. In a different approach, applicable for mobile laser scanners, [40] and [45,46] use the trajectory of the mobile laser scanner to find the points above the trajectory which represent the top of the door and to locate the door frame. Using their method is possible to identify closed and open doors which are crossed by the MLS trajectory.However, the exact border of the opening remains unclear in ray casting method depending on the resolution of data. To detect closed doors, [43] uses images in combination with point clouds. In the absence of images and color for the data, an altered method is required to identify closed doors. In a different approach, applicable for mobile laser scanners, [40] and [45,46] use the trajectory of the mobile laser scanner to find the points above the trajectory which represent the top of the door and to locate the door frame. Using their method is possible to identify closed and open doors which are crossed by the MLS trajectory.</p>
        <p>Stair modeling is another challenge in the reconstruction of a multistory building. Although less attention is devoted to the detection and the modeling of stairs and their surroundings, they are considered a complex but yet important structure of a building. Stairs can be modeled using shape grammars since they have a regular structure [47,48]. Another approach is by fitting a slanted plane to the stair ramp and finding the orientation and extension of the stairs [49]. A plane segmentation method is used by [50] to model stairs for humanoid climbing stairs. When using a wearable mobile laser scanner such as a backpack, it is possible to use the trajectory to detect the stairs [8,51]. Other methods are developed for stair modeling, pathfinding and robotics based on voxels, octree and histograms [52,53].Stair modeling is another challenge in the reconstruction of a multistory building. Although less attention is devoted to the detection and the modeling of stairs and their surroundings, they are considered a complex but yet important structure of a building. Stairs can be modeled using shape grammars since they have a regular structure [47,48]. Another approach is by fitting a slanted plane to the stair ramp and finding the orientation and extension of the stairs [49]. A plane segmentation method is used by [50] to model stairs for humanoid climbing stairs. When using a wearable mobile laser scanner such as a backpack, it is possible to use the trajectory to detect the stairs [8,51]. Other methods are developed for stair modeling, pathfinding and robotics based on voxels, octree and histograms [52,53].</p>
        <p>From navigation aspects, many works have been carried out on presenting the conceptual models and standardization of navigation [29,54]. Unfortunately, less attention is devoted to using cluttered data in complex environment for indoor modeling. Most of the 3D models for indoor navigation are simple and based on synthetic models [55] or represent simple cases such as shortest path [56][57][58]. In a different approach by [59], the access right is used for indoor navigation. This is a new approach to design more flexible navigation routs. Similarly but with a different approach, [10] introduces the flexible space subdivision (FSS) concept for dynamic use of the space and context-aware pathfinding. Based on their method, space can have different functions and based on each function, a navigation graph can be generated.From navigation aspects, many works have been carried out on presenting the conceptual models and standardization of navigation [29,54]. Unfortunately, less attention is devoted to using cluttered data in complex environment for indoor modeling. Most of the 3D models for indoor navigation are simple and based on synthetic models [55] or represent simple cases such as shortest path [56][57][58]. In a different approach by [59], the access right is used for indoor navigation. This is a new approach to design more flexible navigation routs. Similarly but with a different approach, [10] introduces the flexible space subdivision (FSS) concept for dynamic use of the space and context-aware pathfinding. Based on their method, space can have different functions and based on each function, a navigation graph can be generated.</p>
        <p>Consistency control of the 3D model after reconstruction is not investigated sufficiently in the literature. Just few researchers [60][61][62] suggest methods such as using grammar to control the topology and correctness of the generated model. The consistency of 3D city modeling [60] can be applied for indoor modeling in some cases. In [62], a probabilistic grammar is used to generate consistent semantic information of an indoor scene. A constrained grammar is suggested by [61] for controlling the correctness of a model-driven model. However, the authors do not use real data to demonstrate the robustness of their method. Validating the 3D model from semantic and geometry aspects is an important line of research that needs more attention in the future.Consistency control of the 3D model after reconstruction is not investigated sufficiently in the literature. Just few researchers [60][61][62] suggest methods such as using grammar to control the topology and correctness of the generated model. The consistency of 3D city modeling [60] can be applied for indoor modeling in some cases. In [62], a probabilistic grammar is used to generate consistent semantic information of an indoor scene. A constrained grammar is suggested by [61] for controlling the correctness of a model-driven model. However, the authors do not use real data to demonstrate the robustness of their method. Validating the 3D model from semantic and geometry aspects is an important line of research that needs more attention in the future.</p>
        <p>In this section, we give a general overview of the 3D reconstruction pipeline and its application for emergency cases. Fig. 1 shows the overview of steps (stairs modeling is not reflected and is explained in detail in Section 4.5). To keep the overview short, important parameters are discussed in the methodology and at the end of the article in Section 6.In this section, we give a general overview of the 3D reconstruction pipeline and its application for emergency cases. Fig. 1 shows the overview of steps (stairs modeling is not reflected and is explained in detail in Section 4.5). To keep the overview short, important parameters are discussed in the methodology and at the end of the article in Section 6.</p>
        <p>Fig. 1 shows the main steps of the pipeline:Fig. 1 shows the main steps of the pipeline:</p>
        <p>• Input point clouds and the trajectory (if available). The input data of our pipeline is a point cloud collected by mobile laser scanning (MLS) or terrestrial laser scanning systems (TLS). When the data is collected by an MLS the trajectory of the system is required for some of the algorithms (e.g. building levels separation and door detection). Each dataset is subsampled to reduce the number of points to accelerate the processing time and for a smoother visualization. The minimum point spacing of 0.05 is used in down sampling (Fig. 1a).• Input point clouds and the trajectory (if available). The input data of our pipeline is a point cloud collected by mobile laser scanning (MLS) or terrestrial laser scanning systems (TLS). When the data is collected by an MLS the trajectory of the system is required for some of the algorithms (e.g. building levels separation and door detection). Each dataset is subsampled to reduce the number of points to accelerate the processing time and for a smoother visualization. The minimum point spacing of 0.05 is used in down sampling (Fig. 1a).</p>
        <p>• The pipeline starts with separating the building levels and stairs.• The pipeline starts with separating the building levels and stairs.</p>
        <p>Similar to [8], the trajectory is segmented to horizontal and sloped segments, where each horizontal and sloped segment represents the levels and stairs, respectively (Fig. 1b). Each segment in the trajectory is used to cluster the associated point in the point cloud belonging to the same level or to the staircase in case of sloped segments, see Section 4.1 for more details.Similar to [8], the trajectory is segmented to horizontal and sloped segments, where each horizontal and sloped segment represents the levels and stairs, respectively (Fig. 1b). Each segment in the trajectory is used to cluster the associated point in the point cloud belonging to the same level or to the staircase in case of sloped segments, see Section 4.1 for more details.</p>
        <p>• An adjacency graph is created based on the adjacency of planar segments with the minimum supporting points of 500 where nodes represent the segments (Fig. 1c). Analyzing the topology relation of nodes in the graph using suggested heuristic rules result in labeled segments to permanent structures (including wall, floor and ceiling) and clutter containing unknown points and furniture (Fig. 1d).• An adjacency graph is created based on the adjacency of planar segments with the minimum supporting points of 500 where nodes represent the segments (Fig. 1c). Analyzing the topology relation of nodes in the graph using suggested heuristic rules result in labeled segments to permanent structures (including wall, floor and ceiling) and clutter containing unknown points and furniture (Fig. 1d).</p>
        <p>• Parallel wall surfaces are recognized and merged into one segment as a volumetric wall which is represented by a parametric rectangle. Fig. 1e shows volumetric walls represented by boxes as solids. To this end, the permanent structure of the building is reconstructed in a 3D model showing the walls, floor and ceiling. However, for emergency responses, the notion of rooms is required in addition to knowledge about doors, obstacles and access to the stairs (Fig. 1e).• Parallel wall surfaces are recognized and merged into one segment as a volumetric wall which is represented by a parametric rectangle. Fig. 1e shows volumetric walls represented by boxes as solids. To this end, the permanent structure of the building is reconstructed in a 3D model showing the walls, floor and ceiling. However, for emergency responses, the notion of rooms is required in addition to knowledge about doors, obstacles and access to the stairs (Fig. 1e).</p>
        <p>• We exploit the trajectory of the MLS device to detect the doors. A method from [40] is adopted where the doors crossed by the trajectory can be identified and a parametric door model with fixed dimensions is added to the model (Fig. 1f).• We exploit the trajectory of the MLS device to detect the doors. A method from [40] is adopted where the doors crossed by the trajectory can be identified and a parametric door model with fixed dimensions is added to the model (Fig. 1f).</p>
        <p>• Section 5 is dealing with reconstructing the rooms' polyhedra from permanent structures and when adding the furniture, extracting the remaining spaces as navigable space. Rooms modeling is based on a 3D Boolean Operations on solids to extract the enclosed spaces encapsulated by permanent structures. Each permanent structure (wall, floor and ceiling) is a solid which was reconstructed in Section 4. In Fig. 1, room extraction is applied in Fig. 1e and the result is shown in Fig. 1g.• Section 5 is dealing with reconstructing the rooms' polyhedra from permanent structures and when adding the furniture, extracting the remaining spaces as navigable space. Rooms modeling is based on a 3D Boolean Operations on solids to extract the enclosed spaces encapsulated by permanent structures. Each permanent structure (wall, floor and ceiling) is a solid which was reconstructed in Section 4. In Fig. 1, room extraction is applied in Fig. 1e and the result is shown in Fig. 1g.</p>
        <p>• Following reconstruction of the rooms, by including the bounding box of furniture in the model, it is possible to apply the flexible space subdivision [10] framework (FSS) and identify the object spaces (O-Spaces), functional spaces (F-Spaces) and remaining spaces (R-Space). Unlike [10] which uses simulated data to demonstrate the FSS for 3D indoor navigation, we use real data created from point clouds reflecting the as-built situation of the buildings (Fig. 1h).• Following reconstruction of the rooms, by including the bounding box of furniture in the model, it is possible to apply the flexible space subdivision [10] framework (FSS) and identify the object spaces (O-Spaces), functional spaces (F-Spaces) and remaining spaces (R-Space). Unlike [10] which uses simulated data to demonstrate the FSS for 3D indoor navigation, we use real data created from point clouds reflecting the as-built situation of the buildings (Fig. 1h).</p>
        <p>• Finally, three heuristic rules are suggested to control the consistency of the model for emergency applications. Based on those rules, every room should have at least one door and every two spaces in the model at different levels should be connected by a network in the connectivity graph (Fig. 1i).• Finally, three heuristic rules are suggested to control the consistency of the model for emergency applications. Based on those rules, every room should have at least one door and every two spaces in the model at different levels should be connected by a network in the connectivity graph (Fig. 1i).</p>
        <p>The results are evaluated on four datasets where the buildings have complex structures including arbitrary room layout, non-horizontal ceilings, ramps, and glass surfaces. The following sections discuss the methods in detail.The results are evaluated on four datasets where the buildings have complex structures including arbitrary room layout, non-horizontal ceilings, ramps, and glass surfaces. The following sections discuss the methods in detail.</p>
        <p>Our pipeline starts with preparing the data for the detection of permanent structures. Walls, floors and ceilings are the main focus of the permanent structure detection algorithm. Later other important objects such as doors, stairs and furniture will be automatically identified and included in the model. The data is mainly collected by MLS devices, including pushing-cart and handheld systems. The trajectory of the mobile laser scanner is a useful source to interpret the scene, for example, for separating the levels of buildings in case of a multistory building. The data preparation is mainly purging the noise caused by the reflective surfaces, as explained in [40]. The process of classification of point clouds to walls, floors and ceilings starts by a piecewise planar segmentation and then creating an adjacency graph. A heuristic method [8] is applied to analyze the adjacency graph to separate the permanent structure from the clutter. Furniture is classified as the clutter in our pipeline. In the following, the methods are explained in the details.Our pipeline starts with preparing the data for the detection of permanent structures. Walls, floors and ceilings are the main focus of the permanent structure detection algorithm. Later other important objects such as doors, stairs and furniture will be automatically identified and included in the model. The data is mainly collected by MLS devices, including pushing-cart and handheld systems. The trajectory of the mobile laser scanner is a useful source to interpret the scene, for example, for separating the levels of buildings in case of a multistory building. The data preparation is mainly purging the noise caused by the reflective surfaces, as explained in [40]. The process of classification of point clouds to walls, floors and ceilings starts by a piecewise planar segmentation and then creating an adjacency graph. A heuristic method [8] is applied to analyze the adjacency graph to separate the permanent structure from the clutter. Furniture is classified as the clutter in our pipeline. In the following, the methods are explained in the details.</p>
        <p>Every level of a building is a horizontal space which is connected via stairs to the other levels. In complex buildings, sometimes space is extended vertically to the other levels and in the architecture is referred to as a Mezzanine. Therefore merely using a histogram generated from zaxis [38,63] is not sufficient to separate the floors. Moreover, distributed points over the z-value in a sloped ceiling do not create a pick in the z-histogram. Nikoohemat et al. [8] suggest using the MLS trajectory to separate the point clouds associated to each level of the trajectory because separating the trajectory of the MLS into the levels is simpler than separating the point clouds. Their method is based on using the trajectory and the timestamp attribute which is synchronized with the timestamp in the point clouds. Obviously, this method can be only used for mobile laser scanners because they have a trajectory and the time attribute is available in both point clouds and the trajectory. The trajectory is a separate point set representing the discrete positions of the laser scanner during the data acquisition. By segmenting the trajectory to separated levels and slopes (representing the stair's ramps) the associated point cloud can be segmented as well using the timestamp for each segment of the trajectory. Segments in the trajectory with slopes are selected to collect associated points with the stairs. After separation of levels and stairs, each set is processed separately for detection of permanent structures.Every level of a building is a horizontal space which is connected via stairs to the other levels. In complex buildings, sometimes space is extended vertically to the other levels and in the architecture is referred to as a Mezzanine. Therefore merely using a histogram generated from zaxis [38,63] is not sufficient to separate the floors. Moreover, distributed points over the z-value in a sloped ceiling do not create a pick in the z-histogram. Nikoohemat et al. [8] suggest using the MLS trajectory to separate the point clouds associated to each level of the trajectory because separating the trajectory of the MLS into the levels is simpler than separating the point clouds. Their method is based on using the trajectory and the timestamp attribute which is synchronized with the timestamp in the point clouds. Obviously, this method can be only used for mobile laser scanners because they have a trajectory and the time attribute is available in both point clouds and the trajectory. The trajectory is a separate point set representing the discrete positions of the laser scanner during the data acquisition. By segmenting the trajectory to separated levels and slopes (representing the stair's ramps) the associated point cloud can be segmented as well using the timestamp for each segment of the trajectory. Segments in the trajectory with slopes are selected to collect associated points with the stairs. After separation of levels and stairs, each set is processed separately for detection of permanent structures.</p>
        <p>Permanent structures are walls, floor and ceilings. Intuitively, walls are below the adjacent ceiling and above the adjacent floors. In contrast to the other works that assume walls are vertical and ceilings and floors are horizontal [4,28,39], we lift these constraints in our pipeline. Moreover, any arbitrary wall structure can be used as input to the algorithm and there is no need to align the data to the axis (non-Manhattan-World). The only assumption is the z-axis as the gravitational axis.Permanent structures are walls, floor and ceilings. Intuitively, walls are below the adjacent ceiling and above the adjacent floors. In contrast to the other works that assume walls are vertical and ceilings and floors are horizontal [4,28,39], we lift these constraints in our pipeline. Moreover, any arbitrary wall structure can be used as input to the algorithm and there is no need to align the data to the axis (non-Manhattan-World). The only assumption is the z-axis as the gravitational axis.</p>
        <p>To create an adjacency graph G (V, E), the point clouds are segmented using a planar surface growing algorithm [64]. Each node (V) in the graph is associated with a segment, and each edge (E) represents two adjacent segments (Fig. 2). Two segments are adjacent if their points are within a specific distance defined as the adjacency distance (d adj ). Then all the nodes in the graph are attributed to almost-vertical and almost-horizontal based on the normal vector angle of their segments using a threshold of 45°. For example, the nodes which the difference between the normal vector angle of their segment and the positive direction of z-axis is &lt; 45°are attributed as almost-horizontal. After creating the adjacency graph, we use several heuristic rules according to [8] to label the nodes and their associated segments. Four labels are considered for the nodes: walls, floors, ceilings and clutter. In the adjacency graph, each node is examined one time and based on the number of edges and their attributes; the node obtains a label. Rule 1 suggests that if a node has one or more than one wall-ceiling edge, then it is a wall. Rule 2 and rule 3 suggest if a node has more than two wallceiling or more than two wall-floor edges, then it is a ceiling or floor, respectively. Clearly, a node with a floor or ceiling label should not have any wall-wall edge. Some extra soft rules control the labeling process to avoid false-positive detections. For example, almost-horizontal segments which are labeled as a ceiling should not have &gt; 90% overlap with each other. This soft rule excludes some horizontal segments such as ventilation canals and shelves near the ceiling or tables which are attached to walls to be classified as a permanent structure. Moreover, the floor and ceiling nodes should have a distance of &gt; 1.5 m. The label of each node is assigned to the associated points in the segment. Consequently, the output of the adjacency graph is labeled point clouds with four different classes as walls, floors, ceiling and clutter. Note that creating the adjacency graph and exploiting it to identify the permanent structures are not restricted to the assumption of vertical walls or horizontal floor and ceiling. Slanted walls, ceilings and ramps can be identified as well by analyzing the adjacency graph. For example, in the TU Delft building (Fig. 3) part of the floor is lowered, and it is connected with two ramps to other floors. Since the ramp is classified as an almost-horizontal surface and is connected to other floors, it can be classified and modeled as part of the floor. The next step is generating the volumetric walls for a watertight 3D model.To create an adjacency graph G (V, E), the point clouds are segmented using a planar surface growing algorithm [64]. Each node (V) in the graph is associated with a segment, and each edge (E) represents two adjacent segments (Fig. 2). Two segments are adjacent if their points are within a specific distance defined as the adjacency distance (d adj ). Then all the nodes in the graph are attributed to almost-vertical and almost-horizontal based on the normal vector angle of their segments using a threshold of 45°. For example, the nodes which the difference between the normal vector angle of their segment and the positive direction of z-axis is &lt; 45°are attributed as almost-horizontal. After creating the adjacency graph, we use several heuristic rules according to [8] to label the nodes and their associated segments. Four labels are considered for the nodes: walls, floors, ceilings and clutter. In the adjacency graph, each node is examined one time and based on the number of edges and their attributes; the node obtains a label. Rule 1 suggests that if a node has one or more than one wall-ceiling edge, then it is a wall. Rule 2 and rule 3 suggest if a node has more than two wallceiling or more than two wall-floor edges, then it is a ceiling or floor, respectively. Clearly, a node with a floor or ceiling label should not have any wall-wall edge. Some extra soft rules control the labeling process to avoid false-positive detections. For example, almost-horizontal segments which are labeled as a ceiling should not have &gt; 90% overlap with each other. This soft rule excludes some horizontal segments such as ventilation canals and shelves near the ceiling or tables which are attached to walls to be classified as a permanent structure. Moreover, the floor and ceiling nodes should have a distance of &gt; 1.5 m. The label of each node is assigned to the associated points in the segment. Consequently, the output of the adjacency graph is labeled point clouds with four different classes as walls, floors, ceiling and clutter. Note that creating the adjacency graph and exploiting it to identify the permanent structures are not restricted to the assumption of vertical walls or horizontal floor and ceiling. Slanted walls, ceilings and ramps can be identified as well by analyzing the adjacency graph. For example, in the TU Delft building (Fig. 3) part of the floor is lowered, and it is connected with two ramps to other floors. Since the ramp is classified as an almost-horizontal surface and is connected to other floors, it can be classified and modeled as part of the floor. The next step is generating the volumetric walls for a watertight 3D model.</p>
        <p>The labeled segments from the previous section need to be visually inspected to avoid unexpected errors. For example, some of the clutter attached to the ceiling could be misclassified as a wall. Similar to [6], the visual inspection contains two main operations: 1. changing the label of a misclassified segment, 2. extension of two segments to the intersection of their planes in case of large data missing. The first correction is a semantic refinement and the second correction is a geometry refinement. Since the segments are color-coded based on their semantic label (Fig. 3b, green and blue), changing the class label is quick and it takes several minutes for a dataset of 20 rooms. The extension correction is performed after the automatic undershoot correction (Section 4.2.3), where the gap between two segments is larger than the extension threshold. This correction happens in rare cases where part of the data is missing because of large occlusions or unreachable regions in the room (Fig. 3b, dashed circles).The labeled segments from the previous section need to be visually inspected to avoid unexpected errors. For example, some of the clutter attached to the ceiling could be misclassified as a wall. Similar to [6], the visual inspection contains two main operations: 1. changing the label of a misclassified segment, 2. extension of two segments to the intersection of their planes in case of large data missing. The first correction is a semantic refinement and the second correction is a geometry refinement. Since the segments are color-coded based on their semantic label (Fig. 3b, green and blue), changing the class label is quick and it takes several minutes for a dataset of 20 rooms. The extension correction is performed after the automatic undershoot correction (Section 4.2.3), where the gap between two segments is larger than the extension threshold. This correction happens in rare cases where part of the data is missing because of large occlusions or unreachable regions in the room (Fig. 3b, dashed circles).</p>
        <p>An undershoot error happens when two permanent structures are not connected either because of the occlusion or missing data during the scanning. These disjoint structures (segments) should be connected to reconstruct a topologically correct 3D model (Fig. 3b, red circles). Finding undershoots in the data is not simple and fixing them needs a user interface and an expert user. Therefore, we find and fix undershoots automatically. First, for each segment, an oriented minimum rectangle is generated and the best fitting plane of the segment is calculated from the supporting points. For the automatic correction of undershoots, all the rectangles are sorted by their area. Every two nearby rectangles are intersected using their planes if the intersection line is within a distance of the edges of each rectangle, then two rectangles are extended to the intersection line (Fig. 3c). The extension threshold (d ext ) should not be larger than a narrow hallway. Otherwise, the walls on two sides of the hallway will be incorrectly extended. For example, the corridor in Fig. 3 has a width of almost three meters and the extension threshold is set to less than three meters. Consequently, an extension operation is required in the location of dashed black circles in Fig. 3b. Experimentally, running the undershoot correction process for each semantic class separately results in a better outcome. We perform the algorithm first individually per class wall, floor and ceiling, then between wall and ceiling, and wall and floor.An undershoot error happens when two permanent structures are not connected either because of the occlusion or missing data during the scanning. These disjoint structures (segments) should be connected to reconstruct a topologically correct 3D model (Fig. 3b, red circles). Finding undershoots in the data is not simple and fixing them needs a user interface and an expert user. Therefore, we find and fix undershoots automatically. First, for each segment, an oriented minimum rectangle is generated and the best fitting plane of the segment is calculated from the supporting points. For the automatic correction of undershoots, all the rectangles are sorted by their area. Every two nearby rectangles are intersected using their planes if the intersection line is within a distance of the edges of each rectangle, then two rectangles are extended to the intersection line (Fig. 3c). The extension threshold (d ext ) should not be larger than a narrow hallway. Otherwise, the walls on two sides of the hallway will be incorrectly extended. For example, the corridor in Fig. 3 has a width of almost three meters and the extension threshold is set to less than three meters. Consequently, an extension operation is required in the location of dashed black circles in Fig. 3b. Experimentally, running the undershoot correction process for each semantic class separately results in a better outcome. We perform the algorithm first individually per class wall, floor and ceiling, then between wall and ceiling, and wall and floor.</p>
        <p>The goal of this section is to reconstruct volumetric walls from wall segments. A volumetric wall is composed of smaller segments on both Fig. 2. The process of identifying a permanent structure. (a) Point clouds, (b) points segmented using the surface growing algorithm, (c) intersection between adjacent segments, (d) and (e) the adjacency graph where edges are colored by three classes (wall, floor and ceiling), (f) detected walls (blue) and floor (yellow). For simplicity of the figure, an area with minimal clutter is selected. The dataset is acquired by NavVis Trolley system [65]. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.) sides of a wall and in this part of the pipeline the algorithm identifies which segments belong to the same wall. In the previous step, wall segments are corrected by automatic undershoot correction. A correct 3D model should have consistent room layout and topology, which means there should not be a gap between rooms. In this step, we reconstruct the walls by detecting two parallel faces of a wall and merging them into one volumetric wall. A volumetric wall is a parametric object containing width, height, length, normal vector and center. The width represents the thickness of the wall and the height and length define the spatial extension of the wall. The normal vector and the center identify the orientation and location of the wall. To reconstruct a volumetric wall, every two rectangles are checked together. A new rectangle is created from nearby parallel (d, θ) rectangles, where the d is the distance between two planes, calculated from the center of the smaller segment to the plane of the larger segment, and the θ is the angle between normals (Fig. 4a andb). The parameters of the new rectangle should be recalculated in a way that spatial extensions are extracted from the larger face and the width is the distance between two parallel faces (d). The normal vector and the center of the new rectangle are obtained by computing the weighted average of the normal vectors and of the centers of the two faces based on their area. Note that in practice because of the clutter and the occlusion in the data, on each face of the wall there could be more than one segment which should be merged into one rectangle based on their proximity and co-planarity. Therefore, one face of the wall can grow larger and other smaller co-planar faces are merged into it and each time parameters are updated.The goal of this section is to reconstruct volumetric walls from wall segments. A volumetric wall is composed of smaller segments on both Fig. 2. The process of identifying a permanent structure. (a) Point clouds, (b) points segmented using the surface growing algorithm, (c) intersection between adjacent segments, (d) and (e) the adjacency graph where edges are colored by three classes (wall, floor and ceiling), (f) detected walls (blue) and floor (yellow). For simplicity of the figure, an area with minimal clutter is selected. The dataset is acquired by NavVis Trolley system [65]. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.) sides of a wall and in this part of the pipeline the algorithm identifies which segments belong to the same wall. In the previous step, wall segments are corrected by automatic undershoot correction. A correct 3D model should have consistent room layout and topology, which means there should not be a gap between rooms. In this step, we reconstruct the walls by detecting two parallel faces of a wall and merging them into one volumetric wall. A volumetric wall is a parametric object containing width, height, length, normal vector and center. The width represents the thickness of the wall and the height and length define the spatial extension of the wall. The normal vector and the center identify the orientation and location of the wall. To reconstruct a volumetric wall, every two rectangles are checked together. A new rectangle is created from nearby parallel (d, θ) rectangles, where the d is the distance between two planes, calculated from the center of the smaller segment to the plane of the larger segment, and the θ is the angle between normals (Fig. 4a andb). The parameters of the new rectangle should be recalculated in a way that spatial extensions are extracted from the larger face and the width is the distance between two parallel faces (d). The normal vector and the center of the new rectangle are obtained by computing the weighted average of the normal vectors and of the centers of the two faces based on their area. Note that in practice because of the clutter and the occlusion in the data, on each face of the wall there could be more than one segment which should be merged into one rectangle based on their proximity and co-planarity. Therefore, one face of the wall can grow larger and other smaller co-planar faces are merged into it and each time parameters are updated.</p>
        <p>Façade walls and walls which are not accessible from both sides (e.g., because of the occlusion) only have one face in the data. In such cases the measured face is offset to the opposite direction of the normal, assuming the normal vectors are flipped towards the position of the laser scanner. The offset distance can be user-defined or can be extracted from the neighboring walls. The floor and ceiling are reconstructed with a user-defined thickness. For multistory buildings, the thickness of the ceiling of the lower level can be calculated from the floor of the upper level. Volumetric reconstruction of walls, floors and ceiling assures that no empty space is generated between the levels of a building or the rooms of the same level.Façade walls and walls which are not accessible from both sides (e.g., because of the occlusion) only have one face in the data. In such cases the measured face is offset to the opposite direction of the normal, assuming the normal vectors are flipped towards the position of the laser scanner. The offset distance can be user-defined or can be extracted from the neighboring walls. The floor and ceiling are reconstructed with a user-defined thickness. For multistory buildings, the thickness of the ceiling of the lower level can be calculated from the floor of the upper level. Volumetric reconstruction of walls, floors and ceiling assures that no empty space is generated between the levels of a building or the rooms of the same level.</p>
        <p>Doors in our model are the openings which connect two spaces. Since we use an MLS device to collect the data, at least one of the doors of each visited room is crossed by the trajectory of the mobile laser scanner. Crossing the door with the trajectory is exploited by [40] to detect doors. This method can be specifically useful even if the door appears as a closed-door in the data because a door can be closed before or after scanning. However, their method is for the cases that walls are unknown in the data and for detecting doors in the whole unlabeled point clouds. Since the walls are known for us, we adapt their method and intersect the detected walls with the trajectory to identify the approximate center of a door candidate. Before that, the trajectory should be sorted by using the time attribute and be converted to line segments by connecting the successive points (Fig. 5b). Note that the intersection point necessarily is not in the center of the door, but it gives an estimation of the door location. Obviously, doors which are not traversed by the trajectory during the scanning, remain unidentified in our method. Some researchers [40,41] use ray casting to detect openings, but we limit the scope of our work to the doors crossed by the trajectory, which is sufficient for navigation purposes. After detecting the location of the door, an oriented bounding box aligned with the direction of the wall is inserted in the model. The extension of the door (height and width) is user defined and the thickness is inherited from the wall thickness. Therefore, a double door and a single door are modeled the same in our 3D model.Doors in our model are the openings which connect two spaces. Since we use an MLS device to collect the data, at least one of the doors of each visited room is crossed by the trajectory of the mobile laser scanner. Crossing the door with the trajectory is exploited by [40] to detect doors. This method can be specifically useful even if the door appears as a closed-door in the data because a door can be closed before or after scanning. However, their method is for the cases that walls are unknown in the data and for detecting doors in the whole unlabeled point clouds. Since the walls are known for us, we adapt their method and intersect the detected walls with the trajectory to identify the approximate center of a door candidate. Before that, the trajectory should be sorted by using the time attribute and be converted to line segments by connecting the successive points (Fig. 5b). Note that the intersection point necessarily is not in the center of the door, but it gives an estimation of the door location. Obviously, doors which are not traversed by the trajectory during the scanning, remain unidentified in our method. Some researchers [40,41] use ray casting to detect openings, but we limit the scope of our work to the doors crossed by the trajectory, which is sufficient for navigation purposes. After detecting the location of the door, an oriented bounding box aligned with the direction of the wall is inserted in the model. The extension of the door (height and width) is user defined and the thickness is inherited from the wall thickness. Therefore, a double door and a single door are modeled the same in our 3D model.</p>
        <p>Including furniture in the model is useful for creating an insightful space subdivision that considers potential obstacles. In case of emergency, the auditing experts can evaluate if there is enough navigable area in one space or whether the emergency exits are not occluded by furniture. In our work, the furniture is classified as clutter in Section 4.2. We include the larger pieces of furniture by using a connected component analysis (CCA). The CCA is established by considering two points as connected if their distance is less than a threshold (10 cm) and giving each connected component a unique id. Before starting with CCA, the cluttered points in a neighborhood of the permanent structure are removed to make a clearance between furniture and adjacent permanent structures. Then a connected component analysis is applied to the remaining points. A maximum distance threshold of 10 cm between points is set for this analysis, noticing that this threshold should be larger than the average point distance and smaller than the clearance between furniture and the permanent structures. The components with a larger number of points are chosen as the obstacles to be included in the model. The reason that we make a selection is that there is a lot of clutter near the ceiling or on the walls, such as pipes, small lamps, shelves, curtains or noise from reflection, which make the space subdivision cluttered. An oriented bounding box (OBB) is generated from each object and included in the model representing the occupied space with the furniture (Fig. 6).Including furniture in the model is useful for creating an insightful space subdivision that considers potential obstacles. In case of emergency, the auditing experts can evaluate if there is enough navigable area in one space or whether the emergency exits are not occluded by furniture. In our work, the furniture is classified as clutter in Section 4.2. We include the larger pieces of furniture by using a connected component analysis (CCA). The CCA is established by considering two points as connected if their distance is less than a threshold (10 cm) and giving each connected component a unique id. Before starting with CCA, the cluttered points in a neighborhood of the permanent structure are removed to make a clearance between furniture and adjacent permanent structures. Then a connected component analysis is applied to the remaining points. A maximum distance threshold of 10 cm between points is set for this analysis, noticing that this threshold should be larger than the average point distance and smaller than the clearance between furniture and the permanent structures. The components with a larger number of points are chosen as the obstacles to be included in the model. The reason that we make a selection is that there is a lot of clutter near the ceiling or on the walls, such as pipes, small lamps, shelves, curtains or noise from reflection, which make the space subdivision cluttered. An oriented bounding box (OBB) is generated from each object and included in the model representing the occupied space with the furniture (Fig. 6).</p>
        <p>Although the coarse location of staircases can be separated from the rest of the point clouds, the number of steps and the exact model of the stairs need to be reconstructed. Therefore, we develop a method using the adjacency graph G (V, E) to detect the exact size and location of stairs. Our method for stair modeling has two steps: 1. similar to [49] a planar segmentation [66] is employed to search the ramp of the stairs (Fig. 7b); 2. a fine planar segmentation is applied on the detected ramp to identify planar segments representing each rise and tread in the stairs (Fig. 7c). A planar segment is a valid staircase ramp if it inclines between 25 and 50°are respecting the xy-plane. For the planar segmentation of the ramp a surface growing algorithm is applied with a pointto-plane distance set to 20 cm. We choose a larger value for planar segmentation for ramp detection to make sure points belonging to the steps fall into the ramp segment. A minimum enclosing rectangle is created for each valid ramp and the inliers (considering a buffer) would be the points which will be processed in the second step (see Fig. 7b). The risers and treads should be identified in this ramp. In the second step, a surface growing segmentation with finer parameters (point-toplane distance = 5 cm) generates the segments which represent the nodes (V) in the adjacency graph (see Fig. 7c). If two segments are adjacent and create a perpendicular angle with a threshold of 10°, then an edge (e ϵ E) connects two nodes. Smaller segments with fewer than n supporting points (e.g., n = 500 points) are excluded from the graph. On the stairs, there is clutter (e.g., people during the scanning), and walls and bars are attached to the steps. Therefore, to extract the exact steps which form the stairs, the longest path is extracted from the undirected graph [67]. We start from a random node (v ϵ V) and find a node (x ϵ V) with the longest distance from v using a breadth-first search (BFS). The discovered node x is an end node in the graph. By applying another breadth-first search from node x, the longest path in the graph is identified (see Fig. 7d). Note that the edges are unweighted and the graph should not have cycles. Nodes belonging to the longest path represent the steps of the stairs. For each node, the corresponding segment is selected, and a minimum enclosing rectangle is derived. Since the shape and size of the segments are varied, the width and length of a step are approximated from the majority of the rectangles. Then all the rectangles are adjusted with the new width and length. To extract the number of steps, as every step of stairs has two nodes in the graph, one for the riser and one for the tread, the number of steps is the round of n / 2 where n is the number of nodes in the longest path. Eventually, vertical space is generated from the minimum rectangle of the stairs, which represents the staircase space. This vertical space is a virtual space that connects the levels in a building with an extension from the floor of the lower level to the floor of the upper level. Note that in most buildings, the surrounding walls of stairs are not connected to the ceiling and sometimes they are made of metal bars or glass. Therefore, we create this virtual space to subdivide the space of stairs from other spaces for navigation purposes. Although, the stair modeling method presented here has a similarity to [49] in defining the stair ramp, it differs in finding stair steps implying that it does not need to find 6 parameters for template matching as it can be challenging when the stairs are cluttered. Additionally, in our method, we do not need to find the correct azimuth of the stairs, because if the azimuth estimation result in wrong reference point then detecting the steps is not possible. This can happen when the steps are segmented with some attached points to it (metal bars on the steps or connecting wall) or if people are standing on the stairs.Although the coarse location of staircases can be separated from the rest of the point clouds, the number of steps and the exact model of the stairs need to be reconstructed. Therefore, we develop a method using the adjacency graph G (V, E) to detect the exact size and location of stairs. Our method for stair modeling has two steps: 1. similar to [49] a planar segmentation [66] is employed to search the ramp of the stairs (Fig. 7b); 2. a fine planar segmentation is applied on the detected ramp to identify planar segments representing each rise and tread in the stairs (Fig. 7c). A planar segment is a valid staircase ramp if it inclines between 25 and 50°are respecting the xy-plane. For the planar segmentation of the ramp a surface growing algorithm is applied with a pointto-plane distance set to 20 cm. We choose a larger value for planar segmentation for ramp detection to make sure points belonging to the steps fall into the ramp segment. A minimum enclosing rectangle is created for each valid ramp and the inliers (considering a buffer) would be the points which will be processed in the second step (see Fig. 7b). The risers and treads should be identified in this ramp. In the second step, a surface growing segmentation with finer parameters (point-toplane distance = 5 cm) generates the segments which represent the nodes (V) in the adjacency graph (see Fig. 7c). If two segments are adjacent and create a perpendicular angle with a threshold of 10°, then an edge (e ϵ E) connects two nodes. Smaller segments with fewer than n supporting points (e.g., n = 500 points) are excluded from the graph. On the stairs, there is clutter (e.g., people during the scanning), and walls and bars are attached to the steps. Therefore, to extract the exact steps which form the stairs, the longest path is extracted from the undirected graph [67]. We start from a random node (v ϵ V) and find a node (x ϵ V) with the longest distance from v using a breadth-first search (BFS). The discovered node x is an end node in the graph. By applying another breadth-first search from node x, the longest path in the graph is identified (see Fig. 7d). Note that the edges are unweighted and the graph should not have cycles. Nodes belonging to the longest path represent the steps of the stairs. For each node, the corresponding segment is selected, and a minimum enclosing rectangle is derived. Since the shape and size of the segments are varied, the width and length of a step are approximated from the majority of the rectangles. Then all the rectangles are adjusted with the new width and length. To extract the number of steps, as every step of stairs has two nodes in the graph, one for the riser and one for the tread, the number of steps is the round of n / 2 where n is the number of nodes in the longest path. Eventually, vertical space is generated from the minimum rectangle of the stairs, which represents the staircase space. This vertical space is a virtual space that connects the levels in a building with an extension from the floor of the lower level to the floor of the upper level. Note that in most buildings, the surrounding walls of stairs are not connected to the ceiling and sometimes they are made of metal bars or glass. Therefore, we create this virtual space to subdivide the space of stairs from other spaces for navigation purposes. Although, the stair modeling method presented here has a similarity to [49] in defining the stair ramp, it differs in finding stair steps implying that it does not need to find 6 parameters for template matching as it can be challenging when the stairs are cluttered. Additionally, in our method, we do not need to find the correct azimuth of the stairs, because if the azimuth estimation result in wrong reference point then detecting the steps is not possible. This can happen when the steps are segmented with some attached points to it (metal bars on the steps or connecting wall) or if people are standing on the stairs.</p>
        <p>Having the permanent structures created in the previous step, now a method is explained to generate enclosed spaces as polyhedra. Remaining spaces in the presence of obstacles are generated as well, to create more detailed spaces for disaster management cases. In the context of disaster management, several aspects of indoor navigation become critical. One of them is a good knowledge of the occupied/ unoccupied spaces and openings' configuration. The flexible space subdivision (FSS) [10] is a framework aiming to provide a space partitioning that reflects the complexity of the indoor environment. The approach produces three main subspaces: the occupied (O-Spaces), the functional (F-Spaces) and the remaining free spaces (R-Spaces). These latter allow describing the space complexity in terms of spatial occupancy induced by the physical and functional characteristics of the indoor objects. The FSS thereby provides a spatial model that supports fine-grained indoor navigation and makes it possible to account for advanced constraints during the navigation, while ensuring enough granularity for describing precise localization.Having the permanent structures created in the previous step, now a method is explained to generate enclosed spaces as polyhedra. Remaining spaces in the presence of obstacles are generated as well, to create more detailed spaces for disaster management cases. In the context of disaster management, several aspects of indoor navigation become critical. One of them is a good knowledge of the occupied/ unoccupied spaces and openings' configuration. The flexible space subdivision (FSS) [10] is a framework aiming to provide a space partitioning that reflects the complexity of the indoor environment. The approach produces three main subspaces: the occupied (O-Spaces), the functional (F-Spaces) and the remaining free spaces (R-Spaces). These latter allow describing the space complexity in terms of spatial occupancy induced by the physical and functional characteristics of the indoor objects. The FSS thereby provides a spatial model that supports fine-grained indoor navigation and makes it possible to account for advanced constraints during the navigation, while ensuring enough granularity for describing precise localization.</p>
        <p>In order to implement the FSS, one of the most critical features needed is the explicit representation of the indoor spaces. Such features can be generally obtained natively from BIM models such as IFC (e.g., the IfcSpace class) However, since we start from a point cloud, the indoor spaces are not readily available in our workflow. Therefore, we present a way to recover them. Similarly, other critical features to the FSS, already identified in the previous steps, will also be considered, such as the openings and obstacles.In order to implement the FSS, one of the most critical features needed is the explicit representation of the indoor spaces. Such features can be generally obtained natively from BIM models such as IFC (e.g., the IfcSpace class) However, since we start from a point cloud, the indoor spaces are not readily available in our workflow. Therefore, we present a way to recover them. Similarly, other critical features to the FSS, already identified in the previous steps, will also be considered, such as the openings and obstacles.</p>
        <p>The indoor space can be conceptually thought as the space that is encapsulated by the permanent structures of a building (walls, floors, ceilings, etc.). The features that we are explicitly representing correspond to that description. Starting from the wall, floor and ceiling volumes, we reconstruct the volumes that could be described as the rooms of the building. Our approach is to extract the closure of the model's interior using regularized Boolean operations [9]. Such operations produce uniquely closed volume and discard Boolean results of lower dimension (faces, edges or points). In other words, the closed volumes encapsulated by the inner parts of the structural elements are sought. The process consists in successively uniting the volumes of the scene (boxes of the walls, slabs, ceilings, etc.) so as to end up with either several connected components corresponding to the enclosed volumes and the shell of the whole input set, or simply one unique connected component if there is no enclosed volume. Thus, only indoor spaces with full closure can be reconstructed.The indoor space can be conceptually thought as the space that is encapsulated by the permanent structures of a building (walls, floors, ceilings, etc.). The features that we are explicitly representing correspond to that description. Starting from the wall, floor and ceiling volumes, we reconstruct the volumes that could be described as the rooms of the building. Our approach is to extract the closure of the model's interior using regularized Boolean operations [9]. Such operations produce uniquely closed volume and discard Boolean results of lower dimension (faces, edges or points). In other words, the closed volumes encapsulated by the inner parts of the structural elements are sought. The process consists in successively uniting the volumes of the scene (boxes of the walls, slabs, ceilings, etc.) so as to end up with either several connected components corresponding to the enclosed volumes and the shell of the whole input set, or simply one unique connected component if there is no enclosed volume. Thus, only indoor spaces with full closure can be reconstructed.</p>
        <p>Fig. 8 shows an example of the resulting spaces from the room reconstruction process. After extracting the walls, slabs and ceilings in the form of closed volumes from the point cloud, we have to ensure that any of those elements have physical contact with its neighboring elements (Fig. 8a). Because Boolean operations are generally very sensitive to precision issues, the intersections between the structures are exaggerated to ensure the contact. This does not disrupt the generation of the indoor spaces as it guarantees the formation of the space closure where they should happen in the model (Fig. 8a). A limitation to this approach is that spaces which are not entirely bounded by structural elements will not be reconstructed. Furthermore, because our 3D models are reconstructed from the point cloud, areas that are not scanned may cause gaps that make it difficult to determine with certainty if there should be a closure or not, without prior knowledge of the actual building.Fig. 8 shows an example of the resulting spaces from the room reconstruction process. After extracting the walls, slabs and ceilings in the form of closed volumes from the point cloud, we have to ensure that any of those elements have physical contact with its neighboring elements (Fig. 8a). Because Boolean operations are generally very sensitive to precision issues, the intersections between the structures are exaggerated to ensure the contact. This does not disrupt the generation of the indoor spaces as it guarantees the formation of the space closure where they should happen in the model (Fig. 8a). A limitation to this approach is that spaces which are not entirely bounded by structural elements will not be reconstructed. Furthermore, because our 3D models are reconstructed from the point cloud, areas that are not scanned may cause gaps that make it difficult to determine with certainty if there should be a closure or not, without prior knowledge of the actual building.</p>
        <p>The geometry of the volumes resulting from the process is similar to those of the space features that can be found in BIM models, such as the IfcSpace class in IFC. Such features do not purposely consider the indoor obstacles but maintains a spatial link of containment with them. In our case, as we rely on the FSS framework, we proceed to a further subdivision of the space in order to explicitly distinguish between the free and the occupied space.The geometry of the volumes resulting from the process is similar to those of the space features that can be found in BIM models, such as the IfcSpace class in IFC. Such features do not purposely consider the indoor obstacles but maintains a spatial link of containment with them. In our case, as we rely on the FSS framework, we proceed to a further subdivision of the space in order to explicitly distinguish between the free and the occupied space.</p>
        <p>The indoor objects populating the space occupy a central role in the FSS framework as they are critical to indoor navigation applications, even more for emergency response. The point cloud which were classified as clutter during the modeling process are further classified to furniture (e.g. tables, sofa, chairs) and clutter (e.g. objects on the wall and ceiling, curtains, shelves), see Section 4.4, from which larger pieces of furniture are selected and each is replaced by an oriented bounding box. In fact, as explained in [10], accounting for the detailed geometry of the furnishing elements would lead to error-prone Boolean operations and a too complex subspace geometry to work with, for a negligible added value. Thus, the simplification of furniture into OBB fits the purpose (see Section 4.4). Furthermore, the resulting simplified volumes correspond directly to the O-Spaces as defined in the FSS, and spatially intersecting ones are aggregated into a single O-Space accordingly. Fig. 9a shows the O-Spaces contained in their respective spaces.The indoor objects populating the space occupy a central role in the FSS framework as they are critical to indoor navigation applications, even more for emergency response. The point cloud which were classified as clutter during the modeling process are further classified to furniture (e.g. tables, sofa, chairs) and clutter (e.g. objects on the wall and ceiling, curtains, shelves), see Section 4.4, from which larger pieces of furniture are selected and each is replaced by an oriented bounding box. In fact, as explained in [10], accounting for the detailed geometry of the furnishing elements would lead to error-prone Boolean operations and a too complex subspace geometry to work with, for a negligible added value. Thus, the simplification of furniture into OBB fits the purpose (see Section 4.4). Furthermore, the resulting simplified volumes correspond directly to the O-Spaces as defined in the FSS, and spatially intersecting ones are aggregated into a single O-Space accordingly. Fig. 9a shows the O-Spaces contained in their respective spaces.</p>
        <p>Subtracting the O-Spaces from the initial indoor spaces leads to the generation of the remaining non-occupied spaces (R-Spaces), which represent the space where all types of navigation can potentially be performed. Fig. 9b gives an illustration of the R-Spaces generated from the spaces of Fig. 8, with a transparent view to make visible the parts of the spaces that have been carved accordingly to the detected O-Spaces. The carving operation is a Boolean difference between each room and the O-Spaces that it contains. For this reason, similarly to the walls and slabs, it is necessary to guarantee the spatial contact between the O-Spaces and their containing rooms to avoid having them as flying objects, because this would lead to empty set results from the Boolean operations.Subtracting the O-Spaces from the initial indoor spaces leads to the generation of the remaining non-occupied spaces (R-Spaces), which represent the space where all types of navigation can potentially be performed. Fig. 9b gives an illustration of the R-Spaces generated from the spaces of Fig. 8, with a transparent view to make visible the parts of the spaces that have been carved accordingly to the detected O-Spaces. The carving operation is a Boolean difference between each room and the O-Spaces that it contains. For this reason, similarly to the walls and slabs, it is necessary to guarantee the spatial contact between the O-Spaces and their containing rooms to avoid having them as flying objects, because this would lead to empty set results from the Boolean operations.</p>
        <p>F-Spaces correspond to the spaces that are induced by the function of an object. Considering such parameters during the navigation allows taking into account the occupancy caused by the usage of indoor objects. From a more technical point of view, F-Spaces allows producing proper position nodes for agents concerning the function of indoor objects. For example, in a context of emergency response, F-Spaces of objects such as extinguishers would allow navigating the agent up to where the object would be accessible. Similarly, an F-Space of a highly flammable object would stand as a space to avoid during the navigation. However, the semantic level of our model does not allow to get enough information about the function of the furnishing elements. For this reason, F-Spaces are limited to the doors in this paper.F-Spaces correspond to the spaces that are induced by the function of an object. Considering such parameters during the navigation allows taking into account the occupancy caused by the usage of indoor objects. From a more technical point of view, F-Spaces allows producing proper position nodes for agents concerning the function of indoor objects. For example, in a context of emergency response, F-Spaces of objects such as extinguishers would allow navigating the agent up to where the object would be accessible. Similarly, an F-Space of a highly flammable object would stand as a space to avoid during the navigation. However, the semantic level of our model does not allow to get enough information about the function of the furnishing elements. For this reason, F-Spaces are limited to the doors in this paper.</p>
        <p>From a navigation point of view, openings are transition spaces that connect two spaces. For openings such as doors, their F-Spaces can be seen as the space that is traversed when the door performs an opening movement or simply the space required to access and interact with it (open, close, hold, etc.). Therefore, a door has an F-Space in each part of the free spaces that surround it (in other words, from both of its sides). Fig. 10 shows how we extract the F-Spaces for door features. The original doors obtained from the point cloud reconstruction, although not very precise, provide a good indication of the doors' location and size. Thus, on that basis, we extrude them in both of their main sides to make sure that we reach the indoor spaces surrounding them (see Fig. 10c). Hence, we perform Boolean operations again to extract their intersection with the walls which correspond to the opening spaces (it can also be seen as a better estimation of the actual doors, see Fig. 10b andd), and their intersections with the R-Spaces which correspond to their F-Spaces (see Fig. 10b andc).From a navigation point of view, openings are transition spaces that connect two spaces. For openings such as doors, their F-Spaces can be seen as the space that is traversed when the door performs an opening movement or simply the space required to access and interact with it (open, close, hold, etc.). Therefore, a door has an F-Space in each part of the free spaces that surround it (in other words, from both of its sides). Fig. 10 shows how we extract the F-Spaces for door features. The original doors obtained from the point cloud reconstruction, although not very precise, provide a good indication of the doors' location and size. Thus, on that basis, we extrude them in both of their main sides to make sure that we reach the indoor spaces surrounding them (see Fig. 10c). Hence, we perform Boolean operations again to extract their intersection with the walls which correspond to the opening spaces (it can also be seen as a better estimation of the actual doors, see Fig. 10b andd), and their intersections with the R-Spaces which correspond to their F-Spaces (see Fig. 10b andc).</p>
        <p>An indoor navigation system requires several components, among which the most critical ones are a map combined with a spatial model and a localization technology. The former provides a spatial description of the environment that will be explored, and the latter allows to locate and track the guided agent along the suggested paths. From the spatial model, a navigation network (graph) is extracted that reflects the connectivity of the spaces of the environment. Navigation and path planning algorithms will, therefore, rely on that graph to compute the paths that lead to a chosen destination from a chosen starting point, based on specific constraints (shortest path, fastest path, etc.). The most common principle used to generate navigation graph is the Poincaré duality [68,69]. It consists in considering the 3D model as the primal space and its graph as the dual space. An abstraction of volumes (3D) into points (0D) (corresponding to the nodes of the graph) and any adjacency relationship (2D) between two volumes into edge (1D) is then performed. This implies that no overlap between spaces is allowed in the primal space, because adjacency between two volumes must be a shared surface. The primal space generally corresponds to the space units where the navigation takes place. The graph (dual space) is therefore generated by computing the centroids of the space units as the nodes and the adjacency between the space units as edges connecting the nodes. The duality theory does not constraint the nodes to be positioned in a specific way with respect to their corresponding volumes, but in navigation that aspect matters due to the nodes related to positioning during navigation. Thus, the choice of the centroid is mostly motivated by its assumed central position in the corresponding volume, although this assumption does not hold anymore for non-convex volumes.An indoor navigation system requires several components, among which the most critical ones are a map combined with a spatial model and a localization technology. The former provides a spatial description of the environment that will be explored, and the latter allows to locate and track the guided agent along the suggested paths. From the spatial model, a navigation network (graph) is extracted that reflects the connectivity of the spaces of the environment. Navigation and path planning algorithms will, therefore, rely on that graph to compute the paths that lead to a chosen destination from a chosen starting point, based on specific constraints (shortest path, fastest path, etc.). The most common principle used to generate navigation graph is the Poincaré duality [68,69]. It consists in considering the 3D model as the primal space and its graph as the dual space. An abstraction of volumes (3D) into points (0D) (corresponding to the nodes of the graph) and any adjacency relationship (2D) between two volumes into edge (1D) is then performed. This implies that no overlap between spaces is allowed in the primal space, because adjacency between two volumes must be a shared surface. The primal space generally corresponds to the space units where the navigation takes place. The graph (dual space) is therefore generated by computing the centroids of the space units as the nodes and the adjacency between the space units as edges connecting the nodes. The duality theory does not constraint the nodes to be positioned in a specific way with respect to their corresponding volumes, but in navigation that aspect matters due to the nodes related to positioning during navigation. Thus, the choice of the centroid is mostly motivated by its assumed central position in the corresponding volume, although this assumption does not hold anymore for non-convex volumes.</p>
        <p>Most existing navigation systems rely on simplified networks to provide navigation services, which means that in their primal space, the space units are rooms. Thus, they generate a graph in which the nodes are the centroid of rooms in the building and the edges symbolize their connectivity. Simple topographic information of buildings (e.g., floor plan) is used to determine, for example, which room is connected to which corridor, etc. This then leads to a connectivity graph that provides minimal insight into the reality of the indoor environment. A typical path resulting from such system would result in similar navigation instructions: "To go to room D from room A, go to room B, then corridor C and then get to room D." Such guidance heavily assumes that the agents are aware of what room A, B, C and D are, which is not a reasonable assumption in the context of emergency response, where the first responders may interact with the environment for the first time.Most existing navigation systems rely on simplified networks to provide navigation services, which means that in their primal space, the space units are rooms. Thus, they generate a graph in which the nodes are the centroid of rooms in the building and the edges symbolize their connectivity. Simple topographic information of buildings (e.g., floor plan) is used to determine, for example, which room is connected to which corridor, etc. This then leads to a connectivity graph that provides minimal insight into the reality of the indoor environment. A typical path resulting from such system would result in similar navigation instructions: "To go to room D from room A, go to room B, then corridor C and then get to room D." Such guidance heavily assumes that the agents are aware of what room A, B, C and D are, which is not a reasonable assumption in the context of emergency response, where the first responders may interact with the environment for the first time.</p>
        <p>In contrast, fine-grained navigation networks provide more useful insight into the indoor environment and better support for advanced navigation systems [70]. The 3D models resulting from our reconstruction process, enriched with the FSS framework, are suitable for supporting fine-grained indoor navigation because basic spaces (rooms) are subdivided into O-Spaces, F-Spaces and R-Spaces. All those subspaces are explicitly computed during the FSS, leading to a complex of adjacent volumes rich of semantic and topological information (each volume knows its adjacent neighbors). Then, following the Poincaré duality theory, we compute the centroid of each navigable volume (F-Spaces and R-Spaces) to obtain the nodes of our network. This is done by simply averaging the coordinates of all the vertices that compose a volume. A convex subdivision of the volumes is performed when necessary to ensure that their nodes are located inside them. Our network is thereby composed of one node per convex subspace. This explains why in Fig. 11b rooms containing objects are provided with more nodes than empty room. Similarly, rooms with non-convex shapes are provided with as many nodes as their convex subdivision requires, while simple networks produce only one node per room independently of shape or occupancy. In comparison with [60] where a regular grid is proposed instead, our approach allows optimizing the subdivision with more nodes only where obstacles or objects of interest are located, keeping the size of the minimum necessary size of the graph. Indeed, our navigation networks, while providing all the possibilities of a basic connectivity graph, also offer the accessible areas in 3D through the R-Spaces. Furthermore, thanks to the available semantic information and with the identification of the F-Spaces, it is possible to derive paths with much more intelligence, considering the navigation context. For example, one could extract a path that maximizes the free space (to account for the equipment of first responders) while crossing as many extinguishers as possible on the way. This would simply require giving more weight to the nodes of the large subspaces (based on threshold) and those that are adjacent to an O-Space with extinguishers, in the network.In contrast, fine-grained navigation networks provide more useful insight into the indoor environment and better support for advanced navigation systems [70]. The 3D models resulting from our reconstruction process, enriched with the FSS framework, are suitable for supporting fine-grained indoor navigation because basic spaces (rooms) are subdivided into O-Spaces, F-Spaces and R-Spaces. All those subspaces are explicitly computed during the FSS, leading to a complex of adjacent volumes rich of semantic and topological information (each volume knows its adjacent neighbors). Then, following the Poincaré duality theory, we compute the centroid of each navigable volume (F-Spaces and R-Spaces) to obtain the nodes of our network. This is done by simply averaging the coordinates of all the vertices that compose a volume. A convex subdivision of the volumes is performed when necessary to ensure that their nodes are located inside them. Our network is thereby composed of one node per convex subspace. This explains why in Fig. 11b rooms containing objects are provided with more nodes than empty room. Similarly, rooms with non-convex shapes are provided with as many nodes as their convex subdivision requires, while simple networks produce only one node per room independently of shape or occupancy. In comparison with [60] where a regular grid is proposed instead, our approach allows optimizing the subdivision with more nodes only where obstacles or objects of interest are located, keeping the size of the minimum necessary size of the graph. Indeed, our navigation networks, while providing all the possibilities of a basic connectivity graph, also offer the accessible areas in 3D through the R-Spaces. Furthermore, thanks to the available semantic information and with the identification of the F-Spaces, it is possible to derive paths with much more intelligence, considering the navigation context. For example, one could extract a path that maximizes the free space (to account for the equipment of first responders) while crossing as many extinguishers as possible on the way. This would simply require giving more weight to the nodes of the large subspaces (based on threshold) and those that are adjacent to an O-Space with extinguishers, in the network.</p>
        <p>Another advantage of the FSS as a fine-grained spatial model, in comparison with other models, is the possibility to fully exploit the 3D space and thereby enable the extraction of navigation graph for agents with a different kind of mobility [10]. For example, a robot or a drone could be considered as agents and all the spaces close to the ground or the ceiling are then used to compute their dedicated paths. The subspaces in Fig. 11 (right) result from the F-Spaces of openings and the R-Spaces (which are the free spaces that exclude the indoor objects and the F-Spaces). These latter are further subdivided into convex space cells to ensure that their nodes in the network lay exclusively inside their boundaries.Another advantage of the FSS as a fine-grained spatial model, in comparison with other models, is the possibility to fully exploit the 3D space and thereby enable the extraction of navigation graph for agents with a different kind of mobility [10]. For example, a robot or a drone could be considered as agents and all the spaces close to the ground or the ceiling are then used to compute their dedicated paths. The subspaces in Fig. 11 (right) result from the F-Spaces of openings and the R-Spaces (which are the free spaces that exclude the indoor objects and the F-Spaces). These latter are further subdivided into convex space cells to ensure that their nodes in the network lay exclusively inside their boundaries.</p>
        <p>Having nodes exclusively on free spaces makes a critical difference in terms of navigation, as illustrated in Fig. 12. Indeed, as the navigation network is the support for path computation, if it does not reflect the indoor occupancy, the provided path may not be accessible to the agent. The network in Fig. 12a provides positions that are unreachable for an agent, as it is the place of O-Space. By relying on the FSS (mainly the F-Spaces and the R-Spaces), the positions provided by the network would guarantee unoccupied spaces (see Fig. 12b). In terms of path planning, this means more reliable paths. Furthermore, when combined with other spatial properties of the subspaces such as their size or volume, it becomes possible also to estimate the suitability of the path regarding its accessibility and the navigation comfort it can provide to a given agent. The usefulness of the F-Spaces of the openings appears more when obstacles lie in front of openings (see Fig. 12c). Indeed, in such case, the F-Space is truncated to reflect the occupancy. Such information can play a critical role in emergency response navigation, as it may indicate that a room is blocked or hardly accessible, mainly with equipment of important size.Having nodes exclusively on free spaces makes a critical difference in terms of navigation, as illustrated in Fig. 12. Indeed, as the navigation network is the support for path computation, if it does not reflect the indoor occupancy, the provided path may not be accessible to the agent. The network in Fig. 12a provides positions that are unreachable for an agent, as it is the place of O-Space. By relying on the FSS (mainly the F-Spaces and the R-Spaces), the positions provided by the network would guarantee unoccupied spaces (see Fig. 12b). In terms of path planning, this means more reliable paths. Furthermore, when combined with other spatial properties of the subspaces such as their size or volume, it becomes possible also to estimate the suitability of the path regarding its accessibility and the navigation comfort it can provide to a given agent. The usefulness of the F-Spaces of the openings appears more when obstacles lie in front of openings (see Fig. 12c). Indeed, in such case, the F-Space is truncated to reflect the occupancy. Such information can play a critical role in emergency response navigation, as it may indicate that a room is blocked or hardly accessible, mainly with equipment of important size.</p>
        <p>Finally, because we could reconstruct the stairs and the space occupied by the staircases, we can generate a multistory navigation network, which is a challenging task from point cloud [39]. Fig. 13 illustrates a navigation path generated between two spaces at different levels of the building through the opening created in the slab of the upper floor. The latter was made similarly as the doors, by carving a hole using the staircase's space. The FSS can be similarly applied to the model for a fine-grained multistory navigation network.Finally, because we could reconstruct the stairs and the space occupied by the staircases, we can generate a multistory navigation network, which is a challenging task from point cloud [39]. Fig. 13 illustrates a navigation path generated between two spaces at different levels of the building through the opening created in the slab of the upper floor. The latter was made similarly as the doors, by carving a hole using the staircase's space. The FSS can be similarly applied to the model for a fine-grained multistory navigation network.</p>
        <p>As the last step of our pipeline, we verify the consistency of our generated model against three defined heuristic constraints (C). The accuracy of the model regarding the detected doors, stairs and reconstructed spaces can be improved by this consistency check. The focus of this check is the validation of generated spaces in terms of navigation. The three constraints, which are checked on the data sequentially, are described as follows: C1. Each room should have an area larger than A m 2 and a volume greater than V m 3 . C2. Each room should be connected to at least one door. C3. There should be a route connecting every pair of rooms in the graph.As the last step of our pipeline, we verify the consistency of our generated model against three defined heuristic constraints (C). The accuracy of the model regarding the detected doors, stairs and reconstructed spaces can be improved by this consistency check. The focus of this check is the validation of generated spaces in terms of navigation. The three constraints, which are checked on the data sequentially, are described as follows: C1. Each room should have an area larger than A m 2 and a volume greater than V m 3 . C2. Each room should be connected to at least one door. C3. There should be a route connecting every pair of rooms in the graph.</p>
        <p>To verify C1, a 2D boundary projection on the xy-plane is generated for each reconstructed space (see Section 4.1). The area of the room is calculated and it should be larger than a threshold, its volume is also checked against another given threshold. This is necessary because, with the Boolean regularization approach, quasi-flat spaces can occur in thin gaps left by structural elements. Thus, only relying on the surface area would not allow invalidating such spaces. Once a room is validated, it passes for the next check. Otherwise, it should be flagged for further control. Later on, flagged items are returned for visual inspection (Section 4.2.2) to see whether a wall is mislabeled in the process. After correction, the pipeline is repeated to create a consistent model.To verify C1, a 2D boundary projection on the xy-plane is generated for each reconstructed space (see Section 4.1). The area of the room is calculated and it should be larger than a threshold, its volume is also checked against another given threshold. This is necessary because, with the Boolean regularization approach, quasi-flat spaces can occur in thin gaps left by structural elements. Thus, only relying on the surface area would not allow invalidating such spaces. Once a room is validated, it passes for the next check. Otherwise, it should be flagged for further control. Later on, flagged items are returned for visual inspection (Section 4.2.2) to see whether a wall is mislabeled in the process. After correction, the pipeline is repeated to create a consistent model.</p>
        <p>The constraint C2 checks if each room is connected to at least one door. Otherwise, a missing door is flagged for the room. Although the door detection algorithm could have missed more than one door per room, a room without any door reflects necessarily a problem in the reconstruction. This is also an obvious limitation for navigation purposes. As illustrated in Fig. 14, by relying on the navigation graph, it is straightforward to identify the problem, as it only requires detecting rooms associated with isolated nodes. Similar to C1, spaces detected in this checking are tagged for further improvement of the model reconstruction.The constraint C2 checks if each room is connected to at least one door. Otherwise, a missing door is flagged for the room. Although the door detection algorithm could have missed more than one door per room, a room without any door reflects necessarily a problem in the reconstruction. This is also an obvious limitation for navigation purposes. As illustrated in Fig. 14, by relying on the navigation graph, it is straightforward to identify the problem, as it only requires detecting rooms associated with isolated nodes. Similar to C1, spaces detected in this checking are tagged for further improvement of the model reconstruction.</p>
        <p>The third constraint C3 verifies the connectivity of two spaces. It also relies on the navigation network and covers the cases that cannot be detected with C2. We assume that every two spaces in a correct 3D model should be reachable and connected through the navigation graph. Therefore, the process checks the existence of a path between every two rooms in the model. For example, if the connection of level n through the reconstructed stairs to the level n + 1 is broken in part of the 3D model, it is possible to identify the broken path and fix it by generating a connectivity graph between two rooms in two different levels. This typically happens when the number of steps in the stairs is not reconstructed correctly and the stairs are not connected properly to the floor of each level. Similarly, if two rooms on the same floor are not connected, it can be because of a missing door or an invalid room.The third constraint C3 verifies the connectivity of two spaces. It also relies on the navigation network and covers the cases that cannot be detected with C2. We assume that every two spaces in a correct 3D model should be reachable and connected through the navigation graph. Therefore, the process checks the existence of a path between every two rooms in the model. For example, if the connection of level n through the reconstructed stairs to the level n + 1 is broken in part of the 3D model, it is possible to identify the broken path and fix it by generating a connectivity graph between two rooms in two different levels. This typically happens when the number of steps in the stairs is not reconstructed correctly and the stairs are not connected properly to the floor of each level. Similarly, if two rooms on the same floor are not connected, it can be because of a missing door or an invalid room.</p>
        <p>We conducted our experiments on different types of buildings that go beyond the simple grid and regular structure. To demonstrate a full 3D reconstruction, the selected datasets cover a range of different cases such as the non-Manhattan World structures, slanted walls and non- horizontal ceilings, ramps, large glass walls, multiple floors and ceilings with different heights. To compare the robustness of our algorithm regarding different laser scanning systems, the data sets are acquired by various laser scanners and represent different ranges of noise (e) from 0.01 to 0.06 m (Table 1). All the datasets contain furniture and a high level of clutter to evaluate the algorithms in terms of occlusion and missing data problems. We tested our workflow on four datasets (Table 1) and the results are represented in Fig. 15. The data of three datasets is collected by mobile laser scanners and belongs to the project Smart Indoor Models in 3D [71]. The Penthouse dataset is acquired by a terrestrial laser scanner which belongs to the related work [6] and is selected to test our algorithm on slanted walls and ceilings. For one of the datasets (Fire-brigade 2), we use the professionally made BIM model for the comparison. The noise in the datasets collected by a mobile laser scanner varies between 4 and 6 cm. For pushing-cart systems, the data is less noisy than handheld devices.We conducted our experiments on different types of buildings that go beyond the simple grid and regular structure. To demonstrate a full 3D reconstruction, the selected datasets cover a range of different cases such as the non-Manhattan World structures, slanted walls and non- horizontal ceilings, ramps, large glass walls, multiple floors and ceilings with different heights. To compare the robustness of our algorithm regarding different laser scanning systems, the data sets are acquired by various laser scanners and represent different ranges of noise (e) from 0.01 to 0.06 m (Table 1). All the datasets contain furniture and a high level of clutter to evaluate the algorithms in terms of occlusion and missing data problems. We tested our workflow on four datasets (Table 1) and the results are represented in Fig. 15. The data of three datasets is collected by mobile laser scanners and belongs to the project Smart Indoor Models in 3D [71]. The Penthouse dataset is acquired by a terrestrial laser scanner which belongs to the related work [6] and is selected to test our algorithm on slanted walls and ceilings. For one of the datasets (Fire-brigade 2), we use the professionally made BIM model for the comparison. The noise in the datasets collected by a mobile laser scanner varies between 4 and 6 cm. For pushing-cart systems, the data is less noisy than handheld devices.</p>
        <p>We compare our result with a professionally made IFC model for Fire brigade building #2. The results show that 95% of the rooms are reconstructed correctly. The precision and recall of the permanent structure are 91% and 95%, respectively. The calculation of precision and recall in Table 2 is based on comparing the labels per point which are manually labeled with the labels which are predicted by the algorithm. F1-score is a harmony of the correctness (precision) and completeness (recall) of values for each class. The room on the second floor has a curved structure wherein our planar reconstruction algorithm is reconstructed with smaller planar surfaces. The firetruck hall is extended from the first floor to the second floor and it shows that our algorithm can reconstruct a fully 3D model of spaces which are extended vertically. The ramp of the stairs is correctly detected and a staircase is reconstructed as a virtual space which connects the first floor to the second floor and the ramp is used for navigation purposes. Individual stairs are not reconstructed for this model because the stairs are scanned with a pushing-cart system only from the lower and upper floor which is not capable of scanning stairs consequently and adequately the data for all steps is not available. 90% of the doors are correctly detected and represented in Fig. 15 and Table 1. The trajectory crosses most of the doors, just a few doors which are not intersected by the trajectory during the scanning are not recognized by our algorithm. One door is recognized as a false positive. The reason is a false positive wall which is crossed by the trajectory. The corridor on the second floor is separated into two spaces because of a false positive wall (Fig. 15, upper row). The reason is that clutter in the ceiling was identified as part of the wall and was extended to the neighbor walls during the automatic extension process. Consequently, the corridor is subdivided with this wall. The rest of the spaces is correctly reconstructed. To see the spaces, refer to Fig. 15, fire brigade building #2.We compare our result with a professionally made IFC model for Fire brigade building #2. The results show that 95% of the rooms are reconstructed correctly. The precision and recall of the permanent structure are 91% and 95%, respectively. The calculation of precision and recall in Table 2 is based on comparing the labels per point which are manually labeled with the labels which are predicted by the algorithm. F1-score is a harmony of the correctness (precision) and completeness (recall) of values for each class. The room on the second floor has a curved structure wherein our planar reconstruction algorithm is reconstructed with smaller planar surfaces. The firetruck hall is extended from the first floor to the second floor and it shows that our algorithm can reconstruct a fully 3D model of spaces which are extended vertically. The ramp of the stairs is correctly detected and a staircase is reconstructed as a virtual space which connects the first floor to the second floor and the ramp is used for navigation purposes. Individual stairs are not reconstructed for this model because the stairs are scanned with a pushing-cart system only from the lower and upper floor which is not capable of scanning stairs consequently and adequately the data for all steps is not available. 90% of the doors are correctly detected and represented in Fig. 15 and Table 1. The trajectory crosses most of the doors, just a few doors which are not intersected by the trajectory during the scanning are not recognized by our algorithm. One door is recognized as a false positive. The reason is a false positive wall which is crossed by the trajectory. The corridor on the second floor is separated into two spaces because of a false positive wall (Fig. 15, upper row). The reason is that clutter in the ceiling was identified as part of the wall and was extended to the neighbor walls during the automatic extension process. Consequently, the corridor is subdivided with this wall. The rest of the spaces is correctly reconstructed. To see the spaces, refer to Fig. 15, fire brigade building #2.</p>
        <p>The second dataset for comparison is selected from the related work [6], which has a challenging structure with slanted walls, dormers, chimney and built-in bookshelves. Because the data is collected with a terrestrial laser scanner, the noise is less than 1 cm and the planar segments are finer than segments in other datasets. This is important when the algorithm generates the adjacency graph and later the minimum rectangles. The results show that our algorithm successfully reconstructs the dormers and slanted walls (Fig. 17). The walls belong to the chimney are detected in our algorithm, but the chimney space is not reconstructed as space because the walls are not connected to the floor and it does not make an enclosure in the space (Fig. 18, left). Our method reconstructs the green space in the left corner by estimating part of the wall which can be detected near the ceiling. Also, the empty space between the green room and the purple room is modeled differently from [6]in our model. The wall in the purple room is completely occluded by the built-in bookshelves (Figs. 17 and 18b), while in [6] it is modeled as occupied space, our interpretation is that part of the spaceThe second dataset for comparison is selected from the related work [6], which has a challenging structure with slanted walls, dormers, chimney and built-in bookshelves. Because the data is collected with a terrestrial laser scanner, the noise is less than 1 cm and the planar segments are finer than segments in other datasets. This is important when the algorithm generates the adjacency graph and later the minimum rectangles. The results show that our algorithm successfully reconstructs the dormers and slanted walls (Fig. 17). The walls belong to the chimney are detected in our algorithm, but the chimney space is not reconstructed as space because the walls are not connected to the floor and it does not make an enclosure in the space (Fig. 18, left). Our method reconstructs the green space in the left corner by estimating part of the wall which can be detected near the ceiling. Also, the empty space between the green room and the purple room is modeled differently from [6]in our model. The wall in the purple room is completely occluded by the built-in bookshelves (Figs. 17 and 18b), while in [6] it is modeled as occupied space, our interpretation is that part of the space</p>
        <p>Results of the different datasets belonging to SIMs3D Project [71]. The third column shows the scanning device. The fourth column is the acquisition system precision which is related to the sensor noise and the MLS algorithm. The fifth and sixth columns show the correct and detected numbers of rooms and doors, respectively using our methods. The doors in Penthouse dataset is not reported as it is acquired by a TLS and is out of the scope of this research. The seventh column indicates the number of planar surfaces with supporting points &gt; 500 and in the brackets, the number of permanent structures and clutter segments. The visual operations (eighth column) are either changing the label of a segment or extending a wall in the data gaps. Each human intervention is one operation. The last dataset (Penthouse) is from related work [6]. is free space (such as balcony) and we modeled it as a free space between two rooms. A wall is added to enclose the space during the visual inspection. Note that detection of the doors in datasets which are acquired by TLS (Penthouse) is not part of this work. Therefore, the doors in Penthouse dataset are not reconstructed.Results of the different datasets belonging to SIMs3D Project [71]. The third column shows the scanning device. The fourth column is the acquisition system precision which is related to the sensor noise and the MLS algorithm. The fifth and sixth columns show the correct and detected numbers of rooms and doors, respectively using our methods. The doors in Penthouse dataset is not reported as it is acquired by a TLS and is out of the scope of this research. The seventh column indicates the number of planar surfaces with supporting points &gt; 500 and in the brackets, the number of permanent structures and clutter segments. The visual operations (eighth column) are either changing the label of a segment or extending a wall in the data gaps. Each human intervention is one operation. The last dataset (Penthouse) is from related work [6]. is free space (such as balcony) and we modeled it as a free space between two rooms. A wall is added to enclose the space during the visual inspection. Note that detection of the doors in datasets which are acquired by TLS (Penthouse) is not part of this work. Therefore, the doors in Penthouse dataset are not reconstructed.</p>
        <p>A visual inspection is performed after the labeling of the permanent structures. This mainly includes checking if some of the clutter near the ceiling are classified as wall and change the label to clutter. Additionally, if a space is not enclosed with walls because of large data missing or the occlusion similar to the built-in shelves in penthouse dataset (Fig. 18b), then a wall is added manually. In such cases, the thickness and the orientation of the wall are inherited from the adjacent walls. Additionally, our pipeline can export the volumetric walls and spaces to the standard BIM software formats such as 
            <rs type="software">Wavefront</rs> format (.obj) to import it into CAD software for further improvements, for instance, for adding windows. We calculate the time and percentage of operations for visual inspection for Fire brigade building #2 dataset. It takes 5 min per floor (for a floor with almost 15 rooms) and &lt; 6% of the total number of segments are modified.
        </p>
        <p>The navigation graph in this work is a connectivity graph to show the relation between 3D spaces, which are categorized into navigable and non-navigable using the FSS framework. Showing a turn to turn detailed graph is not our goal and it is addressed in many previous works [54,58]. Our focus is showing the thorough process of subdividing the space into more semantic divisions using a model reconstructed from point clouds and considering obstacles and the full 3D space for optimal routing of different kind of agents. Additionally, we showed how the FSS-based navigation graph could improve the navigation by revealing doors occluded by obstacles (see Section 4.4) and also how it could help to improve the 3D model regarding the presence 1. The left column shows the point clouds, masked by the spaces from the model on the right for a better interpretation. The right column shows the 3D models reconstructed with our pipeline (the colors are random). The datasets of Fire brigade #1 and #2 (3rd and 4th rows) are representing two floors. The first dataset belongs to the related work [6] and demonstrates how our algorithm is capable of handling slanted walls and reconstruction of dormers. For a clear visualization, volumetric walls and slabs are removed in the left images. The empty space between rooms on each floor is filled with volumetric walls. For 3D models with walls refer to other images. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.) of the doors per space (see Section 5). If the connection between levels or rooms is broken in the navigation graph, further inspection will be performed.The navigation graph in this work is a connectivity graph to show the relation between 3D spaces, which are categorized into navigable and non-navigable using the FSS framework. Showing a turn to turn detailed graph is not our goal and it is addressed in many previous works [54,58]. Our focus is showing the thorough process of subdividing the space into more semantic divisions using a model reconstructed from point clouds and considering obstacles and the full 3D space for optimal routing of different kind of agents. Additionally, we showed how the FSS-based navigation graph could improve the navigation by revealing doors occluded by obstacles (see Section 4.4) and also how it could help to improve the 3D model regarding the presence 1. The left column shows the point clouds, masked by the spaces from the model on the right for a better interpretation. The right column shows the 3D models reconstructed with our pipeline (the colors are random). The datasets of Fire brigade #1 and #2 (3rd and 4th rows) are representing two floors. The first dataset belongs to the related work [6] and demonstrates how our algorithm is capable of handling slanted walls and reconstruction of dormers. For a clear visualization, volumetric walls and slabs are removed in the left images. The empty space between rooms on each floor is filled with volumetric walls. For 3D models with walls refer to other images. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.) of the doors per space (see Section 5). If the connection between levels or rooms is broken in the navigation graph, further inspection will be performed.</p>
        <p>Parameters are reported in Tables 3 and4. The crucial parameters for permanent structure detection belong to the surface growing and adjacency graph, which are the point-to-plane distance and proximity, respectively. The point-to-plane distance in surface growing segmentation is chosen considering the noise of the sensor, MLS data acquisition noise and point density. For example, for handled scanners the noise is higher than pushing-cart systems and similarly for pushing-cart systems is higher than terrestrial scanners. For surface growing segmentation a threshold of 8 to 10 cm is chosen for MLS devices and a threshold of 4 cm for TLS devices (Penthouse dataset). The exact values are reported in with a threshold of 0.10 m for the proximity of adjacent segments. To classify the segments into almost-vertical and almost-horizontal, the angle of their normals with the positive direction of z-axis is set to 45°f or most datasets. For automatic undershoot correction of walls, the extension threshold is set based on the data. Experimentally, this threshold should be less than the width of a narrow corridor. For most datasets, a value of 1.0 m is optimal. During the reconstruction of volumetric walls, a value of 0.80 m is selected for the maximum distance of two parallel planes to be considered as one wall, and their normal vector should not deviate &gt; 5°.Parameters are reported in Tables 3 and4. The crucial parameters for permanent structure detection belong to the surface growing and adjacency graph, which are the point-to-plane distance and proximity, respectively. The point-to-plane distance in surface growing segmentation is chosen considering the noise of the sensor, MLS data acquisition noise and point density. For example, for handled scanners the noise is higher than pushing-cart systems and similarly for pushing-cart systems is higher than terrestrial scanners. For surface growing segmentation a threshold of 8 to 10 cm is chosen for MLS devices and a threshold of 4 cm for TLS devices (Penthouse dataset). The exact values are reported in with a threshold of 0.10 m for the proximity of adjacent segments. To classify the segments into almost-vertical and almost-horizontal, the angle of their normals with the positive direction of z-axis is set to 45°f or most datasets. For automatic undershoot correction of walls, the extension threshold is set based on the data. Experimentally, this threshold should be less than the width of a narrow corridor. For most datasets, a value of 1.0 m is optimal. During the reconstruction of volumetric walls, a value of 0.80 m is selected for the maximum distance of two parallel planes to be considered as one wall, and their normal vector should not deviate &gt; 5°.</p>
        <p>All the algorithms are written in C++ and tested on a Lenovo ThinkPad workstation with an Intel core i7 (2.5 GHz, 16 GB RAM). Surface growing segmentation runtime is calculated per dataset and is reported in Table 4. The whole pipeline runtime, excluding segmentation, for a dataset with 7 million points and an average of 800 surfaces with 25 rooms takes 10 min. Most of the time is devoted to processing pairs of adjacent segments to build the adjacency graph, extending segments to their intersection, and eventually merging both faces. Other algorithms operated on minimum rectangles such as reconstructing the volumetric walls, generating the spaces from enclosed walls, and the algorithm for the detection of doors and stairs take less than a minute.All the algorithms are written in C++ and tested on a Lenovo ThinkPad workstation with an Intel core i7 (2.5 GHz, 16 GB RAM). Surface growing segmentation runtime is calculated per dataset and is reported in Table 4. The whole pipeline runtime, excluding segmentation, for a dataset with 7 million points and an average of 800 surfaces with 25 rooms takes 10 min. Most of the time is devoted to processing pairs of adjacent segments to build the adjacency graph, extending segments to their intersection, and eventually merging both faces. Other algorithms operated on minimum rectangles such as reconstructing the volumetric walls, generating the spaces from enclosed walls, and the algorithm for the detection of doors and stairs take less than a minute.</p>
        <p>Our volumetric reconstruction method for walls does not reconstruct columns in walls and walls with many intrusions and extrusions. Similarly, a wall with engraved windows such as façade walls are approximated by a planar surface and the details of windows frames are not reconstructed in the model. For the reconstruction of the permanent structures and to model the non-Manhattan World structures, our algorithm does not enforce any vertical, horizontal, or perpendicularity constraints. As a consequence, some walls can be slightly skewed when the surface is segmented with little clutter on the wall. However, this limitation does not jeopardize the space subdivision result and subsequent analyses. Some of the noise outside the building layout caused by the strong reflection of glass surfaces can disturb the detection of a permanent structure and lead to, for example, misclassified walls. However, the final 3D model is correct because these misclassified walls do not enclose a space during the reconstruction Authors in [8] propose a method to identify and to prune the noise of reflective surfaces as a solution, however, in this work, we did not apply their solution because the noise was not disrupting the final 3D model. The algorithm for stair modeling can fail if several steps are missing during the data acquisition. This can happen because the BFS-search detects the longest path which is not representing the correct number of steps. Although, this problem can be disregarded if the data is scanned properly with a mobile laser scanner and the least amount of occlusion. Separating levels of the building using the trajectory is limited to mobile laser scanners which can go to the stair cases (backpacks and handheld). Therefore, for TLS and pushing-cart scanners the z-histogram can be used to separate the levels. Another limitation of using the trajectory is that in the presence of a lot of transparent surfaces can be problematic because laser rays penetrate to other levels, but yet it provides a coarse separation of complex buildings to the levels and stairs. Using the trajectory for the detection of (closed) doors is very effective as closed doors are difficult to detect from simple geometry. However, doors which are not traversed by the trajectory during the scanning are not detected using this approach. Regarding the extraction of the room spaces, it is important to keep in mind that a lack of closure in the bounding elements of such spaces would not allow their reconstruction. While this can be seen as a limitation in highly occluded scenes, it remains a good indicator of the structural elements to reconsider for model correction or improvement.Our volumetric reconstruction method for walls does not reconstruct columns in walls and walls with many intrusions and extrusions. Similarly, a wall with engraved windows such as façade walls are approximated by a planar surface and the details of windows frames are not reconstructed in the model. For the reconstruction of the permanent structures and to model the non-Manhattan World structures, our algorithm does not enforce any vertical, horizontal, or perpendicularity constraints. As a consequence, some walls can be slightly skewed when the surface is segmented with little clutter on the wall. However, this limitation does not jeopardize the space subdivision result and subsequent analyses. Some of the noise outside the building layout caused by the strong reflection of glass surfaces can disturb the detection of a permanent structure and lead to, for example, misclassified walls. However, the final 3D model is correct because these misclassified walls do not enclose a space during the reconstruction Authors in [8] propose a method to identify and to prune the noise of reflective surfaces as a solution, however, in this work, we did not apply their solution because the noise was not disrupting the final 3D model. The algorithm for stair modeling can fail if several steps are missing during the data acquisition. This can happen because the BFS-search detects the longest path which is not representing the correct number of steps. Although, this problem can be disregarded if the data is scanned properly with a mobile laser scanner and the least amount of occlusion. Separating levels of the building using the trajectory is limited to mobile laser scanners which can go to the stair cases (backpacks and handheld). Therefore, for TLS and pushing-cart scanners the z-histogram can be used to separate the levels. Another limitation of using the trajectory is that in the presence of a lot of transparent surfaces can be problematic because laser rays penetrate to other levels, but yet it provides a coarse separation of complex buildings to the levels and stairs. Using the trajectory for the detection of (closed) doors is very effective as closed doors are difficult to detect from simple geometry. However, doors which are not traversed by the trajectory during the scanning are not detected using this approach. Regarding the extraction of the room spaces, it is important to keep in mind that a lack of closure in the bounding elements of such spaces would not allow their reconstruction. While this can be seen as a limitation in highly occluded scenes, it remains a good indicator of the structural elements to reconsider for model correction or improvement.</p>
        <p>In this paper we introduced a complete workflow that allows extracting fine-grained navigation networks from 3D models obtained through an advanced reconstruction process. The resulting model is meant to support disaster management and navigation in the context of emergency response. Since we generate volumetric walls and spaces, our results are also suitable to be used in 
            <rs type="software">BIM</rs> software for further improvements. Facility maps can be co-registered and included in our model for facility management. A safety audit can be performed without the need of sending inspectors to the building and this can be updated regularly for buildings, simply by scanning and generating new models. We use MLS devices for most of our datasets, which enable us to scan and generate the model on the same day. The generated model can be imported in CAD software and can be further improved by adding windows, missing doors, beams and columns. Firefighters can use the spaces to have an overview of the layout of different floors.
        </p>
        <p>When the spaces are enriched with the Object, Functional and Remaining (O, F, R) Spaces, a subspace-based navigation graph which reflects the indoor occupancy and functional spaces of indoor objects can be designed for supporting navigation of different types of agent.When the spaces are enriched with the Object, Functional and Remaining (O, F, R) Spaces, a subspace-based navigation graph which reflects the indoor occupancy and functional spaces of indoor objects can be designed for supporting navigation of different types of agent.</p>
        <p>Our results show that 90% of the rooms are reconstructed correctly and this can be improved with a simple user intervention to 95%. We demonstrate a fully 3D reconstruction pipeline for multistory buildings with slanted walls, ceilings and ramps. The reconstruction of volumetric walls enables us to have a better geometry model close to IFC standards rather than thin-wall 3D models. Therefore, our pipeline can be an initiative for scan-to-BIM problems. Applying the closure-based method to extract spaces does not require the position of a scanner or a 3D cell complex partitioning. Moreover, the FSS approach provides a higher level of details for space subdivision comparing to previous 3D models.Our results show that 90% of the rooms are reconstructed correctly and this can be improved with a simple user intervention to 95%. We demonstrate a fully 3D reconstruction pipeline for multistory buildings with slanted walls, ceilings and ramps. The reconstruction of volumetric walls enables us to have a better geometry model close to IFC standards rather than thin-wall 3D models. Therefore, our pipeline can be an initiative for scan-to-BIM problems. Applying the closure-based method to extract spaces does not require the position of a scanner or a 3D cell complex partitioning. Moreover, the FSS approach provides a higher level of details for space subdivision comparing to previous 3D models.</p>
        <p>The consistency control constraints make sure that the generated spaces are validated for navigation, and rooms are accessible from different locations in the building. Future work could include the automatic semantic identification and enrichment of the furniture. This would help in the creation of more advanced FSS models with more detailed functional spaces and would also allow automatic identification of the room function. The evaluation of the whole pipeline with a flexible navigation network for emergencies in a real case scenario is not a trivial task and needs cooperation of several stakeholders and is part of our future plan. Moreover, automatic reconstruction of other items such as windows, beams and columns are another important improvement that needs to be considered in our 3D models. Although we have introduced a basic process to check the consistency, more in-depth investigations for further constraints checking could improve the pipeline by additionally considering, for example, topological constraints on the 3D models reconstructed from the point clouds. From a planning point of view, an extension to modeling the interior of buildings would be the incorporation with a façade modeling algorithm to obtain a whole building model.The consistency control constraints make sure that the generated spaces are validated for navigation, and rooms are accessible from different locations in the building. Future work could include the automatic semantic identification and enrichment of the furniture. This would help in the creation of more advanced FSS models with more detailed functional spaces and would also allow automatic identification of the room function. The evaluation of the whole pipeline with a flexible navigation network for emergencies in a real case scenario is not a trivial task and needs cooperation of several stakeholders and is part of our future plan. Moreover, automatic reconstruction of other items such as windows, beams and columns are another important improvement that needs to be considered in our 3D models. Although we have introduced a basic process to check the consistency, more in-depth investigations for further constraints checking could improve the pipeline by additionally considering, for example, topological constraints on the 3D models reconstructed from the point clouds. From a planning point of view, an extension to modeling the interior of buildings would be the incorporation with a façade modeling algorithm to obtain a whole building model.</p>
        <p>Penthouse (TLS)Penthouse (TLS)</p>
        <p>Mura et alMura et al</p>
        <p>[6][6]</p>
        <p>Our modelOur model</p>
        <p>Automation in Construction 113 (2020) 103109Automation in Construction 113 (2020) 103109</p>
        <p>This work is part of the TTW Maps4Society project Smart 3D indoor models to support crisis management in large public buildings (13742) which is (partly) financed by the Netherlands Organisation for Scientific Research (NWO). The authors would like to thank the Fire Brigade Rotterdam Rijnmond, Fire Brigade Haaksbergen, and TU Delft for making their buildings available for the tests and data collection. We acknowledge Claudio Mura (University of Zürich) for providing the Penthouse dataset and the model for comparison.This work is part of the TTW Maps4Society project Smart 3D indoor models to support crisis management in large public buildings (13742) which is (partly) financed by the Netherlands Organisation for Scientific Research (NWO). The authors would like to thank the Fire Brigade Rotterdam Rijnmond, Fire Brigade Haaksbergen, and TU Delft for making their buildings available for the tests and data collection. We acknowledge Claudio Mura (University of Zürich) for providing the Penthouse dataset and the model for comparison.</p>
        <p>The authors have no conflicts of interest to declare.The authors have no conflicts of interest to declare.</p>
    </text>
</tei>
