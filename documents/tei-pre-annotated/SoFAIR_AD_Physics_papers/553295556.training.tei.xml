<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-14T14:18+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>In this report we review recent progress achieved in the understanding of heavy quarkonium under extreme conditions from a theory perspective. Its focus lies both on quarkonium properties in thermal equilibrium, as well as recent developments towards a genuine real-time description, valid also out-of-equilibrium. We will give an overview of the theory tools developed and deployed over the last decade, including effective field theories, lattice field theory simulations, modern methods for spectral reconstructions and the open quantum systems paradigm. The report will discuss in detail the concept of quarkonium melting, providing the reader with a contemporary perspective. In order to judge where future progress is needed we will also discuss recent results from experiments and phenomenological modeling of quarkonium in relativistic heavy-ion collisions.In this report we review recent progress achieved in the understanding of heavy quarkonium under extreme conditions from a theory perspective. Its focus lies both on quarkonium properties in thermal equilibrium, as well as recent developments towards a genuine real-time description, valid also out-of-equilibrium. We will give an overview of the theory tools developed and deployed over the last decade, including effective field theories, lattice field theory simulations, modern methods for spectral reconstructions and the open quantum systems paradigm. The report will discuss in detail the concept of quarkonium melting, providing the reader with a contemporary perspective. In order to judge where future progress is needed we will also discuss recent results from experiments and phenomenological modeling of quarkonium in relativistic heavy-ion collisions.</p>
        <p>It is not often to find a single species of particles, whose study has propelled our understanding of the strong interactions as thoroughly as heavy quarkonium did and does. The bound states of a heavy quark and its anti-quark (c and c is called charmonium, b and b bottomonium), more than 40 years after their first observation, still elicit fascination from both experimentalists and theorists due to their versatile role played in high energy nuclear physics. In this review we will consider one of the central foci in contemporary theoretical quarkonium studies, i.e. their behavior under extreme environmental conditions, which typically refers to energy and baryon densities of the order of mega electron volts and above. It is timely to take account of the status of the field, as over the past decade it has seen a boost in activity, taking on the challenge to go beyond the purely static notion of in-medium quarkonium it has refined over the years and to embark on a quest towards a microscopic understanding of quarkonium real-time dynamics.It is not often to find a single species of particles, whose study has propelled our understanding of the strong interactions as thoroughly as heavy quarkonium did and does. The bound states of a heavy quark and its anti-quark (c and c is called charmonium, b and b bottomonium), more than 40 years after their first observation, still elicit fascination from both experimentalists and theorists due to their versatile role played in high energy nuclear physics. In this review we will consider one of the central foci in contemporary theoretical quarkonium studies, i.e. their behavior under extreme environmental conditions, which typically refers to energy and baryon densities of the order of mega electron volts and above. It is timely to take account of the status of the field, as over the past decade it has seen a boost in activity, taking on the challenge to go beyond the purely static notion of in-medium quarkonium it has refined over the years and to embark on a quest towards a microscopic understanding of quarkonium real-time dynamics.</p>
        <p>Already in vacuum, heavy quarkonium constitutes a versatile laboratory of strongly interacting matter and of the underlying field theory of quantum chromo dynamics (QCD) (for a comprehensive review see [1]). A color singlet state with total spin J = 1 can only decay into three gluons (single gluon decays are prohibited due to energy-momentum conservation and color, two gluon decays due to charge conjugation, for the QED counterpart see e.g Ref. [2]). Each of the gluons carries a (relatively) large fraction of momentum and thus the associated coupling constant is (relatively) small, suppressing the decay probability even further. In that case the quarkonium forms an exceptionally stable bound state with inverse life times or equivalently spectral widths of τ -1 J/ψ ,Υ = Γ ∼ O (keV). On the other hand a pseudoscalar quarkonium state with J = 0 admits decays already into two gluons, leading to a decay width commensurate with other hadrons of τ -1 ηc ,η b = Γ ∼ O (MeV). The narrow widths of J = 1 quarkonium in turn lead to a significant fraction of their decays into dileptons e + e -and µ + µ -, which act as well accessible channels for their experimental detection. High precision data on heavy quarkonium vacuum properties, including masses and decay widths have been accumulated, as compiled in the PDG in Ref. [3], by a wealth of experiments, such as BELLE (KEK), BARBAR (SLAC), CLEO (FLAB), BESII+III (BEPC) and LHCb (CERN) to name only recent ones. Below the open heavy flavor threshold these states and their production in elementary collisions are well captured by the naive quark model and its quantum numbers for spin and colorAlready in vacuum, heavy quarkonium constitutes a versatile laboratory of strongly interacting matter and of the underlying field theory of quantum chromo dynamics (QCD) (for a comprehensive review see [1]). A color singlet state with total spin J = 1 can only decay into three gluons (single gluon decays are prohibited due to energy-momentum conservation and color, two gluon decays due to charge conjugation, for the QED counterpart see e.g Ref. [2]). Each of the gluons carries a (relatively) large fraction of momentum and thus the associated coupling constant is (relatively) small, suppressing the decay probability even further. In that case the quarkonium forms an exceptionally stable bound state with inverse life times or equivalently spectral widths of τ -1 J/ψ ,Υ = Γ ∼ O (keV). On the other hand a pseudoscalar quarkonium state with J = 0 admits decays already into two gluons, leading to a decay width commensurate with other hadrons of τ -1 ηc ,η b = Γ ∼ O (MeV). The narrow widths of J = 1 quarkonium in turn lead to a significant fraction of their decays into dileptons e + e -and µ + µ -, which act as well accessible channels for their experimental detection. High precision data on heavy quarkonium vacuum properties, including masses and decay widths have been accumulated, as compiled in the PDG in Ref. [3], by a wealth of experiments, such as BELLE (KEK), BARBAR (SLAC), CLEO (FLAB), BESII+III (BEPC) and LHCb (CERN) to name only recent ones. Below the open heavy flavor threshold these states and their production in elementary collisions are well captured by the naive quark model and its quantum numbers for spin and color</p>
        <p>Quarkonium like states above threshold, which exhibit quantum numbers beyond those available in the quark model, so called exotic XYZ states, are a current focus of quarkonium research at T = 0. The large charm and bottom quark mass compared to the intrinsic scale of quantum fluctuations in QCD, (Λ QCD /m Q ≪ 1), means that quarkonium in vacuum is amenable to a non-relativistic treatment (this fact will be further exploited in Section 2.2). In turn quarkonium states can be classified according to the well known scheme from atomic physics using spin, angular momentum and total spin as labels 2S+1 L J . Examples of so called S-wave states are the 3 S 1 Υ and J/ψ , the bottomonium and charmonium vector channel ground states. The χ c1 and χ b1 states on the other hand are classified as P-wave states with 3 P 1 . Thanks to the different values of the charm and bottom mass a variety of states exist, which exhibit a wide range of binding energies and related spatial extents, ranging from the deeply bound Υ with E bind = 1.1 GeV over χ b1 and J/ψ with nearly degenerate E bind ≈ 0.64 GeV to more weakly bound χ c1 with E bind ≈ 0.2 GeV. Note that binding energy here is defined as the difference in mass between the quarkonium state in question and the open heavy flavor threshold.Quarkonium like states above threshold, which exhibit quantum numbers beyond those available in the quark model, so called exotic XYZ states, are a current focus of quarkonium research at T = 0. The large charm and bottom quark mass compared to the intrinsic scale of quantum fluctuations in QCD, (Λ QCD /m Q ≪ 1), means that quarkonium in vacuum is amenable to a non-relativistic treatment (this fact will be further exploited in Section 2.2). In turn quarkonium states can be classified according to the well known scheme from atomic physics using spin, angular momentum and total spin as labels 2S+1 L J . Examples of so called S-wave states are the 3 S 1 Υ and J/ψ , the bottomonium and charmonium vector channel ground states. The χ c1 and χ b1 states on the other hand are classified as P-wave states with 3 P 1 . Thanks to the different values of the charm and bottom mass a variety of states exist, which exhibit a wide range of binding energies and related spatial extents, ranging from the deeply bound Υ with E bind = 1.1 GeV over χ b1 and J/ψ with nearly degenerate E bind ≈ 0.64 GeV to more weakly bound χ c1 with E bind ≈ 0.2 GeV. Note that binding energy here is defined as the difference in mass between the quarkonium state in question and the open heavy flavor threshold.</p>
        <p>The non-relativistic nature of T = 0 quarkonium makes it possible to capture the properties of these states with good accuracy in a simple potential model, consisting of a Coulombic part at small separation distances and a linearly rising part at large distances, the so called Cornell potential (see e.g. the classic Ref. [4]). This model hence exhibits the two hallmarks of QCD, asymptotic freedom and confinement. In order to accommodate the fact that only a finite number of quarkonium state are stable bound states, the Cornell potential in practice is usually flattened off at a phenomenologically chosen string breaking radius. This flattened part translates into the open heavy-flavor threshold. The many different quarkonium states accommodated by this simple model, according to their depth of binding, allow us to explore in detail the physics associated with both phenomena. Heavy quarkonium at T = 0 has also been explored using lattice QCD simulations where high precision post-and predictions of bound state masses have been achieved (see e.g. Fig. 20 in Ref. [5]), providing a direct link between the microscopic theory of QCD and experiment. (bottom) The tentative life cycle of heavy quarkonium in the context of a relativistic heavy-ion collision.The non-relativistic nature of T = 0 quarkonium makes it possible to capture the properties of these states with good accuracy in a simple potential model, consisting of a Coulombic part at small separation distances and a linearly rising part at large distances, the so called Cornell potential (see e.g. the classic Ref. [4]). This model hence exhibits the two hallmarks of QCD, asymptotic freedom and confinement. In order to accommodate the fact that only a finite number of quarkonium state are stable bound states, the Cornell potential in practice is usually flattened off at a phenomenologically chosen string breaking radius. This flattened part translates into the open heavy-flavor threshold. The many different quarkonium states accommodated by this simple model, according to their depth of binding, allow us to explore in detail the physics associated with both phenomena. Heavy quarkonium at T = 0 has also been explored using lattice QCD simulations where high precision post-and predictions of bound state masses have been achieved (see e.g. Fig. 20 in Ref. [5]), providing a direct link between the microscopic theory of QCD and experiment. (bottom) The tentative life cycle of heavy quarkonium in the context of a relativistic heavy-ion collision.</p>
        <p>The motivation to study heavy quarkonium under extreme conditions is intimately related to exploring the physics of strongly interacting matter in the early universe (for an introduction to the topic see e.g. [6]). At around 10 -20 s after the Big Bang and at correspondingly high temperatures of 100s of MeV the universe is expected to have been filled with nuclear matter in the form of its microscopic building blocks, quarks and gluons, forming a strongly correlated quark-gluon plasma (QGP). In order to understand how the strong interactions behave under such extreme conditions, quarkonium can again play an important role. Due to the deep binding of e.g. Υ , this bound state is expected to exist deep into the QGP phase, meaning that it can still act as well defined experimental observable there. At the same time the separation of scales between binding energy and temperature underlying this stability implies that even under such extreme conditions theoretical tools developed originally in vacuum have a chance to be extended to provide meaningful insight. I.e. quarkonium promises to retain its role as well controlled QCD laboratory even in the context of strongly interacting matter in the early universe.The motivation to study heavy quarkonium under extreme conditions is intimately related to exploring the physics of strongly interacting matter in the early universe (for an introduction to the topic see e.g. [6]). At around 10 -20 s after the Big Bang and at correspondingly high temperatures of 100s of MeV the universe is expected to have been filled with nuclear matter in the form of its microscopic building blocks, quarks and gluons, forming a strongly correlated quark-gluon plasma (QGP). In order to understand how the strong interactions behave under such extreme conditions, quarkonium can again play an important role. Due to the deep binding of e.g. Υ , this bound state is expected to exist deep into the QGP phase, meaning that it can still act as well defined experimental observable there. At the same time the separation of scales between binding energy and temperature underlying this stability implies that even under such extreme conditions theoretical tools developed originally in vacuum have a chance to be extended to provide meaningful insight. I.e. quarkonium promises to retain its role as well controlled QCD laboratory even in the context of strongly interacting matter in the early universe.</p>
        <p>Experimental efforts to recreate the conditions in the early universe have led to the construction of a series of collider facilities and accompanying experiments specialized in relativistic heavy-ion collisions. Starting with SPS at CERN ( √ s NN ≈ 0.15 TeV), followed by RHIC at BNL ( √ s NN = 0.2 TeV) and most recently the LHC, again located at CERN ( √ s NN = 2.76, 5.02 TeV), higher and higher energy ranges for the collision of heavy nuclei, mainly gold and lead, have been explored. In the near future new accelerator facilities devoted to heavy-ion collisions are going online, among them NICA at JINR and FAIR at GSI, possible also a machine at JPARC. All of them feature experiments that are devoted towards the measurement of quarkonium properties under extreme conditions. Over the past decade the interplay of experiment, phenomenology and theory has led to an improved understanding of the different stages of a heavy-ion collision as sketched in Fig. 1. In the instant of the collision, the partons within the highly Lorentz contracted nuclear projectiles, which have formed a color glass condensate (CGC), are able to interact, leading to the generation of strong coherent color electric and color magnetic fields called the glasma. These subsequently fragment into light quarks and gluons, which efficiently exchange energy and momentum, so that after a short prethermalization phase of around 1 fm a locally equilibrated collection of deconfined quarks and gluons emerges. This strongly correlated quark-gluon-plasma expands and cools over a period of 5-10 fm before it reaches the crossover transition at T C = 156.5 ± 1.5 MeV (see [7][8][9]), where colored partons have to combine into color neutral hadrons.Experimental efforts to recreate the conditions in the early universe have led to the construction of a series of collider facilities and accompanying experiments specialized in relativistic heavy-ion collisions. Starting with SPS at CERN ( √ s NN ≈ 0.15 TeV), followed by RHIC at BNL ( √ s NN = 0.2 TeV) and most recently the LHC, again located at CERN ( √ s NN = 2.76, 5.02 TeV), higher and higher energy ranges for the collision of heavy nuclei, mainly gold and lead, have been explored. In the near future new accelerator facilities devoted to heavy-ion collisions are going online, among them NICA at JINR and FAIR at GSI, possible also a machine at JPARC. All of them feature experiments that are devoted towards the measurement of quarkonium properties under extreme conditions. Over the past decade the interplay of experiment, phenomenology and theory has led to an improved understanding of the different stages of a heavy-ion collision as sketched in Fig. 1. In the instant of the collision, the partons within the highly Lorentz contracted nuclear projectiles, which have formed a color glass condensate (CGC), are able to interact, leading to the generation of strong coherent color electric and color magnetic fields called the glasma. These subsequently fragment into light quarks and gluons, which efficiently exchange energy and momentum, so that after a short prethermalization phase of around 1 fm a locally equilibrated collection of deconfined quarks and gluons emerges. This strongly correlated quark-gluon-plasma expands and cools over a period of 5-10 fm before it reaches the crossover transition at T C = 156.5 ± 1.5 MeV (see [7][8][9]), where colored partons have to combine into color neutral hadrons.</p>
        <p>While the chemical abundances of these hadrons are established at around this temperature in what is called chemical freezeout, the resulting gas of hadrons may still interact and exchange energy and momentum until kinetic freezeout is reached.While the chemical abundances of these hadrons are established at around this temperature in what is called chemical freezeout, the resulting gas of hadrons may still interact and exchange energy and momentum until kinetic freezeout is reached.</p>
        <p>How did we end up with this dynamical picture of a heavy-ion collisions? While QCD contains all the physics necessary to describe the evolution of the light bulk matter it has not yet been established how to compute the dynamics of a heavy-ion collision from first principles QCD based on e.g. lattice QCD simulations. The underlying reason is the notorious sign problem. It refers to the fact that the Feynman path integral of a quantum field theory formulated in Minkowski time does not admit a simple probabilistic interpretation due to the complex phase factor exp [iS] and in turn otherwise well established numerical methods, such as Monte Carlo sampling are not applicable (for a review see e.g. Ref. [10]). In addition, the fact that the QGP in a contemporary heavy-ion collision is created at temperatures of up to just T ≲ 600 MeV, as deduced from hydrodynamic modeling of the bulk (see e.g. Ref. [11] or [12]), prevents the use of weak-coupling methods, which are the bedrock of theory computations in elementary particle collisions.How did we end up with this dynamical picture of a heavy-ion collisions? While QCD contains all the physics necessary to describe the evolution of the light bulk matter it has not yet been established how to compute the dynamics of a heavy-ion collision from first principles QCD based on e.g. lattice QCD simulations. The underlying reason is the notorious sign problem. It refers to the fact that the Feynman path integral of a quantum field theory formulated in Minkowski time does not admit a simple probabilistic interpretation due to the complex phase factor exp [iS] and in turn otherwise well established numerical methods, such as Monte Carlo sampling are not applicable (for a review see e.g. Ref. [10]). In addition, the fact that the QGP in a contemporary heavy-ion collision is created at temperatures of up to just T ≲ 600 MeV, as deduced from hydrodynamic modeling of the bulk (see e.g. Ref. [11] or [12]), prevents the use of weak-coupling methods, which are the bedrock of theory computations in elementary particle collisions.</p>
        <p>Instead of trying to solve QCD in its entirety, it turns out that so called effective field theories (EFT) provide an efficient and elegant way to shed light on the physics of interest. An EFT attempts to describe explicitly only a part of the physics, i.e. those degrees of freedom that are relevant (in a sense to be made specific in Section 2.2) at a particular stage of the collision. By focusing on such a subset of degrees of freedom, the problem at hand can be simplified far enough so that a dynamical description may be directly derived from QCD, often in a non-perturbative manner. If such effective descriptions furthermore share a common range of validity they can be chained together to provide a consistent description of the dynamics. In the context of bulk matter a combination of classical statistical simulations of Yang-Mills fields in the earliest stage, followed by kinetic theory, which in turn smoothly matches onto a relativistic hydrodynamic description of the QGP has proven to be a successful strategy. In this report we will explore several avenues of how effective field theories can also support a comprehensive understanding of quarkonium in heavy-ion collisions.Instead of trying to solve QCD in its entirety, it turns out that so called effective field theories (EFT) provide an efficient and elegant way to shed light on the physics of interest. An EFT attempts to describe explicitly only a part of the physics, i.e. those degrees of freedom that are relevant (in a sense to be made specific in Section 2.2) at a particular stage of the collision. By focusing on such a subset of degrees of freedom, the problem at hand can be simplified far enough so that a dynamical description may be directly derived from QCD, often in a non-perturbative manner. If such effective descriptions furthermore share a common range of validity they can be chained together to provide a consistent description of the dynamics. In the context of bulk matter a combination of classical statistical simulations of Yang-Mills fields in the earliest stage, followed by kinetic theory, which in turn smoothly matches onto a relativistic hydrodynamic description of the QGP has proven to be a successful strategy. In this report we will explore several avenues of how effective field theories can also support a comprehensive understanding of quarkonium in heavy-ion collisions.</p>
        <p>The life cycle of heavy quarkonium is aligned with the different stages of a contemporary heavy-ion collision. Due to the required energies and virtualities, only in the earliest moments of the collision can c c and b b pairs be created. At RHIC O(10)c c and O(1)b b pairs are expected to arise in each collision, while at LHC their number already increases to O (100) and O (10) respectively. A simple estimate based on the binding energy of individual states and the uncertainty principle suggests that a deeply bound quarkonium can form early on in the pre-thermal stage of the collision. Whether such early formation indeed takes place however remains an active field of research.The life cycle of heavy quarkonium is aligned with the different stages of a contemporary heavy-ion collision. Due to the required energies and virtualities, only in the earliest moments of the collision can c c and b b pairs be created. At RHIC O(10)c c and O(1)b b pairs are expected to arise in each collision, while at LHC their number already increases to O (100) and O (10) respectively. A simple estimate based on the binding energy of individual states and the uncertainty principle suggests that a deeply bound quarkonium can form early on in the pre-thermal stage of the collision. Whether such early formation indeed takes place however remains an active field of research.</p>
        <p>A pre-formed state that finds itself immersed in the medium consisting of light bulk matter then interacts with this hot medium during the QGP phase, which will in general weaken its binding. Depending on the energy and time scales present, quarkonium may either survive the medium or its constituents may become decorrelated, i.e. the state melts. The inverse process is also fathomable if enough quark-antiquark pairs are present, i.e. quarkonium states may be regenerated. If the lifetime of the medium is long enough, the heavy quarks may even become kinetically equilibrated with the surrounding medium. They however will remain out of chemical equilibrium as their numbers do not change in a medium at temperatures T ≪ m Q . How exactly quarkonium states interact with a deconfined medium and in turn approach equilibrium with their surroundings is one of the central questions theory sets out to answer.A pre-formed state that finds itself immersed in the medium consisting of light bulk matter then interacts with this hot medium during the QGP phase, which will in general weaken its binding. Depending on the energy and time scales present, quarkonium may either survive the medium or its constituents may become decorrelated, i.e. the state melts. The inverse process is also fathomable if enough quark-antiquark pairs are present, i.e. quarkonium states may be regenerated. If the lifetime of the medium is long enough, the heavy quarks may even become kinetically equilibrated with the surrounding medium. They however will remain out of chemical equilibrium as their numbers do not change in a medium at temperatures T ≪ m Q . How exactly quarkonium states interact with a deconfined medium and in turn approach equilibrium with their surroundings is one of the central questions theory sets out to answer.</p>
        <p>At hadronization most of the decorrelated heavy quarks combine with a light quark to form open heavy flavor particles (D or B mesons). On the other hand if a large enough number of pairs has been created early on, they may now also recombine into quarkonium. If an in-medium bound state exists (primordial or regenerated) it will transition into a vacuum state. Note that the dynamics of hadronization are among the least well understood aspects of quarkonium in heavy-ion collisions. After leaving the QGP a collection of quarkonium states will have formed, some of which may still decay into a lower lying state on the way to the detector. I.e. the final abundances as measured by experiment will come from the dilepton signals of vacuum states long after the QGP has ceased to exist. For theory the challenge consists of translating the knowledge gained about heavy quarkonium in a medium, relevant for the QGP phase, into such vacuum abundances in the end, if a connection to the measured yields is to be made.At hadronization most of the decorrelated heavy quarks combine with a light quark to form open heavy flavor particles (D or B mesons). On the other hand if a large enough number of pairs has been created early on, they may now also recombine into quarkonium. If an in-medium bound state exists (primordial or regenerated) it will transition into a vacuum state. Note that the dynamics of hadronization are among the least well understood aspects of quarkonium in heavy-ion collisions. After leaving the QGP a collection of quarkonium states will have formed, some of which may still decay into a lower lying state on the way to the detector. I.e. the final abundances as measured by experiment will come from the dilepton signals of vacuum states long after the QGP has ceased to exist. For theory the challenge consists of translating the knowledge gained about heavy quarkonium in a medium, relevant for the QGP phase, into such vacuum abundances in the end, if a connection to the measured yields is to be made.</p>
        <p>As we will argue in this report, only a comprehensive microscopic understanding of all the different stages of the collision will reveal the nature of heavy quarkonium production. I.e. in order to improve our understanding of heavy quarkonium we are incentivized to also gain a better understanding of many other aspects of strongly interacting matter, be it the composition of the incoming nuclei projectiles or the general dynamics of hadronization.As we will argue in this report, only a comprehensive microscopic understanding of all the different stages of the collision will reveal the nature of heavy quarkonium production. I.e. in order to improve our understanding of heavy quarkonium we are incentivized to also gain a better understanding of many other aspects of strongly interacting matter, be it the composition of the incoming nuclei projectiles or the general dynamics of hadronization.</p>
        <p>One of the most influential early theory studies regarding heavy quarkonium in heavy-ion collisions is Ref. [13] by Matsui and Satz, which shapes intuition about quarkonium production to this day. In this report we will explore which of these early ideas have stood the test of time and which aspects have been overhauled over the past decade.One of the most influential early theory studies regarding heavy quarkonium in heavy-ion collisions is Ref. [13] by Matsui and Satz, which shapes intuition about quarkonium production to this day. In this report we will explore which of these early ideas have stood the test of time and which aspects have been overhauled over the past decade.</p>
        <p>Ref. [13] contains two central ideas. The first is based on an analogy with an electromagnetic plasma in thermal equilibrium. There, the presence of freely moving light charges screens static electric fields (Debye screening), i.e. fields generated by heavy test charges inserted into the medium. In turn it was argued that the presence of a quark-gluon plasma will also weaken the binding between heavy quarks and thus destabilize existing quarkonium, as well as prevent the formation from thermal quark-antiquark pairs. As we will discuss in Section 3.1, by now the presence of screening in a hot QCD medium has been thoroughly established and its strength explored using different non-perturbative means.Ref. [13] contains two central ideas. The first is based on an analogy with an electromagnetic plasma in thermal equilibrium. There, the presence of freely moving light charges screens static electric fields (Debye screening), i.e. fields generated by heavy test charges inserted into the medium. In turn it was argued that the presence of a quark-gluon plasma will also weaken the binding between heavy quarks and thus destabilize existing quarkonium, as well as prevent the formation from thermal quark-antiquark pairs. As we will discuss in Section 3.1, by now the presence of screening in a hot QCD medium has been thoroughly established and its strength explored using different non-perturbative means.</p>
        <p>The picture that Ref. [13] paints and which was made more quantitative in Ref. [14] is one of sequential quarkonium melting. Using a completely static notion of kinetically equilibrated in-medium quarkonium as time independent eigenstates of a hermitean in-medium Hamiltonian, the authors argued that there exist well defined melting temperatures at which quarkonium states instantaneously turn from bound to scattering state. This in turn invited the intuitive picture of quarkonium as a thermometer, indicating the temperature of its environment by what states remain bound and which do not.The picture that Ref. [13] paints and which was made more quantitative in Ref. [14] is one of sequential quarkonium melting. Using a completely static notion of kinetically equilibrated in-medium quarkonium as time independent eigenstates of a hermitean in-medium Hamiltonian, the authors argued that there exist well defined melting temperatures at which quarkonium states instantaneously turn from bound to scattering state. This in turn invited the intuitive picture of quarkonium as a thermometer, indicating the temperature of its environment by what states remain bound and which do not.</p>
        <p>Our understanding of quarkonium took a significant step forward, when the study of Ref. [15] revealed that the potential governing the evolution of the quarkonium system contains an imaginary part. This finding, followed up in Refs. [16,17], asks us to abandon the notion of the static in-medium states that Matsui and Satz built their intuition around and embrace the fact that quarkonium constantly experiences kicks by scatterers in the surrounding medium. It also rekindled interest in understanding in detail how the microscopic wavefunction of the quarkonium system evolves in time in the presence of such scattering processes and how they give rise to an imaginary part of the potential dynamically. This highly non-trivial question has led the community to the framework of open quantum systems, discussed in detail in Section 4.Our understanding of quarkonium took a significant step forward, when the study of Ref. [15] revealed that the potential governing the evolution of the quarkonium system contains an imaginary part. This finding, followed up in Refs. [16,17], asks us to abandon the notion of the static in-medium states that Matsui and Satz built their intuition around and embrace the fact that quarkonium constantly experiences kicks by scatterers in the surrounding medium. It also rekindled interest in understanding in detail how the microscopic wavefunction of the quarkonium system evolves in time in the presence of such scattering processes and how they give rise to an imaginary part of the potential dynamically. This highly non-trivial question has led the community to the framework of open quantum systems, discussed in detail in Section 4.</p>
        <p>Among others it turns out that in the novel dynamical picture the concept of melting temperature is not uniquely defined and thus plays a less decisive role as originally thought. The intuition that those states, which are more weakly bound in vacuum, are more easily destroyed in a medium of course remains true, as elucidated by direct lattice QCD studies of in-medium quarkonium in Section 3.3. At the same time we will see that the physics of quarkonium melting cannot be cast into a static language and instead requires a genuine dynamical treatment. This dynamical treatment will also unify how we think about the melting of charmonium and bottomonium. The legacy picture of heavy quarkonium as static thermometer. After fully kinetically equilibrating the heavy quark state one asks about the probability of its survival in the hot environment. (right) The modern picture of quarkonium melting as a dynamical process, in which the medium acts as a sieve that filters out quarkonium states over time, depending on the strength of their binding.Among others it turns out that in the novel dynamical picture the concept of melting temperature is not uniquely defined and thus plays a less decisive role as originally thought. The intuition that those states, which are more weakly bound in vacuum, are more easily destroyed in a medium of course remains true, as elucidated by direct lattice QCD studies of in-medium quarkonium in Section 3.3. At the same time we will see that the physics of quarkonium melting cannot be cast into a static language and instead requires a genuine dynamical treatment. This dynamical treatment will also unify how we think about the melting of charmonium and bottomonium. The legacy picture of heavy quarkonium as static thermometer. After fully kinetically equilibrating the heavy quark state one asks about the probability of its survival in the hot environment. (right) The modern picture of quarkonium melting as a dynamical process, in which the medium acts as a sieve that filters out quarkonium states over time, depending on the strength of their binding.</p>
        <p>In order to build intuition of how the static and dynamic descriptions of quarkonium differ, let us consider how even in everyday life there are two ways how to measure temperature. One may either bring into contact with the object of study, say a cup of hot earl gray tea, a second smaller system, a thermometer. This thermometer, after mutual equilibration is removed and its internal state interrogated on the, by that time, common temperature. This form of temperature measurement requires the two systems to be in contact for long enough that full thermalization is achieved. It is this static picture that is promoted by Ref. [13] for the case of quarkonium as thermometer. Note that while equilibration of charm quarks turns out to be realized to some degree at the highest available collider energies today, bottomonium so far does not show significant signs of equilibration.In order to build intuition of how the static and dynamic descriptions of quarkonium differ, let us consider how even in everyday life there are two ways how to measure temperature. One may either bring into contact with the object of study, say a cup of hot earl gray tea, a second smaller system, a thermometer. This thermometer, after mutual equilibration is removed and its internal state interrogated on the, by that time, common temperature. This form of temperature measurement requires the two systems to be in contact for long enough that full thermalization is achieved. It is this static picture that is promoted by Ref. [13] for the case of quarkonium as thermometer. Note that while equilibration of charm quarks turns out to be realized to some degree at the highest available collider energies today, bottomonium so far does not show significant signs of equilibration.</p>
        <p>On the other hand we may use a dynamical process to measure temperature. For our cup of tea it amounts to inserting e.g. a sugar cube and to observe how over time the chemical bonds are dissolved one by one. The speed by which this process happens informs us about the temperature present. The important difference to the static approach is that the measurement here can be performed even without reaching mutual equilibrium between sugar cube and tea. Besides the temperature of the environment it is now the timescales for which the process is allowed to proceed, which determine the fate of the sugar cube. Removing it quickly from a very hot surrounding will leave the bonds relatively intact, while even in a cold environment the sugar cube may melt as long as we wait long enough.On the other hand we may use a dynamical process to measure temperature. For our cup of tea it amounts to inserting e.g. a sugar cube and to observe how over time the chemical bonds are dissolved one by one. The speed by which this process happens informs us about the temperature present. The important difference to the static approach is that the measurement here can be performed even without reaching mutual equilibrium between sugar cube and tea. Besides the temperature of the environment it is now the timescales for which the process is allowed to proceed, which determine the fate of the sugar cube. Removing it quickly from a very hot surrounding will leave the bonds relatively intact, while even in a cold environment the sugar cube may melt as long as we wait long enough.</p>
        <p>The change in intuition for quarkonium melting we invite the reader to explore in this report, and which is sketched in Fig. 2 is analogous. When a quarkonium vacuum state is immersed in a hot medium, its binding will over time become weakened. It is then the interplay of how strongly the medium interferes with the binding at any instant, as well as the time spent in the medium that determines the survival of the quarkonium state. The hot medium in turn becomes a sieve that dynamically filters out more weakly bound states first while allows more strongly bound state to survive for longer time. One exciting recent development in quarkonium theory is that by using the open quantum systems framework, originally developed in the context of condensed matter theory, a dynamical description of such a small quarkonium system immersed in a hot QCD environment can be systematically derived from microscopic QCD. It turns out that quarkonium melting is actually intimately connected with the phenomenon of decoherence.The change in intuition for quarkonium melting we invite the reader to explore in this report, and which is sketched in Fig. 2 is analogous. When a quarkonium vacuum state is immersed in a hot medium, its binding will over time become weakened. It is then the interplay of how strongly the medium interferes with the binding at any instant, as well as the time spent in the medium that determines the survival of the quarkonium state. The hot medium in turn becomes a sieve that dynamically filters out more weakly bound states first while allows more strongly bound state to survive for longer time. One exciting recent development in quarkonium theory is that by using the open quantum systems framework, originally developed in the context of condensed matter theory, a dynamical description of such a small quarkonium system immersed in a hot QCD environment can be systematically derived from microscopic QCD. It turns out that quarkonium melting is actually intimately connected with the phenomenon of decoherence.</p>
        <p>Let us now come to the second idea of Ref. [13], which took the melting picture and applied it straight forwardly to quarkonium production in heavy-ion collision. In turn it suggested an equally sequential suppression of quarkonium yields in the presence of a hot QGP medium in the collision center. This suppression arises both from the actual destabilization of bound states, as well as diminished feed-down from higher lying states that melt more easily. In turn quarkonium suppression was positioned as a gold plated signal for the creation of a deconfined quark-gluon plasma in heavy-ion collisions. For bottomonium only a small number of quark-antiquark pairs are produced in the initial stages of current heavy-ion. Its production is thus dominated by primordial quarkonium traveling through a QGP in the collision center and indeed clear signs for such sequential suppression are observed.Let us now come to the second idea of Ref. [13], which took the melting picture and applied it straight forwardly to quarkonium production in heavy-ion collision. In turn it suggested an equally sequential suppression of quarkonium yields in the presence of a hot QGP medium in the collision center. This suppression arises both from the actual destabilization of bound states, as well as diminished feed-down from higher lying states that melt more easily. In turn quarkonium suppression was positioned as a gold plated signal for the creation of a deconfined quark-gluon plasma in heavy-ion collisions. For bottomonium only a small number of quark-antiquark pairs are produced in the initial stages of current heavy-ion. Its production is thus dominated by primordial quarkonium traveling through a QGP in the collision center and indeed clear signs for such sequential suppression are observed.</p>
        <p>On the other hand, the system originally discussed by Ref. [13], i.e. charmonium, turns out to be an instructive tale how in general in a heavy-ion collision the physics of all stages need to be considered carefully to arrive at a comprehensive picture of quarkonium production. I.e. the production of c c pairs in the initial stages can significantly alter the production mechanism. Indeed, as we understand today, and , was first proposed in Refs. [18,19], quarkonium yields may be replenished by the recombination of quark-antiquark pairs both during the QGP phase as well as at the moment of hadronization. While this mechanism was noted early on by Matsui in Ref. [20] at that time it was not followed up further. With the prospect of the RHIC collider on the horizon, regeneration and recombination were considered in much more detail and have over time become vital ingredients in the explanation of measured charmonium yields at RHIC and most prominently at LHC.On the other hand, the system originally discussed by Ref. [13], i.e. charmonium, turns out to be an instructive tale how in general in a heavy-ion collision the physics of all stages need to be considered carefully to arrive at a comprehensive picture of quarkonium production. I.e. the production of c c pairs in the initial stages can significantly alter the production mechanism. Indeed, as we understand today, and , was first proposed in Refs. [18,19], quarkonium yields may be replenished by the recombination of quark-antiquark pairs both during the QGP phase as well as at the moment of hadronization. While this mechanism was noted early on by Matsui in Ref. [20] at that time it was not followed up further. With the prospect of the RHIC collider on the horizon, regeneration and recombination were considered in much more detail and have over time become vital ingredients in the explanation of measured charmonium yields at RHIC and most prominently at LHC.</p>
        <p>In other words, while the concept of sequential quarkonium melting in its modern dynamical fashion remains a valid guiding principle for the understanding of heavy quarkonium in extreme conditions, quarkonium suppression in heavy ion-collision arises from the subtle interplay of several different mechanisms, requiring insight into all different stages of the collision from heavy quark pair production over the QGP phase to hadronization.In other words, while the concept of sequential quarkonium melting in its modern dynamical fashion remains a valid guiding principle for the understanding of heavy quarkonium in extreme conditions, quarkonium suppression in heavy ion-collision arises from the subtle interplay of several different mechanisms, requiring insight into all different stages of the collision from heavy quark pair production over the QGP phase to hadronization.</p>
        <p>What remains then of the role of quarkonium as probe of the quark-gluon plasma? While not as simple as a static thermometer, charmonium and bottomonium provide vital insight into the hot matter created in a heavy-ion collision. The fact that bottomonium at LHC appears to behave still as a genuine test-particle not equilibrated with its surroundings allows it to sample the full time evolution of the QGP. On the other hand charmonium at LHC shows clear signs of kinetic equilibration with its surroundings. This entails a loss of memory about the initial conditions of its evolution, positioning it as a probe of the late stages of the collision. Again the availability of bound states of different sizes and binding energies allows quarkonium to be a versatile laboratory of the strong interactions even under extreme conditions.What remains then of the role of quarkonium as probe of the quark-gluon plasma? While not as simple as a static thermometer, charmonium and bottomonium provide vital insight into the hot matter created in a heavy-ion collision. The fact that bottomonium at LHC appears to behave still as a genuine test-particle not equilibrated with its surroundings allows it to sample the full time evolution of the QGP. On the other hand charmonium at LHC shows clear signs of kinetic equilibration with its surroundings. This entails a loss of memory about the initial conditions of its evolution, positioning it as a probe of the late stages of the collision. Again the availability of bound states of different sizes and binding energies allows quarkonium to be a versatile laboratory of the strong interactions even under extreme conditions.</p>
        <p>In this report we focus on the theory developments over the last decade that have significantly improved our understanding of the dynamical nature of heavy quarkonium in a hot medium and in turn in heavy-ion collisions. We start out in Section 2 with a review of theory tools that are vital ingredients in contemporary studies of quarkonium in medium. These include a brief recap of (non-)equilibrium quantum field theory and the concept of spectral functions in Section 2.1, effective field theories for heavy quarkonium in Section 2.2, lattice QCD in Section 2.3, modern methods for spectral function reconstruction in Section 2.4, as well as the open quantum systems framework in Section 2. 5.In this report we focus on the theory developments over the last decade that have significantly improved our understanding of the dynamical nature of heavy quarkonium in a hot medium and in turn in heavy-ion collisions. We start out in Section 2 with a review of theory tools that are vital ingredients in contemporary studies of quarkonium in medium. These include a brief recap of (non-)equilibrium quantum field theory and the concept of spectral functions in Section 2.1, effective field theories for heavy quarkonium in Section 2.2, lattice QCD in Section 2.3, modern methods for spectral function reconstruction in Section 2.4, as well as the open quantum systems framework in Section 2. 5.</p>
        <p>At first we will consider the idealized setting of fully kinetically equilibrated heavy-quarkonium immersed into a static medium in Section 3. Here it is possible to investigate the questions of screening in QCD (Section 3.1), the concept of the complex valued in-medium potential (Section 3.2) and most importantly the in-medium spectral properties of quarkonium (Section 3.3) directly from first principles by utilizing modern concepts of effective field theories and lattice QCD. The concept of quarkonium melting in thermal equilibrium is discussed in Section 3.4 and its dynamical nature is emphasized.At first we will consider the idealized setting of fully kinetically equilibrated heavy-quarkonium immersed into a static medium in Section 3. Here it is possible to investigate the questions of screening in QCD (Section 3.1), the concept of the complex valued in-medium potential (Section 3.2) and most importantly the in-medium spectral properties of quarkonium (Section 3.3) directly from first principles by utilizing modern concepts of effective field theories and lattice QCD. The concept of quarkonium melting in thermal equilibrium is discussed in Section 3.4 and its dynamical nature is emphasized.</p>
        <p>In order to do justice to the dynamical nature of quarkonium even in thermal equilibrium Section 4 sets out to review recent exciting progress made in the theory community in deriving genuine real-time descriptions for heavy quarkonium from first principles QCD. The open quantum systems framework is instrumental in this task and leads to so called Lindblad equations. From the recent activities in the community, we will highlight several derivations of quarkonium evolution equations, one that can be expressed in the language of wavefunctions (in Section 4.1) one in the language of distribution functions and a third one that is formulated in terms of transport coefficients (in Section 4.3). The former, for the first time, allows to construct a stochastic non-linear Schrödinger equation for quarkonium from first principles, which previously had been proposed on purely phenomenological grounds. The latter section provides a direct connection between QCD and the Boltzmann equation deployed in many transport models of in-medium quarkonium. Not only has it become possible to better understand the dynamical role played by the imaginary part of the in-medium potential in the evolution of the quarkonium wavefunction but also to connect quarkonium melting to the phenomenon of wavefunction decoherence, as discussed in Section 4.2.In order to do justice to the dynamical nature of quarkonium even in thermal equilibrium Section 4 sets out to review recent exciting progress made in the theory community in deriving genuine real-time descriptions for heavy quarkonium from first principles QCD. The open quantum systems framework is instrumental in this task and leads to so called Lindblad equations. From the recent activities in the community, we will highlight several derivations of quarkonium evolution equations, one that can be expressed in the language of wavefunctions (in Section 4.1) one in the language of distribution functions and a third one that is formulated in terms of transport coefficients (in Section 4.3). The former, for the first time, allows to construct a stochastic non-linear Schrödinger equation for quarkonium from first principles, which previously had been proposed on purely phenomenological grounds. The latter section provides a direct connection between QCD and the Boltzmann equation deployed in many transport models of in-medium quarkonium. Not only has it become possible to better understand the dynamical role played by the imaginary part of the in-medium potential in the evolution of the quarkonium wavefunction but also to connect quarkonium melting to the phenomenon of wavefunction decoherence, as discussed in Section 4.2.</p>
        <p>In Section 5 we return to the question of quarkonium production in heavy-ion collisions. In order to showcase the complexities of the task at hand we first discuss the physics of quarkonium production in pp collisions in Section 5.1 and briefly touch on cold nuclear matter effects in Section 5.2. The main discussion of quarkonium production in nucleus-nucleus collisions follows in Section 5.3 considering separately charmonium in Section 5.3.1 and bottomonium in Section 5.3.2. Here we will scout for opportunities how progress in the real-time description of heavy quarkonium can help to discriminate between current models and eventually allows us to arrive at a genuine first principles based description of the measured production yields.In Section 5 we return to the question of quarkonium production in heavy-ion collisions. In order to showcase the complexities of the task at hand we first discuss the physics of quarkonium production in pp collisions in Section 5.1 and briefly touch on cold nuclear matter effects in Section 5.2. The main discussion of quarkonium production in nucleus-nucleus collisions follows in Section 5.3 considering separately charmonium in Section 5.3.1 and bottomonium in Section 5.3.2. Here we will scout for opportunities how progress in the real-time description of heavy quarkonium can help to discriminate between current models and eventually allows us to arrive at a genuine first principles based description of the measured production yields.</p>
        <p>This report aims at highlighting the recent progress achieved in the theory community and builds on the cumulative efforts of many research groups (for previous reviews on in-medium quarkonium see e.g. Refs. [21][22][23]). Therefore the author attempts to provide the appropriate references for each discussed topic, and strongly encourages the citation of that original research.This report aims at highlighting the recent progress achieved in the theory community and builds on the cumulative efforts of many research groups (for previous reviews on in-medium quarkonium see e.g. Refs. [21][22][23]). Therefore the author attempts to provide the appropriate references for each discussed topic, and strongly encourages the citation of that original research.</p>
        <p>In the following five sections we will give an overview to central theory tools used today in the study of quarkonium in extreme conditions. Their purpose is to provide a reference on concepts, techniques and quantities of interest prevalent in the literature. The included references also provide a starting point for newcomers to the field to embark on a more in-depth exploration.In the following five sections we will give an overview to central theory tools used today in the study of quarkonium in extreme conditions. Their purpose is to provide a reference on concepts, techniques and quantities of interest prevalent in the literature. The included references also provide a starting point for newcomers to the field to embark on a more in-depth exploration.</p>
        <p>In general, theoretical studies of quarkonium aim at an understanding of its physics from first principles. I.e. their starting point is a microscopic description of the strong interactions, the quantum field theory quantum-chromo-dynamics, defined with the following gauge invariant classical actionIn general, theoretical studies of quarkonium aim at an understanding of its physics from first principles. I.e. their starting point is a microscopic description of the strong interactions, the quantum field theory quantum-chromo-dynamics, defined with the following gauge invariant classical action</p>
        <p>))</p>
        <p>formulated in terms of matrix valued gluon fields A µ = A a µ T a where T a refers the generators of SU (3). Their covariant derivative reads D µ = ∂ µ + igA µ with g the strong coupling. We denote light quarks of different flavor with ψ j and heavy quarks with Q k (in the following we will often omit the flavor label for the heavy quarks). This action remains invariant under local rotations Λ(x) in SU (3) color space, acting as ψ ′ a (x) = Λ ab (x)ψ b (x) and (A ′ µ ) ab (x) = Λ ac (x)A cd µ (x)(Λ † ) db (x) + i(∂ µ Λ ac (x))(Λ cb ) † (x). The distinction between light and heavy quarks will be exploited in the section on effective field theories and open quantum systems. It is from fully quantized QCD that one wishes to deduce quarkonium properties in thermal equilibrium, as well as its real-time evolution in an evolving medium.formulated in terms of matrix valued gluon fields A µ = A a µ T a where T a refers the generators of SU (3). Their covariant derivative reads D µ = ∂ µ + igA µ with g the strong coupling. We denote light quarks of different flavor with ψ j and heavy quarks with Q k (in the following we will often omit the flavor label for the heavy quarks). This action remains invariant under local rotations Λ(x) in SU (3) color space, acting as ψ ′ a (x) = Λ ab (x)ψ b (x) and (A ′ µ ) ab (x) = Λ ac (x)A cd µ (x)(Λ † ) db (x) + i(∂ µ Λ ac (x))(Λ cb ) † (x). The distinction between light and heavy quarks will be exploited in the section on effective field theories and open quantum systems. It is from fully quantized QCD that one wishes to deduce quarkonium properties in thermal equilibrium, as well as its real-time evolution in an evolving medium.</p>
        <p>In this section we will summarize how quarkonium can be described in the language of (non-)thermal field theory and introduce the concept of spectral functions. The quark-anti-quark pair shall be immersed in a medium of quarks and gluons, which are not necessarily in thermal equilibrium. Excellent introductions to quantum fields in and out-of thermal equilibrium can be found in reviews [24][25][26] and textbooks [27][28][29][30].In this section we will summarize how quarkonium can be described in the language of (non-)thermal field theory and introduce the concept of spectral functions. The quark-anti-quark pair shall be immersed in a medium of quarks and gluons, which are not necessarily in thermal equilibrium. Excellent introductions to quantum fields in and out-of thermal equilibrium can be found in reviews [24][25][26] and textbooks [27][28][29][30].</p>
        <p>In quantum field theory particles are understood as excitations of quantum fields, which propagate with a well defined dispersion relation. I.e. in contrast to quantum mechanics, particles do not appear as individual degrees of freedom and instead emerge from fluctuations of the fields. Thus to describe quarkonium particles, one needs a quantity, which encodes the real-time evolution of fluctuations of a heavy quark Q (x) and antiquark field Q (x) (here Q refers to a Dirac spinor field describing either charm or bottom). The simplest possible candidate is the meson current M(x) = Q (x) Q (x). Two-point correlation functions of such a meson operator, similar to the variance of random variables, provide vital insight into the strength and form of quantum and statistical fluctuations that encode the properties of quarkonium particles. As an example let us consider the time ordered correlator Here σ denotes the initial density matrix of the system and the trace has been formally rewritten in the eigenstates |n⟩ of the system Hamiltonian ĤQCD .In quantum field theory particles are understood as excitations of quantum fields, which propagate with a well defined dispersion relation. I.e. in contrast to quantum mechanics, particles do not appear as individual degrees of freedom and instead emerge from fluctuations of the fields. Thus to describe quarkonium particles, one needs a quantity, which encodes the real-time evolution of fluctuations of a heavy quark Q (x) and antiquark field Q (x) (here Q refers to a Dirac spinor field describing either charm or bottom). The simplest possible candidate is the meson current M(x) = Q (x) Q (x). Two-point correlation functions of such a meson operator, similar to the variance of random variables, provide vital insight into the strength and form of quantum and statistical fluctuations that encode the properties of quarkonium particles. As an example let us consider the time ordered correlator Here σ denotes the initial density matrix of the system and the trace has been formally rewritten in the eigenstates |n⟩ of the system Hamiltonian ĤQCD .</p>
        <p>The path integral formulation in the second line makes explicit that one deals with an initial value problem. It is appropriately formulated along the Schwinger-Keldysh (SK) contour with a forward branch C 1 and backward branch C 2 , as sketched in Fig. 3. The time ordering operator is denoted by T . The fields A, ψ, ψ, Q , Q live on both branches of the contour, whose initial conditions ( + fields for the forward and -fields for the backward contour) are sampled over statistically, weighted by the matrix elements of the density matrix. The presence of the two branches is intimately connected with the fact that one considers here the evolution of an, in general, mixed state in time. To describe it fully we need more than a single unitarily evolving wavefunction but instead propagate a full density matrix flanged between two time evolution operators.The path integral formulation in the second line makes explicit that one deals with an initial value problem. It is appropriately formulated along the Schwinger-Keldysh (SK) contour with a forward branch C 1 and backward branch C 2 , as sketched in Fig. 3. The time ordering operator is denoted by T . The fields A, ψ, ψ, Q , Q live on both branches of the contour, whose initial conditions ( + fields for the forward and -fields for the backward contour) are sampled over statistically, weighted by the matrix elements of the density matrix. The presence of the two branches is intimately connected with the fact that one considers here the evolution of an, in general, mixed state in time. To describe it fully we need more than a single unitarily evolving wavefunction but instead propagate a full density matrix flanged between two time evolution operators.</p>
        <p>One of the benefits of employing the SK contour lies in its ability to disentangle the classical and quantum components of the interaction of the d.o.f. (i.e. those that vanish in or survive the h → 0 limit) by introducing a linear combination of the + andfield components. It also provides a straight forward description of open quantum systems (discussed in Section 2.5) and their master equations via the Feynman-Vernon influence functional (discussed in Section 4.1). The use of coherent states to reverse engineer the operator-valued expressions of the master equation from a path integral plays a central role (for a pedagogic exposition of the connection between SK and OQS see e.g. Ref. [31]).One of the benefits of employing the SK contour lies in its ability to disentangle the classical and quantum components of the interaction of the d.o.f. (i.e. those that vanish in or survive the h → 0 limit) by introducing a linear combination of the + andfield components. It also provides a straight forward description of open quantum systems (discussed in Section 2.5) and their master equations via the Feynman-Vernon influence functional (discussed in Section 4.1). The use of coherent states to reverse engineer the operator-valued expressions of the master equation from a path integral plays a central role (for a pedagogic exposition of the connection between SK and OQS see e.g. Ref. [31]).</p>
        <p>There are several different combinations of the meson operators, which we can consider on the Keldysh contour, all of which provide access to different facets of the field fluctuations. Depending on which part of the real-time contour the meson operator resides on we have D 11 = D(x, x 0 , t, t 0 ) = ⟨T M(x, t) M † (x 0 , t 0 )⟩, (3)There are several different combinations of the meson operators, which we can consider on the Keldysh contour, all of which provide access to different facets of the field fluctuations. Depending on which part of the real-time contour the meson operator resides on we have D 11 = D(x, x 0 , t, t 0 ) = ⟨T M(x, t) M † (x 0 , t 0 )⟩, (3)</p>
        <p>D 21 = D &lt; (x, x 0 , t, t 0 ) = ⟨ M † (x 0 , t 0 ) M(x, t)⟩, (5) D 22 = D(x, x 0 , t, t 0 ) = ⟨ T M(x, t) M † (x 0 , t 0 )⟩. (6) Table 1 A selection of common vertex operators and their quantum numbers. In addition we list the lowest lying quarkonium states contributing to the corresponding channel. Source: Adapted from [21,32].D 21 = D &lt; (x, x 0 , t, t 0 ) = ⟨ M † (x 0 , t 0 ) M(x, t)⟩, (5) D 22 = D(x, x 0 , t, t 0 ) = ⟨ T M(x, t) M † (x 0 , t 0 )⟩. (6) Table 1 A selection of common vertex operators and their quantum numbers. In addition we list the lowest lying quarkonium states contributing to the corresponding channel. Source: Adapted from [21,32].</p>
        <p>{ Â, B} = ÂB + B Â as D S = ⟨{ M(x, t), M † (x 0 , t 0 )}⟩.{ Â, B} = ÂB + B Â as D S = ⟨{ M(x, t), M † (x 0 , t 0 )}⟩.</p>
        <p>((</p>
        <p>The explicit form of M encodes, what kind of meson particles we are dealing with. In the study of heavy quarkonium two kinds of meson operators play a central role, local meson currents, as well as point split operatorsThe explicit form of M encodes, what kind of meson particles we are dealing with. In the study of heavy quarkonium two kinds of meson operators play a central role, local meson currents, as well as point split operators</p>
        <p>MΓ (x, y, t) = Q (x, t)Γ W (x, y, t) Q (y, t). (11) In order for the correlator of point split operators to remain gauge invariant one conventionally inserts a straight Wilson line between the quark and antiquark fields, trading gauge dependence for an easier parametrizable path dependenceMΓ (x, y, t) = Q (x, t)Γ W (x, y, t) Q (y, t). (11) In order for the correlator of point split operators to remain gauge invariant one conventionally inserts a straight Wilson line between the quark and antiquark fields, trading gauge dependence for an easier parametrizable path dependence</p>
        <p>] .] .</p>
        <p>((</p>
        <p>The correlator of local currents encodes directly the properties of heavy quarkonium mesons, while we will encounter the point split operators in the context of defining a potential acting between the heavy quark and antiquark.The correlator of local currents encodes directly the properties of heavy quarkonium mesons, while we will encounter the point split operators in the context of defining a potential acting between the heavy quark and antiquark.</p>
        <p>The quantities Γ residing in the meson currents are referred to as vertex operators. They allow us to select the spin and angular momentum properties of the fluctuations contributing to a correlator. Since Eq. ( 2) involves a path integral, the propagation of the system over time includes all possible field configurations accessible to the system, weighted with the Feynman phase expThe quantities Γ residing in the meson currents are referred to as vertex operators. They allow us to select the spin and angular momentum properties of the fluctuations contributing to a correlator. Since Eq. ( 2) involves a path integral, the propagation of the system over time includes all possible field configurations accessible to the system, weighted with the Feynman phase exp</p>
        <p>. It follows that all mesons states with quantum numbers compatible to Γ contribute to this quantity and in turn computing D will allow us to access the information of what states of a particular quantum number are present in the system.. It follows that all mesons states with quantum numbers compatible to Γ contribute to this quantity and in turn computing D will allow us to access the information of what states of a particular quantum number are present in the system.</p>
        <p>To be specific, we may select under which representation of the Lorentz group the meson transforms. One example is the vector current with Γ = γ µ , which eponymously transforms as a Lorentz four-vector. Since we wish to select angular momentum and spin quantum numbers, the focus in the following lies on transformations in the rotation subgroup of the Lorentz group. Hence using for the meson operator the spatial components Γ = γ i , its correlator receives contributions from all Q Q mesons with quantum numbers J PC = 1 --. In the case of bottomonium in vacuum this would correspond to at least three stable meson states Υ , Υ ′ and Υ ′′ . Access to channels with different quantum numbers requires an appropriate choice for Γ , some of which are listed in Table 1. Since local Γ 's give access to only a limited set of quantum numbers, the computation of e.g. χ c2 with J PC = 2 ++ requires the use of additional covariant derivative operators ↔ D= ← D -→ D, as discussed in Refs. [32,33].To be specific, we may select under which representation of the Lorentz group the meson transforms. One example is the vector current with Γ = γ µ , which eponymously transforms as a Lorentz four-vector. Since we wish to select angular momentum and spin quantum numbers, the focus in the following lies on transformations in the rotation subgroup of the Lorentz group. Hence using for the meson operator the spatial components Γ = γ i , its correlator receives contributions from all Q Q mesons with quantum numbers J PC = 1 --. In the case of bottomonium in vacuum this would correspond to at least three stable meson states Υ , Υ ′ and Υ ′′ . Access to channels with different quantum numbers requires an appropriate choice for Γ , some of which are listed in Table 1. Since local Γ 's give access to only a limited set of quantum numbers, the computation of e.g. χ c2 with J PC = 2 ++ requires the use of additional covariant derivative operators ↔ D= ← D -→ D, as discussed in Refs. [32,33].</p>
        <p>In order to access the information about which states contribute to the evolution of the meson operators, let us decompose the time ordered correlator into its commutator and anticommutator D(x, x 0 , t, t 0 ) = 1 2 ⟨{ M(x, t), M † (x 0 , t 0 )}⟩ + 1 2 ⟨[ M(x, t), M † (x 0 , t 0 )]⟩sign C (tt 0 ) (13) = F (x, t, x 0 , t 0 ) -i 2 ρ(x, t, x 0 , t 0 )sign C (tt 0 ). (14) Here sign C (tt 0 ) tracks the location of t and t 0 on the SK contour. We will see below that the spectral function ρ encodes what states are accessible in the system, whereas the statistical function F encodes how strongly those states are populated.In order to access the information about which states contribute to the evolution of the meson operators, let us decompose the time ordered correlator into its commutator and anticommutator D(x, x 0 , t, t 0 ) = 1 2 ⟨{ M(x, t), M † (x 0 , t 0 )}⟩ + 1 2 ⟨[ M(x, t), M † (x 0 , t 0 )]⟩sign C (tt 0 ) (13) = F (x, t, x 0 , t 0 ) -i 2 ρ(x, t, x 0 , t 0 )sign C (tt 0 ). (14) Here sign C (tt 0 ) tracks the location of t and t 0 on the SK contour. We will see below that the spectral function ρ encodes what states are accessible in the system, whereas the statistical function F encodes how strongly those states are populated.</p>
        <p>The most intuitive representation of that information is found when introducing a Wigner transform, i.e. expressing the correlator in terms of relative and center of mass coordinates r = xx 0 and s = (x + x 0 )/2 and Fourier transforming in the former.The most intuitive representation of that information is found when introducing a Wigner transform, i.e. expressing the correlator in terms of relative and center of mass coordinates r = xx 0 and s = (x + x 0 )/2 and Fourier transforming in the former.</p>
        <p>dt r e iωtr D(s, t s ; r, t r ). (15) The Wigner space spectral function ρ(s, t s ; p, ω) when viewed as a function of p and ω will represent a particle-like excitation as a narrow shell, located along a strip of ω(p). This is how the dispersion relation of the particle is read-off.dt r e iωtr D(s, t s ; r, t r ). (15) The Wigner space spectral function ρ(s, t s ; p, ω) when viewed as a function of p and ω will represent a particle-like excitation as a narrow shell, located along a strip of ω(p). This is how the dispersion relation of the particle is read-off.</p>
        <p>As we are dealing with an initial value problem out of equilibrium, one has to keep in mind that the frequency resolution that can be achieved for the spectral function is limited by how much time t s has passed, as intuitively expected from the uncertainty principle. As it will come in handy later on, we note that the spectral function may be computed from different combinations of correlators introduced above. I.e. we may either express it in terms of the forward and backward correlator or as the imaginary part of the retarded correlator ρ(s, t s ; p, ω) = ] .As we are dealing with an initial value problem out of equilibrium, one has to keep in mind that the frequency resolution that can be achieved for the spectral function is limited by how much time t s has passed, as intuitively expected from the uncertainty principle. As it will come in handy later on, we note that the spectral function may be computed from different combinations of correlators introduced above. I.e. we may either express it in terms of the forward and backward correlator or as the imaginary part of the retarded correlator ρ(s, t s ; p, ω) = ] .</p>
        <p>((</p>
        <p>The Wigner transformed spectral function also allows us to connect directly with its counterpart in thermal equilibrium. Starting out of equilibrium one will observe that the function ρ changes with the center of mass coordinate. As one approaches equilibrium this dependence weakens and eventually the fully thermal system will become independent of it, leaving us with ρ(p, ω).The Wigner transformed spectral function also allows us to connect directly with its counterpart in thermal equilibrium. Starting out of equilibrium one will observe that the function ρ changes with the center of mass coordinate. As one approaches equilibrium this dependence weakens and eventually the fully thermal system will become independent of it, leaving us with ρ(p, ω).</p>
        <p>which reduces to the standard occupation number in thermal equilibrium. This tells us that an enormous simplification of the system takes place in that n not only becomes independent of the center-of-mass coordinates but furthermore becomes a function of ω only, leading to the Bose-Einstein distribution for a bosonic correlation function. I.e. in equilibrium, knowledge of the statistical function already implies knowledge of ρ.which reduces to the standard occupation number in thermal equilibrium. This tells us that an enormous simplification of the system takes place in that n not only becomes independent of the center-of-mass coordinates but furthermore becomes a function of ω only, leading to the Bose-Einstein distribution for a bosonic correlation function. I.e. in equilibrium, knowledge of the statistical function already implies knowledge of ρ.</p>
        <p>In thermal equilibrium the density matrix is given by σ = exp[-β Ĥ], with β = 1/T the inverse temperature and Ĥ the Hamiltonian of the system. In that case the initial conditions part of Eq. ( 2) may be rewritten in the form of a second path integral along a compact imaginary time axis spanning from t = 0 to t = -iβ. The start and end points of that imaginary time axis provide the initial conditions for the forward and backward branch of the Schwinger-Keldysh real-time contour. For operators residing on the imaginary time axis we may consider the Euclidean correlator D E (x, τ ) = ⟨M(x, τ )M † (0, 0)⟩ = D &gt; (x, -iτ ). (18) This correlator is related to the real-time forward correlator via analytic continuation. Due to the compactness of the imaginary time axis, a theory formulated in Euclidean time, after Fourier transform, only has access to the correlator on discrete imaginary frequencies, the so called Matsubara frequencies ω n = 2π nT D M (x, ω n ) = 1 2π ∫ β 0 dτ e iωnτ D E (x, τ ). (19) In addition the KMS relation tells us that the real-time correlators themselves become related to each other via D &gt; (t, t 0 ) = D &lt; (t + iβ, t 0 ). (20) Out of equilibrium we need to determine the off-diagonal correlators D &gt; = D 12 and D &lt; = D 21 separately to compute ρ. Via KMS we learn that D &lt; (ω) = e -βω D &gt; (ω) and already D &gt; suffices.In thermal equilibrium the density matrix is given by σ = exp[-β Ĥ], with β = 1/T the inverse temperature and Ĥ the Hamiltonian of the system. In that case the initial conditions part of Eq. ( 2) may be rewritten in the form of a second path integral along a compact imaginary time axis spanning from t = 0 to t = -iβ. The start and end points of that imaginary time axis provide the initial conditions for the forward and backward branch of the Schwinger-Keldysh real-time contour. For operators residing on the imaginary time axis we may consider the Euclidean correlator D E (x, τ ) = ⟨M(x, τ )M † (0, 0)⟩ = D &gt; (x, -iτ ). (18) This correlator is related to the real-time forward correlator via analytic continuation. Due to the compactness of the imaginary time axis, a theory formulated in Euclidean time, after Fourier transform, only has access to the correlator on discrete imaginary frequencies, the so called Matsubara frequencies ω n = 2π nT D M (x, ω n ) = 1 2π ∫ β 0 dτ e iωnτ D E (x, τ ). (19) In addition the KMS relation tells us that the real-time correlators themselves become related to each other via D &gt; (t, t 0 ) = D &lt; (t + iβ, t 0 ). (20) Out of equilibrium we need to determine the off-diagonal correlators D &gt; = D 12 and D &lt; = D 21 separately to compute ρ. Via KMS we learn that D &lt; (ω) = e -βω D &gt; (ω) and already D &gt; suffices.</p>
        <p>We can pin down some of the properties of the spectral function in thermal equilibrium by explicitly computing D &gt; and D &lt; , suppressing in the following the spatial dependence. Writing the trace as a sum over a complete set of eigenstates of the Hamiltonian ⟨n| and inserting a representation of unity we getWe can pin down some of the properties of the spectral function in thermal equilibrium by explicitly computing D &gt; and D &lt; , suppressing in the following the spatial dependence. Writing the trace as a sum over a complete set of eigenstates of the Hamiltonian ⟨n| and inserting a representation of unity we get</p>
        <p>Tr[e -β Ĥ M(t) M † (t 0 )] =Tr[e -β Ĥ M(t) M † (t 0 )] =</p>
        <p>11</p>
        <p>∑ n,m e -βEn e iEn(t-t 0 ) e -iEm(t-t 0 )∑ n,m e -βEn e iEn(t-t 0 ) e -iEm(t-t 0 )</p>
        <p>|⟨n| M(t 0 )|m⟩| 2 , (21) which subsequently leads to|⟨n| M(t 0 )|m⟩| 2 , (21) which subsequently leads to</p>
        <p>This expression first tells us that the spectral function is antisymmetric around the frequency origin ρ(-ω) = -ρ(ω). As long as the product/contraction of Γ Γ † remains positive (e.g. for Γ i ) and we utilize the same meson operator for creation and annihilation, ρ is positive semi-definite for ω &gt; 0.This expression first tells us that the spectral function is antisymmetric around the frequency origin ρ(-ω) = -ρ(ω). As long as the product/contraction of Γ Γ † remains positive (e.g. for Γ i ) and we utilize the same meson operator for creation and annihilation, ρ is positive semi-definite for ω &gt; 0.</p>
        <p>The vector channel spectral function on the other hand may contain both positive and negative contributions. To see this let us decompose it into its transverse and longitudinal components for general Γ µ Γ ν † ρ µν (p, ω) = P µν T ρ T (p, ω)The vector channel spectral function on the other hand may contain both positive and negative contributions. To see this let us decompose it into its transverse and longitudinal components for general Γ µ Γ ν † ρ µν (p, ω) = P µν T ρ T (p, ω)</p>
        <p>where the following projection operators are usedwhere the following projection operators are used</p>
        <p>For a particular choice of e.g. p = (p, 0, 0) the following relations are obtained ρ T (p, ω) = 1 2 ( ρ 22 (p, ω) + ρ 33 (p, ω) ) , ρ L (p, ω) = ω 2 -p 2 ω 2 ρ 11 (p, ω). (25) This tells us that while ρ T ≥ 0 for positive frequencies, ρ L can become negative below the light cone.For a particular choice of e.g. p = (p, 0, 0) the following relations are obtained ρ T (p, ω) = 1 2 ( ρ 22 (p, ω) + ρ 33 (p, ω) ) , ρ L (p, ω) = ω 2 -p 2 ω 2 ρ 11 (p, ω). (25) This tells us that while ρ T ≥ 0 for positive frequencies, ρ L can become negative below the light cone.</p>
        <p>Based on the canonical dimension of the naively defined composite meson operators dim[M], we can deduce the dimension of ρ. This provides a first guess of how the spectral function behaves at high frequencies, where ω is the dominant scale. I.e.Based on the canonical dimension of the naively defined composite meson operators dim[M], we can deduce the dimension of ρ. This provides a first guess of how the spectral function behaves at high frequencies, where ω is the dominant scale. I.e.</p>
        <p>ρ(p, ω) ω≫p ∼ ω γ , (26) with γ = dim[M] + dim[M † ] -4, which for quarkonium mesons turns out to be γ = 2. For very heavy quarks the spectral expression simplifies, since neither quantum fluctuations nor statistical fluctuations are able to spontaneously produce a Q Q pair. More concretely one can argue [34], that for m Q ≫ T the large mass of the heavy quarks leads to a suppression of Boltzmann factors with E n or E m , whenever the intermediate states |n⟩ or |m⟩ in the spectral decomposition contain heavy quarksρ(p, ω) ω≫p ∼ ω γ , (26) with γ = dim[M] + dim[M † ] -4, which for quarkonium mesons turns out to be γ = 2. For very heavy quarks the spectral expression simplifies, since neither quantum fluctuations nor statistical fluctuations are able to spontaneously produce a Q Q pair. More concretely one can argue [34], that for m Q ≫ T the large mass of the heavy quarks leads to a suppression of Boltzmann factors with E n or E m , whenever the intermediate states |n⟩ or |m⟩ in the spectral decomposition contain heavy quarks</p>
        <p>In Eq. (22) we have assumed the whole spectrum of the Hamiltonian to be discrete, which is the case when the theory is e.g. regularized on a finite space-time lattice. Then we understand that ρ is simply composed of a sum of delta peaks. A peak exists at a certain frequency if the system Hamiltonian admits an energy level at that value and the matrix element |⟨M⟩| 2 is non-vanishing. At zero temperature therefore one expects there to be a well defined ground state peak, clearly separated from higher lying excited states and eventually followed by densely spaced peaks above the continuum threshold, corresponding to unbound states. In thermal equilibrium, due to the sum over the medium states |m⟩, the delta peaks below the threshold can cluster (i.e. the difference between E n and E m can be small) which leads to peak structures whose envelope exhibits a finite thermal width. Well defined peak structures can be related to (quasi-)particle properties. Depending on the relative momentum p the position of a sharp spectral peak traces out the dispersion relation of that particle. At p = 0 it is simply the rest mass of that particle. Its binding energy can be read-off from the distance of the bound state peak from the onset of the continuum structure. On the other hand the width of a peak is related to its inverse lifetime, as it translates into a dampening in e.g. the forward correlator D &gt; . At finite temperature a finite thermal width does not necessarily imply that the state decays via annihilation of the constituent quark-antiquark pair. Instead due to energy and momentum exchange with the medium degrees of freedom the particle may be excited into another state within the same color channel (singlet or octet) or even outside of that channel, signaling decoherence over time. The information of which state the particle transitions into however is encoded in higher correlation functions of meson operators and thus cannot be disentangled from an inspection of the two-point correlator spectral function.In Eq. (22) we have assumed the whole spectrum of the Hamiltonian to be discrete, which is the case when the theory is e.g. regularized on a finite space-time lattice. Then we understand that ρ is simply composed of a sum of delta peaks. A peak exists at a certain frequency if the system Hamiltonian admits an energy level at that value and the matrix element |⟨M⟩| 2 is non-vanishing. At zero temperature therefore one expects there to be a well defined ground state peak, clearly separated from higher lying excited states and eventually followed by densely spaced peaks above the continuum threshold, corresponding to unbound states. In thermal equilibrium, due to the sum over the medium states |m⟩, the delta peaks below the threshold can cluster (i.e. the difference between E n and E m can be small) which leads to peak structures whose envelope exhibits a finite thermal width. Well defined peak structures can be related to (quasi-)particle properties. Depending on the relative momentum p the position of a sharp spectral peak traces out the dispersion relation of that particle. At p = 0 it is simply the rest mass of that particle. Its binding energy can be read-off from the distance of the bound state peak from the onset of the continuum structure. On the other hand the width of a peak is related to its inverse lifetime, as it translates into a dampening in e.g. the forward correlator D &gt; . At finite temperature a finite thermal width does not necessarily imply that the state decays via annihilation of the constituent quark-antiquark pair. Instead due to energy and momentum exchange with the medium degrees of freedom the particle may be excited into another state within the same color channel (singlet or octet) or even outside of that channel, signaling decoherence over time. The information of which state the particle transitions into however is encoded in higher correlation functions of meson operators and thus cannot be disentangled from an inspection of the two-point correlator spectral function.</p>
        <p>If we consider Γ V = γ µ , the area under the spectral peaks in the corresponding ρ V , can be straight forwardly related to experimentally relevant decay processes involving dileptons [35]. It is exactly the vector current j em µ = q Q γ µ Q with electric charge q that couples to the photon field. At T = 0 the prefactor to a spectral delta peak, to first order in QED perturbation theory, encodes the probability of the bound state to decay to a dilepton pair, via annihilation into a virtual photon. I.e. the R-ratio of decay into e + e -pairs is given byIf we consider Γ V = γ µ , the area under the spectral peaks in the corresponding ρ V , can be straight forwardly related to experimentally relevant decay processes involving dileptons [35]. It is exactly the vector current j em µ = q Q γ µ Q with electric charge q that couples to the photon field. At T = 0 the prefactor to a spectral delta peak, to first order in QED perturbation theory, encodes the probability of the bound state to decay to a dilepton pair, via annihilation into a virtual photon. I.e. the R-ratio of decay into e + e -pairs is given by</p>
        <p>In Ref. [36] the decay probability of quarkonium at T = 0 has been connected to a simple picture of a non-relativistic wavefunction determined by a potential, using the concepts of effective field theories discussed in the next section. The strength of spectral features for an individual state is related to the properties of the corresponding radial wavefunction at the origin. At finite temperature it is the area under an in-medium spectral feature, weighted by the Bose-Einstein distribution, which can be related to the dilepton emission rate from fully thermalized heavy quarkonium [37][38][39]. In the center of momentum frame of the emitted dileptons p ℓ -= -p ℓ + and assuming that the energy of the emitted particles ω = E ℓ -+ E ℓ + is sizably larger than twice their masses one obtainsIn Ref. [36] the decay probability of quarkonium at T = 0 has been connected to a simple picture of a non-relativistic wavefunction determined by a potential, using the concepts of effective field theories discussed in the next section. The strength of spectral features for an individual state is related to the properties of the corresponding radial wavefunction at the origin. At finite temperature it is the area under an in-medium spectral feature, weighted by the Bose-Einstein distribution, which can be related to the dilepton emission rate from fully thermalized heavy quarkonium [37][38][39]. In the center of momentum frame of the emitted dileptons p ℓ -= -p ℓ + and assuming that the energy of the emitted particles ω = E ℓ -+ E ℓ + is sizably larger than twice their masses one obtains</p>
        <p>where depending on whether charm or bottom quarks are involved the different electric charges q c = 2 3 and q b = - Another interesting property is encoded in the spatial component of the vector channel spectral function (i.e. using Γ = γ i ). The spectral structures in the low frequency regime may be related via linear-response theory [40][41][42] to the so called Kubo-formula for the heavy quark diffusion coefficientwhere depending on whether charm or bottom quarks are involved the different electric charges q c = 2 3 and q b = - Another interesting property is encoded in the spatial component of the vector channel spectral function (i.e. using Γ = γ i ). The spectral structures in the low frequency regime may be related via linear-response theory [40][41][42] to the so called Kubo-formula for the heavy quark diffusion coefficient</p>
        <p>with χ 00 the quark number susceptibility. Note that the order of limits is important here, first we need to take the spatial momentum to zero and then inspect the low frequency regime of the spectral function.with χ 00 the quark number susceptibility. Note that the order of limits is important here, first we need to take the spatial momentum to zero and then inspect the low frequency regime of the spectral function.</p>
        <p>Besides encoding the particle content of a theory, spectral functions serve another important technical role. They allow us to relate the many different correlators introduced above via appropriate integral transformations. In particular it turns out that the correlator formulated in imaginary time is governed by the same spectral function as the real-time correlator. This fact will become essential when trying to extract real-time information from numerical lattice QCD simulations later on.Besides encoding the particle content of a theory, spectral functions serve another important technical role. They allow us to relate the many different correlators introduced above via appropriate integral transformations. In particular it turns out that the correlator formulated in imaginary time is governed by the same spectral function as the real-time correlator. This fact will become essential when trying to extract real-time information from numerical lattice QCD simulations later on.</p>
        <p>The first relation we consider is that between the spectral function and the Matsubara correlatorThe first relation we consider is that between the spectral function and the Matsubara correlator</p>
        <p>In the second step the antisymmetry of the spectral function has been used. Since the integral kernel here only decays with 1/ω, one has to make sure that the correlation function is still well defined, given the canonical dimension of the spectral function. That means that in practice UV divergent contributions to the spectral functions need to be subtracted for Eq. ( 31) to make sense. Note that this spectral decomposition also tells us that while the Euclidean formulation of thermal field theory does not have access to the values of D M in between the Matsubara frequencies, they are well defined.In the second step the antisymmetry of the spectral function has been used. Since the integral kernel here only decays with 1/ω, one has to make sure that the correlation function is still well defined, given the canonical dimension of the spectral function. That means that in practice UV divergent contributions to the spectral functions need to be subtracted for Eq. ( 31) to make sense. Note that this spectral decomposition also tells us that while the Euclidean formulation of thermal field theory does not have access to the values of D M in between the Matsubara frequencies, they are well defined.</p>
        <p>Using the analytic continuation of the spectral decomposition we may obtain expressions for the retarded and advanced correlatorsUsing the analytic continuation of the spectral decomposition we may obtain expressions for the retarded and advanced correlators</p>
        <p>To arrive at the correlator in Euclidean time, the Fourier series over Matsubara frequencies needs to be carried out. Using the relationTo arrive at the correlator in Euclidean time, the Fourier series over Matsubara frequencies needs to be carried out. Using the relation</p>
        <p>one obtains the following spectral decompositionone obtains the following spectral decomposition</p>
        <p>where for the second equality, we have used the antisymmetry of the meson spectral function. The finite temperature kernel diverges as ω → 0, which is a manifestation of the fact that the spectral function is antisymmetric and thus has to vanish at the origin. It also reduces to a simple exponential falloff at vanishing temperature. Note that in case of the Matsubara correlator, the functional form of the integral kernel itself is not temperature dependent, it simply gets evaluated at different temperature dependent Matsubara frequencies ω n . On the other hand the kernel of the Euclidean correlator depends explicitly on β.where for the second equality, we have used the antisymmetry of the meson spectral function. The finite temperature kernel diverges as ω → 0, which is a manifestation of the fact that the spectral function is antisymmetric and thus has to vanish at the origin. It also reduces to a simple exponential falloff at vanishing temperature. Note that in case of the Matsubara correlator, the functional form of the integral kernel itself is not temperature dependent, it simply gets evaluated at different temperature dependent Matsubara frequencies ω n . On the other hand the kernel of the Euclidean correlator depends explicitly on β.</p>
        <p>Now that we have summarized the formal relations between different correlators and the spectral function, let us consider the non-interacting limit as an analytically accessible example [43,44]. Due to asymptotic freedom in QCD, this limit agrees with the infinite temperature limit. Since at high temperatures binding of quarks into bound states will be impossible, the expectation is that only the continuum persists above ω &gt; 2m Q . Thus contrary to a single-particle spectral functions that exhibit a simple delta peak at the mass of the quantum field, the free meson spectral function shows a non-trivial broad structure at high frequencies. In addition it can also feature a remnant structure at low frequencies related to the transport peak in an interacting theory. At vanishing momentum the explicit form readsNow that we have summarized the formal relations between different correlators and the spectral function, let us consider the non-interacting limit as an analytically accessible example [43,44]. Due to asymptotic freedom in QCD, this limit agrees with the infinite temperature limit. Since at high temperatures binding of quarks into bound states will be impossible, the expectation is that only the continuum persists above ω &gt; 2m Q . Thus contrary to a single-particle spectral functions that exhibit a simple delta peak at the mass of the quantum field, the free meson spectral function shows a non-trivial broad structure at high frequencies. In addition it can also feature a remnant structure at low frequencies related to the transport peak in an interacting theory. At vanishing momentum the explicit form reads</p>
        <p>where the coefficients a Γ , b Γ and f Γ take on specific values for different channels. At asymptotically high energies most channels, including the vector and axial vector one show the scaling ρ(ω) ∼ ω 2 expected from dimensional grounds. Only for Γ = γ 0 and γ 0 γ 5 a cancellation occurs and the dependence on ω drops out.where the coefficients a Γ , b Γ and f Γ take on specific values for different channels. At asymptotically high energies most channels, including the vector and axial vector one show the scaling ρ(ω) ∼ ω 2 expected from dimensional grounds. Only for Γ = γ 0 and γ 0 γ 5 a cancellation occurs and the dependence on ω drops out.</p>
        <p>At vanishing frequencies a remnant of the physics below the light cone persists in the form of a delta peak in the vector and axial vector channel, which would correspond to an infinite diffusion constant. At finite coupling it is expected that both channels contain a washed out counterpart of this delta peak close to zero frequencies. This is the transport peak related to heavy quark diffusion. Modeling its shape based on Brownian motion and a Langevin equation [42] predicts a Breit-Wigner form, where the width of the peak is inversely proportional to the diffusion constant D. Note that an explicit delta peak at the origin leads to a constant contribution in the Euclidean correlator, which, as we will discuss later may lead to complications in the extraction of spectral functions from lattice QCD simulations. In contrast the constant f Γ vanishes for the scalar and pseudoscalar channel. In turn it is expected that also in the interacting theory these channels do not contain a transport peak.At vanishing frequencies a remnant of the physics below the light cone persists in the form of a delta peak in the vector and axial vector channel, which would correspond to an infinite diffusion constant. At finite coupling it is expected that both channels contain a washed out counterpart of this delta peak close to zero frequencies. This is the transport peak related to heavy quark diffusion. Modeling its shape based on Brownian motion and a Langevin equation [42] predicts a Breit-Wigner form, where the width of the peak is inversely proportional to the diffusion constant D. Note that an explicit delta peak at the origin leads to a constant contribution in the Euclidean correlator, which, as we will discuss later may lead to complications in the extraction of spectral functions from lattice QCD simulations. In contrast the constant f Γ vanishes for the scalar and pseudoscalar channel. In turn it is expected that also in the interacting theory these channels do not contain a transport peak.</p>
        <p>Summary. Quarkonium particles in quantum field theory are described by local meson current correlators, different combinations of which can be formally constructed. All particles with quantum numbers compatible with those selected by vertex operators Γ contribute to such a meson correlator. We can relate different correlators (retarded, Matsubara, etc.) to a common spectral function ρ via integral transforms. Expressed in relative momentum and relative frequency ρ(p, ω) encodes bound state particles as peaked features and in turn allows us to read-off their masses, binding energies and lifetimes. At large frequencies the spectral function exhibits a continuous structure related to unbound pairs, which in most channels diverges with ω 2 in accordance with dimensionality. Some channels, such as the vector channel, at vanishing spatial momentum also contain an additional structure close to ω = 0 related to the diffusion of heavy quarks, the so called transport peak.Summary. Quarkonium particles in quantum field theory are described by local meson current correlators, different combinations of which can be formally constructed. All particles with quantum numbers compatible with those selected by vertex operators Γ contribute to such a meson correlator. We can relate different correlators (retarded, Matsubara, etc.) to a common spectral function ρ via integral transforms. Expressed in relative momentum and relative frequency ρ(p, ω) encodes bound state particles as peaked features and in turn allows us to read-off their masses, binding energies and lifetimes. At large frequencies the spectral function exhibits a continuous structure related to unbound pairs, which in most channels diverges with ω 2 in accordance with dimensionality. Some channels, such as the vector channel, at vanishing spatial momentum also contain an additional structure close to ω = 0 related to the diffusion of heavy quarks, the so called transport peak.</p>
        <p>In this section we review how the separation between energy scales in the quarkonium system allows us to simplify its description with non-relativistic language (for the general concept of an EFT see the classic Ref. [45]). To this end we will consider the two effective field theories Non-relativistic QCD (NRQCD) [46] and potential NRQCD (pNRQCD) [47], which have found various applications in the study of in-medium heavy quarkonium. For a pedagogical introduction to the general concept of EFT's see e.g. [48], to NRQCD at T = 0 in particular e.g. Ref. [49]. A comprehensive review of both NRQCD and pNRQCD can be found in Ref. [50].In this section we review how the separation between energy scales in the quarkonium system allows us to simplify its description with non-relativistic language (for the general concept of an EFT see the classic Ref. [45]). To this end we will consider the two effective field theories Non-relativistic QCD (NRQCD) [46] and potential NRQCD (pNRQCD) [47], which have found various applications in the study of in-medium heavy quarkonium. For a pedagogical introduction to the general concept of EFT's see e.g. [48], to NRQCD at T = 0 in particular e.g. Ref. [49]. A comprehensive review of both NRQCD and pNRQCD can be found in Ref. [50].</p>
        <p>Heavy quarkonium is exceptional among mesons, as the masses of charm and bottom quarks arrange ideally so that a hierarchy of well separated scales emergesHeavy quarkonium is exceptional among mesons, as the masses of charm and bottom quarks arrange ideally so that a hierarchy of well separated scales emerges</p>
        <p>Let us consider the characteristic relative velocity of the heavy quark within a bound state v = |p|/m Q . Attributing the mass splitting of e.g. the lowest lying bottomonium and charmonium S-wave states of roughly ∆ ∼ 500 MeV to the average kinetic energy available ⟨m Q v 2 ⟩ it follows [51] that ⟨v 2 b ⟩ ≈ 0.1 and ⟨v 2 c ⟩ ≈ 0.3. In turn we find that the so called hard scale m Q of the rest mass lies well above the soft scale m Q v, which is related to the momentum exchanged between the quark-antiquark pair. For systems that permit a perturbative description, it can be shown that the soft scale is related to the inverse Bohr radius of the bound state. At even lower energies one finds the ultrasoft scale m Q v 2 related to the binding energy of the two-body system. In addition, the rest mass is much larger than the intrinsic scale of quantum fluctuations in QCD, Λ QCD . We will later on consider quarkonium in a heavy-ion collision, where at current collider facilities temperatures up to around T ≈ 0.6 GeV have been achieved. We may thus for the time being assume another separation of scales to hold, i.e. between the heavy quark mass and the characteristic energy density of the environment ϵ medium .Let us consider the characteristic relative velocity of the heavy quark within a bound state v = |p|/m Q . Attributing the mass splitting of e.g. the lowest lying bottomonium and charmonium S-wave states of roughly ∆ ∼ 500 MeV to the average kinetic energy available ⟨m Q v 2 ⟩ it follows [51] that ⟨v 2 b ⟩ ≈ 0.1 and ⟨v 2 c ⟩ ≈ 0.3. In turn we find that the so called hard scale m Q of the rest mass lies well above the soft scale m Q v, which is related to the momentum exchanged between the quark-antiquark pair. For systems that permit a perturbative description, it can be shown that the soft scale is related to the inverse Bohr radius of the bound state. At even lower energies one finds the ultrasoft scale m Q v 2 related to the binding energy of the two-body system. In addition, the rest mass is much larger than the intrinsic scale of quantum fluctuations in QCD, Λ QCD . We will later on consider quarkonium in a heavy-ion collision, where at current collider facilities temperatures up to around T ≈ 0.6 GeV have been achieved. We may thus for the time being assume another separation of scales to hold, i.e. between the heavy quark mass and the characteristic energy density of the environment ϵ medium .</p>
        <p>At asymptotically high temperature another scale hierarchy emerges (for a more detailed discussion see e.g. [52]), involving the temperature T and the QCD coupling g T ≫ gT ≫ g 2 T ≫ g 4 T . (37) In this weak-coupling context at the scale gT color electric fields begin to be screened within the thermal medium. Thus gT ∼ m D is related to the concept of the electric or Debye screening mass of gluons. The next lower scale is g 2 T , where also color magnetic fields become screened. The physics of magnetic screening even at high temperatures is genuinely non-perturbative. The lowest of the scales g 4 T is the scale of the inverse mean free path at which a hydrodynamic long-wavelength description of the thermal medium becomes viable.At asymptotically high temperature another scale hierarchy emerges (for a more detailed discussion see e.g. [52]), involving the temperature T and the QCD coupling g T ≫ gT ≫ g 2 T ≫ g 4 T . (37) In this weak-coupling context at the scale gT color electric fields begin to be screened within the thermal medium. Thus gT ∼ m D is related to the concept of the electric or Debye screening mass of gluons. The next lower scale is g 2 T , where also color magnetic fields become screened. The physics of magnetic screening even at high temperatures is genuinely non-perturbative. The lowest of the scales g 4 T is the scale of the inverse mean free path at which a hydrodynamic long-wavelength description of the thermal medium becomes viable.</p>
        <p>When considering effective field theory descriptions for quarkonium in a thermal medium we will have to deal with the confluence of many of the scales listed above. While at high temperatures their separation is often apparent, in the non-perturbative context of quarkonium in heavy-ion collisions they may become entangled and care must be taken to ensure that scale separation arguments hold.When considering effective field theory descriptions for quarkonium in a thermal medium we will have to deal with the confluence of many of the scales listed above. While at high temperatures their separation is often apparent, in the non-perturbative context of quarkonium in heavy-ion collisions they may become entangled and care must be taken to ensure that scale separation arguments hold.</p>
        <p>In general, effective field theories exploit hierarchies of scales in a systematic fashion in order to simplify the description of physical processes relevant to the user. In the context of heavy quarkonium we are e.g. interested in learning about whether a quark-antiquark pair immersed into a hot medium can form a bound state or at least temporarily coalesce into a resonance. To understand the binding properties of such a two-body system, we are not concerned with how the heavy quark pair came into being in the first place. This is where EFT's play their strength: instead of having to deal with the whole intricacies of relativistic Dirac spinor fields we will see that the physics of bound state formation, involving energies at the order of the binding energy of such a state can be described instead by non-relativistic Pauli spinors. The physics of heavy quark creation and annihilation at a much higher energy scale in this sense is not relevant and thus not treated explicitly, it is said to be integrated out.In general, effective field theories exploit hierarchies of scales in a systematic fashion in order to simplify the description of physical processes relevant to the user. In the context of heavy quarkonium we are e.g. interested in learning about whether a quark-antiquark pair immersed into a hot medium can form a bound state or at least temporarily coalesce into a resonance. To understand the binding properties of such a two-body system, we are not concerned with how the heavy quark pair came into being in the first place. This is where EFT's play their strength: instead of having to deal with the whole intricacies of relativistic Dirac spinor fields we will see that the physics of bound state formation, involving energies at the order of the binding energy of such a state can be described instead by non-relativistic Pauli spinors. The physics of heavy quark creation and annihilation at a much higher energy scale in this sense is not relevant and thus not treated explicitly, it is said to be integrated out.</p>
        <p>In order to set up an EFT description of heavy quarkonium four steps are required:In order to set up an EFT description of heavy quarkonium four steps are required:</p>
        <p>A. Identify the energy scale of interest B. Identify the degrees of freedom relevant at that energy scale C. Construct the most general Lagrangian from these d.o.f. compatible with the symmetries of underlying QCD. Assign each term an in general complex prefactor, a Wilson coefficient. D. Determine the values of the Wilson coefficients by matchingA. Identify the energy scale of interest B. Identify the degrees of freedom relevant at that energy scale C. Construct the most general Lagrangian from these d.o.f. compatible with the symmetries of underlying QCD. Assign each term an in general complex prefactor, a Wilson coefficient. D. Determine the values of the Wilson coefficients by matching</p>
        <p>To understand the basic ingredients of the construction of the effective field theory NRQCD, let us start out by considering processes that occur below some energy Λ EFT scale which itself lies firmly below the hard scale m Q (A). I.e.To understand the basic ingredients of the construction of the effective field theory NRQCD, let us start out by considering processes that occur below some energy Λ EFT scale which itself lies firmly below the hard scale m Q (A). I.e.</p>
        <p>the energies of the quark and gluon fields involved are smaller than what is necessary to create a heavy quark-anti-quark pair. Since pair creation is a hallmark of relativistic field theory, its absence intuitively tells us that eventually a simpler non-relativistic description should emerge. To proceed one needs to determine what degrees of freedom are relevant in such as scenario (B). The Foldy-Tani-Wouthuysen transform [53,54], known from the derivation of the relativistic corrections of the hydrogen atom, proves helpful in this context. Starting out from the relativistic Dirac Lagrangianthe energies of the quark and gluon fields involved are smaller than what is necessary to create a heavy quark-anti-quark pair. Since pair creation is a hallmark of relativistic field theory, its absence intuitively tells us that eventually a simpler non-relativistic description should emerge. To proceed one needs to determine what degrees of freedom are relevant in such as scenario (B). The Foldy-Tani-Wouthuysen transform [53,54], known from the derivation of the relativistic corrections of the hydrogen atom, proves helpful in this context. Starting out from the relativistic Dirac Lagrangian</p>
        <p>with D µ = ∂ µ + igA µ , one introduces a unitary field redefinitionwith D µ = ∂ µ + igA µ , one introduces a unitary field redefinition</p>
        <p>in the form of an exponential, which contains a small dimensionless expansion parameter due to m Q in the denominator.in the form of an exponential, which contains a small dimensionless expansion parameter due to m Q in the denominator.</p>
        <p>A subsequent second field redefinition of the formA subsequent second field redefinition of the form</p>
        <p>with E i = F 0i , the electric field, defined via the temporal components of the field strength tensorwith E i = F 0i , the electric field, defined via the temporal components of the field strength tensor</p>
        <p>, then leads to the following [55] approximate Dirac Lagrangian, then leads to the following [55] approximate Dirac Lagrangian</p>
        <p>This Lagrangian is the Pauli Lagrangian familiar from non-relativistic quantum mechanics, where to the order in the expansion considered here, the upper and lower components of the original Dirac four spinor Q = (ψ , χ) are completely decoupled. Since the rest mass only enters as a constant it too can be eliminated by a field redefinition. No pair creation processes are possible at this stage. I.e. we conclude that as long as the rest mass of the quarks is much larger than the characteristic canonical momentum D i /m Q ≪ 1 Pauli spinors should provide us with an appropriate set of degrees of freedom. One is therefore left with constructing the most general Lagrangian of Pauli spinors (C), which requires us to develop a consistent power counting scheme.This Lagrangian is the Pauli Lagrangian familiar from non-relativistic quantum mechanics, where to the order in the expansion considered here, the upper and lower components of the original Dirac four spinor Q = (ψ , χ) are completely decoupled. Since the rest mass only enters as a constant it too can be eliminated by a field redefinition. No pair creation processes are possible at this stage. I.e. we conclude that as long as the rest mass of the quarks is much larger than the characteristic canonical momentum D i /m Q ≪ 1 Pauli spinors should provide us with an appropriate set of degrees of freedom. One is therefore left with constructing the most general Lagrangian of Pauli spinors (C), which requires us to develop a consistent power counting scheme.</p>
        <p>For the study of particles containing both heavy and light particles the EFT heavy-quark effective theory (HQET) has been devised in Refs. [56][57][58] (for a review see Refs. [59,60]). It is based on an expansion of the QCD Lagrangian formulated in powers of ''Λ EFT /m Q '' and has been successfully used to study the properties of B and D mesons.For the study of particles containing both heavy and light particles the EFT heavy-quark effective theory (HQET) has been devised in Refs. [56][57][58] (for a review see Refs. [59,60]). It is based on an expansion of the QCD Lagrangian formulated in powers of ''Λ EFT /m Q '' and has been successfully used to study the properties of B and D mesons.</p>
        <p>On the other hand quarkonium particles only contain heavy constituents and are thus amenable to an EFT that exploits this fact. It is christened NRQCD and is organized around an expansion in the dimensionless small parameter v, the relative heavy quark velocity. A detailed discussion of its construction can be found in Ref. [50]. At the lowest order, the NRQCD Lagrangian agrees with the Foldy-Tani-Wouthuysen result, but allows to systematically extend the series to higher orders, eventually reproducing the QCD Dirac Lagrangian. Its lowest order terms according to Ref. [46] read explicitly for the ψ componentOn the other hand quarkonium particles only contain heavy constituents and are thus amenable to an EFT that exploits this fact. It is christened NRQCD and is organized around an expansion in the dimensionless small parameter v, the relative heavy quark velocity. A detailed discussion of its construction can be found in Ref. [50]. At the lowest order, the NRQCD Lagrangian agrees with the Foldy-Tani-Wouthuysen result, but allows to systematically extend the series to higher orders, eventually reproducing the QCD Dirac Lagrangian. Its lowest order terms according to Ref. [46] read explicitly for the ψ component</p>
        <p>The NRQCD action for the anti-quark field L χ is obtained from the charge conjugation of L ψ with ψ c = -iσ 2 χ * and A c µ = -A t µ , as antiquarks transform under the 3 representation of SU (3).The NRQCD action for the anti-quark field L χ is obtained from the charge conjugation of L ψ with ψ c = -iσ 2 χ * and A c µ = -A t µ , as antiquarks transform under the 3 representation of SU (3).</p>
        <p>Note that each term has been assigned a complex valued prefactor c i , the so called Wilson coefficients. These play an important conceptual and practical role in the construction of an EFT. Since we include in the EFT only d.o.f. with energies at or below Λ EFT the remnants of the physics of those d.o.f. at higher energies must be able to manifest itself. This is where Wilson coefficients come into play (for the underlying theory of the renormalization group see [61]). For the EFT to reproduce the physics of QCD faithfully below Λ EFT the Wilson coefficients need to be tuned in a procedure called matching (D). I.e. one computes correlation functions of heavy quark fields both in QCD and the EFT and then require that they agree at energies below Λ EFT . In addition the symmetries of the microscopic theory provide apriori constraints on some of them. E.g. Lorentz invariance subtly reappears in NRQCD as the constraints c k = c 4 = 1 and 2c F -c S -1 = 0 (for a more detailed discussion of Lorentz-and reparametrization invariance see Refs. [62][63][64][65][66]). If Λ EFT ≫ Λ QCD the matching procedure can be carried out perturbatively, otherwise it requires fully non-perturbative methods, such as lattice QCD simulations, discussed in the following section.Note that each term has been assigned a complex valued prefactor c i , the so called Wilson coefficients. These play an important conceptual and practical role in the construction of an EFT. Since we include in the EFT only d.o.f. with energies at or below Λ EFT the remnants of the physics of those d.o.f. at higher energies must be able to manifest itself. This is where Wilson coefficients come into play (for the underlying theory of the renormalization group see [61]). For the EFT to reproduce the physics of QCD faithfully below Λ EFT the Wilson coefficients need to be tuned in a procedure called matching (D). I.e. one computes correlation functions of heavy quark fields both in QCD and the EFT and then require that they agree at energies below Λ EFT . In addition the symmetries of the microscopic theory provide apriori constraints on some of them. E.g. Lorentz invariance subtly reappears in NRQCD as the constraints c k = c 4 = 1 and 2c F -c S -1 = 0 (for a more detailed discussion of Lorentz-and reparametrization invariance see Refs. [62][63][64][65][66]). If Λ EFT ≫ Λ QCD the matching procedure can be carried out perturbatively, otherwise it requires fully non-perturbative methods, such as lattice QCD simulations, discussed in the following section.</p>
        <p>Eq. ( 42) however is not yet all that contributes to the heavy quark dynamics at order v 2 . Indeed somehow the pair creation processes eventually need to find their way back in, if NRQCD is a systematic approximation of QCD. This is taken care of by the contributions of additional color singlet and color octet four-fermion interaction terms as given in Ref. [36],Eq. ( 42) however is not yet all that contributes to the heavy quark dynamics at order v 2 . Indeed somehow the pair creation processes eventually need to find their way back in, if NRQCD is a systematic approximation of QCD. This is taken care of by the contributions of additional color singlet and color octet four-fermion interaction terms as given in Ref. [36],</p>
        <p>whose prefactors encode the physics of gluons with energies of the order of the hard scale. Similarly the Fermi constant encodes the explicit physics of the weak gauge bosons. One should keep in mind that to consistently formulate NRQCD also the light degrees of freedom in QCD need to be restricted in their energy below Λ EFT . In turn additional interaction terms appear also for the light quarks and gluons, each with their own Wilson coefficient, which however are suppressed by inverse powers of the EFT cutoff scale.whose prefactors encode the physics of gluons with energies of the order of the hard scale. Similarly the Fermi constant encodes the explicit physics of the weak gauge bosons. One should keep in mind that to consistently formulate NRQCD also the light degrees of freedom in QCD need to be restricted in their energy below Λ EFT . In turn additional interaction terms appear also for the light quarks and gluons, each with their own Wilson coefficient, which however are suppressed by inverse powers of the EFT cutoff scale.</p>
        <p>At least for bottom quarks, a perturbative determination of the Wilson coefficients is often possible, which tells us that the c i 's within Eq. ( 42) start at unity and the first correction goes linearly in the strong coupling c = 1 + O(α S ) including, as expected, logarithmic dependencies on the EFT cutoff. Most of the f 's in Eq. ( 43) start out at O(α 2 S ) except for the octet f 8 ( 3 S 1 ), which goes as O(α S ).At least for bottom quarks, a perturbative determination of the Wilson coefficients is often possible, which tells us that the c i 's within Eq. ( 42) start at unity and the first correction goes linearly in the strong coupling c = 1 + O(α S ) including, as expected, logarithmic dependencies on the EFT cutoff. Most of the f 's in Eq. ( 43) start out at O(α 2 S ) except for the octet f 8 ( 3 S 1 ), which goes as O(α S ).</p>
        <p>When speaking about NRQCD one always refers to a specific cutoff Λ QCD . Once we change its value, in principle, all Wilson coefficients need to be reevaluated to produce a consistent effective description.When speaking about NRQCD one always refers to a specific cutoff Λ QCD . Once we change its value, in principle, all Wilson coefficients need to be reevaluated to produce a consistent effective description.</p>
        <p>In QCD, quarkonium particles are described by correlation functions of meson operators as discussed in Section 2.1. Using a similar strategy as the Foldy-Tani-Wouthuysen transform in the Lagrangian, the form of the NRQCD counterparts of these operators can be derived. In the spirit of EFTs each term in the expansion is assigned a Wilson coefficient. For the vector and axial vector channel the explicit expressions given in Ref. [67] readIn QCD, quarkonium particles are described by correlation functions of meson operators as discussed in Section 2.1. Using a similar strategy as the Foldy-Tani-Wouthuysen transform in the Lagrangian, the form of the NRQCD counterparts of these operators can be derived. In the spirit of EFTs each term in the expansion is assigned a Wilson coefficient. For the vector and axial vector channel the explicit expressions given in Ref. [67] read</p>
        <p>where the symmetric covariant derivative is expressed aswhere the symmetric covariant derivative is expressed as</p>
        <p>How does the behavior of non-relativistic correlators differ from that of their QCD counterparts and in consequence what are the corresponding differences in the underlying spectral functions? Intuitively what we have done in setting up NRQCD is to separate the forward and backward propagating contributions to the spectral function in Eq. (22). I.e. similar to what happens when one introduces a large chemical potential for the heavy quark fields, only spectral structures at positive frequencies contribute. In addition we introduced a field redefinition with a phase exp[-im Q t] to get rid of the rest mass term in the NRQCD Lagrangian. This in turn leads to a frequency shift of 2m Q in the NRQCD quarkonium spectral function. I.e. the frequency origin of the NRQCD spectral function lies at the former threshold 2m Q and a spectrum of bound states can now in principle extend to negative frequencies in this new coordinate system. The transport peak itself is not encoded anymore in these spectra. This leads to a simplification in the spectral representation, in particular when considering the in-medium Euclidean correlator, which is now connected to the equilibrium spectral function by a temperature independent integral kernelHow does the behavior of non-relativistic correlators differ from that of their QCD counterparts and in consequence what are the corresponding differences in the underlying spectral functions? Intuitively what we have done in setting up NRQCD is to separate the forward and backward propagating contributions to the spectral function in Eq. (22). I.e. similar to what happens when one introduces a large chemical potential for the heavy quark fields, only spectral structures at positive frequencies contribute. In addition we introduced a field redefinition with a phase exp[-im Q t] to get rid of the rest mass term in the NRQCD Lagrangian. This in turn leads to a frequency shift of 2m Q in the NRQCD quarkonium spectral function. I.e. the frequency origin of the NRQCD spectral function lies at the former threshold 2m Q and a spectrum of bound states can now in principle extend to negative frequencies in this new coordinate system. The transport peak itself is not encoded anymore in these spectra. This leads to a simplification in the spectral representation, in particular when considering the in-medium Euclidean correlator, which is now connected to the equilibrium spectral function by a temperature independent integral kernel</p>
        <p>Note that even though this correlator does not feature the periodicity usually associated with thermal relativistic correlators, it encodes the physics of a quarkonium particle fully kinetically equilibrated with its surroundings.Note that even though this correlator does not feature the periodicity usually associated with thermal relativistic correlators, it encodes the physics of a quarkonium particle fully kinetically equilibrated with its surroundings.</p>
        <p>Let us have a look at the explicit form of the S-wave and P-wave quarkonium correlators in the non-interacting theory, first computed in Ref. [68], followed up by Ref. [16]. They differ in that the vertex operator of the latter introduces additional factors of the momentum operatorLet us have a look at the explicit form of the S-wave and P-wave quarkonium correlators in the non-interacting theory, first computed in Ref. [68], followed up by Ref. [16]. They differ in that the vertex operator of the latter introduces additional factors of the momentum operator</p>
        <p>This translates [69] into the non-interacting spectral functionsThis translates [69] into the non-interacting spectral functions</p>
        <p>where the finite momentum simply induces a shift of the threshold ω ′ = ωp 2 /4M. In contrast to the relativistic spectral functions the high frequency behavior now differs between the S-wave and the P-wave, the latter containing a much stronger contribution at high frequencies. Note also that the free spectra start off from ω = 0, which corresponds to the threshold 2m Q in the original unshifted frequency axis of QCD.where the finite momentum simply induces a shift of the threshold ω ′ = ωp 2 /4M. In contrast to the relativistic spectral functions the high frequency behavior now differs between the S-wave and the P-wave, the latter containing a much stronger contribution at high frequencies. Note also that the free spectra start off from ω = 0, which corresponds to the threshold 2m Q in the original unshifted frequency axis of QCD.</p>
        <p>The specific properties of the medium so far did not occur in the discussion of the setup of NRQCD. As long as Λ EFT ≥ T , which is the case in current studies of heavy quarkonium, this is fine, since only the separation of scale m Q ≫ Λ EFT has been exploited in setting up the EFT.The specific properties of the medium so far did not occur in the discussion of the setup of NRQCD. As long as Λ EFT ≥ T , which is the case in current studies of heavy quarkonium, this is fine, since only the separation of scale m Q ≫ Λ EFT has been exploited in setting up the EFT.</p>
        <p>If quarkonium binding properties determined by the physics at the ultrasoft scale are our only concern, then NRQCD still contains more explicit d.o.f. than necessary. As has been first considered in Ref. [47] we can set the energy cutoff below the characteristic momentum m Q v ∼ |p| &gt; Λ EFT and wish to integrate out those d.o.f. that cannot be excited spontaneously above E ∼ m Q v 2 . The resulting EFT is called potential NRQCD, where the term potential formally refers to non-local Wilson coefficients, which are a hallmark of how pNRQCD describes heavy quarkonium physics.If quarkonium binding properties determined by the physics at the ultrasoft scale are our only concern, then NRQCD still contains more explicit d.o.f. than necessary. As has been first considered in Ref. [47] we can set the energy cutoff below the characteristic momentum m Q v ∼ |p| &gt; Λ EFT and wish to integrate out those d.o.f. that cannot be excited spontaneously above E ∼ m Q v 2 . The resulting EFT is called potential NRQCD, where the term potential formally refers to non-local Wilson coefficients, which are a hallmark of how pNRQCD describes heavy quarkonium physics.</p>
        <p>The characteristic scale of quantum fluctuations in QCD Λ QCD lies in between the various values of binding energies of different vacuum quarkonium states. At the same time the temperatures created in relativistic heavy-ion collisions can also easily reach the same magnitude. Therefore both selecting the relevant degrees of freedom and the matching of the corresponding Wilson coefficients differs, depending on the exact hierarchy of scales present. In case that m Q v ≫ Λ QCD where a perturbative approach to integrating out the soft scale is applicable, the setup of pNRQCD has been thoroughly established. In the non-perturbative regime an equally robust understanding is still outstanding and remains an active field of research.The characteristic scale of quantum fluctuations in QCD Λ QCD lies in between the various values of binding energies of different vacuum quarkonium states. At the same time the temperatures created in relativistic heavy-ion collisions can also easily reach the same magnitude. Therefore both selecting the relevant degrees of freedom and the matching of the corresponding Wilson coefficients differs, depending on the exact hierarchy of scales present. In case that m Q v ≫ Λ QCD where a perturbative approach to integrating out the soft scale is applicable, the setup of pNRQCD has been thoroughly established. In the non-perturbative regime an equally robust understanding is still outstanding and remains an active field of research.</p>
        <p>Let us briefly summarize the most important ingredients to weakly coupled pNRQCD. In contrast to NRQCD, one now consider two cutoffs, one for the relative spatial momentumLet us briefly summarize the most important ingredients to weakly coupled pNRQCD. In contrast to NRQCD, one now consider two cutoffs, one for the relative spatial momentum</p>
        <p>which is the same as in NRQCD and one for the energy of the heavy quarks which is now restricted to m Q v &gt; Λ E EFT . One further assumes that the relevant d.o.f. are again quarks and gluons, i.e. the actual particle content remains the same between NRQCD and weakly coupled pNRQCD.which is the same as in NRQCD and one for the energy of the heavy quarks which is now restricted to m Q v &gt; Λ E EFT . One further assumes that the relevant d.o.f. are again quarks and gluons, i.e. the actual particle content remains the same between NRQCD and weakly coupled pNRQCD.</p>
        <p>While one could stay with the field ψ and χ, it turns out that in order to write the pNRQCD Lagrangian in an intuitive fashion and to establish a systematic power counting, it is helpful to go over to what in this context is called a quarkonium wavefunctionWhile one could stay with the field ψ and χ, it turns out that in order to write the pNRQCD Lagrangian in an intuitive fashion and to establish a systematic power counting, it is helpful to go over to what in this context is called a quarkonium wavefunction</p>
        <p>given by a point split product of NRQCD fields. Both the color structure and the spatial dependencies of this object may now be decomposed leading to an expression depending on a color singlet S(r, R, t) and color octet wavefunction O(r, R, t) in terms of the relative r = x 1 -x 2 and center coordinates R = 1 2given by a point split product of NRQCD fields. Both the color structure and the spatial dependencies of this object may now be decomposed leading to an expression depending on a color singlet S(r, R, t) and color octet wavefunction O(r, R, t) in terms of the relative r = x 1 -x 2 and center coordinates R = 1 2</p>
        <p>The appropriate choice of quark mass to use in these expressions is an active research topic, having led to the definition of the renormalon subtracted mass [70]. This form of Ψ (r, R, t) is advantageous, since the different transformation properties of S and O under color rotations induced by ultrasoft gluons are explicit. At the same timeThe appropriate choice of quark mass to use in these expressions is an active research topic, having led to the definition of the renormalon subtracted mass [70]. This form of Ψ (r, R, t) is advantageous, since the different transformation properties of S and O under color rotations induced by ultrasoft gluons are explicit. At the same time</p>
        <p>EFT translates into the fact that relative distances r are always smaller than the typical length scales of the light degrees of freedom. In turn the gauge fields that remain active as explicit degrees of freedom in pNRQCD enter the Lagrangian via a multipole expansion.EFT translates into the fact that relative distances r are always smaller than the typical length scales of the light degrees of freedom. In turn the gauge fields that remain active as explicit degrees of freedom in pNRQCD enter the Lagrangian via a multipole expansion.</p>
        <p>In the case considered here, where the ultrasoft scale lies sufficiently above the confinement scale, i.e. m Q v 2 ≳ Λ QCD quarks and gluons remain the relevant degrees of freedom. The most general combination of color singlet and color octet heavy quark wavefunctions in the presence of ultrasoft light degrees of freedom, appropriate for this scale separation, has been derived in Ref. [47] to beIn the case considered here, where the ultrasoft scale lies sufficiently above the confinement scale, i.e. m Q v 2 ≳ Λ QCD quarks and gluons remain the relevant degrees of freedom. The most general combination of color singlet and color octet heavy quark wavefunctions in the presence of ultrasoft light degrees of freedom, appropriate for this scale separation, has been derived in Ref. [47] to be</p>
        <p>with µ = m Q /2 the reduced mass and M = 2m Q the total mass of the two heavy quarks. The nonlocal Wilson coefficientswith µ = m Q /2 the reduced mass and M = 2m Q the total mass of the two heavy quarks. The nonlocal Wilson coefficients</p>
        <p>V can carry a dependence on both the relative distance r the corresponding relative momentum p, the center of mass momentum P, as well as the spin operators of both quark and antiquark S 1 and S 2 . The constraints imposed by Lorentz invariance in addition force the terms c S,O 1,2 to take on the same values and were shown in Ref. [64] to reduce to unity. Let us have a look at the form of this Lagrangian. On the one hand Eq. ( 52) exhibits the simple form of a Schrödinger Lagrangian in the first two lines, telling us that the evolution of the singlet and octet wavefunctions is governed by a potential. The terms V (0) S,O refer to static potentials, which act even in the case of static quarks. The other terms are momentum and spin dependent corrections to these static potentials. On the other hand we are dealing with a genuine field theory here in which ultrasoft gluons are still contributing. Their influence is seen in the third line, inducing dipole-like transitions between the color singlet and color octet states and also within the color octet states. I.e. in pNRQCD even for static quarks, singlet and octet quarkonium states do not automatically evolve separately with a simple Schrödinger equation. As we will see later, we may however find situations where the effects of the dipole exchange can be summarized by a time independent contribution to the in-medium potential.V can carry a dependence on both the relative distance r the corresponding relative momentum p, the center of mass momentum P, as well as the spin operators of both quark and antiquark S 1 and S 2 . The constraints imposed by Lorentz invariance in addition force the terms c S,O 1,2 to take on the same values and were shown in Ref. [64] to reduce to unity. Let us have a look at the form of this Lagrangian. On the one hand Eq. ( 52) exhibits the simple form of a Schrödinger Lagrangian in the first two lines, telling us that the evolution of the singlet and octet wavefunctions is governed by a potential. The terms V (0) S,O refer to static potentials, which act even in the case of static quarks. The other terms are momentum and spin dependent corrections to these static potentials. On the other hand we are dealing with a genuine field theory here in which ultrasoft gluons are still contributing. Their influence is seen in the third line, inducing dipole-like transitions between the color singlet and color octet states and also within the color octet states. I.e. in pNRQCD even for static quarks, singlet and octet quarkonium states do not automatically evolve separately with a simple Schrödinger equation. As we will see later, we may however find situations where the effects of the dipole exchange can be summarized by a time independent contribution to the in-medium potential.</p>
        <p>What changes in the case where the ultrasoft scale lies at or below the confinement scale m Q v 2 ≲ Λ QCD , the so called strongly coupled scenario? At T = 0 the relevant ultrasoft degrees of freedom are the goldstone bosons of QCD, i.e. pions, while both the much heavier glueballs are integrated out. Since only color neutral states remain to scatter with quarkonium, one only needs to consider the color singlet sector. If one disregards the effects of scattering with the Goldstone bosons the physics of strongly coupled pNRQCD is governed thus solely by time independent potential terms. One should keep in mind however that this description is robust only for states far below the open heavy-flavor threshold. Close to it, the energy difference between a quarkonium state and two D or B mesons is small enough so that transitions between the channels need to be explicitly treated, which requires the inclusion of the open-heavy flavor states as additional coupled channels, as discussed early on e.g. in Refs. [4,71]. The question of how to rigorously construct a strongly coupled variant of pNRQCD at finite temperature around the crossover transition, where both hadronic and partonic degrees of freedom are active, remains an active field of research.What changes in the case where the ultrasoft scale lies at or below the confinement scale m Q v 2 ≲ Λ QCD , the so called strongly coupled scenario? At T = 0 the relevant ultrasoft degrees of freedom are the goldstone bosons of QCD, i.e. pions, while both the much heavier glueballs are integrated out. Since only color neutral states remain to scatter with quarkonium, one only needs to consider the color singlet sector. If one disregards the effects of scattering with the Goldstone bosons the physics of strongly coupled pNRQCD is governed thus solely by time independent potential terms. One should keep in mind however that this description is robust only for states far below the open heavy-flavor threshold. Close to it, the energy difference between a quarkonium state and two D or B mesons is small enough so that transitions between the channels need to be explicitly treated, which requires the inclusion of the open-heavy flavor states as additional coupled channels, as discussed early on e.g. in Refs. [4,71]. The question of how to rigorously construct a strongly coupled variant of pNRQCD at finite temperature around the crossover transition, where both hadronic and partonic degrees of freedom are active, remains an active field of research.</p>
        <p>Let us return to the question of how to determine the values of the potential terms. For the implementation of direct perturbative matching of pNRQCD using resummed hard-thermal loop perturbation theory see Ref. [17]. One versatile strategy for matching is to relate the potential terms to expressions involving the real-time QCD Wilson loopLet us return to the question of how to determine the values of the potential terms. For the implementation of direct perturbative matching of pNRQCD using resummed hard-thermal loop perturbation theory see Ref. [17]. One versatile strategy for matching is to relate the potential terms to expressions involving the real-time QCD Wilson loop</p>
        <p>where the gauge field is integrated over a rectangular path with spatial extent r and temporal extent t. As discussed originally in Ref. [55] and more rigorously in Ref. [50], the starting point is to consider the correlator of point split meson operators, the NRQCD counterpart to the pNRQCD correlator of singlet wavefunctionswhere the gauge field is integrated over a rectangular path with spatial extent r and temporal extent t. As discussed originally in Ref. [55] and more rigorously in Ref. [50], the starting point is to consider the correlator of point split meson operators, the NRQCD counterpart to the pNRQCD correlator of singlet wavefunctions</p>
        <p>Since the NRQCD Lagrangian is quadratic in the heavy quark fields, the path integral has been performed in the second line and one ends up with expressions in terms of heavy quark and antiquark propagators.Since the NRQCD Lagrangian is quadratic in the heavy quark fields, the path integral has been performed in the second line and one ends up with expressions in terms of heavy quark and antiquark propagators.</p>
        <p>The propagator G ψ (x, y) = ⟨ψ † (x)ψ (y)⟩ is defined using the NRQCD Lagrangian in the standard way.The propagator G ψ (x, y) = ⟨ψ † (x)ψ (y)⟩ is defined using the NRQCD Lagrangian in the standard way.</p>
        <p>and vice versa for G χ . The form of G can be determined explicitly in the static caseand vice versa for G χ . The form of G can be determined explicitly in the static case</p>
        <p>where it reduces to a temporal Wilson line and in turn Eq. ( 56) reduces to the Wilson loop. At the same time in pNRQCD at zeroth order in the multipole expansion one obtains a simple exponential in the static limit. Singling out the ultrasoft energy regime by considering late times, we may formally writewhere it reduces to a temporal Wilson line and in turn Eq. ( 56) reduces to the Wilson loop. At the same time in pNRQCD at zeroth order in the multipole expansion one obtains a simple exponential in the static limit. Singling out the ultrasoft energy regime by considering late times, we may formally write</p>
        <p>In turn we may connect the late time behavior of the real-time Wilson loop with the values of the static heavy quark potentialIn turn we may connect the late time behavior of the real-time Wilson loop with the values of the static heavy quark potential</p>
        <p>Before we turn our attention to the evaluation of this expression a few remarks are in order. First of all, for Eq. ( 61) to make sense, the non-potential effects encoded in Eq. ( 52) for weakly coupled pNRQCD via the dipole transition terms need to reduce to a time independent contribution to the Wilson loop time evolution. I.e. the transitions between the color singlet and octet sector must be captured by an effective transition rate within the singlet sector alone. A scenario where this indeed takes place is considered in e.g. Ref. [17]. In particular in a strongly coupled scenario it is not a priori clear whether such a simplification occurs and its validity has to be ascertained depending on e.g. the energy density of the medium surrounding the heavy quark fields. A discussion of how to disentangle potential from non-potential effects through the spectral functions of the Wilson loops is given below Eq. ( 174) in Section 3.2.Before we turn our attention to the evaluation of this expression a few remarks are in order. First of all, for Eq. ( 61) to make sense, the non-potential effects encoded in Eq. ( 52) for weakly coupled pNRQCD via the dipole transition terms need to reduce to a time independent contribution to the Wilson loop time evolution. I.e. the transitions between the color singlet and octet sector must be captured by an effective transition rate within the singlet sector alone. A scenario where this indeed takes place is considered in e.g. Ref. [17]. In particular in a strongly coupled scenario it is not a priori clear whether such a simplification occurs and its validity has to be ascertained depending on e.g. the energy density of the medium surrounding the heavy quark fields. A discussion of how to disentangle potential from non-potential effects through the spectral functions of the Wilson loops is given below Eq. ( 174) in Section 3.2.</p>
        <p>In contrast to the definition of the heavy quark potential often encountered in the lattice QCD literature Eq. ( 61) is formulated in Minkowski time and not in imaginary time. I.e. the Wilson loops are oscillatory functions with a real and an imaginary part and thus the value of the potential V S can be in general complex.In contrast to the definition of the heavy quark potential often encountered in the lattice QCD literature Eq. ( 61) is formulated in Minkowski time and not in imaginary time. I.e. the Wilson loops are oscillatory functions with a real and an imaginary part and thus the value of the potential V S can be in general complex.</p>
        <p>Up to this point we have only considered the static potential for the singlet. Note that matching of the octet potential, as well as momentum dependent and spin dependent corrections is in principle possible. The first spin dependent corrections were computed in Ref. [72] and the full O(v 2 ) result presented in Ref. [73]. To connect to the functional language introduced in Section 2.1 one may follow Ref. [55] where corrections are obtained by rewriting the propagator G in terms of a non-relativistic quantum mechanical path integral. In vacuum several finite mass correction terms to the singlet potential have already been determined in lattice QCD in Refs. [74,75] and a non-perturbative definition of a color adjoint potential has been discussed in Ref. [76]. Similar results at finite temperature are however still outstanding.Up to this point we have only considered the static potential for the singlet. Note that matching of the octet potential, as well as momentum dependent and spin dependent corrections is in principle possible. The first spin dependent corrections were computed in Ref. [72] and the full O(v 2 ) result presented in Ref. [73]. To connect to the functional language introduced in Section 2.1 one may follow Ref. [55] where corrections are obtained by rewriting the propagator G in terms of a non-relativistic quantum mechanical path integral. In vacuum several finite mass correction terms to the singlet potential have already been determined in lattice QCD in Refs. [74,75] and a non-perturbative definition of a color adjoint potential has been discussed in Ref. [76]. Similar results at finite temperature are however still outstanding.</p>
        <p>In the following section we will turn our attention to lattice QCD simulations, which will provide us with the means to compute the potential and meson correlation functions in general in a genuinely non-perturbative fashion.In the following section we will turn our attention to lattice QCD simulations, which will provide us with the means to compute the potential and meson correlation functions in general in a genuinely non-perturbative fashion.</p>
        <p>as well as the fact that m Q ≫ Λ QCD and in practice m Q ≫ ϵ medium allow us to simplify the description of quarkonium using non-relativistic language. In the EFT NRQCD the hard scale is integrated out and the relevant d.o.f. are Pauli spinors. In pNRQCD also the soft scale is integrated out. As long as the same relevant d.o.f. can be identified as in NRQCD, one may straightforwardly go over to a description in terms of color singlet and octet wavefunctions whose Lagrangian contains non-local Wilson coefficients called potentials. The propagation of these wavefunctions is determined by both potential and non-potential contributions.as well as the fact that m Q ≫ Λ QCD and in practice m Q ≫ ϵ medium allow us to simplify the description of quarkonium using non-relativistic language. In the EFT NRQCD the hard scale is integrated out and the relevant d.o.f. are Pauli spinors. In pNRQCD also the soft scale is integrated out. As long as the same relevant d.o.f. can be identified as in NRQCD, one may straightforwardly go over to a description in terms of color singlet and octet wavefunctions whose Lagrangian contains non-local Wilson coefficients called potentials. The propagation of these wavefunctions is determined by both potential and non-potential contributions.</p>
        <p>If the former dominate we can match the values of the static potential to the late time evolution of the real-time Wilson loop in QCD. The different energy scales, as well as the corresponding EFT setups are sketched in Fig. 4.If the former dominate we can match the values of the static potential to the late time evolution of the real-time Wilson loop in QCD. The different energy scales, as well as the corresponding EFT setups are sketched in Fig. 4.</p>
        <p>In this section we summarize relevant ingredients to non-perturbative numerical simulations of quarkonium physics, based on lattice regularized QCD. Several excellent textbooks provide a comprehensive introduction to this field [77][78][79]. The need for genuine non-perturbative methods in the study of quarkonium in extreme conditions is twofold. On the one hand, already at T = 0 the binding energies of several of the quarkonium states are close to or even less than Λ QCD . This entails that results in perturbation theory will receive large non-perturbative corrections. While Υ (1S) is considered safe for the application of perturbation theory, such corrections already play a role for J/ψ . On the other hand when we wish to understand heavy quark binding in a heavy-ion collision, the temperatures encountered at today's colliders are so close to the QCD crossover transition that a non-perturbative approach to the quark and gluon d.o.f. in the quarkonium environment is warranted. One indication is the large value of the trace anomaly, also called the interaction measure, in that temperature region [8,80].In this section we summarize relevant ingredients to non-perturbative numerical simulations of quarkonium physics, based on lattice regularized QCD. Several excellent textbooks provide a comprehensive introduction to this field [77][78][79]. The need for genuine non-perturbative methods in the study of quarkonium in extreme conditions is twofold. On the one hand, already at T = 0 the binding energies of several of the quarkonium states are close to or even less than Λ QCD . This entails that results in perturbation theory will receive large non-perturbative corrections. While Υ (1S) is considered safe for the application of perturbation theory, such corrections already play a role for J/ψ . On the other hand when we wish to understand heavy quark binding in a heavy-ion collision, the temperatures encountered at today's colliders are so close to the QCD crossover transition that a non-perturbative approach to the quark and gluon d.o.f. in the quarkonium environment is warranted. One indication is the large value of the trace anomaly, also called the interaction measure, in that temperature region [8,80].</p>
        <p>The starting point for lattice QCD is the discovery of Wilson [81] that QCD can be regularized in a gauge invariant manner by placing its d.o.f. on a compact four dimensional spacetime grid N x × N y × N z × N t with lattice spacing a µ . Most often isotropic a µ = a lattices are considered, but also anisotropies in temporal direction are used in practice with a 0 = a t and a i = a s . Discretized fermion fields ψ a,α (x) reside on the nodes of the grid. The role of gauge fields as parallel transporters for the quarks d.o.f. is made explicit and they are placed on the links of the lattice in the form of so called linkThe starting point for lattice QCD is the discovery of Wilson [81] that QCD can be regularized in a gauge invariant manner by placing its d.o.f. on a compact four dimensional spacetime grid N x × N y × N z × N t with lattice spacing a µ . Most often isotropic a µ = a lattices are considered, but also anisotropies in temporal direction are used in practice with a 0 = a t and a i = a s . Discretized fermion fields ψ a,α (x) reside on the nodes of the grid. The role of gauge fields as parallel transporters for the quarks d.o.f. is made explicit and they are placed on the links of the lattice in the form of so called link</p>
        <p>where no summation over µ is implied. These take on values in the group of SU(3), while the gauge fields Awhere no summation over µ is implied. These take on values in the group of SU(3), while the gauge fields A</p>
        <p>As the number of degrees of freedom is finite, the corresponding Feynman path integral is well defined. In turn correlation functions that exhibit divergences in continuum computations also come out finite. In particular, the quarkonium spectral functions defined in Section 2.1 consist of only a finite number of delta peaks. The challenge of course lies in eventually having to take the continuum limit a → 0 and the thermodynamics limit V → ∞ to recover the continuum theory of QCD. It is at latest at this point where a careful consideration of the renormalization of lattice regularized operators becomes essential.As the number of degrees of freedom is finite, the corresponding Feynman path integral is well defined. In turn correlation functions that exhibit divergences in continuum computations also come out finite. In particular, the quarkonium spectral functions defined in Section 2.1 consist of only a finite number of delta peaks. The challenge of course lies in eventually having to take the continuum limit a → 0 and the thermodynamics limit V → ∞ to recover the continuum theory of QCD. It is at latest at this point where a careful consideration of the renormalization of lattice regularized operators becomes essential.</p>
        <p>In the coordinate space regularization it is possible to set up a numerical simulation prescription, which approximates Feynman's path integral in a non-perturbative fashion. There however exists an important restriction. While we wish to compute real-time correlation functions and the associated spectral functions on the real-time branches C 1 and C 2 of the SK contour, conventional lattice QCD simulations have access only to the compact imaginary time branch C E . On it, bosonic fields, according to the KMS relation, have to obey periodic boundary conditions in τ , fermionic fields anti-periodic ones.In the coordinate space regularization it is possible to set up a numerical simulation prescription, which approximates Feynman's path integral in a non-perturbative fashion. There however exists an important restriction. While we wish to compute real-time correlation functions and the associated spectral functions on the real-time branches C 1 and C 2 of the SK contour, conventional lattice QCD simulations have access only to the compact imaginary time branch C E . On it, bosonic fields, according to the KMS relation, have to obey periodic boundary conditions in τ , fermionic fields anti-periodic ones.</p>
        <p>I.e. while the finite extent of the box in spatial direction is a discretization artifact, the finite extent in imaginary time direction encodes vital physics, i.e. the inverse temperature of the system under consideration. Since the box extent in a numerical simulation is always finite, lattice QCD simulations are always performed at a finite temperature. In what is called a T = 0 simulation, the Euclidean time extent is made large enough that the induced temperature is negligible.I.e. while the finite extent of the box in spatial direction is a discretization artifact, the finite extent in imaginary time direction encodes vital physics, i.e. the inverse temperature of the system under consideration. Since the box extent in a numerical simulation is always finite, lattice QCD simulations are always performed at a finite temperature. In what is called a T = 0 simulation, the Euclidean time extent is made large enough that the induced temperature is negligible.</p>
        <p>Analytically continuing real-time t to Euclidean time τ we may express the partition function of the theory asAnalytically continuing real-time t to Euclidean time τ we may express the partition function of the theory as</p>
        <p>where S E denotes the Euclidean QCD action and DU represents the Haar measure integrating over the link variables in SU(3) group space. The reason for restricting to C E lies in the fact that only on the imaginary time axis the Feynman weight exp[iS] becomes purely real and bounded. In turn exp[-S E ] may be interpreted as an unnormalized probability distribution, opening up the toolbox of stochastic Monte-Carlo simulations. This provides a practical path to evaluate the quantum statistical expectation values of operatorswhere S E denotes the Euclidean QCD action and DU represents the Haar measure integrating over the link variables in SU(3) group space. The reason for restricting to C E lies in the fact that only on the imaginary time axis the Feynman weight exp[iS] becomes purely real and bounded. In turn exp[-S E ] may be interpreted as an unnormalized probability distribution, opening up the toolbox of stochastic Monte-Carlo simulations. This provides a practical path to evaluate the quantum statistical expectation values of operators</p>
        <p>The efforts related to simulating directly in real-time, as well as at finite Baryon density, both of which leads to a complex Feynman weight, are summarized under the label sign problem (see e.g. Ref. [10]).The efforts related to simulating directly in real-time, as well as at finite Baryon density, both of which leads to a complex Feynman weight, are summarized under the label sign problem (see e.g. Ref. [10]).</p>
        <p>The Euclidean action contains a term for the gauge fields and for the fermion degrees of freedom S E = S g E + S f E . Many different implementations are possible in the discretized theory, all of which lead to the same continuum limit. The choice of discretization however determines how efficiently this limit is approached as the lattice spacing is reduced. Better convergence usually requires adding further terms to so called improved actions, increasing the numerical cost for their evaluation. The most naive choice for the gluons is the Wilson plaquette action, which for anisotropic lattices [82] readsThe Euclidean action contains a term for the gauge fields and for the fermion degrees of freedom S E = S g E + S f E . Many different implementations are possible in the discretized theory, all of which lead to the same continuum limit. The choice of discretization however determines how efficiently this limit is approached as the lattice spacing is reduced. Better convergence usually requires adding further terms to so called improved actions, increasing the numerical cost for their evaluation. The most naive choice for the gluons is the Wilson plaquette action, which for anisotropic lattices [82] reads</p>
        <p>) .) .</p>
        <p>((</p>
        <p>The vectors n = (x/a s , y/a s , z/a s , τ /a τ ) and m denote the position on the four dimensional grid, the vectors h = (x/a s , y/a s , z/a s ) and l the spatial part. The central quantitiesThe vectors n = (x/a s , y/a s , z/a s , τ /a τ ) and m denote the position on the four dimensional grid, the vectors h = (x/a s , y/a s , z/a s ) and l the spatial part. The central quantities</p>
        <p>the closed products of links around the unit loop. The unit vector in µ direction is denoted with μ. Here β = 2N c /g 2 does not refer to the inverse temperature but stands for the inverse bare coupling, as is convention in the lattice community.the closed products of links around the unit loop. The unit vector in µ direction is denoted with μ. Here β = 2N c /g 2 does not refer to the inverse temperature but stands for the inverse bare coupling, as is convention in the lattice community.</p>
        <p>The bare anisotropy parameter reads ξ 0 . The Wilson action is invariant under local gauge transformations G(n) ∈ SU (3), which act on the link variables asThe bare anisotropy parameter reads ξ 0 . The Wilson action is invariant under local gauge transformations G(n) ∈ SU (3), which act on the link variables as</p>
        <p>Different improved actions for the gauge sector, such as the Iwasaki action [83], have been developed, following the Szymanzik improvement program introduced in Refs. [84][85][86].Different improved actions for the gauge sector, such as the Iwasaki action [83], have been developed, following the Szymanzik improvement program introduced in Refs. [84][85][86].</p>
        <p>In general the gauge invariant fermionic part of the Euclidean action can be expressed as a bilinear in terms of Grassmann valued quark fields. Since explicit matrix representations of Grassmann numbers in terms of complex numbers are numerically too costly, one instead carries out the Gaussian integral a priori and ends up with a fermion determinant. Most efficient simulation prescriptions exploit further that such a determinant can be expressed as a path integral over auxiliary bosonic fields.In general the gauge invariant fermionic part of the Euclidean action can be expressed as a bilinear in terms of Grassmann valued quark fields. Since explicit matrix representations of Grassmann numbers in terms of complex numbers are numerically too costly, one instead carries out the Gaussian integral a priori and ends up with a fermion determinant. Most efficient simulation prescriptions exploit further that such a determinant can be expressed as a path integral over auxiliary bosonic fields.</p>
        <p>The so called pseudofermion field φ can be straight forwardly accommodated in numerical simulations. Note that while the matrix K usually has a sparse banded structure its inverse is generally dense. The treatment of light fermionic d.o.f. on the lattice, i.e. quarks of the thermal QCD medium, is complicated by the so called doubler problem. The deformed dispersion relation from the discretized Dirac equation leads to artificially light modes within the first Brillouin zone. This issue is intimately related to the question of how to implement a discretized form of chiral symmetry on the lattice. In this context the discretization of the light fermions also leads to an artificially large mass m π of the pion degrees of freedom. In order to keep the numerical cost of simulations under control the largest lattice QCD collaborations working at finite temperature have chosen the staggered quark discretization, e.g. the highly-improved staggered quarks (HISQ) [87] or the so called stout action [88]. As staggered quarks preserve a remnant of chiral symmetry one also has to deal with the issue of doublers. Other collaboration have opted for the more costly but formally advantageous Wilson fermions (see e.g. [89]) or the Wilson fermion derived twisted mass formulation [90].The so called pseudofermion field φ can be straight forwardly accommodated in numerical simulations. Note that while the matrix K usually has a sparse banded structure its inverse is generally dense. The treatment of light fermionic d.o.f. on the lattice, i.e. quarks of the thermal QCD medium, is complicated by the so called doubler problem. The deformed dispersion relation from the discretized Dirac equation leads to artificially light modes within the first Brillouin zone. This issue is intimately related to the question of how to implement a discretized form of chiral symmetry on the lattice. In this context the discretization of the light fermions also leads to an artificially large mass m π of the pion degrees of freedom. In order to keep the numerical cost of simulations under control the largest lattice QCD collaborations working at finite temperature have chosen the staggered quark discretization, e.g. the highly-improved staggered quarks (HISQ) [87] or the so called stout action [88]. As staggered quarks preserve a remnant of chiral symmetry one also has to deal with the issue of doublers. Other collaboration have opted for the more costly but formally advantageous Wilson fermions (see e.g. [89]) or the Wilson fermion derived twisted mass formulation [90].</p>
        <p>For the treatment of the heavy quark degrees of freedom chiral symmetry does not play an equally important role. Instead it is the fact that since discretization artifacts in the most naive formulation scale with m Q a that a very fine lattice spacing is required. Improved actions that allow for a more advantageous scaling are therefore often deployed [91]. Based on the staggered formulation, the O(a 2 ) Szymanzik improved HISQ fermions have been introduced in Ref. [87] with heavy quarks at T = 0 in mind. In finite temperature studies a popular relativistic action for quarkonium is the clover improved Wilson action (also known as the Shekholeslami-Wohlert action and starting point for the Fermilab action [92]), which for anisotropic lattices [93] readsFor the treatment of the heavy quark degrees of freedom chiral symmetry does not play an equally important role. Instead it is the fact that since discretization artifacts in the most naive formulation scale with m Q a that a very fine lattice spacing is required. Improved actions that allow for a more advantageous scaling are therefore often deployed [91]. Based on the staggered formulation, the O(a 2 ) Szymanzik improved HISQ fermions have been introduced in Ref. [87] with heavy quarks at T = 0 in mind. In finite temperature studies a popular relativistic action for quarkonium is the clover improved Wilson action (also known as the Shekholeslami-Wohlert action and starting point for the Fermilab action [92]), which for anisotropic lattices [93] reads</p>
        <p>where D Wilson denotes the original Wilson Dirac operator. The covariant lattice derivatives arewhere D Wilson denotes the original Wilson Dirac operator. The covariant lattice derivatives are</p>
        <p>writing concisely U -µ (n) ≡ U µ (n -μ) † . The additional contribution that implements the improvement is called the clover term which contains the field strength tensor, discretized by four plaquette termswriting concisely U -µ (n) ≡ U µ (n -μ) † . The additional contribution that implements the improvement is called the clover term which contains the field strength tensor, discretized by four plaquette terms</p>
        <p>By appropriate tuning of the parameters ν i and C SW the O(a) lattice artifacts can be made to vanish on the level of the classical action, in turn suppressing the discretization artifacts in the full quantum theory. An empirical but well established non-perturbative procedure to tuning the action parameters is so called tadpole improvement, in which the mean value of link variables is used to improve the convergence of the simulation results to the continuum limit.By appropriate tuning of the parameters ν i and C SW the O(a) lattice artifacts can be made to vanish on the level of the classical action, in turn suppressing the discretization artifacts in the full quantum theory. An empirical but well established non-perturbative procedure to tuning the action parameters is so called tadpole improvement, in which the mean value of link variables is used to improve the convergence of the simulation results to the continuum limit.</p>
        <p>In practice the path integral in Eq. ( 64) is approximated stochastically (see e.g. [94]). I.e. one designs a stochastic process in computer time t MC also called Monte Carlo time, which generates successive sets of 4-dimensional field configurations with a probability distribution according to the Euclidean Feynman weight. In order to obtain an ensemble of gauge configurations that accurately represents the quantum probability distribution, the space of configurations must be efficiently traversed. To this end hybrid Monte Carlo algorithms are currently deployed, where a stochastic update is combined with a classical evolution of Hamilton's equation of motion for gluon and pseudofermion fields. The necessity to solve a large dense system of linear equation at each computer time step constitutes the main numerical cost.In practice the path integral in Eq. ( 64) is approximated stochastically (see e.g. [94]). I.e. one designs a stochastic process in computer time t MC also called Monte Carlo time, which generates successive sets of 4-dimensional field configurations with a probability distribution according to the Euclidean Feynman weight. In order to obtain an ensemble of gauge configurations that accurately represents the quantum probability distribution, the space of configurations must be efficiently traversed. To this end hybrid Monte Carlo algorithms are currently deployed, where a stochastic update is combined with a classical evolution of Hamilton's equation of motion for gluon and pseudofermion fields. The necessity to solve a large dense system of linear equation at each computer time step constitutes the main numerical cost.</p>
        <p>To keep costs manageable, often it is only the light quarks u, d and s that are treated fully dynamically, with some collaborations starting to include c quarks. The dynamical fermion content is indicated in lattice simulations conventionally by a code such as N f = 2 + 1 indicating in that case two mass degenerate u and d quarks and a more massive s quark to be present. At low enough temperatures top and bottom quarks do not significantly contribute to virtual processes and their determinant can be approximated to be unity, they are said to be quenched.To keep costs manageable, often it is only the light quarks u, d and s that are treated fully dynamically, with some collaborations starting to include c quarks. The dynamical fermion content is indicated in lattice simulations conventionally by a code such as N f = 2 + 1 indicating in that case two mass degenerate u and d quarks and a more massive s quark to be present. At low enough temperatures top and bottom quarks do not significantly contribute to virtual processes and their determinant can be approximated to be unity, they are said to be quenched.</p>
        <p>The quantum statistical expectation value of an observable ⟨O⟩, i.e. of a gauge invariant (composite) operator, is approximated by computing the value of O on each field realization within one ensemble. Since one can often use volume averaging in determining the value of O on each lattice configuration, the outcome constitutes a subaverage. If the variance of the these sub-averages O k , what the lattice community often calls a measurement, is finite, then thanks to the central limit theorem their distribution will become approximately Gaussian if enough configurations are available. In that case the mean is taken as simple estimator for the expectation valueThe quantum statistical expectation value of an observable ⟨O⟩, i.e. of a gauge invariant (composite) operator, is approximated by computing the value of O on each field realization within one ensemble. Since one can often use volume averaging in determining the value of O on each lattice configuration, the outcome constitutes a subaverage. If the variance of the these sub-averages O k , what the lattice community often calls a measurement, is finite, then thanks to the central limit theorem their distribution will become approximately Gaussian if enough configurations are available. In that case the mean is taken as simple estimator for the expectation value</p>
        <p>If there are no residual autocorrelations between the generated configurations the statistical error in the end result decreases with 1/If there are no residual autocorrelations between the generated configurations the statistical error in the end result decreases with 1/</p>
        <p>Note that at no step above a particular gauge had to be chosen in the process of simulating ⟨O⟩.Note that at no step above a particular gauge had to be chosen in the process of simulating ⟨O⟩.</p>
        <p>At this point some remarks are in order on how to judge the reliability of a lattice QCD computation result. The outcome of a simulation is an estimate of an imaginary time correlation function with a certain statistical uncertainty, which depending on the computation resources available can be made arbitrary small. At the same time the discretization related artifacts need to be kept in mind according to the following checklist inspired by the FLAG criteria [96]:At this point some remarks are in order on how to judge the reliability of a lattice QCD computation result. The outcome of a simulation is an estimate of an imaginary time correlation function with a certain statistical uncertainty, which depending on the computation resources available can be made arbitrary small. At the same time the discretization related artifacts need to be kept in mind according to the following checklist inspired by the FLAG criteria [96]:</p>
        <p>• For the temperature range considered, are all relevant quarks d.o.f. dynamically included?• For the temperature range considered, are all relevant quarks d.o.f. dynamically included?</p>
        <p>• Is the pion mass at the physical point m π = 140 MeV and related, is the crossover temperature at T c ≈ 156 MeV?• Is the pion mass at the physical point m π = 140 MeV and related, is the crossover temperature at T c ≈ 156 MeV?</p>
        <p>• Has the continuum limit a → 0 been taken? • Has the thermodynamic limit V → ∞ been taken?• Has the continuum limit a → 0 been taken? • Has the thermodynamic limit V → ∞ been taken?</p>
        <p>The first item in current simulations is usually satisfied. On the other hand the second to fourth item still require considerable resources, often preventing these conditions from being fulfilled. If e.g. the limits are not taken one has to make sure that the relevant energy scales are located reasonably far away from the corresponding IR and UV cutoffs. In essence this also tells us that only if all criteria are met, two lattice simulations can be expected to agree within their statistical uncertainties.The first item in current simulations is usually satisfied. On the other hand the second to fourth item still require considerable resources, often preventing these conditions from being fulfilled. If e.g. the limits are not taken one has to make sure that the relevant energy scales are located reasonably far away from the corresponding IR and UV cutoffs. In essence this also tells us that only if all criteria are met, two lattice simulations can be expected to agree within their statistical uncertainties.</p>
        <p>As discussed in Section 2.1 we wish to compute quarkonium current correlators according to fixed quantum numbers. Inspecting their spectral functions allows us to identify possible bound states and their in-medium properties. The evaluation of these correlators requires additional care on the lattice. One reason is that the introduction of the hypercubic grid breaks the rotational symmetry of the continuum theory and reduces it to the octahedral symmetry group O h [97]. Instead of the good quantum number spin J PC labeling one of the infinite numbers of irreducible representations of rotations, we have to deal with Λ PC which refers to a finite number of lattice irreducible representations of O h . For integer spin there exist exactly five irreducible representations A 1 , T 1 , T 2 , E, A 2 . The identification of particles with physical J &gt; 1, such as e.g. χ 2 , which appear as admixtures in different channels set by Λ PC requires particular care as described e.g. in Ref. [98].As discussed in Section 2.1 we wish to compute quarkonium current correlators according to fixed quantum numbers. Inspecting their spectral functions allows us to identify possible bound states and their in-medium properties. The evaluation of these correlators requires additional care on the lattice. One reason is that the introduction of the hypercubic grid breaks the rotational symmetry of the continuum theory and reduces it to the octahedral symmetry group O h [97]. Instead of the good quantum number spin J PC labeling one of the infinite numbers of irreducible representations of rotations, we have to deal with Λ PC which refers to a finite number of lattice irreducible representations of O h . For integer spin there exist exactly five irreducible representations A 1 , T 1 , T 2 , E, A 2 . The identification of particles with physical J &gt; 1, such as e.g. χ 2 , which appear as admixtures in different channels set by Λ PC requires particular care as described e.g. in Ref. [98].</p>
        <p>To evaluate a quarkonium current correlator on the lattice we have to consider the lattice counterpart of the continuum expressionTo evaluate a quarkonium current correlator on the lattice we have to consider the lattice counterpart of the continuum expression</p>
        <p>The renormalization factor Z Γ can be computed in lattice perturbation theory [99], where µ denotes the scale at which the strong coupling is evaluated in such a computation.The renormalization factor Z Γ can be computed in lattice perturbation theory [99], where µ denotes the scale at which the strong coupling is evaluated in such a computation.</p>
        <p>The Euclidean correlator for a general meson operator is obtained after one carries out the heavy quark Graßmann integralsThe Euclidean correlator for a general meson operator is obtained after one carries out the heavy quark Graßmann integrals</p>
        <p>-Tr [-Tr [</p>
        <p>Fig. 5. The non-interacting spectral function on isotropic lattices, normalized to the continuum asymptotic behavior in the pseudoscalar channel for finite mass m/T = 4.8. Note both the approach to the continuum limit for increasing resolution with N τ as well as the presence of discretization artifacts at high momentum.Fig. 5. The non-interacting spectral function on isotropic lattices, normalized to the continuum asymptotic behavior in the pseudoscalar channel for finite mass m/T = 4.8. Note both the approach to the continuum limit for increasing resolution with N τ as well as the presence of discretization artifacts at high momentum.</p>
        <p>Source: Adapted from [43].Source: Adapted from [43].</p>
        <p>Since the mass of the heavy fermion suppresses its contributions to virtual processes we neglect det[K Q ] ≈ 1. The contributions with an overall trace on the outside are referred to as connected diagrams, the ones including two individual traces as disconnected ones. The latter are often neglected for heavy quarks since they are suppressed due to the OZI rule and as their contribution has been found to be small in practice (see e.g. [100]). The computation of the quark propagators K -1 constitutes a boundary value problem and involves solving the defining equationSince the mass of the heavy fermion suppresses its contributions to virtual processes we neglect det[K Q ] ≈ 1. The contributions with an overall trace on the outside are referred to as connected diagrams, the ones including two individual traces as disconnected ones. The latter are often neglected for heavy quarks since they are suppressed due to the OZI rule and as their contribution has been found to be small in practice (see e.g. [100]). The computation of the quark propagators K -1 constitutes a boundary value problem and involves solving the defining equation</p>
        <p>which corresponds to a large system of linear equations.which corresponds to a large system of linear equations.</p>
        <p>We can learn about some of the effects of the lattice discretization by considering the meson correlator in terms of Wilson fermions in the non-interacting limit. In that case explicit expressions for the Euclidean correlator and the spectral function have been computed in Refs. [43,44]. The differences to the continuum theory are cleanly illustrated for the p = 0 correlator in Fig. 5.We can learn about some of the effects of the lattice discretization by considering the meson correlator in terms of Wilson fermions in the non-interacting limit. In that case explicit expressions for the Euclidean correlator and the spectral function have been computed in Refs. [43,44]. The differences to the continuum theory are cleanly illustrated for the p = 0 correlator in Fig. 5.</p>
        <p>For small frequencies the free lattice spectral function lies close to the functional form of its continuum counterpart.For small frequencies the free lattice spectral function lies close to the functional form of its continuum counterpart.</p>
        <p>On the other hand the UV part is severely distorted and the spectral function vanishes above a finite frequency ω max .On the other hand the UV part is severely distorted and the spectral function vanishes above a finite frequency ω max .</p>
        <p>On isotropic lattices it is given by ω iso max a = 2 ln 7, corresponding to the largest energy available to a meson with lattice momentum p = (π /a, π/a, π/a). Whenever the lattice momentum reaches a corner of the Brillouin zone, i.e. at p = (π /a, 0, 0) and p = (π /a, π/a, 0), corresponding to ω 1 a = 2 ln 3 and ω 2 a = 2 ln 5 kinks appear in the spectral function, the lowest one often exhibiting an amplitude above the continuum result.On isotropic lattices it is given by ω iso max a = 2 ln 7, corresponding to the largest energy available to a meson with lattice momentum p = (π /a, π/a, π/a). Whenever the lattice momentum reaches a corner of the Brillouin zone, i.e. at p = (π /a, 0, 0) and p = (π /a, π/a, 0), corresponding to ω 1 a = 2 ln 3 and ω 2 a = 2 ln 5 kinks appear in the spectral function, the lowest one often exhibiting an amplitude above the continuum result.</p>
        <p>It is useful at this point to consider briefly the analysis of interacting quarkonium correlation functions in T = 0 lattice QCD and discuss differences to the T &gt; 0 case. Summing over all spatial lattice points of ⟨ MΓ (n, τ ) M † Γ (0, 0)⟩, the p = 0 correlator is obtained. Since for quarkonium the vacuum ground states are expected to be well separated from excited states and the underlying spectral function is simply a sum of delta peaks, the correlator will exhibit a well pronounced single exponential falloff close to τ = β/2 (for periodic boundary condition the correlator is still symmetric). The exponent is simply the rest mass of the heavy quarkonium particle. It is either determined via an exponential fit to the τ &lt; β/2 correlator or by considering the so called effective massIt is useful at this point to consider briefly the analysis of interacting quarkonium correlation functions in T = 0 lattice QCD and discuss differences to the T &gt; 0 case. Summing over all spatial lattice points of ⟨ MΓ (n, τ ) M † Γ (0, 0)⟩, the p = 0 correlator is obtained. Since for quarkonium the vacuum ground states are expected to be well separated from excited states and the underlying spectral function is simply a sum of delta peaks, the correlator will exhibit a well pronounced single exponential falloff close to τ = β/2 (for periodic boundary condition the correlator is still symmetric). The exponent is simply the rest mass of the heavy quarkonium particle. It is either determined via an exponential fit to the τ &lt; β/2 correlator or by considering the so called effective mass</p>
        <p>which will approach a plateau with the value of the ground state rest mass M 0 at large enough τ . For positive definite spectra m eff will be convex and monotonous. Using correlators at different momenta m eff (τ → ∞) traces out the dispersion relation E(p). At T &gt; 0 the peak structures are not as well separated and the resulting correlator will not exhibit clear exponential falloffs. This induces curvature in the effective mass and a similarly straight forward interpretation in terms of spectral features is unavailable.which will approach a plateau with the value of the ground state rest mass M 0 at large enough τ . For positive definite spectra m eff will be convex and monotonous. Using correlators at different momenta m eff (τ → ∞) traces out the dispersion relation E(p). At T &gt; 0 the peak structures are not as well separated and the resulting correlator will not exhibit clear exponential falloffs. This induces curvature in the effective mass and a similarly straight forward interpretation in terms of spectral features is unavailable.</p>
        <p>Already at T = 0 spectral contributions from excited states induce curvature in m eff (τ ) at early τ 's. The stronger the effect, the later m eff (τ ) reaches a plateau. Since the signal to noise ratio decreases with τ this complicates the determination of M 0 . At T = 0 we are only interested in the mass and the ground state is a single delta function.Already at T = 0 spectral contributions from excited states induce curvature in m eff (τ ) at early τ 's. The stronger the effect, the later m eff (τ ) reaches a plateau. Since the signal to noise ratio decreases with τ this complicates the determination of M 0 . At T = 0 we are only interested in the mass and the ground state is a single delta function.</p>
        <p>Thus we may improve the signal to noise by increasing the amplitude of that peak structure. This requires modifying the overlap, i.e. the magnitude of the ground state matrix element of the meson operator in the spectral decomposition. There are many different strategies to do so on the market, among them so called smearing. It either refers to replacing the delta function on the r.h.s of Eq. ( 81) by an extended object and/or a smoothing prescription of the gauge fields in spatial direction. In the latter the UV modes of the gauge fields are successively damped away. In turn the excited state and continuum contributions to the spectral function diminish and the ground state peak is relatively more pronounced.Thus we may improve the signal to noise by increasing the amplitude of that peak structure. This requires modifying the overlap, i.e. the magnitude of the ground state matrix element of the meson operator in the spectral decomposition. There are many different strategies to do so on the market, among them so called smearing. It either refers to replacing the delta function on the r.h.s of Eq. ( 81) by an extended object and/or a smoothing prescription of the gauge fields in spatial direction. In the latter the UV modes of the gauge fields are successively damped away. In turn the excited state and continuum contributions to the spectral function diminish and the ground state peak is relatively more pronounced.</p>
        <p>Since a bound state at T = 0 is represented by a single delta peak, this procedure often achieves its goal. However at finite temperature where clusters of peaks populate the spectral function and their envelope encodes vital properties, such as thermal widths, the application of smearing requires additional care. It is not a priori clear how the amplitude of individual peaks is affected by smearing and in turn the envelope may be distorted, leading to uncontrolled changes in its position and width. To avoid these additional systematic uncertainties smearing is largely avoided in studies of spectral structures at T &gt; 0.Since a bound state at T = 0 is represented by a single delta peak, this procedure often achieves its goal. However at finite temperature where clusters of peaks populate the spectral function and their envelope encodes vital properties, such as thermal widths, the application of smearing requires additional care. It is not a priori clear how the amplitude of individual peaks is affected by smearing and in turn the envelope may be distorted, leading to uncontrolled changes in its position and width. To avoid these additional systematic uncertainties smearing is largely avoided in studies of spectral structures at T &gt; 0.</p>
        <p>The last item we have not touched so far is the subject of how to select the bare values of the parameters in the lattice action (strong coupling, quark masses, anisotropies). The quantum fluctuations present in the discretized path integral lead to a renormalization of the bare parameters and the values of the physical parameters need to be determined by comparison with a physical measurement a posteriori. One important part is the setting of the absolute energy scale in a lattice simulation [101], most often quoted as a lattice spacing in units of fm. Since a lattice QCD simulation is formulated in dimensionless fields, indeed external input is needed to assign such a physical scale.The last item we have not touched so far is the subject of how to select the bare values of the parameters in the lattice action (strong coupling, quark masses, anisotropies). The quantum fluctuations present in the discretized path integral lead to a renormalization of the bare parameters and the values of the physical parameters need to be determined by comparison with a physical measurement a posteriori. One important part is the setting of the absolute energy scale in a lattice simulation [101], most often quoted as a lattice spacing in units of fm. Since a lattice QCD simulation is formulated in dimensionless fields, indeed external input is needed to assign such a physical scale.</p>
        <p>The most direct approach would be to measure the mass of a stable Baryon but this often is prohibitively expensive, numerically. Instead until recently it has been customary to use the so called Sommer scales r 0 and r 1 to set the scale. These quantities are derived from a phenomenological Cornell type model of heavy quarkonium, fixing in essence the slope of the string like part of the potential extracted from a T = 0 lattice simulations to a model dependent physical value. While easy to implement, the disadvantage of this approach is that it prevents an independent determination of the heavy quark potential on the same lattice. More recently a different high precision scale setting approach [102] has been developed based on the Gradient flow technique [103]. It provides a scale ω 0 derived from smoothed correlators of the field strength tensor, which, if once determined to high precision on a lattice using e.g. a Baryon mass, can function as straight forwardly evaluable standard in other lattice simulations.The most direct approach would be to measure the mass of a stable Baryon but this often is prohibitively expensive, numerically. Instead until recently it has been customary to use the so called Sommer scales r 0 and r 1 to set the scale. These quantities are derived from a phenomenological Cornell type model of heavy quarkonium, fixing in essence the slope of the string like part of the potential extracted from a T = 0 lattice simulations to a model dependent physical value. While easy to implement, the disadvantage of this approach is that it prevents an independent determination of the heavy quark potential on the same lattice. More recently a different high precision scale setting approach [102] has been developed based on the Gradient flow technique [103]. It provides a scale ω 0 derived from smoothed correlators of the field strength tensor, which, if once determined to high precision on a lattice using e.g. a Baryon mass, can function as straight forwardly evaluable standard in other lattice simulations.</p>
        <p>In a simulation without dynamical quarks only the strong coupling β needs to be adjusted to select a particular lattice spacing. In dynamical simulations also the light quark parameters have to be tuned. This requires as additional inputs e.g. the pion decay constant [104] and the physical mass ratio between s and u/d quarks. Instead of trying to reproduce the pion mass, one enforces that the so called partially conserved axial current (PCAC) mass vanishes. At that point the residual Ward identity for the remnant chiral symmetry on the lattice is fulfilled. In turn the pion mass emerges as a dynamical property of the simulation and not as external input.In a simulation without dynamical quarks only the strong coupling β needs to be adjusted to select a particular lattice spacing. In dynamical simulations also the light quark parameters have to be tuned. This requires as additional inputs e.g. the pion decay constant [104] and the physical mass ratio between s and u/d quarks. Instead of trying to reproduce the pion mass, one enforces that the so called partially conserved axial current (PCAC) mass vanishes. At that point the residual Ward identity for the remnant chiral symmetry on the lattice is fulfilled. In turn the pion mass emerges as a dynamical property of the simulation and not as external input.</p>
        <p>For the heavy quarks the mass and anisotropy parameters in the action can be tuned independently from those of the dynamical quarks and gluons. On the one hand, we have to make sure that the ground state mass M 0 of one chosen meson channel agrees with its PDG value and at the same time that the relativistic dispersion relation is fulfilledFor the heavy quarks the mass and anisotropy parameters in the action can be tuned independently from those of the dynamical quarks and gluons. On the one hand, we have to make sure that the ground state mass M 0 of one chosen meson channel agrees with its PDG value and at the same time that the relativistic dispersion relation is fulfilled</p>
        <p>i.e. the kinetic mass M 1 needs to equal the rest mass M 0 . Here the PDG quarkonium mass is the actual external input.i.e. the kinetic mass M 1 needs to equal the rest mass M 0 . Here the PDG quarkonium mass is the actual external input.</p>
        <p>The temperature in a simulation depends on the extent of the imaginary time axis. It can be varied either by changing the lattice coupling β, i.e. the physical lattice spacing (fixed box approach) or by changing the number of grid points (fixed scale approach). Since varying the coupling modifies the renormalization scale of the simulation, accompanying T = 0 simulations need to be carried out for scale setting and the subtraction of temperature independent UV divergent terms.The temperature in a simulation depends on the extent of the imaginary time axis. It can be varied either by changing the lattice coupling β, i.e. the physical lattice spacing (fixed box approach) or by changing the number of grid points (fixed scale approach). Since varying the coupling modifies the renormalization scale of the simulation, accompanying T = 0 simulations need to be carried out for scale setting and the subtraction of temperature independent UV divergent terms.</p>
        <p>The fixed scale approach requires just one T = 0 simulation but temperatures can only be varied in integer steps of N τ and the number of Euclidean time steps at which the correlator can be computed diminishes as one increases temperature.The fixed scale approach requires just one T = 0 simulation but temperatures can only be varied in integer steps of N τ and the number of Euclidean time steps at which the correlator can be computed diminishes as one increases temperature.</p>
        <p>The effective field theory NRQCD provides an alternative discretization prescription for heavy quarks on the lattice [51,105]. The NRQCD expansion on the lattice is formulated in terms of increasing powers of v ∼ p/(m Q a), in contrast to an expansion directly in (m Q a) -1 , as in the EFT called heavy quark effective theory [58,106]. Lattice NRQCD has been successfully used for precision spectroscopy at T = 0 (see e.g. [5]) and found application to in-medium quarkonium, as will be discussed in detail in later sections. Instead of populating the spacetime grid with both heavy and light degrees of freedom, which requires very fine lattice spacings, the quarks and gluons of the QCD medium will be treated separately in a simulation without heavy d.o.f. at a coarser spacing. The evolution of the heavy quarks is implemented in terms of Pauli spinors propagating in the background of the light quarks and gluons.The effective field theory NRQCD provides an alternative discretization prescription for heavy quarks on the lattice [51,105]. The NRQCD expansion on the lattice is formulated in terms of increasing powers of v ∼ p/(m Q a), in contrast to an expansion directly in (m Q a) -1 , as in the EFT called heavy quark effective theory [58,106]. Lattice NRQCD has been successfully used for precision spectroscopy at T = 0 (see e.g. [5]) and found application to in-medium quarkonium, as will be discussed in detail in later sections. Instead of populating the spacetime grid with both heavy and light degrees of freedom, which requires very fine lattice spacings, the quarks and gluons of the QCD medium will be treated separately in a simulation without heavy d.o.f. at a coarser spacing. The evolution of the heavy quarks is implemented in terms of Pauli spinors propagating in the background of the light quarks and gluons.</p>
        <p>On the one hand this strategy provides three clear practical advantages. First, the NRQCD correlator is not periodic in Euclidean time and thus in contrast to a relativistic formulation provides additional independent information at τ &gt; 1/2T . I.e. access to the ground state properties dominant at large τ is improved. Secondly, the absence of a transport peak contribution simplifies the extraction of spectra from Euclidean correlators. Third, the computational cost of the Euclidean heavy quark propagator is significantly reduced. Instead of having to solve a 4d boundary value problem as in Eq. ( 81), one instead faces an initial value problem in Euclidean time and evolves the propagator step by step. On the other hand there are some caveats that require additional care. The process of integrating out the hard scale by shifting the frequency origin on the lattice becomes lattice spacing dependent. I.e. while scale setting fixes the relative frequency scale, an additional comparison with experimental data is needed to fix its absolute scale. Due a steeper rise of the free spectral functions at intermediate frequencies in NRQCD compared to the relativistic computation, the contribution of the continuum may manifest itself more strongly also in the interacting correlator, thus requiring a high signal to noise ratio for e.g. the P-wave channels.On the one hand this strategy provides three clear practical advantages. First, the NRQCD correlator is not periodic in Euclidean time and thus in contrast to a relativistic formulation provides additional independent information at τ &gt; 1/2T . I.e. access to the ground state properties dominant at large τ is improved. Secondly, the absence of a transport peak contribution simplifies the extraction of spectra from Euclidean correlators. Third, the computational cost of the Euclidean heavy quark propagator is significantly reduced. Instead of having to solve a 4d boundary value problem as in Eq. ( 81), one instead faces an initial value problem in Euclidean time and evolves the propagator step by step. On the other hand there are some caveats that require additional care. The process of integrating out the hard scale by shifting the frequency origin on the lattice becomes lattice spacing dependent. I.e. while scale setting fixes the relative frequency scale, an additional comparison with experimental data is needed to fix its absolute scale. Due a steeper rise of the free spectral functions at intermediate frequencies in NRQCD compared to the relativistic computation, the contribution of the continuum may manifest itself more strongly also in the interacting correlator, thus requiring a high signal to noise ratio for e.g. the P-wave channels.</p>
        <p>A conceptually distinct aspect of a lattice EFT is that as a non-renormalizable theory no naive continuum limit exists.A conceptually distinct aspect of a lattice EFT is that as a non-renormalizable theory no naive continuum limit exists.</p>
        <p>Naively, as the continuum limit a → 0 is approached, more and more terms in the expansion need to be taken into account and for each a Wilson coefficient has to be determined. I.e. eventually predictability is lost. What allows EFTs to nevertheless be an important tool of precision physics is that we are usually interested in results only up to a finite accuracy. This can be achieved by working to a certain finite order n in the expansion v n . The set of Wilson coefficients for a given order and given lattice spacing need to be computed via lattice perturbation theory and eventually compared to experimentally measured quantities. Long term efforts to compute radiative corrections to Wilson coefficients, starting with Ref. [107], have led to the development of automated tools for lattice perturbation theory (see e.g. Ref. [108]), which are today able to provide a matching that reproduces the continuum dispersion relation with less than percent deviation as shown in Ref. [109].Naively, as the continuum limit a → 0 is approached, more and more terms in the expansion need to be taken into account and for each a Wilson coefficient has to be determined. I.e. eventually predictability is lost. What allows EFTs to nevertheless be an important tool of precision physics is that we are usually interested in results only up to a finite accuracy. This can be achieved by working to a certain finite order n in the expansion v n . The set of Wilson coefficients for a given order and given lattice spacing need to be computed via lattice perturbation theory and eventually compared to experimentally measured quantities. Long term efforts to compute radiative corrections to Wilson coefficients, starting with Ref. [107], have led to the development of automated tools for lattice perturbation theory (see e.g. Ref. [108]), which are today able to provide a matching that reproduces the continuum dispersion relation with less than percent deviation as shown in Ref. [109].</p>
        <p>Following [105] the lattice Hamiltonian that governs the heavy quark fields to O(v 6 ) is given byFollowing [105] the lattice Hamiltonian that governs the heavy quark fields to O(v 6 ) is given by</p>
        <p>+ H (6) , H 0 = -+ H (6) , H 0 = -</p>
        <p>with the naive kinetic term given by H 0 being of order O(v 2 ) andwith the naive kinetic term given by H 0 being of order O(v 2 ) and</p>
        <p>The contributions to O(v 4 ) readThe contributions to O(v 4 ) read</p>
        <p>Some studies include the effects of spin dependent corrections up to order O(v 6 )Some studies include the effects of spin dependent corrections up to order O(v 6 )</p>
        <p>δH (6) = -c 7 gδH (6) = -c 7 g</p>
        <p>which play an important role in the precision study of the hyperfine splitting of quarkonium states at T = 0. To define the color E and B fields the clover discretized field strength tensor is usedwhich play an important role in the precision study of the hyperfine splitting of quarkonium states at T = 0. To define the color E and B fields the clover discretized field strength tensor is used</p>
        <p>Tr(ImU µν (n))Tr(ImU µν (n))</p>
        <p>))</p>
        <p>In the above definition of the Hamiltonian several corrections terms have already been included that remove O ( a 2 v 4 ) discretization errors. This has been achieved by using a higher order implementation of the field strength tensor in the c 3 and c 4 termsIn the above definition of the Hamiltonian several corrections terms have already been included that remove O ( a 2 v 4 ) discretization errors. This has been achieved by using a higher order implementation of the field strength tensor in the c 3 and c 4 terms</p>
        <p>as well as a higher order derivative in cas well as a higher order derivative in c</p>
        <p>) .) .</p>
        <p>((</p>
        <p>Additional discretization corrections are included as the last two terms in δH (4) , whereAdditional discretization corrections are included as the last two terms in δH (4) , where</p>
        <p>. In order to improve agreement with the continuum theory, tadpole improvement is often implemented on the level of the Hamiltonian. In this empirical approach to matching, laid out in detail in Ref. [110], all links entering the Hamiltonian are divided by the fourth root of the single plaquette u 0 = ⟨ 1 3 TrU µν ⟩ 1 4 and at the same time the Wilson coefficients c i are set to unity.. In order to improve agreement with the continuum theory, tadpole improvement is often implemented on the level of the Hamiltonian. In this empirical approach to matching, laid out in detail in Ref. [110], all links entering the Hamiltonian are divided by the fourth root of the single plaquette u 0 = ⟨ 1 3 TrU µν ⟩ 1 4 and at the same time the Wilson coefficients c i are set to unity.</p>
        <p>Since to this order in NRQCD the propagation of quark and antiquark fields is decoupled G ψ is computed by solving an initial value problem. It is common to deploy the naive Euler scheme for its discretization which in Euclidean time leads toSince to this order in NRQCD the propagation of quark and antiquark fields is decoupled G ψ is computed by solving an initial value problem. It is common to deploy the naive Euler scheme for its discretization which in Euclidean time leads to</p>
        <p>As the simple forward discretization does not possess favorable stability properties it is customary to stabilize it by artificially reducing the temporal step size via the so called Lepage parameter n. It was shown [111] that on isotropic lattices (ξ = 1) a value of n = 1 leads to a well defined UV behavior of the evolution ifAs the simple forward discretization does not possess favorable stability properties it is customary to stabilize it by artificially reducing the temporal step size via the so called Lepage parameter n. It was shown [111] that on isotropic lattices (ξ = 1) a value of n = 1 leads to a well defined UV behavior of the evolution if</p>
        <p>There are efforts underway to implement higher order stable solvers for the evolution of G based on e.g. the Crank-Nicholson scheme [112].There are efforts underway to implement higher order stable solvers for the evolution of G based on e.g. the Crank-Nicholson scheme [112].</p>
        <p>The initial source can be a point source S = δ x,0 , or for an improved signal to noise ratio a complex valued stochastic sourceThe initial source can be a point source S = δ x,0 , or for an improved signal to noise ratio a complex valued stochastic source</p>
        <p>diagonal in spin and color. Note that the explicit choice of the source determines the normalization of D E on the lattice and thus the normalization of the underlying spectral function.diagonal in spin and color. Note that the explicit choice of the source determines the normalization of D E on the lattice and thus the normalization of the underlying spectral function.</p>
        <p>The quarkonium correlation function is composed of heavy quark propagators and quantum numbers are chosen by NRQCD vertex operatorsThe quarkonium correlation function is composed of heavy quark propagators and quantum numbers are chosen by NRQCD vertex operators</p>
        <p>We have listed common vertex operators for S-wave and P-wave states in Table 2, where the following definition of the symmetric derivative has been used χ † ↔sWe have listed common vertex operators for S-wave and P-wave states in Table 2, where the following definition of the symmetric derivative has been used χ † ↔s</p>
        <p>((</p>
        <p>((</p>
        <p>. Note that Euclidean NRQCD is simpler than its Minkowski time counterpart in that only the propagator of one field needs to be computed to construct D E . The calibration of NRQCD simulations first requires selecting an appropriate mass parameter m Q a. The state-of-the art prescription [5] involves fixing the spin averaged kinetic mass M 2 (1S) = (M 2 (η b ) + 3M 2 (Υ ))/4 from the dispersion relation. Note that Euclidean NRQCD is simpler than its Minkowski time counterpart in that only the propagator of one field needs to be computed to construct D E . The calibration of NRQCD simulations first requires selecting an appropriate mass parameter m Q a. The state-of-the art prescription [5] involves fixing the spin averaged kinetic mass M 2 (1S) = (M 2 (η b ) + 3M 2 (Υ ))/4 from the dispersion relation</p>
        <p>The scale setting in the simulation of the light d.o.f. allows us to assign to the quantity ∆E(0) physical units. However, as indicated by writing ∆E(0) instead of E(0), the mass of the ground state in NRQCD does not coincide with the physical rest mass of the quarkonium state. Removing the 2m Q term in constructing NRQCD introduces a scale dependent energy shift, which needs to be accounted for by using one of the experimentally known quarkonium masses as additional input.The scale setting in the simulation of the light d.o.f. allows us to assign to the quantity ∆E(0) physical units. However, as indicated by writing ∆E(0) instead of E(0), the mass of the ground state in NRQCD does not coincide with the physical rest mass of the quarkonium state. Removing the 2m Q term in constructing NRQCD introduces a scale dependent energy shift, which needs to be accounted for by using one of the experimentally known quarkonium masses as additional input.</p>
        <p>As for the continuum theory let us also inspect the free spectral functions on the lattice. Using the non-interacting NRQCD Hamiltonian one obtains the following dispersion relationAs for the continuum theory let us also inspect the free spectral functions on the lattice. Using the non-interacting NRQCD Hamiltonian one obtains the following dispersion relation</p>
        <p>and the spectral functionsand the spectral functions</p>
        <p>can be evaluated numerically (see e.g. [113]). Note that the summation runs over all accessible lattice momenta p. As the spectral functions are composed out of a large number of infinitely thin delta peaks, binning is required for their numerical evaluation. ρ S,P are independent of temperature and are fully specified by the mass parameter M = a s m Q , the physical anisotropy ξ , the Lepage parameter n and the lattice volume. a s denotes the physical spatial lattice spacing. Often the free spectral function in the thermodynamic limit is quoted in the literature, examples of which we plot in the left panel of Fig. 6. The normalization of this spectral function differs from that naively computed on a lattice with unit links, due to differences in the choice of initial sources in the propagator evolution. Fig. 6. A selection of noninteracting NRQCD spectral functions in the thermodynamic limit, zoomed in region around the origin on the right. The smaller the lattice spacing, the better the continuum spectral function is reproduced at small frequencies but at the same time the lattice artifacts extent to higher and higher frequencies. Fig. 7. A selection of noninteracting NRQCD spectral functions at a realistic finite volume 48 3 , zoomed in region around the origin on the right. The binning resolution is chosen as ∆ω = 30 MeV to illustrate the individual delta peak character of ρ. Note the sparseness in the available peaks at small momenta, indicating that also in the interacting theory broad peak structures will be coarsely resolved.can be evaluated numerically (see e.g. [113]). Note that the summation runs over all accessible lattice momenta p. As the spectral functions are composed out of a large number of infinitely thin delta peaks, binning is required for their numerical evaluation. ρ S,P are independent of temperature and are fully specified by the mass parameter M = a s m Q , the physical anisotropy ξ , the Lepage parameter n and the lattice volume. a s denotes the physical spatial lattice spacing. Often the free spectral function in the thermodynamic limit is quoted in the literature, examples of which we plot in the left panel of Fig. 6. The normalization of this spectral function differs from that naively computed on a lattice with unit links, due to differences in the choice of initial sources in the propagator evolution. Fig. 6. A selection of noninteracting NRQCD spectral functions in the thermodynamic limit, zoomed in region around the origin on the right. The smaller the lattice spacing, the better the continuum spectral function is reproduced at small frequencies but at the same time the lattice artifacts extent to higher and higher frequencies. Fig. 7. A selection of noninteracting NRQCD spectral functions at a realistic finite volume 48 3 , zoomed in region around the origin on the right. The binning resolution is chosen as ∆ω = 30 MeV to illustrate the individual delta peak character of ρ. Note the sparseness in the available peaks at small momenta, indicating that also in the interacting theory broad peak structures will be coarsely resolved.</p>
        <p>We find that in contrast to the relativistic formulations the free spectral function does not have a UV cutoff that is fixed by the inverse lattice spacing. The smaller the lattice spacing, the stronger NRQCD approximation artifacts contribute at high frequencies. On the other hand the right panel shows that decreasing the lattice spacing allows lattice NRQCD to better reproduce the continuum spectral function at small frequencies. Due to the Euler discretization there exists a smallest value of M beyond which the time evolution becomes unstable and the spectrum is artificially populated up to infinity.We find that in contrast to the relativistic formulations the free spectral function does not have a UV cutoff that is fixed by the inverse lattice spacing. The smaller the lattice spacing, the stronger NRQCD approximation artifacts contribute at high frequencies. On the other hand the right panel shows that decreasing the lattice spacing allows lattice NRQCD to better reproduce the continuum spectral function at small frequencies. Due to the Euler discretization there exists a smallest value of M beyond which the time evolution becomes unstable and the spectrum is artificially populated up to infinity.</p>
        <p>The effects of finite volume are displayed in Fig. 7 for a realistic scenario on a 48 3 grid using a binning resolution of ∆ω = 30 MeV. This visualization clearly reflects the peaked character of the spectral function. In particular the zoom-in on the right emphasizes that the sparsity of available peaks at small momenta needs to be kept in mind when attempting to interpret how coarsely the broad peak structures of the thermodynamic limit are approximated in a finite box simulation. This closes our discussion of the lattice NRQCD approach.The effects of finite volume are displayed in Fig. 7 for a realistic scenario on a 48 3 grid using a binning resolution of ∆ω = 30 MeV. This visualization clearly reflects the peaked character of the spectral function. In particular the zoom-in on the right emphasizes that the sparsity of available peaks at small momenta needs to be kept in mind when attempting to interpret how coarsely the broad peak structures of the thermodynamic limit are approximated in a finite box simulation. This closes our discussion of the lattice NRQCD approach.</p>
        <p>Summary. Monte-Carlo simulations of QCD on a hypercubic lattice with an imaginary time direction offer nonperturbative access to Euclidean meson correlation functions in QCD. There exist different discretization prescription for heavy quarkonium correlators either based on relativistic or non-relativistic formalisms. While the former offer direct access to the continuum limit they are numerically costly and due to the KMS relation provide only N τ /2 independent correlator points along τ from which to extract spectral information. On the other hand the NRQCD prescription offer reduced numerical cost and N τ independent correlator points. To connect to continuum QCD is more involved as it requires precision matching of the different Wilson coefficients of the EFT. In general when comparing results from different lattice computations it is important to establish, whether the continuum and thermodynamic limits have been reached, as otherwise differences in the results may reflect differences in discretization and not differences in the physics.Summary. Monte-Carlo simulations of QCD on a hypercubic lattice with an imaginary time direction offer nonperturbative access to Euclidean meson correlation functions in QCD. There exist different discretization prescription for heavy quarkonium correlators either based on relativistic or non-relativistic formalisms. While the former offer direct access to the continuum limit they are numerically costly and due to the KMS relation provide only N τ /2 independent correlator points along τ from which to extract spectral information. On the other hand the NRQCD prescription offer reduced numerical cost and N τ independent correlator points. To connect to continuum QCD is more involved as it requires precision matching of the different Wilson coefficients of the EFT. In general when comparing results from different lattice computations it is important to establish, whether the continuum and thermodynamic limits have been reached, as otherwise differences in the results may reflect differences in discretization and not differences in the physics.</p>
        <p>In the previous section we have seen how lattice QCD simulations provide non-perturbative access to correlation functions in Euclidean time D E (τ ). In this section we will explore how to access the physical information encoded in these quantities by extracting the underlying spectral function.In the previous section we have seen how lattice QCD simulations provide non-perturbative access to correlation functions in Euclidean time D E (τ ). In this section we will explore how to access the physical information encoded in these quantities by extracting the underlying spectral function.</p>
        <p>In a zero temperature lattice simulation the low lying structures of the spectral function, as a sum of well separated delta function peaks, are relatively simple. In turn it is possible to extract the position and amplitude of such peaks straight forwardly by exponential fits to the Euclidean correlator. I.e. we use domain knowledge of QCD, which strongly restricts the possible structures present in the spectrum to reduce the difficulty in determining the relevant spectral properties.In a zero temperature lattice simulation the low lying structures of the spectral function, as a sum of well separated delta function peaks, are relatively simple. In turn it is possible to extract the position and amplitude of such peaks straight forwardly by exponential fits to the Euclidean correlator. I.e. we use domain knowledge of QCD, which strongly restricts the possible structures present in the spectrum to reduce the difficulty in determining the relevant spectral properties.</p>
        <p>At finite temperature the presence of light degrees of freedom in the heat bath makes it possible for the delta peaks in the spectral function to cluster. This leads to structures, which in the infinite volume limit, approach a continuous broad peak with a finite width. While still required to be positive definite, their actual functional form may be quite involved.At finite temperature the presence of light degrees of freedom in the heat bath makes it possible for the delta peaks in the spectral function to cluster. This leads to structures, which in the infinite volume limit, approach a continuous broad peak with a finite width. While still required to be positive definite, their actual functional form may be quite involved.</p>
        <p>At T = 0, peak position and height are the only relevant spectral peak properties. At T &gt; 0 we have to distinguish between central position, width, enclosed spectral area and possibly skewness. QCD domain knowledge in general does not allow us to reduce the determination of these properties to a similarly simple fit ansatz as the exponentials in vacuum. Thus we require more flexible schemes to extract the spectral features from in-medium Euclidean correlators. This however leads us towards an inherently ill-posed inverse problem, which needs to be solved.At T = 0, peak position and height are the only relevant spectral peak properties. At T &gt; 0 we have to distinguish between central position, width, enclosed spectral area and possibly skewness. QCD domain knowledge in general does not allow us to reduce the determination of these properties to a similarly simple fit ansatz as the exponentials in vacuum. Thus we require more flexible schemes to extract the spectral features from in-medium Euclidean correlators. This however leads us towards an inherently ill-posed inverse problem, which needs to be solved.</p>
        <p>Indeed, the difficulty is directly visible if the general linear relation between correlator and spectral function found in QCD (Eq. ( 31), Eq. ( 34) and Eq. ( 45)) is written in its discretized formIndeed, the difficulty is directly visible if the general linear relation between correlator and spectral function found in QCD (Eq. ( 31), Eq. ( 34) and Eq. ( 45)) is written in its discretized form</p>
        <p>A lattice QCD simulation provides at most N τ discrete averaged values for the correlator D(τ j ) = D j along a compact imaginary times axis τ j = a τ • j. As the result of the stochastic Monte-Carlo based simulation algorithm, each D j carries a finite statistical error ∆D j . On the other hand in anticipation of the intricate features present in the spectral function the function ρ(ω) is discretized along N ω frequency bins ∆ω with N ω ≫ N τ . To discretize divergent kernels, such as cosh/sinh at T &gt; 0, one can e.g. go over to consider instead ρ ′ = ρ/ω and K ′ = K ω, both of which in turn are well behaved [114].A lattice QCD simulation provides at most N τ discrete averaged values for the correlator D(τ j ) = D j along a compact imaginary times axis τ j = a τ • j. As the result of the stochastic Monte-Carlo based simulation algorithm, each D j carries a finite statistical error ∆D j . On the other hand in anticipation of the intricate features present in the spectral function the function ρ(ω) is discretized along N ω frequency bins ∆ω with N ω ≫ N τ . To discretize divergent kernels, such as cosh/sinh at T &gt; 0, one can e.g. go over to consider instead ρ ′ = ρ/ω and K ′ = K ω, both of which in turn are well behaved [114].</p>
        <p>The confluence of two issues make the inversion of the above relation ill-posed. On the one hand the number of available correlator input points D i in today's simulations lies between 10-200, while it is not uncommon that a frequency discretization with N ω ∼ O(1000) is required. I.e. there are more parameters to fix than input data points. Discretizing the kernel K ij over a finite range of Euclidean times and frequencies usually leads to a strong decay of the singular values of the corresponding matrix. In addition, in QCD already the form of the continuum kernel contains an exponential decay, leading also to an intrinsic decay of the singular values. This makes the inversion task ill-conditioned. On the other hand the finite uncertainty in the input data means that many different combinations of the parameters ρ l are able to reproduce the input data within one standard deviation. Therefore at first sight an infinite number of degenerate solutions exist for the inverse problem, making it genuinely ill-posed. I.e. a naive χ 2 fit of the ρ l 's is meaningless.The confluence of two issues make the inversion of the above relation ill-posed. On the one hand the number of available correlator input points D i in today's simulations lies between 10-200, while it is not uncommon that a frequency discretization with N ω ∼ O(1000) is required. I.e. there are more parameters to fix than input data points. Discretizing the kernel K ij over a finite range of Euclidean times and frequencies usually leads to a strong decay of the singular values of the corresponding matrix. In addition, in QCD already the form of the continuum kernel contains an exponential decay, leading also to an intrinsic decay of the singular values. This makes the inversion task ill-conditioned. On the other hand the finite uncertainty in the input data means that many different combinations of the parameters ρ l are able to reproduce the input data within one standard deviation. Therefore at first sight an infinite number of degenerate solutions exist for the inverse problem, making it genuinely ill-posed. I.e. a naive χ 2 fit of the ρ l 's is meaningless.</p>
        <p>In order to give meaning to this inverse problem, i.e. to select a unique answer, requires to incorporate additional domain knowledge, often called prior information. This prior information may be provided by QCD, at least it should be motivated by general physical arguments. This also means that the answer will in part be determined by the simulation input and in part by the prior information. It is therefore paramount to quantify, how robust the extracted spectral information is with respect to uncertainty both in the data and the choice of prior information that has been included.In order to give meaning to this inverse problem, i.e. to select a unique answer, requires to incorporate additional domain knowledge, often called prior information. This prior information may be provided by QCD, at least it should be motivated by general physical arguments. This also means that the answer will in part be determined by the simulation input and in part by the prior information. It is therefore paramount to quantify, how robust the extracted spectral information is with respect to uncertainty both in the data and the choice of prior information that has been included.</p>
        <p>In the following we will discuss in detail two different approaches, which have found application to the extraction of spectral properties in the quarkonium community.In the following we will discuss in detail two different approaches, which have found application to the extraction of spectral properties in the quarkonium community.</p>
        <p>The Bayesian approach to spectral function extraction utilizes methods of Bayesian inference to regularize the ill-posed nature of the task at hand. This is achieved by providing a systematic prescription on how to incorporate prior information, i.e. domain knowledge, into the inversion task. By formulating statements of confidence in the language of probabilities, Bayesian statistics provides a versatile language to formulate and solve the ill-posed problem (see e.g. Ref. [115]). For an excellent introduction to Bayesian statistics see e.g. Refs. [116,117], for statistical inference see e.g. Refs. [118,119]. We will discuss below both the general ingredients to the Bayesian approach, as well as the particular strengths and weaknesses of three implementations that have found application in the literature on in-medium quarkonium. Particular attention will be placed on an understanding of reconstruction artifacts, which is mandatory for Bayesian methods to fulfill their potential as quantitative precision tools for the investigation of spectral functions.The Bayesian approach to spectral function extraction utilizes methods of Bayesian inference to regularize the ill-posed nature of the task at hand. This is achieved by providing a systematic prescription on how to incorporate prior information, i.e. domain knowledge, into the inversion task. By formulating statements of confidence in the language of probabilities, Bayesian statistics provides a versatile language to formulate and solve the ill-posed problem (see e.g. Ref. [115]). For an excellent introduction to Bayesian statistics see e.g. Refs. [116,117], for statistical inference see e.g. Refs. [118,119]. We will discuss below both the general ingredients to the Bayesian approach, as well as the particular strengths and weaknesses of three implementations that have found application in the literature on in-medium quarkonium. Particular attention will be placed on an understanding of reconstruction artifacts, which is mandatory for Bayesian methods to fulfill their potential as quantitative precision tools for the investigation of spectral functions.</p>
        <p>The central quantity of Bayesian statistics relevant for spectral reconstruction is the posterior probability P[ρ|D, I], .The central quantity of Bayesian statistics relevant for spectral reconstruction is the posterior probability P[ρ|D, I], .</p>
        <p>The Bayesian strategy answers the inversion problem by interrogating the posterior for which function ρ is most probable, given simulation data and domain knowledge. The first term on the right P[D|ρ, I] is called the likelihood probability and encodes all information about how the simulation data has been obtained. This distribution describes how the values of the individual (often sub-averaged) D j 's vary among the different lattice configurations. Thanks to the central limit theorem, one often finds that a Gaussian distribution emerges. In that case P[D|ρ, I], the probability for the data given a known value of the mean and variance, can be written asThe Bayesian strategy answers the inversion problem by interrogating the posterior for which function ρ is most probable, given simulation data and domain knowledge. The first term on the right P[D|ρ, I] is called the likelihood probability and encodes all information about how the simulation data has been obtained. This distribution describes how the values of the individual (often sub-averaged) D j 's vary among the different lattice configurations. Thanks to the central limit theorem, one often finds that a Gaussian distribution emerges. In that case P[D|ρ, I], the probability for the data given a known value of the mean and variance, can be written as</p>
        <p>Here D ρ j denotes the correlator values obtained from inserting the test function ρ into Eq. ( 98) and the indices i and j refer to the imaginary times that are included in the reconstruction τ min /a ≤ i, j ≤ τ max /a, the total number of supplied input points is denoted by N data . C , the covariance matrix of the data average with respect to the true value, in the absence of autocorrelations among lattice configurations readsHere D ρ j denotes the correlator values obtained from inserting the test function ρ into Eq. ( 98) and the indices i and j refer to the imaginary times that are included in the reconstruction τ min /a ≤ i, j ≤ τ max /a, the total number of supplied input points is denoted by N data . C , the covariance matrix of the data average with respect to the true value, in the absence of autocorrelations among lattice configurations reads</p>
        <p>where D m k refers to the mth realization of the kth correlator point andwhere D m k refers to the mth realization of the kth correlator point and</p>
        <p>k /N conf their average. Note that in case of finite autocorrelations in Monte-Carlo time, C needs to be multiplied with the product of autocorrelation times for D j and D k .k /N conf their average. Note that in case of finite autocorrelations in Monte-Carlo time, C needs to be multiplied with the product of autocorrelation times for D j and D k .</p>
        <p>Besides possible autocorrelations in Monte-Carlo time, there exist correlations between the D j 's at different imaginary times. These correlations manifest themselves as off-diagonal entries in C. One has to keep in mind that in order for these off-diagonal elements to be robustly estimated, one requires significantly more realizations N conf ≫ N data than the number of points along imaginary time considered. Is the number of realizations smaller than N data , then C -1 even becomes singular due to exactly vanishing eigenvalues.Besides possible autocorrelations in Monte-Carlo time, there exist correlations between the D j 's at different imaginary times. These correlations manifest themselves as off-diagonal entries in C. One has to keep in mind that in order for these off-diagonal elements to be robustly estimated, one requires significantly more realizations N conf ≫ N data than the number of points along imaginary time considered. Is the number of realizations smaller than N data , then C -1 even becomes singular due to exactly vanishing eigenvalues.</p>
        <p>In order to accelerate the evaluation of the likelihood probability, one transforms the data and the kernel into a basis, in which the correlation matrix is diagonalIn order to accelerate the evaluation of the likelihood probability, one transforms the data and the kernel into a basis, in which the correlation matrix is diagonal</p>
        <p>. This reduced the likelihood to. This reduced the likelihood to</p>
        <p>and correspondingly the kernel K in Eq. ( 98) is replaced by K . Note that in case of correlators with highly constrained values, such as the trace of the Wilson loop, the Gaussian distribution may not be an adequate description of the likelihood and the histogram of the input data needs to be consulted. There exists prior information already about the data generation process that has been used in the literature to modify the likelihood. E.g. some studies use the fact that if Euclidean data from a known spectral function is sampled along N τ points with Gaussian noise, then on average the likelihood, evaluated for the true underlying spectral function will take on the value L = N τ .and correspondingly the kernel K in Eq. ( 98) is replaced by K . Note that in case of correlators with highly constrained values, such as the trace of the Wilson loop, the Gaussian distribution may not be an adequate description of the likelihood and the histogram of the input data needs to be consulted. There exists prior information already about the data generation process that has been used in the literature to modify the likelihood. E.g. some studies use the fact that if Euclidean data from a known spectral function is sampled along N τ points with Gaussian noise, then on average the likelihood, evaluated for the true underlying spectral function will take on the value L = N τ .</p>
        <p>The second and decisive term in Bayes theorem is the prior probabilityThe second and decisive term in Bayes theorem is the prior probability</p>
        <p>which encodes how compatible the test function ρ is to the available prior information. The choice of this distribution is the central ingredient in setting up a Bayesian analysis and differs among the multiple implementations found in the literature. Commonly the parameters of the prior are encoded in terms of the so called default model m(ω), which denotes the extremum δS/δρ| ρ=m = 0. For a convex prior functional this is the only extremum. The hyperparameter α on the other hand encodes the overall uncertainty present in the values of the default model. This historic way of parametrizing the prior arose from choosing originally as prior a Gaussian distribution for each frequency bin ρ l with individual mean and one overall variance (Tikhonov regularization). In a modern Bayesian analysis, domain knowledge with appropriately quantified uncertainties will provide the mean and variance (and possibly higher nontrivial moments) for the prior distribution individually for each of the discretized ρ l .which encodes how compatible the test function ρ is to the available prior information. The choice of this distribution is the central ingredient in setting up a Bayesian analysis and differs among the multiple implementations found in the literature. Commonly the parameters of the prior are encoded in terms of the so called default model m(ω), which denotes the extremum δS/δρ| ρ=m = 0. For a convex prior functional this is the only extremum. The hyperparameter α on the other hand encodes the overall uncertainty present in the values of the default model. This historic way of parametrizing the prior arose from choosing originally as prior a Gaussian distribution for each frequency bin ρ l with individual mean and one overall variance (Tikhonov regularization). In a modern Bayesian analysis, domain knowledge with appropriately quantified uncertainties will provide the mean and variance (and possibly higher nontrivial moments) for the prior distribution individually for each of the discretized ρ l .</p>
        <p>In the study of heavy quarkonium one most often encounters spectral functions that are positive definite. Positivity is a form of prior information obtained from the QCD spectral decomposition of hadronic correlators based on identical source and sink operators. Thus in the following we will focus on implementations of the prior probability that explicitly incorporate this fact (for Bayesian methods applicable to non-positive spectra see e.g. [120] and references therein. For the Backus-Gilbert method see e.g. [121,122]).In the study of heavy quarkonium one most often encounters spectral functions that are positive definite. Positivity is a form of prior information obtained from the QCD spectral decomposition of hadronic correlators based on identical source and sink operators. Thus in the following we will focus on implementations of the prior probability that explicitly incorporate this fact (for Bayesian methods applicable to non-positive spectra see e.g. [120] and references therein. For the Backus-Gilbert method see e.g. [121,122]).</p>
        <p>The most well known implementation of the Bayesian approach is the Maximum Entropy Method (MEM) [123][124][125], which was developed originally for inverse problems in the context of two-dimensional image restoration in astronomy. It has been introduced in the context of lattice QCD simulations for the first time in Ref. [126] and subsequently been used in a variety of studies of quarkonium properties. Its application to continuum QCD was first considered in [127]. The MEM is based on four theorems: locality, coordinate invariance, system independence and the Bayesian requirement that the default model describes the extremum of the prior. The combination of the second and third theorem constrains the function ρ to be positive definite. Taken together the Shannon-Jaynes entropy emergesThe most well known implementation of the Bayesian approach is the Maximum Entropy Method (MEM) [123][124][125], which was developed originally for inverse problems in the context of two-dimensional image restoration in astronomy. It has been introduced in the context of lattice QCD simulations for the first time in Ref. [126] and subsequently been used in a variety of studies of quarkonium properties. Its application to continuum QCD was first considered in [127]. The MEM is based on four theorems: locality, coordinate invariance, system independence and the Bayesian requirement that the default model describes the extremum of the prior. The combination of the second and third theorem constrains the function ρ to be positive definite. Taken together the Shannon-Jaynes entropy emerges</p>
        <p>In a more recently developed implementation of the Bayesian strategy, simply christened Bayesian Reconstruction (BR) [128], the prior is constructed specifically for the one-dimensional inversion problem of Eq. ( 98). While it shares with the MEM the first and last axiom it replaces the two others by a smoothness and a scale invariance axiom. The former requires that the output is a smooth function, where data has not introduced sharp peaked structures. The latter, in contrast to the axioms of the MEM, guarantees that the units assigned to the correlator do not affect the end result. This is achieved as only ratios of ρ and m enter, both of which have to be assigned the same units. Another consequence is that the spectral function must be positive definite. The corresponding regulator functional readsIn a more recently developed implementation of the Bayesian strategy, simply christened Bayesian Reconstruction (BR) [128], the prior is constructed specifically for the one-dimensional inversion problem of Eq. ( 98). While it shares with the MEM the first and last axiom it replaces the two others by a smoothness and a scale invariance axiom. The former requires that the output is a smooth function, where data has not introduced sharp peaked structures. The latter, in contrast to the axioms of the MEM, guarantees that the units assigned to the correlator do not affect the end result. This is achieved as only ratios of ρ and m enter, both of which have to be assigned the same units. Another consequence is that the spectral function must be positive definite. The corresponding regulator functional reads</p>
        <p>which corresponds to P[ρ|I] taking on the form of a gamma distribution.which corresponds to P[ρ|I] taking on the form of a gamma distribution.</p>
        <p>Even though both the MEM and the BR method have been designed in a way that intuitively suggests that they favor smooth functions over wiggly functions, it turns out (see e.g. Ref. [129]) that this is not the case in general.Even though both the MEM and the BR method have been designed in a way that intuitively suggests that they favor smooth functions over wiggly functions, it turns out (see e.g. Ref. [129]) that this is not the case in general.</p>
        <p>In Fig. 8 we provide an explicit example of the penalties assigned to a function with (blue solid) and without wiggles (red dashed) in case of a constant default model. The two curves enclose the same area. Both the Shannon-Jaynes entropy and the BR regulator lead to a higher probability for the wiggly structure (since they are negative, a ratio larger than one means that the wiggly line is favored). This is an issue affecting purely local regulator functionals and may lead to the appearance of artificial ringing in reconstructed spectral functions. Remember that already in well conditioned inverse problems, such as the inverse Fourier series, so called Gibbs ringing occurs. Reconstructing a sharp feature with compact support from a finite number of exactly known Fourier coefficients will lead to a result, which oscillates even where the original input is exactly zero, only converging to the correct result for an increasing number of datapoints. In order to accurately determine the physics content of a reconstructed spectral functions, ringing needs to be reliably controlled.In Fig. 8 we provide an explicit example of the penalties assigned to a function with (blue solid) and without wiggles (red dashed) in case of a constant default model. The two curves enclose the same area. Both the Shannon-Jaynes entropy and the BR regulator lead to a higher probability for the wiggly structure (since they are negative, a ratio larger than one means that the wiggly line is favored). This is an issue affecting purely local regulator functionals and may lead to the appearance of artificial ringing in reconstructed spectral functions. Remember that already in well conditioned inverse problems, such as the inverse Fourier series, so called Gibbs ringing occurs. Reconstructing a sharp feature with compact support from a finite number of exactly known Fourier coefficients will lead to a result, which oscillates even where the original input is exactly zero, only converging to the correct result for an increasing number of datapoints. In order to accurately determine the physics content of a reconstructed spectral functions, ringing needs to be reliably controlled.</p>
        <p>In order to overcome this shortcoming, the state-of-the art implementation of the MEM by Bryan [123] proposes to limit the functional space from which to choose the function ρ to a low dimensional subspace of smooth functions around the default model. In that case the strength of the smoothing is directly related to the number of available input datapoints.In order to overcome this shortcoming, the state-of-the art implementation of the MEM by Bryan [123] proposes to limit the functional space from which to choose the function ρ to a low dimensional subspace of smooth functions around the default model. In that case the strength of the smoothing is directly related to the number of available input datapoints.</p>
        <p>For the BR method a different strategy has been proposed that implements smoothing explicitly in the prior functional S, keeping in line with the Bayesian philosophy. I.e. one adds to the standard BR prior an additional term that penalizes the arc length of the function ρ, one possible criterion to quantify the wiggliness of the spectrum. A naive way of constructing the corresponding regulator has been proposed in Ref. [129] leading toFor the BR method a different strategy has been proposed that implements smoothing explicitly in the prior functional S, keeping in line with the Bayesian philosophy. I.e. one adds to the standard BR prior an additional term that penalizes the arc length of the function ρ, one possible criterion to quantify the wiggliness of the spectrum. A naive way of constructing the corresponding regulator has been proposed in Ref. [129] leading to</p>
        <p>The strength of smoothing in the end result is now made explicit by the additional hyperparameter κ. The value it takes on depends on the problem at hand and needs to be set in a self consistent manner. In practice prior information is used to do so, with one pertinent example being the use of analytically known free spectral functions. In Fig. 9 the procedure for the example of quarkonium in lattice NRQCD is sketched. The black curve denotes the free P-wave spectral function in the thermodynamic limit, which contains no peak structures and extends over a relatively large frequency range. After computing the Euclidean correlator of this spectrum, discretized with a small number of N τ = 12 points along a realistic Euclidean range of β = 1.4 fm the reconstruction outcomes of different methods can be compared. Using κ = 0, i.e. the standard BR method, one finds significant ringing to be present (dashed blue), due to the small number of input points. The MEM (solid green) already shows much less ringing. Increasing the value of κ in the smooth BR method one will arrive at intermediate values at a reconstruction result, which is quite similar to the MEM. Eventually when (in this case) one reaches κ = 1 (red solid) no more remnants of ringing are present and the range of frequencies up to 3 GeV is faithfully reproduced. In all reconstructions a default model with unit value is used, which all reconstruction eventually approach at high frequencies.The strength of smoothing in the end result is now made explicit by the additional hyperparameter κ. The value it takes on depends on the problem at hand and needs to be set in a self consistent manner. In practice prior information is used to do so, with one pertinent example being the use of analytically known free spectral functions. In Fig. 9 the procedure for the example of quarkonium in lattice NRQCD is sketched. The black curve denotes the free P-wave spectral function in the thermodynamic limit, which contains no peak structures and extends over a relatively large frequency range. After computing the Euclidean correlator of this spectrum, discretized with a small number of N τ = 12 points along a realistic Euclidean range of β = 1.4 fm the reconstruction outcomes of different methods can be compared. Using κ = 0, i.e. the standard BR method, one finds significant ringing to be present (dashed blue), due to the small number of input points. The MEM (solid green) already shows much less ringing. Increasing the value of κ in the smooth BR method one will arrive at intermediate values at a reconstruction result, which is quite similar to the MEM. Eventually when (in this case) one reaches κ = 1 (red solid) no more remnants of ringing are present and the range of frequencies up to 3 GeV is faithfully reproduced. In all reconstructions a default model with unit value is used, which all reconstruction eventually approach at high frequencies.</p>
        <p>Returning to the general discussion, we see that prior information enters Bayes theorem in multiple ways. Not only does one need to choose the functional form of the prior probability depending on which sets of axioms appear more appropriate. One also has to set the parameters governing that distribution, i.e. the default model using QCD domain knowledge. Note that already selecting the frequency range along which to discretize ρ(ω) constitutes prior information.Returning to the general discussion, we see that prior information enters Bayes theorem in multiple ways. Not only does one need to choose the functional form of the prior probability depending on which sets of axioms appear more appropriate. One also has to set the parameters governing that distribution, i.e. the default model using QCD domain knowledge. Note that already selecting the frequency range along which to discretize ρ(ω) constitutes prior information.</p>
        <p>The third term in Bayes theorem P[D|I] historically christened the evidence corresponds to the ρ independent normalization of the numerator of Eq. ( 103). While often neglected in practice it can play a role in the self consistent determination of the hyperparameter α in the MEM.The third term in Bayes theorem P[D|I] historically christened the evidence corresponds to the ρ independent normalization of the numerator of Eq. ( 103). While often neglected in practice it can play a role in the self consistent determination of the hyperparameter α in the MEM.</p>
        <p>With all the ingredients on the r.h.s. of Bayes theorem defined, we are ready to solve the inverse problem in a Bayesian fashion, i.e. by interrogating the resulting posterior. The modern form to do so is to deploy Monte-Carlo methods (e.g. the MC-STAN [130] library https://mc-stan.org/) to sample the full distribution P[ρ|D, I] through which we may define the most probable spectral function via the expectation valueWith all the ingredients on the r.h.s. of Bayes theorem defined, we are ready to solve the inverse problem in a Bayesian fashion, i.e. by interrogating the resulting posterior. The modern form to do so is to deploy Monte-Carlo methods (e.g. the MC-STAN [130] library https://mc-stan.org/) to sample the full distribution P[ρ|D, I] through which we may define the most probable spectral function via the expectation value</p>
        <p>An important feature of the Bayesian approach is that it is very easy to incorporate new input data once a higher quality in the lattice simulations has been achieved. We may then use the posterior distribution of a previous analysis as the prior for the next analysis, incrementally improving the accuracy of the inversion.An important feature of the Bayesian approach is that it is very easy to incorporate new input data once a higher quality in the lattice simulations has been achieved. We may then use the posterior distribution of a previous analysis as the prior for the next analysis, incrementally improving the accuracy of the inversion.</p>
        <p>In the past, due to the computational cost involved in sampling the posterior it has been common to simply compute the value of ρ at the extremum of the posterior. This maximum a posteriori solution ρ MAP satisfies δP[ρ|D, I] δρIn the past, due to the computational cost involved in sampling the posterior it has been common to simply compute the value of ρ at the extremum of the posterior. This maximum a posteriori solution ρ MAP satisfies δP[ρ|D, I] δρ</p>
        <p>and is found by carrying out a numerical optimization procedure. Since most optimization algorithms are designed to find minima, one often considers L -αS instead. (For the stochastic analytic inference approach see e.g. [131].)and is found by carrying out a numerical optimization procedure. Since most optimization algorithms are designed to find minima, one often considers L -αS instead. (For the stochastic analytic inference approach see e.g. [131].)</p>
        <p>Since the MAP is still the most common approach to Bayesian reconstruction in the study of heavy quarkonium, let us briefly discuss some of its aspects. The extremum ρ MAP results from a competition between a likelihood with many degenerate local minima and the prior. As long as the prior is convex it can be shown that if an extremum of the posterior exists it is unique (for a proof see [126]). This is the case for both the MEM and the standard BR method. Note that the derivative term in the smooth BR method can lead to the appearance of additional local extrema and thus more sophisticated optimization, such as simulated annealing is in general called for. Note also that for the same choice of m, the curvature of S BR is weaker than that of S SJ , meaning that in a MAP procedure the BR method will imprint the prior information more weakly on the end result than the MEM.Since the MAP is still the most common approach to Bayesian reconstruction in the study of heavy quarkonium, let us briefly discuss some of its aspects. The extremum ρ MAP results from a competition between a likelihood with many degenerate local minima and the prior. As long as the prior is convex it can be shown that if an extremum of the posterior exists it is unique (for a proof see [126]). This is the case for both the MEM and the standard BR method. Note that the derivative term in the smooth BR method can lead to the appearance of additional local extrema and thus more sophisticated optimization, such as simulated annealing is in general called for. Note also that for the same choice of m, the curvature of S BR is weaker than that of S SJ , meaning that in a MAP procedure the BR method will imprint the prior information more weakly on the end result than the MEM.</p>
        <p>Let us remark on the fact that it is possible to obtain a unique result for the N ω ≫ N τ parameters ρ l here. The reason is that we have provided not just the N τ pieces of information via the simulated correlator but in addition N ω pieces of information via the default model, as well as information due to the shape of the regulator functional. Contrary to statements previously made in the literature, there is more information present than free parameters in the inverse problem. I.e. determining the Bayesian answer is well posed in terms of theLet us remark on the fact that it is possible to obtain a unique result for the N ω ≫ N τ parameters ρ l here. The reason is that we have provided not just the N τ pieces of information via the simulated correlator but in addition N ω pieces of information via the default model, as well as information due to the shape of the regulator functional. Contrary to statements previously made in the literature, there is more information present than free parameters in the inverse problem. I.e. determining the Bayesian answer is well posed in terms of the</p>
        <p>The hyperparameter α is handled differently in the MEM and BR method. In the historic MEM prescription the extremum of the posterior is obtained with alpha chosen such that for ρ MAP hist the likelihood takes on the value L = N τ . This choice reflects the fact that on average the correct spectral function sampled with Gaussian noise would lead to exactly this value. On the other hand in the so called modern MEM, several ρ MAP 's are computed for a range of different α value and subsequently averaged, weighted according to which α leads to an extremal evidence. Since the evidence cannot be computed analytically this is conventionally implemented by using a simple Gaussian approximation of P[D|I]. In the BR method on the other hand one assumes complete ignorance of the value of α and marginalizes α a priori. In practice this step is implemented semi-analytically or fully numerically. In addition the BR method also enforces L = N τ as part of the prior information entering the likelihood.The hyperparameter α is handled differently in the MEM and BR method. In the historic MEM prescription the extremum of the posterior is obtained with alpha chosen such that for ρ MAP hist the likelihood takes on the value L = N τ . This choice reflects the fact that on average the correct spectral function sampled with Gaussian noise would lead to exactly this value. On the other hand in the so called modern MEM, several ρ MAP 's are computed for a range of different α value and subsequently averaged, weighted according to which α leads to an extremal evidence. Since the evidence cannot be computed analytically this is conventionally implemented by using a simple Gaussian approximation of P[D|I]. In the BR method on the other hand one assumes complete ignorance of the value of α and marginalizes α a priori. In practice this step is implemented semi-analytically or fully numerically. In addition the BR method also enforces L = N τ as part of the prior information entering the likelihood.</p>
        <p>Note that removing the prior information by setting P[ρ|I] = 1 above, one returns to an underdetermined maximum likelihood problem, equivalent to a naive χ 2 fit. On the other hand, since the prior is defined to have a global extremum at ρ = m, the function m(ω) by definition is the Bayesian answer to the inverse problem in the absence of simulation data.Note that removing the prior information by setting P[ρ|I] = 1 above, one returns to an underdetermined maximum likelihood problem, equivalent to a naive χ 2 fit. On the other hand, since the prior is defined to have a global extremum at ρ = m, the function m(ω) by definition is the Bayesian answer to the inverse problem in the absence of simulation data.</p>
        <p>As long as the input data is finite in number and carries a non-vanishing uncertainty, ρ Bayes the solution of the Bayesian extraction will in general depend on the prior information included in P [ρ|I]. On the other hand Bayes theorem assures us that in the Bayesian continuum limit of concurrently increasing the number of input data N τ → ∞ and reducing the uncertainty dD/D → 0 one converges to a unique result in which the influence of the prior information becomes negligible.As long as the input data is finite in number and carries a non-vanishing uncertainty, ρ Bayes the solution of the Bayesian extraction will in general depend on the prior information included in P [ρ|I]. On the other hand Bayes theorem assures us that in the Bayesian continuum limit of concurrently increasing the number of input data N τ → ∞ and reducing the uncertainty dD/D → 0 one converges to a unique result in which the influence of the prior information becomes negligible.</p>
        <p>As we will see in the investigation of heavy quarkonium spectra, for a given quality of input data, some features in the reconstruction may already be stably reproduced (e.g. the position of the ground state peak), while others are not (e.g. excited state peaks and ground state width). The choice of P [ρ|I] determines in what way we will approach the true result, as the input data quality is improved. I.e. it is imperative to understand what artifacts are present and how they are related to the regularization. The use of mock input data, i.e. correlators computed from known input spectra play an important role in doing so.As we will see in the investigation of heavy quarkonium spectra, for a given quality of input data, some features in the reconstruction may already be stably reproduced (e.g. the position of the ground state peak), while others are not (e.g. excited state peaks and ground state width). The choice of P [ρ|I] determines in what way we will approach the true result, as the input data quality is improved. I.e. it is imperative to understand what artifacts are present and how they are related to the regularization. The use of mock input data, i.e. correlators computed from known input spectra play an important role in doing so.</p>
        <p>Both MEM and BR feature a convex prior, leading in principle to a unique extremum of the posterior. For the MEM, when studying spectra with sharp peaks and otherwise vanishing spectral weight, the convergence to the global extremum is impeded by the fact that the Shannon-Jaynes entropy takes on a finite value -m as ρ → 0, leading effectively to a flat direction, where numerical optimization algorithms are not efficiently pulled towards the global extremum. In the BR method the prior diverges as ρ → 0, avoiding this issue.Both MEM and BR feature a convex prior, leading in principle to a unique extremum of the posterior. For the MEM, when studying spectra with sharp peaks and otherwise vanishing spectral weight, the convergence to the global extremum is impeded by the fact that the Shannon-Jaynes entropy takes on a finite value -m as ρ → 0, leading effectively to a flat direction, where numerical optimization algorithms are not efficiently pulled towards the global extremum. In the BR method the prior diverges as ρ → 0, avoiding this issue.</p>
        <p>Since in quarkonium studies from lattice QCD we are faced with the problem that only a relatively small number of datapoints will be available in the near future N τ ∼ O(10 -40) the most relevant artifact in the BR method and the MEM is the presence of ringing. The appearance of unphysical wiggly structures interferes with the identification of the relevant physical structures, which also come in the form of peaks. Different strategies exist on how to mitigate the effects of ringing.Since in quarkonium studies from lattice QCD we are faced with the problem that only a relatively small number of datapoints will be available in the near future N τ ∼ O(10 -40) the most relevant artifact in the BR method and the MEM is the presence of ringing. The appearance of unphysical wiggly structures interferes with the identification of the relevant physical structures, which also come in the form of peaks. Different strategies exist on how to mitigate the effects of ringing.</p>
        <p>Let us first discuss the BR method. Due to its weak curvature the BR prior is more susceptible to ringing than the Shannon-Jaynes entropy. In order to obtain meaningful results in the presence of only a small number of datapoints, the smooth BR prior has been proposed. The strategy will be to tune the smoothing hyperparameter κ based on a mock-data analysis involving realistic and analytically known input spectral functions. In practice these will often be the non-interacting spectral functions. Reconstructing such spectra featuring broad structures from correlator data that is discretized in the same fashion as the actual simulation data, one finds a minimum value for κ at which it effectively suppresses ringing, while still allowing us to pick up peaked structures that are actually encoded in the input data.Let us first discuss the BR method. Due to its weak curvature the BR prior is more susceptible to ringing than the Shannon-Jaynes entropy. In order to obtain meaningful results in the presence of only a small number of datapoints, the smooth BR prior has been proposed. The strategy will be to tune the smoothing hyperparameter κ based on a mock-data analysis involving realistic and analytically known input spectral functions. In practice these will often be the non-interacting spectral functions. Reconstructing such spectra featuring broad structures from correlator data that is discretized in the same fashion as the actual simulation data, one finds a minimum value for κ at which it effectively suppresses ringing, while still allowing us to pick up peaked structures that are actually encoded in the input data.</p>
        <p>Let us now discuss the MEM. Dealing with ringing in the MEM has traditionally been avoided by incorporating an additional smoothing in the MAP procedure. There are two independent proposals in the literature on how to do so. Both propose that the global extremum of the posterior is located in a subspace spanned by a collection of smooth functions related to the transpose Kernel K t .Let us now discuss the MEM. Dealing with ringing in the MEM has traditionally been avoided by incorporating an additional smoothing in the MAP procedure. There are two independent proposals in the literature on how to do so. Both propose that the global extremum of the posterior is located in a subspace spanned by a collection of smooth functions related to the transpose Kernel K t .</p>
        <p>In the state-of-the-art implementation by Bryan [123], the spectral function is parametrized in terms of deviationsIn the state-of-the-art implementation by Bryan [123], the spectral function is parametrized in terms of deviations</p>
        <p>It is then argued that the parameters a l are restricted to a functional space corresponding to the first N τ columns of the matrix U arising from the singular value decomposition of the transpose kernel K t = UΣ V t . Here U refers to an N ω × N ω matrix containing the orthonormal basis of eigenvectors of K t K , Σ is a N ω × N τ diagonal matrix containing the N τ finite singular values. V t denotes an orthonormal N τ × N τ matrix. The more recent proposal by Jakovac [132] implicitly solves for the MAP solution leading to a restricted search space for the a l 's spanned directly by the columns of K t . If the reconstruction problem were purely linear (the forward problem obviously is) then the two formulations are equivalent. I.e. the columns of K t span the same image space as the first N τ columns of the matrix U obtained by the SVD. In both cases the smoothness of the solution is directly related to the number of input datapoints provided.It is then argued that the parameters a l are restricted to a functional space corresponding to the first N τ columns of the matrix U arising from the singular value decomposition of the transpose kernel K t = UΣ V t . Here U refers to an N ω × N ω matrix containing the orthonormal basis of eigenvectors of K t K , Σ is a N ω × N τ diagonal matrix containing the N τ finite singular values. V t denotes an orthonormal N τ × N τ matrix. The more recent proposal by Jakovac [132] implicitly solves for the MAP solution leading to a restricted search space for the a l 's spanned directly by the columns of K t . If the reconstruction problem were purely linear (the forward problem obviously is) then the two formulations are equivalent. I.e. the columns of K t span the same image space as the first N τ columns of the matrix U obtained by the SVD. In both cases the smoothness of the solution is directly related to the number of input datapoints provided.</p>
        <p>Jakovac already observed that the two prescriptions lead to different results in practice (see Fig. 28 in [132]), indicating that they are actually not equivalent. In turn the question arises whether the global extremum in general is contained within the image space of K t . This question is further emphasized by a counterexample to the SVD restriction, which has been put forward in Ref. [133].Jakovac already observed that the two prescriptions lead to different results in practice (see Fig. 28 in [132]), indicating that they are actually not equivalent. In turn the question arises whether the global extremum in general is contained within the image space of K t . This question is further emphasized by a counterexample to the SVD restriction, which has been put forward in Ref. [133].</p>
        <p>Since it will help us understand the systematics of the MEM more clearly, let us discuss the counterexample in more detail by considering the historic MEM. The SVD search space is fully specified once the range and discretization of τ and ω have been selected. For N τ input data the search space is parametrized by the first N τ columns of U. This statement is made independently of the input data and independently from the recipe of how to choose the value α. Now let us choose instead the N τ +1 st column of U as mock spectrum ρ and compute from it the corresponding Euclidean data. Then, by construction, this data cannot be reproduced within one sigma from within the SVD search space, while it is still possible to reproduce it in the full search space. Taking the errors on that mock input data to zero, the minimal value of L in the SVD subspace can be made arbitrarily large. And since the Shannon-Jaynes entropy is negative definite it cannot compensate the large values of L. In turn the posterior probability of that ρ in the SVD subspace can be made smaller than in the full search space, disproving the general claim that the extremum of the posterior always lies in the SVD subspace. Thus the claim of the counterexample is that the smoothing introduced by restricting the search space to the image of K t is ad-hoc and may lead to artificially smoothed results. In practice it turns out that the SVD prescription works well for problems where accurate prior information is already available. This corresponds to cases where the true global extremum indeed lies within the SVD subspace, as the default model is located close enough to it in parameter space a priori. However in situations where both only a relatively small number of input data is available (e.g. O( 10)) and the prior information is limited, the SVD search space may not provide the Bayesian answer to the inversion task. Of course, since the global extremum of the MEM posterior is unique if it exists, we can still solve for it in the full search space. Systematically extending the search space has been considered in [133,134].Since it will help us understand the systematics of the MEM more clearly, let us discuss the counterexample in more detail by considering the historic MEM. The SVD search space is fully specified once the range and discretization of τ and ω have been selected. For N τ input data the search space is parametrized by the first N τ columns of U. This statement is made independently of the input data and independently from the recipe of how to choose the value α. Now let us choose instead the N τ +1 st column of U as mock spectrum ρ and compute from it the corresponding Euclidean data. Then, by construction, this data cannot be reproduced within one sigma from within the SVD search space, while it is still possible to reproduce it in the full search space. Taking the errors on that mock input data to zero, the minimal value of L in the SVD subspace can be made arbitrarily large. And since the Shannon-Jaynes entropy is negative definite it cannot compensate the large values of L. In turn the posterior probability of that ρ in the SVD subspace can be made smaller than in the full search space, disproving the general claim that the extremum of the posterior always lies in the SVD subspace. Thus the claim of the counterexample is that the smoothing introduced by restricting the search space to the image of K t is ad-hoc and may lead to artificially smoothed results. In practice it turns out that the SVD prescription works well for problems where accurate prior information is already available. This corresponds to cases where the true global extremum indeed lies within the SVD subspace, as the default model is located close enough to it in parameter space a priori. However in situations where both only a relatively small number of input data is available (e.g. O( 10)) and the prior information is limited, the SVD search space may not provide the Bayesian answer to the inversion task. Of course, since the global extremum of the MEM posterior is unique if it exists, we can still solve for it in the full search space. Systematically extending the search space has been considered in [133,134].</p>
        <p>The last point to consider is how to estimate the uncertainties in the spectral reconstruction. Bayes theorem makes explicit that the posterior depends on two ingredients, data and prior information. If one samples the posterior using Monte-Carlo methods, the spread in that distribution encodes the combined uncertainty arising from spread in both the likelihood and prior. If on the other hand one only computes a point estimate, such as the MAP, the uncertainty must be estimated in addition. One proposal in the literature [126] is to evaluate how pronounced the maximum of the posterior is, taking its curvature as a measure for the robustness of the solution. While intuitive, it has been found in practice that this criterion may underestimate the full uncertainty budget.The last point to consider is how to estimate the uncertainties in the spectral reconstruction. Bayes theorem makes explicit that the posterior depends on two ingredients, data and prior information. If one samples the posterior using Monte-Carlo methods, the spread in that distribution encodes the combined uncertainty arising from spread in both the likelihood and prior. If on the other hand one only computes a point estimate, such as the MAP, the uncertainty must be estimated in addition. One proposal in the literature [126] is to evaluate how pronounced the maximum of the posterior is, taking its curvature as a measure for the robustness of the solution. While intuitive, it has been found in practice that this criterion may underestimate the full uncertainty budget.</p>
        <p>In general to estimate the statistical uncertainties of the result, one of the many different bootstrapping methods can be deployed. E.g. the blocked Jackknife procedure remains a simple and computationally cheap option [77]. Instead of using all available lattice realizations of the correlator D for the reconstruction, one forms N J so called Jackknife averages D j , where for each j a consecutive subset of N conf /N J realizations of the correlator have been excluded from the average. This leads to N J reconstructions of the spectral function ρ j . The variance of the spectral function computed from the full statistics average is then estimated asIn general to estimate the statistical uncertainties of the result, one of the many different bootstrapping methods can be deployed. E.g. the blocked Jackknife procedure remains a simple and computationally cheap option [77]. Instead of using all available lattice realizations of the correlator D for the reconstruction, one forms N J so called Jackknife averages D j , where for each j a consecutive subset of N conf /N J realizations of the correlator have been excluded from the average. This leads to N J reconstructions of the spectral function ρ j . The variance of the spectral function computed from the full statistics average is then estimated as</p>
        <p>Quantifying the systematic uncertainties arising from prior information is less formalized. E.g. one often does not possess a reliable estimate of the uncertainty of the values of the default model. However since Bayes theorem makes the influence of the prior information explicit, it may also be varied in a straight forward fashion. I.e. one should repeat the reconstruction using default models, which possess different functional forms in those regions, where accurate information on ρ is absent. In addition deploying different prior distributions that are applicable to the problem at hand provides additional insight on how the regularization affects the end result. The variation among the reconstructions from different default models and priors is then summarized into a systematic error bar. The prescription on how to do so differs between studies in the literature, some taking the maximum deviation, others the quadratic mean.Quantifying the systematic uncertainties arising from prior information is less formalized. E.g. one often does not possess a reliable estimate of the uncertainty of the values of the default model. However since Bayes theorem makes the influence of the prior information explicit, it may also be varied in a straight forward fashion. I.e. one should repeat the reconstruction using default models, which possess different functional forms in those regions, where accurate information on ρ is absent. In addition deploying different prior distributions that are applicable to the problem at hand provides additional insight on how the regularization affects the end result. The variation among the reconstructions from different default models and priors is then summarized into a systematic error bar. The prescription on how to do so differs between studies in the literature, some taking the maximum deviation, others the quadratic mean.</p>
        <p>The second class of reconstruction prescriptions that find application in quarkonium studies falls into the category of projection based methods. I.e. in these methods the simulation data in Euclidean time τ is first Fourier transformed into imaginary frequencies q 0 before being projected onto a set of analytically known functions. In essence one is expanding the data in a particular basis set. The basis functions can then be analytically continued in an appropriate fashion to yield the retarded propagator D R (ω) in real-time frequencies, whose imaginary part is directly related to the spectral functionThe second class of reconstruction prescriptions that find application in quarkonium studies falls into the category of projection based methods. I.e. in these methods the simulation data in Euclidean time τ is first Fourier transformed into imaginary frequencies q 0 before being projected onto a set of analytically known functions. In essence one is expanding the data in a particular basis set. The basis functions can then be analytically continued in an appropriate fashion to yield the retarded propagator D R (ω) in real-time frequencies, whose imaginary part is directly related to the spectral function</p>
        <p>Carrying out a projection does not require prior information. On the other hand, the fact that one is projecting not only the true Euclidean data but also noise means that these methods suffer strongly from statistical uncertainties in the input. The ill-conditioned-ness of the analytic continuation can be understood intuitively. While the basis functions in Euclidean time are mostly monotonously damped functions, in real-time they behave oscillatory, often with strongly growing amplitudes. Thus to linearly combine these basis functions into a finite and damped real-time correlator the coefficients obtained from the projection need to be computed with extremely high precision.Carrying out a projection does not require prior information. On the other hand, the fact that one is projecting not only the true Euclidean data but also noise means that these methods suffer strongly from statistical uncertainties in the input. The ill-conditioned-ness of the analytic continuation can be understood intuitively. While the basis functions in Euclidean time are mostly monotonously damped functions, in real-time they behave oscillatory, often with strongly growing amplitudes. Thus to linearly combine these basis functions into a finite and damped real-time correlator the coefficients obtained from the projection need to be computed with extremely high precision.</p>
        <p>In the case of relativistic Euclidean correlators, which exhibit periodic behavior along Euclidean time, a projection method based on the so called Pollaczek polynomials has been proposed in Ref. [135]. The prescription is straight forward, i.e. the expansion parameters can be explicitly computed from the input data, as can be the analytically continued approximant in terms of Laguerre polynomials. Unfortunately it turned out that in practice the fact that only a finite number of input datapoints are available and that statistical errors are present, leads to a significant deterioration of the reconstruction results [136]. Hence this method has so far not been applied at a large scale.In the case of relativistic Euclidean correlators, which exhibit periodic behavior along Euclidean time, a projection method based on the so called Pollaczek polynomials has been proposed in Ref. [135]. The prescription is straight forward, i.e. the expansion parameters can be explicitly computed from the input data, as can be the analytically continued approximant in terms of Laguerre polynomials. Unfortunately it turned out that in practice the fact that only a finite number of input datapoints are available and that statistical errors are present, leads to a significant deterioration of the reconstruction results [136]. Hence this method has so far not been applied at a large scale.</p>
        <p>A more general approach, also applicable to Euclidean correlators without specific symmetry properties, is the Padé approximation. It expresses the correlator of interest in terms of a rational function. Depending on the choice of the highest monomial contributing to the numerator n or denominator m one refers to a (n, m) Padé approximation R (n,m) . The (n, 0) approximation corresponds to the simple Taylor series to order n. Interest in this method has recently been rekindled by studies of spectral reconstructions from approximate non-perturbative analytic computations [122,137] and the arrival of very high statistics lattice QCD ensembles.A more general approach, also applicable to Euclidean correlators without specific symmetry properties, is the Padé approximation. It expresses the correlator of interest in terms of a rational function. Depending on the choice of the highest monomial contributing to the numerator n or denominator m one refers to a (n, m) Padé approximation R (n,m) . The (n, 0) approximation corresponds to the simple Taylor series to order n. Interest in this method has recently been rekindled by studies of spectral reconstructions from approximate non-perturbative analytic computations [122,137] and the arrival of very high statistics lattice QCD ensembles.</p>
        <p>In the context of spectral function reconstruction the close relation between Padé approximants and continued fractions is exploited in the following way. In order for the analytic continuation of the approximant to be stable, one wishes to construct expressions with either the same highest monomial power in the numerator and denominator (n, n) or even better, with one power less in the numerator (n -1, n). For N data input data points D j along imaginary frequencies q 0 j , one can construct the approximantIn the context of spectral function reconstruction the close relation between Padé approximants and continued fractions is exploited in the following way. In order for the analytic continuation of the approximant to be stable, one wishes to construct expressions with either the same highest monomial power in the numerator and denominator (n, n) or even better, with one power less in the numerator (n -1, n). For N data input data points D j along imaginary frequencies q 0 j , one can construct the approximant</p>
        <p>which corresponds to the ((N data -1)/2, (N data -1)/2) approximation in case that N data is odd and towhich corresponds to the ((N data -1)/2, (N data -1)/2) approximation in case that N data is odd and to</p>
        <p>if N data is even. The expansion coefficients a i can be determined recursively [138] by the Schlessinger methodif N data is even. The expansion coefficients a i can be determined recursively [138] by the Schlessinger method</p>
        <p>} .} .</p>
        <p>((</p>
        <p>The resulting interpolation DN data (iω) exactly reproduces the input data D M at the imaginary frequencies q 0 l provided. The retarded correlator needed to compute the spectral function may now be obtained by Wick rotating the imaginary frequency argument of the approximant D R (ω) ≈ -DN data (q 0 → ωiϵ) approaching ϵ → 0 + from above.The resulting interpolation DN data (iω) exactly reproduces the input data D M at the imaginary frequencies q 0 l provided. The retarded correlator needed to compute the spectral function may now be obtained by Wick rotating the imaginary frequency argument of the approximant D R (ω) ≈ -DN data (q 0 → ωiϵ) approaching ϵ → 0 + from above.</p>
        <p>As in any direct projection method, cancellations occur in the evaluation of the continued fraction, in particularly if there are symmetries in the input data. This requires the evaluation of the intermediate steps in the computation to be carried out with high precision arithmetic. As we will show in the explicit application of the Padé approximation to the determination of the in-medium heavy quark potential, currently available lattice QCD data is of high enough quality for this direct projection method to be of use.As in any direct projection method, cancellations occur in the evaluation of the continued fraction, in particularly if there are symmetries in the input data. This requires the evaluation of the intermediate steps in the computation to be carried out with high precision arithmetic. As we will show in the explicit application of the Padé approximation to the determination of the in-medium heavy quark potential, currently available lattice QCD data is of high enough quality for this direct projection method to be of use.</p>
        <p>While the Padé reconstruction does not presuppose explicit prior information, analyticity of the approximant is required for meaningful results. I.e. if the correlator contains divergences or otherwise non-analytic features the accuracy of the Padé based reconstruction may suffer. In the context of studying the spectral functions of gluons it has been found [139] that the Padé reconstruction often violates the spectral decomposition of the correlator. I.e. plugging the reconstructed spectrum back into Eq. ( 98) will produce a Euclidean correlator deviating from the input data by significantly more than one standard deviation. In addition, since positive definiteness never entered the analysis, the Padé reconstruction may lead to artificial excursions into negative values. The stability of reconstructed spectral features needs to be ascertained with a Jackknife analysis, as well as by testing how the removal of input datapoints affects the end result.While the Padé reconstruction does not presuppose explicit prior information, analyticity of the approximant is required for meaningful results. I.e. if the correlator contains divergences or otherwise non-analytic features the accuracy of the Padé based reconstruction may suffer. In the context of studying the spectral functions of gluons it has been found [139] that the Padé reconstruction often violates the spectral decomposition of the correlator. I.e. plugging the reconstructed spectrum back into Eq. ( 98) will produce a Euclidean correlator deviating from the input data by significantly more than one standard deviation. In addition, since positive definiteness never entered the analysis, the Padé reconstruction may lead to artificial excursions into negative values. The stability of reconstructed spectral features needs to be ascertained with a Jackknife analysis, as well as by testing how the removal of input datapoints affects the end result.</p>
        <p>These artifact however do not spell doom for the method, if our goal is to study only subsets of the spectral features. As will be discussed, the position of e.g. the ground state peak may be well captured by the Padé reconstructed spectral function, while its width and the higher lying structures are not accurately reproduced. It is therefore paramount to test in each individual reconstruction scenario whether the Padé method is able to capture the spectral features of interest, given a certain quality of input data.These artifact however do not spell doom for the method, if our goal is to study only subsets of the spectral features. As will be discussed, the position of e.g. the ground state peak may be well captured by the Padé reconstructed spectral function, while its width and the higher lying structures are not accurately reproduced. It is therefore paramount to test in each individual reconstruction scenario whether the Padé method is able to capture the spectral features of interest, given a certain quality of input data.</p>
        <p>, the most probable spectral function, given simulation data and prior information, may be found. Prior information on the data generation may enter the likelihood, most prior information however resides in the prior probability itself. The MEM and BR method provide two different implementations of P[ρ|I], based on different underlying axioms. They have in common that positivity of ρ is enforced., the most probable spectral function, given simulation data and prior information, may be found. Prior information on the data generation may enter the likelihood, most prior information however resides in the prior probability itself. The MEM and BR method provide two different implementations of P[ρ|I], based on different underlying axioms. They have in common that positivity of ρ is enforced.</p>
        <p>While for a finite number of datapoints with finite uncertainty the most probable spectral function may differ between the methods, they will converge to a unique answer in the Bayesian continuum limit. For reconstructions based on a small number of O(10 -40) datapoints, similar to what is often encountered in T &gt; 0 quarkonium studies, ringing constitutes an important numerical artifact. In the MEM it is suppressed by restricting the solution ad-hoc to a smooth functional subspace while in the smooth BR method it is treated by self-consistently tuning an additional hyperparameter κ. Since prior information is made explicit, its role in the total uncertainty budget can be straight forwardly estimated by comparing results based on different default models and prior probabilities. In case of high precision input data also direct projection based methods become viable. The Padé approximation e.g. exploits the analyticity of the correlator and does not require further prior information. Its sensitivity to statistical fluctuations however also requires careful error estimation.While for a finite number of datapoints with finite uncertainty the most probable spectral function may differ between the methods, they will converge to a unique answer in the Bayesian continuum limit. For reconstructions based on a small number of O(10 -40) datapoints, similar to what is often encountered in T &gt; 0 quarkonium studies, ringing constitutes an important numerical artifact. In the MEM it is suppressed by restricting the solution ad-hoc to a smooth functional subspace while in the smooth BR method it is treated by self-consistently tuning an additional hyperparameter κ. Since prior information is made explicit, its role in the total uncertainty budget can be straight forwardly estimated by comparing results based on different default models and prior probabilities. In case of high precision input data also direct projection based methods become viable. The Padé approximation e.g. exploits the analyticity of the correlator and does not require further prior information. Its sensitivity to statistical fluctuations however also requires careful error estimation.</p>
        <p>In the preceding sections we have discussed how the presence of a separation of energy scales allows us to simplify the description of heavy quarkonium using a non-relativistic language. So far we restricted ourselves to a fully equilibrated scenario, since lattice QCD simulations are limited to Euclidean time. Extracting spectral functions and e.g. thermal widths from these simulations gave first insight into the real-time dynamics of heavy quarkonium in equilibrium with its environment. In the context of a heavy-ion collision however we need to go beyond equilibrium to understand the physics of heavy quarkonium. Indeed insight is required on how a heavy quarkonium state reacts to a QCD environment with which it initially is not equilibrated at all.In the preceding sections we have discussed how the presence of a separation of energy scales allows us to simplify the description of heavy quarkonium using a non-relativistic language. So far we restricted ourselves to a fully equilibrated scenario, since lattice QCD simulations are limited to Euclidean time. Extracting spectral functions and e.g. thermal widths from these simulations gave first insight into the real-time dynamics of heavy quarkonium in equilibrium with its environment. In the context of a heavy-ion collision however we need to go beyond equilibrium to understand the physics of heavy quarkonium. Indeed insight is required on how a heavy quarkonium state reacts to a QCD environment with which it initially is not equilibrated at all.</p>
        <p>One of the exciting developments of the past decade is the realization that heavy quarkonium is an ideal example of an open quantum system (OQS) and we may understand many aspects of its real-time properties in and out-of equilibrium from this viewpoint. One example is the concept of decoherence that provides a new perspective on the dynamics of quarkonium melting. The framework of OQS has a long history (see e.g. [140][141][142][143]) in particular in condensed matter physics and we thus benefit from many established results in that field. For an excellent introduction to OQS see e.g. Ref. [144]. On the other hand, the strongly coupled nature of QCD and the particular physics of the color quantum number introduce additional complexities, leading to rich phenomenology not present in other OQS. While considerations of a separation in energy scales forms the basis for deriving effective descriptions in thermal equilibrium, it is the separation of timescales that will allow us to come up with effective descriptions of the quarkonium real-time dynamics. Bridging the language of the effective field theories NRQCD and pNRQCD and the OQS framework is a central focus of current research on in-medium quarkonium dynamics.One of the exciting developments of the past decade is the realization that heavy quarkonium is an ideal example of an open quantum system (OQS) and we may understand many aspects of its real-time properties in and out-of equilibrium from this viewpoint. One example is the concept of decoherence that provides a new perspective on the dynamics of quarkonium melting. The framework of OQS has a long history (see e.g. [140][141][142][143]) in particular in condensed matter physics and we thus benefit from many established results in that field. For an excellent introduction to OQS see e.g. Ref. [144]. On the other hand, the strongly coupled nature of QCD and the particular physics of the color quantum number introduce additional complexities, leading to rich phenomenology not present in other OQS. While considerations of a separation in energy scales forms the basis for deriving effective descriptions in thermal equilibrium, it is the separation of timescales that will allow us to come up with effective descriptions of the quarkonium real-time dynamics. Bridging the language of the effective field theories NRQCD and pNRQCD and the OQS framework is a central focus of current research on in-medium quarkonium dynamics.</p>
        <p>A system is well suited to the open quantum systems approach if its d.o.f. can be separated into an environment E and a small subsystem S coupled via common interactions. In case that E consists of an infinite number of degrees of freedom it is usually referred to as a reservoir, if in addition it is in thermal equilibrium we may call it a heat bath. It is the presence of a continuous distribution of modes in a reservoir and the fact that its dynamics do not show recurrence that will lead to the emergence of dissipative effects when considering the dynamics of the small subsystem. In our case the environment is represented by a thermal QCD medium and the small subsystem is formed by the quarkonium two-body system.A system is well suited to the open quantum systems approach if its d.o.f. can be separated into an environment E and a small subsystem S coupled via common interactions. In case that E consists of an infinite number of degrees of freedom it is usually referred to as a reservoir, if in addition it is in thermal equilibrium we may call it a heat bath. It is the presence of a continuous distribution of modes in a reservoir and the fact that its dynamics do not show recurrence that will lead to the emergence of dissipative effects when considering the dynamics of the small subsystem. In our case the environment is represented by a thermal QCD medium and the small subsystem is formed by the quarkonium two-body system.</p>
        <p>In the following we will give an introduction to the aspects of OQS relevant for the treatment of quarkonium, following closely the exposition in Ref. [144]. As the concept of the open system is not commonly treated in high energy physics contexts, we will discuss in detail the derivation of two equations of motion arising from two different time scale hierarchies: the quantum optical and quantum Brownian motion limit.In the following we will give an introduction to the aspects of OQS relevant for the treatment of quarkonium, following closely the exposition in Ref. [144]. As the concept of the open system is not commonly treated in high energy physics contexts, we will discuss in detail the derivation of two equations of motion arising from two different time scale hierarchies: the quantum optical and quantum Brownian motion limit.</p>
        <p>The overall system consisting of medium and heavy quark d.o.f. is of course closed and possesses a hermitean Hamiltonian. It can be decomposed in terms of a Hamiltonian acting only on the environment d.o.f. H E , one only in the subsystem H S and an interaction term H int that connects bothThe overall system consisting of medium and heavy quark d.o.f. is of course closed and possesses a hermitean Hamiltonian. It can be decomposed in terms of a Hamiltonian acting only on the environment d.o.f. H E , one only in the subsystem H S and an interaction term H int that connects both</p>
        <p>The density matrix of the full system σ tot initialized using state vectors |ψ k (t 0 )⟩ of the full systemThe density matrix of the full system σ tot initialized using state vectors |ψ k (t 0 )⟩ of the full system</p>
        <p>evolves according to the well known von-Neumann equation, captured in a unitary time evolution operatorevolves according to the well known von-Neumann equation, captured in a unitary time evolution operator</p>
        <p>While solving the dynamics of the whole system may be too demanding it is also not our goal. Instead we wish to focus on the evolution of the quarkonium system only, which we may formally achieve by tracing out all medium degrees of freedom. This leads to the reduced density matrixWhile solving the dynamics of the whole system may be too demanding it is also not our goal. Instead we wish to focus on the evolution of the quarkonium system only, which we may formally achieve by tracing out all medium degrees of freedom. This leads to the reduced density matrix</p>
        <p>The quantity σ S is the central focus in the open quantum systems approach and we will set out to formulate its explicit equation of motion, the so called master equation. Time evolution of σ S is formally implemented via the so called dynamical map V . While V (t) can in general be a very complicated operator there is a class of systems, where its form simplifies to that of a semi-group, i.e. V (t 1 )V (t 2 ) = V (t 1 + t 2 ). This is the case when the dynamics of the system is Markovian, i.e. if the next infinitesimal step in the system evolution only depends on the current state of the system. Neglecting memory effects is admissible if a separation of timescales exists between the fast damping of correlations in the environment τ E and the relaxation scale of the subsystem τ rel . In that case the linear map may be written in terms of a generator of the dynamical semi-group L and a linear evolution equation for σ S emergesThe quantity σ S is the central focus in the open quantum systems approach and we will set out to formulate its explicit equation of motion, the so called master equation. Time evolution of σ S is formally implemented via the so called dynamical map V . While V (t) can in general be a very complicated operator there is a class of systems, where its form simplifies to that of a semi-group, i.e. V (t 1 )V (t 2 ) = V (t 1 + t 2 ). This is the case when the dynamics of the system is Markovian, i.e. if the next infinitesimal step in the system evolution only depends on the current state of the system. Neglecting memory effects is admissible if a separation of timescales exists between the fast damping of correlations in the environment τ E and the relaxation scale of the subsystem τ rel . In that case the linear map may be written in terms of a generator of the dynamical semi-group L and a linear evolution equation for σ S emerges</p>
        <p>The most general form of such a Markovian master equation has been derived independently by two groups [145,146] and is known as the GKS or Lindblad equation The quantities L are called Lindblad operators and encode the coupling of the system to its environment. They can always be chosen to be traceless. The Hamiltonian HS not necessarily agrees with the Hamiltonian H S in Eq. ( 112). If the L's are made dimensionless, the quantities γ k &gt; 0 take on the dimensions of 1/time and represent relaxation rates for modes that decay over time in S. In practice the γ 's are given by correlation functions of the environment degrees of freedom.The most general form of such a Markovian master equation has been derived independently by two groups [145,146] and is known as the GKS or Lindblad equation The quantities L are called Lindblad operators and encode the coupling of the system to its environment. They can always be chosen to be traceless. The Hamiltonian HS not necessarily agrees with the Hamiltonian H S in Eq. ( 112). If the L's are made dimensionless, the quantities γ k &gt; 0 take on the dimensions of 1/time and represent relaxation rates for modes that decay over time in S. In practice the γ 's are given by correlation functions of the environment degrees of freedom.</p>
        <p>Special care needs to be taken if strong external fields are present (for oscillatory fields e.g. Floquet theory is invoked). Note that the time evolution implemented by Eq. ( 116) is irreversible, as sketched in Fig. 10 and we will show explicitly that entropy increases with time inside the small subsystem.Special care needs to be taken if strong external fields are present (for oscillatory fields e.g. Floquet theory is invoked). Note that the time evolution implemented by Eq. ( 116) is irreversible, as sketched in Fig. 10 and we will show explicitly that entropy increases with time inside the small subsystem.</p>
        <p>Formulating the dynamics of an OQS in terms of a Lindblad equation is of particular interest as it can be proven that the resulting time evolution preserves the fundamental properties of the reduced density matrix, i.e. positivity, Hermiticity and unitarityFormulating the dynamics of an OQS in terms of a Lindblad equation is of particular interest as it can be proven that the resulting time evolution preserves the fundamental properties of the reduced density matrix, i.e. positivity, Hermiticity and unitarity</p>
        <p>If the Lindblad operators L do not explicitly depend on time, the time evolution of a Heisenberg operator O(t) can be formulated by simply replacing σ S by O(t) in Eq. ( 116).If the Lindblad operators L do not explicitly depend on time, the time evolution of a Heisenberg operator O(t) can be formulated by simply replacing σ S by O(t) in Eq. ( 116).</p>
        <p>To understand the different types of approximations often invoked in the derivations of master equations in practice, it is instructive to consider a simple weakly coupled example. We will encounter three different timescales, whose hierarchy determines what kind of dynamics emerges. Considering H int = ∑ m Σ m ⊗ Ξ m in terms of operators in the environment Ξ m and the subsystem Σ m we have:To understand the different types of approximations often invoked in the derivations of master equations in practice, it is instructive to consider a simple weakly coupled example. We will encounter three different timescales, whose hierarchy determines what kind of dynamics emerges. Considering H int = ∑ m Σ m ⊗ Ξ m in terms of operators in the environment Ξ m and the subsystem Σ m we have:</p>
        <p>• τ E : the timescale along which correlations in the medium ⟨Ξ m (t)Ξ n (0)⟩ decay.• τ E : the timescale along which correlations in the medium ⟨Ξ m (t)Ξ n (0)⟩ decay.</p>
        <p>• τ S : intrinsic timescale of the evolution in the subsystem, defined by a typical value of neighboring frequencies contributing in the spectral decomposition τ S = |ω -ω ′ | -1 . • τ rel : the subsystem relaxation time, which e.g. for a single heavy particle subsystem is defined from the randomization timescale of its momentum ⟨p⟩(t) ∝ e -t/τ rel ⟨p⟩(0)• τ S : intrinsic timescale of the evolution in the subsystem, defined by a typical value of neighboring frequencies contributing in the spectral decomposition τ S = |ω -ω ′ | -1 . • τ rel : the subsystem relaxation time, which e.g. for a single heavy particle subsystem is defined from the randomization timescale of its momentum ⟨p⟩(t) ∝ e -t/τ rel ⟨p⟩(0)</p>
        <p>In the interaction picture, where Heisenberg operators evolve via the interaction Hamiltonian, let us consider the full density matrix written in integral form (s), σ tot (s)], (118) from which, assuming Tr E [[H int (t), σ tot (0)]] = 0, the evolution of the reduced density matrix follows asIn the interaction picture, where Heisenberg operators evolve via the interaction Hamiltonian, let us consider the full density matrix written in integral form (s), σ tot (s)], (118) from which, assuming Tr E [[H int (t), σ tot (0)]] = 0, the evolution of the reduced density matrix follows as</p>
        <p>] .] .</p>
        <p>((</p>
        <p>The first approximation made to simplify the equation of motion is the Born approximation, which amounts to a weak-coupling assumption between the system and environment leading toThe first approximation made to simplify the equation of motion is the Born approximation, which amounts to a weak-coupling assumption between the system and environment leading to</p>
        <p>Note that this approximation is less strict as may seem at first sight, since it does not automatically require that the d.o.f. of the environment or the medium themselves are weakly interacting. The next simplification, the Markovian approximation invokes a separation of timescales. If excitations of the environment decay much faster than what the dynamics of the subsystem resolves, we may replace σ S (s) by σ S (t). In addition, if the integrand decays appreciably for times s ≫ τ E we may also extend the integral boundary to infinity after taking s → ts. This leads to a master equation coarse grained in time of the formNote that this approximation is less strict as may seem at first sight, since it does not automatically require that the d.o.f. of the environment or the medium themselves are weakly interacting. The next simplification, the Markovian approximation invokes a separation of timescales. If excitations of the environment decay much faster than what the dynamics of the subsystem resolves, we may replace σ S (s) by σ S (t). In addition, if the integrand decays appreciably for times s ≫ τ E we may also extend the integral boundary to infinity after taking s → ts. This leads to a master equation coarse grained in time of the form</p>
        <p>In order to arrive at a Lindblad equation one often invokes another approximation, which involves the intrinsic time scale τ S . In order to see its role, one can introduce a spectral decomposition in terms of the system Hamiltonian H S , so thatIn order to arrive at a Lindblad equation one often invokes another approximation, which involves the intrinsic time scale τ S . In order to see its role, one can introduce a spectral decomposition in terms of the system Hamiltonian H S , so that</p>
        <p>) ,) ,</p>
        <p>wherewhere</p>
        <p>If τ rel ≫ τ E only the diagonal terms with ω = ω ′ contribute. This is called the rotating wave approximation. Further, decomposing Γ mn into a hermitean part S mn = (Γ mn -Γ * mn )/2i and the positive matrix γ mn = (Γ mn + Γ * mn ), the following master equation is obtainedIf τ rel ≫ τ E only the diagonal terms with ω = ω ′ contribute. This is called the rotating wave approximation. Further, decomposing Γ mn into a hermitean part S mn = (Γ mn -Γ * mn )/2i and the positive matrix γ mn = (Γ mn + Γ * mn ), the following master equation is obtained</p>
        <p>wherewhere</p>
        <p>Eq. ( 124) goes over into Lindblad form, if the matrix γ mn is diagonalized. This master equation is based on the separation of scales τ S ≪ τ rel , τ E ≪ τ rel the quantum optical limit.Eq. ( 124) goes over into Lindblad form, if the matrix γ mn is diagonalized. This master equation is based on the separation of scales τ S ≪ τ rel , τ E ≪ τ rel the quantum optical limit.</p>
        <p>((</p>
        <p>As a consistency check one can convince oneself that the late time limit of the above master equation is indeed the thermalAs a consistency check one can convince oneself that the late time limit of the above master equation is indeed the thermal</p>
        <p>While the above discussion provided an easily accessible example of the derivation of a microscopic master equation the underlying separation of timescales did not apply to quarkonium. Indeed, due to the large rest mass of the constituent quarks we expect that the intrinsic dynamics of the subsystem are actually slow compared to that of the medium. In this case the Markovian approximation may hold but the following separation of scales is considered τ E ≪ τ S , τ E ≪ τ rel the quantum Brownian motion limit, (126) i.e. the rotating wave approximation may not apply.While the above discussion provided an easily accessible example of the derivation of a microscopic master equation the underlying separation of timescales did not apply to quarkonium. Indeed, due to the large rest mass of the constituent quarks we expect that the intrinsic dynamics of the subsystem are actually slow compared to that of the medium. In this case the Markovian approximation may hold but the following separation of scales is considered τ E ≪ τ S , τ E ≪ τ rel the quantum Brownian motion limit, (126) i.e. the rotating wave approximation may not apply.</p>
        <p>A well known model of Markovian quantum Brownian motion is the Caldeira-Leggett model at high temperature. In this model a (heavy) point particle is coupled to a bath consisting of a large number (eventually infinitely many) of light harmonic oscillators. It thus represents a very crude but intuitive analogy for a heavy quark. The model Hamiltonian readsA well known model of Markovian quantum Brownian motion is the Caldeira-Leggett model at high temperature. In this model a (heavy) point particle is coupled to a bath consisting of a large number (eventually infinitely many) of light harmonic oscillators. It thus represents a very crude but intuitive analogy for a heavy quark. The model Hamiltonian reads</p>
        <p>))</p>
        <p>,,</p>
        <p>Here the creation and annihilation operators of the harmonic oscillators with mass m n and frequency ν n are denoted by b n and b † n . A linear interaction term between the point particle and the environment is used. If continuous reservoir modes are considered, the interactions lead to a renormalization of the potential. This effect is compensated by adding to theHere the creation and annihilation operators of the harmonic oscillators with mass m n and frequency ν n are denoted by b n and b † n . A linear interaction term between the point particle and the environment is used. If continuous reservoir modes are considered, the interactions lead to a renormalization of the potential. This effect is compensated by adding to the</p>
        <p>The derivation of the master equation at first proceeds very similarly, invoking the Born and Markov approximations.The derivation of the master equation at first proceeds very similarly, invoking the Born and Markov approximations.</p>
        <p>In this model we assume that the particle is immersed in a heat bath of temperatureIn this model we assume that the particle is immersed in a heat bath of temperature</p>
        <p>We had seen that correlation functions of the medium d.o.f. play an important role, which motivates introducing the following thermally averaged commutator and anti-commutatorWe had seen that correlation functions of the medium d.o.f. play an important role, which motivates introducing the following thermally averaged commutator and anti-commutator</p>
        <p>which are known as the dissipation and noise kernel respectively. All the information about the medium in this model is encoded in the two kernel functions, which may be written in terms of the bath spectral densitywhich are known as the dissipation and noise kernel respectively. All the information about the medium in this model is encoded in the two kernel functions, which may be written in terms of the bath spectral density</p>
        <p>The equation of motion so far takes the formThe equation of motion so far takes the form</p>
        <p>) .) .</p>
        <p>((</p>
        <p>We are interested in a reservoir with infinitely many d.o.f. in order to observe genuine damping of modes. Thus we will consider the continuous counterpart of J(ω), whose ω dependence is determined from the particular form of the interactions κ n . An analytically solvable case is obtained with the following model ansatzWe are interested in a reservoir with infinitely many d.o.f. in order to observe genuine damping of modes. Thus we will consider the continuous counterpart of J(ω), whose ω dependence is determined from the particular form of the interactions κ n . An analytically solvable case is obtained with the following model ansatz</p>
        <p>Here the small frequency regime behaves linear, modeling an Ohmic damping of modes in the subsystem with damping constant γ . The high frequency regime on the other hand is regularized by a cutoff function. Let us push the analogy with QCD a bit further at this point. Since the coupling of the heavy quark to the bath occurs via gluons, the spectral density considered above will be linked to a gluon spectral function, while the kernels D and D 1 are the corresponding gluon correlators. In case of quarkonium it will turn out that since the gluon correlators at high temperature are also the building blocks to describe the real-and imaginary part of the in-medium heavy quark potential, D and D 1 are intimately related to Im[V ].Here the small frequency regime behaves linear, modeling an Ohmic damping of modes in the subsystem with damping constant γ . The high frequency regime on the other hand is regularized by a cutoff function. Let us push the analogy with QCD a bit further at this point. Since the coupling of the heavy quark to the bath occurs via gluons, the spectral density considered above will be linked to a gluon spectral function, while the kernels D and D 1 are the corresponding gluon correlators. In case of quarkonium it will turn out that since the gluon correlators at high temperature are also the building blocks to describe the real-and imaginary part of the in-medium heavy quark potential, D and D 1 are intimately related to Im[V ].</p>
        <p>The master equation Eq. ( 131) can be further simplified by invoking the time scale separation of Brownian motion. In case of the model spectral density J(ω) the decay of the kernel functions contains contributions from all finite Matsubara frequencies ω n = 2π nT with n &gt; 0 up to the UV cutoff Λ UV . I.e. the medium relaxation scale is given by τThe master equation Eq. ( 131) can be further simplified by invoking the time scale separation of Brownian motion. In case of the model spectral density J(ω) the decay of the kernel functions contains contributions from all finite Matsubara frequencies ω n = 2π nT with n &gt; 0 up to the UV cutoff Λ UV . I.e. the medium relaxation scale is given by τ</p>
        <p>. Instead of the rotating wave approximation, we consider here the case that the typical timescale of the system is much larger than that of the medium.. Instead of the rotating wave approximation, we consider here the case that the typical timescale of the system is much larger than that of the medium.</p>
        <p>Carefully evaluating all expressions in Eq. ( 131) under τ E ≪ τ S one arrives at the Caldeira-Leggett master equationCarefully evaluating all expressions in Eq. ( 131) under τ E ≪ τ S one arrives at the Caldeira-Leggett master equation</p>
        <p>The von-Neumann like term describes the coherent dynamics of the subsystem similar to when no environment is present.The von-Neumann like term describes the coherent dynamics of the subsystem similar to when no environment is present.</p>
        <p>The second term arises from the contributions associated with the function D and encodes dissipation of energy from the system to the medium. Its strength is governed by the damping rate γ that enters J. The effects of thermal fluctuations on the other hand are encoded in the third term related to D 1 . At this stage the master equation is not in Lindblad form but it can be made such by adding a term that is parametrically small at high temperatures -The second term arises from the contributions associated with the function D and encodes dissipation of energy from the system to the medium. Its strength is governed by the damping rate γ that enters J. The effects of thermal fluctuations on the other hand are encoded in the third term related to D 1 . At this stage the master equation is not in Lindblad form but it can be made such by adding a term that is parametrically small at high temperatures -</p>
        <p>In order for fluctuations and dissipation to work in tandem it makes sense that γ will appear also in the noise related terms. This yields a Lindblad master equation with a single relaxation rate γ and the Lindblad operatorIn order for fluctuations and dissipation to work in tandem it makes sense that γ will appear also in the noise related terms. This yields a Lindblad master equation with a single relaxation rate γ and the Lindblad operator</p>
        <p>We will find Lindblad operators of similar form when considering heavy quarks and heavy quarkonium in QCD. Note that in the open quantum systems literature one will often consider instead the so called collapse operators C n = √ γ n L n , which incorporate the relaxation rate.We will find Lindblad operators of similar form when considering heavy quarks and heavy quarkonium in QCD. Note that in the open quantum systems literature one will often consider instead the so called collapse operators C n = √ γ n L n , which incorporate the relaxation rate.</p>
        <p>Let us briefly list the Ehrenfest equations of motion for position and momentum of the heavy particle in this modelLet us briefly list the Ehrenfest equations of motion for position and momentum of the heavy particle in this model</p>
        <p>For a free particle we findFor a free particle we find</p>
        <p>so that the average momentum relaxes to zero exponentially with a rate of 2γ and the average position at late times is displaced by the value ⟨ẋ(0)⟩/2γ .so that the average momentum relaxes to zero exponentially with a rate of 2γ and the average position at late times is displaced by the value ⟨ẋ(0)⟩/2γ .</p>
        <p>While already much closer to the case of quarkonium, the Caldeira-Leggett model also does not in general accommodate its physics, since the above derivation assumes that the extent of the heavy particle is always smaller than the correlation length of the medium. Since quarkonium possesses an internal structure, its radius can however easily be of the same order or larger than the medium correlation length in practice.While already much closer to the case of quarkonium, the Caldeira-Leggett model also does not in general accommodate its physics, since the above derivation assumes that the extent of the heavy particle is always smaller than the correlation length of the medium. Since quarkonium possesses an internal structure, its radius can however easily be of the same order or larger than the medium correlation length in practice.</p>
        <p>In practice we will often encounter the situation where the medium d.o.f. are formulated in terms of a path integral. Feynman and Vernon [147] developed a systematic treatment of how to derive the system-medium interactions in such a case. Consider the expression for the density matrix evolution on the Schwinger-Keldysh contour, where we denote the d.o.f. in the environment with capital letters, those in the subsystem with lowercase lettersIn practice we will often encounter the situation where the medium d.o.f. are formulated in terms of a path integral. Feynman and Vernon [147] developed a systematic treatment of how to derive the system-medium interactions in such a case. Consider the expression for the density matrix evolution on the Schwinger-Keldysh contour, where we denote the d.o.f. in the environment with capital letters, those in the subsystem with lowercase letters</p>
        <p>The forward path houses the x, X d.o.f., while the backward path contains y, Y . The trace operation over the environment in the language of functional integrals is implemented by integrating over X and Y and inserting a delta function, assumingThe forward path houses the x, X d.o.f., while the backward path contains y, Y . The trace operation over the environment in the language of functional integrals is implemented by integrating over X and Y and inserting a delta function, assuming</p>
        <p>The Feynman-Vernon influence functional F [x, y] together with the subsystem action S S encodes all the information on the subsystem and its interaction with the medium, required to construct a master equation. It can equally well be written as an effective action contribution in the path integral weightThe Feynman-Vernon influence functional F [x, y] together with the subsystem action S S encodes all the information on the subsystem and its interaction with the medium, required to construct a master equation. It can equally well be written as an effective action contribution in the path integral weight</p>
        <p>When expressing the time evolution of the reduced density matrix in terms of its Greens functionWhen expressing the time evolution of the reduced density matrix in terms of its Greens function</p>
        <p>we can read off its path integral representation. The challenge in practice then lies in reverse engineering the operator expressions for the corresponding equation of motion for σ S starting from the c-number valued path integral. It is the inverse operation to the original construction of the path integral starting from the Greens function for an individual wavefunction. A similar task exists in lattice QCD studies, where the Hamilton operator for a lattice discretized path integral is constructed via the so called transfer matrix. For the Caldeira-Leggett model, the Feynman-Vernon influence functional has been considered in [148].we can read off its path integral representation. The challenge in practice then lies in reverse engineering the operator expressions for the corresponding equation of motion for σ S starting from the c-number valued path integral. It is the inverse operation to the original construction of the path integral starting from the Greens function for an individual wavefunction. A similar task exists in lattice QCD studies, where the Hamilton operator for a lattice discretized path integral is constructed via the so called transfer matrix. For the Caldeira-Leggett model, the Feynman-Vernon influence functional has been considered in [148].</p>
        <p>After having gained some insight into the description of open quantum systems via Lindblad type master equations we turn our attention to one of the characteristic phenomena occurring in open quantum systems: Decoherence. Whenever our subsystem evolves in contact with its environment, correlations among the d.o.f. arise. Very often this leads to a particular behavior in the subsystem, once the environment is traced out. I.e. certain sets of states in S are singled out by the interaction, the so called preferred basis, which in turn remain stable under time evolution. Any superpositions of these states on the other hand are damped away. The timescale of this damping τ D is often much shorter than the intrinsic timescales of the subsystem. Decoherence in the context of heavy quarkonium will often be found to be accompanied by a decay of populations of states but in general such decay is not necessarily a byproduct of decoherence.After having gained some insight into the description of open quantum systems via Lindblad type master equations we turn our attention to one of the characteristic phenomena occurring in open quantum systems: Decoherence. Whenever our subsystem evolves in contact with its environment, correlations among the d.o.f. arise. Very often this leads to a particular behavior in the subsystem, once the environment is traced out. I.e. certain sets of states in S are singled out by the interaction, the so called preferred basis, which in turn remain stable under time evolution. Any superpositions of these states on the other hand are damped away. The timescale of this damping τ D is often much shorter than the intrinsic timescales of the subsystem. Decoherence in the context of heavy quarkonium will often be found to be accompanied by a decay of populations of states but in general such decay is not necessarily a byproduct of decoherence.</p>
        <p>The dynamics of decoherence is often characterized by the so-called decoherence function Γ , which describes the decay of the off-diagonal entries of the reduced density matrix, expressed in the preferred basis. Let us consider the particularly chosen interactionThe dynamics of decoherence is often characterized by the so-called decoherence function Γ , which describes the decay of the off-diagonal entries of the reduced density matrix, expressed in the preferred basis. Let us consider the particularly chosen interaction</p>
        <p>Due to unitarity, the norm of ⟨φ m (t)|φ m (t)⟩ = 1 is preserved and the diagonal entries of σ S remain constant. I.e. only the off-diagonal terms are affected by the evolution and we may define the decoherence function Γ mn viaDue to unitarity, the norm of ⟨φ m (t)|φ m (t)⟩ = 1 is preserved and the diagonal entries of σ S remain constant. I.e. only the off-diagonal terms are affected by the evolution and we may define the decoherence function Γ mn via</p>
        <p>whose values are of course highly dependent on the system parameters and also the choice of initial state. The typical timescale over which the overlap ⟨φ n (t)|φ m (t)⟩ decreases is denoted by τ D the decoherence time. If the overlap approaches zero, the reduced density matrix takes on the form of an incoherent mixture of the states |m⟩. We can consider the linear entropywhose values are of course highly dependent on the system parameters and also the choice of initial state. The typical timescale over which the overlap ⟨φ n (t)|φ m (t)⟩ decreases is denoted by τ D the decoherence time. If the overlap approaches zero, the reduced density matrix takes on the form of an incoherent mixture of the states |m⟩. We can consider the linear entropy</p>
        <p>] in the subsystem, which starts out as S l [σ S (0)] = 0 but evolves to] in the subsystem, which starts out as S l [σ S (0)] = 0 but evolves to</p>
        <p>approaching at late timesapproaching at late times</p>
        <p>One interesting effect of decoherence is the localization of the states in position space, which occurs e.g. in quantum Brownian motion at high temperature. Neglecting the effects of dissipation, i.e. taking the recoilless limit, let us consider the master equationOne interesting effect of decoherence is the localization of the states in position space, which occurs e.g. in quantum Brownian motion at high temperature. Neglecting the effects of dissipation, i.e. taking the recoilless limit, let us consider the master equation</p>
        <p>with a simple H S = p 2 /2m. It turns out that the decay of the off-diagonals occurs much faster than the evolution of the diagonals and the free part, hence we may neglect the H S contribution and solve approximatelywith a simple H S = p 2 /2m. It turns out that the decay of the off-diagonals occurs much faster than the evolution of the diagonals and the free part, hence we may neglect the H S contribution and solve approximately</p>
        <p>The resulting decoherence function, which damps away off-diagonal terms in position space, is linear in time and we can read off the corresponding decoherence timeThe resulting decoherence function, which damps away off-diagonal terms in position space, is linear in time and we can read off the corresponding decoherence time</p>
        <p>It remains to get an impression of how the decoherence time relates to the relaxation time of the subsystem. The latter is defined from the relaxation of the square of the momentum, which from the Ehrenfest e.o.m. is τ rel = 1/4γ . Expressed in the thermal wavelength of the medium λ th = h/ √ 2mk B T we then findIt remains to get an impression of how the decoherence time relates to the relaxation time of the subsystem. The latter is defined from the relaxation of the square of the momentum, which from the Ehrenfest e.o.m. is τ rel = 1/4γ . Expressed in the thermal wavelength of the medium λ th = h/ √ 2mk B T we then find</p>
        <p>which especially for macroscopic objects can be an extremely small ratio.which especially for macroscopic objects can be an extremely small ratio.</p>
        <p>In order to observe the phenomenon of decoherence and its consequences in practice, i.e. in realistic systems such as quarkonium, a numerical implementation of the Lindblad equation is required. On the one hand one could attack the problem head on and setup a simulation of ⟨x|σ S |y⟩ in coordinate space and discretize the resulting partial differential equation. In three dimensions this leads to a six dimensional matrix equation which is computationally very demanding.In order to observe the phenomenon of decoherence and its consequences in practice, i.e. in realistic systems such as quarkonium, a numerical implementation of the Lindblad equation is required. On the one hand one could attack the problem head on and setup a simulation of ⟨x|σ S |y⟩ in coordinate space and discretize the resulting partial differential equation. In three dimensions this leads to a six dimensional matrix equation which is computationally very demanding.</p>
        <p>On the other hand one can unravel Eq. ( 116) into the stochastic evolution of an ensemble of wavefunctions |ψ(t)⟩ whose fluctuations allow us to reconstruct the density matrix σ S = ⟨|ψ(t)⟩⟨ψ(t)|⟩ ensemble . (147) In that case one has to deal with the evolution of three-dimensional wavefunctions only. It is important to note that the time evolution described by Eq. ( 116) in general cannot be unraveled in terms of a deterministic Schrödinger equation. Introducing a gradient expansion it may be possible to unravel it into unitary and linear time evolution of a wavefunction with stochastic noise contributions. For the full dynamics, the Quantum State Diffusion (QSD) approach has proven to be an important tool [149]. It tells us that in general to unravel any Lindblad master equation the following non-linear stochastic Schrödinger equation can be consideredOn the other hand one can unravel Eq. ( 116) into the stochastic evolution of an ensemble of wavefunctions |ψ(t)⟩ whose fluctuations allow us to reconstruct the density matrix σ S = ⟨|ψ(t)⟩⟨ψ(t)|⟩ ensemble . (147) In that case one has to deal with the evolution of three-dimensional wavefunctions only. It is important to note that the time evolution described by Eq. ( 116) in general cannot be unraveled in terms of a deterministic Schrödinger equation. Introducing a gradient expansion it may be possible to unravel it into unitary and linear time evolution of a wavefunction with stochastic noise contributions. For the full dynamics, the Quantum State Diffusion (QSD) approach has proven to be an important tool [149]. It tells us that in general to unravel any Lindblad master equation the following non-linear stochastic Schrödinger equation can be considered</p>
        <p>The stochastic nature of the evolution is implemented via complex valued Gaussian noise of the formThe stochastic nature of the evolution is implemented via complex valued Gaussian noise of the form</p>
        <p>Re(dξ i )Re(dξ j )Re(dξ i )Re(dξ j )</p>
        <p>The non-linearity on the other hand arises from the fact that in terms such as ⟨L m ⟩ ψ the expectation value with respect to the wavefunction is computed. Once the Lindblad operators are specified the above prescription offers a straight forward recipe for implementation of numerical simulations.The non-linearity on the other hand arises from the fact that in terms such as ⟨L m ⟩ ψ the expectation value with respect to the wavefunction is computed. Once the Lindblad operators are specified the above prescription offers a straight forward recipe for implementation of numerical simulations.</p>
        <p>Summary. The open quantum systems approach considers systems, which can be decomposed in a small subsystem S and a large environment E and thus naturally accommodates in-medium quarkonium. By tracing out the medium degrees of freedom a simplified description of the irreversible dynamics of the subsystem is developed, formulated as a master equation for the reduced density matrix σ S . Interactions between S and E induce correlations in their d.o.f. which leads to the phenomenon of decoherence in the subsystem. A set of preferred basis states remains stable but superpositions are damped away. Exploiting a separation of time scales between the subsystem and the medium τ E ≪ τ rel Markovian master equations in the Lindblad form can be derived, which preserve the positivity and Hermiticity of the reduced density matrix.Summary. The open quantum systems approach considers systems, which can be decomposed in a small subsystem S and a large environment E and thus naturally accommodates in-medium quarkonium. By tracing out the medium degrees of freedom a simplified description of the irreversible dynamics of the subsystem is developed, formulated as a master equation for the reduced density matrix σ S . Interactions between S and E induce correlations in their d.o.f. which leads to the phenomenon of decoherence in the subsystem. A set of preferred basis states remains stable but superpositions are damped away. Exploiting a separation of time scales between the subsystem and the medium τ E ≪ τ rel Markovian master equations in the Lindblad form can be derived, which preserve the positivity and Hermiticity of the reduced density matrix.</p>
        <p>Simulating the time evolution often involves unraveling of the master equation in terms of the stochastic evolution of an ensemble of wavefunctions. The quantum state diffusion method provides a straight forward implementation.Simulating the time evolution often involves unraveling of the master equation in terms of the stochastic evolution of an ensemble of wavefunctions. The quantum state diffusion method provides a straight forward implementation.</p>
        <p>Our exploration of heavy quarkonium in extreme conditions begins with its physics in thermal equilibrium. Here the quark-anti-quark pair is immersed into an infinitely extended QCD medium at a constant temperature T (and in this report we restrict to vanishing Baryo-chemical potential µ B = 0). The advantage of investigating such an idealized scenario is that quantum field theoretical methods, such as lattice QCD, are capable of providing direct non-perturbative insight from first principles. I.e. no modeling assumptions need to be made. We may learn about various aspects of in-medium heavy quarkonium, which will support the analysis of its physics in more complicated and experimentally relevant scenarios, such as in relativistic heavy ion collisions.Our exploration of heavy quarkonium in extreme conditions begins with its physics in thermal equilibrium. Here the quark-anti-quark pair is immersed into an infinitely extended QCD medium at a constant temperature T (and in this report we restrict to vanishing Baryo-chemical potential µ B = 0). The advantage of investigating such an idealized scenario is that quantum field theoretical methods, such as lattice QCD, are capable of providing direct non-perturbative insight from first principles. I.e. no modeling assumptions need to be made. We may learn about various aspects of in-medium heavy quarkonium, which will support the analysis of its physics in more complicated and experimentally relevant scenarios, such as in relativistic heavy ion collisions.</p>
        <p>In the following we will assume that enough time has passed so that the momentum distribution of the individual quarks has fully equilibrated, becoming Fermi-Dirac distributed. At very high energies T ≫ 2m Q heavy quark pairs may be spontaneously created from thermal fluctuations, i.e. their occupation number also follows the thermal distribution. The system is said to be chemically equilibrated. Since E bind &lt; m Q for quarkonium, one does not expect stable bound states to exist in this regime. On the other hand at lower temperatures E bind &gt; T where quarkonium may survive, the thermal occupancy for heavy quarks is very low. If we consider a Q Q in this regime, some other process must have produced it and placed it in the medium. I.e. the system is kinetically but not chemically equilibrated. Such settings are commonly considered today, as they are the idealized counterpart to a heavy-ion collision, where it is the hard partonic processes in the early stages that create a quark-antiquark pair, which subsequently finds itself surrounded by the hot bulk matter.In the following we will assume that enough time has passed so that the momentum distribution of the individual quarks has fully equilibrated, becoming Fermi-Dirac distributed. At very high energies T ≫ 2m Q heavy quark pairs may be spontaneously created from thermal fluctuations, i.e. their occupation number also follows the thermal distribution. The system is said to be chemically equilibrated. Since E bind &lt; m Q for quarkonium, one does not expect stable bound states to exist in this regime. On the other hand at lower temperatures E bind &gt; T where quarkonium may survive, the thermal occupancy for heavy quarks is very low. If we consider a Q Q in this regime, some other process must have produced it and placed it in the medium. I.e. the system is kinetically but not chemically equilibrated. Such settings are commonly considered today, as they are the idealized counterpart to a heavy-ion collision, where it is the hard partonic processes in the early stages that create a quark-antiquark pair, which subsequently finds itself surrounded by the hot bulk matter.</p>
        <p>The central goal will be to understand how the binding properties of quarkonium vacuum states are altered in the presence of a thermal medium. We will explore this question from several angles: screening of color fields in thermal QCD, the modification of binding in terms of an in-medium potential and the manifestation of binding in the spectral properties of quarkonium states. On the way we will learn to connect the weakening of interquark binding to the concept of a Debye mass and eventually consider what the insight of the past decade tells us about the dynamical process of quarkonium melting.The central goal will be to understand how the binding properties of quarkonium vacuum states are altered in the presence of a thermal medium. We will explore this question from several angles: screening of color fields in thermal QCD, the modification of binding in terms of an in-medium potential and the manifestation of binding in the spectral properties of quarkonium states. On the way we will learn to connect the weakening of interquark binding to the concept of a Debye mass and eventually consider what the insight of the past decade tells us about the dynamical process of quarkonium melting.</p>
        <p>Heavy quarkonium bound states in vacuum are sustained by an exchange of gluons among the constituent charm or bottom quarks. Since the heavy quark velocities are small, it is expected that color electric interactions dominate over color magnetic ones. If immersed into a thermal QCD medium, the exchanged gluons will interact with the medium d.o.f. and their properties become modified. In analogy with electromagnetically interacting media (see e.g. Debye-Hückel theory [150]) it is furthermore expected that this leads to a weakening of the strength of binding. Our goal in this section is thus to gain an understanding of how the medium influences the propagation of QCD color fields. Note that at this point we are asking about a property of the medium and not yet one of the quarkonium system.Heavy quarkonium bound states in vacuum are sustained by an exchange of gluons among the constituent charm or bottom quarks. Since the heavy quark velocities are small, it is expected that color electric interactions dominate over color magnetic ones. If immersed into a thermal QCD medium, the exchanged gluons will interact with the medium d.o.f. and their properties become modified. In analogy with electromagnetically interacting media (see e.g. Debye-Hückel theory [150]) it is furthermore expected that this leads to a weakening of the strength of binding. Our goal in this section is thus to gain an understanding of how the medium influences the propagation of QCD color fields. Note that at this point we are asking about a property of the medium and not yet one of the quarkonium system.</p>
        <p>Consideration of limiting cases, whether physical or not, is a central tool of the physicist toolbox to explore the logical consequences of hypotheses. In classical electrodynamics the idealized concept of a test charge plays an important role to shed light on field configurations and their modification in medium. In the study of QCD a similar role is taken up by considering infinitely heavy quarks. We have already seen in Eq. (58) that in this static limit the propagation of a quark in time reduces simply to a change in its SU(3) color, given by a temporal Wilson line. The spatial position of the quark is obviously fixed.Consideration of limiting cases, whether physical or not, is a central tool of the physicist toolbox to explore the logical consequences of hypotheses. In classical electrodynamics the idealized concept of a test charge plays an important role to shed light on field configurations and their modification in medium. In the study of QCD a similar role is taken up by considering infinitely heavy quarks. We have already seen in Eq. (58) that in this static limit the propagation of a quark in time reduces simply to a change in its SU(3) color, given by a temporal Wilson line. The spatial position of the quark is obviously fixed.</p>
        <p>In QED, screening properties of static electric and magnetic fields are well understood in a gauge invariant manner. The gluons responsible for sustaining the electric field acquire a mass from interactions with the medium. For a medium of fermions with charge e this leads to an electric photon self energy In QCD on the other hand screening is more involved, as is discussed in detail in Ref. [151]. The first stumbling block is that the concept of color electric and magnetic fields is not gauge invariant anymore. So a simple inspection of gluon self energies does not lead to an unambiguous concept of electric or magnetic screening, as one component can be rotated into another. Instead one has to define adequate gauge invariant quantities, whose symmetry properties agree with the symmetries associated with an electric and magnetic field.In QED, screening properties of static electric and magnetic fields are well understood in a gauge invariant manner. The gluons responsible for sustaining the electric field acquire a mass from interactions with the medium. For a medium of fermions with charge e this leads to an electric photon self energy In QCD on the other hand screening is more involved, as is discussed in detail in Ref. [151]. The first stumbling block is that the concept of color electric and magnetic fields is not gauge invariant anymore. So a simple inspection of gluon self energies does not lead to an unambiguous concept of electric or magnetic screening, as one component can be rotated into another. Instead one has to define adequate gauge invariant quantities, whose symmetry properties agree with the symmetries associated with an electric and magnetic field.</p>
        <p>It turns out that at asymptotically high temperatures, where QCD is weakly coupled, color electric fields are screened at a scale gT , where g is the strong coupling. I.e. there exists a QCD counterpart to the Debye mass, which at leading order scales as m D ∼ gT . In contrast to QED, magnetic fields also become screened at a lower energy scale m M ∼ g 2 T but the physics of this magnetic screening is fully non-perturbative even at high temperatures. The underlying reason is the so called perturbative infrared catastrophe affecting non-Abelian Gauge theories, discovered in Ref. [152] and beautifully resolved through the construction of the dimensionally reduced effective field theories electric QCD (EQCD) and the fully non-perturbative magnetic QCD (MQCD) in Ref. [153]. Not only is m M not accessible via perturbative means but also m D receives non-perturbative contributions beyond the first logarithmic correction that itself can be evaluated in perturbation theory. The general result for SU(N c ) gauge theory with N f active fermion flavors in the medium given in Ref. [154,155] readsIt turns out that at asymptotically high temperatures, where QCD is weakly coupled, color electric fields are screened at a scale gT , where g is the strong coupling. I.e. there exists a QCD counterpart to the Debye mass, which at leading order scales as m D ∼ gT . In contrast to QED, magnetic fields also become screened at a lower energy scale m M ∼ g 2 T but the physics of this magnetic screening is fully non-perturbative even at high temperatures. The underlying reason is the so called perturbative infrared catastrophe affecting non-Abelian Gauge theories, discovered in Ref. [152] and beautifully resolved through the construction of the dimensionally reduced effective field theories electric QCD (EQCD) and the fully non-perturbative magnetic QCD (MQCD) in Ref. [153]. Not only is m M not accessible via perturbative means but also m D receives non-perturbative contributions beyond the first logarithmic correction that itself can be evaluated in perturbation theory. The general result for SU(N c ) gauge theory with N f active fermion flavors in the medium given in Ref. [154,155] reads</p>
        <p>where κ already escapes perturbative evaluation.where κ already escapes perturbative evaluation.</p>
        <p>There are currently two main approaches found in the literature to define and determine screening masses in QCD nonperturbatively. Both rely on considering static quarks as test color charges and deploy specifically constructed correlation functions between such a static quark and antiquark pair to reveal how their interactions are damped when the spatial distance between them is increased. Interestingly the intimate relation between Euclidean QFT at finite temperature and statistical physics allows us to connect the evolution of static quarks in imaginary time to a thermodynamic property of the system, its free energy. One may ask how a genuinely gauge dependent concept, such as a color phase rotation can lead to a gauge invariant thermodynamic quantity. As it turns out the compactness of the imaginary time axis plays a key role.There are currently two main approaches found in the literature to define and determine screening masses in QCD nonperturbatively. Both rely on considering static quarks as test color charges and deploy specifically constructed correlation functions between such a static quark and antiquark pair to reveal how their interactions are damped when the spatial distance between them is increased. Interestingly the intimate relation between Euclidean QFT at finite temperature and statistical physics allows us to connect the evolution of static quarks in imaginary time to a thermodynamic property of the system, its free energy. One may ask how a genuinely gauge dependent concept, such as a color phase rotation can lead to a gauge invariant thermodynamic quantity. As it turns out the compactness of the imaginary time axis plays a key role.</p>
        <p>Let us recall how the free energy is connected to static quark propagation, as first discussed in Ref. [156]. The free energies F (x 1 , . . . , x n , x n+1 , . . . , x n+m ) of a system with n static quarks and m antiquarks present, located at positions x i may be related to the partition function viaLet us recall how the free energy is connected to static quark propagation, as first discussed in Ref. [156]. The free energies F (x 1 , . . . , x n , x n+1 , . . . , x n+m ) of a system with n static quarks and m antiquarks present, located at positions x i may be related to the partition function via</p>
        <p>Here the states |s⟩ are those that contain both the medium degrees of freedom and the static quarks and |q⟩ only refer to the medium. Using the fact that e -βH is the generator of imaginary time translations and that these time translations only change the affected fields by a color rotation, we may writeHere the states |s⟩ are those that contain both the medium degrees of freedom and the static quarks and |q⟩ only refer to the medium. Using the fact that e -βH is the generator of imaginary time translations and that these time translations only change the affected fields by a color rotation, we may write</p>
        <p>The above expression is written in terms of the color trace of the Polyakov loopThe above expression is written in terms of the color trace of the Polyakov loop</p>
        <p>which on the lattice is given by a product of links in imaginary time direction closing around the compact Euclidean domain. Note that if the color trace is taken Tr c L is indeed is gauge invariant. The Polyakov loop is hence related to the free energy of a single quark in the medium. It is furthermore the order parameter of the SU(3) center symmetry and in the absence of light quark degrees of freedom ⟨L⟩ in turn takes the role of an order parameter for the, in that case well defined, confinement-deconfinement phase transition. In QCD with dynamical fermions the change of the Polyakov loop with temperature still provides a clear signal for the crossover transition from hadrons to the quark-gluon-plasma.which on the lattice is given by a product of links in imaginary time direction closing around the compact Euclidean domain. Note that if the color trace is taken Tr c L is indeed is gauge invariant. The Polyakov loop is hence related to the free energy of a single quark in the medium. It is furthermore the order parameter of the SU(3) center symmetry and in the absence of light quark degrees of freedom ⟨L⟩ in turn takes the role of an order parameter for the, in that case well defined, confinement-deconfinement phase transition. In QCD with dynamical fermions the change of the Polyakov loop with temperature still provides a clear signal for the crossover transition from hadrons to the quark-gluon-plasma.</p>
        <p>In order to get access to the free energies on the lattice, we need to rewrite Eq. ( 154) in terms of an actual expectation value, i.e. we need to normalize by the partition function of the medium without quarks present. Hence we compute the difference ∆F n,m = F n,m -F 0,0 in the free energy between a system with and without the static quarks presentIn order to get access to the free energies on the lattice, we need to rewrite Eq. ( 154) in terms of an actual expectation value, i.e. we need to normalize by the partition function of the medium without quarks present. Hence we compute the difference ∆F n,m = F n,m -F 0,0 in the free energy between a system with and without the static quarks present</p>
        <p>The main interest in this section lies in the interactions between one static quark and one antiquark, i.e. we consider the spatial correlations of a Polyakov loop and its complex conjugated counterpartThe main interest in this section lies in the interactions between one static quark and one antiquark, i.e. we consider the spatial correlations of a Polyakov loop and its complex conjugated counterpart</p>
        <p>We may understand the corresponding free energy as encoding (after proper renormalization) the amount of work that is required to pull apart the quark-anti-quark pair to a distance r. At very large distances the correlator P 2 will go over into a constant, given by the expectation value of a single Polyakov loop squared. In pure gauge theory at low temperatures this quantity diverges as color confinement prevents the separation of the two static quarks. In QCD with dynamical fermions the phenomenon of string breaking occurs even in vacuum, where the energy stored in the color field between the static quarks is transformed into a light quark-antiquark pair, which in turn forms a color neutral state with the static color sources.We may understand the corresponding free energy as encoding (after proper renormalization) the amount of work that is required to pull apart the quark-anti-quark pair to a distance r. At very large distances the correlator P 2 will go over into a constant, given by the expectation value of a single Polyakov loop squared. In pure gauge theory at low temperatures this quantity diverges as color confinement prevents the separation of the two static quarks. In QCD with dynamical fermions the phenomenon of string breaking occurs even in vacuum, where the energy stored in the color field between the static quarks is transformed into a light quark-antiquark pair, which in turn forms a color neutral state with the static color sources.</p>
        <p>Let us consider the first strategy for defining and extracting the QCD screening masses. It relies on the work of Ref. [151], where it has been shown that transformation properties under Euclidean time reversal R and charge conjugation C allow one to make the distinction between color electric and magnetic operators in a non-perturbative fashion. In short, an operator even (odd) under R is considered to be magnetic (electric). The large distance spatial decay of correlators of such operators are expected to reveal the corresponding magnetic (electric) screening masses. This concept has already been used to study QCD at very high temperature (remember that even there magnetic screening is nonperturbative) using the dimensionally reduced effective field theory EQCD in Ref. [157]. We will now discuss how it can be used in the study of screening in fully dynamical lattice QCD.Let us consider the first strategy for defining and extracting the QCD screening masses. It relies on the work of Ref. [151], where it has been shown that transformation properties under Euclidean time reversal R and charge conjugation C allow one to make the distinction between color electric and magnetic operators in a non-perturbative fashion. In short, an operator even (odd) under R is considered to be magnetic (electric). The large distance spatial decay of correlators of such operators are expected to reveal the corresponding magnetic (electric) screening masses. This concept has already been used to study QCD at very high temperature (remember that even there magnetic screening is nonperturbative) using the dimensionally reduced effective field theory EQCD in Ref. [157]. We will now discuss how it can be used in the study of screening in fully dynamical lattice QCD.</p>
        <p>Ref. [151] first pointed out that since the Polyakov loop as written in Eq. ( 155) does not have well defined transformation properties under Euclidean time reversal RL = L † and charge conjugation CL = L * it mixes both color electric and color magnetic contributions. If its correlator, i.e. the free energy difference ∆F 1,1 (r) shows exponential decay at large distances it is most probably dominated by the magnetic screening mass m M &lt; m E , as electric contributions have already died out before. Note that if we wish to connect the electric screening mass obtained in that fashion to the perturbatively defined concept of Debye mass we will have to divide with a factor two. The reason is that at small distances perturbation theory tells us [158] that ∆F 1,1 (r) is dominated by two-gluon exchange. In turn a -α 2 S exp(-2m D r)/r 2 behavior arises, from which we take it that the screening masses found from such traced out Polyakov loop correlators will represent twice the value of the corresponding gluon mass.Ref. [151] first pointed out that since the Polyakov loop as written in Eq. ( 155) does not have well defined transformation properties under Euclidean time reversal RL = L † and charge conjugation CL = L * it mixes both color electric and color magnetic contributions. If its correlator, i.e. the free energy difference ∆F 1,1 (r) shows exponential decay at large distances it is most probably dominated by the magnetic screening mass m M &lt; m E , as electric contributions have already died out before. Note that if we wish to connect the electric screening mass obtained in that fashion to the perturbatively defined concept of Debye mass we will have to divide with a factor two. The reason is that at small distances perturbation theory tells us [158] that ∆F 1,1 (r) is dominated by two-gluon exchange. In turn a -α 2 S exp(-2m D r)/r 2 behavior arises, from which we take it that the screening masses found from such traced out Polyakov loop correlators will represent twice the value of the corresponding gluon mass.</p>
        <p>As proposed first in the lattice study of Ref. [159] (WHOT collaboration) we can instead considerAs proposed first in the lattice study of Ref. [159] (WHOT collaboration) we can instead consider</p>
        <p>where the only two non-vanishing contributions Tr[L M+ ] and Tr[L E-] represent the real and imaginary parts of the Polyakov loop respectively. The corresponding magnetic and electric correlation functions are written as The continuum extrapolated values for the electric (blue, top) and magnetic (red, bottom) screening masses from Yukawa fits to the large distance decay of the electric and magnetic correlation functions. Source: Figure adapted from Ref. [161].where the only two non-vanishing contributions Tr[L M+ ] and Tr[L E-] represent the real and imaginary parts of the Polyakov loop respectively. The corresponding magnetic and electric correlation functions are written as The continuum extrapolated values for the electric (blue, top) and magnetic (red, bottom) screening masses from Yukawa fits to the large distance decay of the electric and magnetic correlation functions. Source: Figure adapted from Ref. [161].</p>
        <p>]]</p>
        <p>If the above defined correlators show a large distance exponential decay, we may use them to extract the magnetic and electric screening masses in a non-perturbative fashion. The high temperature effective field theory of dimensionally reduced QCD, called EQCD, suggests [160] that the correlator takes on the asymptotic formIf the above defined correlators show a large distance exponential decay, we may use them to extract the magnetic and electric screening masses in a non-perturbative fashion. The high temperature effective field theory of dimensionally reduced QCD, called EQCD, suggests [160] that the correlator takes on the asymptotic form</p>
        <p>which has been found to describe lattice QCD simulations well even at temperatures around the crossover transition.which has been found to describe lattice QCD simulations well even at temperatures around the crossover transition.</p>
        <p>While several studies have considered correlators of Polyakov loops in lattice QCD over the past two decades, it is only recently that fully continuum extrapolated results with dynamical quarks, close to the physical pion mass have been obtained in the temperature range up to T = 350 MeV in Ref. [161] and up to T = 1451 MeV in Ref. [162]. The electric and magnetic correlators have been investigated previously only in Ref. [159].While several studies have considered correlators of Polyakov loops in lattice QCD over the past two decades, it is only recently that fully continuum extrapolated results with dynamical quarks, close to the physical pion mass have been obtained in the temperature range up to T = 350 MeV in Ref. [161] and up to T = 1451 MeV in Ref. [162]. The electric and magnetic correlators have been investigated previously only in Ref. [159].</p>
        <p>Let us consider the electric and magnetic screening masses obtained in Ref. [161] (Budapest-Wuppertal collaboration). The simulations in that study are based on a Symanzik improved gauge action and a stout smearing improved staggered quark action tuned to reproduce physical quark masses. Scale setting along the line of constant physics has been implemented using the gradient flow scale ω 0 . The continuum limit is taken on lattices with different imaginary time extent from N τ = 6 . . . 16, where the physical volume is kept approximately constant with a ratio of N s /N τ ≈ 5 . . . 6. As a fixed box approach, temperature is varied by changing the lattice spacing.Let us consider the electric and magnetic screening masses obtained in Ref. [161] (Budapest-Wuppertal collaboration). The simulations in that study are based on a Symanzik improved gauge action and a stout smearing improved staggered quark action tuned to reproduce physical quark masses. Scale setting along the line of constant physics has been implemented using the gradient flow scale ω 0 . The continuum limit is taken on lattices with different imaginary time extent from N τ = 6 . . . 16, where the physical volume is kept approximately constant with a ratio of N s /N τ ≈ 5 . . . 6. As a fixed box approach, temperature is varied by changing the lattice spacing.</p>
        <p>Since the naive Polyakov loop diverges in the continuum limit, so does its correlator at large separation distances and hence the free energies. I.e. to take the continuum limit in a meaningful way this divergence needs to be subtracted. One possibility (for a detailed discussion see [161]) is to define the renormalized quantitySince the naive Polyakov loop diverges in the continuum limit, so does its correlator at large separation distances and hence the free energies. I.e. to take the continuum limit in a meaningful way this divergence needs to be subtracted. One possibility (for a detailed discussion see [161]) is to define the renormalized quantity</p>
        <p>at a fixed reference temperature T 0 . Since the divergence is UV dominated it is the same at any temperature and by choosing one fixed T 0 the renormalization procedure remains temperature independent, as required.at a fixed reference temperature T 0 . Since the divergence is UV dominated it is the same at any temperature and by choosing one fixed T 0 the renormalization procedure remains temperature independent, as required.</p>
        <p>In the left plot of Fig. 11 the continuum extrapolated results for ∆F ren 1,1 from Ref. [161] are presented. At every temperature considered, the values approach a common low temperature form for small enough distances, where the influence of the thermal medium becomes insignificant. At large distances and high temperatures on the other hand we find that the free energy difference asymptotes to a constant value, which indicates that indeed screening is present. It manifests itself also as an exponential decay in the underlying correlation function of Polyakov loops. It is clear that screening weakens as the temperature is reduced. At lower temperatures around and below the crossover transition T c = 155 MeV the effects of screening will eventually become mixed with those arising from string breaking. A recent analysis of string breaking effects in T = 0 lattice QCD (yet without continuum extrapolation) in Ref. [163] indicates a string breaking distance of r c = 1.224 (15) fm, so that the flattening off in the T = 150 MeV result shown here up to r = 0.7 fm is most likely still an indication of the onset of screening.In the left plot of Fig. 11 the continuum extrapolated results for ∆F ren 1,1 from Ref. [161] are presented. At every temperature considered, the values approach a common low temperature form for small enough distances, where the influence of the thermal medium becomes insignificant. At large distances and high temperatures on the other hand we find that the free energy difference asymptotes to a constant value, which indicates that indeed screening is present. It manifests itself also as an exponential decay in the underlying correlation function of Polyakov loops. It is clear that screening weakens as the temperature is reduced. At lower temperatures around and below the crossover transition T c = 155 MeV the effects of screening will eventually become mixed with those arising from string breaking. A recent analysis of string breaking effects in T = 0 lattice QCD (yet without continuum extrapolation) in Ref. [163] indicates a string breaking distance of r c = 1.224 (15) fm, so that the flattening off in the T = 150 MeV result shown here up to r = 0.7 fm is most likely still an indication of the onset of screening.</p>
        <p>In order to extract the electric and magnetic screening masses, the Yukawa like decay of the corresponding correlators C E-(r) and C M+ (r) is fitted and the results are given in the right plot of Fig. 11 as ratios with the temperature. The values of the magnetic mass m M /T together with the full error budget including statistical and continuum extrapolation uncertainty are plotted as the red band, the electric mass m D /T as blue band. One finds that the separation of m E &gt; m M holds with m E /m M (T = 300 MeV) = 1.63 (8), even in the regime just above the crossover temperature. While not shown in Fig. 11, the value of the magnetic screening mass obtained from C M+ (r) is expected to agree with that from ∆F 1,1 , as had been observed previously in Ref. [159].In order to extract the electric and magnetic screening masses, the Yukawa like decay of the corresponding correlators C E-(r) and C M+ (r) is fitted and the results are given in the right plot of Fig. 11 as ratios with the temperature. The values of the magnetic mass m M /T together with the full error budget including statistical and continuum extrapolation uncertainty are plotted as the red band, the electric mass m D /T as blue band. One finds that the separation of m E &gt; m M holds with m E /m M (T = 300 MeV) = 1.63 (8), even in the regime just above the crossover temperature. While not shown in Fig. 11, the value of the magnetic screening mass obtained from C M+ (r) is expected to agree with that from ∆F 1,1 , as had been observed previously in Ref. [159].</p>
        <p>Within the errorbars the results do not show a significant dependence on temperature, which suggests that the masses indeed scale linearly with temperature. The results obtained in this analysis are consistent with previous studies using EQCD, keeping in mind that applying EQCD at such low temperatures pushes the envelope of its range of validity. EQCD with both N f = 2 and N f = 3 massless quarks in the medium predicts m E /m M (T = 300 MeV) = 1.8(2) as noted in Ref. [161] and originally computed in Ref. [157].Within the errorbars the results do not show a significant dependence on temperature, which suggests that the masses indeed scale linearly with temperature. The results obtained in this analysis are consistent with previous studies using EQCD, keeping in mind that applying EQCD at such low temperatures pushes the envelope of its range of validity. EQCD with both N f = 2 and N f = 3 massless quarks in the medium predicts m E /m M (T = 300 MeV) = 1.8(2) as noted in Ref. [161] and originally computed in Ref. [157].</p>
        <p>As we argued that the electric screening mass extracted here non-perturbatively relates to the Debye mass as m E = 2m D , we can compare its values to the predictions of NLO perturbation theory in Eq. (152). One finds that the lattice values are systematically larger than the weak-coupling results by a factor between 1.8 and 2.0.As we argued that the electric screening mass extracted here non-perturbatively relates to the Debye mass as m E = 2m D , we can compare its values to the predictions of NLO perturbation theory in Eq. (152). One finds that the lattice values are systematically larger than the weak-coupling results by a factor between 1.8 and 2.0.</p>
        <p>The second approach followed in the literature considers the transformation properties of the Polyakov loops under color rotations instead of Euclidean time reversal. In the non-interacting theory a product of two color matrices indeed can be unambiguously decomposed according to 3 ⊗ 3 = 1 ⊕ 8 into a color singlet and a color octet (adjoint) contribution exp [-β∆FThe second approach followed in the literature considers the transformation properties of the Polyakov loops under color rotations instead of Euclidean time reversal. In the non-interacting theory a product of two color matrices indeed can be unambiguously decomposed according to 3 ⊗ 3 = 1 ⊕ 8 into a color singlet and a color octet (adjoint) contribution exp [-β∆F</p>
        <p>exp [-β∆Fexp [-β∆F</p>
        <p>]]</p>
        <p>The quantities, where the trace is on the outside of the product of loops are by themselves not gauge invariant. One conventionally chooses Coulomb gauge when determining their values on the lattice. The physical free energy thus contains both singlet and adjoint contributionsThe quantities, where the trace is on the outside of the product of loops are by themselves not gauge invariant. One conventionally chooses Coulomb gauge when determining their values on the lattice. The physical free energy thus contains both singlet and adjoint contributions</p>
        <p>In the interacting theory the above decomposition may become modified. Following the discussion of Ref. [162], which originated in Refs. [164,165], there exist two linear combinations of the color singlet and adjoint contributions that renormalize multiplicatively. Since each comes with their own renormalization constant, distilling the renormalized singlet contribution from the differently traced Polyakov loop correlators in principle requires knowledge of both of them. I.e. depending on the scale, the naively defined singlet correlator of Eq. ( 163) may in principle receive admixtures from the adjoint sector, even if these are in practice small over the phenomenologically relevant distance scales.In the interacting theory the above decomposition may become modified. Following the discussion of Ref. [162], which originated in Refs. [164,165], there exist two linear combinations of the color singlet and adjoint contributions that renormalize multiplicatively. Since each comes with their own renormalization constant, distilling the renormalized singlet contribution from the differently traced Polyakov loop correlators in principle requires knowledge of both of them. I.e. depending on the scale, the naively defined singlet correlator of Eq. ( 163) may in principle receive admixtures from the adjoint sector, even if these are in practice small over the phenomenologically relevant distance scales.</p>
        <p>The temperature dependence of these quantities has been studied in various lattice QCD scenarios in the literature.The temperature dependence of these quantities has been studied in various lattice QCD scenarios in the literature.</p>
        <p>Starting with SU(2) gauge theory in Refs. [166][167][168][169][170][171] in SU(3) pure gauge in [172][173][174][175][176][177][178] and dynamical QCD with N f = 2 in [179][180][181][182][183][184][185] and N f = 3 in [186]. Continuum extrapolated results with N f = 2 +1 dynamical flavors have been presented in [161,162].Starting with SU(2) gauge theory in Refs. [166][167][168][169][170][171] in SU(3) pure gauge in [172][173][174][175][176][177][178] and dynamical QCD with N f = 2 in [179][180][181][182][183][184][185] and N f = 3 in [186]. Continuum extrapolated results with N f = 2 +1 dynamical flavors have been presented in [161,162].</p>
        <p>The underlying idea to extract electric screening masses from F 1 is to realize that at T = 0 the color singlet contribution agrees with the real-valued interquark potential ∆F 1 (r, T = 0) = V (0) S (r, T = 0), which represents color electric field interactions among the constituent quarks. Hence by investigating the finite temperature counterpart ∆F 1 (r, T &gt; 0) and how it asymptotes to a constant at large distances (manifest as an exponential decay in the corresponding correlation function), one expects to extract the electric screening mass. Considering ∆F 1,1 itself, as argued before will reveal the magnetic screening mass.The underlying idea to extract electric screening masses from F 1 is to realize that at T = 0 the color singlet contribution agrees with the real-valued interquark potential ∆F 1 (r, T = 0) = V (0) S (r, T = 0), which represents color electric field interactions among the constituent quarks. Hence by investigating the finite temperature counterpart ∆F 1 (r, T &gt; 0) and how it asymptotes to a constant at large distances (manifest as an exponential decay in the corresponding correlation function), one expects to extract the electric screening mass. Considering ∆F 1,1 itself, as argued before will reveal the magnetic screening mass.</p>
        <p>Let us consider the latest results from Ref. [162] (TUMQCD and HotQCD collaboration) where the color singlet free energies F 1 and the gauge invariant ∆F 1,1 have been investigated using a Symanzik improved gauge action and the highly improved staggered (HISQ) action to describe N f = 2 + 1 dynamical light quark flavors. The scale along the line of constant physics has been set using the Sommer scale r 1 and light quark parameters are tuned to lead to a physical strange quark mass m s = 20m l and a pion mass that is close to its physical value m π ≈ 160 MeV. Using a fixed box approach, i.e. changing temperature with the lattice spacing, the study covers a temperature range between 116 &lt; T &lt; 5814 MeV. Some ensembles at temperatures above T &gt; 400 MeV use larger pion mass m π ≈ 320 MeV to speed up the simulations, the effects of which has been checked to be insignificant. The continuum limit is taken on lattices with temporal extent between N τ = 4 . . . 16 keeping an aspect ratio of N s /N τ = 4 and 6.Let us consider the latest results from Ref. [162] (TUMQCD and HotQCD collaboration) where the color singlet free energies F 1 and the gauge invariant ∆F 1,1 have been investigated using a Symanzik improved gauge action and the highly improved staggered (HISQ) action to describe N f = 2 + 1 dynamical light quark flavors. The scale along the line of constant physics has been set using the Sommer scale r 1 and light quark parameters are tuned to lead to a physical strange quark mass m s = 20m l and a pion mass that is close to its physical value m π ≈ 160 MeV. Using a fixed box approach, i.e. changing temperature with the lattice spacing, the study covers a temperature range between 116 &lt; T &lt; 5814 MeV. Some ensembles at temperatures above T &gt; 400 MeV use larger pion mass m π ≈ 320 MeV to speed up the simulations, the effects of which has been checked to be insignificant. The continuum limit is taken on lattices with temporal extent between N τ = 4 . . . 16 keeping an aspect ratio of N s /N τ = 4 and 6.</p>
        <p>The free energies are renormalized by first subtracting from their bare value twice the bare value of free energy of a single quark and then adding twice the value of the renormalized single quark free energy obtained from the renormalized Polyakov loop. This procedure leads to a well defined continuum limit for the color singlet free energy F 1 if performed in Coulomb gauge, while other gauge choices leave remnant divergencies in place [187].The free energies are renormalized by first subtracting from their bare value twice the bare value of free energy of a single quark and then adding twice the value of the renormalized single quark free energy obtained from the renormalized Polyakov loop. This procedure leads to a well defined continuum limit for the color singlet free energy F 1 if performed in Coulomb gauge, while other gauge choices leave remnant divergencies in place [187].</p>
        <p>In the left plot of Fig. 12 the continuum extrapolated values of the renormalized color singlet free energies F 1 are shown at different temperatures. At small distances rT &lt; 0.3 this quantity agrees well with the predictions of perturbation theory provided in Ref. [165]. Note that the observed behavior in this regime is not of a simple Debye screened form, which emerges only for rT ≳ 0.3, the eponymous screening regime. The difference in functional form between F 1 and ∆F 1,1 is clearly visible, as is the fact that at small distances all simulation points fall on top of the T = 0 curve. If considered in terms of rescaled distances rT in-medium effects only become significant for rT &gt; 0.3. At large distances also F 1 shows screening, as it asymptotes to a constant value, indicated by the horizontal solid lines. One of the goals of Ref. [162] is to elucidate in which region of distances and temperatures the lattice results for the different free energies become amenable to a perturbative description. It was shown that for rT ≪ 1 the perturbatively matched EFT pNRQCD provides a good description, while for intermediate distances rT ≲ 1 the effective theory EQCD agrees with the lattice data within its scale uncertainty. At the asymptotic large distances, where the screening masses are defined, however neither EQCD not perturbation theory can be deployed and the previously discussed Yukawa fits were used.In the left plot of Fig. 12 the continuum extrapolated values of the renormalized color singlet free energies F 1 are shown at different temperatures. At small distances rT &lt; 0.3 this quantity agrees well with the predictions of perturbation theory provided in Ref. [165]. Note that the observed behavior in this regime is not of a simple Debye screened form, which emerges only for rT ≳ 0.3, the eponymous screening regime. The difference in functional form between F 1 and ∆F 1,1 is clearly visible, as is the fact that at small distances all simulation points fall on top of the T = 0 curve. If considered in terms of rescaled distances rT in-medium effects only become significant for rT &gt; 0.3. At large distances also F 1 shows screening, as it asymptotes to a constant value, indicated by the horizontal solid lines. One of the goals of Ref. [162] is to elucidate in which region of distances and temperatures the lattice results for the different free energies become amenable to a perturbative description. It was shown that for rT ≪ 1 the perturbatively matched EFT pNRQCD provides a good description, while for intermediate distances rT ≲ 1 the effective theory EQCD agrees with the lattice data within its scale uncertainty. At the asymptotic large distances, where the screening masses are defined, however neither EQCD not perturbation theory can be deployed and the previously discussed Yukawa fits were used.</p>
        <p>The screening mass m 1 obtained from the color singlet free energies divided by temperature is plotted in the right panel of Fig. 12. The values at several different lattice spacings are shown and it is found that for N τ &gt; 8 no more cutoff effects remain, providing the result essentially in the continuum limit. Here a much larger temperature range is considered as in the study of C E-. It appears that the ratio shows a tendency to decrease as temperature is increased, while the relatively large uncertainty at N τ = 12 does not yet allow to make a definite statement.The screening mass m 1 obtained from the color singlet free energies divided by temperature is plotted in the right panel of Fig. 12. The values at several different lattice spacings are shown and it is found that for N τ &gt; 8 no more cutoff effects remain, providing the result essentially in the continuum limit. Here a much larger temperature range is considered as in the study of C E-. It appears that the ratio shows a tendency to decrease as temperature is increased, while the relatively large uncertainty at N τ = 12 does not yet allow to make a definite statement.</p>
        <p>Since the color singlet free energies perturbatively are dominated by single gluon exchange, the screening mass m 1 is expected to agree with the Debye screening mass itself at high temperatures. Hence its values may be directly compared to the NLO prediction of Eq. (152). Interestingly, as shown by the dotted and dashed curve, the temperature dependence of the lattice quantities appears to resemble qualitatively the NLO prediction at the scale µ &gt; π T but is systematically larger by a factor of 1.6-2.0. The screening masses obtained here from the renormalized ∆F 1 are compatible with the values of Ref. [161] for temperatures above T = 300 MeV.Since the color singlet free energies perturbatively are dominated by single gluon exchange, the screening mass m 1 is expected to agree with the Debye screening mass itself at high temperatures. Hence its values may be directly compared to the NLO prediction of Eq. (152). Interestingly, as shown by the dotted and dashed curve, the temperature dependence of the lattice quantities appears to resemble qualitatively the NLO prediction at the scale µ &gt; π T but is systematically larger by a factor of 1.6-2.0. The screening masses obtained here from the renormalized ∆F 1 are compatible with the values of Ref. [161] for temperatures above T = 300 MeV.</p>
        <p>The study of asymptotic screening masses at temperatures below T = 200 MeV is challenging due to the low signal to noise ratio in the Polyakov loop correlators in that regime. Thus the errorbars of the extracted screening masses also increases as temperature is lowered. On the other hand the region around the phase transition and below is of particular interest in order to understand the fate of screening in the hadronic phase. In pure gauge theory, where there exists a genuine phase transition, one would expect that below T C screening is strongly suppressed, as it is only glueballs that may interfere with the binding of the (by now) confined static color charges. I.e. the expectation is that m D quite abruptly takes on very small values, probably even vanishes, as e.g. indicated by the results of Ref. [173]. In full QCD without a genuine transition this change in m D will proceed more gently but eventually at T = 0 it also has to vanish. Therefore it will be interesting to see how the lattice results, which down to T = 160 MeV show either a flat or even an increasing ratio of m D /T will behave at temperatures below T c . A first indication of a downward trend in the ratio has been observed in m M in Ref. [162] however only at the lowest temperatures where a continuum limit is not yet available.The study of asymptotic screening masses at temperatures below T = 200 MeV is challenging due to the low signal to noise ratio in the Polyakov loop correlators in that regime. Thus the errorbars of the extracted screening masses also increases as temperature is lowered. On the other hand the region around the phase transition and below is of particular interest in order to understand the fate of screening in the hadronic phase. In pure gauge theory, where there exists a genuine phase transition, one would expect that below T C screening is strongly suppressed, as it is only glueballs that may interfere with the binding of the (by now) confined static color charges. I.e. the expectation is that m D quite abruptly takes on very small values, probably even vanishes, as e.g. indicated by the results of Ref. [173]. In full QCD without a genuine transition this change in m D will proceed more gently but eventually at T = 0 it also has to vanish. Therefore it will be interesting to see how the lattice results, which down to T = 160 MeV show either a flat or even an increasing ratio of m D /T will behave at temperatures below T c . A first indication of a downward trend in the ratio has been observed in m M in Ref. [162] however only at the lowest temperatures where a continuum limit is not yet available.</p>
        <p>We have seen that two independent approaches to electric screening masses m E ≡ 2m D and m 1 ≡ m D provide consistent results on the values of the corresponding Debye mass in the QGP phase. In addition different lattice QCD setups agree within uncertainty on the values of the magnetic screening mass extracted from ∆F 1,1 in the continuum limit. Quantitatively the Debye masses obtained from the lattice in the QGP phase, characterizing electric screening, turn out to be up to a factor 2 larger than what is predicted by NLO perturbation theory. This is pertinent information when it comes to understanding heavy quarkonium binding, as it tells us that the (color electric) interactions that sustain the bound states will receive significant modification in the deconfined medium. There are efforts ongoing in the lattice community to extend the computation of screening masses to a medium with finite Baryo-chemical potential µ B , via the Taylor expansion method [183] or analytic continuation from imaginary chemical potential [188,189]. In the latter case charge conjugation symmetry is broken explicitly and the standard prescription discussed here to separate color electric and magnetic contributions is inapplicable. With a refined strategy it is found that at finite lattice spacing the presence of a small but finite µ B increases both electric and magnetic screening masses. The change is of the same order of magnitude as expected for the Debye mass from lowest order perturbation theory.We have seen that two independent approaches to electric screening masses m E ≡ 2m D and m 1 ≡ m D provide consistent results on the values of the corresponding Debye mass in the QGP phase. In addition different lattice QCD setups agree within uncertainty on the values of the magnetic screening mass extracted from ∆F 1,1 in the continuum limit. Quantitatively the Debye masses obtained from the lattice in the QGP phase, characterizing electric screening, turn out to be up to a factor 2 larger than what is predicted by NLO perturbation theory. This is pertinent information when it comes to understanding heavy quarkonium binding, as it tells us that the (color electric) interactions that sustain the bound states will receive significant modification in the deconfined medium. There are efforts ongoing in the lattice community to extend the computation of screening masses to a medium with finite Baryo-chemical potential µ B , via the Taylor expansion method [183] or analytic continuation from imaginary chemical potential [188,189]. In the latter case charge conjugation symmetry is broken explicitly and the standard prescription discussed here to separate color electric and magnetic contributions is inapplicable. With a refined strategy it is found that at finite lattice spacing the presence of a small but finite µ B increases both electric and magnetic screening masses. The change is of the same order of magnitude as expected for the Debye mass from lowest order perturbation theory.</p>
        <p>In contrast to using gauge invariant correlators of static test charges, the screening properties of QCD may also be elucidated by investigating the in-medium behavior of gluons themselves (for studies of in-medium quark properties see e.g. Refs. [129,190,191]). This line of research is pursued using both non-perturbative lattice QCD, as well as analytic methods, such as the functional renormalization group and Dyson-Schwinger equations.In contrast to using gauge invariant correlators of static test charges, the screening properties of QCD may also be elucidated by investigating the in-medium behavior of gluons themselves (for studies of in-medium quark properties see e.g. Refs. [129,190,191]). This line of research is pursued using both non-perturbative lattice QCD, as well as analytic methods, such as the functional renormalization group and Dyson-Schwinger equations.</p>
        <p>A study of gluon properties necessarily involves gauge fixing (usually to Landau gauge), where transverse (magnetic) and longitudinal (electric) contributions to the gauge fields can be separated by adequate projection. In high temperature QCD, gluons are understood as actual propagating quasiparticle d.o.f. and their interaction with the environment endows them with a dynamically generated mass. This picture underlies the perturbative definition of the Debye mass. Now if a quasiparticle-like structure can be identified in gluon spectral functions, obtained non-perturbatively e.g. from lattice QCD, changes in its position with temperature may substantiate the presence of such a thermal mass.A study of gluon properties necessarily involves gauge fixing (usually to Landau gauge), where transverse (magnetic) and longitudinal (electric) contributions to the gauge fields can be separated by adequate projection. In high temperature QCD, gluons are understood as actual propagating quasiparticle d.o.f. and their interaction with the environment endows them with a dynamically generated mass. This picture underlies the perturbative definition of the Debye mass. Now if a quasiparticle-like structure can be identified in gluon spectral functions, obtained non-perturbatively e.g. from lattice QCD, changes in its position with temperature may substantiate the presence of such a thermal mass.</p>
        <p>Extracting gluon spectral functions is extremely challenging due to the additional technical complication that it is possible for them to contain non-positive regions. This is in particular relevant in both the small frequency regime, as has been recently pointed out in Ref. [139] and as is known from perturbative arguments at very large frequencies. Hence so far only a few studies of in-medium gluon spectral functions on the lattice have been carried out (for two recent ones see e.g. Refs. [192,193]).Extracting gluon spectral functions is extremely challenging due to the additional technical complication that it is possible for them to contain non-positive regions. This is in particular relevant in both the small frequency regime, as has been recently pointed out in Ref. [139] and as is known from perturbative arguments at very large frequencies. Hence so far only a few studies of in-medium gluon spectral functions on the lattice have been carried out (for two recent ones see e.g. Refs. [192,193]).</p>
        <p>Using simulations of the QCD medium by the tmft collaboration, which implements N f = 2 + 1 + 1 dynamical quark flavors in the twisted mass formalism, gluon correlators and spectral functions in Landau gauge have been investigated in Ref. [192]. The study focused on a set of lattices with relatively small lattice spacing a = 0.0646 fm but with a still unphysically high pion mass of m π = 369 MeV. A fixed box approach allowed investigating a temperature range between T = 152-381 MeV changing the number of Euclidean points between N τ = 20 -8. The deconfinement crossover temperature on these lattices is T C = 193Mev. Spectral reconstructions were performed using the generalized BR method [120]. One needs to be aware that due to the KMS relation only half of the input points provide independent information so that the reconstructions are based on a relatively small number of input data. This drawback was partially compensated for by the very good signal to noise ratio in the underlying gluon correlators. A well defined lowest lying spectral feature was observed at all temperatures in both the longitudinal and transversal spectral functions, which in the QGP phase has been interpreted as representing a gluon quasi-particle.Using simulations of the QCD medium by the tmft collaboration, which implements N f = 2 + 1 + 1 dynamical quark flavors in the twisted mass formalism, gluon correlators and spectral functions in Landau gauge have been investigated in Ref. [192]. The study focused on a set of lattices with relatively small lattice spacing a = 0.0646 fm but with a still unphysically high pion mass of m π = 369 MeV. A fixed box approach allowed investigating a temperature range between T = 152-381 MeV changing the number of Euclidean points between N τ = 20 -8. The deconfinement crossover temperature on these lattices is T C = 193Mev. Spectral reconstructions were performed using the generalized BR method [120]. One needs to be aware that due to the KMS relation only half of the input points provide independent information so that the reconstructions are based on a relatively small number of input data. This drawback was partially compensated for by the very good signal to noise ratio in the underlying gluon correlators. A well defined lowest lying spectral feature was observed at all temperatures in both the longitudinal and transversal spectral functions, which in the QGP phase has been interpreted as representing a gluon quasi-particle.</p>
        <p>In Fig. 13In Fig. 13</p>
        <p>which itself is larger at that temperature than the prediction from NLO perturbation theory. A result that is qualitatively compatible with those obtained from the gauge invariant correlation functions discussed previously.which itself is larger at that temperature than the prediction from NLO perturbation theory. A result that is qualitatively compatible with those obtained from the gauge invariant correlation functions discussed previously.</p>
        <p>Summary. The phenomenon of screening in a QCD medium can be investigated by considering the correlations among test color charges in the form of infinitely heavy quarks evolving in Euclidean time. In contrast to QED not only electric fields become screened but also magnetic ones, i.e. at large enough distances all gluons acquire a thermal mass. Expressed as Polyakov loops, the static quark correlation functions are intimately related to the free energy of static pairs in the medium.Summary. The phenomenon of screening in a QCD medium can be investigated by considering the correlations among test color charges in the form of infinitely heavy quarks evolving in Euclidean time. In contrast to QED not only electric fields become screened but also magnetic ones, i.e. at large enough distances all gluons acquire a thermal mass. Expressed as Polyakov loops, the static quark correlation functions are intimately related to the free energy of static pairs in the medium.</p>
        <p>Electric and magnetic screening masses can be extracted from appropriately constructed Polyakov loop correlators. In the literature three independent approached are considered. The first two construct gauge invariant quantities with definite transformation properties w.r.t. Euclidean time reversal or w.r.t. color rotations. Corresponding screening masses have been computed in lattice QCD in the continuum limit and it has been found that the perturbative prediction of m E &gt; m M , as well as m E /T ≈ const. and m M /T ≈ const. holds approximately even in the non-perturbative regime close to the crossover transition. Quantitatively it has been established on the lattice that electric screening, most relevant for the binding of quarkonium states is more efficient than predicted by NLO perturbation theory by a factor of 1.6 to 2.0 in terms of the Debye mass. Alternatively screening may be investigated directly from the in-medium modification of gluon spectral functions, which yields qualitatively consistent behavior of electric and magnetic screening masses.Electric and magnetic screening masses can be extracted from appropriately constructed Polyakov loop correlators. In the literature three independent approached are considered. The first two construct gauge invariant quantities with definite transformation properties w.r.t. Euclidean time reversal or w.r.t. color rotations. Corresponding screening masses have been computed in lattice QCD in the continuum limit and it has been found that the perturbative prediction of m E &gt; m M , as well as m E /T ≈ const. and m M /T ≈ const. holds approximately even in the non-perturbative regime close to the crossover transition. Quantitatively it has been established on the lattice that electric screening, most relevant for the binding of quarkonium states is more efficient than predicted by NLO perturbation theory by a factor of 1.6 to 2.0 in terms of the Debye mass. Alternatively screening may be investigated directly from the in-medium modification of gluon spectral functions, which yields qualitatively consistent behavior of electric and magnetic screening masses.</p>
        <p>In the previous section we have discussed the phenomenon of screening of static color fields in the QGP and found that in the relevant temperature range for current heavy ion collisions, electric screening is not only present but it is stronger than predicted by NLO perturbation theory. This finding begs the question, how the medium affects the binding of actual heavy quarkonium. Due to the separation of scales between the heavy quark rest mass, as well as temperature T /m Q ≪ 1 and Λ QCD /m Q ≪ 1 we have seen in Section 2.2.2 that significant aspects of the physics of quarkonium can be captured in a real-time potential, which corresponds to a non-local Wilson coefficient in the effective field theory pNRQCD. The leading order contribution to the color singlet potential in the heavy quark velocity expansion is given by the static interquark potential V (0) S (r), which is independent of the heavy quark velocity v.In the previous section we have discussed the phenomenon of screening of static color fields in the QGP and found that in the relevant temperature range for current heavy ion collisions, electric screening is not only present but it is stronger than predicted by NLO perturbation theory. This finding begs the question, how the medium affects the binding of actual heavy quarkonium. Due to the separation of scales between the heavy quark rest mass, as well as temperature T /m Q ≪ 1 and Λ QCD /m Q ≪ 1 we have seen in Section 2.2.2 that significant aspects of the physics of quarkonium can be captured in a real-time potential, which corresponds to a non-local Wilson coefficient in the effective field theory pNRQCD. The leading order contribution to the color singlet potential in the heavy quark velocity expansion is given by the static interquark potential V (0) S (r), which is independent of the heavy quark velocity v.</p>
        <p>In this section we will consider evaluating this proper real-time potential V (0) S in QCD at finite temperature according to the defining relation based on the real-time Wilson loopIn this section we will consider evaluating this proper real-time potential V (0) S in QCD at finite temperature according to the defining relation based on the real-time Wilson loop</p>
        <p>The real-time definition of the static potential has been evaluated in thermal equilibrium for the first time in Ref. [15] using hard thermal loop perturbation theory [194] followed by Ref. [17], which extended the computation to different scale hierarchies. For a pedagogical treatment see [16]. The setting chosen in Ref. [15] corresponds to the particular scale hierarchy where mv ∼ gT [195] or in order to accommodate the static limit 1/r ∼ gT , where r denotes the characteristic extent of the bound state [17]. Unexpected at that time, it turns out that the real-time potential besides its real-part also features a finite imaginary part, the explicit expressions of which are given by Re[V (0) S,HTL ](r) = -The real-time definition of the static potential has been evaluated in thermal equilibrium for the first time in Ref. [15] using hard thermal loop perturbation theory [194] followed by Ref. [17], which extended the computation to different scale hierarchies. For a pedagogical treatment see [16]. The setting chosen in Ref. [15] corresponds to the particular scale hierarchy where mv ∼ gT [195] or in order to accommodate the static limit 1/r ∼ gT , where r denotes the characteristic extent of the bound state [17]. Unexpected at that time, it turns out that the real-time potential besides its real-part also features a finite imaginary part, the explicit expressions of which are given by Re[V (0) S,HTL ](r) = -</p>
        <p>where α S = g 2 C F /4π is used as definition of the strong coupling constant, similar to the convention in the quarkonium phenomenology literature. At intermediate distances, where the running of the strong coupling is not pronounced, the temperature dependence of the real part is solely determined by the value of m D , while the imaginary part carries an explicit dependence on the temperature T . We plot the values for Re[V As expected from the discussion of screening in QCD, one finds that the real-part of the potential shows a Debye screened behavior. It asymptotes at large distances to a constant that represents twice the heavy quark in-medium mass shift [196]. Interestingly to this lowest order in the HTL approximation the expression for Re[V (0) S,HTL ] coincides with the color singlet free energies F 1,HTL (r) in Coulomb gauge as noted e.g. in Ref. [197]. The agreement however is believed to be only coincidental and it is expected that from the next higher order in the perturbative approximation, the two quantities are not exactly equal anymore. As we will see, current lattice QCD results for the in-medium heavy quark potential suggest that the difference between the color singlet free energies and Re[V ] remains relatively small. The imaginary part of Eq. ( 170) starts out quadratically and eventually asymptotes to a finite value, twice that of the heavy quark thermal width [16]. It had been already understood in [15] that in this scale hierarchy Im[V (0) S,HTL ] arises from the phenomenon of Landau damping, which corresponds to the low-frequency gluon mediating the binding between the heavy quarks loosing energy to a medium parton with a higher energy ∼T . In the literature this imaginary part has been discussed independently in the context of so called quarkonium dissociation by parton scattering e.g. in Refs. [198,199], which has been treated more recently in a consistent EFT setting in Ref. [200].where α S = g 2 C F /4π is used as definition of the strong coupling constant, similar to the convention in the quarkonium phenomenology literature. At intermediate distances, where the running of the strong coupling is not pronounced, the temperature dependence of the real part is solely determined by the value of m D , while the imaginary part carries an explicit dependence on the temperature T . We plot the values for Re[V As expected from the discussion of screening in QCD, one finds that the real-part of the potential shows a Debye screened behavior. It asymptotes at large distances to a constant that represents twice the heavy quark in-medium mass shift [196]. Interestingly to this lowest order in the HTL approximation the expression for Re[V (0) S,HTL ] coincides with the color singlet free energies F 1,HTL (r) in Coulomb gauge as noted e.g. in Ref. [197]. The agreement however is believed to be only coincidental and it is expected that from the next higher order in the perturbative approximation, the two quantities are not exactly equal anymore. As we will see, current lattice QCD results for the in-medium heavy quark potential suggest that the difference between the color singlet free energies and Re[V ] remains relatively small. The imaginary part of Eq. ( 170) starts out quadratically and eventually asymptotes to a finite value, twice that of the heavy quark thermal width [16]. It had been already understood in [15] that in this scale hierarchy Im[V (0) S,HTL ] arises from the phenomenon of Landau damping, which corresponds to the low-frequency gluon mediating the binding between the heavy quarks loosing energy to a medium parton with a higher energy ∼T . In the literature this imaginary part has been discussed independently in the context of so called quarkonium dissociation by parton scattering e.g. in Refs. [198,199], which has been treated more recently in a consistent EFT setting in Ref. [200].</p>
        <p>In other scale hierarchies, the values for Re[V ] and Im[V ] can take on significantly different values [17,201,202].In other scale hierarchies, the values for Re[V ] and Im[V ] can take on significantly different values [17,201,202].</p>
        <p>The imaginary part may receive additional contributions from the phenomenon of gluo-dissociation (see e.g. the classic Ref. [203] and [204]), where a singlet state absorbs a colored gluon from the medium, changing into an octet and subsequently dissolves. Note that this is a particular case where the interaction with the remaining dynamical gluons in the effective theory can still be recast in the form of a time independent potential. At small distances, where the heavy quarks effectively do not see the thermal medium it turns out that Im[V ] becomes exponentially suppressed.The imaginary part may receive additional contributions from the phenomenon of gluo-dissociation (see e.g. the classic Ref. [203] and [204]), where a singlet state absorbs a colored gluon from the medium, changing into an octet and subsequently dissolves. Note that this is a particular case where the interaction with the remaining dynamical gluons in the effective theory can still be recast in the form of a time independent potential. At small distances, where the heavy quarks effectively do not see the thermal medium it turns out that Im[V ] becomes exponentially suppressed.</p>
        <p>It is important to stress at this point that the potential we have discussed so far governs the time evolution of the medium averaged color singlet correlator of point split meson operators. In particular it does not describe the evolution of the microscopic wavefunction of a heavy quarkonium state. This distinction is important in order to avoid misinterpretations of the imaginary part of the potential. Im[V ] has been derived in the static limit, where the heavy quarks are fixed to their spatial positions and never meet to annihilate. I.e. the probability to find the two heavy quarks in the system remains constant and Im[V ] cannot tell us that the amplitude of the wavefunction of the two-body system decays exponentially. Instead if understood as implementing the damping of the unequal time correlator of singlet fields, the role of the imaginary part becomes clear. It encodes the loss of coherence between the state of the heavy quarkonium particle at initial time (when it was just inserted into the medium) and its state at later time after interacting with the medium. Intuitively, one expects the medium fluctuations to perturb the wavefunction of the quarkonium stochastically until it has equilibrated with its surroundings. Decoherence represented via Im[V ] is an aspect of the thermalization of the quarkonium system. In the context of open quantum systems we will return to the question of how to implement the microscopic dynamics for the wavefunction of heavy quarkonium based on the knowledge of the complex static potential from pNRQCD.It is important to stress at this point that the potential we have discussed so far governs the time evolution of the medium averaged color singlet correlator of point split meson operators. In particular it does not describe the evolution of the microscopic wavefunction of a heavy quarkonium state. This distinction is important in order to avoid misinterpretations of the imaginary part of the potential. Im[V ] has been derived in the static limit, where the heavy quarks are fixed to their spatial positions and never meet to annihilate. I.e. the probability to find the two heavy quarks in the system remains constant and Im[V ] cannot tell us that the amplitude of the wavefunction of the two-body system decays exponentially. Instead if understood as implementing the damping of the unequal time correlator of singlet fields, the role of the imaginary part becomes clear. It encodes the loss of coherence between the state of the heavy quarkonium particle at initial time (when it was just inserted into the medium) and its state at later time after interacting with the medium. Intuitively, one expects the medium fluctuations to perturb the wavefunction of the quarkonium stochastically until it has equilibrated with its surroundings. Decoherence represented via Im[V ] is an aspect of the thermalization of the quarkonium system. In the context of open quantum systems we will return to the question of how to implement the microscopic dynamics for the wavefunction of heavy quarkonium based on the knowledge of the complex static potential from pNRQCD.</p>
        <p>While a lot has been learned about the potential acting between static quarks from perturbative studies, the question remains how quarkonium states behave in the non-perturbative regime just above the crossover transition, where perturbative methods are inapplicable. I.e. to approach an understanding of quarkonium in heavy-ion collisions we need to evaluate Eq. ( 168) using lattice QCD.While a lot has been learned about the potential acting between static quarks from perturbative studies, the question remains how quarkonium states behave in the non-perturbative regime just above the crossover transition, where perturbative methods are inapplicable. I.e. to approach an understanding of quarkonium in heavy-ion collisions we need to evaluate Eq. ( 168) using lattice QCD.</p>
        <p>The real-time definition of the static in-medium potential in Eq. ( 168) is formulated in Minkowski time and thus not directly amenable to an evaluation in lattice QCD. Bridging the real-and imaginary-time domain is however possible by resorting to the technical concept of spectral functions. We saw that all different types of meson correlation functions are ultimately governed by a single positive definite function, i.e. the correlator can be expressed in terms of a convolution of the spectral function with an appropriate kernel function.The real-time definition of the static in-medium potential in Eq. ( 168) is formulated in Minkowski time and thus not directly amenable to an evaluation in lattice QCD. Bridging the real-and imaginary-time domain is however possible by resorting to the technical concept of spectral functions. We saw that all different types of meson correlation functions are ultimately governed by a single positive definite function, i.e. the correlator can be expressed in terms of a convolution of the spectral function with an appropriate kernel function.</p>
        <p>Since the Wilson loop corresponds to the infinite mass limit of the forward correlator of point split meson operators, its spectral decomposition in Euclidean time, as shown in Ref. [34], leads to the simple relationSince the Wilson loop corresponds to the infinite mass limit of the forward correlator of point split meson operators, its spectral decomposition in Euclidean time, as shown in Ref. [34], leads to the simple relation</p>
        <p>The spectral function (in a finite volume) is composed of a finite number of delta peaks. Here E n denotes the energy of an eigenstate |n⟩ of the system without a Q Q pair and E Q Q m (r) the energy of a state with a static Q Q pair present at a distance r. The matrix element M n,m = ⟨n|M(x + r, x, t = 0)|m⟩ also carries an r dependence, while the Boltzmann factor P n (T ) = e -En/T /[ ∑ n e -En/T ] only depends on temperature T. Note that the positions of the peaks in ρ □ are T independent but their amplitude surely is, due to P n (T ). In the infinite volume limit, the delta peaks bunch and their envelope will form a continuous function along real-time frequencies ω.The spectral function (in a finite volume) is composed of a finite number of delta peaks. Here E n denotes the energy of an eigenstate |n⟩ of the system without a Q Q pair and E Q Q m (r) the energy of a state with a static Q Q pair present at a distance r. The matrix element M n,m = ⟨n|M(x + r, x, t = 0)|m⟩ also carries an r dependence, while the Boltzmann factor P n (T ) = e -En/T /[ ∑ n e -En/T ] only depends on temperature T. Note that the positions of the peaks in ρ □ are T independent but their amplitude surely is, due to P n (T ). In the infinite volume limit, the delta peaks bunch and their envelope will form a continuous function along real-time frequencies ω.</p>
        <p>Analytic continuation of the Wilson loop to Minkowski time changes the Laplace-type kernel of Eq. ( 171) into nothing but a Fourier transform over the spectral functionAnalytic continuation of the Wilson loop to Minkowski time changes the Laplace-type kernel of Eq. ( 171) into nothing but a Fourier transform over the spectral function</p>
        <p>In case that we have access to the spectral function we may then straight forwardly relate the value of the potential to ρ □ (ω) by plugging Eq. ( 172) back into Eq. ( 168)In case that we have access to the spectral function we may then straight forwardly relate the value of the potential to ρ □ (ω) by plugging Eq. ( 172) back into Eq. ( 168)</p>
        <p>This relation forms the basis for lattice studies of the proper static interquark potential. The fact that a late time limit is taken, indicates that only spectral features at small frequencies are relevant for the potential. I.e. at T = 0 where there exists a single well separated lowest lying delta peak in ρ □ , it alone determines the value of V (0) S (r). If we plug a single delta peak at position ω 0 into Eq. ( 173) we obtain a purely real Re[V ] = ω 0 and Im[V ] = 0 as expected. The single delta peak present in ρ □ at T = 0 makes it possible to rewrite the real-time definition of the potential in terms of Euclidean quantities, recovering the conventional definition of the vacuum heavy quark potentialThis relation forms the basis for lattice studies of the proper static interquark potential. The fact that a late time limit is taken, indicates that only spectral features at small frequencies are relevant for the potential. I.e. at T = 0 where there exists a single well separated lowest lying delta peak in ρ □ , it alone determines the value of V (0) S (r). If we plug a single delta peak at position ω 0 into Eq. ( 173) we obtain a purely real Re[V ] = ω 0 and Im[V ] = 0 as expected. The single delta peak present in ρ □ at T = 0 makes it possible to rewrite the real-time definition of the potential in terms of Euclidean quantities, recovering the conventional definition of the vacuum heavy quark potential</p>
        <p>I.e. the single delta peak in ρ □ leads to single exponential decay of the Euclidean Wilson loop at late imaginary times and its decay constant may be extracted by considering the logarithm of the Wilson loop. It is often customary to this end to compute the effective potential, which is just the effective mass (see Eq. ( 82)) of the Euclidean Wilson loop. Note that at finite temperature, due to the compact Euclidean domain we cannot take the τ → ∞ limit anymore. Furthermore it turns out that the Wilson loop at the latest available time τ = β is not related directly to the proper in-medium potential.I.e. the single delta peak in ρ □ leads to single exponential decay of the Euclidean Wilson loop at late imaginary times and its decay constant may be extracted by considering the logarithm of the Wilson loop. It is often customary to this end to compute the effective potential, which is just the effective mass (see Eq. ( 82)) of the Euclidean Wilson loop. Note that at finite temperature, due to the compact Euclidean domain we cannot take the τ → ∞ limit anymore. Furthermore it turns out that the Wilson loop at the latest available time τ = β is not related directly to the proper in-medium potential.</p>
        <p>At finite but not too high temperature the single delta peak starts to broaden, while still being well separated from any higher lying spectral structures. In the simplest case we may expect a Breit-Wigner like shape to emerge in ρ □ at low frequencies. Inserting such a shape into Eq. ( 173) it tells us that the position of the peak provides the real-and the width of the peak the imaginary part of the potential. Note that finding in ρ □ (ω) only a single Breit-Wigner would indicate that the evolution of the Wilson loop at any time is governed by a time independent potential. Having derived the relation between the Wilson loop and the static potential at timescales, much longer than the characteristic scales of the medium, based on the lowest order of the multipole expansion, it has to be checked whether also non-potential effects can affect the time evolution of W □ in practice. Since early and late times both contribute to the Fourier transform it is important to disentangle them in order to identify the relevant spectral structures encoding the potential. This has been achieved in Ref. [205]. Consider the general time evolution equation of the Wilson loop, which follows from its spectral decompositionAt finite but not too high temperature the single delta peak starts to broaden, while still being well separated from any higher lying spectral structures. In the simplest case we may expect a Breit-Wigner like shape to emerge in ρ □ at low frequencies. Inserting such a shape into Eq. ( 173) it tells us that the position of the peak provides the real-and the width of the peak the imaginary part of the potential. Note that finding in ρ □ (ω) only a single Breit-Wigner would indicate that the evolution of the Wilson loop at any time is governed by a time independent potential. Having derived the relation between the Wilson loop and the static potential at timescales, much longer than the characteristic scales of the medium, based on the lowest order of the multipole expansion, it has to be checked whether also non-potential effects can affect the time evolution of W □ in practice. Since early and late times both contribute to the Fourier transform it is important to disentangle them in order to identify the relevant spectral structures encoding the potential. This has been achieved in Ref. [205]. Consider the general time evolution equation of the Wilson loop, which follows from its spectral decomposition</p>
        <p>It contains a complex valued and time dependent function Φ(r, t). If the potential picture is valid Φ(r, t) will asymptote to a time independent quantity, we identify with the potentialIt contains a complex valued and time dependent function Φ(r, t). If the potential picture is valid Φ(r, t) will asymptote to a time independent quantity, we identify with the potential</p>
        <p>We wish to understand how the time dependence in Φ(r, t) affects the shape of the lowest lying peak, which encodes the potential. To this end let us decompose Φ(r, t) = V (r) + φ(r, t) into a time dependent part φ(r, t) which vanishes after a characteristic time t Q Q has passed. Only after t Q Q have enough gluon exchanges taken place that the retarded field theoretical interaction may be viewed through the coarse grained lens of an instantaneous exchange potential.We wish to understand how the time dependence in Φ(r, t) affects the shape of the lowest lying peak, which encodes the potential. To this end let us decompose Φ(r, t) = V (r) + φ(r, t) into a time dependent part φ(r, t) which vanishes after a characteristic time t Q Q has passed. Only after t Q Q have enough gluon exchanges taken place that the retarded field theoretical interaction may be viewed through the coarse grained lens of an instantaneous exchange potential.</p>
        <p>We can formally solve Eq. ( 174) at positive times t &gt; 0. For the solution to be convergent at late times the imaginary part of the potential needs to be negative Im[V ](r) &lt; 0. One obtainsWe can formally solve Eq. ( 174) at positive times t &gt; 0. For the solution to be convergent at late times the imaginary part of the potential needs to be negative Im[V ](r) &lt; 0. One obtains</p>
        <p>] .] .</p>
        <p>where the function σ (r, t) = ∫ t 0 φ(r, t)dt is defined from integrating over the time dependent contribution to Φ, and σwhere the function σ (r, t) = ∫ t 0 φ(r, t)dt is defined from integrating over the time dependent contribution to Φ, and σ</p>
        <p>)dt denotes its asymptotic value. The solution of the Wilson loop at negative times can be directly obtained from the symmetry condition W □ (r, -t) = W * □ (r, t). Now we are ready to solve for the corresponding spectral function, which reads)dt denotes its asymptotic value. The solution of the Wilson loop at negative times can be directly obtained from the symmetry condition W □ (r, -t) = W * □ (r, t). Now we are ready to solve for the corresponding spectral function, which reads</p>
        <p>] .] .</p>
        <p>We can distinguish two contributions here, one from within the time rangeWe can distinguish two contributions here, one from within the time range</p>
        <p>) .) .</p>
        <p>It is possible to solve the integral in the first line analytically, as it extends over the whole time axis. The result corresponds to a well defined peak structure, which encodes the values of the potential. It is this peak structure, which we wish to identify in actual lattice QCD spectral functions and fit the shape around its maximum in the region (ω -It is possible to solve the integral in the first line analytically, as it extends over the whole time axis. The result corresponds to a well defined peak structure, which encodes the values of the potential. It is this peak structure, which we wish to identify in actual lattice QCD spectral functions and fit the shape around its maximum in the region (ω -</p>
        <p>The integral in the second line will produce a spectral structure, which acts as background to the potential peak. In order to capture its effect we expand the first exponential in the second integral exp [i(ω -Re[V ](r))t] around the peak frequency.The integral in the second line will produce a spectral structure, which acts as background to the potential peak. In order to capture its effect we expand the first exponential in the second integral exp [i(ω -Re[V ](r))t] around the peak frequency.</p>
        <p>This leads to the following final expressionThis leads to the following final expression</p>
        <p>The first term, related to the potential, takes the form of a skewed Breit-Wigner and reduces to a naive Breit-Wigner peak only in case that non-potential effects are absent ∂ t Φ(r, t) = 0. In addition to the phase σ ∞ , when fitting the potential peak structure one needs to be aware of the background terms c i (r), also arising from the early time dependence of Φ(r, t). I.e. even in the region close to the tip of the peak, where all c i (r) with i &gt; 0 can be ignored, the influence of the early time physics influences the spectral shape through c 0 and Re[σ ∞ ](r), which implies that these two coefficients have to be included no matter what fitting range is chosen. In early attempts of extracting the potential e.g. in Ref. [206] the authors were not aware of this fact, which led to results overestimating the values of the real part of the potential.The first term, related to the potential, takes the form of a skewed Breit-Wigner and reduces to a naive Breit-Wigner peak only in case that non-potential effects are absent ∂ t Φ(r, t) = 0. In addition to the phase σ ∞ , when fitting the potential peak structure one needs to be aware of the background terms c i (r), also arising from the early time dependence of Φ(r, t). I.e. even in the region close to the tip of the peak, where all c i (r) with i &gt; 0 can be ignored, the influence of the early time physics influences the spectral shape through c 0 and Re[σ ∞ ](r), which implies that these two coefficients have to be included no matter what fitting range is chosen. In early attempts of extracting the potential e.g. in Ref. [206] the authors were not aware of this fact, which led to results overestimating the values of the real part of the potential.</p>
        <p>While at first sight it is not clear what kind of potential results from inserting Eq. ( 177) into Eq. ( 173) it turns out that thanks to the late time limit, none of the coefficients c i (r), nor the terms with σ ∞ contribute and a time independent potential emerges. In essence, only the principal part from the skewed Lorentzian, i.e. the term with one negative power of ω survives.While at first sight it is not clear what kind of potential results from inserting Eq. ( 177) into Eq. ( 173) it turns out that thanks to the late time limit, none of the coefficients c i (r), nor the terms with σ ∞ contribute and a time independent potential emerges. In essence, only the principal part from the skewed Lorentzian, i.e. the term with one negative power of ω survives.</p>
        <p>Let us benchmark the extraction of the in-medium potential from Wilson loop spectral functions within HTL perturbation theory, where both the values of the potential and the spectral function are known analytically. To this end in Ref. [197] the authors computed ρ □ at T = 2.33T C = 630 MeV using a UV cutoff of Λ UV = 5π GeV to mimic the effects of a lattice regularization, the outcome of which is plotted for different spatial separation distances r = 0.066-0.466 fm in the left panel of Fig. 15. At this temperature deep in the QGP phase one finds a clear signal for a lowest lying spectral peak, which however is immersed in a large background structure. If one now tries to extract the peak position and On the one hand this analysis in principle bodes well for performing a potential reconstruction in lattice QCD. On the other hand the behavior of the Wilson loop spectrum tells us that the large UV spectral weight will lead to a strong suppression of the Euclidean Wilson loop and in turn it will be very difficult to obtain a good signal to noise ratio at intermediate τ values, where the potential peak signal dominates. The reason for the large (unphysical) background structures in ρ □ is a class of UV divergences, called cusp divergencies [207][208][209][210], which arise from the 90 degree corners of the Wilson loop. The authors of Ref. [197] therefore explored another quantity, the Wilson line correlator in Coulomb gauge W ∥ , which corresponds to the Wilson loop with its spatial Wilson lines removed. This in general gauge dependent quantity goes over into the Wilson loop when axial gauge A 0 = 0 is chosen. It was found that this quantity at leading order in HTL perturbation theory encodes exactly the same potential peak as the Wilson loop but exhibits a significantly reduced background, as shown in Fig. 16. It is this quantity which currently forms the basis for the extraction of the proper in-medium potential on the lattice. (At T = 0 it has been established [211] that the Wilson line correlator and the Wilson loop encode the same potential also non-perturbatively.) We have established that if a potential picture is valid its values can be extracted from spectral functions using appropriate fits to the lowest lying spectral structure. In practice we will turn this argument around and take the presence of a well defined lowest lying peak structure as indication that the late time behavior of the Wilson loop is indeed governed by a simple potential.Let us benchmark the extraction of the in-medium potential from Wilson loop spectral functions within HTL perturbation theory, where both the values of the potential and the spectral function are known analytically. To this end in Ref. [197] the authors computed ρ □ at T = 2.33T C = 630 MeV using a UV cutoff of Λ UV = 5π GeV to mimic the effects of a lattice regularization, the outcome of which is plotted for different spatial separation distances r = 0.066-0.466 fm in the left panel of Fig. 15. At this temperature deep in the QGP phase one finds a clear signal for a lowest lying spectral peak, which however is immersed in a large background structure. If one now tries to extract the peak position and On the one hand this analysis in principle bodes well for performing a potential reconstruction in lattice QCD. On the other hand the behavior of the Wilson loop spectrum tells us that the large UV spectral weight will lead to a strong suppression of the Euclidean Wilson loop and in turn it will be very difficult to obtain a good signal to noise ratio at intermediate τ values, where the potential peak signal dominates. The reason for the large (unphysical) background structures in ρ □ is a class of UV divergences, called cusp divergencies [207][208][209][210], which arise from the 90 degree corners of the Wilson loop. The authors of Ref. [197] therefore explored another quantity, the Wilson line correlator in Coulomb gauge W ∥ , which corresponds to the Wilson loop with its spatial Wilson lines removed. This in general gauge dependent quantity goes over into the Wilson loop when axial gauge A 0 = 0 is chosen. It was found that this quantity at leading order in HTL perturbation theory encodes exactly the same potential peak as the Wilson loop but exhibits a significantly reduced background, as shown in Fig. 16. It is this quantity which currently forms the basis for the extraction of the proper in-medium potential on the lattice. (At T = 0 it has been established [211] that the Wilson line correlator and the Wilson loop encode the same potential also non-perturbatively.) We have established that if a potential picture is valid its values can be extracted from spectral functions using appropriate fits to the lowest lying spectral structure. In practice we will turn this argument around and take the presence of a well defined lowest lying peak structure as indication that the late time behavior of the Wilson loop is indeed governed by a simple potential.</p>
        <p>The central challenge in lattice QCD based studies of the in-medium potential lies in the reconstruction of the spectral function of the Wilson loop or Wilson lines from the Euclidean time observables. As a simple spectral decomposition of the Wilson loop exists (see Eq. ( 171)) this task is but one example of the inverse problem discussed in Section 2.4 amenable to both Bayesian spectral reconstruction and the Padé method. The full recipe is sketched in Fig. 17.The central challenge in lattice QCD based studies of the in-medium potential lies in the reconstruction of the spectral function of the Wilson loop or Wilson lines from the Euclidean time observables. As a simple spectral decomposition of the Wilson loop exists (see Eq. ( 171)) this task is but one example of the inverse problem discussed in Section 2.4 amenable to both Bayesian spectral reconstruction and the Padé method. The full recipe is sketched in Fig. 17.</p>
        <p>The first attempts of extracting spectral functions for the determination of the potential were based on the standard implementation of the MEM by Bryan. Since generally only a small number of simulation datapoints O(10-40) are available, it was found that the restricted SVD search space of the MEM was unable to accurately recover the narrow and strongly peaked spectral feature encoding the potential. Its position was systematically overestimated. The situation improved after an MEM implementation with an extended search space had been developed in Refs. [133,134]. As has been benchmarked with HTL correlator data in Ref. [197] this leads to more accurate values for Re[V ]. On the other hand even with an extended search space the MEM was found to produce spectral features, which resemble Gaussian peaks [206], even if the underlying spectral function contains a Breit-Wigner like structure. This is a serious drawback, since a Gaussian peak inserted into Eq. ( 173) will lead to the incorrect conclusion that the imaginary part of the potential grows with time. It took the development of a completely redesigned reconstruction approach, the BR method, to achieve reconstructions that faithfully reproduce not only the overall functional form, but also quantitatively the position and the width of the encoded peaks (see Ref. [128]). Note that, as is common for all spectral reconstruction approaches, the robust determination of the peak width requires input data of a much higher quality than the determination of the peak position.The first attempts of extracting spectral functions for the determination of the potential were based on the standard implementation of the MEM by Bryan. Since generally only a small number of simulation datapoints O(10-40) are available, it was found that the restricted SVD search space of the MEM was unable to accurately recover the narrow and strongly peaked spectral feature encoding the potential. Its position was systematically overestimated. The situation improved after an MEM implementation with an extended search space had been developed in Refs. [133,134]. As has been benchmarked with HTL correlator data in Ref. [197] this leads to more accurate values for Re[V ]. On the other hand even with an extended search space the MEM was found to produce spectral features, which resemble Gaussian peaks [206], even if the underlying spectral function contains a Breit-Wigner like structure. This is a serious drawback, since a Gaussian peak inserted into Eq. ( 173) will lead to the incorrect conclusion that the imaginary part of the potential grows with time. It took the development of a completely redesigned reconstruction approach, the BR method, to achieve reconstructions that faithfully reproduce not only the overall functional form, but also quantitatively the position and the width of the encoded peaks (see Ref. [128]). Note that, as is common for all spectral reconstruction approaches, the robust determination of the peak width requires input data of a much higher quality than the determination of the peak position.</p>
        <p>The first extraction of the potential from Wilson line correlators using both the BR method and the appropriate fitting strategy was presented in Ref. [213]. This study on the one hand investigated lattice Wilson correlators from pure gauge SU(3) fixed scale simulations on N s = 32 lattices with the naive anisotropic Wilson action. A relatively fine lattice spacing a = 0.039 fm at β = 7 and renormalized anisotropy ξ r = 4 was chosen as originally introduced in Ref. [214]. On the other hand the study used fixed box simulations on isotropic N s = 48 grids with N f = 2 + 1 flavors of light quarks (m π ≈ 300Mev) described by the asqtad action originally deployed in Ref. [215] (HotQCD collaboration). Updated results for quenched QCD on lattices with significantly larger physical volume using the parameter set β = 6.1, a = 0.097 and ξ b = 4 originally tuned in Ref. [216] were subsequently discussed in [217], clarifying the effect of finite volume artifacts in the previous studies.The first extraction of the potential from Wilson line correlators using both the BR method and the appropriate fitting strategy was presented in Ref. [213]. This study on the one hand investigated lattice Wilson correlators from pure gauge SU(3) fixed scale simulations on N s = 32 lattices with the naive anisotropic Wilson action. A relatively fine lattice spacing a = 0.039 fm at β = 7 and renormalized anisotropy ξ r = 4 was chosen as originally introduced in Ref. [214]. On the other hand the study used fixed box simulations on isotropic N s = 48 grids with N f = 2 + 1 flavors of light quarks (m π ≈ 300Mev) described by the asqtad action originally deployed in Ref. [215] (HotQCD collaboration). Updated results for quenched QCD on lattices with significantly larger physical volume using the parameter set β = 6.1, a = 0.097 and ξ b = 4 originally tuned in Ref. [216] were subsequently discussed in [217], clarifying the effect of finite volume artifacts in the previous studies.</p>
        <p>In Fig. 18 we show in the top row concrete examples of reconstructed spectral functions from quenched lattice simulations of Wilson line correlators in Coulomb gauge from Ref. [217]. In order to avoid possible divergent terms, as well as to reduce the influence of lattice artifacts, the reconstruction is carried out by excluding the first τ = 0 and last correlator point τ = 1/T along imaginary time. The effects of regularization are checked by carrying out the reconstruction not just with a constant default model but also deploying polynomials m(ω) = m 0 (ω min -1) γ in frequency with positive and negative powers γ , as well as different amplitudes m 0 .In Fig. 18 we show in the top row concrete examples of reconstructed spectral functions from quenched lattice simulations of Wilson line correlators in Coulomb gauge from Ref. [217]. In order to avoid possible divergent terms, as well as to reduce the influence of lattice artifacts, the reconstruction is carried out by excluding the first τ = 0 and last correlator point τ = 1/T along imaginary time. The effects of regularization are checked by carrying out the reconstruction not just with a constant default model but also deploying polynomials m(ω) = m 0 (ω min -1) γ in frequency with positive and negative powers γ , as well as different amplitudes m 0 .</p>
        <p>The left panel corresponds to a temperature of T = 113 MeV deep in the confined phase, while the right panel contains the results at T = 406 MeV, where the gluonic medium is already deconfined (T β=6.1 c = 290 MeV). The curves of different shades correspond to different spatial separation distances between r/a = 1 . . . 17, from darkest to lightest. One clearly sees that in all cases a well defined lowest lying peak is recovered, which has the form of a skewed Breit-Wigner. In turn the spectral reconstruction indicates that indeed a potential description emerges at sufficiently late Minkowski times. Note that due to the fixed scale approach there are much less datapoints N τ = 20 vs. N τ = 72 available at high temperatures but the BR method is still able to identify a well defined lowest lying peak, as well as indications of the shoulder structures The different datasets correspond to different deviations ∆ from the Coulomb gauge fixing condition (colored points). The slope of the correlator, corresponding to the real-part of the potential is fitted by a single exponential in the range given in the legend and shown as solid line. One finds that while the color singlet free energies, defined from the correlator at τ = β depend on the position in gauge space beyond statistical errors, the slope remains unchanged. at higher frequencies akin to what was found in the HTL computations in Fig. 16. Using the fit ansatz of Eq. ( 177) the real and imaginary parts can be estimated, as shown in the left and right panel of the bottom row respectively. The datapoints of Re[V ] are shifted by hand in y-direction for better readability. Correctly renormalized they take on the same values at small distances, recovering the T = 0 behavior there. The Im[V ] values on the other hand are shifted by hand in x-direction, they originally all vanish at distance r = 0. The errorbars denote statistical uncertainties based on a Jackknife resampling, while the gray errorbands encode systematic uncertainty, among others the dependence on the choice of default model.The left panel corresponds to a temperature of T = 113 MeV deep in the confined phase, while the right panel contains the results at T = 406 MeV, where the gluonic medium is already deconfined (T β=6.1 c = 290 MeV). The curves of different shades correspond to different spatial separation distances between r/a = 1 . . . 17, from darkest to lightest. One clearly sees that in all cases a well defined lowest lying peak is recovered, which has the form of a skewed Breit-Wigner. In turn the spectral reconstruction indicates that indeed a potential description emerges at sufficiently late Minkowski times. Note that due to the fixed scale approach there are much less datapoints N τ = 20 vs. N τ = 72 available at high temperatures but the BR method is still able to identify a well defined lowest lying peak, as well as indications of the shoulder structures The different datasets correspond to different deviations ∆ from the Coulomb gauge fixing condition (colored points). The slope of the correlator, corresponding to the real-part of the potential is fitted by a single exponential in the range given in the legend and shown as solid line. One finds that while the color singlet free energies, defined from the correlator at τ = β depend on the position in gauge space beyond statistical errors, the slope remains unchanged. at higher frequencies akin to what was found in the HTL computations in Fig. 16. Using the fit ansatz of Eq. ( 177) the real and imaginary parts can be estimated, as shown in the left and right panel of the bottom row respectively. The datapoints of Re[V ] are shifted by hand in y-direction for better readability. Correctly renormalized they take on the same values at small distances, recovering the T = 0 behavior there. The Im[V ] values on the other hand are shifted by hand in x-direction, they originally all vanish at distance r = 0. The errorbars denote statistical uncertainties based on a Jackknife resampling, while the gray errorbands encode systematic uncertainty, among others the dependence on the choice of default model.</p>
        <p>At this point let us focus on the qualitative behavior seen in the real-and imaginary parts. In the confined phase the potential exhibits a Cornell like behavior with a Coulombic part at small distances r &lt; 0.3 fm and a linearly rising part at larger distances. In the absence of dynamical quarks no string breaking occurs. Interestingly the lattice results indicate that below T c in the absence of deconfined color charges no significant screening occurs. The heavy mass of the glueball excitations suppresses their interference with the binding of static quarks. Once the deconfined phase is reached at T = 295 MeV a very different behavior emerges, the real part starts to flatten off and approaches a constant at large distances, indicative of screening. Such a rather abrupt change in behavior is interpreted as a manifestation of the phase transition that emerges in the infinite volume limit.At this point let us focus on the qualitative behavior seen in the real-and imaginary parts. In the confined phase the potential exhibits a Cornell like behavior with a Coulombic part at small distances r &lt; 0.3 fm and a linearly rising part at larger distances. In the absence of dynamical quarks no string breaking occurs. Interestingly the lattice results indicate that below T c in the absence of deconfined color charges no significant screening occurs. The heavy mass of the glueball excitations suppresses their interference with the binding of static quarks. Once the deconfined phase is reached at T = 295 MeV a very different behavior emerges, the real part starts to flatten off and approaches a constant at large distances, indicative of screening. Such a rather abrupt change in behavior is interpreted as a manifestation of the phase transition that emerges in the infinite volume limit.</p>
        <p>Another interesting finding is that Re[V ] lies quite close to the color singlet free energies extracted on the same lattices (not shown). This is a nontrivial finding, as the data point W ∥ (r, τ = β), which encodes the free energies, is not even included in the reconstruction of the spectral function. There exists however a clear difference in behavior between F 1 and Re[V ] in the confined phase of quenched QCD. As illustrated in Ref. [218] the former shows a clear overshoot of its T = 0 value. Since it is expected that for a microscopic interaction thermal effects lead at most to a weakening of the potential, it is reassuring that Re[V ](T &gt; 0) indeed does not show a similar overshoot.Another interesting finding is that Re[V ] lies quite close to the color singlet free energies extracted on the same lattices (not shown). This is a nontrivial finding, as the data point W ∥ (r, τ = β), which encodes the free energies, is not even included in the reconstruction of the spectral function. There exists however a clear difference in behavior between F 1 and Re[V ] in the confined phase of quenched QCD. As illustrated in Ref. [218] the former shows a clear overshoot of its T = 0 value. Since it is expected that for a microscopic interaction thermal effects lead at most to a weakening of the potential, it is reassuring that Re[V ](T &gt; 0) indeed does not show a similar overshoot.</p>
        <p>The extraction of the imaginary part is much less robust. Below T c an artificial width is present in the reconstructed spectra, which changes with the choice of default model. I.e. no significant signal for a finite imaginary part is found below T &lt; 290 MeV. On the other hand in the deconfined phase, the spectral width grows significantly and Ref. [217] concludes that indeed a finite Im[V ] has been observed. Note that these results are obtained at a finite lattice spacing and volume and that so far no continuum limit extrapolation for the proper potential in quenched QCD exists.The extraction of the imaginary part is much less robust. Below T c an artificial width is present in the reconstructed spectra, which changes with the choice of default model. I.e. no significant signal for a finite imaginary part is found below T &lt; 290 MeV. On the other hand in the deconfined phase, the spectral width grows significantly and Ref. [217] concludes that indeed a finite Im[V ] has been observed. Note that these results are obtained at a finite lattice spacing and volume and that so far no continuum limit extrapolation for the proper potential in quenched QCD exists.</p>
        <p>The use of the Wilson line correlator to extract the potential begs the question of how the choice of gauge influences the analysis outcome. To shed light on this issue we present in Fig. 19 the Wilson line correlator in quenched QCD from an anisotropic 32 3 × 24 lattice at β = 7 and ξ r = 4. The colored points correspond to a spatial separation of r/a s = 2. After iteratively fixing to Coulomb gauge down to a tolerance of ∆ = 10 -15 (blue squares) we act with a random gauge transformation and again step towards Coulomb gauge computing the Wilson line correlator on the way for different tolerances ∆ = 10 -1 , 10 -2 , 10 -6 . One clearly sees that the absolute value of the correlator changes as the gauge is changed. This e.g. affects the value of the color singlet free energies, which are defined from the logarithm of the correlator at the latest available Euclidean time. Their values change beyond the statistical errorbars. At the same time, an inspection of the behavior of the correlator in the intermediate τ region, which is where the low lying spectral peak dominates, reveals that its slope remains unaffected by the deviation from Coulomb gauge. In turn the real-part of the potential in this example is equally unaffected. The picture that emerges is that the Wilson line correlator contains both gauge dependent and gauge independent information. The position of its lowest lying spectral peak appears to be insensitive to a change of gauge, while its tails at low frequencies (dominating the τ = β regime) as well as the spectral structures at high frequencies (dominating at small τ ) are modified significantly. This crosscheck, while far from a proof, is at least an indication that the extraction of the real part of the potential from Wilson line correlators in Coulomb gauge is fathomable.The use of the Wilson line correlator to extract the potential begs the question of how the choice of gauge influences the analysis outcome. To shed light on this issue we present in Fig. 19 the Wilson line correlator in quenched QCD from an anisotropic 32 3 × 24 lattice at β = 7 and ξ r = 4. The colored points correspond to a spatial separation of r/a s = 2. After iteratively fixing to Coulomb gauge down to a tolerance of ∆ = 10 -15 (blue squares) we act with a random gauge transformation and again step towards Coulomb gauge computing the Wilson line correlator on the way for different tolerances ∆ = 10 -1 , 10 -2 , 10 -6 . One clearly sees that the absolute value of the correlator changes as the gauge is changed. This e.g. affects the value of the color singlet free energies, which are defined from the logarithm of the correlator at the latest available Euclidean time. Their values change beyond the statistical errorbars. At the same time, an inspection of the behavior of the correlator in the intermediate τ region, which is where the low lying spectral peak dominates, reveals that its slope remains unaffected by the deviation from Coulomb gauge. In turn the real-part of the potential in this example is equally unaffected. The picture that emerges is that the Wilson line correlator contains both gauge dependent and gauge independent information. The position of its lowest lying spectral peak appears to be insensitive to a change of gauge, while its tails at low frequencies (dominating the τ = β regime) as well as the spectral structures at high frequencies (dominating at small τ ) are modified significantly. This crosscheck, while far from a proof, is at least an indication that the extraction of the real part of the potential from Wilson line correlators in Coulomb gauge is fathomable.</p>
        <p>First estimates for the real and imaginary parts of the real-time potential in full QCD have been presented in Ref. [213,219] The analysis of the real-time potential in full QCD is currently ongoing on realistic high statistic lattices from the HotQCD and TUMQCD collaboration, a status update has been presented at the 2018 Quark Matter conference in Ref. [220].First estimates for the real and imaginary parts of the real-time potential in full QCD have been presented in Ref. [213,219] The analysis of the real-time potential in full QCD is currently ongoing on realistic high statistic lattices from the HotQCD and TUMQCD collaboration, a status update has been presented at the 2018 Quark Matter conference in Ref. [220].</p>
        <p>Using the HISQ action to implement N f = 2+1 light quarks flavors with almost physical pion mass m π = 160 MeV on N s = 48 and N τ = 12 (see [8]), as well as N τ = 16 grids (see [221]), a large number of configurations (N conf = 4 -9 × 10 3 ) has been generated. Deploying a fixed box approach, the ensembles span a temperature range between T = 150-1451 MeV, much further than previous studies. In the regime T &gt; 198 MeV spectral structures become extended enough that the BR method starts to exhibit ringing artifacts, as it tries to reconstruct these features from a very small number of input datapoints. Since Bayesian methods only improve as both the number of datapoints is increased and the errors on the input is reduced, the available high statistics alone cannot remedy this situation. However with sub percent errors in the correlators one may expect the Padé reconstruction approach of Section 2.4.2 to be a viable alternative.Using the HISQ action to implement N f = 2+1 light quarks flavors with almost physical pion mass m π = 160 MeV on N s = 48 and N τ = 12 (see [8]), as well as N τ = 16 grids (see [221]), a large number of configurations (N conf = 4 -9 × 10 3 ) has been generated. Deploying a fixed box approach, the ensembles span a temperature range between T = 150-1451 MeV, much further than previous studies. In the regime T &gt; 198 MeV spectral structures become extended enough that the BR method starts to exhibit ringing artifacts, as it tries to reconstruct these features from a very small number of input datapoints. Since Bayesian methods only improve as both the number of datapoints is increased and the errors on the input is reduced, the available high statistics alone cannot remedy this situation. However with sub percent errors in the correlators one may expect the Padé reconstruction approach of Section 2.4.2 to be a viable alternative.</p>
        <p>The feasibility of the Padé approach is tested by using the HTL Wilson line correlators corresponding to the spectral functions at T = 2.33T C given in Fig. 16. Discretized with the same N τ = 12 points available on the lattice and distorted with Gaussian noise that leads to constant relative errors ∆W /W = 10 -2 , the real-and imaginary part of the HTL potential The values of the real-time potential on HISQ lattices so far have not been published, as the full uncertainty budget of the computation has not been established. In particular the question remains whether the spectral reconstruction from a discrete set of delta peaks leads to artifacts as of yet unaccounted for. This analysis is currently work in progress.The feasibility of the Padé approach is tested by using the HTL Wilson line correlators corresponding to the spectral functions at T = 2.33T C given in Fig. 16. Discretized with the same N τ = 12 points available on the lattice and distorted with Gaussian noise that leads to constant relative errors ∆W /W = 10 -2 , the real-and imaginary part of the HTL potential The values of the real-time potential on HISQ lattices so far have not been published, as the full uncertainty budget of the computation has not been established. In particular the question remains whether the spectral reconstruction from a discrete set of delta peaks leads to artifacts as of yet unaccounted for. This analysis is currently work in progress.</p>
        <p>The spectral reconstruction presents an ill-posed inverse problem and both the Bayesian as well as the Padé reconstruction can introduce methods artifacts into the extracted potential values that may not have been spotted by mock data analyses so far. Thus there are ongoing efforts to devise extraction strategies that operate directly on the Euclidean correlator or its moments, denoted here as µ n . The first moment is nothing but the effective potential, the second moment is defined as µ 2 = -∂ τ µ 1 . A first study has been presented at the Hard Probes conference 2013 as Ref. [222], where the Wilson line correlator in the QGP phase was fitted using the HTL functional form of the spectral function with modified frequency arguments ρ HTL ∥ (λ(ω -E)). λ and E are taken as fit parameters. At high temperatures, where QCD becomes weakly coupled and on very fine lattices, where the cutoff is far from the relevant spectral structures, this approach is promising. On the other hand around the crossover transition the question remains whether such an ansatz is well justified. In a follow up study presented at Quark Matter 2017 as Ref. [223], a Breit-Wigner fit without skewing has been performed in order to reproduce the first and second moments. In both studies the values for Re[V ] that have been obtained are significantly larger than those from the direct spectral reconstruction and lie close to the T = 0 results. On the one hand the use of a Breit-Wigner without skewing may partially contribute such a larger value. On the other hand these result pose the question whether in general fits of a discrete spectral function composed of delta peaks using a continuous ansatz suffer from sparseness in frequency. At the Lattice 2019 conference an interesting alternative proposal has been put forward [224,225], which by combining Euclidean Wilson correlators in the forward W (τ ) and backward W (βτ ) direction proposes to single out the real-and imaginary parts from a plateau fit of the corresponding Euclidean data itself. Progress in direct methods would indeed be highly appreciated to reduce the systematic uncertainties arising from the spectral reconstructions.The spectral reconstruction presents an ill-posed inverse problem and both the Bayesian as well as the Padé reconstruction can introduce methods artifacts into the extracted potential values that may not have been spotted by mock data analyses so far. Thus there are ongoing efforts to devise extraction strategies that operate directly on the Euclidean correlator or its moments, denoted here as µ n . The first moment is nothing but the effective potential, the second moment is defined as µ 2 = -∂ τ µ 1 . A first study has been presented at the Hard Probes conference 2013 as Ref. [222], where the Wilson line correlator in the QGP phase was fitted using the HTL functional form of the spectral function with modified frequency arguments ρ HTL ∥ (λ(ω -E)). λ and E are taken as fit parameters. At high temperatures, where QCD becomes weakly coupled and on very fine lattices, where the cutoff is far from the relevant spectral structures, this approach is promising. On the other hand around the crossover transition the question remains whether such an ansatz is well justified. In a follow up study presented at Quark Matter 2017 as Ref. [223], a Breit-Wigner fit without skewing has been performed in order to reproduce the first and second moments. In both studies the values for Re[V ] that have been obtained are significantly larger than those from the direct spectral reconstruction and lie close to the T = 0 results. On the one hand the use of a Breit-Wigner without skewing may partially contribute such a larger value. On the other hand these result pose the question whether in general fits of a discrete spectral function composed of delta peaks using a continuous ansatz suffer from sparseness in frequency. At the Lattice 2019 conference an interesting alternative proposal has been put forward [224,225], which by combining Euclidean Wilson correlators in the forward W (τ ) and backward W (βτ ) direction proposes to single out the real-and imaginary parts from a plateau fit of the corresponding Euclidean data itself. Progress in direct methods would indeed be highly appreciated to reduce the systematic uncertainties arising from the spectral reconstructions.</p>
        <p>At first sight the advent of a first principles definition of a proper real-time in-medium interquark potential and its extraction from lattice QCD appears to render potential models irrelevant. On closer inspection however it turns out that only their role has shifted. Lattice QCD results come in the form of discrete datapoints for Re[V ] and Im[V ] which cannot be directly used for solving e.g. a Schrödinger equation for the forward quarkonium correlator D &gt; . I.e. the first role of potential models today is to provide an analytic parametrization of lattice QCD results, best described by as small as possible a number of parameters. The main parameter responsible for the in-medium modification is often called the Debye mass, in analogy with the original works of Debye and Hückel [150]. If secondly the construction of the potential model provides an intuitive physical picture to explain the temperature dependence of the lattice potential, it may help us interpret the otherwise ''black box'' results arising from the numerical simulation. The third role for model potentials can lie in opening up avenues to explore the values of the potential in parameter ranges, where lattice QCD simulations are currently unavailable, be it at finite Baryo-chemical potential or finite center of mass velocity.At first sight the advent of a first principles definition of a proper real-time in-medium interquark potential and its extraction from lattice QCD appears to render potential models irrelevant. On closer inspection however it turns out that only their role has shifted. Lattice QCD results come in the form of discrete datapoints for Re[V ] and Im[V ] which cannot be directly used for solving e.g. a Schrödinger equation for the forward quarkonium correlator D &gt; . I.e. the first role of potential models today is to provide an analytic parametrization of lattice QCD results, best described by as small as possible a number of parameters. The main parameter responsible for the in-medium modification is often called the Debye mass, in analogy with the original works of Debye and Hückel [150]. If secondly the construction of the potential model provides an intuitive physical picture to explain the temperature dependence of the lattice potential, it may help us interpret the otherwise ''black box'' results arising from the numerical simulation. The third role for model potentials can lie in opening up avenues to explore the values of the potential in parameter ranges, where lattice QCD simulations are currently unavailable, be it at finite Baryo-chemical potential or finite center of mass velocity.</p>
        <p>Over the past two decades several studies have put forward proposals on how to construct appropriate analytic parameterizations of the interquark potential at finite temperature. Before the 2007 discovery that the potential is complex valued, the focus lay on capturing its real part. The starting point of all these models is the realization that the T = 0 potential is very well described by the Cornell formOver the past two decades several studies have put forward proposals on how to construct appropriate analytic parameterizations of the interquark potential at finite temperature. Before the 2007 discovery that the potential is complex valued, the focus lay on capturing its real part. The starting point of all these models is the realization that the T = 0 potential is very well described by the Cornell form</p>
        <p>with α S = C F g 2 /4π the (running) strong coupling constant defined in accord with the phenomenology literature. σ denotes the string-tension and c is an additive constant. These three parameters will have to be determined using T = 0 lattice QCD simulations. The first work in this context is the study by Karsch, Mehr and Satz [226]. Using arguments based on the twodimensional Schwinger model, an exponential screening of both the Coulombic and string like part was proposedwith α S = C F g 2 /4π the (running) strong coupling constant defined in accord with the phenomenology literature. σ denotes the string-tension and c is an additive constant. These three parameters will have to be determined using T = 0 lattice QCD simulations. The first work in this context is the study by Karsch, Mehr and Satz [226]. Using arguments based on the twodimensional Schwinger model, an exponential screening of both the Coulombic and string like part was proposed</p>
        <p>which depends on a single temperature dependent parameter m D and reduces to the Cornell form as m D → 0. The in-medium string part of the KMS potential has also been argued to arise from a non vanishing gluon condensate as proposed in [227].which depends on a single temperature dependent parameter m D and reduces to the Cornell form as m D → 0. The in-medium string part of the KMS potential has also been argued to arise from a non vanishing gluon condensate as proposed in [227].</p>
        <p>The KMS expression for the string real part may be obtained by modeling the quark-antiquark interactions as being effectively one-dimensional and string like as proposed in version 1 of Ref. [228]. In addition Ref. [229] suggests that an entropic force may influence the interquark binding. Using an ad-hoc identification of the real part of the potential with thermodynamic quantities such an entropic term may be added and as shown in Ref. [228] leads toThe KMS expression for the string real part may be obtained by modeling the quark-antiquark interactions as being effectively one-dimensional and string like as proposed in version 1 of Ref. [228]. In addition Ref. [229] suggests that an entropic force may influence the interquark binding. Using an ad-hoc identification of the real part of the potential with thermodynamic quantities such an entropic term may be added and as shown in Ref. [228] leads to</p>
        <p>Compared to the KMS result this expression shows a weaker dependence on m D . I.e. using the same value for m D KMS shows a stronger deviation from the m D = 0 behavior. The same form of the potential had been proposed by Bazow and Strickland in Ref. [230] using a different line of reasoning. They start from the KMS potential and subtract an entropy related term, arriving at the expression in Eq. (180).Compared to the KMS result this expression shows a weaker dependence on m D . I.e. using the same value for m D KMS shows a stronger deviation from the m D = 0 behavior. The same form of the potential had been proposed by Bazow and Strickland in Ref. [230] using a different line of reasoning. They start from the KMS potential and subtract an entropy related term, arriving at the expression in Eq. (180).</p>
        <p>Another set of studies have exploited the fact that the concept of Gauss-law, well known from the study of classical electrodynamics, can be extended (for a derivation see Ref. [231]) to potentials with arbitrary monomial powers in the separation distance. In Ref. [232] for the first time the Gauss-law was combined with Debye-Hückel theory to describe the in-medium screening of the Cornell potential. The resulting functional form did not yet allow to capture the behavior of the color singlet free energy in lattice QCD, which at that time was taken as a proxy for Re[V ]. Introducing an additional free fit parameter κ improved the agreement with numerical data, but its relation to m D remained unclear.Another set of studies have exploited the fact that the concept of Gauss-law, well known from the study of classical electrodynamics, can be extended (for a derivation see Ref. [231]) to potentials with arbitrary monomial powers in the separation distance. In Ref. [232] for the first time the Gauss-law was combined with Debye-Hückel theory to describe the in-medium screening of the Cornell potential. The resulting functional form did not yet allow to capture the behavior of the color singlet free energy in lattice QCD, which at that time was taken as a proxy for Re[V ]. Introducing an additional free fit parameter κ improved the agreement with numerical data, but its relation to m D remained unclear.</p>
        <p>The first step towards consistently parametrizing a complex valued potential was taken in Ref. [233]. It is based on linear response theory where the in-medium electric field is computed by dividing the vacuum potential by the static dielectric constant of the medium in momentum space (see e.g. Ref. [41])The first step towards consistently parametrizing a complex valued potential was taken in Ref. [233]. It is based on linear response theory where the in-medium electric field is computed by dividing the vacuum potential by the static dielectric constant of the medium in momentum space (see e.g. Ref. [41])</p>
        <p>The authors propose to use the permittivity of a weakly coupled QGP obtained from HTL perturbation theoryThe authors propose to use the permittivity of a weakly coupled QGP obtained from HTL perturbation theory</p>
        <p>In this expression all medium effects are governed by a single temperature dependent parameter, the Debye mass m D .In this expression all medium effects are governed by a single temperature dependent parameter, the Debye mass m D .</p>
        <p>Since ε is complex valued, so will be the in-medium potential. Computing the inverse Fourier transform separately for the Coulombic and string like part and subsequently adding the two contributions leads toSince ε is complex valued, so will be the in-medium potential. Computing the inverse Fourier transform separately for the Coulombic and string like part and subsequently adding the two contributions leads to</p>
        <p>) ,) ,</p>
        <p>φ is the same function that appears in the HTL result in Eq. ( 170) and χ 0 is given byφ is the same function that appears in the HTL result in Eq. ( 170) and χ 0 is given by</p>
        <p>This potential model suffers from two drawbacks. The first and most critical is the fact that the in-medium real part arising from the string-like contribution of the Cornell potential exhibits an unscreened 1/r term, which is both counter intuitive and also does not reflect the actual behavior found in the lattice QCD potential. It appears that the linear response relation alone does not yet self consistently implement screening. The second issue is related to the fact that the imaginary part arising from the vacuum string diverges logarithmically. As we will discuss below this can be remedied by implementing string breaking. Another proposal using direct Fourier transforms was put forward in version 2 of [228]. The authors add a term to the perturbative gluon propagator, which at T = 0 behaves as ∝ p -4 . At T &gt; 0 it is washed out in momentum space by appropriately placed factors of m D . In vacuum this implements the Cornell potential ansatz. At finite temperature it represents an independent way of incorporating medium effects into the string part of the potential. In practice this setup recovers the KMS real-part and leads in addition to a modified imaginary part, which remains finite in the large distance limit.This potential model suffers from two drawbacks. The first and most critical is the fact that the in-medium real part arising from the string-like contribution of the Cornell potential exhibits an unscreened 1/r term, which is both counter intuitive and also does not reflect the actual behavior found in the lattice QCD potential. It appears that the linear response relation alone does not yet self consistently implement screening. The second issue is related to the fact that the imaginary part arising from the vacuum string diverges logarithmically. As we will discuss below this can be remedied by implementing string breaking. Another proposal using direct Fourier transforms was put forward in version 2 of [228]. The authors add a term to the perturbative gluon propagator, which at T = 0 behaves as ∝ p -4 . At T &gt; 0 it is washed out in momentum space by appropriately placed factors of m D . In vacuum this implements the Cornell potential ansatz. At finite temperature it represents an independent way of incorporating medium effects into the string part of the potential. In practice this setup recovers the KMS real-part and leads in addition to a modified imaginary part, which remains finite in the large distance limit.</p>
        <p>In order to implement screening based on the HTL permittivity in a self consistent fashion Ref. [234] proposed to return to the generalized Gauss law, combining the ideas of the Debye-Hückel theory from [232] with the use of the HTL permittivity from [233]. At that time the authors however were not able to solve the resulting differential equations without introducing an ad-hoc assumption about the form of the string part at finite temperature. Only recently Ref. [235] succeeded in that respect, starting from the generalized Gauss law ∇ •In order to implement screening based on the HTL permittivity in a self consistent fashion Ref. [234] proposed to return to the generalized Gauss law, combining the ideas of the Debye-Hückel theory from [232] with the use of the HTL permittivity from [233]. At that time the authors however were not able to solve the resulting differential equations without introducing an ad-hoc assumption about the form of the string part at finite temperature. Only recently Ref. [235] succeeded in that respect, starting from the generalized Gauss law ∇ •</p>
        <p>applicable to electric fields E vac (r) = -∇V vac (r) = qr a-1 r. For a = -1, q = α S it reduces to the standard Gauss law for the Coulomb potential, but also accommodates a linearly rinsing potential via a = 1, q = σ . The expression for general powers of the separation distance a in terms of the Gauss-law operator G a readsapplicable to electric fields E vac (r) = -∇V vac (r) = qr a-1 r. For a = -1, q = α S it reduces to the standard Gauss law for the Coulomb potential, but also accommodates a linearly rinsing potential via a = 1, q = σ . The expression for general powers of the separation distance a in terms of the Gauss-law operator G a reads</p>
        <p>The decisive step is to apply the Gauss law operator to the linear response relation of Eq. ( 181)The decisive step is to apply the Gauss law operator to the linear response relation of Eq. ( 181)</p>
        <p>The second equal sign follow from the fact that the convolution commutes with G a . Considering the Coulombic and string part separately one thus obtains two sets of differential equations for the in-medium potentialThe second equal sign follow from the fact that the convolution commutes with G a . Considering the Coulombic and string part separately one thus obtains two sets of differential equations for the in-medium potential</p>
        <p>--</p>
        <p>At this point the coordinate space expression for the HTL permittivity is needed, which may be computed from the explicit expression Eq. ( 182)At this point the coordinate space expression for the HTL permittivity is needed, which may be computed from the explicit expression Eq. ( 182)</p>
        <p>) .) .</p>
        <p>Using Eqs. (191) and (192) in Eq. ( 189) reproduces the original HTL result [15] ReVUsing Eqs. (191) and (192) in Eq. ( 189) reproduces the original HTL result [15] ReV</p>
        <p>while for the string part one obtainswhile for the string part one obtains</p>
        <p>) .) .</p>
        <p>((</p>
        <p>Note that the string in-medium real part obtained here, takes on the same form as Eq. ( 180). Interestingly this means that a contribution similar to an entropic force terms arises naturally in this model setup.Note that the string in-medium real part obtained here, takes on the same form as Eq. ( 180). Interestingly this means that a contribution similar to an entropic force terms arises naturally in this model setup.</p>
        <p>Added together we arrive at the Gauss-law expression for the complex in-medium potential. Similar to what we had seen in previous attempts of constructing parameterizations of the in-medium potential, also here the naively evaluated string contribution to Im[V ] diverges at large distances. Ref. [235] proposed that this behavior is connected with the unphysical and unregulated rise in the Cornell potential at T = 0 and can be remedied by modeling the phenomenon of string breaking. After identifying the IR divergence which underlies the unphysical behavior, it is regularized by introducing the term ∆ D = ∆/m D that effectively cuts off very small momenta, where the Debye mass not already does soAdded together we arrive at the Gauss-law expression for the complex in-medium potential. Similar to what we had seen in previous attempts of constructing parameterizations of the in-medium potential, also here the naively evaluated string contribution to Im[V ] diverges at large distances. Ref. [235] proposed that this behavior is connected with the unphysical and unregulated rise in the Cornell potential at T = 0 and can be remedied by modeling the phenomenon of string breaking. After identifying the IR divergence which underlies the unphysical behavior, it is regularized by introducing the term ∆ D = ∆/m D that effectively cuts off very small momenta, where the Debye mass not already does so</p>
        <p>The expression for Im[V ] above has been rewritten in a very similar form to the Coulombic contribution, i.e. as a temperature dependent prefactor with dimensions of energy, which is multiplied by a dimensionless momentum integral.The expression for Im[V ] above has been rewritten in a very similar form to the Coulombic contribution, i.e. as a temperature dependent prefactor with dimensions of energy, which is multiplied by a dimensionless momentum integral.</p>
        <p>The regularization condition is simply that this dimensionless integral shall asymptote to unity for r → ∞, as does the Coulombic one. This leads to the temperature independent value ofThe regularization condition is simply that this dimensionless integral shall asymptote to unity for r → ∞, as does the Coulombic one. This leads to the temperature independent value of</p>
        <p>Consistent with expectation, based on this regularization, the imaginary part goes over to the pure HTL result, as temperature is increased.Consistent with expectation, based on this regularization, the imaginary part goes over to the pure HTL result, as temperature is increased.</p>
        <p>Up to this point the running of the strong coupling in the T = 0 Cornell potential has not yet been considered.Up to this point the running of the strong coupling in the T = 0 Cornell potential has not yet been considered.</p>
        <p>Upcoming lattice QCD results on grids with very fine lattice spacing however will require to take this effect into account, as already indicated by the study of color singlet free energies in [236]. I.e. the parameter α S needs to be elevated to a function of distance α S (r), which for the purposes of the Gauss-law model is written as a power seriesUpcoming lattice QCD results on grids with very fine lattice spacing however will require to take this effect into account, as already indicated by the study of color singlet free energies in [236]. I.e. the parameter α S needs to be elevated to a function of distance α S (r), which for the purposes of the Gauss-law model is written as a power series</p>
        <p>where contributions from α (1) S and α (2) S can be absorbed into the already present vacuum parameters. To accommodate the terms besides a = -1, 1 the corresponding Gauss law operator G a needs to be considered, which leads to the following closed expression for the in-medium Re[V ] and Im[V ]where contributions from α (1) S and α (2) S can be absorbed into the already present vacuum parameters. To accommodate the terms besides a = -1, 1 the corresponding Gauss law operator G a needs to be considered, which leads to the following closed expression for the in-medium Re[V ] and Im[V ]</p>
        <p>ImVImV</p>
        <p>((</p>
        <p>The divergence of the in-medium imaginary part for a ≥ 1 requires a similar regularization strategy as discussed above for the string like part.The divergence of the in-medium imaginary part for a ≥ 1 requires a similar regularization strategy as discussed above for the string like part.</p>
        <p>The main benchmark for any potential parametrization is whether it is able to faithfully reproduce the non-perturbative lattice QCD data. Since the model presented here operates with a single temperature dependent parameter m D this is nontrivial. Based on the published data from [213,219], plotted in Fig. 20, the Gauss-law parametrization presented here has shown to succeed better in this task than the proposals of Ref. [233] and Ref. [234]. For the determination of the vacuum parameters α S , σ and c of the Cornell potential, two low temperature ensembles were utilized. It was found that at the distance scales 0.1 &lt; r &lt; 1.2 fm available on these lattices and within the uncertainties of the reconstruction the running of the coupling is negligible. I.e. as shown in the left panel of Fig. 23 the naive Cornell ansatz reproduces the two T = 0 datasets (gray) very well. Since the results here are not continuum extrapolated a small lattice spacing dependence of the vacuum parameters is observed.The main benchmark for any potential parametrization is whether it is able to faithfully reproduce the non-perturbative lattice QCD data. Since the model presented here operates with a single temperature dependent parameter m D this is nontrivial. Based on the published data from [213,219], plotted in Fig. 20, the Gauss-law parametrization presented here has shown to succeed better in this task than the proposals of Ref. [233] and Ref. [234]. For the determination of the vacuum parameters α S , σ and c of the Cornell potential, two low temperature ensembles were utilized. It was found that at the distance scales 0.1 &lt; r &lt; 1.2 fm available on these lattices and within the uncertainties of the reconstruction the running of the coupling is negligible. I.e. as shown in the left panel of Fig. 23 the naive Cornell ansatz reproduces the two T = 0 datasets (gray) very well. Since the results here are not continuum extrapolated a small lattice spacing dependence of the vacuum parameters is observed.</p>
        <p>Once the values of α S , σ and c are set, a fit of the single temperature dependent parameter m D allows one to reproduce the values of Re[V ] equally well (solid lines). The errorbands include both the uncertainty of the T = 0 and T &gt; 0 fits. interestingly Eqs. (193) and (195) The m D parameter introduced in the Gauss-law parametrization is of phenomenological origin and not equally rigorously related to the concept of screening, as e.g. the screening mass m E defined in Section 3.1. It simply attempts to summarize the in-medium modification as observed in the numerically determined lattice potential but should reduce to the perturbatively defined Debye mass at high temperatures (where the Gauss-law parametrization goes over into the HTL potential). Bearing these differences, as well as the fact that the results are not continuum extrapolated in mind, we may compare m D to the NLO prediction from perturbation theory, as well as the values extracted from both singlet free energies and the electric correlator C E-. What we find is that approaching T C from above, the Gauss-law parameter m D /T takes on smaller and smaller values, consistent with the fact that Re[V ] eventually approaches the Cornell form within the hadronic phase. A similar downward trend is not observed in neither m S nor m E so far. At temperatures well above T C the ratio here takes on slightly smaller values than those arising in m S or m E but still is larger than the NLO perturbative prediction. As shown in Fig. 24, a (surprisingly) good agreement between the prediction of Eqs. (194) and (198) (solid lines) and the tentative values of the imaginary part from the lattice (colored symbols) down to temperatures well within the hadronic phase is indeed found.Once the values of α S , σ and c are set, a fit of the single temperature dependent parameter m D allows one to reproduce the values of Re[V ] equally well (solid lines). The errorbands include both the uncertainty of the T = 0 and T &gt; 0 fits. interestingly Eqs. (193) and (195) The m D parameter introduced in the Gauss-law parametrization is of phenomenological origin and not equally rigorously related to the concept of screening, as e.g. the screening mass m E defined in Section 3.1. It simply attempts to summarize the in-medium modification as observed in the numerically determined lattice potential but should reduce to the perturbatively defined Debye mass at high temperatures (where the Gauss-law parametrization goes over into the HTL potential). Bearing these differences, as well as the fact that the results are not continuum extrapolated in mind, we may compare m D to the NLO prediction from perturbation theory, as well as the values extracted from both singlet free energies and the electric correlator C E-. What we find is that approaching T C from above, the Gauss-law parameter m D /T takes on smaller and smaller values, consistent with the fact that Re[V ] eventually approaches the Cornell form within the hadronic phase. A similar downward trend is not observed in neither m S nor m E so far. At temperatures well above T C the ratio here takes on slightly smaller values than those arising in m S or m E but still is larger than the NLO perturbative prediction. As shown in Fig. 24, a (surprisingly) good agreement between the prediction of Eqs. (194) and (198) (solid lines) and the tentative values of the imaginary part from the lattice (colored symbols) down to temperatures well within the hadronic phase is indeed found.</p>
        <p>After all it appears that the Gauss-law parametrization provides a efficient prescription to summarize the in-medium behavior of the non-perturbative in-medium heavy quark potential based on three vacuum parameters, as well as the temperature dependent Debye mass m D .After all it appears that the Gauss-law parametrization provides a efficient prescription to summarize the in-medium behavior of the non-perturbative in-medium heavy quark potential based on three vacuum parameters, as well as the temperature dependent Debye mass m D .</p>
        <p>So far we have focused on the heavy quark potential defined in the context of non-relativistic effective field theories of QCD. As discussed in Section 2.2 the appeal of using such EFTs lies in their systematic power counting, which allows well controlled matching to QCD using expansions in the heavy quark mass (HQET) or heavy quark velocity (NRQCD). The static potential V (0) S represents the lowest order Wilson coefficient in this sense for pNRQCD. On the other hand there are two other types of potentials found in the literature, which we will briefly discuss in the following. The first utilizes a relativistic notion of a potential based on the concept of the Bethe-Salpeter (BS) equation and the corresponding BS wavefunction. The second class defines the potential from the propagation of the time evolution of an analogue of heavy quarks using the AdS/CFT conjecture.So far we have focused on the heavy quark potential defined in the context of non-relativistic effective field theories of QCD. As discussed in Section 2.2 the appeal of using such EFTs lies in their systematic power counting, which allows well controlled matching to QCD using expansions in the heavy quark mass (HQET) or heavy quark velocity (NRQCD). The static potential V (0) S represents the lowest order Wilson coefficient in this sense for pNRQCD. On the other hand there are two other types of potentials found in the literature, which we will briefly discuss in the following. The first utilizes a relativistic notion of a potential based on the concept of the Bethe-Salpeter (BS) equation and the corresponding BS wavefunction. The second class defines the potential from the propagation of the time evolution of an analogue of heavy quarks using the AdS/CFT conjecture.</p>
        <p>The Bethe-Salpeter equation has been developed to treat the scattering, as well as bound state formation of two particles in a manifest relativistic fashion (for a review see e.g. [237]). The starting point is the time ordered four-point function D = ⟨Ω|φ 1 φ 2 φ 3 φ 4 |Ω⟩ of the involved fields in vacuum |Ω⟩. It represents the transition amplitude of going from two asymptotic incoming particles with relative four-momentum p and total four momentum P to two asymptotic outgoing ones with relative momentum q. Rearranging its perturbative expansion yields an implicit relationThe Bethe-Salpeter equation has been developed to treat the scattering, as well as bound state formation of two particles in a manifest relativistic fashion (for a review see e.g. [237]). The starting point is the time ordered four-point function D = ⟨Ω|φ 1 φ 2 φ 3 φ 4 |Ω⟩ of the involved fields in vacuum |Ω⟩. It represents the transition amplitude of going from two asymptotic incoming particles with relative four-momentum p and total four momentum P to two asymptotic outgoing ones with relative momentum q. Rearranging its perturbative expansion yields an implicit relation</p>
        <p>where the sum of all irreducible two-particle diagrams has already been suggestively assigned the letter V. G(k, P) denotes the propagator of the involved fields. In order to describe the formation of a bound state ψ from the particles of φ 1 and φ 2 the BS wavefunction Φ = ⟨Ω|φ 1 φ 2 |ψ⟩ is considered instead, for which a similar recursive definition as in Eq. ( 203) can be derived. It then acts as the relativistic generalization of the wavefunction of the Schrödinger equation. Since it is not possible to include all diagrams in V in practice, a truncation needs to be employed. The ladder approximation is the most common one. There the G(k, P) are taken to be the free field Feynman propagators of the underlying fields and only single particle interactions are included in V . In general the notion of a potential emerges if the diagrams resummed in the interaction Kernel V lead to a time independent and local quantity in position space. Note that for heavy quarks such a potential would contain not only the contributions from static interactions of the m → ∞ limit but also correction due to finite velocity, spin etc. that are absent in V (0) S .where the sum of all irreducible two-particle diagrams has already been suggestively assigned the letter V. G(k, P) denotes the propagator of the involved fields. In order to describe the formation of a bound state ψ from the particles of φ 1 and φ 2 the BS wavefunction Φ = ⟨Ω|φ 1 φ 2 |ψ⟩ is considered instead, for which a similar recursive definition as in Eq. ( 203) can be derived. It then acts as the relativistic generalization of the wavefunction of the Schrödinger equation. Since it is not possible to include all diagrams in V in practice, a truncation needs to be employed. The ladder approximation is the most common one. There the G(k, P) are taken to be the free field Feynman propagators of the underlying fields and only single particle interactions are included in V . In general the notion of a potential emerges if the diagrams resummed in the interaction Kernel V lead to a time independent and local quantity in position space. Note that for heavy quarks such a potential would contain not only the contributions from static interactions of the m → ∞ limit but also correction due to finite velocity, spin etc. that are absent in V (0) S .</p>
        <p>The BS wavefunction has been used to extract potential-like interaction kernels from non-perturbative T = 0 lattice QCD simulations, a procedure that involves two steps of reasoning. First, if the time evolution of the BS wavefunction in an interacting theory proceeds according to a Schrödinger equation with interaction potential then this potential can be reverse engineered from the computed values of Φ. Secondly, at T = 0 the evolution in Minkowski time and in Euclidean time are governed by the same potential, i.e. V may be read off from an appropriate imaginary time correlation function. Both in the study of nucleon-nucleon interactions [238] (HAL-QCD collaboration) and for charmonium in vacuum this strategy has been deployed [239][240][241][242][243].The BS wavefunction has been used to extract potential-like interaction kernels from non-perturbative T = 0 lattice QCD simulations, a procedure that involves two steps of reasoning. First, if the time evolution of the BS wavefunction in an interacting theory proceeds according to a Schrödinger equation with interaction potential then this potential can be reverse engineered from the computed values of Φ. Secondly, at T = 0 the evolution in Minkowski time and in Euclidean time are governed by the same potential, i.e. V may be read off from an appropriate imaginary time correlation function. Both in the study of nucleon-nucleon interactions [238] (HAL-QCD collaboration) and for charmonium in vacuum this strategy has been deployed [239][240][241][242][243].</p>
        <p>At finite temperature the so called T-matrix approach has been developed to describe both quarkonium and open heavy flavor particles (for a recent overview see [244]). It starts from the fact that the Bethe-Salpeter transition amplitude is related to the scattering S-matrix, whose nontrivial part is christened the T-matrix. The ladder approximation is deployed for both light and heavy degrees of freedom in the system. The interaction diagrams for the T-matrix are expressed by using the free finite temperature quark and gluon propagators G. In this approach the interaction kernel for both light and heavy quarks is modeled by a real-valued two-body potential that implements screening with different screening masses for the Coulombic m D and string like part m ′ D , as well as a third parameter c s to take into account string breaking effectsAt finite temperature the so called T-matrix approach has been developed to describe both quarkonium and open heavy flavor particles (for a recent overview see [244]). It starts from the fact that the Bethe-Salpeter transition amplitude is related to the scattering S-matrix, whose nontrivial part is christened the T-matrix. The ladder approximation is deployed for both light and heavy degrees of freedom in the system. The interaction diagrams for the T-matrix are expressed by using the free finite temperature quark and gluon propagators G. In this approach the interaction kernel for both light and heavy quarks is modeled by a real-valued two-body potential that implements screening with different screening masses for the Coulombic m D and string like part m ′ D , as well as a third parameter c s to take into account string breaking effects</p>
        <p>Note that starting with a real-valued microscopic potential here does not preclude the self energies computed via the T-matrix from becoming complex. In turn scattering effects are included in the evolution of meson-meson correlators and one may still find an imaginary part in the potential governing the evolution of the medium averaged quantities.Note that starting with a real-valued microscopic potential here does not preclude the self energies computed via the T-matrix from becoming complex. In turn scattering effects are included in the evolution of meson-meson correlators and one may still find an imaginary part in the potential governing the evolution of the medium averaged quantities.</p>
        <p>To determine the values of V RL the authors of Ref. [244] computed several quantities, such as the free energy differences in the presence of heavy quark pairs in the T-matrix approach and compared those to first-principle simulations on the lattice. In addition they compared their computations to open-heavy flavor [245] and bottomonium observables [246]. While the output of the iterative procedure to obtain V RL depended on the initialization according to a weak-or strongcoupling potential ansatz, it shows consistently larger values than those found for V (0) S directly on the lattice. Since V RL in the T-matrix approach governs not only the interactions of heavy quarks but also those of the light d.o.f. it is actually surprising that not larger differences compared to the static EFT potential are observed.To determine the values of V RL the authors of Ref. [244] computed several quantities, such as the free energy differences in the presence of heavy quark pairs in the T-matrix approach and compared those to first-principle simulations on the lattice. In addition they compared their computations to open-heavy flavor [245] and bottomonium observables [246]. While the output of the iterative procedure to obtain V RL depended on the initialization according to a weak-or strongcoupling potential ansatz, it shows consistently larger values than those found for V (0) S directly on the lattice. Since V RL in the T-matrix approach governs not only the interactions of heavy quarks but also those of the light d.o.f. it is actually surprising that not larger differences compared to the static EFT potential are observed.</p>
        <p>There have been proposals put forward in Refs. [247,248] to utilize the Euclidean time BS wavefunction at finite temperature to reverse engineer a potential for in-medium quarkonium. While straight forward in implementation, this strategy suffers from the absence of an equally rigorous theoretical connection between the imaginary time and real-time BS wavefunction as at T = 0.There have been proposals put forward in Refs. [247,248] to utilize the Euclidean time BS wavefunction at finite temperature to reverse engineer a potential for in-medium quarkonium. While straight forward in implementation, this strategy suffers from the absence of an equally rigorous theoretical connection between the imaginary time and real-time BS wavefunction as at T = 0.</p>
        <p>For completeness let us also mention another more exploratory proposal to determine the static interquark potential non-perturbatively. In a two step process first the real-time gluon propagator is determined from the lattice in Landau gauge and subsequently Fourier transformed to obtain the in-medium potential. A first implementation at T = 0 has been presented in Ref. [249] and a finite temperature generalization could make use of gluon spectral function results presented e.g. in [192].For completeness let us also mention another more exploratory proposal to determine the static interquark potential non-perturbatively. In a two step process first the real-time gluon propagator is determined from the lattice in Landau gauge and subsequently Fourier transformed to obtain the in-medium potential. A first implementation at T = 0 has been presented in Ref. [249] and a finite temperature generalization could make use of gluon spectral function results presented e.g. in [192].</p>
        <p>Instead of staying within QCD and being limited to the Euclidean domain for first principles computations, one may go over to QCD-like systems, where strong-coupling computations can be carried out directly in real-time. One such strategy to approximate the physics of QCD at finite temperature and density is based on the AdS/CFT conjecture (for a review see [250]). Roughly speaking, a pair of static test charges propagating in four-dimensional space-time is interacting via a string, which spans between the constituents and which extends into a fifth dimensions, called the bulk. Finite temperature fluctuations are implemented via the presence of a Hawking-radiating black-hole in that extra dimension. At small t'Hooft coupling quarkonium in AdS/CFT is expected to be hydrogen-like as discussed in Ref. [251], so the potential at small distances will be dominated by a Coulombic behavior. At large coupling on the other hand the behavior is more involved. It is found in Ref. [252] that even though the Wilson loop does not exhibit an area law, i.e. confinement is absent in the traditional sense, the asymptotic states of the theory are color neutral with the color charge being screened. The latter fact is understood from a process in analogy with string breaking. Separating two quarks analogues far enough apart breaks the string between them and leads to the generation of a light quark analogue pair, which then compensates for the color charge of the heavy color sources.Instead of staying within QCD and being limited to the Euclidean domain for first principles computations, one may go over to QCD-like systems, where strong-coupling computations can be carried out directly in real-time. One such strategy to approximate the physics of QCD at finite temperature and density is based on the AdS/CFT conjecture (for a review see [250]). Roughly speaking, a pair of static test charges propagating in four-dimensional space-time is interacting via a string, which spans between the constituents and which extends into a fifth dimensions, called the bulk. Finite temperature fluctuations are implemented via the presence of a Hawking-radiating black-hole in that extra dimension. At small t'Hooft coupling quarkonium in AdS/CFT is expected to be hydrogen-like as discussed in Ref. [251], so the potential at small distances will be dominated by a Coulombic behavior. At large coupling on the other hand the behavior is more involved. It is found in Ref. [252] that even though the Wilson loop does not exhibit an area law, i.e. confinement is absent in the traditional sense, the asymptotic states of the theory are color neutral with the color charge being screened. The latter fact is understood from a process in analogy with string breaking. Separating two quarks analogues far enough apart breaks the string between them and leads to the generation of a light quark analogue pair, which then compensates for the color charge of the heavy color sources.</p>
        <p>The propagation of the static pair of test charges can be described on the one hand by the real-time Wilson loop and on the other hand may be related to the Nambu-Goto action for the connecting string (the first works in this regard being Refs. [253,254]). The further the charges are spatially separated the deeper the string extends into the bulk, approaching the horizon of the black hole. Following e.g. Refs. [255][256][257], one finds that the finite temperature potential remains purely real until at a threshold distance, an imaginary part abruptly sets in. At this point the string has not yet touched the black hole horizon. Once it does, the computations as of yet cannot be meaningfully continued to further separation distances. For details on the involved difficulties related to identifying the appropriate string configurations contributing to the evolution of the Wilson loop see [257] and references therein.The propagation of the static pair of test charges can be described on the one hand by the real-time Wilson loop and on the other hand may be related to the Nambu-Goto action for the connecting string (the first works in this regard being Refs. [253,254]). The further the charges are spatially separated the deeper the string extends into the bulk, approaching the horizon of the black hole. Following e.g. Refs. [255][256][257], one finds that the finite temperature potential remains purely real until at a threshold distance, an imaginary part abruptly sets in. At this point the string has not yet touched the black hole horizon. Once it does, the computations as of yet cannot be meaningfully continued to further separation distances. For details on the involved difficulties related to identifying the appropriate string configurations contributing to the evolution of the Wilson loop see [257] and references therein.</p>
        <p>The decisive advantage of the AdS/CFT computations is that they are carried out directly in a real-time setting in the four-dimensional gauge theory. This gives access to the values of the AdS/CFT counterpart of the QCD static potential defined from the late-time behavior of the real-time Wilson loop. Comparing the definition of the proper real-time potential V (0) S and the free energies F 1 it has to be stated that what is computed in e.g. Ref. [257] and previous studies is not the free energies but the real-time potential itself. This fact is not correctly reflected in the title of these studies. An important contribution to the field was made in Ref. [257] as the correct renormalization of the potential has been addressed. It leads to a Re[V ], which, as physically expected, reduces to the T = 0 result at small separation distances at any temperature of the thermal medium. Prior to this study a temperature dependent renormalization scheme had been deployed. One current challenge lies in extending the results for the potential in the original AdS/CFT framework to geometries, in which the conformal symmetry is broken, in order to accommodate more realistically the behavior of QCD.The decisive advantage of the AdS/CFT computations is that they are carried out directly in a real-time setting in the four-dimensional gauge theory. This gives access to the values of the AdS/CFT counterpart of the QCD static potential defined from the late-time behavior of the real-time Wilson loop. Comparing the definition of the proper real-time potential V (0) S and the free energies F 1 it has to be stated that what is computed in e.g. Ref. [257] and previous studies is not the free energies but the real-time potential itself. This fact is not correctly reflected in the title of these studies. An important contribution to the field was made in Ref. [257] as the correct renormalization of the potential has been addressed. It leads to a Re[V ], which, as physically expected, reduces to the T = 0 result at small separation distances at any temperature of the thermal medium. Prior to this study a temperature dependent renormalization scheme had been deployed. One current challenge lies in extending the results for the potential in the original AdS/CFT framework to geometries, in which the conformal symmetry is broken, in order to accommodate more realistically the behavior of QCD.</p>
        <p>The proper real-time potential between static quarks at finite temperature in general takes on complex values and its Re[V ] shows Debye screening at high temperature. The potential can be extracted non-perturbatively from imaginary time simulations by inspecting the spectral functions ρ □ of the Wilson loop W □ . If a well defined lowest lying spectral feature is present and takes on the shape of a skewed Breit-Wigner, its position and width encode the real-and imaginary part of V (0) S respectively. Using improved Bayesian spectral reconstruction methods (BR method) as well as the Padé approximation on Wilson line correlators in Coulomb gauge, first estimates of Re[V ] and Im[V ] in quenched and dynamical QCD with N f = 2 + 1 light flavors have been obtained. In both cases well defined spectral peaks have been observed at all temperatures investigated. A transition from a Cornell to a Debye screened behavior is found in Re[V ] and as expected it proceeds relatively abruptly in the quenched and smoothly in the dynamical case. All studies so far report indications of a finite imaginary part for T &gt; T C . The in-medium behavior of the potential can be well reproduced by means of simple potential models. One successful example is the Gauss-law parametrization. Combining self consistently the Cornell ansatz at T = 0 with the HTL medium permittivity it reproduces the T and r dependence of the lattice data using a single temperature dependent fit parameter m D , identified with the Debye mass in the high temperature limit.The proper real-time potential between static quarks at finite temperature in general takes on complex values and its Re[V ] shows Debye screening at high temperature. The potential can be extracted non-perturbatively from imaginary time simulations by inspecting the spectral functions ρ □ of the Wilson loop W □ . If a well defined lowest lying spectral feature is present and takes on the shape of a skewed Breit-Wigner, its position and width encode the real-and imaginary part of V (0) S respectively. Using improved Bayesian spectral reconstruction methods (BR method) as well as the Padé approximation on Wilson line correlators in Coulomb gauge, first estimates of Re[V ] and Im[V ] in quenched and dynamical QCD with N f = 2 + 1 light flavors have been obtained. In both cases well defined spectral peaks have been observed at all temperatures investigated. A transition from a Cornell to a Debye screened behavior is found in Re[V ] and as expected it proceeds relatively abruptly in the quenched and smoothly in the dynamical case. All studies so far report indications of a finite imaginary part for T &gt; T C . The in-medium behavior of the potential can be well reproduced by means of simple potential models. One successful example is the Gauss-law parametrization. Combining self consistently the Cornell ansatz at T = 0 with the HTL medium permittivity it reproduces the T and r dependence of the lattice data using a single temperature dependent fit parameter m D , identified with the Debye mass in the high temperature limit.</p>
        <p>m D /T on the lattice is found to approach zero shortly below T C and at T &gt; T C takes on larger values than predicted by NLO perturbation theory. Alternative non-EFT potentials based on the Bethe-Salpeter equation, the T-matrix approach and the AdS/CFT correspondence have been studied in detail in the literature.m D /T on the lattice is found to approach zero shortly below T C and at T &gt; T C takes on larger values than predicted by NLO perturbation theory. Alternative non-EFT potentials based on the Bethe-Salpeter equation, the T-matrix approach and the AdS/CFT correspondence have been studied in detail in the literature.</p>
        <p>Up to this point we have investigated quark binding and screening of color fields in the context of static color sources. With these preparations at hand, we take the next step in this section, and shed light on the in-medium properties of realistic quarkonium with finite mass. To this end we will investigate quarkonium spectral functions, comparing those at T = 0 with those at T &gt; 0 so that changes in their peak structures reveal the influence that the medium exerts. This section is divided into four subsections presenting computations of heavy quarkonium spectral functions according to the involved compromise between accuracy and precision.Up to this point we have investigated quark binding and screening of color fields in the context of static color sources. With these preparations at hand, we take the next step in this section, and shed light on the in-medium properties of realistic quarkonium with finite mass. To this end we will investigate quarkonium spectral functions, comparing those at T = 0 with those at T &gt; 0 so that changes in their peak structures reveal the influence that the medium exerts. This section is divided into four subsections presenting computations of heavy quarkonium spectral functions according to the involved compromise between accuracy and precision.</p>
        <p>We will start out with quarkonium formulated fully relativistically in lattice QCD. This approach does not entail any truncations and in principle is able to reproduce in-medium quarkonium properties highly accurately. We will see however that the numerical effort required to extract spectral functions is extremely high and has so far limited the quantitative insight into in-medium spectral properties of individual states. To obtain an understanding of the overall in-medium modification among quarkonium states with the same quantum numbers, the Euclidean time correlation functions will also be studied.We will start out with quarkonium formulated fully relativistically in lattice QCD. This approach does not entail any truncations and in principle is able to reproduce in-medium quarkonium properties highly accurately. We will see however that the numerical effort required to extract spectral functions is extremely high and has so far limited the quantitative insight into in-medium spectral properties of individual states. To obtain an understanding of the overall in-medium modification among quarkonium states with the same quantum numbers, the Euclidean time correlation functions will also be studied.</p>
        <p>The second approach we consider is the effective field theory NRQCD discretized on the lattice. While still challenging, the extraction of spectral functions from its meson current correlation functions is less demanding than in full QCD and first quantitatively robust determinations of in-medium ground state properties indeed have been achieved. The price to pay is that the physics of the heavy quarks is only captured up to the order in which the NRQCD expansion is implemented numerically.The second approach we consider is the effective field theory NRQCD discretized on the lattice. While still challenging, the extraction of spectral functions from its meson current correlation functions is less demanding than in full QCD and first quantitatively robust determinations of in-medium ground state properties indeed have been achieved. The price to pay is that the physics of the heavy quarks is only captured up to the order in which the NRQCD expansion is implemented numerically.</p>
        <p>The third approach uses the static in-medium potential defined from the effective field theory pNRQCD evaluated non-perturbatively on the lattice. Combining the static potential with a kinetic term with a finite mass, the Schrödinger equation governing the real-time point split forward meson correlator is computed. Taking the imaginary part of its Fourier transform after removing the spatial splitting yields an approximation of the meson spectral function. This approach provides the most precise determination of in-medium spectral functions but misses so far any corrections of the in-medium potential according to finite velocity and spin.The third approach uses the static in-medium potential defined from the effective field theory pNRQCD evaluated non-perturbatively on the lattice. Combining the static potential with a kinetic term with a finite mass, the Schrödinger equation governing the real-time point split forward meson correlator is computed. Taking the imaginary part of its Fourier transform after removing the spatial splitting yields an approximation of the meson spectral function. This approach provides the most precise determination of in-medium spectral functions but misses so far any corrections of the in-medium potential according to finite velocity and spin.</p>
        <p>In the fourth subsection we will briefly survey results on quarkonium in-medium spectral functions that are not based on lattice QCD or effective field theory. These include QCD sum rules, the T-matrix approach and the AdS/CFT correspondence.In the fourth subsection we will briefly survey results on quarkonium in-medium spectral functions that are not based on lattice QCD or effective field theory. These include QCD sum rules, the T-matrix approach and the AdS/CFT correspondence.</p>
        <p>Relativistic meson current correlators in Euclidean time 1 that can be simulated in lattice QCD at finite temperature in principle contain a wealth of vital information on in-medium heavy quarks. On the one hand they encode the in-medium 1 Some works also consider spatial correlation functions along a single axis. These are related to the spectral function via a Fourier transform (205) and their exponential decay at large spatial separation distances is connected to the concept of spatial hadronic screening mass, which is helpful in investigations of symmetry properties of finite temperature QCD (see e.g. Refs. [258,259]). We will not consider these correlators further here. quarkonium spectral functions, whose peak structures inform us about the changes in mass and lifetime of each individual state. On the other hand, whenever a correlator is related to a conserved charge, in addition, the spectral function may contain a so called transport peak, describing the propagation of that conserved charge over large distance scales. This is the case for the vector, scalar and axial vector channel. While the vector channel Γ = γ i is related to the approximately conserved heavy flavor quark number, the scalar channel with Γ = 1 is related to the fermionic contribution to the trace anomaly.Relativistic meson current correlators in Euclidean time 1 that can be simulated in lattice QCD at finite temperature in principle contain a wealth of vital information on in-medium heavy quarks. On the one hand they encode the in-medium 1 Some works also consider spatial correlation functions along a single axis. These are related to the spectral function via a Fourier transform (205) and their exponential decay at large spatial separation distances is connected to the concept of spatial hadronic screening mass, which is helpful in investigations of symmetry properties of finite temperature QCD (see e.g. Refs. [258,259]). We will not consider these correlators further here. quarkonium spectral functions, whose peak structures inform us about the changes in mass and lifetime of each individual state. On the other hand, whenever a correlator is related to a conserved charge, in addition, the spectral function may contain a so called transport peak, describing the propagation of that conserved charge over large distance scales. This is the case for the vector, scalar and axial vector channel. While the vector channel Γ = γ i is related to the approximately conserved heavy flavor quark number, the scalar channel with Γ = 1 is related to the fermionic contribution to the trace anomaly.</p>
        <p>The challenge for lattice QCD lies in the fact that the discretization artifacts for heavy quarks go in powers of a s m Q , requiring extremely finely spaced grids for the study of bottomonium. So far, most dynamical QCD studies have thus focused on charmonium, while bottomonium is treated mainly in the quenched approximation, where large enough lattices can be efficiently simulated (exploratory steps towards fully relativistic bottomonium spectroscopy at T = 0 have been presented at the 2019 lattice conference [260]). A wealth of studies has scrutinized correlation functions and spectra over the past two decades. The first spectral reconstructions in this context have been pioneered in Ref. [214]. On the one hand there are those works that remain in the quenched approximation (see e.g. Refs. [132,[261][262][263][264]), which allows them to deploy large grids and recently even perform continuum extrapolations (see Ref. [265]). On the other hand heavy quarkonium correlators and spectra have been investigated using isotropic and anisotropic dynamical QCD scenarios in Refs. [266][267][268]. All studies at T &gt; 0 so far deploy a form of improved Wilson fermions to discretize the heavy d.o.f. The extraction of spectral functions from relativistic correlators is particularly challenging, since the input data are symmetric around τ = 1/2T and thus only half the points simulated on the lattice provide independent information. The presence of a transport contributions leads to an additional challenge. As was first pointed out by Ref. [269], the physics of the transport peak and the in-medium modification of the bound state spectra become intertwined in the correlator and particular care is needed to disentangle them.The challenge for lattice QCD lies in the fact that the discretization artifacts for heavy quarks go in powers of a s m Q , requiring extremely finely spaced grids for the study of bottomonium. So far, most dynamical QCD studies have thus focused on charmonium, while bottomonium is treated mainly in the quenched approximation, where large enough lattices can be efficiently simulated (exploratory steps towards fully relativistic bottomonium spectroscopy at T = 0 have been presented at the 2019 lattice conference [260]). A wealth of studies has scrutinized correlation functions and spectra over the past two decades. The first spectral reconstructions in this context have been pioneered in Ref. [214]. On the one hand there are those works that remain in the quenched approximation (see e.g. Refs. [132,[261][262][263][264]), which allows them to deploy large grids and recently even perform continuum extrapolations (see Ref. [265]). On the other hand heavy quarkonium correlators and spectra have been investigated using isotropic and anisotropic dynamical QCD scenarios in Refs. [266][267][268]. All studies at T &gt; 0 so far deploy a form of improved Wilson fermions to discretize the heavy d.o.f. The extraction of spectral functions from relativistic correlators is particularly challenging, since the input data are symmetric around τ = 1/2T and thus only half the points simulated on the lattice provide independent information. The presence of a transport contributions leads to an additional challenge. As was first pointed out by Ref. [269], the physics of the transport peak and the in-medium modification of the bound state spectra become intertwined in the correlator and particular care is needed to disentangle them.</p>
        <p>To gain insight into the in-medium properties without having to deal with the additional uncertainty from a spectral reconstruction one starts with an inspection of the imaginary time correlators themselves. Naively one might expect that the ratio of the in-medium correlation function and the vacuum correlation function is a good quantity in this regard. In the relativistic formulation however the current correlator according to Eq. ( 34) contains two sources of temperature dependence. One arises from the kernel and is not informative, the other is from changes in the spectral function which is our main focus. To eliminate the effect of the temperature dependence of the kernel in ratios of correlators, according to Ref. [262,263] one may construct the so called reconstructed correlatorTo gain insight into the in-medium properties without having to deal with the additional uncertainty from a spectral reconstruction one starts with an inspection of the imaginary time correlators themselves. Naively one might expect that the ratio of the in-medium correlation function and the vacuum correlation function is a good quantity in this regard. In the relativistic formulation however the current correlator according to Eq. ( 34) contains two sources of temperature dependence. One arises from the kernel and is not informative, the other is from changes in the spectral function which is our main focus. To eliminate the effect of the temperature dependence of the kernel in ratios of correlators, according to Ref. [262,263] one may construct the so called reconstructed correlator</p>
        <p>Here T ′ , τ ′ and N ′ τ denote the temperature, imaginary time and Euclidean extent for the simulated correlator D E . The quantity D rec now represents the Euclidean correlator where the same spectral function underlying D E is encoded with a kernel at T and correspondingly N τ . A ratio of unity between the in-medium correlator D E (τ , T &gt; T C ) and D rec (τ , T , T ′ &lt; T C ) indicates that no medium modification is present. It has to be kept in mind however that changes in the underlying spectral function in different frequency regimes may cancel out, once the convolution with the in-medium kernel is taken. This is a manifestation of the inherent exponential information loss induced by the convolution.Here T ′ , τ ′ and N ′ τ denote the temperature, imaginary time and Euclidean extent for the simulated correlator D E . The quantity D rec now represents the Euclidean correlator where the same spectral function underlying D E is encoded with a kernel at T and correspondingly N τ . A ratio of unity between the in-medium correlator D E (τ , T &gt; T C ) and D rec (τ , T , T ′ &lt; T C ) indicates that no medium modification is present. It has to be kept in mind however that changes in the underlying spectral function in different frequency regimes may cancel out, once the convolution with the in-medium kernel is taken. This is a manifestation of the inherent exponential information loss induced by the convolution.</p>
        <p>Another quantity that is considered in the literature is the midpoint subtracted correlators D sub (τ ) = D E (τ ) -D(τ = 1/2T ). If the transport contribution is of the free theory form of Eq. ( 35), i.e. ρ transp (ω) = ωδ(ω) only, then subtracting the midpoint D(τ = 1/2T ) from the Euclidean correlator (or taking its derivative) will remove it completely. On the other hand in an interacting theory the transport peak is expected to be of Breit-Wigner type [42] and subtractions will only remove part of its contribution.Another quantity that is considered in the literature is the midpoint subtracted correlators D sub (τ ) = D E (τ ) -D(τ = 1/2T ). If the transport contribution is of the free theory form of Eq. ( 35), i.e. ρ transp (ω) = ωδ(ω) only, then subtracting the midpoint D(τ = 1/2T ) from the Euclidean correlator (or taking its derivative) will remove it completely. On the other hand in an interacting theory the transport peak is expected to be of Breit-Wigner type [42] and subtractions will only remove part of its contribution.</p>
        <p>In Fig. 25 the results for the ratio of the in-medium and a low temperature reconstructed correlator from two representative studies of charmonium on isotropic lattices are shown. In both cases the particles are considered at rest, i.e. the correlators are summed over all spatial positions. The left column shows data from Ref. [263] on large quenched QCD lattices N s = 128 with a fine spacing of a = 0.01 fm, where the low reference temperature is T ′ = 0.73T C . On the right hand side the plots were obtained in Ref. [267] in simulations with N f = 2 + 1 dynamical Wilson fermions with still relatively large pion masses of m π = 545 MeV on N s = 64 lattices. The reference temperature is T ′ = 0.6T C . The top row shows the pseudoscalar channel, containing the two particles η c (1S) and η c (2S) below the D D threshold. The bottom row on the other hand corresponds to the vector channel, which houses J/ψ and ψ ′ below threshold. We have to keep in mind that even though the η c and J/ψ have significantly different decay widths [3], the latter being of keV magnitude, while in the former being on the MeV level, the spectral function underlying the correlators shown here only relate to electromagnetic decays [36]. I.e. dilepton decay J/ψ → ℓ -ℓ + and diphoton decay η s → γ γ , which are of the same order of keV the latter smaller than the former. Since the mass difference between the J/ψ and η c can be understood as hyperfine splitting, it is only a few tens of MeV with η c being a bit more strongly bound. The excited states η ′ c and ψ ′ both lie less than 100 MeV away from the D D threshold, i.e. their vacuum binding energies are similarly small and should be similarly affected by medium effects.In Fig. 25 the results for the ratio of the in-medium and a low temperature reconstructed correlator from two representative studies of charmonium on isotropic lattices are shown. In both cases the particles are considered at rest, i.e. the correlators are summed over all spatial positions. The left column shows data from Ref. [263] on large quenched QCD lattices N s = 128 with a fine spacing of a = 0.01 fm, where the low reference temperature is T ′ = 0.73T C . On the right hand side the plots were obtained in Ref. [267] in simulations with N f = 2 + 1 dynamical Wilson fermions with still relatively large pion masses of m π = 545 MeV on N s = 64 lattices. The reference temperature is T ′ = 0.6T C . The top row shows the pseudoscalar channel, containing the two particles η c (1S) and η c (2S) below the D D threshold. The bottom row on the other hand corresponds to the vector channel, which houses J/ψ and ψ ′ below threshold. We have to keep in mind that even though the η c and J/ψ have significantly different decay widths [3], the latter being of keV magnitude, while in the former being on the MeV level, the spectral function underlying the correlators shown here only relate to electromagnetic decays [36]. I.e. dilepton decay J/ψ → ℓ -ℓ + and diphoton decay η s → γ γ , which are of the same order of keV the latter smaller than the former. Since the mass difference between the J/ψ and η c can be understood as hyperfine splitting, it is only a few tens of MeV with η c being a bit more strongly bound. The excited states η ′ c and ψ ′ both lie less than 100 MeV away from the D D threshold, i.e. their vacuum binding energies are similarly small and should be similarly affected by medium effects.</p>
        <p>We find that the two studies show very similar behavior, which due to the large pion masses may not be surprising. For the pseudoscalars the ratios at small τ is consistent with unity and then shows a downward trend, which becomes stronger and sets in at earlier imaginary time as temperature increases. The vector channel shows the opposite behavior, i.e. while Source: Figures adapted from Refs. [263,267].We find that the two studies show very similar behavior, which due to the large pion masses may not be surprising. For the pseudoscalars the ratios at small τ is consistent with unity and then shows a downward trend, which becomes stronger and sets in at earlier imaginary time as temperature increases. The vector channel shows the opposite behavior, i.e. while Source: Figures adapted from Refs. [263,267].</p>
        <p>starting out at unity for small τ it bends upward. The full QCD result indicates that the bending up actually becomes stronger as temperature rises. The deviations from unity in both cases are between 10-20% at the highest temperature with those for η c being smaller than those for J/ψ . Note that both computations use a fixed scale approach, which means that the UV behavior of the underlying spectral functions is the same at all temperatures.starting out at unity for small τ it bends upward. The full QCD result indicates that the bending up actually becomes stronger as temperature rises. The deviations from unity in both cases are between 10-20% at the highest temperature with those for η c being smaller than those for J/ψ . Note that both computations use a fixed scale approach, which means that the UV behavior of the underlying spectral functions is the same at all temperatures.</p>
        <p>From the point of view of the vacuum bound state content alone, such a different behavior is not expected. On the other hand only the pseudoscalar channel is expected to be free from the transport contribution. This has led to attempts to remove the related transport peak from the correlator in order to showcase only the modification of the bound states. In Fig. 26 we thus show on the left the values of the in-medium correlator with the reconstructed correlator at a lower reference temperature subtracted in quenched QCD from Ref. [263]. On the right the ratio of the midpoint subtracted correlator with the correspondingly subtracted reconstructed correlator is shown in N f = 2 + 1 dynamical QCD from Ref. [267].From the point of view of the vacuum bound state content alone, such a different behavior is not expected. On the other hand only the pseudoscalar channel is expected to be free from the transport contribution. This has led to attempts to remove the related transport peak from the correlator in order to showcase only the modification of the bound states. In Fig. 26 we thus show on the left the values of the in-medium correlator with the reconstructed correlator at a lower reference temperature subtracted in quenched QCD from Ref. [263]. On the right the ratio of the midpoint subtracted correlator with the correspondingly subtracted reconstructed correlator is shown in N f = 2 + 1 dynamical QCD from Ref. [267].</p>
        <p>Roughly speaking: the increasing magnitude, combined with being negative, of the difference D E -D rec in the pseudoscalar channel (top left) is interpreted as indicating that the amplitudes in the underlying spectral function of D E decreases. This is in agreement with expectations for a weakening bound state content. On the other hand in the vector channel the upward movement is indicative of parts of the spectrum amplitude increasing, which is interpreted as arising from an increasing transport peak. This interpretation is supported by the ratio of the midpoint subtracted correlators on the right, which shows that the difference in the η c channel do not change significantly compared to the unsubtracted ratio, while in the vector channel the deviation from unity is markedly reduced.Roughly speaking: the increasing magnitude, combined with being negative, of the difference D E -D rec in the pseudoscalar channel (top left) is interpreted as indicating that the amplitudes in the underlying spectral function of D E decreases. This is in agreement with expectations for a weakening bound state content. On the other hand in the vector channel the upward movement is indicative of parts of the spectrum amplitude increasing, which is interpreted as arising from an increasing transport peak. This interpretation is supported by the ratio of the midpoint subtracted correlators on the right, which shows that the difference in the η c channel do not change significantly compared to the unsubtracted ratio, while in the vector channel the deviation from unity is markedly reduced.</p>
        <p>While these above arguments are consistent, it turns out that the upward behavior observed here in the vector channel, which is attributed mainly to the transport peak will be present also in ratios of NRQCD correlators, which are free from transport contributions. In addition in a recent computation [268,270] of charmonium correlators on anisotropic lattices with N f = 2 + 1 dynamical Wilson fermions with a lighter pion mass m π = 380 MeV a much more similar behavior between pseudoscalar and vector channel ratios has been observed. It will be highly interesting to compute these ratios in the future on lattices much closer to the physical pion mass to further elucidate the question of the transport contribution.While these above arguments are consistent, it turns out that the upward behavior observed here in the vector channel, which is attributed mainly to the transport peak will be present also in ratios of NRQCD correlators, which are free from transport contributions. In addition in a recent computation [268,270] of charmonium correlators on anisotropic lattices with N f = 2 + 1 dynamical Wilson fermions with a lighter pion mass m π = 380 MeV a much more similar behavior between pseudoscalar and vector channel ratios has been observed. It will be highly interesting to compute these ratios in the future on lattices much closer to the physical pion mass to further elucidate the question of the transport contribution.</p>
        <p>Another way of understanding the physics encoded in a correlation function is to compare to those from a model of the underlying spectral function. For the pseudoscalar correlator of both charmonium and bottomonium this has been achieved using continuum resummed perturbation theory for the high energy region and a pNRQCD computation at the threshold. These analytic results are then compared to continuum extrapolated correlators in the quenched approximation.Another way of understanding the physics encoded in a correlation function is to compare to those from a model of the underlying spectral function. For the pseudoscalar correlator of both charmonium and bottomonium this has been achieved using continuum resummed perturbation theory for the high energy region and a pNRQCD computation at the threshold. These analytic results are then compared to continuum extrapolated correlators in the quenched approximation.</p>
        <p>As discussed in detail in Ref. [265] the behavior of the pseudoscalar charmonium channel already at T = 1.1T C can be reproduced using a (slightly rescaled) spectrum that does not show any peak structure besides an enhanced onset of the threshold. At the same time for bottomonium the correlator at T = 1.1T C is compatible with the presence of a well distinguishable in-medium remnant peak. At T = 2.25T C neither for η b nor η c a peak is required to reproduce the correlator within errors. A similar analysis of the vector channel is currently work in progress.As discussed in detail in Ref. [265] the behavior of the pseudoscalar charmonium channel already at T = 1.1T C can be reproduced using a (slightly rescaled) spectrum that does not show any peak structure besides an enhanced onset of the threshold. At the same time for bottomonium the correlator at T = 1.1T C is compatible with the presence of a well distinguishable in-medium remnant peak. At T = 2.25T C neither for η b nor η c a peak is required to reproduce the correlator within errors. A similar analysis of the vector channel is currently work in progress.</p>
        <p>Let us also consider the scalar and axial-vector channel encoding the P-wave states. When computed in the quenched approximation and even more so in the dynamical theory the ratios show an upward bend whose deviation from unity is much larger than in the S-wave channels. It easily reaches 50% and more, indicating that sizable in-medium changes already occur for these channels just above T C .Let us also consider the scalar and axial-vector channel encoding the P-wave states. When computed in the quenched approximation and even more so in the dynamical theory the ratios show an upward bend whose deviation from unity is much larger than in the S-wave channels. It easily reaches 50% and more, indicating that sizable in-medium changes already occur for these channels just above T C .</p>
        <p>Up to this point we have only discussed quarkonium at zero momentum but also the finite momentum situation has been considered, e.g. in the quenched approximation in Ref. [264] on anisotropic N s = 64 lattices with a s /a t = 4 and a τ = 0.00975 fm (see also Ref. [258]). If a quarkonium bound state peak exists, it will follow a dispersion relation, in which the peak position will move to higher frequencies for larger values of p. The stronger decay in the corresponding Euclidean correlator is expected to lead to a lower than unity ratio to the p = 0 case. As shown in Fig. 27 this is exactly what is observed in practice. Note that two sets of curves are shown representing the longitudinal and transversal components defined in Eq. ( 25).Up to this point we have only discussed quarkonium at zero momentum but also the finite momentum situation has been considered, e.g. in the quenched approximation in Ref. [264] on anisotropic N s = 64 lattices with a s /a t = 4 and a τ = 0.00975 fm (see also Ref. [258]). If a quarkonium bound state peak exists, it will follow a dispersion relation, in which the peak position will move to higher frequencies for larger values of p. The stronger decay in the corresponding Euclidean correlator is expected to lead to a lower than unity ratio to the p = 0 case. As shown in Fig. 27 this is exactly what is observed in practice. Note that two sets of curves are shown representing the longitudinal and transversal components defined in Eq. ( 25).</p>
        <p>Let us next consider the spectral functions themselves. All the studies quoted above have used the in-medium correlation functions to extract the underlying spectral functions deploying mostly the MEM, one also used the BR method.Let us next consider the spectral functions themselves. All the studies quoted above have used the in-medium correlation functions to extract the underlying spectral functions deploying mostly the MEM, one also used the BR method.</p>
        <p>These computations are particularly challenging since only N τ /2 individual datapoints exist and in addition the physical Euclidean range reduces as temperature increases. In the MEM, as discussed in Section 2.4.1 the smoothing induced through the restricted SVD subspace becomes stronger, as the number of datapoint is reduced. At the same time the amount of information on the ground state decreases as the imaginary time extend decreases. In the BR method there is no additional smoothing present which in case of a small number of datapoints may lead to numerical ringing. I.e. besides the actual in-medium effects manifesting themselves in the spectral function, the reconstruction efficiency of the deployed methods changes at different temperatures. Those effects need to be disentangled. The clearest comparison is obtained when taking the low temperature reference correlator and use it to compute a reconstructed correlator at high temperature. Subsequently the spectral reconstruction is performed both on that D rec , as well as the actual high temperature correlator and compared, as suggested and for the first time deployed in Ref. [268].These computations are particularly challenging since only N τ /2 individual datapoints exist and in addition the physical Euclidean range reduces as temperature increases. In the MEM, as discussed in Section 2.4.1 the smoothing induced through the restricted SVD subspace becomes stronger, as the number of datapoint is reduced. At the same time the amount of information on the ground state decreases as the imaginary time extend decreases. In the BR method there is no additional smoothing present which in case of a small number of datapoints may lead to numerical ringing. I.e. besides the actual in-medium effects manifesting themselves in the spectral function, the reconstruction efficiency of the deployed methods changes at different temperatures. Those effects need to be disentangled. The clearest comparison is obtained when taking the low temperature reference correlator and use it to compute a reconstructed correlator at high temperature. Subsequently the spectral reconstruction is performed both on that D rec , as well as the actual high temperature correlator and compared, as suggested and for the first time deployed in Ref. [268].</p>
        <p>It is currently still difficult to arrive at a quantitative interpretation of the reconstructed spectra due to the involved reconstruction uncertainties. As presented in Fig. 28, on the one hand Ref. [264] shows clear peaks for the pseudoscalar channel charmonium at T = 1.62T C , while Ref. [263] already at T = 1.46T C shows a very washed out lowest lying feature.It is currently still difficult to arrive at a quantitative interpretation of the reconstructed spectra due to the involved reconstruction uncertainties. As presented in Fig. 28, on the one hand Ref. [264] shows clear peaks for the pseudoscalar channel charmonium at T = 1.62T C , while Ref. [263] already at T = 1.46T C shows a very washed out lowest lying feature.</p>
        <p>In both studies the in-medium spectral feature appears to move to higher frequencies above T C . Note that both studies use a similar MEM reconstruction and that the authors of Ref. [264] also carried out the reconstruction based on the reconstructed correlator in Ref. [271] indicating that the shift in the peak position may not simply be a methods artifact. The difference between the two results lies in that the former is carried out on anisotropic lattices with roughly twice the spatial volume compared to the latter. On the other hand the UV cutoff is located at a lower energy in the former. Especially in light of the results from modeling the pseudoscalar correlator in the continuum limit, it is paramount to clarify the situation further. Let us note that in Ref. [264] no significant difference between the longitudinal and transversal reconstructed spectral functions was observed even though at finite temperature these two components need not agree. In the case of dynamical QCD on anisotropic lattices, as shown e.g. in Fig. 29 from Ref. [268] (a continuation of the FASTSUM results presented in Ref. [266]), the comparison between the actual high temperature reconstructed spectrum and the one reconstructed from the low temperature reconstructed correlator show only very small differences around T C . At T = 1.9T C indications for in-medium modification are visible. While there are hints for the in-medium ground state peak moving to higher frequencies (similar to what was found in the quenched approximation in Ref. [264]), it will require more robust reconstructions in dynamical QCD to draw a final conclusion on this point.In both studies the in-medium spectral feature appears to move to higher frequencies above T C . Note that both studies use a similar MEM reconstruction and that the authors of Ref. [264] also carried out the reconstruction based on the reconstructed correlator in Ref. [271] indicating that the shift in the peak position may not simply be a methods artifact. The difference between the two results lies in that the former is carried out on anisotropic lattices with roughly twice the spatial volume compared to the latter. On the other hand the UV cutoff is located at a lower energy in the former. Especially in light of the results from modeling the pseudoscalar correlator in the continuum limit, it is paramount to clarify the situation further. Let us note that in Ref. [264] no significant difference between the longitudinal and transversal reconstructed spectral functions was observed even though at finite temperature these two components need not agree. In the case of dynamical QCD on anisotropic lattices, as shown e.g. in Fig. 29 from Ref. [268] (a continuation of the FASTSUM results presented in Ref. [266]), the comparison between the actual high temperature reconstructed spectrum and the one reconstructed from the low temperature reconstructed correlator show only very small differences around T C . At T = 1.9T C indications for in-medium modification are visible. While there are hints for the in-medium ground state peak moving to higher frequencies (similar to what was found in the quenched approximation in Ref. [264]), it will require more robust reconstructions in dynamical QCD to draw a final conclusion on this point.</p>
        <p>The P-wave states in the scalar and axial vector channels, shown in Fig. 30 due to the smaller signal to noise ratio exhibit larger uncertainties. Again we plot both the reconstruction of the actual in-medium spectrum, as well as the reconstructions from the low-temperature reference reconstructed correlator. The sizable in-medium modification of the correlator translates into significant changes of the spectra already around T C , with no discernible peak structure remaining at T = 0.95T C . This is in stark contrast to the S-wave states, which are much less affected. It will be important to improve the signal to noise ratio in the P-wave channels to more robustly ascertain the full extend of the in-medium effects.The P-wave states in the scalar and axial vector channels, shown in Fig. 30 due to the smaller signal to noise ratio exhibit larger uncertainties. Again we plot both the reconstruction of the actual in-medium spectrum, as well as the reconstructions from the low-temperature reference reconstructed correlator. The sizable in-medium modification of the correlator translates into significant changes of the spectra already around T C , with no discernible peak structure remaining at T = 0.95T C . This is in stark contrast to the S-wave states, which are much less affected. It will be important to improve the signal to noise ratio in the P-wave channels to more robustly ascertain the full extend of the in-medium effects.</p>
        <p>The study of the effect of finite momentum in the spectral functions suffers from less systematics, since for a fixed temperature the Euclidean extend the same among different momenta. Ref. [264] confirmed that the less than unit ratio between the p &gt; 0 and p = 0 correlator indeed translates into an in-medium peak, which moves higher frequencies. Extracting the dispersion relation of this peak structure, it was observed that it differed only minutely from the vacuum form, both indicating that this peak actually encodes a particle d.o.f. and that its in-medium modification is apparently weak.The study of the effect of finite momentum in the spectral functions suffers from less systematics, since for a fixed temperature the Euclidean extend the same among different momenta. Ref. [264] confirmed that the less than unit ratio between the p &gt; 0 and p = 0 correlator indeed translates into an in-medium peak, which moves higher frequencies. Extracting the dispersion relation of this peak structure, it was observed that it differed only minutely from the vacuum form, both indicating that this peak actually encodes a particle d.o.f. and that its in-medium modification is apparently weak.</p>
        <p>A concerted effort is undertaken to elucidate the in-medium properties of quarkonium, based on the relativistic formulation in lattice QCD. It is now understood that an investigation of the pseudoscalar sector allows to disentangle transport from bound state physics. Modeling its physics content using perturbation theory and pNRQCD indicates a fast disappearance of any peak structures for charmonium around T C , while the lattice data indicates the presence of a bottomonium remnant peak up to around T ≈ 2T C . On the other hand it remains highly challenging to quantitatively extract the in-medium effects on individual states via reconstructed spectral functions. There are clear signs of an inmedium modification in the P-wave states, whose peak structures seem to disappear quickly around T C , while for the S-wave states the final word has not yet been spoken, up to which temperature their features persist. Indications are found that above T C the in-medium peak structures tend towards higher frequencies. Further progress will depend on improving the spectral reconstructions significantly, which is currently work in progress both based on continuum extrapolated correlators (Bielefeld-CCNU collaboration), as well as improved anisotropic lattices closer to the continuum in full QCD (FASTSUM collaboration).A concerted effort is undertaken to elucidate the in-medium properties of quarkonium, based on the relativistic formulation in lattice QCD. It is now understood that an investigation of the pseudoscalar sector allows to disentangle transport from bound state physics. Modeling its physics content using perturbation theory and pNRQCD indicates a fast disappearance of any peak structures for charmonium around T C , while the lattice data indicates the presence of a bottomonium remnant peak up to around T ≈ 2T C . On the other hand it remains highly challenging to quantitatively extract the in-medium effects on individual states via reconstructed spectral functions. There are clear signs of an inmedium modification in the P-wave states, whose peak structures seem to disappear quickly around T C , while for the S-wave states the final word has not yet been spoken, up to which temperature their features persist. Indications are found that above T C the in-medium peak structures tend towards higher frequencies. Further progress will depend on improving the spectral reconstructions significantly, which is currently work in progress both based on continuum extrapolated correlators (Bielefeld-CCNU collaboration), as well as improved anisotropic lattices closer to the continuum in full QCD (FASTSUM collaboration).</p>
        <p>In order to progress with currently available lattice simulations one may decide to leave the relativistic formulation and instead deploy the lattice regularized version of the effective field theory NRQCD. As a theory of non-relativistic Pauli spinors, valid at energies of the order m Q v and below it offers several advantages over the direct relativistic formulation as discussed in [51,105]. On the other hand it has to be kept in mind that the EFT is only an approximation to QCD and that effects, such as accurately capturing the hyperfine splitting of the S-wave states requires high order expansions in the quark velocity and beyond leading order radiative corrections. As the uncertainties in the spectral decomposition outweigh those systematics, most studies so far deploy the O(v 4 ) NRQCD Hamiltonian and leading order Wilson coefficients with tadpole improvements. There have been exploratory studies of in-medium quarkonium in NRQCD presented early on in Ref. [272]. The first comprehensive study on in-medium Bottomonium in lattice NRQCD has been undertaken in a series of papers by the FASTSUM collaboration in Refs. [69,113,[273][274][275]. A complementary lattice effort has been started with the papers of Refs. [276,277], the latter of which extended the use of NRQCD to a study of charmonium properties.In order to progress with currently available lattice simulations one may decide to leave the relativistic formulation and instead deploy the lattice regularized version of the effective field theory NRQCD. As a theory of non-relativistic Pauli spinors, valid at energies of the order m Q v and below it offers several advantages over the direct relativistic formulation as discussed in [51,105]. On the other hand it has to be kept in mind that the EFT is only an approximation to QCD and that effects, such as accurately capturing the hyperfine splitting of the S-wave states requires high order expansions in the quark velocity and beyond leading order radiative corrections. As the uncertainties in the spectral decomposition outweigh those systematics, most studies so far deploy the O(v 4 ) NRQCD Hamiltonian and leading order Wilson coefficients with tadpole improvements. There have been exploratory studies of in-medium quarkonium in NRQCD presented early on in Ref. [272]. The first comprehensive study on in-medium Bottomonium in lattice NRQCD has been undertaken in a series of papers by the FASTSUM collaboration in Refs. [69,113,[273][274][275]. A complementary lattice effort has been started with the papers of Refs. [276,277], the latter of which extended the use of NRQCD to a study of charmonium properties.</p>
        <p>Lattice setups and spectral reconstruction methods differ between the two recent sets of papers. The groups have focused on achieving good accuracy either in the heavy quark or the medium sector. Since in both cases NRQCD matching has not been performed beyond leading order, the result of the different studies do not necessarily have to agree within their statistical errors.Lattice setups and spectral reconstruction methods differ between the two recent sets of papers. The groups have focused on achieving good accuracy either in the heavy quark or the medium sector. Since in both cases NRQCD matching has not been performed beyond leading order, the result of the different studies do not necessarily have to agree within their statistical errors.</p>
        <p>The latest FASTSUM studies (see e.g. [113]) are carried out in a fixed box approach on N s = 24 anisotropic lattices of a s /a τ = 3.5 with N f = 2 + 1 light flavors of clover improved Wilson fermions at a = 0.1227 fm. Using temporal grids N τ = 40 . . . 16 a temperature range between T = 141 . . . 352 = 0.76T C . . . 1.90T C is covered. For calibration a N τ = 128 ensemble has been obtained. Between 500 and 1000 realizations of the current correlators on the individual lattices are computed. The values of the heavy quark mass parameter are fixed using the dispersion relation of quarkonium S-wave states, maintaining a spin averaged 1S kinetic mass close to the PDG value [3].The latest FASTSUM studies (see e.g. [113]) are carried out in a fixed box approach on N s = 24 anisotropic lattices of a s /a τ = 3.5 with N f = 2 + 1 light flavors of clover improved Wilson fermions at a = 0.1227 fm. Using temporal grids N τ = 40 . . . 16 a temperature range between T = 141 . . . 352 = 0.76T C . . . 1.90T C is covered. For calibration a N τ = 128 ensemble has been obtained. Between 500 and 1000 realizations of the current correlators on the individual lattices are computed. The values of the heavy quark mass parameter are fixed using the dispersion relation of quarkonium S-wave states, maintaining a spin averaged 1S kinetic mass close to the PDG value [3].</p>
        <p>The benefit of this approach is that the anisotropy allows the NRQCD expansion to be very robust, i.e. a Lepage parameter of n = 1 has been deployed in the time evolution throughout. The drawback of this approach on the other hand is that the pion mass is rather heavy with M π ≈ 400 MeV so that e.g. the crossover temperature T lat C = 185 MeV lies above the physical value.The benefit of this approach is that the anisotropy allows the NRQCD expansion to be very robust, i.e. a Lepage parameter of n = 1 has been deployed in the time evolution throughout. The drawback of this approach on the other hand is that the pion mass is rather heavy with M π ≈ 400 MeV so that e.g. the crossover temperature T lat C = 185 MeV lies above the physical value.</p>
        <p>The second set of works uses lattice ensembles from the HotQCD collaboration originally intended for the study of the crossover transition in Refs. [8,221], where N f = 2 + 1 light quarks are discretized with the HISQ action on 48 3 × 12 isotropic grids in a fixed box approach. For each of the different lattice spacings that implement a temperature range between T = 140 . . . Previously there have been tensions reported between Ref. [113] (using MEM) and Ref. [276] (using BR) in the inmedium modification of P-wave states that went beyond what was expected to arise simply from the different lattice setups. From a much improved understanding of the uncertainties in the spectral reconstruction, especially the role of ringing and smoothing, these differences have recently been sorted out. The P-wave disappearance is found to occur closer to the earlier results of Ref. [113]. In addition improved quantitative results on the in-medium masses, for the first time consistent with the behavior of the in-medium correlator ratios, have been obtained in Ref. [276].The second set of works uses lattice ensembles from the HotQCD collaboration originally intended for the study of the crossover transition in Refs. [8,221], where N f = 2 + 1 light quarks are discretized with the HISQ action on 48 3 × 12 isotropic grids in a fixed box approach. For each of the different lattice spacings that implement a temperature range between T = 140 . . . Previously there have been tensions reported between Ref. [113] (using MEM) and Ref. [276] (using BR) in the inmedium modification of P-wave states that went beyond what was expected to arise simply from the different lattice setups. From a much improved understanding of the uncertainties in the spectral reconstruction, especially the role of ringing and smoothing, these differences have recently been sorted out. The P-wave disappearance is found to occur closer to the earlier results of Ref. [113]. In addition improved quantitative results on the in-medium masses, for the first time consistent with the behavior of the in-medium correlator ratios, have been obtained in Ref. [276].</p>
        <p>Since the results for the correlation functions are quite similar among the different studies in the bottomonium sector, we showcase here the recent data from Ref. [277] where also the charm d.o.f. were computed. In NRQCD the integral Kernel of the spectral representation is temperature independent and therefore the in-medium changes in the spectral function may be investigated from the naive ratio of the in-medium correlator to the T = 0 correlator, i.e. without having to construct a reference reconstructed correlator. For completeness the ratios for all available channels are shown in Fig. 31. There are four panels on the left corresponding to bottomonium for temperatures between T = 140 . . . 407 MeV.Since the results for the correlation functions are quite similar among the different studies in the bottomonium sector, we showcase here the recent data from Ref. [277] where also the charm d.o.f. were computed. In NRQCD the integral Kernel of the spectral representation is temperature independent and therefore the in-medium changes in the spectral function may be investigated from the naive ratio of the in-medium correlator to the T = 0 correlator, i.e. without having to construct a reference reconstructed correlator. For completeness the ratios for all available channels are shown in Fig. 31. There are four panels on the left corresponding to bottomonium for temperatures between T = 140 . . . 407 MeV.</p>
        <p>The channels starting from the top left panel and going counterclockwise are the 1 S 0 (η b ), 3 S 1 (Υ ), 3 P 1 (χ b1 ) and 1 P 0 (h b ) respectively. The charmonium results in the restricted temperature range of T = 140 . . . 251 MeV are arranged also counterclockwise from the top left as the 1 S 0 (η c ), 3 S 1 (J/ψ ), 3 P 1 (χ c1 ) and 1 P 0 (h c ) channels.The channels starting from the top left panel and going counterclockwise are the 1 S 0 (η b ), 3 S 1 (Υ ), 3 P 1 (χ b1 ) and 1 P 0 (h b ) respectively. The charmonium results in the restricted temperature range of T = 140 . . . 251 MeV are arranged also counterclockwise from the top left as the 1 S 0 (η c ), 3 S 1 (J/ψ ), 3 P 1 (χ c1 ) and 1 P 0 (h c ) channels.</p>
        <p>As first qualitative difference to the relativistic case we find that all channels, in particular also the pseudoscalar channel of the η particles show the same characteristic upward bending as temperature increases. The difference in the underlying spectral function is two-fold: no transport peak is present at small frequencies and the UV continuum behavior differs due to different powers dominating at large ω. A full understanding of these differences remains to be established.As first qualitative difference to the relativistic case we find that all channels, in particular also the pseudoscalar channel of the η particles show the same characteristic upward bending as temperature increases. The difference in the underlying spectral function is two-fold: no transport peak is present at small frequencies and the UV continuum behavior differs due to different powers dominating at large ω. A full understanding of these differences remains to be established.</p>
        <p>For the S-wave bottomonium states there are virtually no medium effects visible at around T C , while both bottomonium P-waves and charmonium S-waves show deviations from unity at T = 140 MeV beyond statistical error bars. This is a first hint that the overall strength of the in-medium modification is connected with the vacuum binding energies of the encoded states. The higher temperature results confirm this impression. We compare the maximum deviation at T = 407 MeV between the Υ channel (bottom left panel) and the χ b1 channel (bottom right panel). The ground state of the former is very strongly bound with E Υ bind (T = 0) ≈ 1.1 GeV the one of the latter with E χ b1 bind (T = 0) ≈ 0.64 GeV. And indeed while the 3 S 1 channel shows below 2% deviations in the ratio, the 3 P 1 channel already shows 6.5%. We continue the comparison with charmonium, where the S-wave channel (bottom left panel) with ground state J/ψ E J/ψ bind (T = 0) ≈ 0.64 GeV features a very similar vacuum binding as χ b1 . To compare apples to apples, let us take the highest temperature where both bottom and charm are available, i.e. at T = 251 MeV. And indeed both the χ b1 channel, as well as the J/ψ Fig. 31. Ratios of the in-medium NRQCD quarkonium correlator to its T = 0 counterpart. In the left block of four panels, we show the bottomonium ratios for temperatures between T = 140 . . . 407 MeV. Counterclockwise from the top left the 1 S 0 (η b ), 3 S 1 (Υ ), 3 P 1 (χ b1 ) and 1 P 0 (h b ) channel is shown. In the right block of four panels, we show the charmonium ratios for T = 140 . . . 251 MeV. Counterclockwise from the top left the 1 S 0 (η c ), 3 S 1 (J/ψ ), 3 P 1 (χ c1 ) and 1 P 0 (h c )channel is plotted. Note that no transport contribution is expected to contribute to any of these NRQCD correlators. Source: Figures partially reproduced from Ref. [277]. channel show a very similar 5% deviation there. On the other hand the χ c1 channel (bottom right) with a much lower ground state binding energy of E χ b1 bind (T = 0) ≈ 0.2 GeV already exhibits a deviation of 12.5% at that temperature. These results clearly establish an ordering of the overall in-medium modification with the vacuum binding energy. This is in agreement with our intuition, as a more strongly bound state also features a smaller spatial extent, which in turn makes it more difficult for the medium d.o.f. to interfere with the binding.For the S-wave bottomonium states there are virtually no medium effects visible at around T C , while both bottomonium P-waves and charmonium S-waves show deviations from unity at T = 140 MeV beyond statistical error bars. This is a first hint that the overall strength of the in-medium modification is connected with the vacuum binding energies of the encoded states. The higher temperature results confirm this impression. We compare the maximum deviation at T = 407 MeV between the Υ channel (bottom left panel) and the χ b1 channel (bottom right panel). The ground state of the former is very strongly bound with E Υ bind (T = 0) ≈ 1.1 GeV the one of the latter with E χ b1 bind (T = 0) ≈ 0.64 GeV. And indeed while the 3 S 1 channel shows below 2% deviations in the ratio, the 3 P 1 channel already shows 6.5%. We continue the comparison with charmonium, where the S-wave channel (bottom left panel) with ground state J/ψ E J/ψ bind (T = 0) ≈ 0.64 GeV features a very similar vacuum binding as χ b1 . To compare apples to apples, let us take the highest temperature where both bottom and charm are available, i.e. at T = 251 MeV. And indeed both the χ b1 channel, as well as the J/ψ Fig. 31. Ratios of the in-medium NRQCD quarkonium correlator to its T = 0 counterpart. In the left block of four panels, we show the bottomonium ratios for temperatures between T = 140 . . . 407 MeV. Counterclockwise from the top left the 1 S 0 (η b ), 3 S 1 (Υ ), 3 P 1 (χ b1 ) and 1 P 0 (h b ) channel is shown. In the right block of four panels, we show the charmonium ratios for T = 140 . . . 251 MeV. Counterclockwise from the top left the 1 S 0 (η c ), 3 S 1 (J/ψ ), 3 P 1 (χ c1 ) and 1 P 0 (h c )channel is plotted. Note that no transport contribution is expected to contribute to any of these NRQCD correlators. Source: Figures partially reproduced from Ref. [277]. channel show a very similar 5% deviation there. On the other hand the χ c1 channel (bottom right) with a much lower ground state binding energy of E χ b1 bind (T = 0) ≈ 0.2 GeV already exhibits a deviation of 12.5% at that temperature. These results clearly establish an ordering of the overall in-medium modification with the vacuum binding energy. This is in agreement with our intuition, as a more strongly bound state also features a smaller spatial extent, which in turn makes it more difficult for the medium d.o.f. to interfere with the binding.</p>
        <p>Since in NRQCD the change in the correlator is expected to be dominated by bound state modification, we may attempt to reverse engineer the underlying behavior of the quarkonium spectral function. To this end one can construct nonrelativistic model spectral functions based on e.g. the lattice static interquark potential (see next subsection) and compute from these the corresponding Euclidean correlator. Having done so in Ref. [277] with the results for bottomonium shown in Fig. 32, the authors concluded that the upward behavior can be understood from the vacuum peaks starting to broaden and moving to lower frequencies. Due to the difficulty of modeling e.g. the lattice cutoff in such an approach this result should be understood as qualitative, i.e. the magnitude of the deviation from unity is not captured accurately as of yet.Since in NRQCD the change in the correlator is expected to be dominated by bound state modification, we may attempt to reverse engineer the underlying behavior of the quarkonium spectral function. To this end one can construct nonrelativistic model spectral functions based on e.g. the lattice static interquark potential (see next subsection) and compute from these the corresponding Euclidean correlator. Having done so in Ref. [277] with the results for bottomonium shown in Fig. 32, the authors concluded that the upward behavior can be understood from the vacuum peaks starting to broaden and moving to lower frequencies. Due to the difficulty of modeling e.g. the lattice cutoff in such an approach this result should be understood as qualitative, i.e. the magnitude of the deviation from unity is not captured accurately as of yet.</p>
        <p>Let us continue with considering the spectral functions as extracted by the MEM in Ref. [113] on anisotropic N f = 2+1 lattices and shown in Fig. 33. The left panel contains the S-wave results, the right panel those for the P-wave. One can clearly see that at low temperatures the ground state peak agrees with the T = 0 result indicated by gray vertical lines.Let us continue with considering the spectral functions as extracted by the MEM in Ref. [113] on anisotropic N f = 2+1 lattices and shown in Fig. 33. The left panel contains the S-wave results, the right panel those for the P-wave. One can clearly see that at low temperatures the ground state peak agrees with the T = 0 result indicated by gray vertical lines.</p>
        <p>The second bump structure summarizes both the first and possible higher excited states, which is why it is shifted above the T = 0 excited state position. With increasing temperature the ground state amplitude monotonously reduces and only one washed out continuum feature remains at high frequencies. A well defined ground state peak structure at T = 1.9T C is still observed.The second bump structure summarizes both the first and possible higher excited states, which is why it is shifted above the T = 0 excited state position. With increasing temperature the ground state amplitude monotonously reduces and only one washed out continuum feature remains at high frequencies. A well defined ground state peak structure at T = 1.9T C is still observed.</p>
        <p>The P-wave results, as expected, show a much weaker ground state signal at small temperatures. There are several reasons responsible for this difference to the S-wave. On the one hand the signal to noise ratio in the P-wave is lower, due to the larger mass of the ground state. Secondly while the amplitude of the S-wave ground state peak at T = 0 is related to the radial S-wave wavefunction at the origin squared, the strength of the P-wave state is related to the first derivative of the wavefunction and suppressed by the square of the heavy quark mass. The third issue is related to the different scaling of the continuum which in the S-wave goes as ω 1/2 , while it is much more dominant in the P-wave with ω 3/2 . Nevertheless around T C a ground state feature is visible, which however vanishes into the continuum above T = 1.09T C .The P-wave results, as expected, show a much weaker ground state signal at small temperatures. There are several reasons responsible for this difference to the S-wave. On the one hand the signal to noise ratio in the P-wave is lower, due to the larger mass of the ground state. Secondly while the amplitude of the S-wave ground state peak at T = 0 is related to the radial S-wave wavefunction at the origin squared, the strength of the P-wave state is related to the first derivative of the wavefunction and suppressed by the square of the heavy quark mass. The third issue is related to the different scaling of the continuum which in the S-wave goes as ω 1/2 , while it is much more dominant in the P-wave with ω 3/2 . Nevertheless around T C a ground state feature is visible, which however vanishes into the continuum above T = 1.09T C .</p>
        <p>At the highest temperatures only a shoulder-like feature persists.At the highest temperatures only a shoulder-like feature persists.</p>
        <p>On the one hand several crosschecks of the systematic uncertainties, such as dependence on the number of used input datapoints and the shape of the default model, have been carried out in Ref. [113]. These indicate that within the MEM the results are robust. On the other hand these checks did not include a comparison to a different Bayesian reconstruction approach. I.e. while the default model has been varied, the influence of the functional form of the prior probability and the limitation of the search space was not assessed.On the one hand several crosschecks of the systematic uncertainties, such as dependence on the number of used input datapoints and the shape of the default model, have been carried out in Ref. [113]. These indicate that within the MEM the results are robust. On the other hand these checks did not include a comparison to a different Bayesian reconstruction approach. I.e. while the default model has been varied, the influence of the functional form of the prior probability and the limitation of the search space was not assessed.</p>
        <p>Ref. [276] contrasted the MEM to the standard BR method when reconstructing the in-medium spectral functions. A very similar presence of the S-wave ground state peak feature deep in the QGP phase has been observed, while for the P-wave a stronger ground state signal beyond T = 1.09T C has been obtained. During this study it became clear that while the BR method is able to reproduce sharp peak with higher accuracy than the MEM, it may introduce numerical ringing when reconstructing extended structures from a small number of datapoints. Systematic crosschecks were carried out to identify ringing but questions on the strength of the P-wave signal remained.Ref. [276] contrasted the MEM to the standard BR method when reconstructing the in-medium spectral functions. A very similar presence of the S-wave ground state peak feature deep in the QGP phase has been observed, while for the P-wave a stronger ground state signal beyond T = 1.09T C has been obtained. During this study it became clear that while the BR method is able to reproduce sharp peak with higher accuracy than the MEM, it may introduce numerical ringing when reconstructing extended structures from a small number of datapoints. Systematic crosschecks were carried out to identify ringing but questions on the strength of the P-wave signal remained.</p>
        <p>In the follow up Ref. [277] an improved understanding of the role of ringing and smoothing has been achieved. To this end the newly developed smooth BR method was deployed. In it the strength of smoothing is implemented in the prior probability with an explicit hyperparameter and thus decoupled from the number of datapoints, contrary to the case in the MEM. The tuning of the smoothing parameter as discussed in Section 2.4.1, is carried out using the analytically known free NRQCD spectral functions. It has been checked that the choice of κ = 1 both removes ringing artifacts and at the same time still allows to accurately identify the ground state features present at T = 0. In practice it is then deployed in tandem with the standard BR method. After ascertaining with the smooth method, whether a genuine in-medium peak has been found, the standard BR method is used to extract its peak position.In the follow up Ref. [277] an improved understanding of the role of ringing and smoothing has been achieved. To this end the newly developed smooth BR method was deployed. In it the strength of smoothing is implemented in the prior probability with an explicit hyperparameter and thus decoupled from the number of datapoints, contrary to the case in the MEM. The tuning of the smoothing parameter as discussed in Section 2.4.1, is carried out using the analytically known free NRQCD spectral functions. It has been checked that the choice of κ = 1 both removes ringing artifacts and at the same time still allows to accurately identify the ground state features present at T = 0. In practice it is then deployed in tandem with the standard BR method. After ascertaining with the smooth method, whether a genuine in-medium peak has been found, the standard BR method is used to extract its peak position.</p>
        <p>To interpret the in-medium results particular care was taken to understand the effect of the finite Euclidean extent available on the lattice. In Fig. 34 we show comparisons between the T = 0 reconstructions (colored solid) both on the full Euclidean correlator, i.e. with input data extending over the full imaginary time extend, as well as using a truncated input dataset with the same Euclidean extent as is available at finite temperature. Obviously the underlying spectral function is the same. On the lattices with coarser lattice spacing e.g. β = 6.664 the differences are not significant. On the other hand for the finely spaced lattices β = 7.925 a clear artificial shift and broadening is observed. These methods artifacts need to be kept in mind when interpreting the in-medium reconstructions.To interpret the in-medium results particular care was taken to understand the effect of the finite Euclidean extent available on the lattice. In Fig. 34 we show comparisons between the T = 0 reconstructions (colored solid) both on the full Euclidean correlator, i.e. with input data extending over the full imaginary time extend, as well as using a truncated input dataset with the same Euclidean extent as is available at finite temperature. Obviously the underlying spectral function is the same. On the lattices with coarser lattice spacing e.g. β = 6.664 the differences are not significant. On the other hand for the finely spaced lattices β = 7.925 a clear artificial shift and broadening is observed. These methods artifacts need to be kept in mind when interpreting the in-medium reconstructions.</p>
        <p>Let us discuss the in-medium results from Ref. [277]. When pitting the standard BR method, the MEM and the smooth BR method against each other it is found that for bottomonium the results of the smooth BR and the MEM agree, in that the Upsilon ground state peak survives up to the highest T = 407 MeV and that χ b1 disappears at around T = 185-210 MeV. These temperatures are similar to those found earlier in Ref. [113], keeping in mind that the underlying medium description still differs between the two studies. Looking at the charmonium spectral functions shown in Fig. 35, we find that in the S-wave channel the MEM and the standard BR method both seem to be affected by ringing, while the smooth BR method recovers a smooth continuum regime. The J/ψ peak becomes insignificant between T = 200-210 MeV. For the η c the MEM and the smooth BR show rather similar behavior for the ground state, while only the smooth BR manages to avoid ringing in the continuum regime. Here no peak structures are discernible at around T = 185 MeV.Let us discuss the in-medium results from Ref. [277]. When pitting the standard BR method, the MEM and the smooth BR method against each other it is found that for bottomonium the results of the smooth BR and the MEM agree, in that the Upsilon ground state peak survives up to the highest T = 407 MeV and that χ b1 disappears at around T = 185-210 MeV. These temperatures are similar to those found earlier in Ref. [113], keeping in mind that the underlying medium description still differs between the two studies. Looking at the charmonium spectral functions shown in Fig. 35, we find that in the S-wave channel the MEM and the standard BR method both seem to be affected by ringing, while the smooth BR method recovers a smooth continuum regime. The J/ψ peak becomes insignificant between T = 200-210 MeV. For the η c the MEM and the smooth BR show rather similar behavior for the ground state, while only the smooth BR manages to avoid ringing in the continuum regime. Here no peak structures are discernible at around T = 185 MeV.</p>
        <p>The main quantitative finding of Ref. [277] is an improved determination of the in-medium mass shifts of the ground state quarkonium particles. In the top row of Fig. 36 the raw masses entering the analysis are shown for bottomonium (left) and charmonium (right) S-wave channels. Errorbars include both statistical and systematic uncertainties from the Bayesian spectral reconstruction and the ground state peak fit. The blue crosses denote the ground state mass obtained from reconstructing the full T = 0 datasets, while the gray boxes are obtained from the truncated T = 0 datasets, which feature the same imaginary time extent as the data at T &gt; 0. The actual T &gt; 0 mass estimates are given by the colored symbols. A first naive comparison by eye of the blue crosses and colored symbols would lead to the (premature) conclusion that the in-medium masses lies above the vacuum ones. Since at T &gt; not only the spectral function changes but also the Euclidean time extend is significantly reduced the authors of Ref. [277] argue that instead the gray boxes should taken as reference point. This changes the conclusion significantly leading to negative mass shifts, which plotted in the bottom row. As we will see in the next section the values obtained here are compatible with the results obtained from non-relativistic spectral functions computed using model potentials. Note that for bottomonium at T = 140 MeV virtually no difference between the colored triangle and the gray box is found, consistent with no in-medium modification seen in the correlator ratio. For charmonium on the other hand one finds a difference beyond the uncertainties, which again corresponds qualitatively with the changes present in the correlator ratios. The fact that the mass shift is negative agrees with the upward bend observed in the correlator ratios.The main quantitative finding of Ref. [277] is an improved determination of the in-medium mass shifts of the ground state quarkonium particles. In the top row of Fig. 36 the raw masses entering the analysis are shown for bottomonium (left) and charmonium (right) S-wave channels. Errorbars include both statistical and systematic uncertainties from the Bayesian spectral reconstruction and the ground state peak fit. The blue crosses denote the ground state mass obtained from reconstructing the full T = 0 datasets, while the gray boxes are obtained from the truncated T = 0 datasets, which feature the same imaginary time extent as the data at T &gt; 0. The actual T &gt; 0 mass estimates are given by the colored symbols. A first naive comparison by eye of the blue crosses and colored symbols would lead to the (premature) conclusion that the in-medium masses lies above the vacuum ones. Since at T &gt; not only the spectral function changes but also the Euclidean time extend is significantly reduced the authors of Ref. [277] argue that instead the gray boxes should taken as reference point. This changes the conclusion significantly leading to negative mass shifts, which plotted in the bottom row. As we will see in the next section the values obtained here are compatible with the results obtained from non-relativistic spectral functions computed using model potentials. Note that for bottomonium at T = 140 MeV virtually no difference between the colored triangle and the gray box is found, consistent with no in-medium modification seen in the correlator ratio. For charmonium on the other hand one finds a difference beyond the uncertainties, which again corresponds qualitatively with the changes present in the correlator ratios. The fact that the mass shift is negative agrees with the upward bend observed in the correlator ratios.</p>
        <p>With several consistent arguments presented here for the mass shifts in NRQCD to be negative it has to be understood how this stack up to the results in the relativistic formulation. Crosschecks with the reconstructed correlator performed in Ref. [271] e.g. seem to indicate that a positive mass shift is obtained instead. Whether this difference is related to a deficiency of the lattice NRQCD implementation (e.g. due to radiative corrections) or whether it is a reconstruction artifact of the MEM used in the relativistic study, remains to be seen.With several consistent arguments presented here for the mass shifts in NRQCD to be negative it has to be understood how this stack up to the results in the relativistic formulation. Crosschecks with the reconstructed correlator performed in Ref. [271] e.g. seem to indicate that a positive mass shift is obtained instead. Whether this difference is related to a deficiency of the lattice NRQCD implementation (e.g. due to radiative corrections) or whether it is a reconstruction artifact of the MEM used in the relativistic study, remains to be seen.</p>
        <p>Up to this point only ground state properties have been discussed in finite temperature NRQCD, since the excited state contributions already at T = 0 are difficult to pin down in spectral reconstructions. To quantify the challenge ahead one can take a look at the mock data tests shown in Fig. 37. The left panel shows the BR method reconstructions (colored solid) of a T = 0 bottomonium spectrum, as expected to be present in an NRQCD setting. To focus on the bound state reconstruction, no continuum has been added in the mock input spectrum. Discretized with N τ = 32 and a realistic a = 0.117 fm one finds that sub-percent precision in the input data is required to get hold of the second peak. In the right panel we show the same mock spectrum now reconstructed with double the number of input points at half the lattice spacing. The bad news is that no significant improvement in the bound state reconstruction is obtained. On the other hand if a continuum structure is added to the mock spectrum it is seen that a smaller lattice spacing does improve the reconstruction of the UV part of the spectral function. One might think that by improving the quality of the reconstruction algorithm the problem might be solved. That this also is not the magic bullet has been shown by tests of the information content of the correlators performed in Ref. [277]. After subtracting from the T = 0 correlator the ground state peak contribution, as well as the second exponential falloff, usually associated with the first excited state, only a very small number of convex points remain from which all the intricate structure of the higher lying states, as well as the continuum need to be determined. Even with a perfect reconstruction algorithm this will remain challenging 2 . One possibility is to consequently deploy anisotropic lattices (as is done by the FASTSUM collaboration and in planning at the HotQCD collaboration), to have the UV part of the spectrum better resolved. In the long run it appears that improvements in simulation algorithms, e.g. an extension of the multilevel algorithm to dynamical QCD would be required for substantial progress in the reconstruction of the bound state features.Up to this point only ground state properties have been discussed in finite temperature NRQCD, since the excited state contributions already at T = 0 are difficult to pin down in spectral reconstructions. To quantify the challenge ahead one can take a look at the mock data tests shown in Fig. 37. The left panel shows the BR method reconstructions (colored solid) of a T = 0 bottomonium spectrum, as expected to be present in an NRQCD setting. To focus on the bound state reconstruction, no continuum has been added in the mock input spectrum. Discretized with N τ = 32 and a realistic a = 0.117 fm one finds that sub-percent precision in the input data is required to get hold of the second peak. In the right panel we show the same mock spectrum now reconstructed with double the number of input points at half the lattice spacing. The bad news is that no significant improvement in the bound state reconstruction is obtained. On the other hand if a continuum structure is added to the mock spectrum it is seen that a smaller lattice spacing does improve the reconstruction of the UV part of the spectral function. One might think that by improving the quality of the reconstruction algorithm the problem might be solved. That this also is not the magic bullet has been shown by tests of the information content of the correlators performed in Ref. [277]. After subtracting from the T = 0 correlator the ground state peak contribution, as well as the second exponential falloff, usually associated with the first excited state, only a very small number of convex points remain from which all the intricate structure of the higher lying states, as well as the continuum need to be determined. Even with a perfect reconstruction algorithm this will remain challenging 2 . One possibility is to consequently deploy anisotropic lattices (as is done by the FASTSUM collaboration and in planning at the HotQCD collaboration), to have the UV part of the spectrum better resolved. In the long run it appears that improvements in simulation algorithms, e.g. an extension of the multilevel algorithm to dynamical QCD would be required for substantial progress in the reconstruction of the bound state features.</p>
        <p>Lattice NRQCD provides an alternative discretization of heavy quarks on the lattice, which has been applied to the study of both bottomonium and charmonium at finite temperature. Due to the absence of transport contributions and full N τ individual correlator datapoints available, a robust picture of ground state in-medium modification has emerged.Lattice NRQCD provides an alternative discretization of heavy quarks on the lattice, which has been applied to the study of both bottomonium and charmonium at finite temperature. Due to the absence of transport contributions and full N τ individual correlator datapoints available, a robust picture of ground state in-medium modification has emerged.</p>
        <p>Correlator ratios show a hierarchical ordering of the overall in-medium modification with the vacuum binding energy of the states in that channel. Their temperature dependence also hints at the in-medium particles to become lighter as temperature increases. Spectral reconstructions have been carried out using a range of different Bayesian methods, which has significantly improved the understanding of the involved methods uncertainties. In addition the effects of diminishing access to Euclidean time have been elucidated. In turn very similar patterns for the disappearance of bound state features in the bottomonium sector are found among different groups. In-medium mass shifts extracted from the reconstructed charmonium and bottomonium spectral functions show negative values, consistent with the findings of the correlator ratios, as well as with spectral functions computed with potential models in the next section. Improvements of the spectral reconstruction results obtained so far, especially for excited states will require substantial efforts by the whole lattice community.Correlator ratios show a hierarchical ordering of the overall in-medium modification with the vacuum binding energy of the states in that channel. Their temperature dependence also hints at the in-medium particles to become lighter as temperature increases. Spectral reconstructions have been carried out using a range of different Bayesian methods, which has significantly improved the understanding of the involved methods uncertainties. In addition the effects of diminishing access to Euclidean time have been elucidated. In turn very similar patterns for the disappearance of bound state features in the bottomonium sector are found among different groups. In-medium mass shifts extracted from the reconstructed charmonium and bottomonium spectral functions show negative values, consistent with the findings of the correlator ratios, as well as with spectral functions computed with potential models in the next section. Improvements of the spectral reconstruction results obtained so far, especially for excited states will require substantial efforts by the whole lattice community.</p>
        <p>While the use of the effective field theory NRQCD on lattice has already led to significantly improved understanding of the ground state in-medium properties in both bottomonium and charmonium, we have seen that so far excited states, as well as the continuum not well To progress in this direction we can turn to the effective field theory pNRQCD, allows us to derive the proper real-time in-medium potential systematically from QCD.While the use of the effective field theory NRQCD on lattice has already led to significantly improved understanding of the ground state in-medium properties in both bottomonium and charmonium, we have seen that so far excited states, as well as the continuum not well To progress in this direction we can turn to the effective field theory pNRQCD, allows us to derive the proper real-time in-medium potential systematically from QCD.</p>
        <p>The study of quarkonium in-medium properties based on potentials has a long history. Until recently however only model potential were utilized, starting with works that used purely real potential models (for an overview see e.g. Ref. [279]), such as the color singlet free energies (see e.g. Ref. [280]) or internal energies. With the realization that the proper real-time potential is complex, first computations of the in-medium spectral functions using the perturbatively evaluated real-time potential were carried out in Ref. [68], followed by models combining a lattice inspired real part with the perturbative imaginary part [22]. Shortly after the first non-perturbative lattice determination of the proper real-time potential had been achieved, it became a vital ingredient in spectral function computations in Refs. [219,281].The study of quarkonium in-medium properties based on potentials has a long history. Until recently however only model potential were utilized, starting with works that used purely real potential models (for an overview see e.g. Ref. [279]), such as the color singlet free energies (see e.g. Ref. [280]) or internal energies. With the realization that the proper real-time potential is complex, first computations of the in-medium spectral functions using the perturbatively evaluated real-time potential were carried out in Ref. [68], followed by models combining a lattice inspired real part with the perturbative imaginary part [22]. Shortly after the first non-perturbative lattice determination of the proper real-time potential had been achieved, it became a vital ingredient in spectral function computations in Refs. [219,281].</p>
        <p>2 During the review process of this manuscript a new study appeared that sets out to extract the mass shifts and spectral width of both ground and excited states of in-medium quarkonium. It does so by combining interpolating operators optimized via T = 0 quarkonium wavefunctions with a simple model of the spectral function used to fit the resulting Euclidean correlator. As presented in Ref. [278] no significant sign of a mass shift is found in this approach, adding further urgency to the resolution of the in-medium mass shift question.2 During the review process of this manuscript a new study appeared that sets out to extract the mass shifts and spectral width of both ground and excited states of in-medium quarkonium. It does so by combining interpolating operators optimized via T = 0 quarkonium wavefunctions with a simple model of the spectral function used to fit the resulting Euclidean correlator. As presented in Ref. [278] no significant sign of a mass shift is found in this approach, adding further urgency to the resolution of the in-medium mass shift question.</p>
        <p>There are several generic features of in-medium spectral functions, which can be directly related to the form of the potential. At T = 0 the energy at which string breaking sets in Re[V ] indicates the position of the open-heavy flavor threshold. Generically finite temperature effects lead to a weakening of the real part. For very small Debye masses, string breaking dominates the asymptotic flattening off, while at some point the inverse of the Debye mass becomes smaller than the string breaking radius and screening takes over. Note that contrary to a purely Coulombic term that always asymptotes to zero, the asymptotic value of Re[V ] reduces monotonously from the T = 0 value, indicating that the continuum threshold moves to lower and lower energies. As the binding energy of a state, defined via spectral functions, is computed from the energy distance between the continuum threshold and the position of the bound-state peak, a weakening of the in-medium binding is thus expected to occur. While for a purely real potential genuine bound state peaks remain at finite temperature, the presence of an imaginary part leads to a finite width (and essentially no additional shift) in the spectral function, indicating the dynamical nature of the Q Q pair in the medium.There are several generic features of in-medium spectral functions, which can be directly related to the form of the potential. At T = 0 the energy at which string breaking sets in Re[V ] indicates the position of the open-heavy flavor threshold. Generically finite temperature effects lead to a weakening of the real part. For very small Debye masses, string breaking dominates the asymptotic flattening off, while at some point the inverse of the Debye mass becomes smaller than the string breaking radius and screening takes over. Note that contrary to a purely Coulombic term that always asymptotes to zero, the asymptotic value of Re[V ] reduces monotonously from the T = 0 value, indicating that the continuum threshold moves to lower and lower energies. As the binding energy of a state, defined via spectral functions, is computed from the energy distance between the continuum threshold and the position of the bound-state peak, a weakening of the in-medium binding is thus expected to occur. While for a purely real potential genuine bound state peaks remain at finite temperature, the presence of an imaginary part leads to a finite width (and essentially no additional shift) in the spectral function, indicating the dynamical nature of the Q Q pair in the medium.</p>
        <p>The computation of spectral functions proceeds via solving the Schrödinger equation for the unequal time and point split meson correlator D &gt; (t; r, r ′ ). In the vector channel it readsThe computation of spectral functions proceeds via solving the Schrödinger equation for the unequal time and point split meson correlator D &gt; (t; r, r ′ ). In the vector channel it reads</p>
        <p>Transforming time to Fourier space and expanding the angular dependencies of r and r ′ into spherical harmonics withTransforming time to Fourier space and expanding the angular dependencies of r and r ′ into spherical harmonics with</p>
        <p>Note that the in-medium potential which we will use to implement this time evolution was defined in the static limit in Eq. ( 61), i.e. it denotes the leading order contribution in a systematic expansion in the finite heavy quark velocity. This entails that at this point no finite velocity, e.g. spin dependent, corrections have been included. In the following we will use the static potential to approximately describe the evolution of quarkonium with a finite mass. After evolving to late enough Minkowski time the Fourier transform can be reliably computedNote that the in-medium potential which we will use to implement this time evolution was defined in the static limit in Eq. ( 61), i.e. it denotes the leading order contribution in a systematic expansion in the finite heavy quark velocity. This entails that at this point no finite velocity, e.g. spin dependent, corrections have been included. In the following we will use the static potential to approximately describe the evolution of quarkonium with a finite mass. After evolving to late enough Minkowski time the Fourier transform can be reliably computed</p>
        <p>The vector channel spectral function follows from considering its imaginary part and taking limit of vanishing quark-antiquark separation, which recovers the appropriate frequency space current correlatorThe vector channel spectral function follows from considering its imaginary part and taking limit of vanishing quark-antiquark separation, which recovers the appropriate frequency space current correlator</p>
        <p>In Appendix A of Ref. [68] an efficient implementation of the above prescription has worked out for both vector channel (S-wave) and scalar channel (P-wave) spectral functions. It is directly formulated in frequency space and carefully considers the involved limiting procedure. The reference provides a readily implementable prescription for practical use. Since to low order in the heavy quark velocity expansion it can be argued that ρ P ≃ -In Appendix A of Ref. [68] an efficient implementation of the above prescription has worked out for both vector channel (S-wave) and scalar channel (P-wave) spectral functions. It is directly formulated in frequency space and carefully considers the involved limiting procedure. The reference provides a readily implementable prescription for practical use. Since to low order in the heavy quark velocity expansion it can be argued that ρ P ≃ -</p>
        <p>all relevant spectra can be obtained. In case of a purely Coulombic potential, due to its additional symmetries, it may happen that the vector and scalar channel mix with a numerically small contribution.all relevant spectra can be obtained. In case of a purely Coulombic potential, due to its additional symmetries, it may happen that the vector and scalar channel mix with a numerically small contribution.</p>
        <p>To achieve an accurate description of the in-medium properties of quarkonium, all input parameters of the above Schrödinger equation need to be evaluated in a realistic setting. For the potential this means that we require continuum extrapolated lattice data, as well as an appropriately renormalized quark mass. While there are ongoing efforts to extract the static interquark potential on ensembles close to the continuum (see e.g. Ref. [220]) no genuine continuum extrapolation has been computed so far. This necessitates manual continuum corrections and we discuss here the strategy introduced in Ref. [219].To achieve an accurate description of the in-medium properties of quarkonium, all input parameters of the above Schrödinger equation need to be evaluated in a realistic setting. For the potential this means that we require continuum extrapolated lattice data, as well as an appropriately renormalized quark mass. While there are ongoing efforts to extract the static interquark potential on ensembles close to the continuum (see e.g. Ref. [220]) no genuine continuum extrapolation has been computed so far. This necessitates manual continuum corrections and we discuss here the strategy introduced in Ref. [219].</p>
        <p>As it was found that the Gauss-law parametrization successfully reproduces the real part of the lattice potential and shows good agreement with the tentatively extracted values of the imaginary part, it has been used in the literature to implement the in-medium effects. In a first step its vacuum parameters are tuned in a phenomenological fashion. I.e. they are varied until the solution of the corresponding S-wave and P-wave Schrödinger equation reproduces the PDG values of the different ground state masses. The finite temperature physics is then introduced by using appropriately rescaled values of the Debye mass found on the lattice.As it was found that the Gauss-law parametrization successfully reproduces the real part of the lattice potential and shows good agreement with the tentatively extracted values of the imaginary part, it has been used in the literature to implement the in-medium effects. In a first step its vacuum parameters are tuned in a phenomenological fashion. I.e. they are varied until the solution of the corresponding S-wave and P-wave Schrödinger equation reproduces the PDG values of the different ground state masses. The finite temperature physics is then introduced by using appropriately rescaled values of the Debye mass found on the lattice.</p>
        <p>For the quark mass parameter we consider first the bottomonium system, as here pNRQCD is expected to work reliably.For the quark mass parameter we consider first the bottomonium system, as here pNRQCD is expected to work reliably.</p>
        <p>In addition the matching to QCD can be implemented perturbatively, since the bottom mass is much larger than Λ QCD . As has been suggested in Ref. [70] one consistent and elegant way to define an appropriate mass to be used in the Schrödinger equation is the renormalon subtracted mass. It provides a prescription that reshuffles the ambiguities in the perturbative definition of the pole mass into the definition of the constant part of the potential, which contains the same ambiguity,In addition the matching to QCD can be implemented perturbatively, since the bottom mass is much larger than Λ QCD . As has been suggested in Ref. [70] one consistent and elegant way to define an appropriate mass to be used in the Schrödinger equation is the renormalon subtracted mass. It provides a prescription that reshuffles the ambiguities in the perturbative definition of the pole mass into the definition of the constant part of the potential, which contains the same ambiguity,</p>
        <p>Vacuum properties of relevant bottomonium particles based on the best fit parameters of Eq. ( 213) and the renormalon subtracted mass of Eq. (212).Vacuum properties of relevant bottomonium particles based on the best fit parameters of Eq. ( 213) and the renormalon subtracted mass of Eq. (212).</p>
        <p>Vacuum properties of relevant charmonium particles based on the best fit parameters of Eq. ( 213) and the best estimate of the charm mass of Eq. (214). effectively canceling the two in turn leading to a well defined Schrödinger equation. For bottom the renormalon subtracted mass provided in Tab.4 of Ref. [70] takes on the valueVacuum properties of relevant charmonium particles based on the best fit parameters of Eq. ( 213) and the best estimate of the charm mass of Eq. (214). effectively canceling the two in turn leading to a well defined Schrödinger equation. For bottom the renormalon subtracted mass provided in Tab.4 of Ref. [70] takes on the value</p>
        <p>Note that this value is different from both the often deployed bottom pole mass m This mass now enters the tuning procedure for the vacuum parameters of the Gauss-law parametrization that allows one to successfully reproduce the masses of the four low lying S-wave states Υ (1S) -Υ (4S). By manually introducing a flattening of the string-like part of the Cornell potential at a characteristic string-breaking scale r SB also the location of the B meson threshold can be reproduced. The consistency of the tuning procedure has been checked by subsequent comparison to the spin averaged mass of the P-wave states χ b0 (1P) -χ b0 (3P) not included in the original fit. The best fit values obtained in the most recent study in Ref. [235] are given by α S = 0.513 ± 0.0024 GeV, √ σ = 0.412 ± 0.0041 GeV, c = -0.161 ± 0.0025 GeV, r SB = 1.25 ± 0.05fm (213) and the resulting vacuum properties of bottomonium states are listed in Table 3 3 .Note that this value is different from both the often deployed bottom pole mass m This mass now enters the tuning procedure for the vacuum parameters of the Gauss-law parametrization that allows one to successfully reproduce the masses of the four low lying S-wave states Υ (1S) -Υ (4S). By manually introducing a flattening of the string-like part of the Cornell potential at a characteristic string-breaking scale r SB also the location of the B meson threshold can be reproduced. The consistency of the tuning procedure has been checked by subsequent comparison to the spin averaged mass of the P-wave states χ b0 (1P) -χ b0 (3P) not included in the original fit. The best fit values obtained in the most recent study in Ref. [235] are given by α S = 0.513 ± 0.0024 GeV, √ σ = 0.412 ± 0.0041 GeV, c = -0.161 ± 0.0025 GeV, r SB = 1.25 ± 0.05fm (213) and the resulting vacuum properties of bottomonium states are listed in Table 3 3 .</p>
        <p>Once the values for the static vacuum potential are fixed, only the charm mass remains to be set. Since its physical value lies much closer to the relevant ΛOnce the values for the static vacuum potential are fixed, only the charm mass remains to be set. Since its physical value lies much closer to the relevant Λ</p>
        <p>MS = 332 MeV (quoted here for three light flavors from Ref. [3]) compared to the bottom mass, a similar robust perturbative renormalon subtracted mass is not available. Instead one may use the fact that the static potential in pNRQCD is universal among different flavors and thus the parameters of Eq. ( 213) may also be used to compute the charmonium vacuum states. This allows us to find the optimal charm quark mass by fitting to the PDG masses of the S-wave states (J/ψ , ψ ′ ). As expected finite velocity corrections do already play a role for charmonium and thus the masses are less accurately reproduced than in the bottomonium case using just the static potential. The corresponding best fit value isMS = 332 MeV (quoted here for three light flavors from Ref. [3]) compared to the bottom mass, a similar robust perturbative renormalon subtracted mass is not available. Instead one may use the fact that the static potential in pNRQCD is universal among different flavors and thus the parameters of Eq. ( 213) may also be used to compute the charmonium vacuum states. This allows us to find the optimal charm quark mass by fitting to the PDG masses of the S-wave states (J/ψ , ψ ′ ). As expected finite velocity corrections do already play a role for charmonium and thus the masses are less accurately reproduced than in the bottomonium case using just the static potential. The corresponding best fit value is</p>
        <p>and the vacuum properties of the resulting states are given in Table 4. With the vacuum sector set up, the focus turns to the question of how to translate the Debye masses extracted at finite lattice spacing to values representative of continuum physics. The discretization leads to two main effects: first, since the masses of light quarks do not yet take their physical values the crossover temperature also lies above its physical value. Secondly, the vacuum parameters of the Cornell potential contain a small lattice spacing dependence and also are not yet at their physical value. In Refs. [219,235] these artifacts are counteracted by considering the dimensionless ratio of the lattice Debye mass and the square root of the lattice string tension. It is multiplied by the square root of the physical string tension and then evaluated at a rescaled temperature where T C lies at 155 MeVand the vacuum properties of the resulting states are given in Table 4. With the vacuum sector set up, the focus turns to the question of how to translate the Debye masses extracted at finite lattice spacing to values representative of continuum physics. The discretization leads to two main effects: first, since the masses of light quarks do not yet take their physical values the crossover temperature also lies above its physical value. Secondly, the vacuum parameters of the Cornell potential contain a small lattice spacing dependence and also are not yet at their physical value. In Refs. [219,235] these artifacts are counteracted by considering the dimensionless ratio of the lattice Debye mass and the square root of the lattice string tension. It is multiplied by the square root of the physical string tension and then evaluated at a rescaled temperature where T C lies at 155 MeV</p>
        <p>3 Note the phenomenological character of this procedure: we do not deploy a short distance Coulombic part in the potential computed in the same scheme as used for the determination of m RS ′ b . This leads to a total quark rest mass given by m RS ′ b + c/2. In case that a consistent scheme were deployed for the potential, the term c should vanish. The values of the continuum corrected Debye mass with errorbars including both uncertainties from the lattice extraction and those from the correction procedure itself are shown in Fig. 38. The characteristic bending down of the ratio around the (now physical) crossover temperature is visible. In order to clearly expose the strength of the in-medium modification in the spectral functions, a temperature scan needs to be carried out for which an interpolation of the Debye mass will be a prerequisite. Amending the NLO expression for the Debye mass in Eq. ( 152) by a second non-perturbative correction term one ends up with the following expression3 Note the phenomenological character of this procedure: we do not deploy a short distance Coulombic part in the potential computed in the same scheme as used for the determination of m RS ′ b . This leads to a total quark rest mass given by m RS ′ b + c/2. In case that a consistent scheme were deployed for the potential, the term c should vanish. The values of the continuum corrected Debye mass with errorbars including both uncertainties from the lattice extraction and those from the correction procedure itself are shown in Fig. 38. The characteristic bending down of the ratio around the (now physical) crossover temperature is visible. In order to clearly expose the strength of the in-medium modification in the spectral functions, a temperature scan needs to be carried out for which an interpolation of the Debye mass will be a prerequisite. Amending the NLO expression for the Debye mass in Eq. ( 152) by a second non-perturbative correction term one ends up with the following expression</p>
        <p>taking here Λ = 2π T as renormalization scale. The four loop results from Ref. [284] have been used to implement the running of the strong coupling g. For evaluating g, a value of Λ QCD = 0.2145 GeV is deployed, initializing the renormalization group flow downwards from energies, where N f = 5 flavors are active. The two non-perturbative parameters κ 1 and κ 2 may now be fitted to the continuum corrected values of m D . Ref. [235] reports best fit values oftaking here Λ = 2π T as renormalization scale. The four loop results from Ref. [284] have been used to implement the running of the strong coupling g. For evaluating g, a value of Λ QCD = 0.2145 GeV is deployed, initializing the renormalization group flow downwards from energies, where N f = 5 flavors are active. The two non-perturbative parameters κ 1 and κ 2 may now be fitted to the continuum corrected values of m D . Ref. [235] reports best fit values of</p>
        <p>which implement the deviation from the perturbative result, needed to describe the downward trend of m D /T around T C .which implement the deviation from the perturbative result, needed to describe the downward trend of m D /T around T C .</p>
        <p>All ingredients have thus been collected for the evaluation of the Schrödinger equation of Eq. ( 207), using a lattice vetted parametrization of the static in-medium potential via the Gauss-law parametrization. The latest results for the S-wave spectral functions are shown in Fig. 39. Characteristic in-medium effects are clearly visible. The bound state peaks at T = 0 are delta-peaks, as here only the strong interaction contribution to the physics is included. The peaks start to broaden at finite temperature and move to lower frequencies, indicating that the particles become lighter inmedium. Since at the same time the continuum also moves to lower energies, the in-medium binding energy actually reduces. Eventually bound state remnants will merge with the continuum leading to a threshold enhancement, which reflects remnant correlations between the quark-antiquark pair even if no genuine bound state structure is discernible. The in-medium modifications are found to be ordered hierarchically with the vacuum binding energy of each individual state.All ingredients have thus been collected for the evaluation of the Schrödinger equation of Eq. ( 207), using a lattice vetted parametrization of the static in-medium potential via the Gauss-law parametrization. The latest results for the S-wave spectral functions are shown in Fig. 39. Characteristic in-medium effects are clearly visible. The bound state peaks at T = 0 are delta-peaks, as here only the strong interaction contribution to the physics is included. The peaks start to broaden at finite temperature and move to lower frequencies, indicating that the particles become lighter inmedium. Since at the same time the continuum also moves to lower energies, the in-medium binding energy actually reduces. Eventually bound state remnants will merge with the continuum leading to a threshold enhancement, which reflects remnant correlations between the quark-antiquark pair even if no genuine bound state structure is discernible. The in-medium modifications are found to be ordered hierarchically with the vacuum binding energy of each individual state.</p>
        <p>For a more quantitative exploration of the in-medium properties, the peak structures can be fitted to extract the corresponding particle mass and thermal width. Scattering theory suggests [285] to use a skewed Breit-Wigner of the following formFor a more quantitative exploration of the in-medium properties, the peak structures can be fitted to extract the corresponding particle mass and thermal width. Scattering theory suggests [285] to use a skewed Breit-Wigner of the following form</p>
        <p>with a skewing fit parameter δ, as well as possible background terms C i . The values for the in-medium mass and width according to the spectral functions of Fig. 39 are shown in Fig. 40. The left column corresponds to bottomonium, the right column to charmonium. In the top row the in-medium masses for the different states that are bound in vacuum are shown as colored solid lines, with the error bands being dominated by the uncertainty in the Debye mass determination.with a skewing fit parameter δ, as well as possible background terms C i . The values for the in-medium mass and width according to the spectral functions of Fig. 39 are shown in Fig. 40. The left column corresponds to bottomonium, the right column to charmonium. In the top row the in-medium masses for the different states that are bound in vacuum are shown as colored solid lines, with the error bands being dominated by the uncertainty in the Debye mass determination.</p>
        <p>The lines end at the temperature where the in-medium peak remnant becomes too washed out for a fit to succeed. The gray line denotes the onset of the continuum.The lines end at the temperature where the in-medium peak remnant becomes too washed out for a fit to succeed. The gray line denotes the onset of the continuum.</p>
        <p>The reduction in the in-medium quarkonium mass at first may appear counter intuitive, as perturbative pNRQCD computations in Refs. [68,201] based on a Coulombic potential, predicted an opposite behavior. The sign of the mass shift one encounter however depends on the scale hierarchy present. If one considers instead pNRQCD in a strongly coupled medium at temperatures larger than the binding energy as e.g. in Refs. [17,286,287] a change towards lighter masses arises.The reduction in the in-medium quarkonium mass at first may appear counter intuitive, as perturbative pNRQCD computations in Refs. [68,201] based on a Coulombic potential, predicted an opposite behavior. The sign of the mass shift one encounter however depends on the scale hierarchy present. If one considers instead pNRQCD in a strongly coupled medium at temperatures larger than the binding energy as e.g. in Refs. [17,286,287] a change towards lighter masses arises.</p>
        <p>Non-perturbatively, from the viewpoint of the static potential, the reduction emerges from the subtle interplay of the medium modification of the string part and the Coulombic part of the vacuum Cornell potential. In addition one may ask how the lowering of the in-medium quarkonium mass compares to the mass gain δm Q for an individual parton, which takes place at finite temperature. That effect enters as a first correction to the static limit, i.e. it is suppressed with the heavy quark mass. As argued in [219] using perturbation theory, the expected values at T = 200 MeV would be δm c ≈ 7 MeV and δm b ≈ 2 MeV, which are insignificant compared to the shifts of tens to hundreds of MeV observed in Fig. 40. (Recently a prescription to compute the in-medium mass shift non-perturbatively from a Euclidean correlators has been put forward in Ref. [288].)Non-perturbatively, from the viewpoint of the static potential, the reduction emerges from the subtle interplay of the medium modification of the string part and the Coulombic part of the vacuum Cornell potential. In addition one may ask how the lowering of the in-medium quarkonium mass compares to the mass gain δm Q for an individual parton, which takes place at finite temperature. That effect enters as a first correction to the static limit, i.e. it is suppressed with the heavy quark mass. As argued in [219] using perturbation theory, the expected values at T = 200 MeV would be δm c ≈ 7 MeV and δm b ≈ 2 MeV, which are insignificant compared to the shifts of tens to hundreds of MeV observed in Fig. 40. (Recently a prescription to compute the in-medium mass shift non-perturbatively from a Euclidean correlators has been put forward in Ref. [288].)</p>
        <p>Note that the mass shifts observed here for the ground state particles are in agreement, within the relatively large errorbands, with those extracted from direct lattice QCD determinations of the spectral function using the NRQCD discretization of the heavy quarks in Fig. 36. This is reassuring, as it signals consistency between the two different non-relativistic approaches.Note that the mass shifts observed here for the ground state particles are in agreement, within the relatively large errorbands, with those extracted from direct lattice QCD determinations of the spectral function using the NRQCD discretization of the heavy quarks in Fig. 36. This is reassuring, as it signals consistency between the two different non-relativistic approaches.</p>
        <p>For the P-wave states, spectral functions have been computed using a legacy version of the Gauss-law parametrization in Ref. [281] and the results are shown in Fig. 41. The main difference to the S-wave case is the presence of the centrifugal term in the underlying Schrödinger equation. It was found that the centrifugal barrier, which it induces, leads to a slightly different pattern of weakening of the in-medium states. In the S-wave case the continuum approaches the in-medium peaks with increasing temperature and eventually swallows them, leaving only a threshold enhancement. For P-waves, bound state remnant features persist after being engulfed by the continuum, before they also wash out eventually.For the P-wave states, spectral functions have been computed using a legacy version of the Gauss-law parametrization in Ref. [281] and the results are shown in Fig. 41. The main difference to the S-wave case is the presence of the centrifugal term in the underlying Schrödinger equation. It was found that the centrifugal barrier, which it induces, leads to a slightly different pattern of weakening of the in-medium states. In the S-wave case the continuum approaches the in-medium peaks with increasing temperature and eventually swallows them, leaving only a threshold enhancement. For P-waves, bound state remnant features persist after being engulfed by the continuum, before they also wash out eventually.</p>
        <p>Summary. The computation of in-medium quarkonium spectral functions from a Schrödinger equation with the static potential at finite temperature provides precise information on not only ground state properties but also those of in-medium excited states and the continuum. The price to pay is reduced accuracy in that so far no finite velocity corrections have been included. The values of the potential available in lattice QCD can be incorporated via the Gausslaw parametrization vetted on appropriately continuum corrected numerical data. The in-medium effects manifest themselves in a characteristic manner: the delta-like vacuum state peaks broaden and shift to lower energies, before being swallowed by the continuum, which even more quickly moves downward in energy as temperature rises. This behavior is qualitatively in agreement with pNRQCD in the presence of a strongly coupled medium with a scale hierarchy, where the temperature is of the order of the binding energy but it is opposite to the predictions from weakly coupled perturbative pNRQCD. The observed mass shift arises in the language of the static potential from an interplay of the medium modification of the string and Coulombic part of the Cornell potential. The values for the resulting negative in-medium mass shift are compatible with those obtained recently in direct lattice NRQCD studies, signaling consistency between different non-relativistic approaches.Summary. The computation of in-medium quarkonium spectral functions from a Schrödinger equation with the static potential at finite temperature provides precise information on not only ground state properties but also those of in-medium excited states and the continuum. The price to pay is reduced accuracy in that so far no finite velocity corrections have been included. The values of the potential available in lattice QCD can be incorporated via the Gausslaw parametrization vetted on appropriately continuum corrected numerical data. The in-medium effects manifest themselves in a characteristic manner: the delta-like vacuum state peaks broaden and shift to lower energies, before being swallowed by the continuum, which even more quickly moves downward in energy as temperature rises. This behavior is qualitatively in agreement with pNRQCD in the presence of a strongly coupled medium with a scale hierarchy, where the temperature is of the order of the binding energy but it is opposite to the predictions from weakly coupled perturbative pNRQCD. The observed mass shift arises in the language of the static potential from an interplay of the medium modification of the string and Coulombic part of the Cornell potential. The values for the resulting negative in-medium mass shift are compatible with those obtained recently in direct lattice NRQCD studies, signaling consistency between different non-relativistic approaches.</p>
        <p>Having focused on direct lattice QCD and effective field theory based strategies in the previous subsections, let us briefly touch on other related approaches which have contributed to improving our understanding of in-medium quarkonium.Having focused on direct lattice QCD and effective field theory based strategies in the previous subsections, let us briefly touch on other related approaches which have contributed to improving our understanding of in-medium quarkonium.</p>
        <p>The first approach to mention is based on finite temperature QCD sum rules, developed in their modern form in Refs. [289][290][291], which generalize the well established sum rules in vacuum (see e.g. Ref. [292]). By combining the operator product expansion of the in-medium meson current correlation function with a Borel transformation, this approach allows to probe differently weighted convolutions of the in-medium spectral functions. Non-perturbative information enters e.g. via the (quenched) lattice QCD determination of the matrix elements constituting the OPE. In particular the scalar and twist-2 gluon condensates, derived from the Lorentz decomposition of the field strength tensor play a role, which in practice are extracted via thermodynamic relations.The first approach to mention is based on finite temperature QCD sum rules, developed in their modern form in Refs. [289][290][291], which generalize the well established sum rules in vacuum (see e.g. Ref. [292]). By combining the operator product expansion of the in-medium meson current correlation function with a Borel transformation, this approach allows to probe differently weighted convolutions of the in-medium spectral functions. Non-perturbative information enters e.g. via the (quenched) lattice QCD determination of the matrix elements constituting the OPE. In particular the scalar and twist-2 gluon condensates, derived from the Lorentz decomposition of the field strength tensor play a role, which in practice are extracted via thermodynamic relations.</p>
        <p>In the past decade, progress has been achieved by further combining the sum rule approach with Bayesian reconstruction methods, such as the MEM, in Ref. [293]. This in turn allows to determine charmonium in-medium spectral function and provides insight into the ground state in-medium modification. In addition sum rules have been instrumental in deriving constraints on the in-medium spectral function in Refs. [294,295], which may be used as prior information in studies of spectral functions directly in lattice QCD. The sum rule approach has been used to study the real-part of the in-medium heavy quark potential in Ref. [296] indicating preference for a value close to the color singlet free energies in agreement with findings in direct lattice QCD. A sum rule approach valid in the presence of strong magnetic fields has been introduced in Ref. [297] with a special focus on the mixing of the S-wave hyperfine doublet η c and J/ψ as discussed in Ref. [298]. Extending the parameter of the Borel transformation, the Borel mass, into the complex plane, the sum rule approach has been generalized in Ref. [299], making possible to also extract spectral information on the excited charmonium states at finite temperature [300]. The sum rule approach at T = 0 reproduces the ground and excited state vacuum masses within 50 -150 MeV. In addition, consistent with the non-relativistic approaches discussed before, it is found that the vacuum peaks move to lower energies as temperature is increased, the magnitude of the shift being a bit weaker than that found from the lattice QCD potential.In the past decade, progress has been achieved by further combining the sum rule approach with Bayesian reconstruction methods, such as the MEM, in Ref. [293]. This in turn allows to determine charmonium in-medium spectral function and provides insight into the ground state in-medium modification. In addition sum rules have been instrumental in deriving constraints on the in-medium spectral function in Refs. [294,295], which may be used as prior information in studies of spectral functions directly in lattice QCD. The sum rule approach has been used to study the real-part of the in-medium heavy quark potential in Ref. [296] indicating preference for a value close to the color singlet free energies in agreement with findings in direct lattice QCD. A sum rule approach valid in the presence of strong magnetic fields has been introduced in Ref. [297] with a special focus on the mixing of the S-wave hyperfine doublet η c and J/ψ as discussed in Ref. [298]. Extending the parameter of the Borel transformation, the Borel mass, into the complex plane, the sum rule approach has been generalized in Ref. [299], making possible to also extract spectral information on the excited charmonium states at finite temperature [300]. The sum rule approach at T = 0 reproduces the ground and excited state vacuum masses within 50 -150 MeV. In addition, consistent with the non-relativistic approaches discussed before, it is found that the vacuum peaks move to lower energies as temperature is increased, the magnitude of the shift being a bit weaker than that found from the lattice QCD potential.</p>
        <p>In the second approach, the T-matrix formalism is used to compute bottomonium in-medium spectra from a realvalued interaction potential that enters a local interaction kernel of a Bethe-Salpeter equation. As the potential is provided as external input and it is not uniquely determined by comparisons with lattice data of e.g. the system free energies, two scenarios, the weak-binding and the strong-binding one are considered. In earlier studies (see e.g. Ref. [301]) a temperature dependent renormalization of the potential had been deployed which leads to significant in-medium mass shift to higher energies, incompatible with the results from the non-perturbative EFT potential. In the most recent stateof-the-art realization of the T-matrix approach reviewed in Ref. [244] the potential is renormalized such that it agrees in the short distance regime at all temperatures. In turn the resulting charmonium spectra for both the weak and strong binding scenario are in qualitative agreement with the EFT potential computations, showing negative mass shifts at finite temperature. The authors conclude that the strong coupling scenario, in which the potential governing the interactions among both light and heavy degrees of freedom is significantly larger than the color singlet free energies is preferred by their results. Since this potential is not directly related to the EFT potential derived for static quarks, there is a priori no tension between these results.In the second approach, the T-matrix formalism is used to compute bottomonium in-medium spectra from a realvalued interaction potential that enters a local interaction kernel of a Bethe-Salpeter equation. As the potential is provided as external input and it is not uniquely determined by comparisons with lattice data of e.g. the system free energies, two scenarios, the weak-binding and the strong-binding one are considered. In earlier studies (see e.g. Ref. [301]) a temperature dependent renormalization of the potential had been deployed which leads to significant in-medium mass shift to higher energies, incompatible with the results from the non-perturbative EFT potential. In the most recent stateof-the-art realization of the T-matrix approach reviewed in Ref. [244] the potential is renormalized such that it agrees in the short distance regime at all temperatures. In turn the resulting charmonium spectra for both the weak and strong binding scenario are in qualitative agreement with the EFT potential computations, showing negative mass shifts at finite temperature. The authors conclude that the strong coupling scenario, in which the potential governing the interactions among both light and heavy degrees of freedom is significantly larger than the color singlet free energies is preferred by their results. Since this potential is not directly related to the EFT potential derived for static quarks, there is a priori no tension between these results.</p>
        <p>The third approach we mention here is based on the AdS/CFT correspondence. While we had briefly mentioned that the real-time potential from the Wilson loop may be computed in this approach it is also possible to directly compute the in-medium spectral functions. The challenge here lies in the fact that as discussed in Ref. [251] by adding heavy quark analogues to N = 4 super Yang-Mills theory one obtains heavy-light meson states, that would be bound so deeply that it is instead favorable to produce light quark pairs to shield the charge of the heavy constituent. In addition the spatial extent of quarkonium analogues appears to be independent (at least in order of magnitude) of their radial excitation. It is difficult to identify these bound states with actual QCD quarkonium particles. In order to overcome these limitations of the top-down approach, instead AdS/CFT models, such as the soft-wall model (see e.g. [302,303]) have been constructed from the bottom up (see also [304]) to incorporate e.g. additional scales that allow to produce a more realistic quarkonium behavior.The third approach we mention here is based on the AdS/CFT correspondence. While we had briefly mentioned that the real-time potential from the Wilson loop may be computed in this approach it is also possible to directly compute the in-medium spectral functions. The challenge here lies in the fact that as discussed in Ref. [251] by adding heavy quark analogues to N = 4 super Yang-Mills theory one obtains heavy-light meson states, that would be bound so deeply that it is instead favorable to produce light quark pairs to shield the charge of the heavy constituent. In addition the spatial extent of quarkonium analogues appears to be independent (at least in order of magnitude) of their radial excitation. It is difficult to identify these bound states with actual QCD quarkonium particles. In order to overcome these limitations of the top-down approach, instead AdS/CFT models, such as the soft-wall model (see e.g. [302,303]) have been constructed from the bottom up (see also [304]) to incorporate e.g. additional scales that allow to produce a more realistic quarkonium behavior.</p>
        <p>The computation of spectral functions may be implemented via the identification of a vector field in the bulk with the vector meson current on the gauge theory side. Some model computations in the holographic approach, such as in Ref. [305] produce in-medium modifications of quarkonium spectral functions that are qualitatively compatible with the QCD results, in that the in-medium peaks move to lower energies as temperature is increased. On the other hand there are also computations found in the literature, which produce opposite behavior, such as in Ref. [306]. It appears that there is not yet a final consensus reached on the in-medium modification of quarkonium within the holography community.The computation of spectral functions may be implemented via the identification of a vector field in the bulk with the vector meson current on the gauge theory side. Some model computations in the holographic approach, such as in Ref. [305] produce in-medium modifications of quarkonium spectral functions that are qualitatively compatible with the QCD results, in that the in-medium peaks move to lower energies as temperature is increased. On the other hand there are also computations found in the literature, which produce opposite behavior, such as in Ref. [306]. It appears that there is not yet a final consensus reached on the in-medium modification of quarkonium within the holography community.</p>
        <p>Summary. The development of QCD sum rules in thermal equilibrium has opened a complementary route to investigating quarkonium in-medium properties. The approach has matured over the past two decades and its results on in-medium modification are consistent with those obtained directly from lattice QCD and effective field theory. The improved renormalization of the interaction potential in the T-matrix approach has allowed to obtain in-medium quarkonium spectral functions that are also in qualitative agreement with the EFT potential based results. The apparent discrepancy between the larger values of the T-matrix potential and the EFT potential is partially related to the fact that the two quantities are not the same, the former also governing the physics of the light degrees of freedom. In the bottom-up approach to the holographic description of QCD, quarkonium in-medium spectral functions have been computed. Different implementations of the bulk physics produce opposite in-medium modifications of the bound state features and it appears that a consensus in the community is still outstanding.Summary. The development of QCD sum rules in thermal equilibrium has opened a complementary route to investigating quarkonium in-medium properties. The approach has matured over the past two decades and its results on in-medium modification are consistent with those obtained directly from lattice QCD and effective field theory. The improved renormalization of the interaction potential in the T-matrix approach has allowed to obtain in-medium quarkonium spectral functions that are also in qualitative agreement with the EFT potential based results. The apparent discrepancy between the larger values of the T-matrix potential and the EFT potential is partially related to the fact that the two quantities are not the same, the former also governing the physics of the light degrees of freedom. In the bottom-up approach to the holographic description of QCD, quarkonium in-medium spectral functions have been computed. Different implementations of the bulk physics produce opposite in-medium modifications of the bound state features and it appears that a consensus in the community is still outstanding.</p>
        <p>In the preceding sections we have compiled a wealth of insight into the in-medium behavior of quarkonium immersed in a heat bath at finite temperature by studying the in-medium spectral functions and associated Euclidean correlation functions. This preparation in turn allows us to approach the question of quarkonium melting in this section.In the preceding sections we have compiled a wealth of insight into the in-medium behavior of quarkonium immersed in a heat bath at finite temperature by studying the in-medium spectral functions and associated Euclidean correlation functions. This preparation in turn allows us to approach the question of quarkonium melting in this section.</p>
        <p>Historically the theoretically well posed question of the stability of quarkonium states at finite temperature has been intimately connected to the experimental measurements of quarkonium yields in relativistic heavy-ion collisions. Starting with the seminal work by Matsui and Satz in Ref. [13] on quarkonium suppression by QGP formation (see also Ref. [307]), as well as through the proposal of the sequential suppression scenario in Ref. [14] this has led to an unfortunate entangling of the question of quarkonium in-medium binding in equilibrium with the intricacies related to quarkonium production in a highly non-equilibrium environment, such as present in a heavy-ion collisions.Historically the theoretically well posed question of the stability of quarkonium states at finite temperature has been intimately connected to the experimental measurements of quarkonium yields in relativistic heavy-ion collisions. Starting with the seminal work by Matsui and Satz in Ref. [13] on quarkonium suppression by QGP formation (see also Ref. [307]), as well as through the proposal of the sequential suppression scenario in Ref. [14] this has led to an unfortunate entangling of the question of quarkonium in-medium binding in equilibrium with the intricacies related to quarkonium production in a highly non-equilibrium environment, such as present in a heavy-ion collisions.</p>
        <p>Without diminishing the important role played by quarkonium in the study of heavy-ion collisions, we shall try to disentangle the two, by clearly distinguishing between quarkonium melting and quarkonium suppression. The former we will discuss in this section the latter we will return to in the context of heavy-ion collisions in Section 5.3.Without diminishing the important role played by quarkonium in the study of heavy-ion collisions, we shall try to disentangle the two, by clearly distinguishing between quarkonium melting and quarkonium suppression. The former we will discuss in this section the latter we will return to in the context of heavy-ion collisions in Section 5.3.</p>
        <p>For more than 20 years, intuition surrounding the question of in-medium quarkonium stability has been acquired in terms of real-valued potential models (for an overview see e.g. [279] and references therein). In these models the thermal environment leads to a monotonous weakening of the potential, which was used to compute the eigenfunctions and energies of a non-relativistic Hamiltonian. Instead of the bound stationary states of the vacuum Hamiltonian, at T &gt; 0 one considered stationary states of the in-medium Hamiltonian. At low temperatures these states remain bound but, at well defined thresholds T melt , one by one go over into unbound states, as can be cleanly identified e.g. using the complex scaling method reviewed in Ref. [308]. This entirely static setup has given rise to the intuitively appealing idea of sequential melting, i.e. vacuum states that are more deeply bound will dissociate more easily at finite temperatures than those that are more weakly bound at T = 0. In addition a strong focus was placed on determining the stability parameters of quarkonium states in this model approach, the melting temperatures T melt .For more than 20 years, intuition surrounding the question of in-medium quarkonium stability has been acquired in terms of real-valued potential models (for an overview see e.g. [279] and references therein). In these models the thermal environment leads to a monotonous weakening of the potential, which was used to compute the eigenfunctions and energies of a non-relativistic Hamiltonian. Instead of the bound stationary states of the vacuum Hamiltonian, at T &gt; 0 one considered stationary states of the in-medium Hamiltonian. At low temperatures these states remain bound but, at well defined thresholds T melt , one by one go over into unbound states, as can be cleanly identified e.g. using the complex scaling method reviewed in Ref. [308]. This entirely static setup has given rise to the intuitively appealing idea of sequential melting, i.e. vacuum states that are more deeply bound will dissociate more easily at finite temperatures than those that are more weakly bound at T = 0. In addition a strong focus was placed on determining the stability parameters of quarkonium states in this model approach, the melting temperatures T melt .</p>
        <p>In the following we argue that the concept of sequential melting, interpreted as a dynamical statement, remains a valid guiding principle in a modern understanding of in-medium quarkonium. On the other hand the concept of melting temperature turns out to be less informative than originally anticipated.In the following we argue that the concept of sequential melting, interpreted as a dynamical statement, remains a valid guiding principle in a modern understanding of in-medium quarkonium. On the other hand the concept of melting temperature turns out to be less informative than originally anticipated.</p>
        <p>Our understanding of in-medium quarkonium changed fundamentally with the realization that the in-medium interquark potential is complex valued. It forced the research community to acknowledge that the Q Q system is far from stationary and instead should be understood as inherently dynamical. It also reinforced the fact that the potential computed in the effective field theory pNRQCD does not govern the time evolution of the Q Q wavefunction but instead that of the unequal time point-split meson correlator. As we saw in Section 3.3.3 the complex static interquark potential hence allows us to compute an approximation of the T &gt; 0 spectral function, from which in-medium properties of individual states can be read off. It is this information that QCD theory brings to the table and from which vital insight into the stability and eventual melting of heavy quarkonium in thermal equilibrium is deduced.Our understanding of in-medium quarkonium changed fundamentally with the realization that the in-medium interquark potential is complex valued. It forced the research community to acknowledge that the Q Q system is far from stationary and instead should be understood as inherently dynamical. It also reinforced the fact that the potential computed in the effective field theory pNRQCD does not govern the time evolution of the Q Q wavefunction but instead that of the unequal time point-split meson correlator. As we saw in Section 3.3.3 the complex static interquark potential hence allows us to compute an approximation of the T &gt; 0 spectral function, from which in-medium properties of individual states can be read off. It is this information that QCD theory brings to the table and from which vital insight into the stability and eventual melting of heavy quarkonium in thermal equilibrium is deduced.</p>
        <p>An important feature at finite temperature is the presence of thermal broadening, induced by Im[V ] ̸ = 0. The width Γ of an in-medium spectral peak represents the finite probability for that state to transition into some other state over a characteristic time scale ∼1/Γ . While the lattice simulation may provide insight into the values of Γ , it does not tell us about the processes involved in generating it. On the other hand perturbative studies (see Ref. [17]) have revealed that depending on the hierarchy of energy scales e.g. Landau damping and gluon absorption may contribute to the thermal broadening. Unfortunately, from the spectral function alone one cannot determine into which state the quarkonium transitions, i.e. whether it stays in the singlet channel as a more highly excited (or de-excited) state or whether it turns into an unbound color octet. This information is hidden in higher order correlation functions, similar to the density matrix of the quarkonium system, which only recently has been studied starting from first principles. In Section 4 we will discuss how the changes in occupancies of individual states can be described in real-time and will find that the phenomenon of decoherence is an essential ingredient in understanding the survival of heavy quarkonium in medium. It is clear that the question of quarkonium stability cannot be answered in a static picture and quarkonium melting is an inherently time dependent process.An important feature at finite temperature is the presence of thermal broadening, induced by Im[V ] ̸ = 0. The width Γ of an in-medium spectral peak represents the finite probability for that state to transition into some other state over a characteristic time scale ∼1/Γ . While the lattice simulation may provide insight into the values of Γ , it does not tell us about the processes involved in generating it. On the other hand perturbative studies (see Ref. [17]) have revealed that depending on the hierarchy of energy scales e.g. Landau damping and gluon absorption may contribute to the thermal broadening. Unfortunately, from the spectral function alone one cannot determine into which state the quarkonium transitions, i.e. whether it stays in the singlet channel as a more highly excited (or de-excited) state or whether it turns into an unbound color octet. This information is hidden in higher order correlation functions, similar to the density matrix of the quarkonium system, which only recently has been studied starting from first principles. In Section 4 we will discuss how the changes in occupancies of individual states can be described in real-time and will find that the phenomenon of decoherence is an essential ingredient in understanding the survival of heavy quarkonium in medium. It is clear that the question of quarkonium stability cannot be answered in a static picture and quarkonium melting is an inherently time dependent process.</p>
        <p>The stability of in-medium quarkonium of course is closely related with its in-medium binding energy, defined from the distance between the in-medium peak and the continuum threshold. Qualitatively similar to what had been observed in the historic potential models, we found in Section 3.3.3 that screening of Re[V ] leads to a decrease of the in-medium binding energy from an interplay of a reduction in the bound-state mass and the onset of the continuum threshold. As the formerly long lived quarkonium state is heated up its binding is weakened. The associated increase in spatial extent leads to a higher chance of scattering with medium partons that in turn may kick it into a different state. I.e. the reduction in E bind goes hand in hand with an increase of Γ .The stability of in-medium quarkonium of course is closely related with its in-medium binding energy, defined from the distance between the in-medium peak and the continuum threshold. Qualitatively similar to what had been observed in the historic potential models, we found in Section 3.3.3 that screening of Re[V ] leads to a decrease of the in-medium binding energy from an interplay of a reduction in the bound-state mass and the onset of the continuum threshold. As the formerly long lived quarkonium state is heated up its binding is weakened. The associated increase in spatial extent leads to a higher chance of scattering with medium partons that in turn may kick it into a different state. I.e. the reduction in E bind goes hand in hand with an increase of Γ .</p>
        <p>What the computations based on the lattice vetted complex potential show, supported by the consistent correlator ratios in NRQCD, is that the weakening of the in-medium quarkonium states indeed proceeds hierarchically ordered withWhat the computations based on the lattice vetted complex potential show, supported by the consistent correlator ratios in NRQCD, is that the weakening of the in-medium quarkonium states indeed proceeds hierarchically ordered with</p>
        <p>Melting temperatures for S-wave quarkonium states estimated from the spectral functions of Fig. 39 and Ref. [235].Melting temperatures for S-wave quarkonium states estimated from the spectral functions of Fig. 39 and Ref. [235].</p>
        <p>Melting temperatures for P-wave quarkonium states estimated from the spectral functions of Fig. 39 and Ref. [235]. the vacuum binding energy. The more weakly bound states start to broaden first, while the more deeply bound vacuum states remain as narrow structures up to high temperatures. In this dynamical sense quarkonium melting is a sequential process.Melting temperatures for P-wave quarkonium states estimated from the spectral functions of Fig. 39 and Ref. [235]. the vacuum binding energy. The more weakly bound states start to broaden first, while the more deeply bound vacuum states remain as narrow structures up to high temperatures. In this dynamical sense quarkonium melting is a sequential process.</p>
        <p>The fact that the in-medium peaks are broadened and smoothly go over into the continuum structure at high temperatures also tells us that the concept of melting temperature in this dynamical picture is not uniquely defined. For historic reasons one may still wish to single out where melting happens, selecting a single temperature at which individual quarkonium states are already highly susceptible to transitions due to kicks from the medium. To this end it has been suggested in e.g. Ref. [15] to choose a T melt , where the in-medium binding energy is equal to the thermal width. This represents a situation where the correlations between a meson state identified at time t 0 have diminished by a factor 1/e after having evolved by a time ∼1/E med bind . For the latest estimates based on this criterion and the spectral functions computed in Ref. [235] see Tables 5 and6. These values may be compared to estimates for the Upsilon melting temperature from a purely weak-coupling treatment presented in Ref. [309], which lead to the same value of T melt = 440 MeV.The fact that the in-medium peaks are broadened and smoothly go over into the continuum structure at high temperatures also tells us that the concept of melting temperature in this dynamical picture is not uniquely defined. For historic reasons one may still wish to single out where melting happens, selecting a single temperature at which individual quarkonium states are already highly susceptible to transitions due to kicks from the medium. To this end it has been suggested in e.g. Ref. [15] to choose a T melt , where the in-medium binding energy is equal to the thermal width. This represents a situation where the correlations between a meson state identified at time t 0 have diminished by a factor 1/e after having evolved by a time ∼1/E med bind . For the latest estimates based on this criterion and the spectral functions computed in Ref. [235] see Tables 5 and6. These values may be compared to estimates for the Upsilon melting temperature from a purely weak-coupling treatment presented in Ref. [309], which lead to the same value of T melt = 440 MeV.</p>
        <p>It is important to note that as of yet only studies based on an in-medium potential are able to provide melting temperatures defined in this quantitative manner, as it requires knowledge of the onset of the continuum structure. In other words, melting temperatures quoted in studies based on lattice NRQCD and relativistic lattice QCD may take on different values, as they are based solely on a visual inspection of the disappearance of discernible peak structures.It is important to note that as of yet only studies based on an in-medium potential are able to provide melting temperatures defined in this quantitative manner, as it requires knowledge of the onset of the continuum structure. In other words, melting temperatures quoted in studies based on lattice NRQCD and relativistic lattice QCD may take on different values, as they are based solely on a visual inspection of the disappearance of discernible peak structures.</p>
        <p>One of the main reasons underlying the interest in melting temperatures was related to phenomenological modeling. In e.g. rate equation based approaches to heavy quarkonium in heavy ion collisions, melting temperatures provided a convenient way to incorporate non-perturbative information from QCD. In an era, where reliable access to the full spectral function is available and where genuine real-time descriptions of quarkonium are developed that directly interface with EFTs and lattice QCD, as discussed in Section 4, the concept of melting temperature thus has become less and less relevant.One of the main reasons underlying the interest in melting temperatures was related to phenomenological modeling. In e.g. rate equation based approaches to heavy quarkonium in heavy ion collisions, melting temperatures provided a convenient way to incorporate non-perturbative information from QCD. In an era, where reliable access to the full spectral function is available and where genuine real-time descriptions of quarkonium are developed that directly interface with EFTs and lattice QCD, as discussed in Section 4, the concept of melting temperature thus has become less and less relevant.</p>
        <p>The interplay of scattering and screening also complicates stability estimates, which had been common in the era of real-valued potential models. The inverse of the Debye mass of the QCD medium still represents the characteristic length scale beyond which color sources do not communicate with each other. I.e. if the spatial extent of the quark-antiquark pair becomes similar to this distance, it can be considered fully decorrelated. At the same time the kicks of the medium partons already at closer separation distances may have induced a transition to an unbound configuration. Stability arguments based on the Debye mass alone are thus understood to provide only upper limits. In Section 4 we will show in more detail how the effect of in-medium kicks can be understood in terms of decoherence of the quarkonium system.The interplay of scattering and screening also complicates stability estimates, which had been common in the era of real-valued potential models. The inverse of the Debye mass of the QCD medium still represents the characteristic length scale beyond which color sources do not communicate with each other. I.e. if the spatial extent of the quark-antiquark pair becomes similar to this distance, it can be considered fully decorrelated. At the same time the kicks of the medium partons already at closer separation distances may have induced a transition to an unbound configuration. Stability arguments based on the Debye mass alone are thus understood to provide only upper limits. In Section 4 we will show in more detail how the effect of in-medium kicks can be understood in terms of decoherence of the quarkonium system.</p>
        <p>The appearance of the thermal width in the quarkonium spectral function is a clear indication that we are dealing with a truly dynamical problem even in thermal equilibrium. While access to spectral functions has helped to shed light on the overall stability of kinetically equilibrated quarkonium, it does not yet allow us to answer even the simple straight forward questions of what happens to a vacuum quarkonium state as it is thrown into a thermal QCD bath. A comprehensive understanding of quarkonium stability and quarkonium melting thus requires a genuine real-time description, which will be the focus of the next section.The appearance of the thermal width in the quarkonium spectral function is a clear indication that we are dealing with a truly dynamical problem even in thermal equilibrium. While access to spectral functions has helped to shed light on the overall stability of kinetically equilibrated quarkonium, it does not yet allow us to answer even the simple straight forward questions of what happens to a vacuum quarkonium state as it is thrown into a thermal QCD bath. A comprehensive understanding of quarkonium stability and quarkonium melting thus requires a genuine real-time description, which will be the focus of the next section.</p>
        <p>The study of meson spectral functions and the in-medium heavy quark potential has revealed the dynamical nature of in-medium quarkonium, even in an idealized setting such as in thermal equilibrium. The first task at hand thus is to develop a description that is capable of shedding light on how individual quarkonium states evolve in real-time in the presence of a QCD medium. This will allow us to form a more detailed picture of dynamical quarkonium melting. The second step will be to use such a framework to support the interpretation of heavy quarkonium measurements in a heavy-ion collision.The study of meson spectral functions and the in-medium heavy quark potential has revealed the dynamical nature of in-medium quarkonium, even in an idealized setting such as in thermal equilibrium. The first task at hand thus is to develop a description that is capable of shedding light on how individual quarkonium states evolve in real-time in the presence of a QCD medium. This will allow us to form a more detailed picture of dynamical quarkonium melting. The second step will be to use such a framework to support the interpretation of heavy quarkonium measurements in a heavy-ion collision.</p>
        <p>Phenomenological modeling of heavy quarkonium real-time dynamics has a long history. For charmonium the method of choice is to consider Boltzmann type transport equations from which, under additional time scale separation assumptions, coupled rate equations for the different quarkonium states are obtained (see Refs. [199,[310][311][312][313] and Refs. [314][315][316], for application to bottomonium see e.g. Ref. [317]). In this approach the dissociation of quarkonium and recombination of individual quarks is both included. Arguments based on detailed balance, potential model computations for quarkonium binding and perturbative insight on dissociation provide the input values for the strength of each term. A step towards a more systematic treatment of the individual contributions was taken in Refs. [318,319] and Ref. [202], where screening, dissociation and recombination contributions have been elucidated based on the effective field theory pNRQCD.Phenomenological modeling of heavy quarkonium real-time dynamics has a long history. For charmonium the method of choice is to consider Boltzmann type transport equations from which, under additional time scale separation assumptions, coupled rate equations for the different quarkonium states are obtained (see Refs. [199,[310][311][312][313] and Refs. [314][315][316], for application to bottomonium see e.g. Ref. [317]). In this approach the dissociation of quarkonium and recombination of individual quarks is both included. Arguments based on detailed balance, potential model computations for quarkonium binding and perturbative insight on dissociation provide the input values for the strength of each term. A step towards a more systematic treatment of the individual contributions was taken in Refs. [318,319] and Ref. [202], where screening, dissociation and recombination contributions have been elucidated based on the effective field theory pNRQCD.</p>
        <p>For Bottomonium, where an in-medium potential picture is expected to provide an accurate description, the most common approach to date is to solve some form of Schrödinger equation. Either one considers a deterministic linear equation to which a complex model potential is supplied (see e.g. Refs. [230,[320][321][322]) or one implements the dynamics via a non-linear stochastic Schrödinger equation as in Ref. [323].For Bottomonium, where an in-medium potential picture is expected to provide an accurate description, the most common approach to date is to solve some form of Schrödinger equation. Either one considers a deterministic linear equation to which a complex model potential is supplied (see e.g. Refs. [230,[320][321][322]) or one implements the dynamics via a non-linear stochastic Schrödinger equation as in Ref. [323].</p>
        <p>For both charmonium and bottomonium the above strategies have been successfully applied to reproduce the experimental measurements of quarkonium states in heavy-ion collisions.For both charmonium and bottomonium the above strategies have been successfully applied to reproduce the experimental measurements of quarkonium states in heavy-ion collisions.</p>
        <p>Developing a genuine first principles based understanding of quarkonium real-time evolution thus serves multiple roles. On the one hand it will lead to an intrinsically better understanding of quarkonium stability in idealized situations, such as in thermal equilibrium, but it will also reduce the amount of modeling input necessary when describing quarkonium in complex scenarios such as a heavy-ion collision.Developing a genuine first principles based understanding of quarkonium real-time evolution thus serves multiple roles. On the one hand it will lead to an intrinsically better understanding of quarkonium stability in idealized situations, such as in thermal equilibrium, but it will also reduce the amount of modeling input necessary when describing quarkonium in complex scenarios such as a heavy-ion collision.</p>
        <p>A genuine real-time description of quarkonium forces us to amend the theoretical guiding principle based on separation of energy scales by taking into account the different time scales present in the system under consideration. As discussed in Section 2.5 the open quantum systems approach offers a promising road towards a systematic treatment of heavy quarkonium in this respect. In thermal equilibrium a non-perturbative understanding of various aspects of heavy quarkonium has been achieved, by connecting first principles lattice QCD and effective field theories. However an equally non-perturbative implementation of the real-time dynamics is not available yet. Since the sign problem prevents direct real-time simulations on the lattice, one central focus of theory today lies in establishing how to non-perturbatively match effective field theories, such as pNRQCD to QCD. This in turn may then be used as a starting point to derive quarkonium real-time evolution equations formulated in the language of open quantum systems. More concretely, it needs to be established whether and, if so, how a master equation for the Q Q density matrix can be derived which systematically incorporates the information on the proper real-time heavy-quark potential, as well as the other non-local Wilson coefficients of pNRQCD.A genuine real-time description of quarkonium forces us to amend the theoretical guiding principle based on separation of energy scales by taking into account the different time scales present in the system under consideration. As discussed in Section 2.5 the open quantum systems approach offers a promising road towards a systematic treatment of heavy quarkonium in this respect. In thermal equilibrium a non-perturbative understanding of various aspects of heavy quarkonium has been achieved, by connecting first principles lattice QCD and effective field theories. However an equally non-perturbative implementation of the real-time dynamics is not available yet. Since the sign problem prevents direct real-time simulations on the lattice, one central focus of theory today lies in establishing how to non-perturbatively match effective field theories, such as pNRQCD to QCD. This in turn may then be used as a starting point to derive quarkonium real-time evolution equations formulated in the language of open quantum systems. More concretely, it needs to be established whether and, if so, how a master equation for the Q Q density matrix can be derived which systematically incorporates the information on the proper real-time heavy-quark potential, as well as the other non-local Wilson coefficients of pNRQCD.</p>
        <p>The past five years have already seen major progress in the context of an open quantum systems description of heavy quarkonium. Indeed it is now possible to derive from QCD, using a well controlled set of approximations, a non-linear stochastic Schrödinger equation describing the quantum dissipative evolution of the quark-antiquark pair in a hot thermal medium (see Fig. 42). This for the first time provides a field theoretical basis to phenomenological models of this type. It is further understood how computations based on deterministic Schrödinger equations can be systematically improved to become more accurate. At the same time first proposals have been put forward to derive the Boltzmann equation in a weakly coupled medium directly from QCD via the open quantum systems approach, not only providing insight on the range of validity of transport approaches for quarkonium but opening up new venues for eventually deriving a fully non-perturbative equation of motion for quarkonium distribution functions.The past five years have already seen major progress in the context of an open quantum systems description of heavy quarkonium. Indeed it is now possible to derive from QCD, using a well controlled set of approximations, a non-linear stochastic Schrödinger equation describing the quantum dissipative evolution of the quark-antiquark pair in a hot thermal medium (see Fig. 42). This for the first time provides a field theoretical basis to phenomenological models of this type. It is further understood how computations based on deterministic Schrödinger equations can be systematically improved to become more accurate. At the same time first proposals have been put forward to derive the Boltzmann equation in a weakly coupled medium directly from QCD via the open quantum systems approach, not only providing insight on the range of validity of transport approaches for quarkonium but opening up new venues for eventually deriving a fully non-perturbative equation of motion for quarkonium distribution functions.</p>
        <p>In the following we briefly survey the current activities in the field from which we will highlight two types of studies that both make close contact to the effective field theory concepts encountered previously in equilibrium and offer concrete paths to the improvement of current phenomenological real-time approaches to in-medium quarkonium.In the following we briefly survey the current activities in the field from which we will highlight two types of studies that both make close contact to the effective field theory concepts encountered previously in equilibrium and offer concrete paths to the improvement of current phenomenological real-time approaches to in-medium quarkonium.</p>
        <p>The first steps in the direction of an open quantum systems based understanding of in-medium quarkonium were inspired by the Caldeira-Leggett model in Ref. [325], but did not yet attempt to derive a real-time description. Subsequently Refs. [326,327] explored the role played by transitions induced between different quarkonium states by the medium and suggested that an open quantum systems approach (called a quantum dissipative system in their paper) would be most appropriate to capture the relevant physics. Independently Ref. [328] proposed the first open quantum systems description to real-time heavy quarkonium that made direct connection with the complex real-time potential. It suggested an interpretation of the imaginary part of the in-medium potential in terms of decoherence induced by the medium kicks on the quarkonium particle. The paper proposed that the values of Im[V ] manifest themselves in the local correlations of a real valued noise term added to an otherwise real-valued potential, in turn leading to a unitary stochastic time evolution. This early stochastic potential approach has been subsequently used to take a first look at bottomonium evolution as open quantum system in Ref. [329].The first steps in the direction of an open quantum systems based understanding of in-medium quarkonium were inspired by the Caldeira-Leggett model in Ref. [325], but did not yet attempt to derive a real-time description. Subsequently Refs. [326,327] explored the role played by transitions induced between different quarkonium states by the medium and suggested that an open quantum systems approach (called a quantum dissipative system in their paper) would be most appropriate to capture the relevant physics. Independently Ref. [328] proposed the first open quantum systems description to real-time heavy quarkonium that made direct connection with the complex real-time potential. It suggested an interpretation of the imaginary part of the in-medium potential in terms of decoherence induced by the medium kicks on the quarkonium particle. The paper proposed that the values of Im[V ] manifest themselves in the local correlations of a real valued noise term added to an otherwise real-valued potential, in turn leading to a unitary stochastic time evolution. This early stochastic potential approach has been subsequently used to take a first look at bottomonium evolution as open quantum system in Ref. [329].</p>
        <p>The next decisive step was achieved by Akamatsu in Ref. [330] in deriving a master equation for quarkonium at high temperatures directly from the QCD path integral via the Feynman-Vernon influence functional. In turn he showed that, based on single gluon exchange, the dynamics in the recoilless limit can be reduced to a stochastic potential, corresponding to the first order in a systematic gradient expansion of the equation of motion. It also clarified how the non-local correlations of the stochastic noise are related to the imaginary part of the potential. Note that this colored stochastic potential does not simply reduce to the color singlet version introduced in Ref. [328], since singlet to singlet transitions are only possible via multi-gluon exchanges.The next decisive step was achieved by Akamatsu in Ref. [330] in deriving a master equation for quarkonium at high temperatures directly from the QCD path integral via the Feynman-Vernon influence functional. In turn he showed that, based on single gluon exchange, the dynamics in the recoilless limit can be reduced to a stochastic potential, corresponding to the first order in a systematic gradient expansion of the equation of motion. It also clarified how the non-local correlations of the stochastic noise are related to the imaginary part of the potential. Note that this colored stochastic potential does not simply reduce to the color singlet version introduced in Ref. [328], since singlet to singlet transitions are only possible via multi-gluon exchanges.</p>
        <p>A refined analysis, with a particular focus on the implementation of time coarse graining presented in Ref. [331] then delivered for the first time a genuine Lindblad master equation for quarkonium at high temperatures. Having established that the in-medium real-time evolution of quarkonium can be captured in the well established open quantum systems framework using a clearly defined set of approximations, the community took notice and concerted efforts arose to explore the dynamical aspects of in-medium quarkonium.A refined analysis, with a particular focus on the implementation of time coarse graining presented in Ref. [331] then delivered for the first time a genuine Lindblad master equation for quarkonium at high temperatures. Having established that the in-medium real-time evolution of quarkonium can be captured in the well established open quantum systems framework using a clearly defined set of approximations, the community took notice and concerted efforts arose to explore the dynamical aspects of in-medium quarkonium.</p>
        <p>Recently several research groups are actively exploring the open quantum systems approach to heavy quarkonium. Two of these (see Refs. [286,287,332] and Ref. [333]) take as starting point directly the effective field theory pNRQCD. The benefit of this approach is that the effective field theory is systematically derived from QCD based on matching with the intermediate effective theory NRQCD. On the other hand a drawback for phenomenology is that pNRQCD is derived for a certain scale hierarchy. Often this hierarchy is taken to apply to the S-wave ground state but excited states and P-wave states may not adhere to the same hierarchy, thus complicating a concurrent treatment of all the states present in a heavy-ion collision. A central difference between the two sets of studies is that in the former the medium degrees are treated as strongly coupled m D ∼ T and the information on the in-medium dynamics is formulated in terms of nonperturbative transport-coefficients, possibly accessible on the lattice [287]. In the latter, pNRQCD is matched to NRQCD perturbatively, which in turn is argued to allow a simplification of the equations of motions up to the point where the perturbative Boltzmann equation is obtained. Such a systematic derivation of the Boltzmann equation from QCD is an important contribution to putting phenomenological modeling on a solid footing, by exposing the underlying chain of required approximations.Recently several research groups are actively exploring the open quantum systems approach to heavy quarkonium. Two of these (see Refs. [286,287,332] and Ref. [333]) take as starting point directly the effective field theory pNRQCD. The benefit of this approach is that the effective field theory is systematically derived from QCD based on matching with the intermediate effective theory NRQCD. On the other hand a drawback for phenomenology is that pNRQCD is derived for a certain scale hierarchy. Often this hierarchy is taken to apply to the S-wave ground state but excited states and P-wave states may not adhere to the same hierarchy, thus complicating a concurrent treatment of all the states present in a heavy-ion collision. A central difference between the two sets of studies is that in the former the medium degrees are treated as strongly coupled m D ∼ T and the information on the in-medium dynamics is formulated in terms of nonperturbative transport-coefficients, possibly accessible on the lattice [287]. In the latter, pNRQCD is matched to NRQCD perturbatively, which in turn is argued to allow a simplification of the equations of motions up to the point where the perturbative Boltzmann equation is obtained. Such a systematic derivation of the Boltzmann equation from QCD is an important contribution to putting phenomenological modeling on a solid footing, by exposing the underlying chain of required approximations.</p>
        <p>Other groups approach the derivation of the quarkonium real-time evolution from a weakly coupled perspective without direct reference to pNRQCD. A central aspect of the works of Refs. [334,335] is to explore the effects of dynamical dissociation and recombination in a semi-classical language, reducing the master equation further to an effective Langevin form. The first paper considers the effects common to Abelian and non-Abelian plasmas, while the second focuses on the additional effects played by the color degrees of freedom present in QCD. Ref. [336] also investigated the classicalization of the heavy quark dynamics. While the dynamics of quarkonium can become classical if decoherence acts efficiently, it needs to be ascertained in each case whether remnant quantum superpositions among quarkonium state can be neglected on the timescales under consideration. The authors of Ref. [337] have taken first steps beyond the Markovian approximation in this context, which may e.g. be relevant for the description of quarkonium at intermediate temperatures.Other groups approach the derivation of the quarkonium real-time evolution from a weakly coupled perspective without direct reference to pNRQCD. A central aspect of the works of Refs. [334,335] is to explore the effects of dynamical dissociation and recombination in a semi-classical language, reducing the master equation further to an effective Langevin form. The first paper considers the effects common to Abelian and non-Abelian plasmas, while the second focuses on the additional effects played by the color degrees of freedom present in QCD. Ref. [336] also investigated the classicalization of the heavy quark dynamics. While the dynamics of quarkonium can become classical if decoherence acts efficiently, it needs to be ascertained in each case whether remnant quantum superpositions among quarkonium state can be neglected on the timescales under consideration. The authors of Ref. [337] have taken first steps beyond the Markovian approximation in this context, which may e.g. be relevant for the description of quarkonium at intermediate temperatures.</p>
        <p>Ref. [324] attempted an alternative derivation of the e.o.m. at high temperature, but since no explicit Lindblad operators could be constructed, doubts remain whether this study has produced a genuine Lindblad master equation. A thorough reinvestigation of the stochastic potential approximation to the full dynamics has been presented in Ref. [338] focusing on the role of decoherence played on the stability of quarkonium. Fig. 42 attempts to summarize the currently available open quantum systems based approached to quarkonium.Ref. [324] attempted an alternative derivation of the e.o.m. at high temperature, but since no explicit Lindblad operators could be constructed, doubts remain whether this study has produced a genuine Lindblad master equation. A thorough reinvestigation of the stochastic potential approximation to the full dynamics has been presented in Ref. [338] focusing on the role of decoherence played on the stability of quarkonium. Fig. 42 attempts to summarize the currently available open quantum systems based approached to quarkonium.</p>
        <p>In Section 2.5 we considered two iconic models of open quantum systems, the quantum optical master equation, as well as quantum Brownian motion at high temperature. While the latter model appears at first to be well suited to the description of heavy quarkonium it needs to be kept in mind that its evolution equation was derived for a single particle, i.e. for a system whose extent is smaller than the correlation length of the medium. This is in general not the case for heavy quarkonium, where depending on the interplay of temperature and binding energy the extent of the in-medium state may easily be of the same order or larger than the medium correlation length.In Section 2.5 we considered two iconic models of open quantum systems, the quantum optical master equation, as well as quantum Brownian motion at high temperature. While the latter model appears at first to be well suited to the description of heavy quarkonium it needs to be kept in mind that its evolution equation was derived for a single particle, i.e. for a system whose extent is smaller than the correlation length of the medium. This is in general not the case for heavy quarkonium, where depending on the interplay of temperature and binding energy the extent of the in-medium state may easily be of the same order or larger than the medium correlation length.</p>
        <p>In Ref. [331] a Lindblad master equation for in-medium quarkonium has been derived based on the Feynman-Vernon influence functional. It rests on three sets of approximations, which have been justified apriori using the scales present in Coulombically bound quarkonium states. The first refers to the non-relativistic limit, requiring that bothIn Ref. [331] a Lindblad master equation for in-medium quarkonium has been derived based on the Feynman-Vernon influence functional. It rests on three sets of approximations, which have been justified apriori using the scales present in Coulombically bound quarkonium states. The first refers to the non-relativistic limit, requiring that both</p>
        <p>T /m Q ≪ 1 as well as α S ≪ 1. The second requires the medium to be weakly coupled so that g ≪ 1 and the third is related to how the coarse graining in time is implemented, assuming 1/gT ≪ 1/Mα 2 . This last relation is nothing but the condition τ E ≪ τ S also used in the quantum Brownian motion master equation. If fulfilled it tells us that the acceleration of the heavy quarks, i.e. the change in the relative velocity v induced by the individual interactions with the medium is small.T /m Q ≪ 1 as well as α S ≪ 1. The second requires the medium to be weakly coupled so that g ≪ 1 and the third is related to how the coarse graining in time is implemented, assuming 1/gT ≪ 1/Mα 2 . This last relation is nothing but the condition τ E ≪ τ S also used in the quantum Brownian motion master equation. If fulfilled it tells us that the acceleration of the heavy quarks, i.e. the change in the relative velocity v induced by the individual interactions with the medium is small.</p>
        <p>Starting from the Schwinger-Keldysh path integral for the system of gauge fields A, light fermions q and heavy quarks Q , summarized as φ = (A, q, Q ) with φ 1 on the forward branch and φ 2 on the backward branch, one may write down the generating functional with external source terms η 1 and η 2 asStarting from the Schwinger-Keldysh path integral for the system of gauge fields A, light fermions q and heavy quarks Q , summarized as φ = (A, q, Q ) with φ 1 on the forward branch and φ 2 on the backward branch, one may write down the generating functional with external source terms η 1 and η 2 as</p>
        <p>Assuming the factorization of the initial density matrix, defining the heavy quark color current j aµ = Q T a γ µ Q and setting the external sources to zero one arrives at the partition functionAssuming the factorization of the initial density matrix, defining the heavy quark color current j aµ = Q T a γ µ Q and setting the external sources to zero one arrives at the partition function</p>
        <p>where the all terms that couple the heavy fields with the gauge fields are contained withinwhere the all terms that couple the heavy fields with the gauge fields are contained within</p>
        <p>× ∫ A 2 (0),q 2 (0)× ∫ A 2 (0),q 2 (0)</p>
        <p>Note that the medium is assumed to be in thermal equilibrium at this point and that the currents j 1 and j 2 are not external currents but represent the heavy color sources to which the gauge field couples dynamically. By performing the non-relativistic approximation first, the coupling between the heavy quarks and the gauge fields is simplified to only include the heavy quark color density, i.e. an interaction term of the form gj a0 A a 0 . The subsequent perturbative expansion of Eq. ( 223) to second order in the strong coupling allows one to relate the interactions between quarkonium and the medium in terms of the different gluon propagators G defined on the Schwinger-Keldysh contourNote that the medium is assumed to be in thermal equilibrium at this point and that the currents j 1 and j 2 are not external currents but represent the heavy color sources to which the gauge field couples dynamically. By performing the non-relativistic approximation first, the coupling between the heavy quarks and the gauge fields is simplified to only include the heavy quark color density, i.e. an interaction term of the form gj a0 A a 0 . The subsequent perturbative expansion of Eq. ( 223) to second order in the strong coupling allows one to relate the interactions between quarkonium and the medium in terms of the different gluon propagators G defined on the Schwinger-Keldysh contour</p>
        <p>[ G ab,00 (xy) -G &lt; ab,00 (xy) -G &gt; ab,00 (xy) Gab,00 (xy) ] ([ G ab,00 (xy) -G &lt; ab,00 (xy) -G &gt; ab,00 (xy) Gab,00 (xy) ] (</p>
        <p>))</p>
        <p>+ O(g 3 ).+ O(g 3 ).</p>
        <p>((</p>
        <p>One of the important contributions of Ref. [331] is to identify that with a particular choice of time variables, i.e. t = max(x 0 , y 0 ) in addition to the relative time s = |x 0 -y 0 |, coarse graining of the influence functional in time leads to interaction terms that only contain the retarded correlator G R and the related gluon spectral function denoted here by ρ G .One of the important contributions of Ref. [331] is to identify that with a particular choice of time variables, i.e. t = max(x 0 , y 0 ) in addition to the relative time s = |x 0 -y 0 |, coarse graining of the influence functional in time leads to interaction terms that only contain the retarded correlator G R and the related gluon spectral function denoted here by ρ G .</p>
        <p>In particular this means that all in-medium information is contained in three quantitiesIn particular this means that all in-medium information is contained in three quantities</p>
        <p>The first one, related to the Fourier transform of the retarded gluon correlator at vanishing frequencies, is nothing but the real-part of the proper real-time potential evaluated perturbatively. The second and third one is related to the gluon spectral function, which in the perturbative language is given by the appropriately shifted imaginary part of the real-time potential, i.e. D(r) = Im[V ](r)-Im[V ](r = ∞). Combining the weak coupling expansion and time coarse graining together with the Markovian approximation the influence functional may be rewritten asThe first one, related to the Fourier transform of the retarded gluon correlator at vanishing frequencies, is nothing but the real-part of the proper real-time potential evaluated perturbatively. The second and third one is related to the gluon spectral function, which in the perturbative language is given by the appropriately shifted imaginary part of the real-time potential, i.e. D(r) = Im[V ](r)-Im[V ](r = ∞). Combining the weak coupling expansion and time coarse graining together with the Markovian approximation the influence functional may be rewritten as</p>
        <p>In order to make the coupling between gluons and heavy quarks local, one must neglect possible overlap of interactions, similar to taking the ladder approximation in the Bethe-Salpeter equation. The individual terms have been suggestively named from an analogy with the quantum Brownian motion case. S fluct encodes the effects of fluctuations, where e.g. kicks of the medium particles transfer energy into the quarkonium system. S diss [D] on the other hand describes the physics of dissipation, by which the quarkonium state may release energy back to the medium. The combination of the two makes it possible for the quarkonium system to eventually thermalize with its environment. Only thanks to the additional term S L [A], a genuine Lindblad master equation emerges, that preserves all relevant properties of the density matrix under time evolution. Note that here in contrast to the Caldeira-Leggett model this last term is not added by hand but arises due to a careful choice of the coarse graining procedure.In order to make the coupling between gluons and heavy quarks local, one must neglect possible overlap of interactions, similar to taking the ladder approximation in the Bethe-Salpeter equation. The individual terms have been suggestively named from an analogy with the quantum Brownian motion case. S fluct encodes the effects of fluctuations, where e.g. kicks of the medium particles transfer energy into the quarkonium system. S diss [D] on the other hand describes the physics of dissipation, by which the quarkonium state may release energy back to the medium. The combination of the two makes it possible for the quarkonium system to eventually thermalize with its environment. Only thanks to the additional term S L [A], a genuine Lindblad master equation emerges, that preserves all relevant properties of the density matrix under time evolution. Note that here in contrast to the Caldeira-Leggett model this last term is not added by hand but arises due to a careful choice of the coarse graining procedure.</p>
        <p>At this point the influence functional is formulated in terms of actions and heavy quark fields, while we are ultimately interested in an evolution equation for the density matrix operator for the two-body system in the position basis. To this end the strategy put forward in Ref. [331] is based on using the properties of coherent states as generating functionals for heavy quarkonium particles. Using the same notation for the quark and antiquark field operators as in NRQCD, i.e. ψ and χ, the matrix elements of the reduced density matrix in the coherent state basis can be written asAt this point the influence functional is formulated in terms of actions and heavy quark fields, while we are ultimately interested in an evolution equation for the density matrix operator for the two-body system in the position basis. To this end the strategy put forward in Ref. [331] is based on using the properties of coherent states as generating functionals for heavy quarkonium particles. Using the same notation for the quark and antiquark field operators as in NRQCD, i.e. ψ and χ, the matrix elements of the reduced density matrix in the coherent state basis can be written as</p>
        <p>)] ,)] ,</p>
        <p>where the sources J i are just complex numbers. Using the path integral representation of σwhere the sources J i are just complex numbers. Using the path integral representation of σ</p>
        <p>the position space basis density matrix can be obtained via functional differentiationthe position space basis density matrix can be obtained via functional differentiation</p>
        <p>Collecting all the terms obtained in the evolution equation for the position basis density matrix, these can be summarized as a Lindblad equation with two distinct Lindblad operators. Using the constituent heavy quark positionCollecting all the terms obtained in the evolution equation for the position basis density matrix, these can be summarized as a Lindblad equation with two distinct Lindblad operators. Using the constituent heavy quark position</p>
        <p>x and momentum operator p, as well as the antiquark operators ŷ and q, the Lindblad operators and their coefficients take the formx and momentum operator p, as well as the antiquark operators ŷ and q, the Lindblad operators and their coefficients take the form</p>
        <p>k,a = e ikx/2k,a = e ikx/2</p>
        <p>L2 k,a = e ikx/2L2 k,a = e ikx/2</p>
        <p>where V = L 3 refers to a large but finite volume of the combined system of heavy quarks and medium. In addition to the Lindblad operators, a non-trivial Hamiltonian for the reduced quarkonium system is obtainedwhere V = L 3 refers to a large but finite volume of the combined system of heavy quarks and medium. In addition to the Lindblad operators, a non-trivial Hamiltonian for the reduced quarkonium system is obtained</p>
        <p>Several remarks are in order. Similar to assigning physical roles to the individual terms in S FV we can identify the corresponding contributions in the Lindblad operators. The physics of fluctuations is encoded in the terms independent of the heavy quark momentum, while the effects of dissipation reside in those that carry an explicit p or q dependence. Interestingly this tells us that the center of mass motion and relative motion both influence dissipation. It turns out that in case that dissipative effects are non-negligible, the physics of relative and finite center of mass momenta cannot be fully separated. Note that the coefficients of the Lindblad operators depend on the gluon spectral function and thus on the imaginary part of the potential. They are both positive, as required for the Lindblad formalism to be valid. In case of γ 2 this is only possible due to the contributions of the A term arising from S L in the expansion of the influence functional. In practice it is often assumed that the term 8T 2 A-D is small so that only L 1 remains active. It is important to recognize that the Hamiltonian features both the familiar term containing the screened potential V but also harbors another contribution which arises from the fluctuation part and which may not be neglected a priori. It is interesting to contemplate how and under which circumstances such an additional term can be related to the concept of entropic force (discussed in detail in Refs. [229,339]) which too is understood as an emergent phenomenon induced by medium fluctuations.Several remarks are in order. Similar to assigning physical roles to the individual terms in S FV we can identify the corresponding contributions in the Lindblad operators. The physics of fluctuations is encoded in the terms independent of the heavy quark momentum, while the effects of dissipation reside in those that carry an explicit p or q dependence. Interestingly this tells us that the center of mass motion and relative motion both influence dissipation. It turns out that in case that dissipative effects are non-negligible, the physics of relative and finite center of mass momenta cannot be fully separated. Note that the coefficients of the Lindblad operators depend on the gluon spectral function and thus on the imaginary part of the potential. They are both positive, as required for the Lindblad formalism to be valid. In case of γ 2 this is only possible due to the contributions of the A term arising from S L in the expansion of the influence functional. In practice it is often assumed that the term 8T 2 A-D is small so that only L 1 remains active. It is important to recognize that the Hamiltonian features both the familiar term containing the screened potential V but also harbors another contribution which arises from the fluctuation part and which may not be neglected a priori. It is interesting to contemplate how and under which circumstances such an additional term can be related to the concept of entropic force (discussed in detail in Refs. [229,339]) which too is understood as an emergent phenomenon induced by medium fluctuations.</p>
        <p>With the derivation of the Lindblad operators and the Hamiltonian for a system at high temperature, it is now possible to state, how the real-and imaginary part of the in-medium potential govern the microscopic evolution of the quarkonium state. The latter encodes the physics of fluctuations and dissipation and, together with the real part, determines the stability of the quarkonium state. Establishing these roles in a genuine non-perturbative fashion however remains a central open research question.With the derivation of the Lindblad operators and the Hamiltonian for a system at high temperature, it is now possible to state, how the real-and imaginary part of the in-medium potential govern the microscopic evolution of the quarkonium state. The latter encodes the physics of fluctuations and dissipation and, together with the real part, determines the stability of the quarkonium state. Establishing these roles in a genuine non-perturbative fashion however remains a central open research question.</p>
        <p>Note that the Lindblad equation explicitly takes into account the physics of both constituent quark and antiquark. This in turn means that the corresponding density matrix not only contains information about possible color singlet bound states but also captures the physics of (possibly decorrelated) individual color charged quarks. In other words it possesses the necessary knowledge to not only answer questions about dynamical melting of quarkonium but also to eventually answer how probable the recombination of individual quarks and antiquarks is. (As has been explicitly pointed out in the related works of Refs. [335,337] the recombination probability actually becomes zero in an infinite volume, but since the fireball of a heavy-ion collision is finite, also the probabilities are.)Note that the Lindblad equation explicitly takes into account the physics of both constituent quark and antiquark. This in turn means that the corresponding density matrix not only contains information about possible color singlet bound states but also captures the physics of (possibly decorrelated) individual color charged quarks. In other words it possesses the necessary knowledge to not only answer questions about dynamical melting of quarkonium but also to eventually answer how probable the recombination of individual quarks and antiquarks is. (As has been explicitly pointed out in the related works of Refs. [335,337] the recombination probability actually becomes zero in an infinite volume, but since the fireball of a heavy-ion collision is finite, also the probabilities are.)</p>
        <p>Solving the equation of motion defined by Eqs. ( 234) and ( 235) head on is still too costly. There are however efforts underway to derive a reduced equation of motion [340] focusing on the relative coordinates (see also Ref. [324]). Preliminary findings suggest that as anticipated above, relative and center of mass momentum cannot be fully decoupled in the dissipative terms, the latter however appears simply as an external parameter. Even such a reduced density matrix carries a dependence on six spatial dimensions, i.e. the direct simulation of the corresponding partial differential equation is very demanding. On the other hand the quantum state diffusion approach discussed in Section 2.5 has already been successfully implemented for the description of the Lindblad equation of single heavy quarks in Ref. [341] and promises a viable path towards unraveling the evolution of the quarkonium density matrix in terms of an ensemble of wavefunctions. Including both fluctuation and dissipation effects, such a simulation in principle will be able to implement genuine thermalization of a heavy quarkonium state with its surrounding. Conceptually the QSD approach for the first time provides a QCD derived non-linear stochastic Schrödinger equation for in-medium quarkonium, which so far has only been introduced based on phenomenological modeling.Solving the equation of motion defined by Eqs. ( 234) and ( 235) head on is still too costly. There are however efforts underway to derive a reduced equation of motion [340] focusing on the relative coordinates (see also Ref. [324]). Preliminary findings suggest that as anticipated above, relative and center of mass momentum cannot be fully decoupled in the dissipative terms, the latter however appears simply as an external parameter. Even such a reduced density matrix carries a dependence on six spatial dimensions, i.e. the direct simulation of the corresponding partial differential equation is very demanding. On the other hand the quantum state diffusion approach discussed in Section 2.5 has already been successfully implemented for the description of the Lindblad equation of single heavy quarks in Ref. [341] and promises a viable path towards unraveling the evolution of the quarkonium density matrix in terms of an ensemble of wavefunctions. Including both fluctuation and dissipation effects, such a simulation in principle will be able to implement genuine thermalization of a heavy quarkonium state with its surrounding. Conceptually the QSD approach for the first time provides a QCD derived non-linear stochastic Schrödinger equation for in-medium quarkonium, which so far has only been introduced based on phenomenological modeling.</p>
        <p>Since the thermalization of quarkonium states can be captured with the Lindblad equation based on Eqs. ( 234) and (235), the resulting late time behavior will provide a direct connection to the equilibrium results discussed in Section 3.3. These may then e.g. function as a benchmark of the real-time evolution.Since the thermalization of quarkonium states can be captured with the Lindblad equation based on Eqs. ( 234) and (235), the resulting late time behavior will provide a direct connection to the equilibrium results discussed in Section 3.3. These may then e.g. function as a benchmark of the real-time evolution.</p>
        <p>After discussing that quarkonium melting is an inherently dynamical process in Section 3.4, we are now able to shed light on some of its details by using the open quantum systems approach. And even though simulations of the full dissipative Lindblad dynamics are still work in progress, we can already consider what has been learned about the in-medium evolution from truncations of Eqs. ( 234) and (235). In particular this has led to insight into the role played by the phenomenon of decoherence on the stability of in-medium quarkonium and its melting.After discussing that quarkonium melting is an inherently dynamical process in Section 3.4, we are now able to shed light on some of its details by using the open quantum systems approach. And even though simulations of the full dissipative Lindblad dynamics are still work in progress, we can already consider what has been learned about the in-medium evolution from truncations of Eqs. ( 234) and (235). In particular this has led to insight into the role played by the phenomenon of decoherence on the stability of in-medium quarkonium and its melting.</p>
        <p>As it allows us to identify already many relevant aspects of quarkonium stability, we start out by considering the recoilless limit, which corresponds to neglecting all dissipative contributions. In turn this amounts to setting S FV = S fluct or simply taking the momentum independent terms of Eq. (234). At this first order in the gradient expansion of the influence functional one can completely integrate out the center of mass coordinates. This leads to a stochastic linear Schrödinger equation coupling the color singlet and octet sector. For the purpose of this section one may consider an even simpler scenario, where only transitions from the color singlet to singlet sector are implemented. This is nothing but the stochastic potential description originally proposed in [328]. Note that while the absence of dissipation will prevent the thermalization of the quarkonium system at late times, this approximation is expected to work well, even quantitatively, for tightly localized states at early times.As it allows us to identify already many relevant aspects of quarkonium stability, we start out by considering the recoilless limit, which corresponds to neglecting all dissipative contributions. In turn this amounts to setting S FV = S fluct or simply taking the momentum independent terms of Eq. (234). At this first order in the gradient expansion of the influence functional one can completely integrate out the center of mass coordinates. This leads to a stochastic linear Schrödinger equation coupling the color singlet and octet sector. For the purpose of this section one may consider an even simpler scenario, where only transitions from the color singlet to singlet sector are implemented. This is nothing but the stochastic potential description originally proposed in [328]. Note that while the absence of dissipation will prevent the thermalization of the quarkonium system at late times, this approximation is expected to work well, even quantitatively, for tightly localized states at early times.</p>
        <p>Let us follow the exposition given in Ref. [338], where one considers a quark located at x = R + r 2 and an antiquark atLet us follow the exposition given in Ref. [338], where one considers a quark located at x = R + r 2 and an antiquark at</p>
        <p>At this level of the approximation, the dynamics can be written in terms of a real-valued in-medium potential V (r) and two noise terms η, whose spatial correlations are intimately connected to the imaginary part of the potentialAt this level of the approximation, the dynamics can be written in terms of a real-valued in-medium potential V (r) and two noise terms η, whose spatial correlations are intimately connected to the imaginary part of the potential</p>
        <p>The origin of the two noise terms lies in the separate fluctuation contributions to the quark and antiquark, similar to the two fluctuation terms present in the high temperature Lindblad equation. These also carry opposite color, which leads to a relative minus sign in the singlet sector. Since the Markovian approximation has been used, the noise is Gaussian but carries non-trivial spatial structure given by ⟨η(x, t)⟩ = 0, ⟨η(x, t)η(xThe origin of the two noise terms lies in the separate fluctuation contributions to the quark and antiquark, similar to the two fluctuation terms present in the high temperature Lindblad equation. These also carry opposite color, which leads to a relative minus sign in the singlet sector. Since the Markovian approximation has been used, the noise is Gaussian but carries non-trivial spatial structure given by ⟨η(x, t)⟩ = 0, ⟨η(x, t)η(x</p>
        <p>keeping in mind that at high temperaturekeeping in mind that at high temperature</p>
        <p>Consistent with Ito calculus, one finds that the noise terms scale with η ∼ dt -1/2 . This requires one to take into account one additional term, absent for deterministic variables, when deriving the wavefunction evolution equation from the time evolution operator. The following stochastic differential equation ensuesConsistent with Ito calculus, one finds that the noise terms scale with η ∼ dt -1/2 . This requires one to take into account one additional term, absent for deterministic variables, when deriving the wavefunction evolution equation from the time evolution operator. The following stochastic differential equation ensues</p>
        <p>Since the time evolution operator U = exp[-i∆tH] is unitary, the above equation of motion also preserves the norm of the evolving microscopic wavefunction. Nevertheless considering the ensemble average of the wavefunction, one obtains the following Schrödinger equationSince the time evolution operator U = exp[-i∆tH] is unitary, the above equation of motion also preserves the norm of the evolving microscopic wavefunction. Nevertheless considering the ensemble average of the wavefunction, one obtains the following Schrödinger equation</p>
        <p>This simple example shows that the presence of an imaginary part in the potential governing the time evolution of a thermally averaged correlation function (corresponding to ⟨ψ Q Q (r, t)ψ * Q Q (r, 0)⟩) does not automatically reflect a dampening of the underlying microscopic wavefunction. (Note that the full dissipative dynamics are on the other hand irreversible and can indeed lead to a dampening of the microscopic wavefunction.) The effect of Im[V ] here instead is a manifestation of the phenomenon of wavefunction decoherence, where the fluctuations of the medium successively perturb the individual realizations of the wave function so that after a characteristic time τ D there is only faint resemblance among each other and the average washes out. While decoherence does not necessarily imply a decay of occupations, in the case of in-medium quarkonium, destabilization of formerly stable bound states is one of its central effects. Interestingly there is an additional scale hiding in plain sight in the imaginary part of the potential that determines the strength of decoherence and its role in heavy quarkonium stability.This simple example shows that the presence of an imaginary part in the potential governing the time evolution of a thermally averaged correlation function (corresponding to ⟨ψ Q Q (r, t)ψ * Q Q (r, 0)⟩) does not automatically reflect a dampening of the underlying microscopic wavefunction. (Note that the full dissipative dynamics are on the other hand irreversible and can indeed lead to a dampening of the microscopic wavefunction.) The effect of Im[V ] here instead is a manifestation of the phenomenon of wavefunction decoherence, where the fluctuations of the medium successively perturb the individual realizations of the wave function so that after a characteristic time τ D there is only faint resemblance among each other and the average washes out. While decoherence does not necessarily imply a decay of occupations, in the case of in-medium quarkonium, destabilization of formerly stable bound states is one of its central effects. Interestingly there is an additional scale hiding in plain sight in the imaginary part of the potential that determines the strength of decoherence and its role in heavy quarkonium stability.</p>
        <p>As an example consider the function D evaluated in HTL perturbation theory, as shown in Fig. 43. Its spatial dependence exhibits a well defined peak around the origin, which allows to define a characteristic scale ℓ med governing the spatial extend of the noise correlations in Eq. (237). While in perturbation theory at high temperatures the correlation length and temperature are closely related ℓ PT med ∼ 1/gT , in a non-perturbative setting e.g. close to the crossover transition in QCD the relation may be quite different. In other words ℓ med represents an independent additional scale in the system.As an example consider the function D evaluated in HTL perturbation theory, as shown in Fig. 43. Its spatial dependence exhibits a well defined peak around the origin, which allows to define a characteristic scale ℓ med governing the spatial extend of the noise correlations in Eq. (237). While in perturbation theory at high temperatures the correlation length and temperature are closely related ℓ PT med ∼ 1/gT , in a non-perturbative setting e.g. close to the crossover transition in QCD the relation may be quite different. In other words ℓ med represents an independent additional scale in the system.</p>
        <p>Depending on the size of the quarkonium system under consideration (denoted in the following by ℓ Q Q ) and the size of the correlation length ℓ med the effects on the bound state are quite different, as has been discussed in detail in Refs. [324,338]. Indeed based on how well the medium is able to resolve the internal structure of the quarkonium system three distinct regimes can be identified.Depending on the size of the quarkonium system under consideration (denoted in the following by ℓ Q Q ) and the size of the correlation length ℓ med the effects on the bound state are quite different, as has been discussed in detail in Refs. [324,338]. Indeed based on how well the medium is able to resolve the internal structure of the quarkonium system three distinct regimes can be identified.</p>
        <p>If the correlation length ℓ med ≫ ℓ Q Q is large compared to the intrinsic length scale of the Q Q system it corresponds to very soft momentum kicks ∆p med ∼ h/ℓ med on the small subsystem. Viewed as a color rotation on the quark and antiquark, both the particle and antiparticle undergo essentially the same change. In the limit of negligible momentum transfer one simply ends up with reversible dynamics, described by the von-Neumann like part of the master equation. Decoherence in this case is inefficient in destroying the quantum superposition present in the system.If the correlation length ℓ med ≫ ℓ Q Q is large compared to the intrinsic length scale of the Q Q system it corresponds to very soft momentum kicks ∆p med ∼ h/ℓ med on the small subsystem. Viewed as a color rotation on the quark and antiquark, both the particle and antiparticle undergo essentially the same change. In the limit of negligible momentum transfer one simply ends up with reversible dynamics, described by the von-Neumann like part of the master equation. Decoherence in this case is inefficient in destroying the quantum superposition present in the system.</p>
        <p>Once the correlation length ℓ med ≲ ℓ Q Q becomes of the same order of the size of the quarkonium system or smaller the full dissipative dynamics of quantum Brownian motion sets in. I.e. the color rotations on the quark and anti-quark now differ from each other. This entails that decoherence becomes efficient, which in turn means that superpositions of quantum states in the system are gradually transferred into a probabilistic mixture of classical states. After a characteristic decoherence time scale τ D the system may then be described by semi-classical means.Once the correlation length ℓ med ≲ ℓ Q Q becomes of the same order of the size of the quarkonium system or smaller the full dissipative dynamics of quantum Brownian motion sets in. I.e. the color rotations on the quark and anti-quark now differ from each other. This entails that decoherence becomes efficient, which in turn means that superpositions of quantum states in the system are gradually transferred into a probabilistic mixture of classical states. After a characteristic decoherence time scale τ D the system may then be described by semi-classical means.</p>
        <p>Up to now we have only considered one characteristic scale for the quarkonium system ℓ Q Q . However different states, due to their separated values of the binding energy, exhibit quite different spatial extends and therefore are affected differently by the medium kicks underlying decoherence. An appropriate analogy suggested in Ref. [324] is that a medium with ℓ med acts as a quarkonium sieve: easily destabilizing those states with ℓ med ≪ ℓ Q Q and only weakly affecting those with ℓ med ≫ ℓ Q Q .Up to now we have only considered one characteristic scale for the quarkonium system ℓ Q Q . However different states, due to their separated values of the binding energy, exhibit quite different spatial extends and therefore are affected differently by the medium kicks underlying decoherence. An appropriate analogy suggested in Ref. [324] is that a medium with ℓ med acts as a quarkonium sieve: easily destabilizing those states with ℓ med ≪ ℓ Q Q and only weakly affecting those with ℓ med ≫ ℓ Q Q .</p>
        <p>At very high temperatures the correlation length will become smaller than all of the quarkonium states and thus the medium is able to resolve even the most deeply bound ones. Taken to the asymptotic limit, all states will thus be destabilized equally efficiently.At very high temperatures the correlation length will become smaller than all of the quarkonium states and thus the medium is able to resolve even the most deeply bound ones. Taken to the asymptotic limit, all states will thus be destabilized equally efficiently.</p>
        <p>Numerical simulations support the conclusions drawn above. In the left panel of Fig. 44 a simple 1+1 dimensional computation has been performed, where the in-medium stationary ground state of a Hamiltonian with a Debye screened potential is evolved using the stochastic potential prescription. The noise correlations are given by a Gaussian function D with characteristic scale ℓ med . In such a scenario in the absence of medium induced fluctuations the survival probability ⟨1S|σ Q Q (t)|1S⟩ of a subsystem eigenstate would remain unity (for details see Ref. [338]). Keeping the temperature and thus the strength of the screening fixed and only changing the correlation length of the medium fluctuations leads to the different curves shown. As the radius of the initial state is around ℓ Q Q = 0.2 fm we expect and also find that a correlation length of ℓ med = 0.96 fm is unable to efficiently destabilize the bound state. A much more rapid decay (note the log scale) sets in once the correlation length drops below ℓ med = 0.32 fm, becoming equal to the bound state size. While not plotted here, the excited states in the system will be populated more and more strongly, the shorter the correlation length is.Numerical simulations support the conclusions drawn above. In the left panel of Fig. 44 a simple 1+1 dimensional computation has been performed, where the in-medium stationary ground state of a Hamiltonian with a Debye screened potential is evolved using the stochastic potential prescription. The noise correlations are given by a Gaussian function D with characteristic scale ℓ med . In such a scenario in the absence of medium induced fluctuations the survival probability ⟨1S|σ Q Q (t)|1S⟩ of a subsystem eigenstate would remain unity (for details see Ref. [338]). Keeping the temperature and thus the strength of the screening fixed and only changing the correlation length of the medium fluctuations leads to the different curves shown. As the radius of the initial state is around ℓ Q Q = 0.2 fm we expect and also find that a correlation length of ℓ med = 0.96 fm is unable to efficiently destabilize the bound state. A much more rapid decay (note the log scale) sets in once the correlation length drops below ℓ med = 0.32 fm, becoming equal to the bound state size. While not plotted here, the excited states in the system will be populated more and more strongly, the shorter the correlation length is.</p>
        <p>Note that survival probabilities with values much smaller than unity ensue, not only for the ground but also for the excited states, signaling that a large admixture of the system is actually made up of unbound states in the continuum. An interesting aspect of these dynamics is that continuously excitations and de-excitations are taking place between different states. Such a reshuffling of states will lead to the emergence of a thermalized fixed point of the (full dissipative) dynamics at late times. The availability of transitions between bound and scattering states also entails that if one were to start out from an unbound initial state, efficient decoherence can also lead to a re-population of bound states over time. The probability for this inverse process however is volume dependent, since only in a finite volume the number of unbound states remains finite and thus a non-vanishing probability exists to return into one of the few bound states. By treating explicitly the dynamics between all accessible states the open quantum systems approach naturally incorporates the physics of recombination. It is important to note however that this form of recombination only considers the two quarks of the initially prepared quarkonium bound state. In order to understand what happens in the presence of multiple Q Q pairs a higher order density matrix, such as σ Q Q Q Q needs to be considered, which, while in principle possible, will be a challenge for future studies.Note that survival probabilities with values much smaller than unity ensue, not only for the ground but also for the excited states, signaling that a large admixture of the system is actually made up of unbound states in the continuum. An interesting aspect of these dynamics is that continuously excitations and de-excitations are taking place between different states. Such a reshuffling of states will lead to the emergence of a thermalized fixed point of the (full dissipative) dynamics at late times. The availability of transitions between bound and scattering states also entails that if one were to start out from an unbound initial state, efficient decoherence can also lead to a re-population of bound states over time. The probability for this inverse process however is volume dependent, since only in a finite volume the number of unbound states remains finite and thus a non-vanishing probability exists to return into one of the few bound states. By treating explicitly the dynamics between all accessible states the open quantum systems approach naturally incorporates the physics of recombination. It is important to note however that this form of recombination only considers the two quarks of the initially prepared quarkonium bound state. In order to understand what happens in the presence of multiple Q Q pairs a higher order density matrix, such as σ Q Q Q Q needs to be considered, which, while in principle possible, will be a challenge for future studies.</p>
        <p>At this point it is informative to consider how the approximate stochastic evolution differs from the adiabatic approximation often employed in phenomenological modeling. In that case the Schrödinger equation Eq. ( 239) is used to solve for the microscopic wavefunction. In the right hand panel of Fig. 44 the two different computations are shown for a 1+1 dimensional setup at two distinct values for ℓ med . What is found is that the adiabatic approximation works better for cases where the influence of noise is weak. In addition the adiabatic result systematically underestimates the stochastic result, a fact that needs to be kept in mind when such simulations are compared to actual experimental data. Currently first steps are taken to incorporate the insight gained from the open quantum systems approach into phenomenological simulations of quarkonium, going beyond the adiabatic approximation [342].At this point it is informative to consider how the approximate stochastic evolution differs from the adiabatic approximation often employed in phenomenological modeling. In that case the Schrödinger equation Eq. ( 239) is used to solve for the microscopic wavefunction. In the right hand panel of Fig. 44 the two different computations are shown for a 1+1 dimensional setup at two distinct values for ℓ med . What is found is that the adiabatic approximation works better for cases where the influence of noise is weak. In addition the adiabatic result systematically underestimates the stochastic result, a fact that needs to be kept in mind when such simulations are compared to actual experimental data. Currently first steps are taken to incorporate the insight gained from the open quantum systems approach into phenomenological simulations of quarkonium, going beyond the adiabatic approximation [342].</p>
        <p>Access to the (approximate) real-time dynamics of heavy-quarkonium has thus already provided vital insight into their dynamical melting process, in which wavefunction decoherence plays an important role. The historic intuition of sequential melting is elevated to a genuine real-time picture, where depending on the size of individual states, medium fluctuations can efficiently resolve the bound state and induce transitions into higher excited bound or scattering states. The phenomenon of quarkonium melting thus can only be formulated as an initial value problem, inquiring how many of an initial collection of quarkonium states will survive in a medium after a given time.Access to the (approximate) real-time dynamics of heavy-quarkonium has thus already provided vital insight into their dynamical melting process, in which wavefunction decoherence plays an important role. The historic intuition of sequential melting is elevated to a genuine real-time picture, where depending on the size of individual states, medium fluctuations can efficiently resolve the bound state and induce transitions into higher excited bound or scattering states. The phenomenon of quarkonium melting thus can only be formulated as an initial value problem, inquiring how many of an initial collection of quarkonium states will survive in a medium after a given time.</p>
        <p>In the study of single heavy quarks in the open quantum systems approach it has been pointed out e.g. in Ref. [336] that the dynamics in phase space, i.e. governed by the momentum operator, in general cannot be disentangled from those in color space and that their interplay under decoherence is essential to understanding of the classicalization of the quarkonium evolution. Thus for a more comprehensive understanding of dynamical quarkonium melting it is paramount that master equations are derived and simulated, which incorporate the dynamics of color degrees of freedom explicitly. This challenge is currently taken on by several groups. For a selection of published master equations including color degrees of freedom see Refs. [331][332][333]335].In the study of single heavy quarks in the open quantum systems approach it has been pointed out e.g. in Ref. [336] that the dynamics in phase space, i.e. governed by the momentum operator, in general cannot be disentangled from those in color space and that their interplay under decoherence is essential to understanding of the classicalization of the quarkonium evolution. Thus for a more comprehensive understanding of dynamical quarkonium melting it is paramount that master equations are derived and simulated, which incorporate the dynamics of color degrees of freedom explicitly. This challenge is currently taken on by several groups. For a selection of published master equations including color degrees of freedom see Refs. [331][332][333]335].</p>
        <p>In Section 4.2 we discussed the derivation of a Lindblad master equation from QCD at high temperature. It both provided insight into the range of validity of simple Schrödinger equation based descriptions of in-medium quarkonium and offered possible routes for their improvement. In this section we will review two other open quantum systems based approach to quarkonium, which instead make close connection with the effective field theory of pNRQCD. The first is based on a scenario, where the medium itself is weakly coupled and the matching between QCD and the EFT can be carried out perturbatively. The dominant physics it incorporates is that of gluo-dissociation. The second study considers a different scale hierarchy, in which the medium is not weakly coupled T ∼ m D . By focusing on the subset of Coulombically bound quarkonium states it is shown that their dynamics are governed by two transport coefficients amenable to a lattice QCD evaluation.In Section 4.2 we discussed the derivation of a Lindblad master equation from QCD at high temperature. It both provided insight into the range of validity of simple Schrödinger equation based descriptions of in-medium quarkonium and offered possible routes for their improvement. In this section we will review two other open quantum systems based approach to quarkonium, which instead make close connection with the effective field theory of pNRQCD. The first is based on a scenario, where the medium itself is weakly coupled and the matching between QCD and the EFT can be carried out perturbatively. The dominant physics it incorporates is that of gluo-dissociation. The second study considers a different scale hierarchy, in which the medium is not weakly coupled T ∼ m D . By focusing on the subset of Coulombically bound quarkonium states it is shown that their dynamics are governed by two transport coefficients amenable to a lattice QCD evaluation.</p>
        <p>In the first study originally presented in Ref. [333] one starts from perturbatively matched pNRQCD and translates the operators, states and Wilson coefficients of that EFT into the language of a Lindblad equation. Introducing a Wigner transform of the density matrix, the quarkonium distribution functions are defined, for which transport equations of Boltzmann type are derived under certain time scale separation assumptions.In the first study originally presented in Ref. [333] one starts from perturbatively matched pNRQCD and translates the operators, states and Wilson coefficients of that EFT into the language of a Lindblad equation. Introducing a Wigner transform of the density matrix, the quarkonium distribution functions are defined, for which transport equations of Boltzmann type are derived under certain time scale separation assumptions.</p>
        <p>Starting point of the derivation is pNRQCD considered in thermal equilibrium under the particular scale hierarchyStarting point of the derivation is pNRQCD considered in thermal equilibrium under the particular scale hierarchy</p>
        <p>which corresponds to a scenario where the medium still allows for a well defined bound state to exist (c.f. also Ref. [343]).which corresponds to a scenario where the medium still allows for a well defined bound state to exist (c.f. also Ref. [343]).</p>
        <p>Taking the S-wave ground state charmonium binding energy as ultrasoft scale Mv 2Taking the S-wave ground state charmonium binding energy as ultrasoft scale Mv 2</p>
        <p>∼ E bind (1S) = 600 MeV, one finds that it is indeed larger than the temperatures currently reached in heavy-ion experiments. (Note that in this direct comparison, we assume that the relevant energy scale in the medium is indeed T and not π T .) As made explicit in Eq. ( 52) the interactions between heavy quarkonium states and the ultrasoft gluons in pNRQCD is to lowest order mediated via a dipole interaction. In a perturbative matching to NRQCD it can be shown (see Ref. [344,345]) that the corresponding Wilson coefficient V A (r) does not run in the renormalization group sense and thus at the matching scale can be set to∼ E bind (1S) = 600 MeV, one finds that it is indeed larger than the temperatures currently reached in heavy-ion experiments. (Note that in this direct comparison, we assume that the relevant energy scale in the medium is indeed T and not π T .) As made explicit in Eq. ( 52) the interactions between heavy quarkonium states and the ultrasoft gluons in pNRQCD is to lowest order mediated via a dipole interaction. In a perturbative matching to NRQCD it can be shown (see Ref. [344,345]) that the corresponding Wilson coefficient V A (r) does not run in the renormalization group sense and thus at the matching scale can be set to</p>
        <p>s ) to leading order. In order to connect to the open quantum systems picture formulated in terms of states in a Hilbert space, we need to consider what degrees of freedom are present in such a perturbative pNRQCD setup. Since the color singlet potential is attractive there may be either bound or unbound singlet states present, while due to the repulsive octet potential only unbound colored states exist. Their time evolution in the absence of coupling to ultrasoft gluons can be cast into the form of a Schrödinger equation governed by the Hamiltonianss ) to leading order. In order to connect to the open quantum systems picture formulated in terms of states in a Hilbert space, we need to consider what degrees of freedom are present in such a perturbative pNRQCD setup. Since the color singlet potential is attractive there may be either bound or unbound singlet states present, while due to the repulsive octet potential only unbound colored states exist. Their time evolution in the absence of coupling to ultrasoft gluons can be cast into the form of a Schrödinger equation governed by the Hamiltonians</p>
        <p>arising from the terms in the first and second lines of the pNRQCD Lagrangian in Eq. ( 52). Note that here V S,O are purely real and can be perturbatively computed from QCD. Under the present scale separation the kinetic terms P 2 /4m Q related to the center of mass motion are subdominant. We can thus compute the single particle stationary states of the Hilbert space for the relative motion, by solving the following Schrödinger equationsarising from the terms in the first and second lines of the pNRQCD Lagrangian in Eq. ( 52). Note that here V S,O are purely real and can be perturbatively computed from QCD. Under the present scale separation the kinetic terms P 2 /4m Q related to the center of mass motion are subdominant. We can thus compute the single particle stationary states of the Hilbert space for the relative motion, by solving the following Schrödinger equations</p>
        <p>Ref. [333] now considers creation ( †) and annihilation operators for all three distinct composite particle entities with given center of mass momentum P aRef. [333] now considers creation ( †) and annihilation operators for all three distinct composite particle entities with given center of mass momentum P a</p>
        <p>which fulfill canonical commutation relations. Since here the Hilbert spaces of relative and center of mass motion factorize, a single particle state is given by a direct product of one of the wavefunctions of Eq. ( 243) and a plain wave with momentum P. The Fock space is populated by applying the above creation operatorswhich fulfill canonical commutation relations. Since here the Hilbert spaces of relative and center of mass motion factorize, a single particle state is given by a direct product of one of the wavefunctions of Eq. ( 243) and a plain wave with momentum P. The Fock space is populated by applying the above creation operators</p>
        <p>where the kets |K, nl, 1⟩, |P, p, 1⟩, |P, p, a⟩ are a shorthand notation for the single particle direct product states mentioned above.where the kets |K, nl, 1⟩, |P, p, 1⟩, |P, p, a⟩ are a shorthand notation for the single particle direct product states mentioned above.</p>
        <p>The set of wavefunctions and particle operators allows the authors to write an explicit representation of the singlet and octet wavefunctions asThe set of wavefunctions and particle operators allows the authors to write an explicit representation of the singlet and octet wavefunctions as</p>
        <p>|O a (R, t)⟩ = ∫|O a (R, t)⟩ = ∫</p>
        <p>Defining the matrix elements in the relative position space for the singlet and octet sector as the interaction terms of the pNRQCD Lagrangian can be reexpressed (see Ref. [346]) in an alternative form, which directly invites the connection to the open quantum systems formulation. Take for example the singlet to octet termDefining the matrix elements in the relative position space for the singlet and octet sector as the interaction terms of the pNRQCD Lagrangian can be reexpressed (see Ref. [346]) in an alternative form, which directly invites the connection to the open quantum systems formulation. Take for example the singlet to octet term</p>
        <p>) .) .</p>
        <p>((</p>
        <p>It can be reinterpreted according to aIt can be reinterpreted according to a</p>
        <p>where the subscript m refers to the center of mass coordinate R, the vector components i and the color degrees of freedom a.where the subscript m refers to the center of mass coordinate R, the vector components i and the color degrees of freedom a.</p>
        <p>It is at this point that the Markovian approximation is invoked. In the scale hierarchy considered here, it is justified by comparing the characteristic medium time scale 1/T with the inverse of the dissociation rate, in turn allowing one to neglect all memory integrals in the master equation. (For technical details see the appendices of Ref. [333])It is at this point that the Markovian approximation is invoked. In the scale hierarchy considered here, it is justified by comparing the characteristic medium time scale 1/T with the inverse of the dissociation rate, in turn allowing one to neglect all memory integrals in the master equation. (For technical details see the appendices of Ref. [333])</p>
        <p>As we saw e.g. in the derivation of the quantum optical master equation in Eq. ( 123), the two-point correlation functions of the Ξ operators can be split into two contributions. One S mn will lead to a modification of the subsystem Hamiltonian and the other γ mn provides the prefactors of the Lindblad operators.As we saw e.g. in the derivation of the quantum optical master equation in Eq. ( 123), the two-point correlation functions of the Ξ operators can be split into two contributions. One S mn will lead to a modification of the subsystem Hamiltonian and the other γ mn provides the prefactors of the Lindblad operators.</p>
        <p>It turns out that the former can be straight forwardly evaluated in pNRQCD as it arises from the self energy Feynman diagram where a singlet state via interaction with an ultrasoft gluon turns into an intermediate octet state and eventually returns to the singlet by a second interaction (see Fig. 45). The real part of this contribution enters as a loop correction to the otherwise real-valued potential and can be used to define the effective subsystem Hamiltonian HS . I.e. we are considering a system where part of the genuine field theoretical interactions between the quarkonium and the remaining dynamical gluons can be summarized in a correction to a time independent potential. (For a similar treatment see also Ref. [286])It turns out that the former can be straight forwardly evaluated in pNRQCD as it arises from the self energy Feynman diagram where a singlet state via interaction with an ultrasoft gluon turns into an intermediate octet state and eventually returns to the singlet by a second interaction (see Fig. 45). The real part of this contribution enters as a loop correction to the otherwise real-valued potential and can be used to define the effective subsystem Hamiltonian HS . I.e. we are considering a system where part of the genuine field theoretical interactions between the quarkonium and the remaining dynamical gluons can be summarized in a correction to a time independent potential. (For a similar treatment see also Ref. [286])</p>
        <p>Before continuing to a more detailed discussion of the contributions from fluctuations onto the quarkonium dynamics one can connect to the language of transport equations. To this end a distribution function for the heavy quarkonium states needs to be defined. Since the main interest lies in the evolution of bound states this may be achieved by taking the Wigner transform of the corresponding matrix elements of the reduced system density matrix in the singlet basisBefore continuing to a more detailed discussion of the contributions from fluctuations onto the quarkonium dynamics one can connect to the language of transport equations. To this end a distribution function for the heavy quarkonium states needs to be defined. Since the main interest lies in the evolution of bound states this may be achieved by taking the Wigner transform of the corresponding matrix elements of the reduced system density matrix in the singlet basis</p>
        <p>The strategy here is to derive explicit expressions for f nl (X, K, t) at finite time t given by terms that possess a linear dependence on time, so that taking the time derivative results in the evolution equation of interest. Essentially one sandwiches many independent small time evolution steps after each other. This trick is applicable due to the Markovian approximation, where e.g. the explicit t dependence of possible integral terms has been removed by setting the upper boundaries to infinity.The strategy here is to derive explicit expressions for f nl (X, K, t) at finite time t given by terms that possess a linear dependence on time, so that taking the time derivative results in the evolution equation of interest. Essentially one sandwiches many independent small time evolution steps after each other. This trick is applicable due to the Markovian approximation, where e.g. the explicit t dependence of possible integral terms has been removed by setting the upper boundaries to infinity.</p>
        <p>The first step is to consider the effect of the von-Neumann like term in the Lindblad equation on the time evolution of the distribution function. The commutator with HS leads toThe first step is to consider the effect of the von-Neumann like term in the Lindblad equation on the time evolution of the distribution function. The commutator with HS leads to</p>
        <p>where the additional terms from the Lindblad operators are not shown explicitly. In conjunction with the Wigner transform this expression can be used as the starting point of a gradient expansion, leading eventually towhere the additional terms from the Lindblad operators are not shown explicitly. In conjunction with the Wigner transform this expression can be used as the starting point of a gradient expansion, leading eventually to</p>
        <p>where for notational purposes the center of mass velocity is defined as v = K/2m Q .where for notational purposes the center of mass velocity is defined as v = K/2m Q .</p>
        <p>The terms involving Lindblad operators can be divided into two sets. The one including L † Lσ and σ L † L is directly related to the perturbative dissociation rate, as it is defined from the dipole transition between the singlet to octet. I.e. here the imaginary part of the pNRQCD self energy contribution implements the process depicted on the right hand side of Fig. 45. This finding is consistent with previous results of Ref. [343], where the same diagram was reinterpreted to give an imaginary part to the in-medium heavy quark potential. Note that to this order in the approximation, the potential in the pNRQCD Lagrangian is completely real and that it is the loop corrections from the interaction with the ultrasoft gluons in the scale hierarchy present that induce an imaginary part.The terms involving Lindblad operators can be divided into two sets. The one including L † Lσ and σ L † L is directly related to the perturbative dissociation rate, as it is defined from the dipole transition between the singlet to octet. I.e. here the imaginary part of the pNRQCD self energy contribution implements the process depicted on the right hand side of Fig. 45. This finding is consistent with previous results of Ref. [343], where the same diagram was reinterpreted to give an imaginary part to the in-medium heavy quark potential. Note that to this order in the approximation, the potential in the pNRQCD Lagrangian is completely real and that it is the loop corrections from the interaction with the ultrasoft gluons in the scale hierarchy present that induce an imaginary part.</p>
        <p>The last missing term is the one involving Lσ L † , which is shown to be related to the regeneration of quarkonium states in this scale hierarchy. This can be intuitively understood from the fact that it contains the distribution function of color octet quarkonium states, as well as the dipole transition probability between the singlet and octet sector.The last missing term is the one involving Lσ L † , which is shown to be related to the regeneration of quarkonium states in this scale hierarchy. This can be intuitively understood from the fact that it contains the distribution function of color octet quarkonium states, as well as the dipole transition probability between the singlet and octet sector.</p>
        <p>Combined into one expression a Boltzmann equation emergesCombined into one expression a Boltzmann equation emerges</p>
        <p>wherewhere</p>
        <p>nl (X, K, t) encodes the recombination and C (-) nl (X, K, t) the dissociation processes arising from the Lindblad operators. In the computation of the recombination term often additional approximations are employed. One of these is the so called molecular chaos approximation, where the distribution of the octet quarkonium states is written as a simple product of distribution functions for the individual quark and antiquark degrees of freedom. One may argue from a comparison of the decorrelation rate of the heavy quarks with the relaxation rate of the quarkonium system that such a simplification is justified.nl (X, K, t) encodes the recombination and C (-) nl (X, K, t) the dissociation processes arising from the Lindblad operators. In the computation of the recombination term often additional approximations are employed. One of these is the so called molecular chaos approximation, where the distribution of the octet quarkonium states is written as a simple product of distribution functions for the individual quark and antiquark degrees of freedom. One may argue from a comparison of the decorrelation rate of the heavy quarks with the relaxation rate of the quarkonium system that such a simplification is justified.</p>
        <p>A detailed comparison of the involved time scales, finally allows Ref. [333] to recover in addition to the dissociation term also a regeneration term of the same form as used in previous implementation of the Boltzmann equation in e.g. Ref. [318]. This completes the systematic derivation of the transport approach to heavy quarkonium from the underlying microscopic theory of QCD for a medium, in which the temperature is low enough for well defined bound states to exist.A detailed comparison of the involved time scales, finally allows Ref. [333] to recover in addition to the dissociation term also a regeneration term of the same form as used in previous implementation of the Boltzmann equation in e.g. Ref. [318]. This completes the systematic derivation of the transport approach to heavy quarkonium from the underlying microscopic theory of QCD for a medium, in which the temperature is low enough for well defined bound states to exist.</p>
        <p>We find that the open quantum systems approach based on perturbative pNRQCD incorporates in a consistent manner the relevant processes for the S-wave ground state dynamics: (1) screening of a real-valued microscopic potential, (2) the effects of scatterings which both include the dissociation of quarkonium due to excitation into octet states (3) recombination from the inverse process where a colored quark-antiquark pair can emit a gluon and coalesce back into a bound state.We find that the open quantum systems approach based on perturbative pNRQCD incorporates in a consistent manner the relevant processes for the S-wave ground state dynamics: (1) screening of a real-valued microscopic potential, (2) the effects of scatterings which both include the dissociation of quarkonium due to excitation into octet states (3) recombination from the inverse process where a colored quark-antiquark pair can emit a gluon and coalesce back into a bound state.</p>
        <p>Note that Ref. [333] also considered the annihilation of heavy quark-antiquark pairs via the four-fermion interactions of the NRQCD Lagrangian, adding their contributions as additional Lindblad operators. It is found that for phenomenologically relevant temperatures and accessible time scales this effect is indeed negligible. This finding reinforces the point that the dileptons measured in a heavy-ion collision are not those emitted from in-medium quarkonium states but actually from vacuum states decaying long after the QGP has ceased to exist.Note that Ref. [333] also considered the annihilation of heavy quark-antiquark pairs via the four-fermion interactions of the NRQCD Lagrangian, adding their contributions as additional Lindblad operators. It is found that for phenomenologically relevant temperatures and accessible time scales this effect is indeed negligible. This finding reinforces the point that the dileptons measured in a heavy-ion collision are not those emitted from in-medium quarkonium states but actually from vacuum states decaying long after the QGP has ceased to exist.</p>
        <p>In many applications of transport theory to heavy quarkonium, instead of the Boltzmann equation, a simpler rate equation is deployed [347]. In light of the systematic derivation of the Boltzmann equation from QCD it is an interesting question to ask under which conditions such a rate equation can be subsequently derived as well. Since usually the regeneration term in such an approach is determined from arguments based on detailed balance, the system needs to have had enough time to approach thermal equilibrium for that setup to be valid.In many applications of transport theory to heavy quarkonium, instead of the Boltzmann equation, a simpler rate equation is deployed [347]. In light of the systematic derivation of the Boltzmann equation from QCD it is an interesting question to ask under which conditions such a rate equation can be subsequently derived as well. Since usually the regeneration term in such an approach is determined from arguments based on detailed balance, the system needs to have had enough time to approach thermal equilibrium for that setup to be valid.</p>
        <p>The second approach we consider here and which has been put forward in Refs. [286,287,332] explores how the quarkonium dynamics within pNRQCD can be extended towards a strongly coupled medium. To this end one wishes to relax the condition π T ≫ m D , which is e.g. employed in the derivation of the Boltzmann equation (see Eq. ( 240)) and implies that the physics of the medium is weakly coupled. Instead one considers the following scale hierarchyThe second approach we consider here and which has been put forward in Refs. [286,287,332] explores how the quarkonium dynamics within pNRQCD can be extended towards a strongly coupled medium. To this end one wishes to relax the condition π T ≫ m D , which is e.g. employed in the derivation of the Boltzmann equation (see Eq. ( 240)) and implies that the physics of the medium is weakly coupled. Instead one considers the following scale hierarchy</p>
        <p>The first inequality in Eq. ( 256) amounts to a scenario where the extent of the quarkonium state (given by its Bohr radius a 0 ) is small enough that its inverse lies at the soft scale and significantly above the temperature scale πT . In practice this restricts us to the ground state of bottomonium for which 1/a 0 ≈ 1.5 GeV, while for charmonium, if considered Coulombicallly bound, 1/a 0 ≈ 0.84 GeV limits this approach to temperatures below 2T c . With the quarkonium relaxation scale approximated as τ R ∼ 1/(a 2 0 (π T ) 3 ), the assumption of Coulombic binding further leads to τ R ≫ τ E , which hints at the dynamics to be Markovian. On the other hand, since πT ≫ E bind also the quantum Brownian motion conditions is fulfilled τ S ≫ τ E for this system.The first inequality in Eq. ( 256) amounts to a scenario where the extent of the quarkonium state (given by its Bohr radius a 0 ) is small enough that its inverse lies at the soft scale and significantly above the temperature scale πT . In practice this restricts us to the ground state of bottomonium for which 1/a 0 ≈ 1.5 GeV, while for charmonium, if considered Coulombicallly bound, 1/a 0 ≈ 0.84 GeV limits this approach to temperatures below 2T c . With the quarkonium relaxation scale approximated as τ R ∼ 1/(a 2 0 (π T ) 3 ), the assumption of Coulombic binding further leads to τ R ≫ τ E , which hints at the dynamics to be Markovian. On the other hand, since πT ≫ E bind also the quantum Brownian motion conditions is fulfilled τ S ≫ τ E for this system.</p>
        <p>In the scale hierarchy of Eq. ( 256) the pNRQCD Lagrangian does take the same form as in Eq. ( 52)In the scale hierarchy of Eq. ( 256) the pNRQCD Lagrangian does take the same form as in Eq. ( 52)</p>
        <p>where the singlet and octet Hamiltonians h s and h o are governed by Coulombic potentialswhere the singlet and octet Hamiltonians h s and h o are governed by Coulombic potentials</p>
        <p>Note that here the theory convention is adopted, in which the Casimir C F of SU(3) is not absorbed in the definition of α s .Note that here the theory convention is adopted, in which the Casimir C F of SU(3) is not absorbed in the definition of α s .</p>
        <p>Let us consider the leading order self energy corrections to the singlet propagation arising in pNRQCD from the diagram on the left of Fig. 45, which in an isotropic system may be expressed as the following correlator of electric fields.Let us consider the leading order self energy corrections to the singlet propagation arising in pNRQCD from the diagram on the left of Fig. 45, which in an isotropic system may be expressed as the following correlator of electric fields.</p>
        <p>ds ⟨T E a,i (s, 0)E a,i (0, 0)⟩. (259) If in addition the electric field correlator is approximately time-translation invariant, as is the case in thermal equilibrium the expression simplifies further and one may replace Σ s with the time-independent expression Σ eq.ds ⟨T E a,i (s, 0)E a,i (0, 0)⟩. (259) If in addition the electric field correlator is approximately time-translation invariant, as is the case in thermal equilibrium the expression simplifies further and one may replace Σ s with the time-independent expression Σ eq.</p>
        <p>s . Note that the latter also encompasses the situation where the medium temperature is slowly changing, which in the context of a heavy-ion collision may be fulfilled at late times but correction become relevant at early times.s . Note that the latter also encompasses the situation where the medium temperature is slowly changing, which in the context of a heavy-ion collision may be fulfilled at late times but correction become relevant at early times.</p>
        <p>The self energy can be split into a real-and imaginary part, each of which possess a well defined physical interpretation as transport coefficients of the quarkonium system (i.e. they can be written as a zero frequency limit of an appropriate spectral function, in the spirit of a Kubo formula)The self energy can be split into a real-and imaginary part, each of which possess a well defined physical interpretation as transport coefficients of the quarkonium system (i.e. they can be written as a zero frequency limit of an appropriate spectral function, in the spirit of a Kubo formula)</p>
        <p>The real part κ turns out to be the heavy-quark diffusion coefficient, a quantity under intense scrutiny by the theory community. (See e.g. Ref. [348] for a holographic, Ref. [349] perturbative, Ref. [350] phenomenological and Ref. [351] for a lattice QCD perspective). In the scale hierarchy considered here pNRQCD connects κ to the spectral width of the 1S ground state as Γ = -2⟨Im (-iΣ s )⟩ = 3a 2 0 κ. The second quantity γ , corresponding to the imaginary part, has been evaluated in a weakly coupled setting in e.g. Ref. [17] and a first proposal how to extract it from the lattice has been put forward in Ref. [287,288]. In pNRQCD it is related to the mass shift δm, the quarkonium experiences in the medium δm = ⟨Re (-iΣ s )⟩ = 3 2 a 2 0 γ .The real part κ turns out to be the heavy-quark diffusion coefficient, a quantity under intense scrutiny by the theory community. (See e.g. Ref. [348] for a holographic, Ref. [349] perturbative, Ref. [350] phenomenological and Ref. [351] for a lattice QCD perspective). In the scale hierarchy considered here pNRQCD connects κ to the spectral width of the 1S ground state as Γ = -2⟨Im (-iΣ s )⟩ = 3a 2 0 κ. The second quantity γ , corresponding to the imaginary part, has been evaluated in a weakly coupled setting in e.g. Ref. [17] and a first proposal how to extract it from the lattice has been put forward in Ref. [287,288]. In pNRQCD it is related to the mass shift δm, the quarkonium experiences in the medium δm = ⟨Re (-iΣ s )⟩ = 3 2 a 2 0 γ .</p>
        <p>As was shown in detail in Section 3 of Ref. [286] one can translate the language of color singlet and color octet fields living on the Schwinger-Keldysh contour (forward path fields denoted with subscript 1, backward path fields with 2) into a language of the corresponding density matrix in coordinate space via the identificationsAs was shown in detail in Section 3 of Ref. [286] one can translate the language of color singlet and color octet fields living on the Schwinger-Keldysh contour (forward path fields denoted with subscript 1, backward path fields with 2) into a language of the corresponding density matrix in coordinate space via the identifications</p>
        <p>The evolution equations for the singlet and octet density matrices following from Eqs. ( 257) and ( 261) appear to contain memory integrals. However a careful consideration of the power counting reveals that these non-Markovian contributions are subdominant at the current order of the multipole expansion. The equations one obtains can be interpreted in terms of a quantum jump model. It considers the evolution of the density matrix based on the singlet or octet potential, which is amended by stochastically distributed transitions induced by the pNRQCD self energies. This dynamics is represented by the following closed set of master equations for the singlet and octet componentThe evolution equations for the singlet and octet density matrices following from Eqs. ( 257) and ( 261) appear to contain memory integrals. However a careful consideration of the power counting reveals that these non-Markovian contributions are subdominant at the current order of the multipole expansion. The equations one obtains can be interpreted in terms of a quantum jump model. It considers the evolution of the density matrix based on the singlet or octet potential, which is amended by stochastically distributed transitions induced by the pNRQCD self energies. This dynamics is represented by the following closed set of master equations for the singlet and octet component</p>
        <p>which are fully specified by the potentials and the electric field correlator. The time dependent self energieswhich are fully specified by the potentials and the electric field correlator. The time dependent self energies</p>
        <p>are expressed in terms of their realκ(t) and imaginary part γ (t). Note that these expressions may be replaced by their static counterparts, the transport coefficients κ = κ(∞) and γ = γ (∞), discussed above, if the electric fields are approximately time translation invariant and the medium is sufficiently close to thermal equilibrium. The operators related to the interactions with the electric fields, which induce transitions between the singlet and octet sector, as well as within the octet sector readare expressed in terms of their realκ(t) and imaginary part γ (t). Note that these expressions may be replaced by their static counterparts, the transport coefficients κ = κ(∞) and γ = γ (∞), discussed above, if the electric fields are approximately time translation invariant and the medium is sufficiently close to thermal equilibrium. The operators related to the interactions with the electric fields, which induce transitions between the singlet and octet sector, as well as within the octet sector read</p>
        <p>Since the mixing terms considered in Eq. ( 262) are linear in the density matrix, one may recast the equation of motion in Lindblad form. Absorbing the relaxation rate into appropriately defined collapse operators C n it can be written asSince the mixing terms considered in Eq. ( 262) are linear in the density matrix, one may recast the equation of motion in Lindblad form. Absorbing the relaxation rate into appropriately defined collapse operators C n it can be written as</p>
        <p>) .) .</p>
        <p>((</p>
        <p>The density matrix consists of a direct product of singlet and octet sector and the Hamiltonian correspondingly takes on a block-diagonal formThe density matrix consists of a direct product of singlet and octet sector and the Hamiltonian correspondingly takes on a block-diagonal form</p>
        <p>) .) .</p>
        <p>One finds that in a thermal medium the potential receives a correction due to the transport coefficient γ , while the collapse operators are governed by the heavy-quark diffusion constantOne finds that in a thermal medium the potential receives a correction due to the transport coefficient γ , while the collapse operators are governed by the heavy-quark diffusion constant</p>
        <p>) .) .</p>
        <p>Note the similarity with the Lindblad operators of Eq. ( 234) derived in Ref. [331] under a weak coupling quantum Brownian motion assumption. There it is the function D, defined via the gluon spectral function and related to the imaginary part of the heavy-quark potential, which mediates the transitions between the singlet and octet sector.Note the similarity with the Lindblad operators of Eq. ( 234) derived in Ref. [331] under a weak coupling quantum Brownian motion assumption. There it is the function D, defined via the gluon spectral function and related to the imaginary part of the heavy-quark potential, which mediates the transitions between the singlet and octet sector.</p>
        <p>Limiting oneself to states with small spatial extent compared to the temperature of the system, i.e. those that may be considered Coulombically bound, one finds that their dynamics can be cast in form of a Lindblad equation even if the medium is strongly coupled. The ensuing coupled equations of motion for a medium close to thermal equilibrium depend on the singlet and octet potentials (which in this scale hierarchy are simply the vacuum potentials) and two transport coefficients, the heavy quark diffusion coefficient κ and the quantity γ related to a mass shift of the quarkonium system. This finding has invigorated the ongoing efforts for a high precision determination of κ from lattice QCD and jumpstarted work on the extraction of the mass shift from Euclidean time correlation functions.Limiting oneself to states with small spatial extent compared to the temperature of the system, i.e. those that may be considered Coulombically bound, one finds that their dynamics can be cast in form of a Lindblad equation even if the medium is strongly coupled. The ensuing coupled equations of motion for a medium close to thermal equilibrium depend on the singlet and octet potentials (which in this scale hierarchy are simply the vacuum potentials) and two transport coefficients, the heavy quark diffusion coefficient κ and the quantity γ related to a mass shift of the quarkonium system. This finding has invigorated the ongoing efforts for a high precision determination of κ from lattice QCD and jumpstarted work on the extraction of the mass shift from Euclidean time correlation functions.</p>
        <p>Summary. Significant progress in our understanding of the real-time evolution of heavy quarkonium has been achieved over the past years. With quarkonium in a medium naturally inviting the distinction between a small system and the environment, the open quantum systems approach has been a vital tool in this regard. It provides a versatile theoretical framework to account for the different timescales present in the system and has led to an improved understanding of quarkonium melting as a genuine dynamical process. Decoherence induced by the medium fluctuations is found to play an important role in addition to static screening, allowing the medium to act as a bound state sieve. An improved theory understanding of quarkonium real-time evolution has also allowed to put current approaches to phenomenological modeling of quarkonium dynamics on a more solid footing by exposing their underlying assumption. Not only has the stochastic Schrödinger equation been derived from a Lindblad equation via the quantum state diffusion method but also the Boltzmann transport equations have been systematically obtained from a pNRQCD based master equation. The quest for a genuine non-perturbative implementation of the open quantum systems master equations is ongoing and first results based on pNRQCD revealed that the dynamics in certain scale hierarchies may be represented in terms of transport coefficients amenable to a lattice QCD evaluation.Summary. Significant progress in our understanding of the real-time evolution of heavy quarkonium has been achieved over the past years. With quarkonium in a medium naturally inviting the distinction between a small system and the environment, the open quantum systems approach has been a vital tool in this regard. It provides a versatile theoretical framework to account for the different timescales present in the system and has led to an improved understanding of quarkonium melting as a genuine dynamical process. Decoherence induced by the medium fluctuations is found to play an important role in addition to static screening, allowing the medium to act as a bound state sieve. An improved theory understanding of quarkonium real-time evolution has also allowed to put current approaches to phenomenological modeling of quarkonium dynamics on a more solid footing by exposing their underlying assumption. Not only has the stochastic Schrödinger equation been derived from a Lindblad equation via the quantum state diffusion method but also the Boltzmann transport equations have been systematically obtained from a pNRQCD based master equation. The quest for a genuine non-perturbative implementation of the open quantum systems master equations is ongoing and first results based on pNRQCD revealed that the dynamics in certain scale hierarchies may be represented in terms of transport coefficients amenable to a lattice QCD evaluation.</p>
        <p>In the previous sections we have developed an improved theoretical understanding of the properties of kinetically equilibrated heavy quarkonium, as well as its real-time evolution in the background of a thermal medium. It is now time to ask how this insight can help us in shedding light on quarkonium production in heavy-ion collisions.In the previous sections we have developed an improved theoretical understanding of the properties of kinetically equilibrated heavy quarkonium, as well as its real-time evolution in the background of a thermal medium. It is now time to ask how this insight can help us in shedding light on quarkonium production in heavy-ion collisions.</p>
        <p>While the focus of this review is the theoretical understanding of in-medium quarkonium it pertains to only but one part of the puzzle in understanding quarkonium production in heavy-ion collisions (for a recent review including also an extended survey of experimental measurements see Ref. [352]). Indeed such collisions encompass many complex aspects, from the production of the heavy quark-antiquark pairs, the evolution of the bulk medium consisting of light partons, to the physics of hadronization, as well as the evolution within the hadronic phase. Even in the context of heavy quarkonium alone many open questions remain, some of the most pressing are listed below:While the focus of this review is the theoretical understanding of in-medium quarkonium it pertains to only but one part of the puzzle in understanding quarkonium production in heavy-ion collisions (for a recent review including also an extended survey of experimental measurements see Ref. [352]). Indeed such collisions encompass many complex aspects, from the production of the heavy quark-antiquark pairs, the evolution of the bulk medium consisting of light partons, to the physics of hadronization, as well as the evolution within the hadronic phase. Even in the context of heavy quarkonium alone many open questions remain, some of the most pressing are listed below:</p>
        <p>• How do the energetic partons inside the projectile nuclei interact to form heavy quark-antiquark pairs?• How do the energetic partons inside the projectile nuclei interact to form heavy quark-antiquark pairs?</p>
        <p>• Do heavy quarkonium states form in the early stages of the collision, which are dominated by the strong coherent fields of the glasma and if so what are the time scales involved?• Do heavy quarkonium states form in the early stages of the collision, which are dominated by the strong coherent fields of the glasma and if so what are the time scales involved?</p>
        <p>• If a quarkonium state has formed early on, how does it react to the emergent quark-gluon plasma it is immersed in?• If a quarkonium state has formed early on, how does it react to the emergent quark-gluon plasma it is immersed in?</p>
        <p>• How does the interaction with a locally thermalized but steadily cooling medium affect the stability of existing bound states? How efficient is recombination of color octet pairs into singlet bound states in such a setting?• How does the interaction with a locally thermalized but steadily cooling medium affect the stability of existing bound states? How efficient is recombination of color octet pairs into singlet bound states in such a setting?</p>
        <p>• Depending on the flavor of the constituent quark and the lifetime of the fireball, to what degree does quarkonium and in turn the heavy quarks equilibrate?• Depending on the flavor of the constituent quark and the lifetime of the fireball, to what degree does quarkonium and in turn the heavy quarks equilibrate?</p>
        <p>• What happens at the crossover transition, where individual colored partons need to come together to form color neutral hadrons?• What happens at the crossover transition, where individual colored partons need to come together to form color neutral hadrons?</p>
        <p>• How do the bound states formed at the crossover transition propagate in the hadronic phase, how are their stability properties modified? A true theory understanding of quarkonium in HICs requires a QCD based reply to all of the above, which at the same time should provide an efficient prescription to compute quantitative postdictions of the measured yields in current experiments. Vital insight has been already achieved and further progress is on the horizon based on the steady development of an effective field theory based real-time understanding of heavy-icon collisions. Combining a description of the initial stages of the collisions based on the color glass condensate, of thermalization and evolution of the light degrees of freedom via classical statistical simulations, kinetic theory and relativistic hydrodynamics, of the physics of heavy quarks via NRQCD and that of heavy quarkonium in the open quantum systems approach, all orchestrated in conjunction with the non-perturbative predictive power of lattice QCD bodes well for such an ambitious task to succeed in the next decade.• How do the bound states formed at the crossover transition propagate in the hadronic phase, how are their stability properties modified? A true theory understanding of quarkonium in HICs requires a QCD based reply to all of the above, which at the same time should provide an efficient prescription to compute quantitative postdictions of the measured yields in current experiments. Vital insight has been already achieved and further progress is on the horizon based on the steady development of an effective field theory based real-time understanding of heavy-icon collisions. Combining a description of the initial stages of the collisions based on the color glass condensate, of thermalization and evolution of the light degrees of freedom via classical statistical simulations, kinetic theory and relativistic hydrodynamics, of the physics of heavy quarks via NRQCD and that of heavy quarkonium in the open quantum systems approach, all orchestrated in conjunction with the non-perturbative predictive power of lattice QCD bodes well for such an ambitious task to succeed in the next decade.</p>
        <p>As a first step one can consider the process of quarkonium production in the absence of a hot medium (for details see e.g. Chap. 2 of Ref. [352]). This area of study has a long history and is still actively pursued both experimentally and theoretically in proton-proton and proton-nucleus collisions at current collider facilities. Quarkonium in p + p collisions constitutes a fascinating subject by itself which allows us to learn e.g. about the complex inner structure of nucleons, as well as the intricate dynamics of hadronization. Its understanding also forms the basis for developing insight into the production process in more complex scenarios such as proton-nucleus and nucleus-nucleus collisions.As a first step one can consider the process of quarkonium production in the absence of a hot medium (for details see e.g. Chap. 2 of Ref. [352]). This area of study has a long history and is still actively pursued both experimentally and theoretically in proton-proton and proton-nucleus collisions at current collider facilities. Quarkonium in p + p collisions constitutes a fascinating subject by itself which allows us to learn e.g. about the complex inner structure of nucleons, as well as the intricate dynamics of hadronization. Its understanding also forms the basis for developing insight into the production process in more complex scenarios such as proton-nucleus and nucleus-nucleus collisions.</p>
        <p>Let us clarify what one actually refers to when talking about quarkonium production. The so called inclusive production contains two independent contributions, prompt and non-prompt. As sketched on the leftmost panel of Fig. 46, for the example of the charmonium ground state J/ψ . The prompt contribution consists of both directly produced J/ψ and those that follow from feed-down from excited states ψ ′ as well as P-wave states χ c . On the other hand the non-prompt contribution refers to J/ψ that results from the decay of B mesons that initially formed in the collision.Let us clarify what one actually refers to when talking about quarkonium production. The so called inclusive production contains two independent contributions, prompt and non-prompt. As sketched on the leftmost panel of Fig. 46, for the example of the charmonium ground state J/ψ . The prompt contribution consists of both directly produced J/ψ and those that follow from feed-down from excited states ψ ′ as well as P-wave states χ c . On the other hand the non-prompt contribution refers to J/ψ that results from the decay of B mesons that initially formed in the collision.</p>
        <p>In general the production of quarkonium only constitutes a small fraction of all mesons that arise from the production of a heavy quark-antiquark pair. As indicated in the second panel from the left in Fig. 46 mostly open heavy flavor mesons emerge from the collision. Even the formation of Baryons with one heavy quark component constitutes a larger share than that of actual quarkonium. If one wishes to understand the yields of the quarkonium ground states, one further needs to understand the feed-down contributions from excited states, which, depending on the transverse momentum involved, actually differ significantly as illustrated in the two right panels of Fig. 46. The corresponding charts for Bottomonium including in particular the recent measurements by the LHCb collaboration can be found in Ref. [352].In general the production of quarkonium only constitutes a small fraction of all mesons that arise from the production of a heavy quark-antiquark pair. As indicated in the second panel from the left in Fig. 46 mostly open heavy flavor mesons emerge from the collision. Even the formation of Baryons with one heavy quark component constitutes a larger share than that of actual quarkonium. If one wishes to understand the yields of the quarkonium ground states, one further needs to understand the feed-down contributions from excited states, which, depending on the transverse momentum involved, actually differ significantly as illustrated in the two right panels of Fig. 46. The corresponding charts for Bottomonium including in particular the recent measurements by the LHCb collaboration can be found in Ref. [352].</p>
        <p>The theory understanding of the physics of the production process benefits from the presence of a separation of scales between the hard scale of the heavy quark rest mass and the correspondingly large momenta of the partons in the projectiles, as well as lower scales, such as Λ QCD and the binding energies of quarkonium states. In turn the overall production process can be considered as factorized between individual subprocesses, i.e. the production of a heavy quark and the subsequent formation of color neutral hadrons as indicated in Fig. 47. Theory has seen significant progress and success in studying quarkonium production over the past decades, the question of quarkonium polarization however remains a challenging topic.The theory understanding of the physics of the production process benefits from the presence of a separation of scales between the hard scale of the heavy quark rest mass and the correspondingly large momenta of the partons in the projectiles, as well as lower scales, such as Λ QCD and the binding energies of quarkonium states. In turn the overall production process can be considered as factorized between individual subprocesses, i.e. the production of a heavy quark and the subsequent formation of color neutral hadrons as indicated in Fig. 47. Theory has seen significant progress and success in studying quarkonium production over the past decades, the question of quarkonium polarization however remains a challenging topic.</p>
        <p>The first step consists of understanding how the heavy quarks come into being. The main ingredient is the presence of highly energetic partons in the proton projectiles, which may scatter off of each other to produce a heavy quark-antiquark pair. The four most relevant processes in this regard are shown in Fig. 48, consisting of s-channel and t-channel flavor production, as well as gluon splitting and flavor excitation. At the end of the interaction a Q Q [n] pair in any of n possible states emerges, which may possess large relative, as well as center of mass momentum. Due to the heavy quark mass being much larger than Λ QCD it might appear that the production of the heavy quark pair is a purely perturbative issue. However we must not forget that the gluons were actually part of a proton, whose highly non-perturbative parton distribution functions F p i (q) tell us how probable it is that a gluon with a certain momentum takes part in the scattering process. The cross section σ pp→Q Q [n]+X to produce the Q Q from a p + p collision, can actually be approximated to a good degree as a product over the genuinely perturbative cross-section for each of the gluon scattering processes and the gluon distribution functions F p g (q)The first step consists of understanding how the heavy quarks come into being. The main ingredient is the presence of highly energetic partons in the proton projectiles, which may scatter off of each other to produce a heavy quark-antiquark pair. The four most relevant processes in this regard are shown in Fig. 48, consisting of s-channel and t-channel flavor production, as well as gluon splitting and flavor excitation. At the end of the interaction a Q Q [n] pair in any of n possible states emerges, which may possess large relative, as well as center of mass momentum. Due to the heavy quark mass being much larger than Λ QCD it might appear that the production of the heavy quark pair is a purely perturbative issue. However we must not forget that the gluons were actually part of a proton, whose highly non-perturbative parton distribution functions F p i (q) tell us how probable it is that a gluon with a certain momentum takes part in the scattering process. The cross section σ pp→Q Q [n]+X to produce the Q Q from a p + p collision, can actually be approximated to a good degree as a product over the genuinely perturbative cross-section for each of the gluon scattering processes and the gluon distribution functions F p g (q)</p>
        <p>2 ) • σ gg→Q Q [n]+X ′ (q 1 , q 2 ).2 ) • σ gg→Q Q [n]+X ′ (q 1 , q 2 ).</p>
        <p>((</p>
        <p>The information about the distribution of momenta among the partons within a proton has been studied thoroughly via deep inelastic scattering. Its computation from first principles lattice QCD on the other hand is an active field of research.The information about the distribution of momenta among the partons within a proton has been studied thoroughly via deep inelastic scattering. Its computation from first principles lattice QCD on the other hand is an active field of research.</p>
        <p>The second step is to consider how the in general color charged Q Q pair actually forms a color neutral quarkonium denoted here by H [36]. Again one benefits from an approximate factorization between the production and the formation stageThe second step is to consider how the in general color charged Q Q pair actually forms a color neutral quarkonium denoted here by H [36]. Again one benefits from an approximate factorization between the production and the formation stage</p>
        <p>where Π denotes an appropriate integration over the phase space of the quark-antiquark pair and M refers to the matrix element of producing the hadronwhere Π denotes an appropriate integration over the phase space of the quark-antiquark pair and M refers to the matrix element of producing the hadron</p>
        <p>Here X denotes any other hadron and K appropriate combinations of color and spin matrices, depending on the stateHere X denotes any other hadron and K appropriate combinations of color and spin matrices, depending on the state</p>
        <p>Modeling the formation process has a long history starting from the color singlet model (CSM) and the more recent color evaporation model (CEM). In the former one assumes that a color neutral quarkonium can only arise from an originally color singlet quark-antiquark pair. Further, one neglects the relative momentum between the heavy quarks essentially considering the Q Q being born at rest on top of each other. Then the radial wavefunction of the quarkonium at the origin R H (0) can be used to estimate the production cross sectionModeling the formation process has a long history starting from the color singlet model (CSM) and the more recent color evaporation model (CEM). In the former one assumes that a color neutral quarkonium can only arise from an originally color singlet quark-antiquark pair. Further, one neglects the relative momentum between the heavy quarks essentially considering the Q Q being born at rest on top of each other. Then the radial wavefunction of the quarkonium at the origin R H (0) can be used to estimate the production cross section</p>
        <p>In this form the CSM, when applied to S-wave states, corresponds to the lowest order approximation of NRQCD, i.e. to the leading order in the heavy quark velocity v.In this form the CSM, when applied to S-wave states, corresponds to the lowest order approximation of NRQCD, i.e. to the leading order in the heavy quark velocity v.</p>
        <p>In the CEM on the other hand each Q Q pair is assigned the same probability to form a quarkonium, as long as the invariant mass of the quark pair is less than that of the meson H. The probability for each meson is contained in a model parameter F HIn the CEM on the other hand each Q Q pair is assigned the same probability to form a quarkonium, as long as the invariant mass of the quark pair is less than that of the meson H. The probability for each meson is contained in a model parameter F H</p>
        <p>The CEM is able to provide a reasonably good reproduction of e.g. J/ψ production at LHC and it is actively further developed to improve quantitative agreement with data, also in the case of bottomonium. For recent developments see e.g. Refs. [353][354][355], where both the agreement with the measured p T dependence of J/ψ as well as an improved postdiction of the ψ ′ yields have been achieved. In turn the first computation of the explicit p T dependence of the ψ ′ to J/ψ ratio in the context of the CEM was presented.The CEM is able to provide a reasonably good reproduction of e.g. J/ψ production at LHC and it is actively further developed to improve quantitative agreement with data, also in the case of bottomonium. For recent developments see e.g. Refs. [353][354][355], where both the agreement with the measured p T dependence of J/ψ as well as an improved postdiction of the ψ ′ yields have been achieved. In turn the first computation of the explicit p T dependence of the ψ ′ to J/ψ ratio in the context of the CEM was presented.</p>
        <p>The NRQCD approach is based on a systematic power counting in terms of the heavy quark velocity v, which includes contributions in particular from color octet states. At large enough transverse momenta, where the NRQCD scale separation is expected to be valid, one can write the cross section as a sumThe NRQCD approach is based on a systematic power counting in terms of the heavy quark velocity v, which includes contributions in particular from color octet states. At large enough transverse momenta, where the NRQCD scale separation is expected to be valid, one can write the cross section as a sum</p>
        <p>where the operators O n H are obtained from the four fermion interactions of NRQCDwhere the operators O n H are obtained from the four fermion interactions of NRQCD</p>
        <p>and contain the creation and annihilation operators of the hadron, as well as the NRQCD heavy quark ψ and antiquark fields χ. For a more detailed discussion and the explicit form of the operators in NRQCD the reader is referred toand contain the creation and annihilation operators of the hadron, as well as the NRQCD heavy quark ψ and antiquark fields χ. For a more detailed discussion and the explicit form of the operators in NRQCD the reader is referred to</p>
        <p>Refs. [36,356,357].Refs. [36,356,357].</p>
        <p>One recent interesting development in the context of quarkonium production is the extension of the NRQCD approach to transverse momenta lower than 5 GeV. Ref. [358] proposes to combine heavy quark effective field theory matrix elements with a color glass condensate model to approximate the gluon distributions in the proton projectiles, leading to good agreement with data also for the challenging subject of quarkonium polarization [359]. One finds a smooth overlap region of these new results with the standard NLO NRQCD at high p T .One recent interesting development in the context of quarkonium production is the extension of the NRQCD approach to transverse momenta lower than 5 GeV. Ref. [358] proposes to combine heavy quark effective field theory matrix elements with a color glass condensate model to approximate the gluon distributions in the proton projectiles, leading to good agreement with data also for the challenging subject of quarkonium polarization [359]. One finds a smooth overlap region of these new results with the standard NLO NRQCD at high p T .</p>
        <p>After gaining a first taste of quarkonium production in p + p collisions let us touch on the next more complex scenario of proton-nucleus collisions. Here one wishes to learn about so called cold nuclear matter effects, which may affect quarkonium production also in a heavy-ion collision. A comprehensive overview of this topic may be found in Refs. [360][361][362] and chapter 3 of Ref. [352], a collection of recent results in Ref. [363].After gaining a first taste of quarkonium production in p + p collisions let us touch on the next more complex scenario of proton-nucleus collisions. Here one wishes to learn about so called cold nuclear matter effects, which may affect quarkonium production also in a heavy-ion collision. A comprehensive overview of this topic may be found in Refs. [360][361][362] and chapter 3 of Ref. [352], a collection of recent results in Ref. [363].</p>
        <p>Experimentally one expresses the deviations in measured yields between a p+p collision and any other type of collision involving a nucleus, be it p + A or A + A, with the nuclear modification factorExperimentally one expresses the deviations in measured yields between a p+p collision and any other type of collision involving a nucleus, be it p + A or A + A, with the nuclear modification factor</p>
        <p>where the prefactor including the number of binary collisions simply acts as a normalization. If the physics in a collision involving a nucleus were simply that of a large number individual p + p collisions this ratio would stay at unity.where the prefactor including the number of binary collisions simply acts as a normalization. If the physics in a collision involving a nucleus were simply that of a large number individual p + p collisions this ratio would stay at unity.</p>
        <p>A natural distinction lies between effects which affect the initial-state and the final state. The former are related to differences in the parton composition of nuclei as compared to protons. The latter on the other hand arise from the fact that quarkonium states produced in p + A and A + A collisions may find themselves within a nuclear environment or surrounded by collision fragments, which destabilize the quark-antiquark bound state.A natural distinction lies between effects which affect the initial-state and the final state. The former are related to differences in the parton composition of nuclei as compared to protons. The latter on the other hand arise from the fact that quarkonium states produced in p + A and A + A collisions may find themselves within a nuclear environment or surrounded by collision fragments, which destabilize the quark-antiquark bound state.</p>
        <p>The study of parton distribution functions in nuclei is an active research area (for a recent brief overview see e.g. Ref. [365]), which to date relies on an interplay between theory and experiment to extract from measured yields constraints on the momentum fraction carried by quarks and gluons in nucleons embedded in a nucleus. As shown in Fig. 49 three generic features emerge: at small values of the parton momentum fraction x &lt; 10 -2 the ratio of nuclear to free parton distribution functionThe study of parton distribution functions in nuclei is an active research area (for a recent brief overview see e.g. Ref. [365]), which to date relies on an interplay between theory and experiment to extract from measured yields constraints on the momentum fraction carried by quarks and gluons in nucleons embedded in a nucleus. As shown in Fig. 49 three generic features emerge: at small values of the parton momentum fraction x &lt; 10 -2 the ratio of nuclear to free parton distribution function</p>
        <p>takes on values smaller than unity, a feature referred to as small-x shadowing. At intermediate x ≲ 0.1 on the other hand the ratio shows a hump-like structure, which is simply called anti-shadowing, followed by a dip at x ≈ 0.6 which was first identified by the EMC collaboration and thus has been christened the EMC effect. There are many different nuclear PDFs on the market that differ in the theory input, as well as the fitting procedure to experimental data, among them EPS09, nCTEQ15 or EPPS16.takes on values smaller than unity, a feature referred to as small-x shadowing. At intermediate x ≲ 0.1 on the other hand the ratio shows a hump-like structure, which is simply called anti-shadowing, followed by a dip at x ≈ 0.6 which was first identified by the EMC collaboration and thus has been christened the EMC effect. There are many different nuclear PDFs on the market that differ in the theory input, as well as the fitting procedure to experimental data, among them EPS09, nCTEQ15 or EPPS16.</p>
        <p>We may now ask how the modification of the nuclear PDF's affects the production of the individual quarkonium states.We may now ask how the modification of the nuclear PDF's affects the production of the individual quarkonium states.</p>
        <p>I.e. we ask how the nuclear modification factor R pA differs from unity. When evaluating J/ψ and Υ production in p -Pb collisions at √ s = 5 TeV the modified PDF's predict [360] a suppression of around 10% for b b and 20% for c c. It is here that we encounter for the first time the notion of quarkonium suppression. At this point this suppression is not related to the presence of a hot medium and simply reflects changes in the initial projectile. Obviously these numbers need to be kept in mind when investigating production patterns observed in nucleus-nucleus collisions, in order to correctly disentangle the possible effects of a hot QCD medium from those arising from cold-nuclear matter.I.e. we ask how the nuclear modification factor R pA differs from unity. When evaluating J/ψ and Υ production in p -Pb collisions at √ s = 5 TeV the modified PDF's predict [360] a suppression of around 10% for b b and 20% for c c. It is here that we encounter for the first time the notion of quarkonium suppression. At this point this suppression is not related to the presence of a hot medium and simply reflects changes in the initial projectile. Obviously these numbers need to be kept in mind when investigating production patterns observed in nucleus-nucleus collisions, in order to correctly disentangle the possible effects of a hot QCD medium from those arising from cold-nuclear matter.</p>
        <p>On the theory side, the color glass condensate approach [366] is used to explore how the phenomenon of parton saturation affects the dynamics of partons within nuclei [367][368][369][370]. Already in an individual proton, the parton distribution function at large Q 2 but small x is expected not to grow indefinitely but to eventually saturate at the eponymous saturation scale Q s , due to nonlinear effects of many self interacting gluons. As the saturation effect depends on the number A of nucleons present, it is expected that its physics needs to be accounted for in detail if quarkonium production is to be understood in a heavy-ion collision. Eventually the goal for theory has to be to compute nuclear parton distribution functions from first principles, which at the moment however is still computationally unfeasible.On the theory side, the color glass condensate approach [366] is used to explore how the phenomenon of parton saturation affects the dynamics of partons within nuclei [367][368][369][370]. Already in an individual proton, the parton distribution function at large Q 2 but small x is expected not to grow indefinitely but to eventually saturate at the eponymous saturation scale Q s , due to nonlinear effects of many self interacting gluons. As the saturation effect depends on the number A of nucleons present, it is expected that its physics needs to be accounted for in detail if quarkonium production is to be understood in a heavy-ion collision. Eventually the goal for theory has to be to compute nuclear parton distribution functions from first principles, which at the moment however is still computationally unfeasible.</p>
        <p>There are many different phenomenological approaches proposed to describe the final state interactions. At low enough energies, where quarkonium formation may actually take place within the projectile nucleus volume, the bound state may interact with remnants of the nuclear environment leading to its destabilization. Such a scenario, which is considered for SPS beam energies but due to the Lorentz contraction of the nuclei at LHC is unlikely to be of relevance there, is referred to as nuclear absorption or nuclear break-up. On the other hand for LHC energies the effects of coherent energy loss have been discussed originally in Ref. [371], which lead to a suppression of yields compatible with the data and which do not require any modification on the nuclear PDFs. It remains an interesting question of how to reconcile these final state results with the present understanding of nuclear PDFs.There are many different phenomenological approaches proposed to describe the final state interactions. At low enough energies, where quarkonium formation may actually take place within the projectile nucleus volume, the bound state may interact with remnants of the nuclear environment leading to its destabilization. Such a scenario, which is considered for SPS beam energies but due to the Lorentz contraction of the nuclei at LHC is unlikely to be of relevance there, is referred to as nuclear absorption or nuclear break-up. On the other hand for LHC energies the effects of coherent energy loss have been discussed originally in Ref. [371], which lead to a suppression of yields compatible with the data and which do not require any modification on the nuclear PDFs. It remains an interesting question of how to reconcile these final state results with the present understanding of nuclear PDFs.</p>
        <p>Interestingly the above mentioned initial state effects, as well as coherent energy loss are expected to affect the ground state and final state in an equal fashion. It has however been observed that the excited states of bottomonium and charmonium in p + A collisions suffer from a stronger suppression than the ground states. While at low energies this might be explained by nuclear absorption effects, at LHC energies the comover interaction model [372,373] has been proposed and successfully describes this phenomenon. The idea is that the quarkonium state scatters with particles that possess a similar rapidity traveling in its vicinity. Their effects is modeled by a rate equation, which is similar to the treatment in terms of a transport model in [313] and the final-state interactions in recent computations based on the color-glass condensate and improved color evaporation model in Ref. [374].Interestingly the above mentioned initial state effects, as well as coherent energy loss are expected to affect the ground state and final state in an equal fashion. It has however been observed that the excited states of bottomonium and charmonium in p + A collisions suffer from a stronger suppression than the ground states. While at low energies this might be explained by nuclear absorption effects, at LHC energies the comover interaction model [372,373] has been proposed and successfully describes this phenomenon. The idea is that the quarkonium state scatters with particles that possess a similar rapidity traveling in its vicinity. Their effects is modeled by a rate equation, which is similar to the treatment in terms of a transport model in [313] and the final-state interactions in recent computations based on the color-glass condensate and improved color evaporation model in Ref. [374].</p>
        <p>It is important to note that while theory progress has been made in regards to understanding initial state effects in proton-nucleus collisions the question of how cold nuclear matter affects quarkonium production in a nucleus-nucleus collision remains a central open question. Vital insight will be gained on the experimental side with the arrival of electronion colliders, which will be able to shed light on the parton distribution functions within nuclei with unprecedented precision. On the theory side the question for saturation based computations is how elevate the computations currently carried out for a dilute-dense scenario into the dense-dense sector, relevant for heavy-ion collisions. At the same time it needs to be understood whether and if so how the factorization of subprocesses, a vital tool to make quarkonium production tractable in p + p and p + A collisions, survives in a nucleus-nucleus collision.It is important to note that while theory progress has been made in regards to understanding initial state effects in proton-nucleus collisions the question of how cold nuclear matter affects quarkonium production in a nucleus-nucleus collision remains a central open question. Vital insight will be gained on the experimental side with the arrival of electronion colliders, which will be able to shed light on the parton distribution functions within nuclei with unprecedented precision. On the theory side the question for saturation based computations is how elevate the computations currently carried out for a dilute-dense scenario into the dense-dense sector, relevant for heavy-ion collisions. At the same time it needs to be understood whether and if so how the factorization of subprocesses, a vital tool to make quarkonium production tractable in p + p and p + A collisions, survives in a nucleus-nucleus collision.</p>
        <p>Besides the modification of how partons in nuclei interact to form a Q Q pair, the evolution of such a colored state in the background of highly occupied soft gauge fields in the initial glasma phase of a heavy-ion collisions needs to be elucidated. Classical statistical simulations of the gauge field sector in conjunction with kinetic theory have proven insightful to understand the emergence of hydrodynamical behavior of the bulk matter (see e.g. Refs. [375][376][377]). Combining such a glasma inspired real-time framework with the effective field theory NRQCD is currently considered, to gain new insight how quarkonium formation in the early stages of a nucleus-nucleus collision proceeds. The goal of this and the preceding subsection is to serve as a reminder that a comprehensive understanding of quarkonium in a heavy-ion collisions relies on an interplay of many different physical mechanisms, many of which are not directly related to quarkonium in a hot medium, but still offer ample opportunity for first principle theory to contribute. At the same time some of the effects discussed above may directly affect e.g. the initial conditions from which a real-time simulation of heavy-quarkonium in a hot environment commences. Hence a lively exchange between the communities working on cold and hot nuclear matter effects will be essential to progress towards a genuine microscopic understanding of the physics involved in producing quarkonium states in a heavy-ion collision.Besides the modification of how partons in nuclei interact to form a Q Q pair, the evolution of such a colored state in the background of highly occupied soft gauge fields in the initial glasma phase of a heavy-ion collisions needs to be elucidated. Classical statistical simulations of the gauge field sector in conjunction with kinetic theory have proven insightful to understand the emergence of hydrodynamical behavior of the bulk matter (see e.g. Refs. [375][376][377]). Combining such a glasma inspired real-time framework with the effective field theory NRQCD is currently considered, to gain new insight how quarkonium formation in the early stages of a nucleus-nucleus collision proceeds. The goal of this and the preceding subsection is to serve as a reminder that a comprehensive understanding of quarkonium in a heavy-ion collisions relies on an interplay of many different physical mechanisms, many of which are not directly related to quarkonium in a hot medium, but still offer ample opportunity for first principle theory to contribute. At the same time some of the effects discussed above may directly affect e.g. the initial conditions from which a real-time simulation of heavy-quarkonium in a hot environment commences. Hence a lively exchange between the communities working on cold and hot nuclear matter effects will be essential to progress towards a genuine microscopic understanding of the physics involved in producing quarkonium states in a heavy-ion collision.</p>
        <p>In this section we arrive at the ultimate challenge for current studies of quarkonium in extreme conditions, i.e. gaining a truly microscopic understanding of its production in relativistic heavy-collisions. As we have discussed in the previous sections, this task consists of many elements besides describing quarkonium dynamics in a hot medium. Both the realtime evolution of quarkonium states discussed in Section 4 and their properties in equilibrium discussed in Section 3 constitute central pieces of the puzzle without which no comprehensive picture of their production can arise. At the same time a more detailed knowledge about the partonic make-up of the incoming projectile nuclei and a dynamical picture of hadronization are required to fully account for the observed phenomenology.In this section we arrive at the ultimate challenge for current studies of quarkonium in extreme conditions, i.e. gaining a truly microscopic understanding of its production in relativistic heavy-collisions. As we have discussed in the previous sections, this task consists of many elements besides describing quarkonium dynamics in a hot medium. Both the realtime evolution of quarkonium states discussed in Section 4 and their properties in equilibrium discussed in Section 3 constitute central pieces of the puzzle without which no comprehensive picture of their production can arise. At the same time a more detailed knowledge about the partonic make-up of the incoming projectile nuclei and a dynamical picture of hadronization are required to fully account for the observed phenomenology.</p>
        <p>Let us start with a discussion of charmonium. Its study in heavy-ion collisions presents an instructive tale about how only a comprehensive understanding of all stages of the collision can provide us with a full account of the physics of quarkonium production. The first steps towards elucidating charmonium in a heavy-ion collision were made in the context of quarkonium melting. I.e. the classic work of Matsui and Satz [13] considered the stability properties of charmonium in a thermal medium, concluding in a first step that the presence of a deconfined QGP will prevent the formation of in-medium bound states. Their arguments at that time were based on a static picture of quarkonium melting, its modern dynamical viewpoint has been discussed in Section 3.4. In general the higher the energy density of the medium, the more efficient the melting will be. At the same time the more weakly the charmonium state is bound in vacuum the more easily the medium will be able to dissolve it. We presented support for this concept of hierarchical ordering of in-medium effects from first principles computations in Section 3.3. Ref. [13] then goes on to argue in a second step that such a failure of binding will translate into a reduction of charmonium yields, i.e. into quarkonium suppression that follows a similar pattern as that of the in-medium melting. This scenario is known as sequential suppression and has been laid out in detail in [14]. From it follows that in central collisions and at small rapidities, i.e. where the density of medium scatterers is highest, the suppression should be strongest.Let us start with a discussion of charmonium. Its study in heavy-ion collisions presents an instructive tale about how only a comprehensive understanding of all stages of the collision can provide us with a full account of the physics of quarkonium production. The first steps towards elucidating charmonium in a heavy-ion collision were made in the context of quarkonium melting. I.e. the classic work of Matsui and Satz [13] considered the stability properties of charmonium in a thermal medium, concluding in a first step that the presence of a deconfined QGP will prevent the formation of in-medium bound states. Their arguments at that time were based on a static picture of quarkonium melting, its modern dynamical viewpoint has been discussed in Section 3.4. In general the higher the energy density of the medium, the more efficient the melting will be. At the same time the more weakly the charmonium state is bound in vacuum the more easily the medium will be able to dissolve it. We presented support for this concept of hierarchical ordering of in-medium effects from first principles computations in Section 3.3. Ref. [13] then goes on to argue in a second step that such a failure of binding will translate into a reduction of charmonium yields, i.e. into quarkonium suppression that follows a similar pattern as that of the in-medium melting. This scenario is known as sequential suppression and has been laid out in detail in [14]. From it follows that in central collisions and at small rapidities, i.e. where the density of medium scatterers is highest, the suppression should be strongest.</p>
        <p>The first conclusion on the hierarchical nature of quarkonium melting in its dynamical form remains valid also today, however it is now understood that suppression, especially at high beam energies does not follow automatically. The reason, as we understand it today, lies in both what happens before and what happens at the end of quark-gluon-plasma phase originally considered by Matsui and Satz. Indeed due to the cross section for charm anti-charm pairs rising steeply with collision energy a hotter plasma in practice is accompanied also with a higher abundance in c c pairs. Primordial bound states formed from these c c pairs due to the destabilizing effects of the plasma can melt. At the same time either already during the QGP phase or at hadronization different c c pairs can recombine again into charmonium pairs, thus replenishing the yields. This effect had been discussed by Matsui early on (see e.g. Ref. [20]) but at that time was discarded due to the small charm cross section accessible experimentally. Several years later with the advent of high energy machines, such as RHIC, on the horizon, regeneration was considered in more detail and it turns out to provide an important piece of the puzzle to understand charmonium production. It is important to note that for collision systems where the effects of regeneration are less important, e.g. at moderate to large p T , the R AA of different quarkonium species do follow a suppression pattern that is ordered with their in-medium binding energy. We will come back to this issue in the context of bottomonium later on.The first conclusion on the hierarchical nature of quarkonium melting in its dynamical form remains valid also today, however it is now understood that suppression, especially at high beam energies does not follow automatically. The reason, as we understand it today, lies in both what happens before and what happens at the end of quark-gluon-plasma phase originally considered by Matsui and Satz. Indeed due to the cross section for charm anti-charm pairs rising steeply with collision energy a hotter plasma in practice is accompanied also with a higher abundance in c c pairs. Primordial bound states formed from these c c pairs due to the destabilizing effects of the plasma can melt. At the same time either already during the QGP phase or at hadronization different c c pairs can recombine again into charmonium pairs, thus replenishing the yields. This effect had been discussed by Matsui early on (see e.g. Ref. [20]) but at that time was discarded due to the small charm cross section accessible experimentally. Several years later with the advent of high energy machines, such as RHIC, on the horizon, regeneration was considered in more detail and it turns out to provide an important piece of the puzzle to understand charmonium production. It is important to note that for collision systems where the effects of regeneration are less important, e.g. at moderate to large p T , the R AA of different quarkonium species do follow a suppression pattern that is ordered with their in-medium binding energy. We will come back to this issue in the context of bottomonium later on.</p>
        <p>In Fig. 50 we showcase a selection of experimental measurements of charmonium from heavy ion collision history, which have been instrumental in pushing forward our understanding of quarkonium production, as well as to spur advances in the development of phenomenological approaches. The quantity we show is the nuclear modification factor R AA for the J/ψ particle. In the leftmost panel R AA from the NA60 and NA49 experiments at SPS and from the 
            <rs type="software">PHENIX</rs> experiment at RHIC are compared. Note that x-axis shows the charged particle multiplicity, which is used instead of the historic choice of number of participants to indicate the activity in the collision center (allowing us to make sense of e.g. signals for bulk collectivity even in pp collisions at high multiplicity). The values plotted are divided by the predictions for cold nuclear matter effects. While in In + In collisions at SPS with √ s NN = 158 GeV only relatively small multiplicities are reached that do not show any suppression beyond cold nuclear matter effects, with the advent of Pb + Pb at SPS a clear additional suppression has been registered. Extending the energy range to
        </p>
        <p>s NN = 200 GeV at RHIC with Au + Au collisions even higher multiplicities are reached and the suppression trend continues. Historically the expectation was that the suppression at RHIC should be stronger than that at SPS, due to the higher beam energies and thus temperatures involved. The question is, can we find indications why the suppression might not increase further? To this end let us take a look at the center panel of Fig. 50, where the rapidity dependence of R AA (without division by the CNM baseline) is plotted as measured by the PHENIX collaboration at RHIC. In non-central collisions (bottom row) we find a pattern consistent with both arguments from comovers and medium induced melting. I.e. at y = 0 where the density of potential scatterers is highest the R AA is lowest. On the other hand in more central collisions (top row) the pattern inverts and R AA takes on the largest value at y = 0. As we will discuss in more quantitative detail below, this effect is what one would expect when regeneration plays a role in the production dynamics. I.e. at y = 0 the largest number of c c pairs is created and will thus lead to the largest recombination probability, in effect overcoming the effects from melting of primordial charmonium pairs. That regeneration plays an important role to describe the measured yields at increasing beam energies is further supported by the measurements of R AA by the ALICE collaboration at LHC, shown in the right most panel of Fig. 50. Compared along multiplicities, we see that at As a lot of intuition on quarkonium production originally arose from considering idealized settings in kinetic thermal equilibrium. The question of how efficiently the charm quarks exchange energy and momentum with their surrounding is e.g. of central interest. One possibility to infer this is to look for signs of the produced charmonium to participate in the collective motion of the bulk matter, expressed e.g. in a finite value of elliptic flow v 2 for J/ψ . Finite values of v 2 would indicate that the charm quarks are in at least partial kinetic equilibrium with their surroundings, which in turn entails a loss of memory of the initial conditions their evolution. In Fig. 51 we show measurements of said v 2 by the STAR collaboration at RHIC √ s NN = 0.2 GeV from Ref. [381] on the left and from the ALICE collaboration at LHC √ s NN = 5.02 TeV from Ref. [382] on the right. While at the lower beam energies no significant deviation of v 2 from zero was observed by STAR, the situation significantly changes at LHC, where an elliptic flow of around 50% of that of D-mesons has been reported by the ALICE collaboration. In turn we expect that arguments based on thermal equilibrium are a reasonable starting point to develop an understanding of charmonium at LHC. After this very rough survey of charmonium measurements and their qualitative discussion let us turn to more quantitative means of describing charmonium production. While the ultimate goal for theory is to provide a microscopic description from the initial c c pair production over their real-time evolution to dynamical hadronization, such an ambitious framework has yet to be developed. In the meantime it is very instructive to consider what already has been learned about charmonium from describing its production using phenomenological models.s NN = 200 GeV at RHIC with Au + Au collisions even higher multiplicities are reached and the suppression trend continues. Historically the expectation was that the suppression at RHIC should be stronger than that at SPS, due to the higher beam energies and thus temperatures involved. The question is, can we find indications why the suppression might not increase further? To this end let us take a look at the center panel of Fig. 50, where the rapidity dependence of R AA (without division by the CNM baseline) is plotted as measured by the PHENIX collaboration at RHIC. In non-central collisions (bottom row) we find a pattern consistent with both arguments from comovers and medium induced melting. I.e. at y = 0 where the density of potential scatterers is highest the R AA is lowest. On the other hand in more central collisions (top row) the pattern inverts and R AA takes on the largest value at y = 0. As we will discuss in more quantitative detail below, this effect is what one would expect when regeneration plays a role in the production dynamics. I.e. at y = 0 the largest number of c c pairs is created and will thus lead to the largest recombination probability, in effect overcoming the effects from melting of primordial charmonium pairs. That regeneration plays an important role to describe the measured yields at increasing beam energies is further supported by the measurements of R AA by the ALICE collaboration at LHC, shown in the right most panel of Fig. 50. Compared along multiplicities, we see that at As a lot of intuition on quarkonium production originally arose from considering idealized settings in kinetic thermal equilibrium. The question of how efficiently the charm quarks exchange energy and momentum with their surrounding is e.g. of central interest. One possibility to infer this is to look for signs of the produced charmonium to participate in the collective motion of the bulk matter, expressed e.g. in a finite value of elliptic flow v 2 for J/ψ . Finite values of v 2 would indicate that the charm quarks are in at least partial kinetic equilibrium with their surroundings, which in turn entails a loss of memory of the initial conditions their evolution. In Fig. 51 we show measurements of said v 2 by the STAR collaboration at RHIC √ s NN = 0.2 GeV from Ref. [381] on the left and from the ALICE collaboration at LHC √ s NN = 5.02 TeV from Ref. [382] on the right. While at the lower beam energies no significant deviation of v 2 from zero was observed by STAR, the situation significantly changes at LHC, where an elliptic flow of around 50% of that of D-mesons has been reported by the ALICE collaboration. In turn we expect that arguments based on thermal equilibrium are a reasonable starting point to develop an understanding of charmonium at LHC. After this very rough survey of charmonium measurements and their qualitative discussion let us turn to more quantitative means of describing charmonium production. While the ultimate goal for theory is to provide a microscopic description from the initial c c pair production over their real-time evolution to dynamical hadronization, such an ambitious framework has yet to be developed. In the meantime it is very instructive to consider what already has been learned about charmonium from describing its production using phenomenological models.</p>
        <p>As starting point we can return to the question of why we distinguish heavy quarkonium production from the physics of other lighter flavors. The reason lies in the separation of scales present. In the collider experiments conducted so far, starting at SPS, followed by RHIC and currently at LHC, the temperatures reached in the collision center, as deduced by modeling of the hydrodynamic expansion of the bulk medium, are at maximum T max ≈ 600 MeV and thus much smaller than the charm quark mass. In turn it is consensus that heavy quark pairs are created only in the early stages of the collision and their number remains approximately constant over the short time scales in which a hot medium may form in the collision center. I.e. in a contemporary heavy-ion collision heavy quarks are not chemically equilibrated and their production yields must be understood with this fact in mind.As starting point we can return to the question of why we distinguish heavy quarkonium production from the physics of other lighter flavors. The reason lies in the separation of scales present. In the collider experiments conducted so far, starting at SPS, followed by RHIC and currently at LHC, the temperatures reached in the collision center, as deduced by modeling of the hydrodynamic expansion of the bulk medium, are at maximum T max ≈ 600 MeV and thus much smaller than the charm quark mass. In turn it is consensus that heavy quark pairs are created only in the early stages of the collision and their number remains approximately constant over the short time scales in which a hot medium may form in the collision center. I.e. in a contemporary heavy-ion collision heavy quarks are not chemically equilibrated and their production yields must be understood with this fact in mind.</p>
        <p>Experimental data backs up this reasoning when scrutinized through the lens of hadron resonance gas based models, most prominently the statistical hadronization model first introduced in Refs. [18,19] and reviewed in Ref. [383]. Let us take a closer look what this model can tell us about equilibration of light and heavy degrees of freedom in heavy-ion collisions (see e.g. Refs. [379,384]). The model is based on the grand canonical partition function expressed in terms of an ideal, i.e. non-interacting, gas of hadronic degrees of freedom. Remember that for an ideal quantum gas in the occupation number representation the partition function factorizesExperimental data backs up this reasoning when scrutinized through the lens of hadron resonance gas based models, most prominently the statistical hadronization model first introduced in Refs. [18,19] and reviewed in Ref. [383]. Let us take a closer look what this model can tell us about equilibration of light and heavy degrees of freedom in heavy-ion collisions (see e.g. Refs. [379,384]). The model is based on the grand canonical partition function expressed in terms of an ideal, i.e. non-interacting, gas of hadronic degrees of freedom. Remember that for an ideal quantum gas in the occupation number representation the partition function factorizes</p>
        <p>with the upper sign for bosons and the lower ones for fermions. Here ϵ(p) denotes the energy of the eigenmodes of the Hamiltonian H with momentum p and n p refers to the corresponding occupation number of that mode. The chemical potentials µ i refer to possible conserved charges q i that the modes carry. In our case what we call modes of the Hamiltonian will be the different hadrons and their excitations that are present in the low temperature phase of QCDwith the upper sign for bosons and the lower ones for fermions. Here ϵ(p) denotes the energy of the eigenmodes of the Hamiltonian H with momentum p and n p refers to the corresponding occupation number of that mode. The chemical potentials µ i refer to possible conserved charges q i that the modes carry. In our case what we call modes of the Hamiltonian will be the different hadrons and their excitations that are present in the low temperature phase of QCD</p>
        <p>Here m i is taken to be the vacuum mass of these states, as temperature effects are implemented via the trace over the thermal density matrix. The conserved charges to which a chemical potential is assigned are strangeness (S, µ s ), baryon number (B, µ B ) and the third component of the isospin charge (I 3 , µ I 3 ). In a heavy ion collision with projectiles consisting of protons and neutrons, the overall system has to follow the constraintsHere m i is taken to be the vacuum mass of these states, as temperature effects are implemented via the trace over the thermal density matrix. The conserved charges to which a chemical potential is assigned are strangeness (S, µ s ), baryon number (B, µ B ) and the third component of the isospin charge (I 3 , µ I 3 ). In a heavy ion collision with projectiles consisting of protons and neutrons, the overall system has to follow the constraints</p>
        <p>The power of hadron resonance gas models lies in the fact that all the non-perturbative information on the strong interactions is included in the values of the masses of the individual contributing hadrons, which one usually takes from measurements cataloged by the PDG, amended by lattice QCD spectroscopy results. Below the crossover transition temperature it has been shown that the equation of state, i.e. the dependence of pressure on temperature arising from the hadron resonance gas model is in good agreement with first principles computations from lattice QCD, lending support to its construction (see e.g. Ref. [8]).The power of hadron resonance gas models lies in the fact that all the non-perturbative information on the strong interactions is included in the values of the masses of the individual contributing hadrons, which one usually takes from measurements cataloged by the PDG, amended by lattice QCD spectroscopy results. Below the crossover transition temperature it has been shown that the equation of state, i.e. the dependence of pressure on temperature arising from the hadron resonance gas model is in good agreement with first principles computations from lattice QCD, lending support to its construction (see e.g. Ref. [8]).</p>
        <p>after accounting for spin degeneracies with a factor g i , contributes with logafter accounting for spin degeneracies with a factor g i , contributes with log</p>
        <p>where the λ i takes on the role of a fugacity. This expression can be further rewritten by expanding the logarithm via itswhere the λ i takes on the role of a fugacity. This expression can be further rewritten by expanding the logarithm via its</p>
        <p>Taylor series and carrying out the momentum integral logTaylor series and carrying out the momentum integral log</p>
        <p>The function K 2 refers to the modified Bessel function. To arrive at the particle number densities at constant temperature and volume one exploits the equivalent definition of ⟨N⟩ from a derivative with respect to chemical potential ⟨N⟩ =The function K 2 refers to the modified Bessel function. To arrive at the particle number densities at constant temperature and volume one exploits the equivalent definition of ⟨N⟩ from a derivative with respect to chemical potential ⟨N⟩ =</p>
        <p>. Taking into account the physical constraints, the model thus predicts the particle number densities given three adjustable parameters, the temperature of the system, its volume and Baryo-chemical potential.. Taking into account the physical constraints, the model thus predicts the particle number densities given three adjustable parameters, the temperature of the system, its volume and Baryo-chemical potential.</p>
        <p>This basic formulation of the model can be amended to use another piece of non-perturbative information, which is the decay width of resonance hadronic states, that also contribute to the partition function. Their physics may be incorporated by translating the spectral width into a convolution over different masses in Eq. ( 280)This basic formulation of the model can be amended to use another piece of non-perturbative information, which is the decay width of resonance hadronic states, that also contribute to the partition function. Their physics may be incorporated by translating the spectral width into a convolution over different masses in Eq. ( 280)</p>
        <p>where N BW normalizes the integral over the Breit-Wigner to unity. The total number of particles measured in experiment furthermore needs to take into account decays of resonances so thatwhere N BW normalizes the integral over the Breit-Wigner to unity. The total number of particles measured in experiment furthermore needs to take into account decays of resonances so that</p>
        <p>Note that once the Baryo-chemical potential becomes large with respect to the temperature, some form of repulsive interactions are often included via an excluded volume prescription. A priori it is not clear, whether such a model will be able to describe the yields of hadrons composed of the light quarks u, d and s. It however has been shown in detailed comparisons with measurements ranging from AGS energies aroundNote that once the Baryo-chemical potential becomes large with respect to the temperature, some form of repulsive interactions are often included via an excluded volume prescription. A priori it is not clear, whether such a model will be able to describe the yields of hadrons composed of the light quarks u, d and s. It however has been shown in detailed comparisons with measurements ranging from AGS energies around</p>
        <p>76 TeV that in central heavy-ion collisions a remarkable agreement with a wide variety of particle and antiparticle yields can be achieved, ranging from pions up to Helium and anti-Helium (for a more detailed discussion, in particular also of the aspect of strangeness production see Refs. [379,384]). At lower beam energies some particle species seem to deviate from the model predictions, among them the proton and some kaons. At LHC energies only the protons show slightly less yields than predicted. Irrespective of the history of the matter in the collision center, at some point it must be possible to describe the end products of the collision in terms of a collection of hadrons, as these are the final measured degrees of freedom. The abundances of these hadrons are fixed at the so called chemical freezeout (see e.g. [385] and references therein) after which they may still change their momentum and energy via number preserving reactions such as e.g. ππ → ρ → ππ .76 TeV that in central heavy-ion collisions a remarkable agreement with a wide variety of particle and antiparticle yields can be achieved, ranging from pions up to Helium and anti-Helium (for a more detailed discussion, in particular also of the aspect of strangeness production see Refs. [379,384]). At lower beam energies some particle species seem to deviate from the model predictions, among them the proton and some kaons. At LHC energies only the protons show slightly less yields than predicted. Irrespective of the history of the matter in the collision center, at some point it must be possible to describe the end products of the collision in terms of a collection of hadrons, as these are the final measured degrees of freedom. The abundances of these hadrons are fixed at the so called chemical freezeout (see e.g. [385] and references therein) after which they may still change their momentum and energy via number preserving reactions such as e.g. ππ → ρ → ππ .</p>
        <p>In comparison, number changing processes in a hadron gas are expected to occur on much longer timescales (up to 100s of fm). Therefore the results by the statistical model are interesting as they tell us that the hadrons at freezeout already exhibit the abundances expected from a chemically equilibrated ensemble, even though the time passed since the collision would not allow for such equilibration to take place in a simple hadron gas. Therefore it has been suggested that the mechanism of hadron production itself can generate such abundances. The fact that hadron yields in pp and e + e -collisions can also be captured by essentially the same statistical model supports such a statistical picture of hadron formation at least for low energy heavy-ion collisions. (Recently ideas have been put forward that relate the thermal distribution of produced particles in elementary collisions to the entanglement between observable and non-observable patches of the light cone in Ref. [386].)In comparison, number changing processes in a hadron gas are expected to occur on much longer timescales (up to 100s of fm). Therefore the results by the statistical model are interesting as they tell us that the hadrons at freezeout already exhibit the abundances expected from a chemically equilibrated ensemble, even though the time passed since the collision would not allow for such equilibration to take place in a simple hadron gas. Therefore it has been suggested that the mechanism of hadron production itself can generate such abundances. The fact that hadron yields in pp and e + e -collisions can also be captured by essentially the same statistical model supports such a statistical picture of hadron formation at least for low energy heavy-ion collisions. (Recently ideas have been put forward that relate the thermal distribution of produced particles in elementary collisions to the entanglement between observable and non-observable patches of the light cone in Ref. [386].)</p>
        <p>The freezeout temperature as determined from the model fits rises with the beam energy until it saturates around a temperature that is suggestively close to the crossover transition temperature computed from first principles lattice QCD. Hence also from the point of view of the statistical model in current heavy-ion collisions at RHIC and LHC it is very likely that the matter in the collision center has actually persisted in a state of even higher temperatures shortly after the collision. The presence of deconfined quarks and gluons at that point would allow the bulk to more efficiently (locally) chemically and kinetically thermalize, so that at hadronization the grand canonical abundances are reached.The freezeout temperature as determined from the model fits rises with the beam energy until it saturates around a temperature that is suggestively close to the crossover transition temperature computed from first principles lattice QCD. Hence also from the point of view of the statistical model in current heavy-ion collisions at RHIC and LHC it is very likely that the matter in the collision center has actually persisted in a state of even higher temperatures shortly after the collision. The presence of deconfined quarks and gluons at that point would allow the bulk to more efficiently (locally) chemically and kinetically thermalize, so that at hadronization the grand canonical abundances are reached.</p>
        <p>What about heavy quarks? If we simply extend the hadron resonance gas by including charmed hadrons, i.e. the D mesons, charmed baryons and charmonium states, would we also be able to reproduce the experimental abundances? The answer regarding the absolute yields is a clear no, as first discussed in Ref. [18]. However inspection of the ratio of excited state charmonium to ground state charmonium revealed that for central collisions its value became close to the prediction of the statistical model. I.e. while the overall number of c c pairs produced in the earliest stages of the collision does not correspond to the value expected in chemical equilibrium at the freezeout temperature it appears that relative abundances produced at freezeout are again in agreement with chemical equilibration. How can this be accommodated in the language of the hadron gas? What is needed is to enhance the yields of charmed hadrons relative to their chemical equilibrium levels by introducing an additional charm conservation constraint and the enhancement factor g cWhat about heavy quarks? If we simply extend the hadron resonance gas by including charmed hadrons, i.e. the D mesons, charmed baryons and charmonium states, would we also be able to reproduce the experimental abundances? The answer regarding the absolute yields is a clear no, as first discussed in Ref. [18]. However inspection of the ratio of excited state charmonium to ground state charmonium revealed that for central collisions its value became close to the prediction of the statistical model. I.e. while the overall number of c c pairs produced in the earliest stages of the collision does not correspond to the value expected in chemical equilibrium at the freezeout temperature it appears that relative abundances produced at freezeout are again in agreement with chemical equilibration. How can this be accommodated in the language of the hadron gas? What is needed is to enhance the yields of charmed hadrons relative to their chemical equilibrium levels by introducing an additional charm conservation constraint and the enhancement factor g c</p>
        <p>Here the only relevant terms are those for open heavy flavor mesons, singly charmed Baryons and the charm anti-charm mesons. For a small number of singly charmed hadrons the exact conservation of the charm quantum number needs to be correctly treated in the canonical formalism, which leads to additional correction factor involving the Bessel functions I 1 and I 2 , the ratio of which reduces to unity for large overall number of produced c c. The total number of charm anti-charm pairs for a particular collision centrality is computed by using the total charm cross section taken from pp collisions and scaled with the nuclear overlap factor T AA , i.e. N direct c c = σ pp c c T AA . The charm cross section grows rapidly with √ s NN so that as shown in Ref. [387] at SPS g c ≲ 5 while at RHIC it is already g c ≈ 10 and for LHC it takes on even larger values 17 &lt; g c &lt; 30. Note that g c in this model is a function of rapidity and the number of participants are closely related to the total charm cross section, which due to the challenging nature of the underlying measurements unfortunately still to this day carries relatively large uncertainties.Here the only relevant terms are those for open heavy flavor mesons, singly charmed Baryons and the charm anti-charm mesons. For a small number of singly charmed hadrons the exact conservation of the charm quantum number needs to be correctly treated in the canonical formalism, which leads to additional correction factor involving the Bessel functions I 1 and I 2 , the ratio of which reduces to unity for large overall number of produced c c. The total number of charm anti-charm pairs for a particular collision centrality is computed by using the total charm cross section taken from pp collisions and scaled with the nuclear overlap factor T AA , i.e. N direct c c = σ pp c c T AA . The charm cross section grows rapidly with √ s NN so that as shown in Ref. [387] at SPS g c ≲ 5 while at RHIC it is already g c ≈ 10 and for LHC it takes on even larger values 17 &lt; g c &lt; 30. Note that g c in this model is a function of rapidity and the number of participants are closely related to the total charm cross section, which due to the challenging nature of the underlying measurements unfortunately still to this day carries relatively large uncertainties.</p>
        <p>Combining the fact that heavy quark pair production takes place in the early stages of a collision with the thermal hadron resonance gas model at freezeout enables an efficient description of the measured charmonium data. The interplay of the production yields of singly charmed mesons and baryons together with the overall number of c c pairs set by the charm cross section allows one to reproduce the decrease of R AA of J/ψ with increasing number of activity in the collision center at RHIC. At the same time it provides a mechanism to explain why the values of R AA at LHC take on significantly larger values, as shown in the left panel of Fig. 52. The rapidity dependence of the total charm cross section, being largest at mid rapidity, furthermore provides an explanation to the measurements in the middle panel of Fig. 50 showing that the suppression at RHIC is weakest for small values of y.Combining the fact that heavy quark pair production takes place in the early stages of a collision with the thermal hadron resonance gas model at freezeout enables an efficient description of the measured charmonium data. The interplay of the production yields of singly charmed mesons and baryons together with the overall number of c c pairs set by the charm cross section allows one to reproduce the decrease of R AA of J/ψ with increasing number of activity in the collision center at RHIC. At the same time it provides a mechanism to explain why the values of R AA at LHC take on significantly larger values, as shown in the left panel of Fig. 52. The rapidity dependence of the total charm cross section, being largest at mid rapidity, furthermore provides an explanation to the measurements in the middle panel of Fig. 50 showing that the suppression at RHIC is weakest for small values of y.</p>
        <p>The success of the statistical model combined with the fact that charmonium at LHC shows clear signs of partial kinetic equilibration may be taken as indication that the idealization of full kinetic equilibrium employed in first principles lattice QCD based computations is indeed a good starting point. One possible route then to connect QCD results to the measured yields was explored in Refs. [219,235] where the ψ ′ to J/ψ ratio has been estimated using thermal spectral functions, computed using a lattice QCD vetted potential. The reason to focus on the ratio of excited to ground state is that it is independent of the enhancement factor g c related to the actual number of c c pairs produced. Remember that the area under the peak structures in the in-medium spectral function encodes the dilepton emission rate from that quarkonium state in a fully equilibrated setting. This however is not what is measured in experiment, which is instead the decay of vacuum quarkonium states long after the QGP has ceased to exist. Thus the question is how to translate the spectral features around the crossover transition into abundances of vacuum states produced at hadronization. Ref. [219] proposed to use an instantaneous freezeout scenario, where the number of produced vacuum particles are estimated from the spectral functions in units of dilepton emission. I.e. one takes the weighted area under in-medium peak for e.g. J/ψ and divides it by the area of the peak in the vacuum spectral function, which is directly related to the radial wavefunction of the T = 0 J/ψ at the origin. This value is then used as estimate for the number of vacuum states produced. Carrying out the same procedure for ψ ′ and dividing the two results has then been taken as estimate for the ψ ′ to J/ψ ratio. It is found that the value obtained in this fashion lies quite close to the statistical model and using a conservative error estimate is currently compatible within the combined theory uncertainties. Such an agreement bodes well for future studies trying to explore quarkonium production from genuine first principle thermal QCD computations.The success of the statistical model combined with the fact that charmonium at LHC shows clear signs of partial kinetic equilibration may be taken as indication that the idealization of full kinetic equilibrium employed in first principles lattice QCD based computations is indeed a good starting point. One possible route then to connect QCD results to the measured yields was explored in Refs. [219,235] where the ψ ′ to J/ψ ratio has been estimated using thermal spectral functions, computed using a lattice QCD vetted potential. The reason to focus on the ratio of excited to ground state is that it is independent of the enhancement factor g c related to the actual number of c c pairs produced. Remember that the area under the peak structures in the in-medium spectral function encodes the dilepton emission rate from that quarkonium state in a fully equilibrated setting. This however is not what is measured in experiment, which is instead the decay of vacuum quarkonium states long after the QGP has ceased to exist. Thus the question is how to translate the spectral features around the crossover transition into abundances of vacuum states produced at hadronization. Ref. [219] proposed to use an instantaneous freezeout scenario, where the number of produced vacuum particles are estimated from the spectral functions in units of dilepton emission. I.e. one takes the weighted area under in-medium peak for e.g. J/ψ and divides it by the area of the peak in the vacuum spectral function, which is directly related to the radial wavefunction of the T = 0 J/ψ at the origin. This value is then used as estimate for the number of vacuum states produced. Carrying out the same procedure for ψ ′ and dividing the two results has then been taken as estimate for the ψ ′ to J/ψ ratio. It is found that the value obtained in this fashion lies quite close to the statistical model and using a conservative error estimate is currently compatible within the combined theory uncertainties. Such an agreement bodes well for future studies trying to explore quarkonium production from genuine first principle thermal QCD computations.</p>
        <p>The ability of the statistical model to reproduce the production yields of light hadrons and charmonium is intriguing and has been instrumental in revealing the role played by regeneration in the production of charmonium at RHIC and LHC. At the same time, being formulated in terms of a hadron gas, this model can only make statements about the physics at and after freezeout. Therefore the next step towards a fully dynamical understanding of charmonium production is to consider phenomenological models that allow us to describe the physics within the QGP realm and to see how they compare to the statistical model. One question, which is of particular interest is to what degree charmonium states produced early on in a heavy-ion collision, so called primordial charmonium, survive until the end of the QGP phase or whether they are efficiently melted on the way. Two groups, one based at Texas A &amp; M and the other at Tsinghua university have developed transport models based on the Boltzmann equation, respectively on a corresponding averaged rate equation. Both approaches have in common that they implement the possibility for dissociation of primordial charmonium particles, as well as the dynamical recombination of such states throughout the QGP evolution. Feed-down from excited state is included at the end of the medium evolution. Non-perturbative information on quarkonium dissociation is implemented in the former approach by computing their stability properties via the T-matrix approach or via melting temperatures in the latter. As we discussed in Section 3.2, the definition of the potential used in a Bethe-Salpeter based approach and its relation to the EFT based potential remain an active area of research and constitute one significant source of uncertainty. On the other hand we have seen that the definition of a melting temperature in the presence of a thermal width is not uniquely defined and especially difficult when using direct lattice QCD results, which in turn contributes to the overall systematic uncertainty. The recombination probability in these models is constructed using arguments of detailed balance, which are expected to work well close to equilibrium but may require corrections at early times far from equilibrium. More details on the construction of loss and gain terms can be found in Ref. [388] and Ref. [389]. The medium evolution is treated somewhat differently among the two models. In the former the concept of entropy conservation in conjunction with the measured particle multiplicities is used to model a temperature profile within an isotropically expanding fireball. The latter model on the other hand computes a temperature profile directly based on 2 + 1 dimensional Bjorken expansion in the QGP phase. In each case a first order transition like regime is used to connect the QGP with a hadron resonance gas phase at lower temperatures.The ability of the statistical model to reproduce the production yields of light hadrons and charmonium is intriguing and has been instrumental in revealing the role played by regeneration in the production of charmonium at RHIC and LHC. At the same time, being formulated in terms of a hadron gas, this model can only make statements about the physics at and after freezeout. Therefore the next step towards a fully dynamical understanding of charmonium production is to consider phenomenological models that allow us to describe the physics within the QGP realm and to see how they compare to the statistical model. One question, which is of particular interest is to what degree charmonium states produced early on in a heavy-ion collision, so called primordial charmonium, survive until the end of the QGP phase or whether they are efficiently melted on the way. Two groups, one based at Texas A &amp; M and the other at Tsinghua university have developed transport models based on the Boltzmann equation, respectively on a corresponding averaged rate equation. Both approaches have in common that they implement the possibility for dissociation of primordial charmonium particles, as well as the dynamical recombination of such states throughout the QGP evolution. Feed-down from excited state is included at the end of the medium evolution. Non-perturbative information on quarkonium dissociation is implemented in the former approach by computing their stability properties via the T-matrix approach or via melting temperatures in the latter. As we discussed in Section 3.2, the definition of the potential used in a Bethe-Salpeter based approach and its relation to the EFT based potential remain an active area of research and constitute one significant source of uncertainty. On the other hand we have seen that the definition of a melting temperature in the presence of a thermal width is not uniquely defined and especially difficult when using direct lattice QCD results, which in turn contributes to the overall systematic uncertainty. The recombination probability in these models is constructed using arguments of detailed balance, which are expected to work well close to equilibrium but may require corrections at early times far from equilibrium. More details on the construction of loss and gain terms can be found in Ref. [388] and Ref. [389]. The medium evolution is treated somewhat differently among the two models. In the former the concept of entropy conservation in conjunction with the measured particle multiplicities is used to model a temperature profile within an isotropically expanding fireball. The latter model on the other hand computes a temperature profile directly based on 2 + 1 dimensional Bjorken expansion in the QGP phase. In each case a first order transition like regime is used to connect the QGP with a hadron resonance gas phase at lower temperatures.</p>
        <p>Both models are able to describe the R AA in terms of centrality and transverse momentum at RHIC and LHC in an equally good fashion, as shown for the example of its centrality dependence in the center panel of Fig. 52, see also Ref. [352] (in Measurements of the ψ ′ to J/ψ ratio from the NA50 [393], ALICE [392] and CMS [390,391] collaborations in Pb + Pb collisions. The pp baseline is given as orange datapoints [379,394]. The green solid line denotes the prediction of the statistical model of hadronization [379], while the purple line corresponds to a computation based on pNRQCD spectral functions combined with an instantaneous freezeout scenario from [235].Both models are able to describe the R AA in terms of centrality and transverse momentum at RHIC and LHC in an equally good fashion, as shown for the example of its centrality dependence in the center panel of Fig. 52, see also Ref. [352] (in Measurements of the ψ ′ to J/ψ ratio from the NA50 [393], ALICE [392] and CMS [390,391] collaborations in Pb + Pb collisions. The pp baseline is given as orange datapoints [379,394]. The green solid line denotes the prediction of the statistical model of hadronization [379], while the purple line corresponds to a computation based on pNRQCD spectral functions combined with an instantaneous freezeout scenario from [235].</p>
        <p>non-central collisions the model of Ref. [388] seems to somewhat underestimate the actual R AA ). For the p t dependence we select here for better readability in the right panel of Fig. 52 a single results from Ref. [389] compared to the measurements by the ALICE collaboration at √ s AA = 2.76 TeV. As indicated by the two different black lines referring to the primordial and the regeneration component of the total R AA there are two different regimes present, which are smoothly connected. At large p t primordial charmonium appears to contribute a majority of the yield, while at small p t a significant fraction of produced J/ψ arises from recombination effects. Similar behavior for the R AA dependence on centrality is observed: in non-central collisions primordial J/ψ dominates but for central collisions regeneration plays an almost equally important role. The effects of regeneration at LHC are pronounced but also at RHIC the transport model computations indicate that dissociation of primordial charmonium alone cannot account for the observed patterns in R AA .non-central collisions the model of Ref. [388] seems to somewhat underestimate the actual R AA ). For the p t dependence we select here for better readability in the right panel of Fig. 52 a single results from Ref. [389] compared to the measurements by the ALICE collaboration at √ s AA = 2.76 TeV. As indicated by the two different black lines referring to the primordial and the regeneration component of the total R AA there are two different regimes present, which are smoothly connected. At large p t primordial charmonium appears to contribute a majority of the yield, while at small p t a significant fraction of produced J/ψ arises from recombination effects. Similar behavior for the R AA dependence on centrality is observed: in non-central collisions primordial J/ψ dominates but for central collisions regeneration plays an almost equally important role. The effects of regeneration at LHC are pronounced but also at RHIC the transport model computations indicate that dissociation of primordial charmonium alone cannot account for the observed patterns in R AA .</p>
        <p>From considerations of the nuclear modification factor of the charmonium ground state J/ψ we have so far learned that dissociation and regeneration are leading to an intricate pattern of charmonium suppression requiring insight into all stages of the collision. While in the transport models a partial equilibration of the charmonium states occurs, equilibration is assumed to be complete in the statistical model. The question thus remains: is there a way how to distinguish between these two scenarios even though both reproduce the R AA well. This question becomes even more pressing when realizing that also models with a very different physics content are able to reproduce the R AA at LHC, as seen in the green dashed lines in the center panel of Fig. 52, which corresponds to a model based solely on shadowing, comovers and the possibility for c c pairs to recombine [372].From considerations of the nuclear modification factor of the charmonium ground state J/ψ we have so far learned that dissociation and regeneration are leading to an intricate pattern of charmonium suppression requiring insight into all stages of the collision. While in the transport models a partial equilibration of the charmonium states occurs, equilibration is assumed to be complete in the statistical model. The question thus remains: is there a way how to distinguish between these two scenarios even though both reproduce the R AA well. This question becomes even more pressing when realizing that also models with a very different physics content are able to reproduce the R AA at LHC, as seen in the green dashed lines in the center panel of Fig. 52, which corresponds to a model based solely on shadowing, comovers and the possibility for c c pairs to recombine [372].</p>
        <p>Two paths forward are possible. On the one hand one can look for other experimental observables, which are more discriminatory among the different models. One such quantity of current interest is the ratio of ψ ′ to J/ψ . It is a particularly challenging observable due to the small signal to noise ratio in the measurements of the excited state yields. At the LHC there exist currently measurements by the CMS collaboration (see Refs. [390,391]), however published only as double ratios with respect to pp collisions and upper limits by the ALICE collaboration [392]. These values together with the pp baseline and earlier measurements at lower beam energies by the NA50 experiment are listed in Fig. 53 together with the predictions from the statistical hadronization model from Ref. [379] as well as the computations of Ref. [235] modeled based on pNRQCD spectral functions combined with an instantaneous freezeout scenario.Two paths forward are possible. On the one hand one can look for other experimental observables, which are more discriminatory among the different models. One such quantity of current interest is the ratio of ψ ′ to J/ψ . It is a particularly challenging observable due to the small signal to noise ratio in the measurements of the excited state yields. At the LHC there exist currently measurements by the CMS collaboration (see Refs. [390,391]), however published only as double ratios with respect to pp collisions and upper limits by the ALICE collaboration [392]. These values together with the pp baseline and earlier measurements at lower beam energies by the NA50 experiment are listed in Fig. 53 together with the predictions from the statistical hadronization model from Ref. [379] as well as the computations of Ref. [235] modeled based on pNRQCD spectral functions combined with an instantaneous freezeout scenario.</p>
        <p>On the other hand one needs to develop further first principles based real-time descriptions of heavy quarkonium in order to reduce the need for model assumptions. As we discussed in Section 4, the open quantum systems approach appears to be a viable candidate allowing one e.g. to derive evolution equations via pNRQCD from underlying QCD. In the weak-coupling scenario even the Boltzmann equation that forms the basis for the transport model computations has been derived in that fashion. In general in such a setup the dynamical evolution of the quarkonium states is governed by low energy matching coefficients, be it the complex heavy quark potential or other non-perturbative transport coefficients. However all the approaches developed so far make extensive use of a separation of scales between the heavy quark rest mass and other relevant scales, which means that their application to charmonium in current heavy-ion collisions does not rest on as solid foundations as one would like. E.g. the complex in-medium potential currently available corresponds only to the lowest order contribution of the full in-medium potential without finite velocity corrections. For charmonium in heavy-ion collisions such corrections are expected to be relevant, as already at T = 0 the static potential alone is not able to reproduce the vacuum charmonium bound states in an equally accurate fashion as is possible for bottomonium. The theory community thus needs to develop further the effective field theory based approaches to heavy quarkonium, on the one hand to establish their validity in the non-perturbative regime (one recent example being Refs. [287,288]) and furthermore for masses in which the separation of scales is not as pronounced, i.e. to higher order in their respective expansion schemes.On the other hand one needs to develop further first principles based real-time descriptions of heavy quarkonium in order to reduce the need for model assumptions. As we discussed in Section 4, the open quantum systems approach appears to be a viable candidate allowing one e.g. to derive evolution equations via pNRQCD from underlying QCD. In the weak-coupling scenario even the Boltzmann equation that forms the basis for the transport model computations has been derived in that fashion. In general in such a setup the dynamical evolution of the quarkonium states is governed by low energy matching coefficients, be it the complex heavy quark potential or other non-perturbative transport coefficients. However all the approaches developed so far make extensive use of a separation of scales between the heavy quark rest mass and other relevant scales, which means that their application to charmonium in current heavy-ion collisions does not rest on as solid foundations as one would like. E.g. the complex in-medium potential currently available corresponds only to the lowest order contribution of the full in-medium potential without finite velocity corrections. For charmonium in heavy-ion collisions such corrections are expected to be relevant, as already at T = 0 the static potential alone is not able to reproduce the vacuum charmonium bound states in an equally accurate fashion as is possible for bottomonium. The theory community thus needs to develop further the effective field theory based approaches to heavy quarkonium, on the one hand to establish their validity in the non-perturbative regime (one recent example being Refs. [287,288]) and furthermore for masses in which the separation of scales is not as pronounced, i.e. to higher order in their respective expansion schemes.</p>
        <p>Let us now turn to the heavier flavor, bottomonium, which due to its larger mass and the correspondingly smaller b b cross section requires higher luminosities or more sensitive detectors at the same beam energies than charmonium.Let us now turn to the heavier flavor, bottomonium, which due to its larger mass and the correspondingly smaller b b cross section requires higher luminosities or more sensitive detectors at the same beam energies than charmonium.</p>
        <p>The absence of significant non-prompt contributions to their production on the other hand simplifies the analysis. The most comprehensive results to date, including individual measurements of the R AA for the bottomonium ground state, as well as the first and second excited states, stem from the CMS collaboration at LHC (for the most recent installment see e.g. Ref. [395], for a review see Ref. [396]). More recently the ALICE collaboration has also published first measurements of the ground state R AA in Ref. [397]. At RHIC, the STAR collaboration has presented recent measurements [398] of the ground state R AA as well as the combined R AA of ground and excited states.The absence of significant non-prompt contributions to their production on the other hand simplifies the analysis. The most comprehensive results to date, including individual measurements of the R AA for the bottomonium ground state, as well as the first and second excited states, stem from the CMS collaboration at LHC (for the most recent installment see e.g. Ref. [395], for a review see Ref. [396]). More recently the ALICE collaboration has also published first measurements of the ground state R AA in Ref. [397]. At RHIC, the STAR collaboration has presented recent measurements [398] of the ground state R AA as well as the combined R AA of ground and excited states.</p>
        <p>In Fig. 54 we showcase a selection of recent and characteristic measurements from LHC run2 at √ s NN = 5.02 TeV. The left and center panel contain measurements of the R AA of the ground and excited states from the CMS collaboration [395] plotted versus the centrality of the collision and versus transverse momentum respectively. The values show clear and consistent suppression patterns. The more central the collision becomes the stronger the suppression. At the same time, the excited states are more strongly suppressed than the more deeply bound ground state. While the uncertainties are still significant at small p t there appears to be a trend at least for the ground state that the suppression is stronger close to p T = 0 than for those at the largest momenta. A similar trend for the first excited state is not visible at the moment. This behavior is decidedly different from that found for charmonium (see e.g. Fig. 52) and at first sight is reminiscent of what a scenario based primarily on quarkonium melting would suggest. The hot medium in the collision center destabilizes the more weakly bound states more thoroughly and this suppression is most pronounced where the quarkonium spends most time in the hot environment. This conclusion is supported by the fact that by going from √ s AA = 2.76 TeV to √ s AA = 5.02 TeV the suppression in bottomonium is found to become slightly stronger, while it becomes weaker in charmonium.In Fig. 54 we showcase a selection of recent and characteristic measurements from LHC run2 at √ s NN = 5.02 TeV. The left and center panel contain measurements of the R AA of the ground and excited states from the CMS collaboration [395] plotted versus the centrality of the collision and versus transverse momentum respectively. The values show clear and consistent suppression patterns. The more central the collision becomes the stronger the suppression. At the same time, the excited states are more strongly suppressed than the more deeply bound ground state. While the uncertainties are still significant at small p t there appears to be a trend at least for the ground state that the suppression is stronger close to p T = 0 than for those at the largest momenta. A similar trend for the first excited state is not visible at the moment. This behavior is decidedly different from that found for charmonium (see e.g. Fig. 52) and at first sight is reminiscent of what a scenario based primarily on quarkonium melting would suggest. The hot medium in the collision center destabilizes the more weakly bound states more thoroughly and this suppression is most pronounced where the quarkonium spends most time in the hot environment. This conclusion is supported by the fact that by going from √ s AA = 2.76 TeV to √ s AA = 5.02 TeV the suppression in bottomonium is found to become slightly stronger, while it becomes weaker in charmonium.</p>
        <p>While equilibration with the environment has been an important part of the dynamics of charmonium no significant signs of participation in the collective motion of the bulk have so far been observed for bottomonium, as shown in recent measurements of v 2 by the ALICE collaboration in the right panel of Fig. 54. One should however keep in mind that the errorbars on these first measurements are quite large and are compatible with small values of v 2 predicted by some models (see e.g. Ref. [399]).While equilibration with the environment has been an important part of the dynamics of charmonium no significant signs of participation in the collective motion of the bulk have so far been observed for bottomonium, as shown in recent measurements of v 2 by the ALICE collaboration in the right panel of Fig. 54. One should however keep in mind that the errorbars on these first measurements are quite large and are compatible with small values of v 2 predicted by some models (see e.g. Ref. [399]).</p>
        <p>The naive visual inspection of the experimental results suggest that bottomonium, in contrast to charmonium at LHC, behaves as a genuine non-equilibrium probe of the collision center, for which regeneration effects do not play a major role. Since the b b cross section at RHIC is even smaller and the lifetime of the medium produced shorter than at LHC, this conclusion is expected to remain equally valid atThe naive visual inspection of the experimental results suggest that bottomonium, in contrast to charmonium at LHC, behaves as a genuine non-equilibrium probe of the collision center, for which regeneration effects do not play a major role. Since the b b cross section at RHIC is even smaller and the lifetime of the medium produced shorter than at LHC, this conclusion is expected to remain equally valid at</p>
        <p>s NN = 0.2 TeV.s NN = 0.2 TeV.</p>
        <p>On the theory side Bottomonium, due to its larger mass, is a promising candidate for a direct application of effective field theory based approaches. In particular descriptions utilizing the static in-medium potential are expected to provide a reasonable description of the relevant physics. While the large bottom mass m b ≫ Λ QCD allows the partonic processes in b b production to be described in a fully perturbative manner, the in-medium evolution may still require non-perturbative insight. Remember that only the binding energy of the ground state Upsilon lies well above the characteristic QCD scale E Υ (1S) bind ≫ Λ QCD , while for others this separation is less well pronounced.On the theory side Bottomonium, due to its larger mass, is a promising candidate for a direct application of effective field theory based approaches. In particular descriptions utilizing the static in-medium potential are expected to provide a reasonable description of the relevant physics. While the large bottom mass m b ≫ Λ QCD allows the partonic processes in b b production to be described in a fully perturbative manner, the in-medium evolution may still require non-perturbative insight. Remember that only the binding energy of the ground state Upsilon lies well above the characteristic QCD scale E Υ (1S) bind ≫ Λ QCD , while for others this separation is less well pronounced.</p>
        <p>From the point of view of the dynamical description of heavy quarkonium discussed in Section 4, bottomonium modeling has recently entered an phase of rapid evolution. The open quantum systems approach has led to new avenues to implement the real-time evolution of this quarkonium species leading to Lindblad-type master equations derived systematically from QCD. While many of these approaches still use weak-coupling arguments in intermediate steps first fully non-perturbative formulations are under development. At high temperature we discussed in Section 4.1 that when one remains within the language of wavefunctions, a non-linear stochastic Schrödinger equation needs to be solved to account for the full dissipative dynamics of the quarkonium system in a QCD medium. In terms of distribution functions for the quarkonium states, we have seen in Section 4.3 that a Boltzmann equation can be derived based on a set of clearly specified assumption. Note that all the derivations of real-time dynamics in Section 4 were based on a fully thermal background. When considering an evolving medium, as is present in the case of a heavy-ion collision a new timescale, describing the cooling process enters. If that scale is large enough compared to the other relevant timescales we may regard the temperature of the medium as external parameter, governing the values of e.g. the potential of the stochastic Schrödinger equation, an approximation that is used in most models today.From the point of view of the dynamical description of heavy quarkonium discussed in Section 4, bottomonium modeling has recently entered an phase of rapid evolution. The open quantum systems approach has led to new avenues to implement the real-time evolution of this quarkonium species leading to Lindblad-type master equations derived systematically from QCD. While many of these approaches still use weak-coupling arguments in intermediate steps first fully non-perturbative formulations are under development. At high temperature we discussed in Section 4.1 that when one remains within the language of wavefunctions, a non-linear stochastic Schrödinger equation needs to be solved to account for the full dissipative dynamics of the quarkonium system in a QCD medium. In terms of distribution functions for the quarkonium states, we have seen in Section 4.3 that a Boltzmann equation can be derived based on a set of clearly specified assumption. Note that all the derivations of real-time dynamics in Section 4 were based on a fully thermal background. When considering an evolving medium, as is present in the case of a heavy-ion collision a new timescale, describing the cooling process enters. If that scale is large enough compared to the other relevant timescales we may regard the temperature of the medium as external parameter, governing the values of e.g. the potential of the stochastic Schrödinger equation, an approximation that is used in most models today.</p>
        <p>Historically the most common approach to bottomonium modeling is to resort to solving a deterministic Schrödinger equation which is governed by an in-medium potential. From our discussion in Section 4.2 we saw in Eq. ( 239) that such an ansatz amounts to a truncation of the dynamics, neglecting dissipative effects, and in addition to an adiabatic approximation that averages over the fluctuations. From the numerical tests within the stochastic potential model, we learned that in such an adiabatic truncation the survival of quarkonium states may be underestimated if the effects of decoherence are relevant. I.e. the R AA computed in that way may underestimate the correct physical value.Historically the most common approach to bottomonium modeling is to resort to solving a deterministic Schrödinger equation which is governed by an in-medium potential. From our discussion in Section 4.2 we saw in Eq. ( 239) that such an ansatz amounts to a truncation of the dynamics, neglecting dissipative effects, and in addition to an adiabatic approximation that averages over the fluctuations. From the numerical tests within the stochastic potential model, we learned that in such an adiabatic truncation the survival of quarkonium states may be underestimated if the effects of decoherence are relevant. I.e. the R AA computed in that way may underestimate the correct physical value.</p>
        <p>The Kent State University group has explored the suppression of bottomonium in heavy-ion collisions in detail, combining the deterministic Schrödinger equation with an anisotropic hydrodynamic description of the medium background evolution. They use a Glauber model based initial distribution of primordial states and take into account the decays from feed-down after hadronization. A full description of the framework is found in Ref. [230], where in particular the implementation of the potential in an anisotropic background is discussed. Note that no recombination contribution enters in this framework. (A similar model based on isotropic hydrodynamics has been used in Refs. [401,402])The Kent State University group has explored the suppression of bottomonium in heavy-ion collisions in detail, combining the deterministic Schrödinger equation with an anisotropic hydrodynamic description of the medium background evolution. They use a Glauber model based initial distribution of primordial states and take into account the decays from feed-down after hadronization. A full description of the framework is found in Ref. [230], where in particular the implementation of the potential in an anisotropic background is discussed. Note that no recombination contribution enters in this framework. (A similar model based on isotropic hydrodynamics has been used in Refs. [401,402])</p>
        <p>The potential used in the Schrödinger equation itself is an input of the model and so far two ansätze have been deployed. Both of these models feature a Debye screened Coulombic in-medium part. For the in-medium string part either Eq. ( 180) or the similar legacy Gauss law parametrization is used. The main difference between them lies the form of the imaginary part, which is taken to be the purely Coulombic HTL one in the former [230,320,321,403], while in the latter it contains both contributions from the Coulombic and string in-medium potential [322].The potential used in the Schrödinger equation itself is an input of the model and so far two ansätze have been deployed. Both of these models feature a Debye screened Coulombic in-medium part. For the in-medium string part either Eq. ( 180) or the similar legacy Gauss law parametrization is used. The main difference between them lies the form of the imaginary part, which is taken to be the purely Coulombic HTL one in the former [230,320,321,403], while in the latter it contains both contributions from the Coulombic and string in-medium potential [322].</p>
        <p>A prescription of how to initialize the Schrödinger equation for a mixed ensemble of bottomonium states in agreement with the scale separation of NRQCD has been put forward in Ref. [404]. Its proposal for efficient evolution of such an ensemble however remains restricted to unitary time evolution, i.e. when dissipation effects are small.A prescription of how to initialize the Schrödinger equation for a mixed ensemble of bottomonium states in agreement with the scale separation of NRQCD has been put forward in Ref. [404]. Its proposal for efficient evolution of such an ensemble however remains restricted to unitary time evolution, i.e. when dissipation effects are small.</p>
        <p>Let us start with Bottomonium at STAR, since there the separation of scales between the medium temperature created in the collision center and the bottom mass is most pronounced. In addition bottomonium is expected to act as a true non-equilibrium probe, without reaching any significant degree of kinetic thermalization. In such a scenario, one may speculate that decoherence is not yet very effective and thus the adiabatic approximation may prove already satisfactory. In the left panel of Fig. 55 we plot a comparison of the Bottomonium ground state R AA from recent measurements of the STAR collaboration together with the computed values from Refs. [230,322]. The gray curve denotes the computation based on the potential using only the Coulombic imaginary part, while the blue shaded curve denotes the outcome from using a lattice vetted Gauss-law potential. One finds that the R AA is well reproduced from the Gauss-law potential whose stronger Im[V ] leads to more efficient bottomonium destabilization and brings the computed values into agreement with experiment. One important difference between the two results is that the computation based on the Gauss-law potential is much less sensitive to differences in the values of the shear viscosity governing the hydrodynamics back ground evolution.Let us start with Bottomonium at STAR, since there the separation of scales between the medium temperature created in the collision center and the bottom mass is most pronounced. In addition bottomonium is expected to act as a true non-equilibrium probe, without reaching any significant degree of kinetic thermalization. In such a scenario, one may speculate that decoherence is not yet very effective and thus the adiabatic approximation may prove already satisfactory. In the left panel of Fig. 55 we plot a comparison of the Bottomonium ground state R AA from recent measurements of the STAR collaboration together with the computed values from Refs. [230,322]. The gray curve denotes the computation based on the potential using only the Coulombic imaginary part, while the blue shaded curve denotes the outcome from using a lattice vetted Gauss-law potential. One finds that the R AA is well reproduced from the Gauss-law potential whose stronger Im[V ] leads to more efficient bottomonium destabilization and brings the computed values into agreement with experiment. One important difference between the two results is that the computation based on the Gauss-law potential is much less sensitive to differences in the values of the shear viscosity governing the hydrodynamics back ground evolution.</p>
        <p>I.e. while the gray band denotes the difference between changing the values for the shear viscosity over entropy ratio η/S in the background hydrodynamics from 1/4π -3/4π , such a change has virtually no effect on the blue curve. There the error band stems instead from the uncertainty in determining the Debye mass parameter from lattice QCD simulations.I.e. while the gray band denotes the difference between changing the values for the shear viscosity over entropy ratio η/S in the background hydrodynamics from 1/4π -3/4π , such a change has virtually no effect on the blue curve. There the error band stems instead from the uncertainty in determining the Debye mass parameter from lattice QCD simulations.</p>
        <p>In contrast to fully perturbative description of the in-medium evolution, where the contributions from e.g. Landau damping and gluo-dissociation can be explicitly disentangled, here the values of the imaginary part represent the aggregate of all these effects. I.e. the bottomonium state may be excited into another singlet state, bound or unbound or may go over to an unbound octet state. The suppression of e.g. the ground state contains two elements. On the one hand the ground state itself may be destabilized by the medium. On the other hand as argued in e.g. Ref. [401] the melting of excited state quarkonium leads to a diminished contribution from feed-down, already reducing the R AA in the presence of an otherwise stable ground state.In contrast to fully perturbative description of the in-medium evolution, where the contributions from e.g. Landau damping and gluo-dissociation can be explicitly disentangled, here the values of the imaginary part represent the aggregate of all these effects. I.e. the bottomonium state may be excited into another singlet state, bound or unbound or may go over to an unbound octet state. The suppression of e.g. the ground state contains two elements. On the one hand the ground state itself may be destabilized by the medium. On the other hand as argued in e.g. Ref. [401] the melting of excited state quarkonium leads to a diminished contribution from feed-down, already reducing the R AA in the presence of an otherwise stable ground state.</p>
        <p>What happens then at LHC, where bottomonium spends a significantly longer time in a much hotter medium? Comparing the predictions for LHC at √ s NN = 5.02 TeV based on the potential with Coulombic Im[V ] from Refs. [321,403] with the postdictions using the Gauss law potential in Ref. [322] an interesting trend emerges. The potential that led to overestimation of R AA at RHIC now manages to describe the yields with very good accuracy at LHC. On the other hand the Gauss-Law model already at √ s NN = 2.76 TeV starts to show signs of underestimating R AA which it clearly does at the highest LHC energies. There are several possible mechanism at play here. On the one hand the imaginary part of the potential in the Gauss-law parametrization has only been vetted to tentative values of the lattice Im[V ] at relatively low temperatures T &lt; 300 MeV. Whether the Gauss law potential describes the imaginary part accurately at higher temperatures still needs to be ascertained, which is work in progress. On the other hand if the Gauss-law potential is indeed the appropriate potential to use then two sources for the underestimation of the R AA come to mind. The first one is related to the effects of fluctuations and dissipation that have been discarded in the adiabatic approximation. Indeed the stochastic potential computations suggest that when these effects are included the R AA should increase. Ongoing efforts towards developing and implementing fully dissipative dynamics in the open quantum systems language promise to provide the necessary tools to do so in the near future. At the same time one has to investigate whether regeneration effects have already set in at the accessible LHC energies. The last question has been investigated in the context of transport models to Bottomonium evolution. Among the used models are variants of the two approaches [317,406,407] we have already met in the study of charmonium, as well as a new approach, which is a combined transport model based on the Boltzmann equation derived from pNRQCD [319] and a Langevin evolution [408] for individual bottom quarks in order to allow for dynamical regeneration. Due to the explicit treatment of the heavy quarks it does not rely on detailed balance to implement recombination while still being able to reach equilibrium distributions in the late time limit. For a partial non-perturbative approach based on pNRQCD see also Ref. [286].What happens then at LHC, where bottomonium spends a significantly longer time in a much hotter medium? Comparing the predictions for LHC at √ s NN = 5.02 TeV based on the potential with Coulombic Im[V ] from Refs. [321,403] with the postdictions using the Gauss law potential in Ref. [322] an interesting trend emerges. The potential that led to overestimation of R AA at RHIC now manages to describe the yields with very good accuracy at LHC. On the other hand the Gauss-Law model already at √ s NN = 2.76 TeV starts to show signs of underestimating R AA which it clearly does at the highest LHC energies. There are several possible mechanism at play here. On the one hand the imaginary part of the potential in the Gauss-law parametrization has only been vetted to tentative values of the lattice Im[V ] at relatively low temperatures T &lt; 300 MeV. Whether the Gauss law potential describes the imaginary part accurately at higher temperatures still needs to be ascertained, which is work in progress. On the other hand if the Gauss-law potential is indeed the appropriate potential to use then two sources for the underestimation of the R AA come to mind. The first one is related to the effects of fluctuations and dissipation that have been discarded in the adiabatic approximation. Indeed the stochastic potential computations suggest that when these effects are included the R AA should increase. Ongoing efforts towards developing and implementing fully dissipative dynamics in the open quantum systems language promise to provide the necessary tools to do so in the near future. At the same time one has to investigate whether regeneration effects have already set in at the accessible LHC energies. The last question has been investigated in the context of transport models to Bottomonium evolution. Among the used models are variants of the two approaches [317,406,407] we have already met in the study of charmonium, as well as a new approach, which is a combined transport model based on the Boltzmann equation derived from pNRQCD [319] and a Langevin evolution [408] for individual bottom quarks in order to allow for dynamical regeneration. Due to the explicit treatment of the heavy quarks it does not rely on detailed balance to implement recombination while still being able to reach equilibrium distributions in the late time limit. For a partial non-perturbative approach based on pNRQCD see also Ref. [286].</p>
        <p>All transport models manage to describe the measured ground and first excited state R AA 's for bottomonium at LHC in a satisfactory manner, one example from Ref. [405] is shown in the center panel of Fig. 55. In general a small but non-vanishing regeneration component is found to be required when considering the measurements from CMS. For the latest results from the ALICE collaboration on the Υ (1S) suppression, the situation is not as clear, as shown in the right panel of Fig. 55. There the experimental data is better reproduced with regeneration in one and without regeneration in another model. It would be interesting in this context to see the results of Ref. [405] divided into their dissociation and regeneration contributions.All transport models manage to describe the measured ground and first excited state R AA 's for bottomonium at LHC in a satisfactory manner, one example from Ref. [405] is shown in the center panel of Fig. 55. In general a small but non-vanishing regeneration component is found to be required when considering the measurements from CMS. For the latest results from the ALICE collaboration on the Υ (1S) suppression, the situation is not as clear, as shown in the right panel of Fig. 55. There the experimental data is better reproduced with regeneration in one and without regeneration in another model. It would be interesting in this context to see the results of Ref. [405] divided into their dissociation and regeneration contributions.</p>
        <p>The path forward for bottomonium studies is clear. On the one hand the potential based studies need to incorporate the effects of dissociation via a genuine stochastic evolution prescription for the wavefunction of the quarkonium system. This will remove a significant source of systematic uncertainty currently inherent in the adiabatic approximation. The explicit coupling of color singlet and color octet sectors, which is work in progress, will eventually allow to self-consistently treat the effects of recombination in the wavefunction language. It will also allow to disentangle the different effects currently summarized in the imaginary part of the singlet potential. In addition the determination of the potential, especially of its imaginary part in non-perturbative lattice QCD needs to be improved, to reduce extrapolation artifacts at high temperatures relevant in the beginning of the QGP evolution. All of these aspects are in principle feasible and are on the agenda of the theory community.The path forward for bottomonium studies is clear. On the one hand the potential based studies need to incorporate the effects of dissociation via a genuine stochastic evolution prescription for the wavefunction of the quarkonium system. This will remove a significant source of systematic uncertainty currently inherent in the adiabatic approximation. The explicit coupling of color singlet and color octet sectors, which is work in progress, will eventually allow to self-consistently treat the effects of recombination in the wavefunction language. It will also allow to disentangle the different effects currently summarized in the imaginary part of the singlet potential. In addition the determination of the potential, especially of its imaginary part in non-perturbative lattice QCD needs to be improved, to reduce extrapolation artifacts at high temperatures relevant in the beginning of the QGP evolution. All of these aspects are in principle feasible and are on the agenda of the theory community.</p>
        <p>On the side of transport models the derivation of the Boltzmann equation from pNRQCD via the open quantum systems approach has been a major step forward. The next step has to be to compute the matching coefficients required in this context from lattice QCD with high precision. The Langevin based approach to heavy quark evolution will eventually require precision knowledge of e.g. the heavy quark diffusion constant whose extraction from the lattice is also actively pursued.On the side of transport models the derivation of the Boltzmann equation from pNRQCD via the open quantum systems approach has been a major step forward. The next step has to be to compute the matching coefficients required in this context from lattice QCD with high precision. The Langevin based approach to heavy quark evolution will eventually require precision knowledge of e.g. the heavy quark diffusion constant whose extraction from the lattice is also actively pursued.</p>
        <p>In both cases efforts need to be intensified to put the derivation of the underlying evolution equations on a nonperturbative footing. The dissipative dynamics of the wavefunction approach currently relies on a Feynman-Vernon influence functional, derived at weak coupling, while the Boltzmann equation was obtained with weakly coupled pNRQCD in mind. These are exciting challenges that have the potential elevate phenomenological modeling even closer to first principles theory as has already been possible over the past decade.In both cases efforts need to be intensified to put the derivation of the underlying evolution equations on a nonperturbative footing. The dissipative dynamics of the wavefunction approach currently relies on a Feynman-Vernon influence functional, derived at weak coupling, while the Boltzmann equation was obtained with weakly coupled pNRQCD in mind. These are exciting challenges that have the potential elevate phenomenological modeling even closer to first principles theory as has already been possible over the past decade.</p>
        <p>Summary. Heavy quarkonium in heavy-ion collisions constitutes a rich and challenging field of study. A microscopic understanding of quarkonium production requires insight not only into the evolution of quark-antiquark pairs in a hot environment but also into the non-perturbative composition of the incoming projectiles and the dynamics of hadronization. Such an all-encompassing view of quarkonium production has already led to a significantly improved understanding of the phenomenon of quarkonium suppression. It arises from an intricate interplay of quarkonium destabilization due to the environment present in the collision center, as well as from recombination of heavy quarkantiquark pairs, when produced in ample numbers in the earliest moments of the collision. One current focus of the community is to hone in on the quantitative details of production mechanism for charmonium, shedding light e.g. on the role of primordial versus regenerated yields. This task requires to more strongly discriminate between the various models currently able to reproduce the experimental J/ψ , i.e. ground state R AA . Both the experimental efforts to measure excited states, such as ψ ′ and the overall charm cross section, as well as theory efforts to reduce the modeling input by bringing transport models closer to first principles QCD, will be essential in this regard. For bottomonium direct effective field theory based approaches either in the language of wavefunctions or distribution functions have already been quite successful in reproducing the hierarchical suppression patterns observed at LHC. With a much more pronounced separation of scales at hand for bottomonium, theory is looking ahead to using the open quantum systems framework to systematically derive non-perturbative evolution equations treating both the color singlet and octet sector explicitly. With the dynamics of these degrees of freedom governed by non-perturbative matching coefficients, such as transport coefficients and potentials, efficient extraction procedures from QCD are being investigated. Bottomonium thus appears to provide a unique opportunity to develop a genuine non-perturbative and first principles based real-time formalism for a system of strongly interacting matter, eventually capable of connecting microscopic QCD and experimental measurements of heavy quarkonium in extreme conditions.Summary. Heavy quarkonium in heavy-ion collisions constitutes a rich and challenging field of study. A microscopic understanding of quarkonium production requires insight not only into the evolution of quark-antiquark pairs in a hot environment but also into the non-perturbative composition of the incoming projectiles and the dynamics of hadronization. Such an all-encompassing view of quarkonium production has already led to a significantly improved understanding of the phenomenon of quarkonium suppression. It arises from an intricate interplay of quarkonium destabilization due to the environment present in the collision center, as well as from recombination of heavy quarkantiquark pairs, when produced in ample numbers in the earliest moments of the collision. One current focus of the community is to hone in on the quantitative details of production mechanism for charmonium, shedding light e.g. on the role of primordial versus regenerated yields. This task requires to more strongly discriminate between the various models currently able to reproduce the experimental J/ψ , i.e. ground state R AA . Both the experimental efforts to measure excited states, such as ψ ′ and the overall charm cross section, as well as theory efforts to reduce the modeling input by bringing transport models closer to first principles QCD, will be essential in this regard. For bottomonium direct effective field theory based approaches either in the language of wavefunctions or distribution functions have already been quite successful in reproducing the hierarchical suppression patterns observed at LHC. With a much more pronounced separation of scales at hand for bottomonium, theory is looking ahead to using the open quantum systems framework to systematically derive non-perturbative evolution equations treating both the color singlet and octet sector explicitly. With the dynamics of these degrees of freedom governed by non-perturbative matching coefficients, such as transport coefficients and potentials, efficient extraction procedures from QCD are being investigated. Bottomonium thus appears to provide a unique opportunity to develop a genuine non-perturbative and first principles based real-time formalism for a system of strongly interacting matter, eventually capable of connecting microscopic QCD and experimental measurements of heavy quarkonium in extreme conditions.</p>
        <p>It is an exciting time to work on heavy quarkonium in extreme conditions (for a recent community perspective see e.g. Ref. [409]). Experiment has amassed a wealth of high precision data on quarkonium production in relativistic heavyion collisions at RHIC and LHC in different kinematical regimes that provides a challenging testing ground for theory and phenomenology. These include the nuclear modification factors of the charmonium ground state, as well as those of the bottomonium ground and excited states. Measurements of both J/ψ and Υ elliptic flow are by now also available.It is an exciting time to work on heavy quarkonium in extreme conditions (for a recent community perspective see e.g. Ref. [409]). Experiment has amassed a wealth of high precision data on quarkonium production in relativistic heavyion collisions at RHIC and LHC in different kinematical regimes that provides a challenging testing ground for theory and phenomenology. These include the nuclear modification factors of the charmonium ground state, as well as those of the bottomonium ground and excited states. Measurements of both J/ψ and Υ elliptic flow are by now also available.</p>
        <p>Experiments are currently taking aim at even more challenging measurements, such as a detailed study of the excited state of charmonium ψ ′ . The determination of the overall charm and bottom cross section is equally high up on the agenda. Hopefully luminosities and detector performance in the future will allow us to also capture the P-wave states in heavy-ion collisions, which so far have only been studied in proton-proton collisions.Experiments are currently taking aim at even more challenging measurements, such as a detailed study of the excited state of charmonium ψ ′ . The determination of the overall charm and bottom cross section is equally high up on the agenda. Hopefully luminosities and detector performance in the future will allow us to also capture the P-wave states in heavy-ion collisions, which so far have only been studied in proton-proton collisions.</p>
        <p>We have seen that charmonium at RHIC and LHC behaves quite differently with regeneration taking on a more and more important role at higher energies. In order to learn in more quantitative detail how this change in production mechanism proceeds, and also to prepare for bottomonium at future higher energy colliders, where it is expected to behave very similarly to charmonium at LHC, a series of lower energy collisions at LHC would be very instructive. The planned electron-ion colliders on the other hand will in the near future provide unprecedented insight into the internal make-up of the nuclear projectiles allowing to much better constrain the initial conditions from which heavy-quarkonium production proceeds in a heavy-ion collision.We have seen that charmonium at RHIC and LHC behaves quite differently with regeneration taking on a more and more important role at higher energies. In order to learn in more quantitative detail how this change in production mechanism proceeds, and also to prepare for bottomonium at future higher energy colliders, where it is expected to behave very similarly to charmonium at LHC, a series of lower energy collisions at LHC would be very instructive. The planned electron-ion colliders on the other hand will in the near future provide unprecedented insight into the internal make-up of the nuclear projectiles allowing to much better constrain the initial conditions from which heavy-quarkonium production proceeds in a heavy-ion collision.</p>
        <p>This report discussed several aspects in which the theory understanding of quarkonium in thermal equilibrium has improved over the last decade. Better access to ground state spectral properties from combined lattice QCD and effective field theory studies, as well as the development of a QCD derived and non-perturbatively evaluated in-medium potential are two examples. While progress has been made, a lot of challenging work remains. First principles access to the excited state spectral properties in direct lattice QCD studies will require both advances in simulation algorithms and data analysis strategies. At the same time extending the in-medium potential beyond the lowest order in pNRQCD asks for both conceptual and numerical work on the effective field theory and lattice QCD side.This report discussed several aspects in which the theory understanding of quarkonium in thermal equilibrium has improved over the last decade. Better access to ground state spectral properties from combined lattice QCD and effective field theory studies, as well as the development of a QCD derived and non-perturbatively evaluated in-medium potential are two examples. While progress has been made, a lot of challenging work remains. First principles access to the excited state spectral properties in direct lattice QCD studies will require both advances in simulation algorithms and data analysis strategies. At the same time extending the in-medium potential beyond the lowest order in pNRQCD asks for both conceptual and numerical work on the effective field theory and lattice QCD side.</p>
        <p>When it comes to quarkonium real-time descriptions the community is in a state of heightened activity. Several groups concurrently explore complementary ways to derive and implement an open quantum systems treatment of heavy quarkonium. Some of these efforts in the context of weak-coupling approaches and a recent proposal towards a nonperturbative treatment have been highlighted in this report. The central task at hand for the near future is to further our understanding on how the real-time description can be put on a genuine non-perturbative footing that encompasses all phenomenologically relevant states. This will entail connecting the transport coefficients and potentials governing the evolution with first principles lattice QCD simulations. Similarly the transport properties of individual heavy quarks, such as the heavy quark diffusion coefficient need to be determined with much higher precision than is possible today. These challenges will require a close collaboration between practitioners in the fields of open quantum systems, effective field theory and lattice QCD.When it comes to quarkonium real-time descriptions the community is in a state of heightened activity. Several groups concurrently explore complementary ways to derive and implement an open quantum systems treatment of heavy quarkonium. Some of these efforts in the context of weak-coupling approaches and a recent proposal towards a nonperturbative treatment have been highlighted in this report. The central task at hand for the near future is to further our understanding on how the real-time description can be put on a genuine non-perturbative footing that encompasses all phenomenologically relevant states. This will entail connecting the transport coefficients and potentials governing the evolution with first principles lattice QCD simulations. Similarly the transport properties of individual heavy quarks, such as the heavy quark diffusion coefficient need to be determined with much higher precision than is possible today. These challenges will require a close collaboration between practitioners in the fields of open quantum systems, effective field theory and lattice QCD.</p>
        <p>Theory is also making inroads into a first principles understanding of the initial conditions of proton-proton collisions. Recent developments in defining and extracting parton distribution functions of nucleons from lattice QCD simulations (the current status is discussed in Ref. [410]) promise to provide novel complementary constraints to the momentum and spin distributions of partons in the proton projectiles compared to those that are currently extracted from experimental scattering data. Taking a step further, with the arrival of the proposed electron-ion collider (EIC, see e.g. Ref. [411]) the three-dimensional structure of the parton content not only of nucleons but also of nuclei will become accessible in unprecedented precision (note that quarkonium also plays a central role in the study of transverse momentum dependent gluon distributions [412][413][414][415]). While only on the horizon, the goal for theory would be to eventually understand at least partially the changes induced in the parton distribution functions in a nuclear environment from first principle. With the rapid pace of advances in lattice QCD simulations over the past decade such insight might not be out of reach in the next decade.Theory is also making inroads into a first principles understanding of the initial conditions of proton-proton collisions. Recent developments in defining and extracting parton distribution functions of nucleons from lattice QCD simulations (the current status is discussed in Ref. [410]) promise to provide novel complementary constraints to the momentum and spin distributions of partons in the proton projectiles compared to those that are currently extracted from experimental scattering data. Taking a step further, with the arrival of the proposed electron-ion collider (EIC, see e.g. Ref. [411]) the three-dimensional structure of the parton content not only of nucleons but also of nuclei will become accessible in unprecedented precision (note that quarkonium also plays a central role in the study of transverse momentum dependent gluon distributions [412][413][414][415]). While only on the horizon, the goal for theory would be to eventually understand at least partially the changes induced in the parton distribution functions in a nuclear environment from first principle. With the rapid pace of advances in lattice QCD simulations over the past decade such insight might not be out of reach in the next decade.</p>
        <p>There are many aspects of heavy quarkonium in extreme conditions that did not find their way into this report. One is the physics at finite baryon chemical potential, whose study from first principles is still hindered by lattice QCD simulations suffering from the sign problem. Future collider facilities such as NICA and FAIR, as well as the beam energy scan at RHIC set out to explore this region of the QCD phase diagram in more detail, offering additional motivation for theory to develop novel computational approaches for this regime.There are many aspects of heavy quarkonium in extreme conditions that did not find their way into this report. One is the physics at finite baryon chemical potential, whose study from first principles is still hindered by lattice QCD simulations suffering from the sign problem. Future collider facilities such as NICA and FAIR, as well as the beam energy scan at RHIC set out to explore this region of the QCD phase diagram in more detail, offering additional motivation for theory to develop novel computational approaches for this regime.</p>
        <p>Another topic is the physics of quarkonium at large external magnetic fields (for a review on magnetic fields in heavyion collision see e.g. Refs. [416][417][418]), which recently has attracted attention in the community (see e.g. Refs. [419][420][421]). With first principles computations possible, the question to answer is whether or how such large fields can exert an influence on quarkonium formation in the early stages of collisions. This bring us to the third topic which is the formation dynamics of quarkonium at early time. Currently only simple estimates based on the uncertainty principle are used to argue why some quarkonium stated may form early on in the prethermal phase. To gain a true first principles understanding of quarkonium production we will however need to develop genuine real-time descriptions for heavy quark pairs in the presence of strong coherent glasma fields. First steps in that direction are being taken at the moment by combining classical statistical simulations of gauge fields with a real-time implementation of the effective field theory of NRQCD [422].Another topic is the physics of quarkonium at large external magnetic fields (for a review on magnetic fields in heavyion collision see e.g. Refs. [416][417][418]), which recently has attracted attention in the community (see e.g. Refs. [419][420][421]). With first principles computations possible, the question to answer is whether or how such large fields can exert an influence on quarkonium formation in the early stages of collisions. This bring us to the third topic which is the formation dynamics of quarkonium at early time. Currently only simple estimates based on the uncertainty principle are used to argue why some quarkonium stated may form early on in the prethermal phase. To gain a true first principles understanding of quarkonium production we will however need to develop genuine real-time descriptions for heavy quark pairs in the presence of strong coherent glasma fields. First steps in that direction are being taken at the moment by combining classical statistical simulations of gauge fields with a real-time implementation of the effective field theory of NRQCD [422].</p>
        <p>The study of heavy quarkonium in extreme conditions hence remains an active field of research with many challenging facets for both experiment and theory. The start-up of new colliders in the near future and the continuation of successful programs at current facilities, all with quarkonium on the agenda, promises continued research funding opportunities in the field for the next decade. This support will help the theory community to sustain its activities in the quest for a truly microscopic QCD based understanding of quarkonium in extreme conditions.The study of heavy quarkonium in extreme conditions hence remains an active field of research with many challenging facets for both experiment and theory. The start-up of new colliders in the near future and the continuation of successful programs at current facilities, all with quarkonium on the agenda, promises continued research funding opportunities in the field for the next decade. This support will help the theory community to sustain its activities in the quest for a truly microscopic QCD based understanding of quarkonium in extreme conditions.</p>
        <p>Alexander Rothkopf: Conceptualization, Data curation, Investigation, Writing -original draft, Writing -review &amp; editing.Alexander Rothkopf: Conceptualization, Data curation, Investigation, Writing -original draft, Writing -review &amp; editing.</p>
        <p>need to be taken into account.need to be taken into account.</p>
        <p>The author thanks Y. Akamatsu and P. Petreczky for insightful discussions and the nuclear theory group at the University of Tokyo for their hospitality, where part of this manuscript has been composed. The author also would like to thank the referees of Physics Report for valuable suggestions and comments that have contributed to improving the quality of this manuscript. Funding from the Research Council of Norway under the FRIPRO Young Research Talent grant 286883 and grant 295310 is gladly acknowledged.The author thanks Y. Akamatsu and P. Petreczky for insightful discussions and the nuclear theory group at the University of Tokyo for their hospitality, where part of this manuscript has been composed. The author also would like to thank the referees of Physics Report for valuable suggestions and comments that have contributed to improving the quality of this manuscript. Funding from the Research Council of Norway under the FRIPRO Young Research Talent grant 286883 and grant 295310 is gladly acknowledged.</p>
    </text>
</tei>
