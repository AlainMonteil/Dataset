<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-25T06:31+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>The European Space Agency's Planck satellite, which was dedicated to studying the early Universe and its subsequent evolution, was launched on 14 May 2009. It scanned the microwave and submillimetre sky continuously between 12 August 2009 and 23 October 2013, producing deep, high-resolution, all-sky maps in nine frequency bands from 30 to 857 GHz. This paper presents the cosmological legacy of Planck, which currently provides our strongest constraints on the parameters of the standard cosmological model and some of the tightest limits available on deviations from that model. The 6-parameter ΛCDM model continues to provide an excellent fit to the cosmic microwave background data at high and low redshift, describing the cosmological information in over a billion map pixels with just six parameters. With 18 peaks in the temperature and polarization angular power spectra constrained well, Planck measures five of the six parameters to better than 1 % (simultaneously), with the best-determined parameter (θ * ) now known to 0.03 %. We describe the multi-component sky as seen by Planck, the success of the ΛCDM model, and the connection to lower-redshift probes of structure formation. We also give a comprehensive summary of the major changes introduced in this 2018 release. The Planck data, alone and in combination with other probes, provide stringent constraints on our models of the early Universe and the large-scale structure within which all astrophysical objects form and evolve. We discuss some lessons learned from the Planck mission, and highlight areas ripe for further experimental advances.</p>
        <p>This paper, one of a set associated with the 2018 release of data from the Planckfoot_0 mission, presents the cosmological legacy of Planck. Planck was dedicated to studying the early Universe and its subsequent evolution by mapping the anisotropies in the cosmic microwave background (CMB) radiation.</p>
        <p>The CMB, discovered in 1965 (Penzias &amp; Wilson 1965;Dicke et al. 1965), has been a pillar of our cosmological world view since it was determined to be of cosmological origin. The CMB spectrum is the best-measured blackbody in nature (Fixsen 2009), and the absence of spectral distortions places very strong constraints on the amount of energy that could have been injected into the Universe at epochs later than z 2 × 10 6 (e.g., Fixsen et al. 1996;Chluba &amp; Sunyaev 2012). This limits the properties of decaying or annihilating particles, primordial black holes, topological defects, primordial magnetic fields, and other exotic physics. Perhaps its largest impact, however, has come from CMB anisotropies, the small deviations in intensity and polarization from point to point on the sky.</p>
        <p>The anisotropies in the CMB, first detected by the Cosmic Background Explorer (COBE) satellite (Smoot et al. 1992), provide numerous, strong tests of the cosmological paradigm and the current best measurements on most of the parameters of our cosmological model (Planck Collaboration XVI 2014;Planck Collaboration XIII 2016;Planck Collaboration VI 2018). The COBE detection cemented the gravitational instability paradigm within a cold dark matter (CDM) model (Efstathiou et al. 1992). Ground-based and balloon-borne experiments (e.g., de Bernardis et al. 2000;Balbi et al. 2000;Miller et al. 2002;Macías-Pérez et al. 2007) established that the Universe has no significant spatial curvature (Knox &amp; Page 2000a;Pierpaoli et al. 2000). The Wilkinson Microwave Anisotropy Probe (WMAP) showed that the fluctuations are predominantly adiabatic (Kogut et al. 2003; from the phasing of the peaks and polarization) and provided multiple, simultaneous, tight constraints on cosmological parameters (Bennett et al. 2003) -a legacy that the Planck mission has continued and enriched (Sect. 3.2).</p>
        <p>Planck was the third-generation space mission dedicated to measurements of CMB anisotropies. It was a tremendous technical success, operating in a challenging environment without interruption over three times the initially planned mission duration, with performance exceeding expectations. Currently our best measurements of the anisotropy spectra on the scales most relevant for cosmology come from Planck.</p>
        <p>Some milestones in the Planck mission are listed in Table 1. A set of 13 pre-launch papers was published in a special issue of Astronomy and Astrophysics (Vol. 520, 2010; see Tauber et al. 2010). For an overview of the scientific operations of the Planck mission see Planck Collaboration I (2014) and the Explanatory Supplement (Planck Collaboration ES 2015, 2018). The first set of scientific data, the Early Release Compact Source Catalogue (ERCSC; Planck Collaboration VII 2011), was released in January 2011. A set of 26 papers related to astrophysical foregrounds was published in another special issue of Astronomy and Astrophysics (Vol. 536, 2011;see Planck Collaboration I 2011). The first cosmological results from Planck, based mainly on temperature maps of the whole sky acquired during the nominal mission duration of 15.5 months, were reported in 2013 and the data products made available (as "PR1") on the Planck Legacy Archive (PLAfoot_1 ). These cosmological results were published as a series along with further data-processing and astrophysics papers in 2014 (A&amp;A Vol. 571, 2014;see Planck Collaboration I 2014). The first results from the full mission, including some polarization data, were presented in 2015; for a summary see Planck Collaboration I (2016). The raw time-ordered observations were released to the public in their entirety in February 2015, as part of this second Planck data release ("PR2"), together with associated frequency and component sky maps and higher-level science derivatives.</p>
        <p>This paper is part of a final series of papers from the Planck collaboration, released along with the final data ("PR3"). It presents an overview of the Planck mission and the numerous contributions Planck has made to our understanding of cosmology, that is, we consider the cosmological legacy of Planck.</p>
        <p>After a broad overview of the useful products derived from Planck data, from the maps at nine frequencies to astrophysical components and their broad characterization (specifics of this release are detailed in Appendix A), we discuss the CMB anisotropies, which were the main focus of the Planck mission. We then turn to a comparison of our results to theoretical models, and the way in which the Planck data confirm and inform those models, before comparing to a wider range of astrophysical and cosmological data. A discussion of how Planck has placed constraints on models of the early and late Universe and the relationship of the Planck data to other cosmological probes precedes a discussion of the post-Planck landscape, and finally our conclusions. In appendices, we include some details of this release, and a more detailed discussion of improvements in the data processing between the 2015 and 2018 releases.</p>
        <p>Details about the Planck mission and its scientific payload and performance have been discussed in previous publications (Planck Collaboration I 2014, 2016, andreferences therein). Planck was the first submillimetre mission to map the entire sky to sub-Jansky sensitivity with angular resolution better than 10 . In this section we describe the calibration and main properties of the frequency maps (Figs. 1 and2), and the methods used to separate the sky emission into different components. We briefly describe the main foreground components before discussing the CMB anisotropies, whose characterization was the main goal of the Planck mission.</p>
        <p>We distinguish between two dipoles related to motion with respect to the CMB rest frame. The first is the "Solar dipole," induced by the motion of the Solar System barycentre with respect to the CMB. The second is the "orbital dipole," that is, the modulation of the Solar dipole induced by the orbital motion of the satellite around the Solar System barycentre. The orbital velocity is known exquisitely well, and hence the induced dipole in ∆T/T units; this means that the accuracy of the predicted orbital dipole is ultimately limited by the accuracy with which we know the temperature of the CMB. In the 2015 data release, photometric calibration from 30 to 353 GHz was based on the "orbital dipole". This allowed us to measure the amplitude and direction of the "Solar dipole" on the calibrated maps of individual detectors, at frequencies where the CMB is the dominant signal (70 to 353 GHz). The dipole parameters measured in 2015 were significantly more accurate than the previous best measurements provided by WMAP (see Table 2). However, comparison of individual detector determinations showed clear indications of the presence of small residual systematic effects (Planck Collaboration II 2016;Planck Collaboration VIII 2016). The dipole amplitude and direction showed shifts with position in the focal plane for LFI; for HFI the shifts were associated with frequency, as well as with the Galactic mask and the component-separation method used, indicating the presence of dipolar and quadrupolar residuals after removal of the dust and CMB anisotropies.</p>
        <p>In 2018, both instruments have achieved a significant reduction in the levels of residual systematic effects (especially at the largest angular scales where the dipole signals are present) and in the case of HFI also in the accuracy of photometric calibration. Furthermore, the HFI dust foreground effect was identified with large-scale (mostly quadrupolar) spectral energy distribution changes. Correcting these brought full consistency between frequencies, as well as for detectors within each frequency band. This has resulted in dramatic improvement in the determination of the 2018 Solar dipole parameters, which are Fig. 1. Fluctuations of sky emission in each of nine Planck frequency bands, after removal of a common dipole component. The fluctuations are expressed as equivalent temperature variations at each of the seven lowest frequencies, so that fluctuations with a thermal spectrum will appear the same in each map (except for the effects of the varying resolution of the maps). The highest frequencies, which monitor the dust emission, are expressed in more conventional units. the last column indicates the polarized intensity, P = Q 2 + U 2 (although this emphasizes the strength of polarization in noisy regions). In addition to the rich science that they enable on their own, these maps set the baseline for all future CMB polarization experiments, for example by defining the most cosmologically challenged areas. Kogut et al. (1993); Lineweaver et al. (1996); we have added statistical and systematic uncertainty estimates linearly.</p>
        <p>b Hinshaw et al. (2009). c The 2015 Planck "nominal" Solar dipole was chosen as a plausible combination of the LFI and HFI 2015 measurements to subtract the dipole from the 2018 frequency maps. The difference compared with the final determination of the dipole is very small for most purposes. d Uncertainties include an estimate of systematic errors. In the case of HFI, we have added statistical and systematic errors linearly. e The current best Planck determination of the dipole is that of HFI (Planck Collaboration III 2018). The central value for the direction corresponds to RA = 167. • 942 ± 0.</p>
        <p>• 007, Dec = -6. • 944 ± 0.</p>
        <p>• 007 (J2000). The uncertainties are the (linear) sum of the statistical and systematic uncertainties detailed in Planck Collaboration III (2018). The uncertainty on the amplitude does not include the 0.02% uncertainty on the temperature of the CMB monopole.</p>
        <p>presented in Table 2. The independent LFI and HFI measurements are fully consistent with each other and with those of WMAP, and, as described in Planck Collaboration II (2018) and Planck Collaboration III (2018), they are no longer significantly affected by systematic effects (in the sense that the results are consistent between frequencies, sky fractions, and componentseparation methods used, although the uncertainties are not purely statistical). Considering that the uncertainties in the HFI determination are much lower than those of LFI, we recommend that users adopt the HFI determination of the Solar dipole as the most accurate one available from Planck.</p>
        <p>In the 2018 maps, the 2015 "nominal" Solar dipole, which is slightly different than the final best dipole, has been subtracted. (The induced quadrupole has also been subtracted from the maps.) This was done in order to produce a consistent data set that is independent of the best determination of the dipole parameters, which was made at a later time separately at each individual frequency. This implies that a very small, residual Solar dipole is present in all released maps. This can be removed if desired using the procedure described in Planck Collaboration III (2018).</p>
        <p>The Solar dipole can still be measured with high signalto-noise ratio at 545 GHz. The 545-GHz data were not calibrated on the orbital dipole, however, but instead on observations of Uranus and Neptune (Planck Collaboration III 2018). Therefore the photometric accuracy of this calibration is limited by that of the physical emission model of the planets, to a level of approximately 5 %. However, the dispersion of the Solar dipole amplitude measured in individual 545-GHz detector maps is within 1 % of that at lower frequencies. This implies that, in actual fact, the planet model can be calibrated on this measurement more precisely than has been assumed so far (Planck Collaboration Int. LII 2017). It also means that an improved model can be extended to recalibrate the 857 GHz channel. These improvements have not been implemented in the 2018 release.</p>
        <p>The amplitude of the dipole provides a constraint for building a picture of the local large-scale structure, through the expected convergence of bulk-flow measurements for galaxies (e.g., Scrimgeour et al. 2016). The new best-fit dipole amplitude is known more precisely than the CMB monopole, and even when we fold in an estimate of systematic uncertainties it is now known to about 0.025 % (essentially the same as the monopole). The dipole amplitude corresponds to β ≡ v/c = (1.23357 ± 0.00036) × 10 -3 or v = (369.82 ± 0.11) km s -1 , where we have added in the systematic uncertainties linearly. When giving the amplitude of the dipole in temperature units, one should also include the uncertainty in T 0 .</p>
        <p>The Solar dipole direction lies just inside the little-known constellation of Crater (near the boundary with Leo). The error ellipse of Planck's dipole direction (a few arcsec in radius, or around 30 including systematic uncertainties) is so small that it is empty in most published astronomical catalogues. We discuss the cosmological implications of the dipole in Sect. 5.1.</p>
        <p>The Sun's motion in the CMB frame is not the only relative velocity of interest, and indeed from a cosmological perspective more relevant would be the motion of the centre of our Galaxy relative to the CMB or the motion of our group of galaxies relative to the CMB. The peculiar motion of the Local Group is well known to have a larger speed than that of the Sun relative to the CMB, due to the roughly anti-coincident direction of our rotation around the Galaxy. It is this larger peculiar velocity that has been the focus of studies to explain the origin of the motion in the context of structures in our extragalactic neighbourhood (e.g., Lynden-Bell et al. 1988;Tully et al. 2008). Estimates of the corrections required to obtain the motion of the Galactic centre relative to the CMB and the motion of the centre of mass of the Local Group relative to the CMB were given by Kogut et al. (1993), and have seldom been revisited since then. We summarize more modern determinations in Table 3.</p>
        <p>Firstly, we take the estimate of the Sun's motion relative to the Local Standard of Rest from Schönrich et al. (2010), which uses nearby stars, and the estimate of the motion of the LSR around the centre of the Milky Way from McMillan (2011), which combines studies of larger-scale Galactic dynamics. These can be subtracted from the Solar dipole to give the velocity of the Galactic centre relative to the CMB, as presented in the fourth line of Table 3.</p>
        <p>Secondly, we take the estimate of the Sun's velocity relative to the centre of the Local Group from Diaz et al. (2014), found by averaging velocities of members galaxies (as also performed by several other studies, e.g., Yahil et al. 1977;Courteau &amp; van den Bergh 1999;Mikulizky 2015). This vector can be subtracted from the Solar dipole velocity to derive the velocity of the Local Group relative to the CMB. The value is (620 ± 15) km s -1 in a direction (known to about a couple of degrees) that lies about 30 • above the Galactic plane and is nearly opposite in latitude to the direction of Galactic rotation. The uncertainty in the Local Group's speed relative to the CMB is almost entirely due to the uncertainty in the speed of the Sun relative to the centre-of-mass of the Local Group.</p>
        <p>The Low and High Frequency Instruments together contained an array of 74 detectors in nine bands, covering frequencies between 25 and 1000 GHz, imaging the whole sky twice per year with angular resolution between 33 and 5 . Table 4 gives the main characteristics of the Planck frequency maps, including angular resolution and sensitivity. An extensive series of null tests for the consistency of the maps is provided in Planck Collaboration XXXI (2014), Planck Collaboration I (2016), Planck Collaboration II (2018), and Planck Collaboration III (2018). We find impressive consistency between the maps. Consistency of absolute calibration across the nine frequency channels is discussed extensively in the same papers, and we discuss inter-instrument consistency in Appendix C. Some considerations about the principles followed in the Planck analysis (including a discussion of blinding) are given in Appendix D. For the main CMB channels (70-217 GHz) the inter-calibration is at the level of 0.2 % (Planck Collaboration I 2016). At 100 GHz, the absolute photometric calibration on large scales is an astounding 0.008 %. For the HFI polarization maps, the largest source of uncertainty is the polarization efficiency (Table 4).</p>
        <p>The beams are estimated from planetary observations, and the polarized beam models are combined with the specific scanning strategy to generate "effective beams," which describe the relation of maps to the sky (see Planck Collaboration IV 2016;Planck Collaboration VII 2016). The response in harmonic space is known as a window function, and both the mean windows and the major error eigenmodes are provided in the PLA. Typical uncertainties are well below 0.1 % for the main CMB channels.</p>
        <p>Figures 1 and2 show views of the sky as seen by Planck in intensity and polarization. Planck uses HEALPix (Górski et al. 2005) as its pixelization scheme, with resolution labelled by the N side value. In HEALPix the sphere is divided into 12 N 2 side pixels. At N side = 2048, typical of Planck maps, their mean spacing is 1. 7. Each panel in Fig. 1 shows the intensity in one of Planck's nine frequency channels, in Galactic coordinates. In all cases the figures are unable to convey both the angular resolution and the dynamic range of the Planck data. However, they serve to show the major features of the maps and the numerous astrophysical components that contribute to the signal. Similarly, Fig. 2 shows the polarization properties measured by Planck at seven frequencies. The CMB component of the maps has a 6% linear polarization, though the foregrounds exhibit differing polarization levels as a function of frequency.</p>
        <p>The most prominent feature in the maps is the Galactic plane, steadily brightening to both higher (where Galactic dust dominates the emission) and lower (where synchrotron and freefree emission dominate) frequencies. At high Galactic latitudes, and over much of the sky between 70 and 217 GHz, the signal is dominated by the "primary" CMB anisotropies, which were frozen in at the surface of last scattering and provide the main information constraining our cosmological model.</p>
        <p>To be more quantitative, it is useful to introduce two-point statistics, in the form of a two-point angular correlation function, or its harmonic-space counterpart, the angular power spectrum. We follow the usual convention and perform an harmonic decomposition of the sky maps. If T , Q, and U represent the intensity and polarization 3 Stokes parameters (in thermodynamic temperature units), then we define</p>
        <p>where ±2 Y m are the spin-spherical harmonics, which are proportional to Wigner D-functions 4 . The polarization is defined through the scalar E and pseudo-scalar B fields, which are nonlocal, linear combinations of Q and U (Zaldarriaga &amp; Seljak 1997;Kamionkowski et al. 1997;Hu &amp; White 1997;Dodelson 2003). For small patches of sky, E and B are simply Q and U in the coordinate system defined by the Fourier transform coordinate (Seljak 1997). Alternatively, near a maximum of the polarization the direction of greatest change for an E mode is parallel or perpendicular to the polarization direction (see Fig. 7).</p>
        <p>When statistical isotropy may be assumed, it demands that a * m a m be diagonal and depend only on . We write</p>
        <p>3 Planck uses the "COSMO" convention for polarization (corresponding to the FITS keyword "POLCCONV"), which differs from the IAU convention often adopted for astrophysical data sets (Planck Collaboration ES 2018).</p>
        <p>4 See e.g., Wikipedia.</p>
        <p>Planck Collaboration: The cosmological legacy of Planck a For LFI channels (30-70 GHz), this is the centre frequency. For HFI channels , it is a reference (identifier) frequency.</p>
        <p>b Mean FWHM of the elliptical Gaussian fit of the effective beam. c Estimates of noise in intensity and polarization scaled to 1 • assuming that the noise is white. These levels are unchanged from 2015. d Absolute calibration accuracy obtained using the measurement of the Solar dipole at = 1. e The 857-GHz channel retains the 2015 planet calibration, and the accuracy is calculated a posteriori using a model of planet emission (Planck Collaboration et al. 2017) and the 545-GHz data. f For LFI this is the ratio of 30-and 44-GHz half-ring cross-spectra in the range 50-850 to that of the 70-GHz cross-spectrum. For HFI it is the upper limit derived from the levels of the first three CMB acoustic peaks ( 15-1000), relative to the 100 GHz channel. g Additional calibration uncertainty applicable to Q and U only. For LFI, the additional uncertainty (based on simulations) is negligible. For HFI, the dominant inaccuracy is the knowledge of the polarization efficiency, which is currently derived from the relative levels of the first three CMB acoustic peaks ( 15-1000), in combination with a prediction of the best-fit T T -based cosmology. The best estimates (Planck Collaboration III 2018) indicate that a bias should be applied to the maps of 0.7, -1.7, and 1.9 %, at 100, 143, and 217 GHz, respectively, with an uncertainty as indicated in this table. h Average contribution of the zodiacal emission to the monopole. As the level of this emission is dependent on the time of observation, it has been removed from the frequency maps during processing. i Estimated uncertainty in the zero levels associated with Galactic emission. The zero levels were set by fitting a model of Galactic emission that varies as the cosecant of the latitude to the maps after CMB subtraction. The levels subtracted were 11.9, -15.4, and -35.7 µK CMB at 30, 44, and 70 GHz, respectively. j The zero levels of the HFI maps are set by correlating the Galactic emission component to a map of the diffuse H i column density, as in Planck Collaboration VIII (2014). The uncertainties in the estimated zero levels are unchanged since 2013. k Once the Galactic zero level has been set, the monopole of the Béthermin et al. (2012) CIB model has been added to the frequency maps. l The estimated uncertainty of the CIB monopole that has been added to the maps. and similarly for T E, EE, BB, etc. We find it convenient to define</p>
        <p>which we will often refer to as the angular power spectrum. An auto-spectrum, D XX indicates the approximate contribution per logarithmic interval of multipoles centred on to the variance of the fluctuation, that is, the 2-point correlation function at zero lag. It thus captures the relative importance of various contributions to the signal as a function of scale.</p>
        <p>Figure 3 shows the estimated levels of CMB and residual systematics in frequency maps as a function of scale. The plots show the E-mode power spectrum, D EE , for all core CMB channels at 70, 100, 143, and 217 GHz, and at the adjacent 30-and 350-GHz channels, which are of particular use for understanding foregrounds. At the largest scales, the residual systematics are comparable to the noise level, which is itself close to the low level of the reionization bump determined by Planck (see Sect. 6.6). This points to the great challenge of this measurement. At small scales, residual systematic effects are significantly smaller than the signal and the noise in the main CMB channels. This figure summarizes most of the data-processing work by the Planck collaboration, in the sense that it embodies the final quantitative understanding of the measurements and their processing. This determines what has to be included in faithful end-to-end simulations.</p>
        <p>The all-sky, fully calibrated maps of sky intensity and polarization, shown in Figs. 1 and2, together with their detailed instrumental characterization and simulations, are the main legacy of the Planck mission and will be a resource to multiple communities for addressing numerous science questions in decades to come. In the next few sections, we discuss the separation of the maps into their physical components and then the cosmological consequences that can be derived from the CMB anisotropies.</p>
        <p>In addition to the primary anisotropies that are the main focus of the Planck mission, the sky emission contains many other astrophysical components, which differ by their dependence on frequency as well as their spatial properties. By making measurements at multiple frequencies, spanning the peak of the CMB blackbody spectrum, we are able to characterize the foregrounds and reduce their contamination of the primary CMB anisotropies to unprecedented levels.</p>
        <p>In order to separate the maps into their contributing signals and to clean the CMB map from foregrounds, we have used four different approaches, as we did in earlier re- Fig. 3. Estimates of the residual polarization systematic effects and noise across the core CMB channels at 70-217 GHz and two adjacent foreground-monitoring channels at 30 and 353 GHz. The residual systematics E-mode auto-power spectra are compared to that of the CMB signal after convolution with the beam window function at that frequency (noting that the CMB contribution to the total signal is small in the foreground-monitoring channels). The top panel displays the 30-and 70-GHz channels of the LFI instrument, with specific systematic effects colour-coded in the accompanying legend. The middle and lower panels show the HFI estimates at 100 and 143 GHz, and at 217 and 353 GHz, respectively. 2016). The four approaches were initially selected as a representative of a particular class of algorithm (blind, non-blind, configuration-space, and harmonic-space methods). They were also checked with a common series of map simulations, the last test being blind (and actually used to select a baseline).</p>
        <p>Combined, they represent most of the methods proposed in the literature. They are:</p>
        <p>-Commander, a pixel-based parameter and template fitting procedure (Eriksen et al. 2008;Planck Collaboration X 2016); -NILC, a needlet-based internal linear combination approach (Basak &amp; Delabrouille 2013); -SEVEM, which employs template fitting (Leach et al. 2008;Fernández-Cobos et al. 2012); and -SMICA, which uses an independent component analysis of power spectra (Planck Collaboration IV 2018).</p>
        <p>In addition we employ the GNILC algorithm (Remazeilles et al. 2011) to extract high (electromagnetic) frequency foregrounds. Each method produces: CMB maps in Stokes I, Q, and U; confidence maps (i.e., masks); an effective beam; and a noise estimate map, together characterizing the CMB. The differences between the four maps can be used as an estimate of the uncertainty in the recovery of the CMB, and is reassuringly small (Planck Collaboration IV 2018). These CMB maps and accompanying simulations are the basic input for all analyses of homogeneity, stationarity, and Gaussianity of the CMB fields (Planck Collaboration VII 2018;Planck Collaboration VIII 2018;Planck Collaboration IX 2018).</p>
        <p>For this release, the primary objective of the componentseparation process was to obtain the best possible polarization maps. The steps taken to ensure high-fidelity polarization maps (especially at 100-353 GHz) are described in detail in Planck Collaboration III (2018); see also Appendix B. Some of the choices made for the sake of polarization compromised to some extent the accuracy of the temperature maps; advice on how to use the temperature maps is contained within Planck Collaboration III (2018). The Planck 2018 data release does not include new foreground reconstructions in intensity, since the improved HFI processing regarding bandpass leakage requires new methodological developments in other areas that are not yet available (see Appendices B.2 and B.4).</p>
        <p>Even with these compromises, the foreground maps produced by Planck in this and the 2015 release are a treasure trove for many areas of astrophysics, including the study of the Galactic interstellar medium (see, e.g., Planck Collaboration XI 2018; Planck Collaboration XII 2018), the cosmic infrared background (CIB; Planck Collaboration XXX 2014), and the Sunyaev-Zel'dovich (SZ) effect (Sunyaev &amp; Zeldovich 1972, 1980). SZ-related science results from Planck are reported in, for example Planck Collaboration XXII (2016) and Planck Collaboration XXIV (2016).</p>
        <p>Planck's unprecedented sensitivity and frequency coverage have enabled dramatic advances in component separation, reducing the frequency maps into their astrophysical components, as described above. These component products, which should be thought of as phenomenological rather than being based on ab initio models, include maps in both temperature and polarization of: the CMB; the thermal SZ effect; thermal dust and the cosmicinfrared background; carbon monoxide; synchrotron; free-free; and anomalous microwave emission. They also effectively give rise to catalogues of compact Galactic and extragalactic sources, including polarization information. The maps and catalogues have a wide range of astrophysical uses that we shall not attempt to survey here (but see appendix A of Planck Collaboration XII 2018, for a guide to the Planck papers dealing with polarized thermal emission from dust).</p>
        <p>An overview of the frequency dependence of the major components (free-free emission, synchrotron, and dust) is given in Fig. 4. We first look at the angular power spectra of these contaminants, since this allows us to better judge the foreground contributions at different angular scales in regions actually used for the cosmology analysis. Figure 5 shows the angular power spectra of the sky at 143 GHz, compared to that of the primary CMB. Out to 2500 the latter dominates for the key cosmology channels. This shows that the Galaxy is fortunately more transparent to the CMB over most angular scales than one might fear based on the examination of Fig. 4. The full angular spectra at all frequencies, including the T E cross-spectra, can be found in Planck Collaboration V (2018).</p>
        <p>The foregrounds can be usefully characterized as Galactic or extragalactic, and diffuse or compact. Compact sources have been obtained by identifying locations with a significantly high signal in a narrow band-pass spatial filter. 2016) provides a list of 2 151 high-frequency sources (called the "PHz" catalogue, see also Planck Collaboration Int. XXVII 2015), selected over 26 % of the sky using a combination of submillimetre colours. These are likely to lie at high redshift (z &gt; ∼ 2), the majority being over-densities of star-forming galaxies (including a population of proto-clusters), with a small fraction representing some of the brightest submillimetre gravitational lenses discovered so far (Cañameras et al. 2015). A discussion of how sources are treated (e.g., masked or modelled) for the main cosmology analysis can be found in Planck Collaboration IV ( 2018 The data (corrected for systematic effects) are very well fit by a model (cyan curves) that is largely dominated by the CMB fluctuation spectra (light blue curves, mostly inside the model), with a superposition of foreground emission (orange curves) dominated by dust at large scales (red curve), together with a noise contribution (dotted line). We note, however, that foreground emission actually dominates the "reionization bump" at the lowest polarization multipoles. The grey shaded area shows the area in temperature which is not used for cosmology.</p>
        <p>Planck detects many types of diffuse foregrounds, which must be modelled or removed in order to study the primary CMB anisotropies. The separation of the diffuse emission into component maps is described in Planck Collaboration IX (2016). At frequencies below 50 GHz, the total intensity is dominated by free-free (bremsstrahlung from electron-ion collisions), syn-chrotron, and spinning dust emission, while polarization is dominated by synchrotron emission from relativistic cosmic ray electrons spiralling in the Galactic magnetic field (e.g., Planck Collaboration XXV 2016). At higher frequencies (above 100 GHz) the total intensity is dominated by thermal dust emission from our Galaxy (extending to high Galactic latitudes and sometimes referred to as "cirrus") at low , and the cosmic infrared background (CIB; primarily unresolved, dusty, starforming galaxies) at high (Planck Collaboration XXX 2014). Only the former contribution is significantly polarized. There is also a small contribution from free-free and synchrotron emission near 100 GHz.</p>
        <p>Above 70 GHz, polarized thermal emission from diffuse, interstellar, Galactic dust is the main foreground for CMB polarization. Grain sizes are thought to range from microns to that of large molecules, with the grains made primarily of carbon, silicon, and oxygen. The dust is made up of different components with different polarization properties, and has a complex morphology.</p>
        <p>Planck has already determined that there are no dust-free windows on the sky at the level relevant for future CMB experiments, so measuring and understanding this important foreground signal will be a major component of all future CMB polarization experiments. The Planck results show that pre-Planck dust models were too simplistic, and suggest that more accurate models, which include the insights from Planck, will take many years to fully develop. However, Planck observations already provide us with unprecedented data to describe, at least on a statistical basis, the turbulent component of the Galactic magnetic field and its interplay with the structure of interstellar matter on scales ranging from a fraction of a parsec to 100 pc (Planck Collaboration Int. XIX 2015). The data show that the interstellar magnetic fields have a coherent orientation with respect to density structures, aligned with filamentary structures in the diffuse interstellar medium, and mainly perpendicular in star forming molecular clouds (Planck Collaboration Int. XXXII 2016;Planck Collaboration Int. XXXV 2016). This result is far from being clearly understood, but it may signal the importance of magnetic fields in the formation of structures in the interstellar medium.</p>
        <p>The polarization power spectra of dust are well described by power laws, with C EE,BB ∝ -2.42±0.02 , and frequency dependence given by a modified blackbody (similar to that for the total intensity, namely an emissivity index of about 1.55 and a temperature of about 20 K). The power spectrum analyses presented in Planck Collaboration Int. XXX (2016) led to three unexpected results: a positive T E correlation; C BB 0.5 C EE for 40 &lt; &lt; 600; and a non-negative T B signal from Galactic dust emission. Several studies (Clark et al. 2015;Planck Collaboration Int. XXXVIII 2016;Ghosh et al. 2017) have shown that both the observed T E correlation and the asymmetry between E-and B-mode amplitudes for dust polarization can be accounted for by the preferred alignment between the filamentary structure of the diffuse ISM and the orientation of the magnetic field inferred from the polarization angle (while the non-zero T B correlation is also related to the fact that the Milky Way is not parity invariant). Planck Collaboration Int. L (2017) further demonstrated that the frequency spectral index of the emission varies across the sky. We discuss this important foreground component further in Planck Collaboration IV (2018), Planck Collaboration XI (2018), andPlanck Collaboration XII (2018).</p>
        <p>Planck produced the first well-calibrated, all-sky maps across the frequencies relevant for CMB anisotropies. The dramatic increase in our understanding of the submillimetre sky has wide legacy value. For cosmology, perhaps the most important lesson is the realization that there are no "holes" in which one can see B modes comparable to the signal from a tensor-to-scalar ratio r ∼ 10 -2 without component separation. At this level, foreground contamination comes from both low fre-quencies (synchrotron) and high frequencies (dust), with neither component being negligible. In this component-separationdominated regime, wide frequency coverage, such as attained by Planck, will be essential.</p>
        <p>Figure 6 shows the maps of CMB anisotropies on which we base our analyses of the statistical character of these fluctuations. 5The component with the highest signal-to-noise ratio (S/N) is the temperature anisotropy. As shown later, Planck has measured more than a million harmonic modes of the temperature map with a signal-to-noise greater than unity.</p>
        <p>The (linear) polarization signal is shown in the middle panel with a relatively low angular resolution of 5 • to increase legibility. The polarization signal, shown by rods of varying length and orientation,foot_3 is smaller in amplitude than the temperature signal. It is dominated by E modes generated by Thomson scattering in the last-scattering surface of the anisotropic temperature field. Unlike the temperature, Planck's measurement of the polarization is limited by noise. The small-scale polarization pattern and its relationship to temperature anisotropies can be appreciated in Fig. 7, which displays a 10 • × 10 • patch in the vicinity of the south ecliptic pole and a zoom into the central 2.5 • × 2.5 • patch. In these figures, the polarization is superimposed on the temperature anisotropies (shown in the background). It is clear that the two fields are correlated, as expected in the standard model (Sect. 4.1). This is directly visualized in Fig. 8 by stacking the polarization pattern around hot spots of the temperature anisotropy map. It reveals that the pattern is mirror-symmetric, that is, it is predominantly E modes, as expected. This trace of the dynamics of acoustic perturbations at the last scattering surface behaves precisely accordingly to ΛCDM predictions (simulated in the right panel).</p>
        <p>Most of the signal seen in the first two maps of Fig. 6 is dominated by processes occurring at z 10 3 . However, the deflection of CMB photons by the gravitational potentials associated with large-scale structure subtly modifies the signals Planck observes. By measuring the impact of this CMB lensing on such wide-area but high-angular-resolution sky maps, Planck is able to measure the lensing potential over much of the sky (Planck Collaboration XVII 2014;Planck Collaboration XV 2016;Planck Collaboration VIII 2018). This is shown in the bottom panel of Fig. 6 and provides sensitivity to the lowerredshift Universe and a powerful test of the gravitational instability paradigm.</p>
        <p>The primary use of CMB maps is to study their statistical properties. It turns out that the primary CMB anisotropies (formed at the last-scattering epoch) are extremely close to Gaussian-distributed (Planck Collaboration VII 2018;Planck Collaboration IX 2018), although there are a number of potential deviations (or "anomalies") to which we shall return in Sect. 5.6. This is in accord with the predictions of the simplest models of inflation, and indeed provides strong • . This smoothing is done for visibility purposes; the enlarged region presented in Fig. 7 shows that the Planck polarization map is still dominated by signal at much smaller scales. Both CMB maps have been masked and inpainted in regions where residuals from foreground emission are expected to be substantial. This mask, mostly around the Galactic plane, is delineated by a grey line in the full resolution temperature map. The bottom panel shows the Planck lensing map (derived from ∇φ, that is, the E mode of the lensing deflection angle), specifically a minimum variance, Wiener filtered, map obtained from both temperature and polarization information; the unmasked area covers 80.7 % of the sky, which is larger than that used for cosmology. constraints on many inflationary models (see Sect. 5 and Planck Collaboration X 2018). Such models also imply that the information content in the CMB comes from its statistical properties, rather than the precise locations of individual features, and that those properties are statistically isotropic. Since a Gaussian field can be entirely described by its mean and correlation function, and since the mean is zero by definition for the anisotropies, essentially all of the cosmologically-relevant information in the CMB anisotropies resides in their correlation functions or power spectra. This allows a huge compression, with concomitant increase in S/N: the 1.16 billion pixels in the 23 maps can be compressed to 10 6 high-S/N multipoles. As we will see later, the ΛCDM model allows even more dramatic compression: only six numbers describe around 10 3 σ worth of power spectrum detection.</p>
        <p>2.6. CMB angular power spectra</p>
        <p>The foreground-subtracted, frequency-averaged, cross-halfmission T T , T E, and EE spectra are plotted in Fig. 9, together with the Commander power spectrum at multipoles &lt; 30. The figure also shows the best-fit base-ΛCDM theoretical spectrum fitted to the combined temperature, polarization, and lensing data.</p>
        <p>Figure 9 clearly illustrates that Planck has determined the angular power spectrum of the primary temperature anisotropies to high precision across all the physically relevant scales. In this sense, Planck brings to an end an era in CMB studies that was opened by the first detection of these anisotropies by COBE in 1992 (Smoot et al. 1992). At the same time, Planck has made important measurements of the polarization power spectra and maps of the effects of gravitational lensing. Improvements in these measurements will be the focus of the field in coming years. Fig. 9. Planck CMB power spectra. These are foreground-subtracted, frequency-averaged, cross-half-mission angular power spectra for temperature (top), the temperature-polarization cross-spectrum (middle), the E mode of polarization (bottom left), and the lensing potential (bottom right). Within ΛCDM these spectra contain the majority of the cosmological information available from Planck, and the blue lines show the best-fitting model. The uncertainties of the T T spectrum are dominated by sampling variance, rather than by noise or foreground residuals, at all scales below about = 1800 -a scale at which the CMB information is essentially exhausted within the framework of the ΛCDM model. The T E spectrum is about as constraining as the T T one, while the EE spectrum still has a sizeable contribution from noise. The lensing spectrum represents the highest signal-to-noise ratio detection of CMB lensing to date, exceeding 40 σ. The anisotropy power spectra use a standard binning scheme (which changes abruptly at = 30), but are plotted here with a multipole axis that goes smoothly from logarithmic at low to linear at high . In all panels, the blue line is the best-fit Planck 2018 model, based on the combination of T T , T E, and EE.</p>
        <p>The impressive agreement between the ΛCDM model and the Planck data will be the subject of later sections. For now let us focus on a number of ways of characterizing the information obtained in the spectra of Fig. 9.</p>
        <p>One way of assessing the constraining power contained in a particular measurement of CMB anisotropies is to determine the effective number of a m modes that have been measured. This is equivalent to estimating 2 times the square of the total S/N in the power spectra, a measure that contains all the available cosmological information (Scott et al. 2016) if we assume that the anisotropies are purely Gaussian (and hence ignore all non-Gaussian information coming from lensing, the CIB, cross-correlations with other probes, etc.). Translating this S/N into inferences about cosmology or particular parameters is not straightforward, since it needs to take into account how the spectra respond to changes in parameters and in particular to degeneracies; however, the raw numbers are still instructive. For the Planck 2013 T T power spectrum, the number was 826 000 (rounded to the nearest 1 000, including the effects of instrumental noise, cosmic variance, and masking). The 2015 T T data increased this value to 1 114 000, with T E and EE adding a further 60 000 and 96 000 modes, respectively (where these were from the basic likelihood, with a conservative sky fraction). Based on the 2018 data the numbers are now 1 430 000 for T T , 64 000 for T E, 109 000 for EE, and also 3 000 for φφ (the lensing spectrum). For comparison, the equivalent number of modes from the final WMAP T T power spectrum is 150 000.</p>
        <p>Planck thus represents a 900 σ detection of power (for the sake of simplicity, we do not include the correlations of the covariance in this calculation; doing so would increase these numbers by about 10-20 %). This increases even further if one is less conservative and includes more sky, along with more complicated foreground modelling.</p>
        <p>The acoustic peaks in the D s reveal the underlying physics of oscillating sound waves in the coupled photon-baryon fluid, driven by gravitational potential perturbations. One can easily see the fundamental mode (which reaches a density and temperature maximum as the Universe recombines) at 220, and then the first harmonic, the second harmonic, and so on. It is natural to treat the positions of the individual peaks in the power spectra as empirical information that becomes part of the canon of facts now known about our Universe.</p>
        <p>Fitting for the positions and amplitudes of features in the band powers is a topic with a long history, with approaches becoming more sophisticated as the fidelity of the data has improved (e.g., Scott &amp; White 1994, Hancock &amp; Rocha 1997, Knox &amp; Page 2000b, de Bernardis et al. 2002, Bond et al. 2003, Page et al. 2003, Durrer et al. 2003, Readhead et al. 2004, Jones et al. 2006, Hinshaw et al. 2007, Corasaniti &amp; Melchiorri 2008, Pryke et al. 2009). We follow the approach (with small differences) described in Planck Collaboration I (2016), fitting Gaussians to the peaks in T T and EE, but parabolas to the peaks in T E. For T T we remove a featureless damping tail (using extreme lensing) in order to fit the higher-region (starting with trough 3). 7 We also fit the first peak in C EE with a Gaussian directly. Our numerical values, presented in in Table 5, are consistent with previous estimates, but with increased precision. Planck detects 18 peaks (with still only marginal detection of the eighth T T peak) and 17 troughs, for a total of 35 power spectra extrema (36 if the C φφ peak is included).</p>
        <p>We shall use the rich structure of the anisotropy spectra, described above, to constrain cosmological models in later sections.</p>
        <p>The photons that we see as the cosmic microwave background must traverse almost the entire observable Universe on their way to us. During this journey they have their wavelengths stretched by the cosmological expansion and their paths deflected by the gravitational potentials associated with inhomogeneities in the Universe (Blanchard &amp; Schneider 1987). The lensing-induced deflections are of order 2 to 3 , coherent over patches 2 • to 3 • across, and arise primarily from structures at redshifts of 0.5-10. Since each photon undergoes multiple deflections during its travel, this "secondary" anisotropy is enhanced over naive ex-Planck Collaboration: The cosmological legacy of Planck pectations and turns out to be one of the most important secondary signals we measure. This "gravitational lensing" of CMB photons by largescale structures along their path has several effects (see e.g., Lewis &amp; Challinor 2006;Hanson et al. 2010, for reviews). One is to slightly smooth the peak and trough structure of the CMB power spectra and the damping tail (this is fully accounted for by the numerical codes when deriving the parameter constraints on a model; Seljak 1996). Another effect is to transform some of the polarization E modes into B modes, adding to the potentially pre-existing B-mode contribution from primordial tensor fluctuations (Zaldarriaga &amp; Seljak 1998). These distortions couple adjacent modes, which would otherwise be uncorrelated if the initial fluctuations were statistically homogeneous. This can then be used to obtain an estimator of the lensing potential by cross-correlating CMB maps (T , E, B) and their derivatives, with appropriate weightings (Hu &amp; Okamoto 2002;Hirata &amp; Seljak 2003). These lensing measurements provide sensitivity to parameters that affect the late-time expansion, the geometry, or the clustering of matter, and can be cross-correlated with large-scale structure surveys in a variety of ways (see Sect. 6.2).</p>
        <p>The lensing deflections are usually written as the gradientfoot_7 of a "lensing potential," α = ∇ψ( n), which is a measure of the integrated mass distribution back to the surface of last scattering:</p>
        <p>where χ * is the comoving distance to the surface of last scattering and Ψ W is the (Weyl) potential, which probes the matter through Poisson's equation. For this reason the nearly all-sky lensing map shown in Fig. 6 provides a remarkable view of (essentially) all of the matter in the Universe, as traced by photons travelling through 13.8 Gyr of cosmic history. At &gt; 40 σ, this is the largest area, and highest significance, detection of weak lensing to date and constrains the amplitude of large-scale structure power to 3.5 % (Planck Collaboration VIII 2018). The highest S/N per mode is achieved near L = 60, where the signal-to-noise ratio per L is close to unity (we follow the standard convention and use L rather than for lensing multipoles). This drops by about a factor of 2 by L = 200, though there is still some power out beyond L = 1000.</p>
        <p>Planck was the first experiment to measure the lensing power spectrum to higher accuracy than it could be theoretically predicted from measurements of the anisotropies. This represents a turning point, where lensing measurements start to meaningfully impact parameter constraints. In the future, lensing will play an increasingly important role in CMB experiments -a future that Planck has ushered in.</p>
        <p>In addition to enhancements of data processing into maps, the final data release includes several improvements in the lensing pipeline over the 2013 and 2015 analyses (Planck Collaboration VIII 2018), including a polarization-only lensing reconstruction, as a demonstration of consistency and a cross-check on the paradigm. In addition to the lensing measured from the CMB channels, Planck Collaboration VIII (2018) also presents a joint analysis of lensing reconstruction and the CIB, as probed by our highest frequency channels. The CIB is a high-z tracer of the density field that is around 80 % correlated with the CMB lensing potential. Figure 10 shows the lensing deflection inferred from our lensing maps, stacked on the 20 000 brightest peaks and deepest troughs in the CIB. One can clearly see the high degree of correlation and the expected convergence and divergence patterns around over and underdensities. Having a high signal-to-noise ratio, the CIB map provides a good estimate of the lensing modes on small scales and the best picture we have at present of the lensing potential. Finally, Planck Collaboration VIII (2018) demonstrates that the smoothing effect of lensing on the CMB acoustic peaks can be corrected, with "delensing" removing approximately 50 % of the effect. The ability to delens the CMB will grow in importance as we move into a future of low-noise observations where lensing-induced power becomes dominant.</p>
        <p>The lensing potential power spectrum provides additional information on the low-z Universe, and thus an alternative route to constraining cosmological parameters and a means of breaking degeneracies that affect the primary anisotropies. The reduction in the uncertainty of the effects of reionization afforded by the new low-polarization data (see Sect. 3.2) leads to a reduction in the uncertainty on the power spectrum normalization when using primary anisotropies alone. The constraints on the amplitude from the primary anisotropies are thus tighter, and this reduces the impact of the lensing upon parameter shifts. However, lensing still plays an important role and provides a consistency check on the overall picture. For example, the best-determined combination of parameters from CMB lensing is σ 8 Ω 0.25 m , which is now determined to 3.5 % (0.589 ± 0.020; 68 % CL). Combining this with the baryon density from big-bang nucleosynthesis (BBN) and distance measurements from baryon acoustic oscillations (BAOs) allows us to place competitive constraints on σ 8 , Ω m , and H 0 individually (Planck Collaboration VIII 2018).</p>
        <p>Our baseline lensing likelihood is based on an f sky 70 %, foreground-cleaned combination of the high-frequency maps. The usable range of multipoles extends from L = 8 to L = 400. Multipoles below this are adversely affected by a large and uncertain mean-field correction (Planck Collaboration VIII 2018). Although the lensing maps are provided to L = 4096, the data above L = 400 do not pass some null tests (Planck Collaboration VIII 2018) and thus are regarded as less reliable. Multipoles L 60 become increasingly noise dominated, but some residual signal is present even at very high L, which can be of use in cross-correlation or stacking analyses.</p>
        <p>In addition to the power-spectrum band powers and covariance, we have released temperature-based, polarizationbased, and joint temperature-and polarization-based convergence maps, plus the simulations, response functions, and masks necessary to use them for cosmological science. We also release the joint CIB map, the likelihood, and parameter chains.</p>
        <p>Probably the most striking characteristic to emerge from the last few decades of cosmological research is the almost unreasonable effectiveness of the minimal 6-parameter ΛCDM model in accounting for cosmological observations over many decades in length scale and across more than 10 Gyr of cosmic time. Though many of the ingredients of the model remain highly mysterious from a fundamental physics point of view, ΛCDM is one of our most successful phenomenological models. As we will discuss later, it provides a stunning fit to an ensemble of cosmological observations on scales ranging from Mpc to the Hubble scale, and from the present day to the epoch of last scattering.</p>
        <p>The ΛCDM model rests upon a number of assumptions, many of which can be directly tested with Planck data. With the 2014), a paper devoted to studying the gravitational lensing-infrared background correlation. It shows temperature maps of size 1 deg 2 at 545 GHz stacked on the 20 000 brightest peaks (left column), troughs (centre column), and random map locations (right column). The stacked (averaged) temperature maps are in K. The arrows indicate the lensing deflection angle deduced from the gradient of the band-pass filtered lensing potential map stacked on the same peaks. The longest arrow corresponds to a deflection of 6. 3, which is only a fraction of the total deflection angle because of our filtering. This stacking allows us to visualize in real space the lensing of the CMB by the potential wells traced by galaxies that generate the CIB. This vividly demonstrates that our lensing map, albeit noisy, is well correlated with a high-z tracer; it also warrants using the CIB as a lensing potential tracer at smaller scales (and in other experiments).</p>
        <p>model tested and the basic framework established, Planck provides the strongest constraints on the six parameters that specify the model (Tables 6 and7). Indeed, of these six parameters all but one -the optical depth -are now known to sub-percent precision (for n s this claim depends upon the conventional choice that n s = 1 represents scale-invariance).</p>
        <p>A complete list of the assumptions underlying the ΛCDM model is not the goal of this section, but below we list several of the major assumptions.</p>
        <p>A1 Physics is the same throughout the observable Universe. A2 General Relativity (GR) is an adequate description of gravity. A3 On large scales the Universe is statistically the same everywhere (initially an assumption, or "principle," but now strongly implied by the near isotropy of the CMB). A4 The Universe was once much hotter and denser and has been expanding since early times. A5 There are five basic cosmological constituents:</p>
        <p>(a) Dark energy that behaves just like the energy density of the vacuum. (b) Dark matter that is pressureless (for the purposes of forming structure), stable, and interacts with normal matter only gravitationally. (c) Regular atomic matter that behaves just like it does on Earth. (d) The photons we observe as the CMB. (e) Neutrinos that are almost massless (again for structure formation) and stream like non-interacting, relativistic particles at the time of recombination. A6 The curvature of space is very small. A7 Variations in density were laid down everywhere at early times, and are Gaussian, adiabatic, and nearly scale invariant (i.e., proportionally in all constituents and with similar amplitudes as a function of scale) as predicted by inflation. A8 The observable Universe has "trivial" topology (i.e., like R 3 ).</p>
        <p>In particular it is not periodic or multiply connected.</p>
        <p>With these assumptions it is possible to predict a wide range of observations with a very small number of parameters. The observed fact that the fluctuations in temperature and polarization in the CMB are small makes the calculation of CMB observables an exercise in linear perturbation theory (see Peacock 1999, Dodelson 2003, Mukhanov 2005, Peter &amp; Uzan 2009and Lyth &amp; Liddle 2009 for textbook treatments, and Partridge 1995 andPeebles et al. 2009 for historical discussions). The evolution of the perturbations in each species can be computed to high accuracy using a "Boltzmann code" once the initial conditions, constituents, and ionization history are specified. The initial conditions are part of our assumptions. The high-z part of the ionization history can be computed to high accuracy given the assumptions above (see, e.g., extensive discussion and references in Planck Collaboration Int. XLVII 2016). Thus one needs to specify only the values of the constituents and the low-z part of the ionization history.</p>
        <p>To fully prescribe the ΛCDM model we need to specify its parameters. Adopting the convention that the Hubble parameter today is H 0 = 100 h km s -1 Mpc -1 , we take these to be: the density of cold dark matter, ω c = Ω c h 2 ; the density of baryons, ω b = Ω b h 2 (consisting of hydrogen, and helium with mass fraction Y P obtained from standard BBN); the amplitude, A s , and spectral index, n s , of a power-law spectrum of adiabatic perturbations; a proxy (θ MC ; Eq. 6 of Planck Collaboration XVI 2014) for the angular scale of the acoustic oscillations, θ * ; and the optical depth to Thomson scattering from reionization, τ. The best-fit model and constraints on these parameters are given in Tables 6 and7.</p>
        <p>We assume that the radiation is made up of photons (as a blackbody with T = 2.7260 K, Fixsen 2009) and neutrinos with ρ ν = N eff (7/8)(4/11) 4/3 ρ γ andfoot_8 N eff = 3.046 (Mangano et al. 2002). The neutrinos are assumed to have very low masses, which we approximate as a single eigenstate with m ν = 0.06 eV. Other parameters can be derived from these and the assumptions that we already spelled out. For example, since |Ω K | 1, we have Ω Λ = 1 -Ω m , and the redshift of equality can be found from ρ γ + ρ ν = ρ c + ρ b (assuming neutrinos are relativistic at z &gt; 10 3 , as required by the current data). A list of derived parameters and their relation to the base parameters can be found in Planck Collaboration XIV (2016) or Tables 6 and7. Further discussion of how the parameters affect the anisotropy spectra can be found in the aforementioned textbooks or in Planck Collaboration XIV (2016) and Planck Collaboration Int. LI (2017).</p>
        <p>Figure 9 shows the measured angular power spectra from Planck, with the blue line representing the best-fit ΛCDM model. Beginning with the T T spectrum, one can see three regions, separated by two characteristic scales. On scales larger than the Hubble scale at last scattering (low ) the almost scaleinvariant spectrum is a pristine imprint of the initial conditions. On degree angular scales the almost harmonic sequence of power maxima represents the peaks and troughs in density and temperature of the baryon-photon fluid as it oscillates in the gravitational potentials prior to recombination. On scales smaller than the geometric meanfoot_9 of the Hubble scale and the mean free path, photon diffusion during the epoch of recombination erases the fluctuations. A similar behaviour is seen in the polarization spectra, without the low-plateau and with sharper peaks that are sourced primarily by the quadrupole anisotropy generated during last scattering. Not visible by eye, but included in the calculation, are slight changes to the primordial signal due to gravitational lensing by large-scale structure along the line of sight.</p>
        <p>Figure 9 nicely illustrates the three conditions that make the CMB such a powerful cosmological probe: (i) exquisite measurements with well controlled and understood systematic errors; (ii) a reliable and computationally tractable framework for statistical inference and well understood statistical errors; and (iii) a rich phenomenology predicted by a precise theoretical model, allowing simultaneous and tight constraints on key parameters.</p>
        <p>The best determined parameter is θ * (for which θ MC is a proxy), which is constrained to better than 0.03 % by the peak and trough positions. Since θ * is determined by the positions of the extrema, not their amplitudes, the measurement is extremely stable and only weakly dependent upon the model details. One of the impressive consistency checks of the paradigm is that θ * determined from the temperature power spectrum matches to high precision those determined from the polarization power spectrum and from the cross-spectrum between temperature and polarization. This limits the fraction of the perturbations that were not adiabatic in nature. The angular scale of the acoustic oscillations measures the ratio of the (comoving) angular diameter distance to last scattering and the sound horizon, r * = c s dt = dη/ 3(1 + 3ρ b /4ρ γ ), with η the conformal time. Within the ΛCDM model, r * depends on the sound speed and the Hubble scale at last scattering, which is primarily determined by the baryon and matter densities. The angular-diameter distance depends primarily upon the late-time evolution and geometry, and within ΛCDM this translates into a dependence on h and ω m . Since ω b (which changes the mass loading of the photon-baryon fluid and hence the ratio of gravity to pressure) is well constrained (&lt; 1 %) by the relative amplitudes of the acoustic peaks, the θ * measurement provides a very tight constraint in the 2-dimensional Ω m -h subspace:</p>
        <p>The direction orthogonal to the Ω m h 3 line is less well constrained. Changes in Ω m h 2 affect the damping scale and the amount by which the gravitational potentials are determined by the cold dark matter (which does not take part directly in the acoustic oscillations), as opposed to the amount determined by the baryon-photon fluid. This alters the relative heights of the peaks, allowing a sub-percent-level measurement of both Ω m h 2 and h, and hence constraints on Ω m and Ω Λ .</p>
        <p>Changes in the primordial spectral index, n s , yield a corresponding change in the observed CMB power spectrum. Increasing n s , with the amplitude fixed at the pivot point k = k 0 = 0.05 Mpc -1 , increases power at &gt; 500 while decreasing power at &lt; 500, since modes with k = k 0 project onto angular scales close to = 500. Given the large lever arm of Planck, measuring three decades in wavenumber, we can isolate this tilt precisely and have shown that it departs from scale invariance at more than 8 σ.</p>
        <p>Finally, reionization in the late Universe (z &lt; ∼ 10) recouples the CMB photons to the matter field (but not as tightly as before recombination, since the matter density has dropped by six orders of magnitude in the intervening period). Scattering of photons off electrons in the ionized intergalactic medium suppresses the power in the primary anisotropies on scales smaller than the Hubble scale at reionization ( &gt; 10) by e -2τ , only weakly generating new anisotropies. More importantly for our ability to measure τ, the scattering of photons during this period generates additional polarization on large scales (set by the angle subtended by the Hubble scale at reionization), whose amplitude scales as C EE ∝ τ 2 . The combination of high sensitivity with all-sky coverage allows Planck to measure this large-angle signal in order to constrain τ and limits the redshift of reionization to &lt; 9 at the 95 % confidence level.</p>
        <p>To demonstrate the impressive advances in the field, we show in Figs. 11 and 12 the evolution of constraints on some of the parameters of the base ΛCDM model and its most common extensions, in Fig. 13 the improvement in statistical weight, and in Figs. 14 and 15 the improvements in a number of extensions. Figure 11 focusses on parameters describing "the early Universe," while Fig. 12 presents late-time and derived parameters. In order to avoid too many arbitrary choices, we have opted to plot only CMB constraints and have started the historical development with the pre-WMAP compilations of Wang et al. (2003) and Bond et al. (2003). The values for WMAP and Planck are taken from the LAMBDA archivefoot_10 and the PLA, respectively.</p>
        <p>The top two panels of Fig. 11 indicate non-detections of non-Gaussianity and primordial tensor models, respectively, with dramatically improved precision. The last panel shows how the primordial power spectrum is now convincingly known to depart from scale invariance (n s = 1), with more power at large scalesfoot_11 than a scale-invariant spectrum. The Planck data demonstrate this departure from scale invariance in a way that is robust to single-parameter extensions of the basic ΛCDM model.</p>
        <p>Figure 12 shows a dramatic shrinking of the error bars on the late-time parameters, a reduction that becomes even more impressive considering that they are all being constrained simultaneously. Except for the optical depth, τ, the parameters are simultaneously known with percent-level precision.</p>
        <p>Another view of the dramatic increase in precision on these key parameters describing our Universe is shown in Fig. 13. Here we present, for a selection of parameters, how the "statistical weight" has improved over time. We use the inverse variance on each parameter (marginalised over all of the others and normalized to unity for the last Planck point) as a proxy for statistical weight. While other choices could be defended, this provides one way of seeing how the continuing high-quality fits of the model and improvements in the data have refined our knowledge of these key parameters.</p>
        <p>Particularly impressive in Fig. 13 are the improvements in measurement of the densities, ω m and ω b , and the present-day expansion rate, h, each now measured at over 100 σ. These parameters are key to defining both the evolution of the background cosmology and the shape of the matter power spectrum describing large-scale structure. The dramatic improvements visible in Fig. 13 translate directly into improvements in our ability to convert redshift into times or distances, to measure volumes and number densities, and to characterize the cosmic web within which all astrophysical objects (e.g., galaxies) form and evolve.</p>
        <p>Finally we emphasize the large step forward taken with the Planck data by showing in Fig. 14 how the constraints on 1-parameter extensions to ΛCDM have improved in going from pre-WMAP to Planck. For pre-WMAP, we have included the joint constraints from the BOOMERANG, MAXIMA, DASI, VSA, and CBI experiments (Netterfield et al. 2002;Hanany et al. 2000;Halverson et al. 2002;Scott et al. 2003;Pearson et al. 2003). Prior to WMAP, there were few meaningful constraints on extended models, even those with only one additional parameter. The situation improved with the WMAP measurements, but many extensions remained highly unconstrained. Fig. 11. Evolution of CMB constraints on assumptions and parameters describing "early Universe physics," specifically the amount of primordial, local non-Gaussianity ( f NL ), the tensor-toscalar ratio (r), and the slope of the primordial power spectrum (n s ).</p>
        <p>With the advent of Planck, most of these 1-parameter extensions are now highly constrained, and become even more so if additional data are added.</p>
        <p>Figure 15 provides a different view of this same improvement, extending farther back to COBE (a data set of three bands from = 2-26; Bennett et al. 1996) supplemented by a Planck prior on the optical depth τ = 0.055 ± 0.009. It shows the impressive increase of the figure of merit, defined by FoM -2 = det Cov Ω b h 2 ; Ω c h 2 ; τ, A s ; n s ; . . . , for various models and data sets, relative to COBE. The relative reduction of the allowed parameter space volume is impressive for all models. For ΛCDM, the 6-dimensional space has decreased in volume by about 10 10 in the 26 years since the initial discovery. For the 11-dimensional models that we also consider here, the reduction is a million times larger.</p>
        <p>One of the strongest pieces of evidence for the universality of physics (point A1 in Sect. 3.1) comes from the agreement between the baryon density, ω b , as measured by the CMB and through consideration of BBN. The inference from the CMB relies on the acoustic physics of the primordial plasma before 400 000 yr. The inference from BBN depends upon modelling nuclear physics in the first 3 minutes after the big bang, calibrated by laboratory measurements here on Earth. The comparison invokes all of the known forces of nature: strong and weak Fig. 12. Evolution of CMB constraints on parameters describing "late time physics," specifically the matter density (ω m ≡ Ω m h 2 ), the baryon density (ω b ≡ Ω b h 2 ), the acoustic scale (θ * ), the normalization of the (linear theory) matter power spectrum (σ 8 ), the dimensionless Hubble constant (h), and the Thomson optical depth (τ). nuclear, electromagnetic, and gravity. The level of agreement is remarkable, as shown in Fig. 16.</p>
        <p>The connection between cosmology and GR (point A2) goes back to the founding of both subjects in the early part of the 20th century. GR has been extensively tested on the scale of the Solar System (e.g., Will 2006). The recent direct detection of gravitational waves (Abbott et al. 2016) provides a further confirmation of the theory in the strong gravitational fields of merging black holes. The detection of an optical counterpart (Abbott et al. 2017b) provides stringent limits on the speed of propagation of gravitational waves and thus on modified gravity theories (Lombriser &amp; Taylor 2016;Creminelli &amp; Vernizzi 2017;Ezquiaga &amp; Zumalacárregui 2017;Sakstein &amp; Jain 2017;Baker et al. 2017;Crisostomi &amp; Koyama 2018;Amendola et al. 2018b). By contrast, constraints on modifications of gravity on large scales are weaker, although complementary because they apply to an entirely different regime.</p>
        <p>The structure of the peaks in the anisotropy power spectra depends upon the gravity-driven oscillations of a relativistic fluid, and as such is sensitive to departures from the predictions of GR. Indeed, most modifications of gravity take as a starting point that GR be restored in the early Universe, precisely in order to avoid modifying the predictions of CMB anisotropies (Jain &amp; Khoury 2010;Joyce et al. 2015Joyce et al. , 2016;;Amendola et al. 2018a).</p>
        <p>In the presence of inhomogeneity, the metric of space-time is perturbed from its Friedmann form. It is common to parametrize the deviations to the time-time and space-space components by two potentials (often denoted Ψ and Φ, where Ψ is the Newtonian potential while Φ represents the General Relativistic effect of the bending of space by gravity). General Relativity predicts that, in the absence of anisotropic stresses, Ψ and Φ should be equal in magnitude (Peacock 1999;Dodelson 2003;Lyth &amp; Liddle 2009). The Planck data alone can place a constraint on the deviation of the two metric potentials from the GR prediction at the last-scattering surface. Assuming that the mod-ification to the potentials is scale independent, the ratio of the potentials (in units of the GR prediction 13 ) is η slip = 1.004 ± 0.007 (68 % CL).</p>
        <p>(7)</p>
        <p>This shows that gravity is behaving in the early Universe exactly as predicted by General Relativity, and is one of the tightest constraints on the behaviour of the potentials at such early epochs. At late times, direct constraints on modifications to GR on cosmological scales are weaker. Planck has also served an important role in these constraints by providing an all-sky map of lensing, which can be compared to dynamical measurements at relatively recent epochs. Gravitational lensing measures the combination of Φ and Ψ, while the motions of non-relativistic objects such as galaxies probe only the time-time component (Ψ). It is this fact that accounts for the famous "factor of 2" in Einstein's prediction for the bending of light by the Sun, as tested in the eclipse expedition of 1919. For this reason, a comparison of the two measures provides a useful check of GR on cosmological scales. The fact that the ΛCDM model provides a good fit to a wide range of auto-and cross-correlations (Sect. 4) suggests that GR passes this test. Pullen et al. (2016) and Singh et al. (2018) quantified this expectation by crosscorrelating low-z galaxies with the Planck lensing maps, finding consistency with the predictions of GR on tens of Mpc scales, although with intriguing tension on very large scales. Finally, the large-scale gravitational potentials are predicted to decay once the expansion of the Universe begins to accelerate, leading to an additional source of anisotropy: the integrated Sachs-Wolfe (ISW) effect (Sachs &amp; Wolfe 1967). Here the blueshift of photons falling into a potential is not precisely cancelled by the redshift upon climbing out due to the evolution of the potential during traversal. Planck's measurements of the ISW effect are consistent with expectations (Planck Collaboration XIX 2014;Planck Collaboration XXI 2016).</p>
        <p>The low level of the relative fluctuations in the CMB provides some of our strongest evidence for the statistical homogeneity and isotropy of the Universe (point A3), and the impressive fit of the ΛCDM model predictions to the observations relies on all of the above assumptions.</p>
        <p>The blackbody nature of the CMB is the best evidence that the Universe was once hot and dense (point A4). Further evidence comes from the wiggles we see in the angular power spectrm, which arise due to acoustic oscillations in the baryonphoton plasma. This implies that the Universe was hot enough to ionize hydrogen and dense enough to support acoustic oscillations without excessive dissipation.</p>
        <p>The constituents of the Universe (point A5) have been described previously. Within the ΛCDM paradigm the CMB allows measurements to be made of the total density of these components to high precision. We shall return to points A6 and A7 when we discuss the impact of Planck on studies of inflation and fundamental physics. Here we simply highlight how the CMB spectra provide strong evidence that the fluctuations from which all structure grows were laid down at very early times. The combination of the regular, oscillatory structure of the CMB peaks and the relative phases of the temperature and polarization spectra implies that the perturbations responsible for CMB anisotropies were "primordial" and "apparently acausal" (Coulson et al. 1994;Crittenden &amp; Turok 1995;Hu &amp; White 1996a;Hu et al. 1997;Spergel &amp; Zaldarriaga 1997). By z 1100 the fluctuations were all in their growing ; Ω c h 2 ; τ, A s ; n s ; . . . -1/2 for various models and data sets, relative to COBE. This shows the relative improvement with respect to the anisotropy discovery experiment, COBE (with first results in 1992). For COBE, we have additionally (anachronistically) assumed a Planck prior on the optical depth 0.055 ± 0.009. The relative reduction of the allowed phase space volume is impressive for all models, with even greater shrinkage in volume for higher-dimensional model extensions. For ΛCDM, the improvement is more than 10 10 . For the largest model spaces, having four or five additional dimensions compared to ΛCDM, this improvement is more than 10 16 in 26 years, corresponding to a 6-month doubling time, three times faster than Moore's Law! This is one reason why the study of the CMB has allowed us to address more and more ambitious questions with time, a feature that is expected to continue with future experiments.</p>
        <p>mode, and there is no evidence for "active sources" during this period (e.g., cosmic strings or textures, whose motion generates anisotropies, see Planck Collaboration XXV 2014). Importantly, there were fluctuations in spatial curvature on scales larger than the Hubble length at last scattering. Two of the most significant properties of dark energy, for cosmology, are that it be spatially nearly constant and only recently relevant. Sections 5.5, as well as Planck Collaboration XIV (2016) and Planck Collaboration VI (2018) discuss Planck's constraints on these properties. To give just one example, the combination of Planck data with other, lower-redshift data sets demands that the dark-energy contribution must rise from less than 10 % of the total to nearly 70 % of the total within just the last e-fold of expansion and the contribution from any "early" dark energy must be highly sub-dominant. The constraints on DM decays and neutrino masses are dealt with in Sect. 5.3 and Sect. 5.4.</p>
        <p>In addition, the Planck maps provide the highest quality, full-sky view of the surface of last scattering that we have, and as such allow us to place extremely tight constraints on departures from a globally isotropic cosmology with trivial topology (point A8; Planck Collaboration XVIII 2016). Searches for cubic toroidal or slab topologies yield no detection, with a scale below the diameter of the last-scattering surface. The excellent agreement on the inferred value of ω b from processes in the first 3 minutes of the Universe's history with that from the CMB at 380 000 years after the big bang is one of our best demonstrations of the universality of the laws of physics.</p>
        <p>The Planck data constrain the parameters of the base, 6parameter, ΛCDM model with high precision, without the need for any external data sets. With the model tested and constrained, it can then be used to make predictions for a host of other astrophysical measurements. Despite its apparent simplicity, the model -with the Planck-constrained parameters -has proven to be extremely successful in describing a wide range of cosmological data across four orders of magnitude in scale and 13.8 Gyr of cosmic history.</p>
        <p>In this section we describe the extent to which the predictions of this model are in accord with other data sets and point out where there are tensions.</p>
        <p>Planck is not the first experiment to measure CMB anisotropies, nor will it be the last. So we begin our discussion of concordance by assessing the degree to which different measurements of the CMB sky by different experiments agree. Our focus will be on the most recent and powerful experiments, since these provide the most stringent tests.</p>
        <p>Internal consistency checks and jackknife tests, including splits by spatial and electromagnetic frequency, are discussed extensively in Planck Collaboration Int. LI (2017), Planck Collaboration V (2018), and Planck Collaboration VI (2018), and we refer the reader to those papers and to Appendix B for details. A discussion of HFI-LFI consistency is given in Appendix C. While some mild tensions exist, overall the data are highly consistent. One of the newest consistency checks that is made available by the latest Planck data is a comparison of the temperature and polarization power spectra.</p>
        <p>That the CMB sky be linearly polarized is a direct consequence of the existence of the anisotropies and the polarization dependence of Thomson scattering, which itself traces back to electromagnetic gauge invariance (for a pedagogical review see Hu &amp; White 1997). Since the origin of the temperature and polarization spectra are so closely intertwined, we can use them as a test of internal consistency. In fact we find that the Planckmeasured T T , T E, and EE CMB power spectra are completely consistent with each other under the assumptions of ΛCDM (Planck Collaboration V 2018; Planck Collaboration VI 2018). The same ΛCDM models that fit the temperature provide good fits to the polarization data and vice versa. Figure 17 shows the difference between the T T , T E, or EE spectra we measure and the spectra predicted by the ΛCDM model that best fits the other two. The differences are completely consistent with expectations given our noise and sky coverage. Not surprisingly, the ΛCDM model parameters that best fit each subset of the spectra are consistent. We see small shifts in the parameters as more data are added, with the size of the shifts consistent with our expectations. The comparison of the temperature, polarization, and lensing spectra may provide some indication that the temperatureonly results have fluctuated "high" in some parameters (e.g., σ 8 ) and that adding more data has brought us closer to the mean. We will see similar behaviour when we consider the distance scale as probed by BAO (Sect. 6.3), and discuss this further in Sect. 4.3.</p>
        <p>External consistency checks come from comparing the Planck angular power spectra to those measured by other experiments. No single experiment can match Planck's sky coverage and angular resolution, but we can compare to multiple experiments in order to test our data. A comparison of the Planck power spectrum measurements with those of other, contemporary, experiments is given in Fig. 18 2016). While Planck dominates the primary temperature anisotropy measurements and the E-mode polarization measurements up to 10 3 , the other experiments' higher angular resolution and sensitivity provide better measurements 14 of secondary anisotropies (at high ), as well as B-mode polarization. A next generation of experiments, soon to be fielded, will also improve upon Planck's lensing measurement. Visually, the impression in Fig. 18 is one of concordance in all of the spectra.</p>
        <p>The comparison of the lower-resolution and noisier WMAP data to Planck has been discussed in some detail in Planck Collaboration XVI (2014) and Planck Collaboration XIII (2016). The agreement is excellent, multipole by multipole, for the frequencies in common, up until the WMAP data become significantly affected by noise. The agreement between the best-fitting ΛCDM models is also quite good, once external data (such as BAO) are introduced to break the degeneracies that the WMAP data do not have sufficient dynamic range to break internally. For example 14 Though Planck still contributes here as a source of calibration.</p>
        <p>the constraints ω m = 0.1398 ± 0.0023, H 0 = 68.14 ± 0.73, and σ 8 = 0.82 ± 0.18 are obtained from WMAP plus BAO, whereas ω m = 0.14240 ± 0.00087, H 0 = 67.66 ± 0.42, and σ 8 = 0.8102 ± 0.0060 come from Planck plus BAO.</p>
        <p>Planck Collaboration Int. LI (2017) further investigated the discrepancy in ΛCDM parameters between Planck and WMAP alone. They found that when one carefully compares low-data to full-data, the differences are not as large as they might naively appear to be (with probabilities to exceed of order 10 %). When the lever arm of the data is reduced by only using the larger angular scales ( &lt; 800), cosmological parameters are more strongly affected by the low-deficit (Sect. 5.6), that is, the apparent lack of power at &lt; ∼ 30 compared to ΛCDM expectations. To decrease power at &lt; ∼ 30, the best-fit n s increases, A s e -2τ is then lowered to reduce power at &gt; ∼ 500, and ω m decreases to compensate the induced change of power below 500, while ω b increases to reduce the amplitude of the second peak (which was raised by the decrease in ω m ). The Hubble constant is in turn pulled higher to keep the angular size of the horizon unchanged. In the Planck data, the impact of the lowdeficit was much reduced by the presence of the high-data. As we saw above, if BAO data are combined with the WMAP data (to reduce the geometric distance degeneracy, wherein a change in physical scale can be traded against a change in distance to last scattering in order to hold the angular scale fixed) the parameters shift towards the Planck-preferred values (see Planck Collaboration Int. LI 2017, for further comparison).</p>
        <p>At the other end of the spectrum we can compare the Planck data to data with higher angular resolution and higher S/N from ACTPol (Louis et al. 2017) and SPTpol (Henning et al. 2018), but only over a limited area. The ACTPol results of Louis et al. (2017), from 100 deg 2 of sky, are consistent with the ΛCDM model fit to Planck. Similarly, Hou et al. (2018) find no evidence for systematic errors in either SPT or Planck when comparing temperature power spectra computed from the same area of sky. Aylor et al. (2017) and Planck Collaboration VI (2018) compare the parameters for the base-ΛCDM model between SPT and Planck. Again, restricting to the same patch of sky the agreement between the experiments is quite good. The Planck T E and EE spectra are compatible with the SPT T E and EE spectra over the multipole range well-constrained by Planck, though there are hints of some differences at higher multipoles (with limited statistical power, in a regime where foregrounds are large). However, the ΛCDM model that best fits the Planck data is formally inconsistent with the SPT T E + EE data. These issues are discussed in more detail in Planck Collaboration VI (2018). It will be interesting to see how this discrepancy develops, and whether it provides evidence for physics beyond ΛCDM or is due to systematic or statistical errors in the modelling of the data.</p>
        <p>In summary, once foreground models and calibrations are taken into account, and allowing for mild inaccuracies in the covariance matrices, the level of agreement between different CMB experiments is excellent.</p>
        <p>Within the gravitational instability paradigm, the anisotropies that we see in the CMB form the seeds for the large-scale structure that we observe more locally. It is thus interesting to ask whether these low-z measurements of inhomogeneity are consistent with what would be expected to arise from the anisotropies seen by Planck.</p>
        <p>Figure 19 shows inferences of the matter fluctuation spectrum from a wide range of different cosmological probes, cov- ] Fig. 17. Conditional residuals for the co-added T T (top panel), EE (middle), and T E (bottom) power spectra. The blue points show the difference between the co-added spectra and the 2018 base-ΛCDM spectra, with the points at more than 2 σ coloured pink. The black lines show the difference between the conditional prediction of the spectrum and the base model. The prediction for a given spectrum is performed (within the framework of base ΛCDM) conditional on the two others, e.g., in the top panel, the T T prediction is conditioned on both the T E and EE data. The solid and dashed blue lines show the ±1 σ and ±2 σ contours of the prediction (around the black line), corresponding to the diagonal of the block of the conditional covariance computed from the 2018 covariance matrix and data. Probabilities to exceed (PTEs) are computed for the difference between the data and its conditional prediction using the conditional covariance for each panel. We see that any pair of spectra predicts the third one well (assuming that ΛCDM is a good model), bringing support to the consistency of the temperature and polarization measurements within ΛCDM. This is particularly true at low and intermediate multipoles (where Planck is cosmic-variance limited), where the conditionals successfully predict the deviations of the co-added spectra from the theoretical base-ΛCDM spectra. Fig. 19. Linear-theory matter power spectrum (at z = 0) inferred from different cosmological probes (the dotted line shows the impact of non-linear clustering at z = 0). The broad agreement of the model (black line) with such a disparate compilation of data, spanning 14 Gyr in time and three decades in scale, is an impressive testament to the explanatory power of ΛCDM. Earlier versions of similar plots can be found in, for example, White et al. (1994), Scott et al. (1995), Tegmark &amp; Zaldarriaga (2002), and Tegmark et al. (2004). A comparison with those papers shows that the evolution of the field in the last two decades has been dramatic, with ΛCDM continuing to provide a good fit on these scales.</p>
        <p>ering three orders of magnitude in scale and much of cosmic history. The level of agreement, assuming the ΛCDM model, is quite remarkable. That structure grows through gravitational instability in a dark-matter-dominated Universe seems well established, and the power of the model to explain a wide range of different phenomena is impressive. However, the tremendous statistical power of the Planck data, and modern probes of largescale structure, is such that we can perform much more detailed comparisons than this. One consistency check, which we can make internal to the Planck data set, is to check whether the large-scale structure that lenses the CMB anisotropies at z 0.5-10 has the right amplitude given the size of the anisotropies and the constituents inferred from the acoustic oscillations. Between the epoch of last scattering at z 1100 and and the epoch corresponding to the peak of the lensing kernel (z 2-3), the fluctuations in the matter density are predicted to grow in amplitude by nearly three orders of magnitude. Since for much of this time the Universe is matter dominated and the fluctuations are in the linear regime, GR predicts the amount of growth at the percent level, allowing a precision test of the theory. In fact, the comparison can be done to such high accuracy that it is best phrased as a scaling, A φφ L , of the theoretical prediction -taking into account the distributed effects of lensing, etc. We find A φφ L = 0.997±0.031, which provides a stunning confirmation of the gravitational instability paradigm, and also allows us to constrain constituents of the Universe that do not cluster on small scales (such as massive neutrinos; see Sect. 5.3) and so reduce the small-scale power spectrum. Future, more precise, measurements of CMB lensing will provide strong constraints on neutrino masses, extra relativistic degrees of freedom, and early dark energy. Also shown in Fig. 19 are measurements of the matter power spectrum inferred from galaxy clustering and the Ly α forest. The former represents a measurement at z 0, although it has an uncertain amplitude because of galaxy bias. In plotting the SDSS galaxy clustering points, we have accounted for galaxy bias assuming the phenomenological bias model of Reid et al. (2010). Specifically, we have fit this model to the Planck bestfit cosmology, yielding {b 0 , a 1 , a 2 } = {1.23, 0.56, -0.35} at a pivot wave-number of k * = 0.2 h Mpc -1 . The agreement on the shape of the power spectrum at k 0.1 h Mpc -1 , between the galaxy surveys at z 0 and the predictions of ΛCDM constrained by Planck at z 10 3 , is a validation of the paradigm of gravitational instability in a Universe with predominantly cold dark matter. The measurements inferred from the Ly α forest are presented at z = 0 using a scale-and redshift-dependent relation between the 1D and 3D Ly α power spectra, coupled with the measured 3D flux power spectrum of Ly α absorption. The former was computed by means of hydrodynamical simulations, for a fiducial model corresponding to the best fit values of Palanque-Delabrouille et al. (2015); the latter was obtained by differentiating the corresponding 1D power spectrum using the method of Chartrand (2011). The measurements of Ly α are at higher redshift (2 &lt; z &lt; 3) than galaxy clustering and probe smaller scales, but are more model-dependent.</p>
        <p>Intermediate in redshift between the galaxy clustering and Ly α forest data are cosmic shear measurements and redshiftspace distortions (Hamilton 1998;Weinberg et al. 2013). Here we plot the results from the The Dark Energy Survey Y1 measurements (Troxel et al. 2017), which are currently the most constraining cosmic shear measurements. They show good agreement with the matter power spectrum inferred from ΛCDM constrained to Planck. Had we used earlier data from, for example, KiDS (Hildebrandt et al. 2017) it would have looked quite similar. These points depend upon the non-linear matter power spectrum, and we have used the method of Tegmark &amp; Zaldarriaga (2002) based on the fitting function of Peacock &amp; Dodds (1996) to deconvolve the non-linear effects, which yields constraints sensitive to larger scales than would would otherwise appear. The nuisance parameters have been fixed for the purposes of this plot. (More detail of the calculations involved in producing Fig. 19 can be found in Chabanier et al. 2019). Bearing in mind all of these caveats, the good agreement across more than three decades in wavenumber in Fig. 19 is quite remarkable.</p>
        <p>Figure 20 shows the ratefoot_13 of growth, f σ 8 , determined from redshift-space distortions over the range 0 &lt; z &lt; 1.6, compared to the predictions of ΛCDM fit to Planck. Though the current constraints from redshift surveys have limited statistical power, the agreement is quite good over the entire redshift range. In particular, there is little evidence that the amplitude of fluctuations in the late Universe determined from these measurements is systematically lower than predicted.</p>
        <p>We shall discuss in Sect. 6 cross-correlations of CMB lensing with other tracers and the distance scale inferred from baryon acoustic oscillations (BAO). In general there is very good agreement between the predictions of the ΛCDM model and the measurements. If there is new physics beyond base ΛCDM, then its signatures are very weak on large scales and at early times, where the calculations are best understood.</p>
        <p>While there are many measurements that are consistent with the predictions of the ΛCDM model fitted to Planck, there are also some areas of discordance.</p>
        <p>Within the Planck data themselves we find a preference for a larger smoothing of the power spectrum at small scales than the ΛCDM model predicts (Zarrouk et al. 2018).</p>
        <p>The agreement between the low-z measures and the ΛCDM prediction is very good, indicating that the model (constrained by observations in the high-z Universe) correctly predicts the rate of growth of large-scale structure observed in the nearby Universe.</p>
        <p>). While at face value it might seem like this smoothing is the sign of an excess amplitude of gravitational lensing, it is also possible to fit these features through non-lensing related effects (see Planck Collaboration Int. LI 2017, for discussion).</p>
        <p>The preference for these features is driven almost entirely by the CMB spectra and not by the lensing reconstruction, which is consistent with theoretical expectations. The peak smoothing features are not statistically highly significant (2-3 σ), and could just be statistical fluctuations in the data. Further, the level of significance depends upon choices made about the calibration of the polarization channels, the sky fraction, and other analysis choices, as discussed further in Planck Collaboration VI (2018). This discrepancy may indicate that the best-fit parameters from the primary CMB have fluctuated from their true values by a few σ, in which case the combination afforded by multiple probes may be a more faithful measure. We will discuss distance measurements using BAO in Sect. 6.3. There we will see (Fig. 27) that the inferred angular diameter distance to z 2 from the auto-and crosscorrelation of Ly α measurements by the Baryon Oscillation Spectroscopic Survey (BOSS) is discrepant with the ΛCDM predictions fit to Planck at about 2.3 σ (Bautista et al. 2017;du Mas des Bourboux et al. 2017). Within the ΛCDM family, parameter changes that would improve agreement with the Ly α distances are highly disfavoured by Planck and the more accurate, lower-redshift BAO measurements. Even within an extended class of models, it is very difficult to fit the combination of comoving angular diameter distance, D M , and Hubble distance, D H , inferred from the Ly α data (Aubourg et al. 2015). This mild tension could be the result of either a statistical fluctuation or as yet unrealized systematics in the Ly α measurements. However the size of the discrepancy highlights the importance of future measurements at these redshifts.</p>
        <p>At lower redshift, some measures of the amplitude of clustering prefer lower values than ΛCDM normalized to Planck. In particular the Köhlinger et al. (2017) analysis of the KiDS cosmic-shear-only results constrains S 8 ≡ σ 8 (Ω m /0.3) 0.5 to be 0.651 ± 0.058 (which was shifted upwards to 0.772 ± 0.034 in an alternative analysis by Troxel et al. 2018). When combined with galaxy data the results are 0.742 ± 0.035 or 0.800 ± 0.028 (Joudaki et al. 2018;van Uitert et al. 2018). The preferred value from Planck plus BAO is 0.825 ± 0.011, which is 2.9 σ higher, 1.5 σ higher, 2.3 σ higher, or basically consistent with these results. The recent DES results (DES Collaboration et al. 2017) are consistent with both Planck and the earlier lensing results, S 8 = 0.782 ± 0.024, when analysed with the same fixed neutrino mass assumption as Planck (Planck Collaboration VI 2018). While these data are in only modest tension with the Planck best-fit cosmology, they are consistent with each other and both pull to lower S 8 , which would lead to an increased significance in a joint analysis.</p>
        <p>Some estimates of the amplitude inferred from the abundance of rich clusters of galaxies also imply a lower σ 8 . The most difficult issue with these inferences is the dependence on the calibration of the mass-observable relation, which Planck itself can shed little light on. We discuss these observations further in Sect. 6.4.</p>
        <p>There is also tension at the very lowest redshifts. One of the notable impacts of the Planck data has been a downward shift in the value of H 0 compared with some earlier results (Fig. 21; plotted using the compilation of J. Huchrafoot_14 , though the shift is small compared to earlier versions of the "H 0 discrepancy"). The same downward shift in H 0 is seen if WMAP data are combined with BAO, which serves to break the geometric degeneracy that limits the WMAP data alone (leading to H 0 = 68.14 ± 0.73). A similar shift is also seen if BAO data are combined with inferences about ω b from BBN and just the acoustic scale measured by WMAP or Planck (Planck Collaboration VI 2018), or from Planck lensing plus BAO inverse-distance-ladder results (Planck Collaboration VIII 2018, table 3). Another view of this tension is shown in Fig. 22 (as discussed in more detail in Planck Collaboration VI 2018), which demonstrates how robustly the inverse-distance-ladder constraints prefer lower H 0 than the measurements of Riess et al. (2018aRiess et al. ( ,b, 2019)).</p>
        <p>It is worth revisiting how the inference of a "low" H 0 comes about from CMB data. Recall that the well measured θ * relates the sound horizon and the distance to last scattering. For ΛCDM this becomes a tight constraint on Ω m h 3 (Eq. 6). An increase of ω m decreases the sound horizon approximately as ω -0.25 m , requiring the distance to last scattering to decrease by the same amount. This distance is an integral of 1/H(z) out to z 1100, withfoot_15 H 2 (z) ∝ ω m (1 + z) 3 -1 + h 2 for the dominant contribution from z z eq . Thus h must decrease in order for the distance to last scattering not to decrease too much.</p>
        <p>The combination of absolute BAO distances calibrated to Planck, with relative SNe distances at overlapping redshifts, allows us to extrapolate the distance scale from moderate redshifts 2018), and Riess et al. (2018a,b). Blue circles show "traditional" measures of H 0 , while cyan and red squares show H 0 inferred from fits to CMB data from WMAP (Bennett et al. 2011;Hinshaw et al. 2013) and Planck. The magenta diamond shows the standard siren measurement from Abbott et al. (2017a). Inferences from the inverse distance ladder are discussed in the text and Fig. 22. We note the tremendous increase in precision with time, driven by improvements in methods and in data, and the narrowing of the difference between "high" and ''low" values of H 0 .</p>
        <p>to z = 0. This significantly reduces the sensitivity of inferences on H 0 to uncertainties in the dark energy model, but still results in a consistent H 0 value (Planck Collaboration VI 2018).</p>
        <p>The decrease in the inferred value of H 0 has resulted in tension with some locally derived values (e.g., Riess et al. 2019), as described in detail in Planck Collaboration VI (2018) and our earlier papers. In making this comparison it is important to realize that while the CMB results are very stable to different analysis choices and data sets, H 0 is not directly measured from the high-z data, but rather inferred via a model. One possibility is thus that the discrepancy between the results indicates a failure of the ΛCDM model. Unfortunately no simple, 1-parameter extension of the model alleviates the tension between the measurements. From the agreement between the Planck-inferred distance scale and that measured by BAO and SNe, it seems that any discrepancy should either be localized to quite low z or that ΛCDM is not correctly predicting the sound horizon at the lastscattering and decoupling epochs. It is quite difficult to change these quantities without changing other, well measured, features of the CMB (see, e.g., Eisenstein &amp; White 2004), so if the discrepancy is due to new physics, it must act in a complex manner. The more prosaic explanation is that there are under-appreciated systematics in one or all of the data sets. Alternatively, this could represent a statistical fluctuation: there are six dimensions in the ΛCDM parameter space, and many other derived-parameter directions, and hence large fluctuations in some direction occur relatively often. It is presently unclear what combination of statistical fluctuations, a posteriori statistics, systematic uncertainties, and genuinely new physics is responsible for any of the ten- sions seen in today's data combinations. Until this discrepancy is better understood we expect that this will continue to be a fruitful area of research.</p>
        <p>Finally, there are possible tensions on galactic and subgalactic scales, where the inner profiles of dark-matter halos and the abundance, orbital properties, and structure of satellites in the Milky Way and Andromeda provide a new avenue for testing ΛCDM. The comparison of theory and observation in this regime is quite complex and definitive statements are hard to make at this juncture; however, the field is evolving rapidly both observationally and theoretically. The challenges and possible resolutions are reviewed in Bullock &amp; Boylan-Kolchin (2017).</p>
        <p>We have already discussed the best estimate of the dipole pattern on the sky, with the usual interpretation that it derives from Doppler boosting of the CMB monopole, with an amplitude of βT 0 . In the standard picture there is an "intrinsic" dipole of order 10 -5 expected, although this is unobservable (as well as being a small fraction of the extrinsic, velocity-induced dipole). However, as has been discussed previously in the literature (e.g., Turner 1991;Zibin &amp; Scott 2008), there is also the possibility of an intrinsic isocurvature contribution to the observed dipole. In addition to the usual temperature dipole (i.e., the = 1 anisotropy pattern) on the sky, four separate effects appear at second order in β, namely: an inferred frequency-dependent quadrupole; an inferred frequency-dependent dipolar modula-tion of the CMB sky, altering the power on all scales according to a dipole pattern; a shift in the monopole temperature; and aberration of the CMB sky. The first two effects are independent of the source of the CMB dipole and therefore cannot be used to distinguish an intrinsic dipole from a boost. The third effect is unobservable. The last effect normally only appears in the presence of a boost. However, aberration is completely degenerate with an L = 1 lensing mode; in other words, a very large-scale gravitational potential fluctuation can shift the photon directions in a dipole pattern on the sky. Therefore, while the detection of aberration is consistent with interpreting the CMB dipole as arising from a boost, the case against an intrinsic dipole is not definitive (though quite compelling, since it would otherwise require an isocurvature mode on the largest scales, despite the fact that the fluctuations are consistent with being entirely adiabatic on all other scales).</p>
        <p>In Planck Collaboration XXVII (2014), we performed the first experimental verifications of the modulation and aberration effects, finding the former to be consistent with the prediction from the CMB dipole and the latter to be consistent with the interpretation of the dipole coming from a boost (barring any large sources of an L = 1 lensing mode). This required treating the signal as being a frequency-dependent coupling between adjacent modes. Given that aberration and modulation effectively shift the power spectra in the angular scale and amplitude directions, respectively, one also needs to consider whether these boosting effects, combined with masking part of the sky, can give any significant differences between the Planck-derived cosmological results and those that would come from an unboosted sky. Here the largest potential effect comes from aberration; for a full-sky CMB map it would average out, but for the Planck data the need to mask the Galaxy (in an asymmetric way) biases θ * at a level estimated conservatively to be less than 0.1 σ (Planck Collaboration VI 2018; agreeing with more detailed calculations by Jeong et al. 2014). The bias can hence safely be ignored for Planck.</p>
        <p>The second-order quadrupole signal (sometimes called the "kinematic quadrupole") also has a frequency-dependent spectrum, as discussed by Kamionkowski &amp; Knox (2003). This signal was already apparent in differences between the 2013 and 2015 Planck data releases, arising from the different treatment of the expected dipole-related quadrupole in these two data releases (see Planck Collaboration IX 2016; Planck Collaboration XII 2016); however, no estimate has been made of the amplitude of the signature, just a check that it is broadly consistent with expectation.</p>
        <p>A key ingredient of the standard cosmological model is the presence of small, seed fluctuations in the very early Universe, which are amplified by gravitational instability to form all of the structure we see in the Universe today. Some of the first observations of CMB anisotropies gave strong support to an early Universe origin for the fluctuations, through the coherence of the acoustic peaks in the power spectrum and the phasing of the temperature and polarization anisotropies (Coulson et al. 1994;Crittenden &amp; Turok 1995;Hu &amp; White 1996a;Hu et al. 1997;Spergel &amp; Zaldarriaga 1997). In the most popular models, a period of quasi-exponential expansion in the very early Universe pushes quantum fluctuations outside the Hubble volume, where they become classical perturbations in the gravitational potentials and density of the Universe (Lyth &amp; Liddle 2009). This highly parsimonious explanation, using the inevitable quantum "noise" as the source of all of the observed structure, is one of the key pieces of the "cosmo-micro" connection. Planck has dramatically improved upon this early legacy by firmly establishing essentially all of the major predictions of inflation (see Table 8), while tightly constraining many specific popular models of inflation. Whatever the true origin of the primordial fluctuations turns out to be, it must share these features with models of inflation.</p>
        <p>Table 8. Inflationary "scorecard," comparing the predictions of the simplest inflationary models with observations. In all cases, the tightest observational limits come from Planck, sometimes in combination with other data sets (as described in the text). Here we quote symmetric, 68 % CL uncertainties or 95 % upper limits on each quantity, taken from Planck Collaboration XI (2016), Planck Collaboration VI (2018), Planck Collaboration IX (2018), and Planck Collaboration X (2018). All quantities have their usual meanings, with α -1 the amplitude of an isocurvature component to the fluctuations and the topological defect limit referring specifically to Nambu-Goto cosmic strings (see table 8 of Planck Collaboration XI 2016, for other cases).</p>
        <p>A spatially flat universe Ω K = 0.0007 ± 0.0019 with a nearly scale-invariant (red) spectrum of density perturbations, n s = 0.967 ± 0.004 which is almost a power law, dn/d ln k = -0.0042 ± 0.0067 dominated by scalar perturbations, r 0.002 &lt; 0.065 which are Gaussian f NL = -0.9 ± 5.1 and adiabatic, α -1 = 0.00013 ± 0.00037 with negligible topological defects f &lt; 0.01</p>
        <p>The comparison of the Planck measurements with models of inflation is discussed in detail in Planck Collaboration XXII (2014), Planck Collaboration XX (2016), and Planck Collaboration X (2018). As summarized in Table 8, Planck provides very strong support for the inflationary paradigm, and at the same time tightly constrains the space of allowed inflationary models (Fig. 23). There are several points to note in the table. First, the combination of Planck data with lower-redshift data on acoustic oscillations (measured in the distribution of galaxies) tightly constrains the spatial hypersurfaces to be flat (Ω K = 0.0007 ± 0.0019, 68 % CL). In the standard interpretation, this suggests that the duration of the slow-roll phase was not fine tuned.</p>
        <p>The primordial power spectrum shows no significant deviations from a power law (e.g., Fig. 24). That the simple, power-law form for the primordial power spectrum continues to provide a good fit to the data is quite impressive when one considers the degree to which our constraints have improved. Figure 25 shows the reconstructed primordial power spectrum, starting from the COBE likelihood described in Bennett et al. (1996), through "pre-WMAP" (from the product of the previous likelihood with those from MAXIMA, DASI, BOOMERANG, VSA, and DASI; Hanany et al. 2000;Halverson et al. 2002;Netterfield et al. 2002;Scott et al. 2003;Pearson et al. 2003), to "WMAP" (from the 9-year, final release), and to Planck. Even within the results from Planck, the weak significance of any possible features in our earlier releases has decreased even further.</p>
        <p>Within the context of inflationary models, this implies that the inflaton potential was featureless and relatively flat. The power law is "tilted" away from scale invariance (n s = 1), as expected for an inflaton rolling "down" a potential. Planck was the first experiment able to show that n s 1 in a way that was robust to changes in the underlying theoretical model. In fact the CMB constraints on the scalar spectral index have improved by about two orders of magnitude since the initial COBE measurement. Additionally, we see no evidence for isocurvature modes, suggesting at most one (relevant) dynamical degree of freedom, and no "curvaton" behaviour once the modes were shifted outside the horizon.</p>
        <p>Planck has dramatically reduced the upper limits on non-Gaussianity (Planck Collaboration XXIV 2014; Planck Collaboration XVII 2016; Planck Collaboration IX 2018), again suggesting a featureless inflaton potential, tightly limiting the possibility of higher-order couplings of the inflaton field, and ruling out a number of string-inspired models (e.g., Burgess et al. 2013). The constraints on non-Gaussianity from the CMB have improved by two orders of magnitude from the early limits during the first decade of the millennium (Spergel et al. 2007;Komatsu et al. 2009). While consistent with the simplest models based upon slow roll of a single degree of freedom, these limits have improved so dramatically that wide classes of previously allowed models are now excluded. The models that best fit the Planck data are those in which any multi-field dynamics present does not do much during the crucial epochs of horizon exit, and for which the motion in field space is sub-Planckian.</p>
        <p>With Planck we have shown that scalar modes dominate the anisotropies in the CMB by an order of magnitude (compared to tensor modes; Fig. 23). With current CMB experiments, we are probing the class of inflationary models for which r ∼ 1 -n s , excluding the popular monomial potentials m 2 φ 2 and λφ 4 that arise in chaotic inflation at more than the 99 % CL. The combination of n s &lt; 1 and r 1 suggests that the fluctuations were produced near a "special point" in the inflaton potential (i.e., V 0 while V 0), and that the space of models with "convex" potentials is severely limited. Models with concave potentials, often predicting r ∼ (1 -n s ) 2 , are consistent with the Planck data and include a variety of supersymmetry-or string-inspired models with exponential potentials. It will require dramatic increases in sensitivity, systematics control, and foreground mitigation to probe this class of models. Detection of tensor modes from the wide class of models with r</p>
        <p>(1 -n s ) 2 , or sub-Planckian field evolution, remains out of reach with current or near-future technologies.</p>
        <p>As a dramatic illustration of the "cosmo-micro" connection, Planck is able to provide strong constraints on the properties of relic neutrinos and additional light particles. To discuss this further, we begin by presenting the constraints on the masses of ordinary ("active") neutrinos, and then turn to discussing other light particles. As we will see, the lower limits on neutrino masses from oscillation experiments, combined with the upper limits from Planck, leave only a narrow window at a value (m ν 0.1 eV) that cries out for explanation in fundamental physics.</p>
        <p>The detection of Solar and atmospheric neutrino oscillations proves that neutrinos are massive, with at least two species being non-relativistic by the present day. In the normal hierarchy (m 1 &lt; ∼ m 2 &lt; m 3 ) the sum of the neutrino masses must be larger than 0.06 eV (ω ν = Ω ν h 2 m ν /93.04 eV 0.0006), while in the inverted scenario (m 2 &gt; ∼ m 1 m 3 ) the lower limit is 0.1 eV.</p>
        <p>Fig. 23. Limits on the tensor-to-scalar ratio, r 0.002 , as a function of n S in the ΛCDM model at 95% CL, from Planck alone (grey area), or including BICEP2/Keck data 2014 (red) and BAO (blue). Constraints assume negligible running of the inflationary consistency relation, and the lines show the predictions of a number of models as a function of the number of e-folds, N , until the end of inflation. This can be compared with the middle panel in the top row of Fig. 14, which gives a temporal perspective.</p>
        <p>Planck data provide strong upper limits on the sum of the neutrino masses, of the same order, thus requiring m ν 0.1 eV.</p>
        <p>The cosmological effects of neutrinos are covered in several reviews, for example, Lesgourgues et al. (2013), Patterson (2015), Archidiacono et al. (2017), and Lattanzi &amp; Gerbino (2017), to which the reader is referred for more details. For masses O(0.1 eV), the neutrinos are still relativistic at recombination and the effects on the anisotropy spectrum are small (and primarily near the first acoustic peak, due to the evolution of the potentials near recombination, known as the "early ISW effect"). The largest impact of massive neutrinos is in altering the late-time expansion history and the shape of the matter power spectrum. In the observationally relevant range, increasing neutrino masses increases the expansion rate at z &gt; 1, changing the distance-redshift relation at low z. Since neutrinos free stream, while contributing to the background expansion, the matter power spectrum is suppressed on small scales. To hold θ * fixed, an increase in m ν needs to be accompanied by changes in other parameters that suppress large-scale power. The overall effect is thus a broad suppression of the matter power spectrum at fixed CMB amplitude. Planck has moved us into a new regime, where the neutrino mass constraints come not from their small effect on the primary anisotropies, but from the measurement of the late-time potentials through gravitational lensing. Current upper limits on m ν correspond to an O(1 %) suppression of power on sub-degree scales (unfortunately, Planck is not sensitive to mass splittings between the neutrinos).</p>
        <p>Even tighter constraints can be obtained when combining Planck data with lower-redshift probes, in particular those that measure H(z). Increasing m ν while holding the angular scale of the acoustic peaks fixed reduces the expansion rate at low z (and increases it at high z). For fixed θ * this lowers the Hubble constant and increases the distance to z 0.5-1, which is tightly constrained by BAO. It is a testament to the incredible precision of modern cosmological observations that neutrino masses can be constrained through such tiny effects on the late-time expansion history.</p>
        <p>With the improvement in the low-data of this final Planck release, which helps break degeneracies with A s and τ, the neutrino mass limits have improved. Unlike in earlier years, all three effects of massive neutrinos -changes in the distance to z dec , in the smoothing of the temperature and polarization spectra, and in the shape of the lensing spectrum -contribute to the constraint in mutually reinforcing ways. Thus the combination of acoustic oscillations in the early and late Universe with the gravitational deflections of light across cosmic time provide a tight constraint on the sum of the neutrino masses: m ν &lt; 0.12 eV (95 % CL).</p>
        <p>(8)</p>
        <p>This implies that the inverted mass hierarchy is beginning to be disfavoured by robust, cosmological data. For this (very restricted) range of neutrino masses the impact on other cosmological parameters is small, but not completely negligible given the precision of the existing constraints. As discussed in detail in Planck Collaboration XIII (2016), including m ν as an additional parameter can change the allowed values of Ω m , h, and σ 8 . However, all of the changes are correlated, so large areas of parameter space are still excluded. In particular, one needs to include massive neutrinos and one other</p>
        <p>Marginalised 10 1 10 2 10 3 10 1 10 2 10 3 10 1 10 2 10 3 1 2 3 σ Fig. 24. Primordial (scalar curvature) power spectrum, reconstructed by using the Planck 2018 TTTEEE+lowE+lensing likelihood. This was done by sampling the parameters of an extended ΛCDM model, where the initial power spectrum was described with a varying number of movable spline nodes (from one to nine), rather than assumed to be a power law. The final reconstruction (bottom right plot) is obtained by marginalising, i.e., weighting each of the nine reconstructions by its own evidence. With two nodes (top left), the departure from scale invariance with n s -1 -0.035 is nicely recovered. With three nodes the uncertainties at low (due to the small number of modes) and high-(due to noise) becomes visible. With a larger numbers of nodes, anomalies may be captured, and the most visible departure from a pure power law reflects the well-known power deficit at 20-30. However, the evidence-weighted plot (bottom right panel) shows that the evidence for such a spectral feature is actually not very significant. In Planck Collaboration XX (2016), this spectrum was reconstructed using three additional methods, with similar conclusions.</p>
        <p>parameter (e.g., N eff ) in order to simultaneously have low values of σ 8 and high values of h. Low values of σ 8 also go with higher values of Ω m and lower values of h, so neutrinos do not offer a solution to the discrepancy with some (but not all) of the weak lensing or cluster count data (see, e.g., the discussion in Planck Collaboration VI 2018).</p>
        <p>As well as neutrino mass, the CMB also gives sensitivity to the number of types of neutrino. The density of non-photon radiation in the Universe is usually parametrized by an effective neutrino number</p>
        <p>specifying the energy density when the species are relativistic, in terms of the neutrino temperature, assuming that three flavours of neutrinos instantaneously decoupled. In the standard model N eff 3.045-3.046 (Mangano et al. 2002;de Salas &amp; Pastor 2016). As with m ν , at Planck sensitivity the best constraints on N eff come from the distance scale. Increasing N eff at fixed acoustic scale (θ * ) and fixed z eq increases the expansion rate before recombination. This changes the sound hori-zon (approximately linearly with the age at recombination) and the scale of photon diffusion (approximately as the square root of the age). The combination allows us to constrain additional relativistic species (e.g., Hu &amp; White 1996b). A tighter constraint is obtained if we include BAO data. The increase in N eff (at fixed θ * and z eq ) increases the expansion rate at low z as well. Although the sound horizon at the end of the baryon drag epoch, r drag , also decreases, the combination of Planck+BAO data still provides a strong constraint: N eff = 3.01 ± 0.35 (95 % CL). Imposing the constraint N eff ≥ 3.046, the 95 % CL upper limit on ∆N eff = N eff -3.046 is 0.3. This mildly disfavours any light, thermal relics that froze out after the quantum chromodynamics phase transition (which predicts ∆N eff = 0.3 per degree of freedom).</p>
        <p>The combination of robust cosmological probes has grown sufficiently constraining that we are also able to provide limits on additional massless relics, on top of the three active neutrinos. Even allowing for non-minimal neutrino masses, N eff &lt; 3.29 (95 % CL; Planck Collaboration VI 2018) thus excluding one thermalized sterile neutrino at the 3 σ level. `10 1 10 2 10 3 `1 2 3 Fig. 25. Temporal evolution of constraints on the reconstructed primordial power spectrum. Using the same methodology as in Fig. 24, we compare the (marginalised) Planck 2018 reconstruction with versions based on earlier likelihoods (see text).</p>
        <p>The above summary shows that Planck provides evidence for a cosmic neutrino background at very high significance. Since the neutrinos make up a non-negligible fraction of the total energy density near recombination (ρ ν 0.1 ρ tot ), the CMB is highly sensitive to their properties, and in particular to their anisotropies (Hu et al. 1995;Hu 1998;Trotta &amp; Melchiorri 2005). The Planck data provide compelling constraints on the neutrino anisotropy for the first time, showing that both the speed of sound in the neutrino reference frame and the neutrino anisotropic stress are consistent with standard predictions, c 2 eff = c 2 vis = 1/3 (to within 2 % and 10 % respectively, Planck Collaboration XIII 2016); this limits non-standard neutrino interactions.</p>
        <p>Since COBE first measured the amplitude of the anisotropies at the surface of last scattering (Smoot et al. 1992), the explanation of the observed large-scale structure in the Universe through gravitational instability has required the presence of dark matter (Efstathiou et al. 1992). Indeed, the evolution of the gravitational potentials and the stabilizing influence of dark matter allow us to measure the cold dark matter density to around 1 % from the shape of the peaks in the power spectrum. Planck has gone further and allowed us to map, in projection, all of the dark matter back to the surface of last scattering, through its effects on the propagation of CMB photons (i.e., gravitational lensing). Inferences from the detailed shape of the power spectrum imply that the dark matter must be stable, cold, and dark; moreover, if they are thermally produced then the dark matter particles must also be massive.</p>
        <p>If dark matter annihilates in the early Universe, and there is significant energy in the post-decay shower at keV scales, then secondary particles can ionize or heat the primordial gas and change the recombination history (see sec-tion 6.6 of Planck Collaboration XIII 2016). This can dramatically alter the CMB anisotropies (Chen &amp; Kamionkowski 2004;Padmanabhan &amp; Finkbeiner 2005). Planck is sensitive to energy injection over the range 600 &lt; ∼ z &lt; ∼ 10 3 (Finkbeiner et al. 2012), and the effects of DM annihilation can be relatively well modelled by a single parameter that encodes the dependence on DM particle properties. Since the main effect of DM annihilation is to increase the duration of last scattering and enhance the ionization fraction at low z, a precise measurement of polarization is particularly important. For this reason the Planck data provide some of our tightest constraints on the energy release per unit volume and thus DM annihilation. For example, they exclude a low mass (m χ &lt; 44 GeV) thermal relic annihilating into e + e - pairs.</p>
        <p>Of the many unexplained ingredients in our phenomenological ΛCDM model, the cosmological constant (Λ) may be the most mysterious. We currently lack any compelling explanation for its value, or a natural mechanism to produce it. In addition, the models that fit the data all predict that the present epoch represents a "special time" in the history of the Universe. Two alternatives to the introduction of a cosmological constant are to promote Λ to a dynamical field (or set of fields) that have an effectively negative pressure to drive accelerated expansion (dark energy), or to modify GR so that accelerated expansion can be achieved with a "standard" stress-energy tensor (i.e., modified gravity).</p>
        <p>Planck, in combination with other probes, enables tests of dark energy and modified gravity on the scales where linear theory is most applicable, which tend to be the most theoretically robust. In fact, many constraints on dark energy and modified gravity in cosmology depend upon the CMB anisotropies in crucial ways. Planck Collaboration XIV (2016) and Planck Collaboration VI (2018) discuss the Planck constraints on dark energy and modified gravity in detail. The CMB is sensitive to these ingredients through their effects on the expansion history, the evolution of the metric perturbations, lensing, and the growth-rate of structure. Since in most models dark energy or modifications to gravity are late-time phenomena, the strongest constraints come from combining the Planck data with other data sets; however, the CMB lensing measured by Planck also provides some sensitivity. In fact Planck lensing provided the first CMB-only evidence for dark energy (Planck Collaboration VIII 2018).</p>
        <p>The background evolution can be constrained by Planck+BAO+SNe (see Planck Collaboration VI 2018, which contains details on the particular data used). This provides a long enough lever arm in redshift that the geometric degeneracy is largely broken. Gravitational dynamics can be probed through "growth of structure" probes, such as redshift-space distortions. The Weyl potential can also be probed through weak lensing of the CMB or galaxy weak lensing.</p>
        <p>The combination of Planck+BAO+SNe data is compatible with ΛCDM, and for simple models tightly constrains the dark energy equation of state, w ≡ p/ρ (e.g., w = -1.028 ± 0.032 if it is constant). For more flexible parameterizations, a range of equations of state remains allowed. Such a range in equation of state, however, does not translate into a large uncertainty in other parameters such as Ω m or σ 8 . In fact, the posterior volume in the w 0 w a CDM model (where the equation of state of the dark-energy component is w = w 0 +[1-a]w a ) is not much larger than for ΛCDM. Interestingly, the region that is opened up by in-troducing new degrees of freedom for the dark-energy evolution is not the region of reduced σ 8 preferred by the low-z probes appearing to exhibit tension with Planck (some cosmic shear measurements and some analyses of the counts of rich clusters; Sect. 4.3). Thus evolving dark energy does not significantly impact the tension between those measurements and Planck.</p>
        <p>The combination of the relative distance scale measured by SNe with the absolute distance scale determined from CMB+BAO requires that the dark energy density be subdominant at redshifts beyond 1. In most models, the dark-energy density becomes irrelevant above z 2, and early dark energy and coupled DE models are now strongly constrained. For example, the dark-energy density at early times must be below 0.02 ρ crit (95 % CL), even if it only plays a role below z = 50 (Planck Collaboration XII 2016).</p>
        <p>The observed late-time acceleration of the cosmic expansion could be due to modifications of GR instead of an additional component of the energy density (e.g., recent reviews by Jain &amp; Khoury 2010and Joyce et al. 2015, 2016). However, at present there are no compelling models of modified gravity that explain cosmic acceleration while being compatible with the observational constraints, thus most explorations have tended to focus on generic parameterizations of possible deviations from GR. For example, within the subclass of scalar-tensor theories, the large-scale behaviour can be effectively captured by two free functions of scale and time.</p>
        <p>On very large scales and at late times, cosmological observations probe the two metric potentials Ψ and Φ (Sect. 3), or some combinations of them. In Planck Collaboration XIV ( 2016) and Planck Collaboration VI (2018), those potentials were allowed to vary away from their GR values in time, holding the spatial dependence fixed at the GR expectation. No evidence was found for modifications to GR, although once the relationship between the matter components and the metric potentials is freed, lower values of Ω m and σ 8 are allowed by the data.</p>
        <p>Overall, the Planck data support the basic model with a spatially and temporally constant dark-energy density (i.e., a cosmological constant) that is just now coming to dominate the energy density of the Universe. The constraints, however, are relatively weak compared to similar tests of General Relativity on Solar System scales. Future observations will be required to provide stringent constraints on the plethora of models that are currently consistent with the data.</p>
        <p>For almost all the most important Planck results, statistical isotropy and Gaussianity of the CMB anisotropies are implicitly assumed. This is reasonable, since when these assumptions are tested on our CMB sky they seem to hold up well (see Planck Collaboration VII 2018, as well as Planck Collaboration IX 2018 and Planck Collaboration X 2018, and the earlier papers Planck Collaboration XXIII 2014 andPlanck Collaboration XVI 2016). That is, no significant signals of statistical anisotropy or non-Gaussianity appear, apart from those predicted by ΛCDM itself (such as lensing and the integrated Sachs-Wolfe effect; Sachs &amp; Wolfe 1967) or arising from foregrounds such as the SZ effect or the CIB. Nevertheless, when such tests are restricted to the largest angular scales ( &lt; 70, say), some apparently 2-3 σ signals begin to appear, and these have been called "CMB anomalies." Specifically, it has been found that the temperature anisotropies at the largest scales exhibit a dipolar asymmetry of power, show a preference for odd parity modes, and contain a large cold spot in the southern hemi-sphere. The existence of these signals is not in dispute. They appear in both WMAP and Planck, which have quite different systematics, and moreover all of the Planck results are robust with respect to the choice of component-separated CMB map. Thus these "anomalies" must be regarded as features of the CMB temperature sky. The main question then is whether such signals are unusual enough for physical explanations to be sought, beyond merely being excursions in Gaussian random skies. This issue of "a posteriori" statistics is complicated by the fact that for these scales the measurements are essentially cosmic-variancelimited, thus new measurements of the relevant modes will not change the significance of the anomalies.</p>
        <p>This final release of Planck data then represents a major new opportunity, since it contains our first comprehensive attempt at assessing the isotropy of the Universe via an analysis of the fullmission Planck polarization data. This was not possible in earlier releases, due to residual large-scale systematics that required high-pass filtering of the CMB polarization maps. Probing independent information on the sky, the large-angular-scale polarization gives us a rare opportunity to study some of these anomalies; however, inferences are hindered by the fact that the signalto-noise ratio in the Planck polarization data is lower than in temperature, at large scales the signal is very small (see Fig. 9), and the E modes are only partially correlated with temperature. The degree to which we expect a signature of various claimed anomalies to appear in the polarization is therefore somewhat model dependent.</p>
        <p>Planck Collaboration VII (2018) attempts a comprehensive analysis of the statistics of the polarization signal from large to small angular scales, using either maps of the Stokes parameters (Q and U) or the E-mode signal. While these studies are limited by residual systematics, a series of null tests applied to the maps indicate that these issues do not dominate the analysis on intermediate and large angular scales (i.e., 400). In this regime, there is no unambiguous detection of cosmological non-Gaussianity, or of anomalies corresponding to those seen in temperature. Notably, the stacking of CMB polarization signals centred on the positions of temperature hot and cold spots exhibits excellent agreement with the expectations of the ΛCDM cosmological model. However it will require future, more sensitive, polarization observations to fully test the models that have been advanced to explain the anomalies.</p>
        <p>It is worth stressing that none of these so-called anomalies are strongly inconsistent with the assumption of statistical isotropy and Gaussianity, once one marginalises over a set of similar tests. It would nevertheless be premature to completely dismiss all the CMB anomalies as simple fluctuations of a pure ΛCDM cosmology, since if any of the anomalies have a primordial origin, then their large-scale nature would suggest an explanation rooted in fundamental physics. Thus it is worth exploring any models that might explain an anomaly (or even better, multiple anomalies) naturally, or with very few free parameters. Given a theoretical prediction, new probes of independent modes on similar scales (obtained through more sensitive polarization measurements, lensing, Ly α, or 21-cm studies for example) would increase the significance of existing anomalies and allow us to develop novel probes of early Universe physics. So far the simplest models explaining a single anomaly are not favoured over ΛCDM (see Planck Collaboration X 2018, and references therein). Further investigation of these anomalies will need to proceed on a case-by-case basis, and will be the subject of future work.</p>
        <p>By cementing the gravitational instability paradigm and accurately measuring the initial conditions and parameters determining the subsequent growth of structure, Planck provides the framework within which to discuss the formation and evolution of large-scale structure and galaxies, black holes, and other astrophysical objects.. With Planck we have tightly constrained the densities of radiation, matter, and baryons, as well as the amplitude and shape of the fluctuations in the linear phase over three decades in length scale. Our knowledge of the physical conditions and large-scale structure at z = 10 3 is better than our knowledge of such quantities at z = 0. It is for this reason that "CMB priors" have become an integral part of current and future cosmological inference; indeed almost no cosmological experiment interprets their data without adding the existing constraints from Planck.</p>
        <p>In cosmology we frequently refer to standard candles (objects of known luminosity) or standard rulers (objects of known size). However, the CMB has provided us with a "calibrated, standard fluctuation spectrum," from which we can accurately compute how big a sample has to be in order to be "fair," how many objects constitute a "dense" sample, how strong clustering will be for objects of various sizes, and the abundance of dark-matter halos as a function of mass and epoch. By constraining the fluctuations in regions of a given volume or for halos of a given mass, it provides quantitative answers to questions about how well a set of objects in a sampled region embodies the average properties, and the relative importance of sampling variance and shot noise.</p>
        <p>Here we discuss tests enabled by this calibrated spectrum. In the next subsections we will explore lensing cross-correlations (Sect. 6.2) and discuss the acoustic features in the matter power spectrum (BAO) that can be used as a standard ruler (Sect. 6.3). Since the growth of structure depends sensitively on the properties of the objects that cluster strongly (e.g., dark matter) and on those that do not (e.g., neutrinos and dark energy), as well as on our theory of gravity (i.e., GR), studies of clustering address many of the most fundamental questions in cosmology.</p>
        <p>In Sect. 4.2 we showed that the shape of the matter power spectrum predicted by ΛCDM fit to the Planck data is in excellent agreement with measurements at lower z (Fig. 19). Figure 26 shows another aspect of this, highlighting the evolution of P(k). Within the ΛCDM paradigm the late-time matter power spectrum is very well predicted once the initial fluctuation spectrum and matter contents are known. In fact P(k) is sensitive to combinations of parameters that are generally well measured by the CMB, so the final uncertainty is small. Figure 26 shows the nonlinear matter power spectrum, over three decades in wavenumber, as predicted by ΛCDM fit to Planck. We display the results with and without variations in m ν , since this is one of the best-motivated extensions that impacts the matter power spectrum. We show results at z = 2, before dark energy becomes an appreciable fraction of the total energy density, and at the present epoch (z = 0). In physical units (i.e., Mpc -1 rather than h Mpc -1 ) the power spectrum is predicted at the few percent level up to k 1 Mpc -1 (beyond which effects from astrophysical processes such as stellar and AGN feedback become important, for example White 2004;Zhan &amp; Knox 2004;Chisari et al. 2018). If we include dark energy with a time-varying equation of state in the model, then the power spectrum at z ≥ 2 is only mildly affected, but we introduce an extra uncertainty in the am-Fig. 26. Top: Matter power spectrum (including non-linear corrections using the fitting form of Takahashi et al. 2012) at redshifts 0 and 2, predicted by the ΛCDM model with a single massive neutrino of 0.06 eV (dashed curve) or allowing the neutrino mass to float (dotted curve). Bottom: Fractional error in each power spectrum, compared to the average plotted above, due to the remaining uncertainties in the cosmological parameters. Uncertainty in the evolution of the scale factor at late times (due to dark energy) leads to an additional uncertainty in the overall amplitude, coherent across scales, which is not shown here. With current BAO and SNe data the uncertainty in the growth from z = 2 to z = 0 is 8 % (or 16 % in power). plitude of P(k, z = 0) at around the 16 % level. The dominant uncertainty is in the amplitude, leaving the shape almost invariant. The fact that the constrained model predicts the spectrum to such exquisite accuracy provides a stable platform for inferences about the lower-redshift evolution and a target for tests of GR, the expansion history, and the contents of the Universe.</p>
        <p>The main feature visible in Figs. 19 and26 is the peak at k 10 -2 Mpc -1 . The location of this peak is setfoot_16 by the Hubble scale at matter-radiation equality, which is now extremely well determined by the Planck data: z eq = 3387 ± 21. Along with the amplitude of P(k), this scale, k eq = (0.01034 ± 0.00006) Mpc -1 , sets the characteristic volume of the Universe that needs to be surveyed in order for a sample to be considered a "fair" representation of the Universal average.</p>
        <p>The amplitude of the spectrum and its evolution sets the level of clustering in the Universe and, indirectly, the halo mass function. A population of objects whose number density times large-scale bias squared is less than the inverse peak power (i.e., b 2 n P -1 peak ) will always be in the shot-noise limited regime, that is, it will be a "sparse" tracer of large-scale structure. This means that such a population cannot measure the large-scale structure on a mode-by-mode basis (although it can be used to determine the statistics of large-scale structure by averaging over many independent modes) on any scale. For example, such a population can be used to measure P(k), or in cross-correlations, but it will not be a good choice for density-field reconstruction or mapping the cosmic web. When a sample becomes "dense" is less clear, but roughly speaking it occurs when the number den-Planck Collaboration: The cosmological legacy of Planck sity (times b 2 ) becomes larger than the matter power spectrum at the non-linear scale. Surveys of such objects are dominated by sample variance on all linear scales (Feldman et al. 1994).</p>
        <p>Future galaxy, quasar, and CMB surveys will constrain P(k) ever more tightly. One immediate goal of such surveys is to look for the suppression of small-scale power imparted by massive neutrinos (Sect. 5.3) or warm dark matter. More ambitious surveys may be able to detect any running of the spectral index, or extra relativistic degrees of freedom. If we can improve our knowledge of star and galaxy formation, the well-determined power spectrum at z 1 may enable forward modelling to the reionization epoch (Sect. 6.6), which can be probed by 21-cm surveys and next-generation CMB experiments.</p>
        <p>Lensing provides us with both a map of all of the matter in the Universe and a persuasive cross-check on our cosmological model. There are three main ways in which lensing contributes:</p>
        <p>it provides better constraints on the basic parameters; -it tests the gravitational instability paradigm and constrains modifications to GR on very large scales; and it allows for cross-correlations, to provide more information.</p>
        <p>We have already discussed the first two points. The Planck lensing maps have also been used in a wide variety of crosscorrelation studies, for a number of purposes. Since the lensing signal comes from an already well-probed redshift range and comes from largely linear modes, it allows us to determine the bias of cosmological objects and place constraints on their redshift distribution.</p>
        <p>Starting with the 2013 data, the Planck team has crosscorrelated the lensing maps with large-scale structure traced by radio, optical, and IR surveys (Planck Collaboration XVII 2014). Other studies have correlated the Planck maps with: mid-IR selected quasars at z 1 (Geach et al. 2013;DiPompeo et al. 2015DiPompeo et al. , 2016)); optical galaxies from SDSS-III (Pullen et al. 2016;Giusarma et al. 2018;Singh et al. 2018;Doux et al. 2017), CFHT (Omori &amp; Holder 2015), and DES (Giannantonio et al. 2016); galaxies from 2MASS, WISE, and SuperCOSMOS (Bianchini &amp; Reichardt 2018;Raghunathan et al. 2017;Peacock &amp; Bilicki 2018); the Ly α forest (Doux et al. 2016); and high-z submillimetre galaxies from Herschel-ATLAS (Bianchini et al. 2015). Crosscorrelations with unresolved sources include dusty star-forming galaxies (Planck Collaboration XVIII 2014) and the γ-ray sky from Fermi-LAT (Fornengo et al. 2015;Feng et al. 2017). In fact, Planck even has sufficient sensitivity to detect the lensing signal on the scale of individual dark-matter halos (Planck Collaboration XXIV 2016).</p>
        <p>Not only have the Planck lensing maps been crosscorrelated with tracers of the density field, but also with other measures of lensing, in particular cosmic shear surveys (Liu &amp; Hill 2015;Kirk et al. 2016;Harnois-Déraps et al. 2016, 2017;Miyatake et al. 2017;Singh et al. 2017). These two independent measures of the gravitational potentials from large-scale structure promise significant complementarity, and the comparison may aid systematic error mitigation in future surveys. Such studies with the Planck lensing maps provide a strong proof of principle.</p>
        <p>As large-scale structure surveys push to high redshift over large fractions of the sky, we expect the synergies described above to become ever more compelling. While current and next generation experiments are expected to significantly improve lensing maps on small scales, the Planck lensing maps are likely to remain our best tracers of the low-lensing modes for some time. In addition, the higher-frequency channels of Planck will not be surpassed for many years, and they contain valuable information on foregrounds that will impact temperature-based lensing reconstruction for at least another decade. While contaminating signals such as our galaxy, the Sunyaev-Zeldovich effect from groups and clusters, or the cosmic infrared background from dusty, star-forming galaxies remain a cause for concern, one may also view them as valuable signals to be extracted. To this end, cross-correlations will enhance the legacy value of the Planck data.</p>
        <p>Planck has now mapped 18 acoustic peaks and an almost equal number of troughs (in T T , T E, and EE together), which form an almost harmonic series of features in the temperature and polarization power spectra (Table 5). The peaks arise from gravitydriven acoustic oscillations in the baryon-photon fluid prior to recombination. The non-trivial contribution of the baryons to the total matter content implies that an analogous series of peaks is also visible in the matter power spectrum, leading to a special scale that is fixed in comoving coordinates as the Universe evolves (Peebles &amp; Yu 1970;Sunyaev &amp; Zeldovich 1970;Doroshkevich et al. 1978). Measurement of this scale at low redshifts, for example in large galaxy redshift surveys or in the absorption lines imprinted by intergalactic gas in the spectra of high-z quasars, provides a "standard ruler" for constraining the expansion history of the Universe. 19 . Since the scale (approximately 150 Mpc) is so large, it is nearly immune to astrophysical processing and non-linear evolution. The major obstacle to measuring the feature in the low-z Universe is that very large volumes need to be surveyed in order to obtain a robust detection. It is convenient that the same acoustic phenomena that give rise to the key features in the angular power spectra also give a signature that can break one of the few remaining (near-)degeneracies between CMB-determined parameters, namely the angular distance degeneracy.</p>
        <p>Measurements of the BAO feature currently span the redshift range 0 &lt; z &lt; 2.5, using either galaxies or the Ly α forest as tracers. A comparison of the (angle-averaged) distance-redshift relation inferred from a number of BAO measurements, to the distance scale predicted by ΛCDM constrained by Planck, is shown in Fig. 27. The agreement is excellent. The uncertainty in the prediction, from the remaining spread in the model parameters, is at the percent level for all redshifts. The BAO data are approaching comparable precision, especially the BOSS DR12 data (Alam et al. 2017). Acoustic oscillations in the high-and low-z Universe give a consistent, percent-level determination of the distance scale within the ΛCDM paradigm. While we do not show it, the distances inferred from high-redshift Type Ia SNe also provide a consistent distance-redshift relation. In fact the combination of CMB, BAO, and SNe distances allows us to establish an "inverse distance ladder," in which distances in the range 0.2 &lt; z &lt; 2 are calibrated to the physical scale provided by the CMB at z 1100, rather than being bootstrapped up from z 0 to larger redshifts. The BAO method also provides measures of distances along the line of sight, that is, of the Hubble parameter. The current best measurements of the BAO feature comes from BOSS (Dawson et al. 2013), which has surveyed 18.7 Gpc 3 of the low-z Universe and 150 Gpc 3 of the z 2.5 Universe to provide highly significant detections of the acoustic feature. Figure 28 shows the comparison in the D M -H space, and we see that the agreement is excellent. The thin contours show the Planck ΛCDM predictions, where the geometric degeneracy is evident. Moving along this line, ω m and h are changing in concert to hold θ * (almost) constant. In Fig. 28 the green points show samples from the Planck TT+lowE chains, while the red points include the high-polarization and lensing data. As more data are added there is a shift towards slightly lower D M and higher H, in better agreement with the BAO results. This is also true for adding polarization and lensing separately (not shown).</p>
        <p>The real power of the BAO data becomes apparent, however, when we open up the parameter space beyond ΛCDM. One of the key degeneracies that enters in these extended parameter spaces is the angular scaling (often called the "geometric distance degeneracy"), which means that changes in the parameters that hold the angular diameter distance to the surface of last scattering fixed 20 are only weakly constrained. By providing a low-redshift distance determination, the BAO measurements largely break this degeneracy. One example is presented in Fig. 29, which shows the constraints in the Ω m -Ω K plane. With only the primary CMB information, the geometric degeneracy allows a wide range of solutions. Including CMB lensing tightens this somewhat, but the highly precise BAO distances break the degeneracy almost entirely (a similar effect happens 20 Or more generally combinations which change r * and the distance so as to hold θ * fixed.</p>
        <p>with massive neutrinos, as discussed in Sect. 5.3). It is worthy of note that the constraint on Ω K has improved by two orders of magnitude in under two decades.</p>
        <p>Looking at this from the point of view of BAO surveys, Planck fixes r drag to 0.2 % (for base ΛCDM), allowing line-ofsight BAO measurements to be translated into measures of H(z) on an absolute scale, which is limited only by our uncertainty about the high-z Universe:</p>
        <p>This allows BAO experiments to provide a direct measure of the expansion rate in physical units.</p>
        <p>Planck has had a significant impact on the study of galaxy clusters using the Sunyaev-Zeldovich effect (SZ; Sunyaev &amp; Zeldovich 1972, 1980 Planck Collaboration XXXII 2015). It contains 1 653 detections, of which 1 203 are confirmed clusters with identified counterparts in external data sets. It was the first SZ catalogue with more than 1000 confirmed clusters. New detections, relative to the 2013 catalogue, are shown in the redshift-mass plane in Fig. 31; these can be seen to fit well with the completeness contours of the new survey.</p>
        <p>The legacy catalogue enabled the subset of clusters that were used as a sample for cosmology constraints to be substantially increased compared with the number used in 2013, with 439 clusters included in 2015 versus 189 in 2013. A key constraint that emerges from the 2015 cosmology sample (Planck Collaboration XXIV 2016) is the result for σ 8 versus Ω m , shown in Fig. 32. The coloured contours in that figure refer to different ways of treating the crucial scaling between the measured cluster Compton distortion parameter, Y 500 , and the cluster mass, M 500 (both defined within a radius where the mean enclosed density is 500 times the critical density). This is a complex procedure, in which numerous possible systematic and sta- (Alam et al. 2017). The green points show samples from the Planck TT+lowE chains, while the red points include the high-polarization and lensing data. As more data are added there is a shift towards slightly lower D M and higher H, in better agreement with the BAO results. This is also true for adding polarization and lensing separately (not shown). tistical errors have to be taken into account, and is at the heart of any attempt to use cluster abundance data for cosmology. The Planck data themselves provide only weak constraints on this scaling, so external data are typically required. An additional uncertainty comes from the choice of "mass function," that is, the function that predicts the abundance of clusters of different mass for varying cosmological parameters. This is generally derived from fits of dark-matter halo abundances in numerical simulations, ideally accounting for the effects of the baryonic component. 3) × 10 14 M ⊙ from a weak lensing analysis. However, clusters are also detectable through the Sunyaev-Zeldovich (SZ) effect (Sunyaev &amp; Zeldovich 1972), the spectral distortion of the cosmic microwave background (CMB) generated via inverse Compton scattering of CMB photons by the hot electrons in the intra-cluster medium. Crucially, the total SZ signal is expected to be closely related to the cluster mass (e.g. da Silva et al. 2004), and its brightness insensitive to redshift dimming. As a result, SZ surveys can potentially provide unbiased cluster samples that are as close as possible to being mass-selectedfoot_18 . They offer an ideal way to identify massive, high-redshift clusters. One recent illustration is the detection of SPT-CL J2106-5844 at z = 1.13 by the South Pole Telescope In this paper, we adop 70 km s -1 Mpc -1 , Ω M = 0 Ω M (1 + z) 3 + Ω Λ is the ra z to its present-day value. tal mass and radius corresp compared to ρ c (z), the critic ter redshift; M δ = (4π/3) δ by Y 500 , where Y 500 Dfoot_19 A is th rameter within R 500 (corres angular-diameter distance t</p>
        <p>The blind search for cluste matched filter (MMF) appr then undergo a validation checks and cross-correlatio as described in Planck C produces a list of new Pl given S/N threshold that req XMM-Newton follow-up fo Discretionary Time via an a Here "WTG" is Weighing the Giants, "CCCP" is the Canadian Cluster Comparison Project, "CMBlens" refers to the CMB lensing method as analysed by Melin &amp; Bartlett (2015) and re-analysed by Zubeldia &amp; Challinor (2019). Blue contours are constraints from CMB anisotropies.</p>
        <p>In the 2013 results paper (Planck Collaboration XX 2014), the scaling was carried out by using an X-ray-defined version of the Compton parameter Y 500 (called Y X ) as an intermediary, and using the Y X -M 500 relation, assumed known up to some socalled mass bias factor (1 -b), in order to calibrate the Y 500 -M 500 relation in the cosmological sample. Leaving aside other factors, the relation found was of the form</p>
        <p>with α 1.8. The factor (1 -b) arises from an expected miscalibration of the local sample used to calibrate the X-ray relation, due to deviation of the clusters from the assumption of hydrostatic equilibrium, but also encompasses other systematic errors.</p>
        <p>Various values of (1 -b) were considered in the 2013 results paper, some motivated from simulations, and the analysis was carried out assuming a baseline of (1 -b) varying over the range [0.7, 1.0] with a flat prior. This yielded an equivalent to Fig. 32, which showed quite strong discrepancy between the confidence contours for σ 8 and Ω m coming from the Planck primordial CMB results, and those from the SZ cluster analysis. It was possible to reconcile the two, but only by moving (1-b) to lower values than suggested by numerical simulations. Specifically, asking for agreement between the Planck primordial CMB results and SZ cluster counts, yielded a "measurement" of (1 -b) of 0.59 ± 0.05, definitely lower that the 10 to 20 % bias away from hydrostatic equilibrium expected previously from simulations.</p>
        <p>In the Planck 2018 results shown in Fig. 32, we see that the situation has alleviated somewhat, in that for some versions of the procedure to establish the scaling relation between observed SZ value and mass, there is effectively no discrepancy with the primordial CMB values of σ 8 and Ω m . In particular, the mass scaling implied by the "Weighing the Giants" programme (von der Linden et al. 2014), based on the availability of high-quality gravitational shear information for 22 clusters from the Planck 2013 cosmology sample, gives (1 -b) = 0.688 ± 0.072, and therefore little evidence of any tension with primary CMB results. On the other hand, we see that some alternative methods do still give some tension. The violet contours of Fig. 32 refer to a mass calibration carried out using lensing of the CMB itself by the clusters (Melin &amp; Bartlett 2015), which finds 1/(1 -b) = 0.99 ± 0.19 (the CMB lensing method constrains the reciprocal of the quantity found from the shear measurements). Since this implies a small hydrostatic-equilibrium bias, then it follows that there is a fairly large discrepancy between the results in the (Ω m , σ 8 ) plane using this method, and the CMB anisotropy values. In contrast a recent reanalysis of the CMB lensing data by Zubeldia &amp; Challinor (2019), shown as the red contours in Fig. 32, implies no such discrepancy. Other recent determinations show a similar diversity. For example, Applegate et al. (2016) find consistency between hydrostatic and weak-lensing mass measurements of massive, dynamically relaxed clusters, Okabe &amp; Smith (2016) obtain different mass measurements for some clusters than the "Weighing the Giants" programme, Medezinski et al. (2018) for the cosmology sub-sample (and provide a summary of other determinations, their table 5).</p>
        <p>The situation overall, therefore, is not yet wholly clear. In particular, are the residual discrepancies caused by uncorrected systematics or remaining biases in the astrophysical assumptions and simulations, or are they perhaps a hint of something more important, such as the first signs of new physics?</p>
        <p>As well as building up a catalogue of individual SZ clusters, it is possible to make a map of the Compton y-parameter over the whole sky. This was presented in Planck Collaboration XXI (2014), updated in Planck Collaboration XXII (2016), and is available as a Planck product via the PLA. A sub-region of this map is shown in Fig. 33, and illustrates the combination of individual clusters (plus possible diffuse SZ effect regions) that is visible. An important question is whether the power spectrum of this map agrees with the conclusions from the catalogue-based analysis discussed above. Figure 34 shows power spectra derived from the all-sky y map for a division into components consisting of clustered CIB, infrared sources, radio sources, and a thermal SZ model. We can see that overall a quite reasonable fit is obtained. One can then use the SZ spectrum to set constraints on Ω m and σ 8 , and compare these with the main CMB values, as above. Again this will depend on assumptions about mass bias, and the result is best expressed in terms of the combination σ 8 (Ω m /0.3) 3/8 . With a mass bias of (1 -b) = 0.8, a result of σ 8 (Ω m /0.3) 3/8 = 0.78 +0.01 -0.03 is obtained, while with (1 -b) = 0.6, the result is σ 8 (Ω m /0.3) 3/8 = 0.86 +0.01 -0.03 . For the Planck CMB anisotropy value of Ω m = 0.3156 (using TTTEEE+lowP, as in Planck Collaboration XXVII 2016), the former result gives σ 8 = 0.76, while the the latter gives σ 8 = 0.86. Recently Horowitz &amp; Seljak (2017) have re-analysed the thermal SZ power spectrum, including the effects of feedback and the tri-spectrum contribution to the uncertainties, finding σ 8 = 0.81 +0.021 -0.009 (Ω m /0.3) 0.4 when fixing other parameters to their central values. This is in excellent agreement with the results of the anisotropy analysis. Fig. 15: NILC -MILCA F/L cross-power spectrum (black) compared to the power spectra of the physically motivated foreground models. The considered foregrounds are: clustered CIB (green line); infrared sources (cyan line); and radio sources (blue line). Additionally, the best-fit tSZ power spectrum model presented in Sect. 7.1 is also plotted as a solid red line.</p>
        <p>maps are masked with the combination of PSMASK, described in Sect. 4.4.1, and a Galactic mask at 50, 60 or 70%, described in Sect. 5.2.1 (in the rest of this section we will simply denote as X% mask the combination of PSMASK and the Galactic mask at X%). The best-fit monopole and dipole outside the mask are finally removed before estimation. An important part of the pipeline is then to correct for the bias introduced by masking. To this end, we compute the ratio of the full-sky and masked sky bispectra, on highly non-Gaussian simulations with a tSZ-like bispectrum and a 10 resolution. This ratio is used to correct the measured bispectra and flag unreliable ( 1 , 2 , 3 ) configurations. Specifically we flag configurations where the ratio is different by &gt; 25% from the naive expectation f SKY B( 1 ) B( 2 ) B( 3 ), where B( ) is the Gaussian 10 beam.</p>
        <p>For both NILC and MILCA, we find that the bispectra computed on the 50, 60 and 70% masks are consistent. This indicates that there is no detectable residual galactic contamination in these bispectra. However we did find Galactic contamination on less aggressive Galactic masks, specifically positive Galactic dust. As Galactic dust is highly non-Gaussian, we warn the use against the measurement of higher order statistics using Galactic masks smaller than 50%. In the following we adopt the 50% mask as baseline, as it leaves the most sky available for estimation and minimizes masking effects in the measurement. With a detection per configuration at an average significance of 3.5σ, and a total significance of ∼ 60σ, the Planck data thus provide a high quality measurement of the non-Gaussianity of the thermal Sunyaev-Zel'dovich signal, with undetectable contamination from foregrounds.</p>
        <p>7.1. Power spectrum analysis 7.1.1. tSZ power spectrum modelling As a measure of structure growth, the tSZ power spectrum can provide independent constraints on cosmological parameters. As shown by Komatsu &amp; Seljak (2002), the power spectrum of the tSZ effect is highly sensitive to the normalization of the Another important contribution to cluster physics from Planck has been work on the average density profile in clusters. Planck Collaboration Int. V (2013) showed that by stacking individual clusters, the resolution and sensitivity of Planck allowed the construction of an average profile out to a radius of 3 × R 500 , giving for the first time a quantitative description of the thermal pressure distribution in the outer regions of clusters. Using fits to a generalized profile, this study showed that the average pressure profile is slightly flatter than most predictions from numerical simulations, indicating the need for more detailed modelling of baryonic physics in cluster outskirts. The gas fraction values found appeared to converge well to the expected cosmological value of f gas = Ω b h 2 /Ω m h 2 = 0.156 (using values from Planck Collaboration XIII 2016 for the same TTTEEE+lowP combination as above).</p>
        <p>A further area of SZ studies where Planck has contributed significantly is the kinetic SZ effect, where peculiar velocities of material encountered by CMB photons on their way to us result in a frequency-independent shift of the CMB spectrum to a slightly different temperature. In Planck Collaboration Int. XIII (2014), searches were carried out for evidence of large-scale bulk flows in the Universe, including those on very large scales for which there had previously been some suggestions in the literature, most prominently a dipole signal in z 0.1 clusters claimed by Kashlinsky et al. (2008) and Atrio-Barandela (2013). Planck Collaboration Int. XIII (2014) found tight constraints on such dipoles by carefully fitting to filtered multifrequency Planck maps at the positions of known clusters, constraining bulk flows to be below 250 km s -1 (at 95 % confidence). Planck Collaboration Int. XIII (2014) also describes how results similar to those seen in the Kashlinsky et al. (2008) and Atrio-Barandela (2013) studies can be found when performing the same analysis steps, but suggests that this approach is nonoptimal and that the apparent signal should be attributed to residuals (mostly of CMB origin) in the filtered map rather than to the clusters' peculiar motion. Planck's lack of a kSZ dipole shows that the Universe is not more inhomogeneous on gigaparsec scales than expected in the ΛCDM model. In addition, the lack of a strong kSZ monopole signal (from outward flows), provides extremely stringent constraints on those inhomogeneous cosmologies that attempt to explain the apparent cosmic acceleration by placing us at the centre of a giant void (e.g., figure 13 in Planck Collaboration Int. XIII 2014).</p>
        <p>In Planck Collaboration Int. XXXVII (2016), searches were carried out for the kinetic SZ effects around the positions of galaxies from the "Central Galaxy Catalogue," which are expected to be the central galaxies of their dark-matter halos. This provided evidence for unbound diffuse gas at twice the mean virial radius of halos, supporting the idea that the majority of baryons lie outside this radius; however, the specific correlations found between SZ and velocity fields suggest that the gas both inside and outside the central galaxy host halos is comoving with the overall matter flows.</p>
        <p>A further statistical use of the Planck data for investigating the kSZ effect is to determine the excess kSZ variance at the positions of clusters (Planck Collaboration Int. LIII 2018, see also Hill et al. 2016) compared to random positions. Interpreted as a velocity dispersion the result is v 2 = (120±70)×10 3 (km s -1 ) 2 , which is consistent with results from other large-scale structure studies (e.g., Scrimgeour et al. 2016).</p>
        <p>Planck maps do not have the sensitivity or resolution to measure individual kSZ cluster signals, but nevertheless, the all-sky nature of the Planck observations, coupled with the redshiftindependence of the SZ signal, have enabled statistical insights to be gained on the thermal contents of cluster gas and the homogeneity of the Universe on large scales. Future CMB observations with higher resolution and lower noise will be able to mine even more information from studies like these.</p>
        <p>The high-frequency channels of Planck have enabled very precise measurements of anisotropy in the cosmic infrared background (CIB). Discovered in 1996 (Puget et al. 1996), the CIB is the cumulative far-IR emission from all galaxies throughout cosmic history, containing an equal amount of energy as from direct starlight (Dwek et al. 1998;Dole et al. 2006;Hill et al. 2018) and implying a considerable amount of star formation in dust-enshrouded galaxies (e.g., Gispert et al. 2000).</p>
        <p>Since dusty star-forming galaxies trace large-scale structure, one expects anisotropy in the CIB (Knox et al. 2001), and these theoretical expectations were confirmed by early measurements (Lagache &amp; Puget 2000;Matsuhara et al. 2000;Lagache et al. 2007;Grossan &amp; Smoot 2007;Viero et al. 2009). Compared to these early detections, Planck (and Herschel) provide greater sky area, lower systematics, and longer wavelengths (and thus a more favourable ratio of CIB signal over Galactic dust contamination). The anisotropy measurements have been presented in Amblard et al. (2011), Planck Collaboration XVIII (2011), Viero et al. (2013), andPlanck Collaboration XXIX (2014), and modelled by Shang et al. (2012), Béthermin et al. (2013), Thacker et al. (2013), andManiyar et al. (2018). The models imply that the mass of the "typical" dark matter halo contributing to the CIB at z = 2 is log(M h /M ) = 12.77 +0.128 -0.125 (Maniyar et al. 2018). Such modelling predicts that dusty star-forming galaxies at high redshift are highly biased. The cosmic abundance of dust is Ω dust = (1-8) × 10 -6 for z 0-3 (Thacker et al. 2013;Schmidt et al. 2015). This implies that the dust-to-stellar-mass ratio increases from about 0.2 % at z = 0 to 1 % at z 2. The modelling of Maniyar et al. (2018) implies that obscured star formation dominates unobscured up to at least z = 4, with obscured and unobscured contributions becoming comparable at z = 5.</p>
        <p>As described in Sect. 2.6.2, the large-scale structure traced by dusty galaxies lenses the primary CMB anisotropies. Since the CIB probes the structure at intermediate redshift, the two are highly correlated (Song et al. 2003;Holder et al. 2013;Planck Collaboration XVIII 2014;Planck Collaboration VIII 2018). In Planck Collaboration VIII (2018) we present a joint analysis of lensing reconstruction and the CIB, with the latter providing our best current picture of the lensing modes on small scales.</p>
        <p>The CMB spectra of Fig. 18 provide the critical context for our understanding of reionization. The presence of a series of acoustic peaks in the angular power spectra of the CMB indicates that the Universe was dense and ionized at early times and then underwent a rapid transition to being (largely) neutral at z 1100. This neutral period lasted for a significant time. Had this transition not occurred, or lasted only a short time, multiple scatterings would have erased the anisotropies on scales smaller than the Hubble scale (e.g., Efstathiou 1988). The presence of an enhancement in the E-mode power spectrum at low indicates that the Universe became ionized again at z 10. This second transition is known as "reionization," and is often referred to as the end of the dark ages.</p>
        <p>The picture described above is consistent with numerous observations (see, e.g., Furlanetto et al. 2006, Becker et al. 2015, Bouwens et al. 2015, McQuinn 2016, and Mesinger 2016 for reviews) which can be used to constrain the sources of reionization and the manner in which the process occurred. By providing a measurement of the (integrated) optical depth to Thomson scattering, τ, and constraints on the kinetic SZ effect, the CMB can provide limits on the epoch and duration of the reionization process that are highly complementary to those obtained from other probes (Planck Collaboration Int. XLVII 2016).</p>
        <p>In currently popular models, ultraviolet photons from massive stars in relatively low mass early galaxies reionize hydrogen progressively throughout the Universe between z 12 and z 6, while quasars take over to reionize helium from z 6 to z 2. The combination of measurements indirectly constrains the nature of the sources driving reionization, and hence the formation of early stars and galaxies. The current observations point towards a "late and fast" reionization period, though with considerable uncertainty.</p>
        <p>The amplitude of the large-scale anisotropies in polarization is particularly sensitive to the value of τ (C EE ∝ τ 2 ; Fig. 35), with the shape of the low-bump encoding information about how the Universe reionized. This measurement is very demanding, since the expected level of the E-mode polarization power spectrum at low multipoles ( &lt; ∼ 10) is only a few times 10 -2 µK 2 , lower by more than two orders of magnitude than the level of the temperature anisotropy power spectrum. For such weak signals, the difficulty is not only to have enough detector sensitivity, but also to reduce and control both instrumental systematic effects and foreground residuals to very low levels. Our best estimate (Planck Collaboration VI 2018) is</p>
        <p>= 0.056 ± 0.007,</p>
        <p>where σ T is the Thomson scattering cross-section, n H (0) is the number density of hydrogen nuclei today and x e is the ionized fraction. 21 At low τ the measurement becomes very difficult. Indeed for the low values of τ currently favoured, the CMB cannot give tight constraints on details of the reionization process, although early reionization models are disfavoured.</p>
        <p>Fig. 35. The polarization angular power spectrum, D EE , for different optical depths, τ, running from τ = 0.04 to 0.07 in steps of 0.01. The thick black line shows the fiducial value τ = 0.056, while the grey shading shows the ±1 σ sample variance band for f sky = 0.67.</p>
        <p>On smaller scales, reionization generates CMB temperature anisotropies through the kinetic Sunyaev-Zeldovich (kSZ) effect, that is, the Doppler shift of photons scattering off electrons moving with bulk velocities. Currently we have only upper limits on the kSZ effect arising from the Universe during reionization, which suggest that reionization happened relatively quickly.</p>
        <p>Given the extreme difficulty of the measurement, and the trend of measured τ values to drop with time (Fig. 12) as measurement uncertainties have decreased, it is encouraging that Planck Collaboration: The cosmological legacy of Planck Planck provides another channel for constraining τ. Though more model dependent, the lensing of the CMB provides an independent, consistent measurement of τ. Within ΛCDM the peak of the τ posterior from lensing peaks at slightly higher values than Eq. ( 13), but is consistent at the 1.4 σ level.</p>
        <p>The latest results confirm that reionization occurred rather late, leaving little room for any significant ionization at high redshift (the optical depth from z &gt; 15 is less than 1 %; Planck Collaboration VI 2018). This is consistent with suggestions from other probes (Becker et al. 2015;Bouwens et al. 2015;McQuinn 2016;Mesinger 2016), as shown in Fig. 36. The Planck results strongly reduce the need for a significant contribution of Lyman continuum emission at early times. Non-standard early galaxies or significantly evolving escape and clumping factors are no longer required, nor do the Planck results require any emission from high-redshift (z = 10-15) galaxies. Fig. 36. Free electron fraction, x e (z), constrained from Planck using the "FlexKnots" method of Planck Collaboration VI (2018) and Millea &amp; Bouchet (2018), along with astrophysical constraints, as tabulated in Bouwens et al. (2015), updated to include Greig et al. (2017), Bañados et al. (2018), Mason et al. (2018), and Davies et al. (2018).</p>
        <p>The lower optical depth measured by Planck, in concert with the rapidly declining abundance of bright galaxies measured in UV luminosity functions at high redshift (e.g., Oesch et al. 2018) is consistent with this simple, galaxy-driven scenario. Indeed an extrapolation of the measured UV LFs to galaxies in halos above the atomic cooling threshold (T vir &gt; 10 4 K) provides enough photons to reionize the Universe by z 6 if the escape fraction of ionizing photons is f esc 0.1 (Bouwens et al. 2015).</p>
        <p>Measurements of redshifted 21-cm radiation promise to provide a complementary view to the one provided by the intergalactic medium, galaxy, and Thomson-scattering constraints. The recent, claimed detection of a larger-than-expected feature in the sky-averaged (that is, global) 21-cm signal by EDGES (Bowman et al. 2018) would require a colder IGM than most models predict, or some other change in the conditions at high z. Since many mechanisms for explaining the signal would also generate some ionization at high z, the low optical depth measured by Planck serves to limit candidates. Future observations of this global signal, and the fluctuations in the background, will be able to shed further light on this apparent discrepancy, and provide constraints that are complementary to those coming from the CMB.</p>
        <p>Planck was designed to measure the CMB temperature anisotropies to fundamental limits over the range of scales defined by the Hubble radius and the diffusion damping scale. It achieved this through a combination of instrument design, experimental optimization, sophisticated and iterative instrument modelling, and analysis. Planck validated the standard cosmological model (ΛCDM) and provided simultaneous, precise measurements of its key parameters, as well as tight constraints on possible extensions. However, multiple questions remain. For example:</p>
        <p>-What is the mechanism for the generation of fluctuations in the early Universe? -If it is inflation, as we suspect, what is the inflaton, what determines the initial state, and how does inflation end? -How did baryogenesis occur and why is ω b ∼ ω c ? -What is the dark matter? -Are there additional, light, relic particles? -What is causing the accelerated expansion of the Universe today? -How did the Universe reionize? -How do astrophysical objects form and evolve in the cosmic web?</p>
        <p>Absent a breakthrough in our theoretical understanding, the route forward on all of these questions is improved measurements, in which further observations of CMB anisotropies will play a key role. Advances in detector technology and in processing power will enable much higher-sensitivity observations of the CMB than Planck was able to provide. Given that Planck has effectively mined the information in the primary temperature anisotropies, the focus of CMB research is now shifting to studies of polarization and secondary effects such as CMB lensing.</p>
        <p>Many of the lessons learnedfoot_21 from Planck remain relevant in this post-Planck landscape. Wide frequency coverage and excellent control of systematic effects are prerequisites, but these must be coupled with a thorough modelling of the instrument, detailed simulations, and a sophisticated and efficient analysis pipeline. The Planck experience was that detailed simulations were invaluable, but required an enormous effort and needed attention from an early stage. Redundant methods for critical steps, including reconciling areas of disagreement, was important for verification of the final results. The understanding of the data and the extraction of the core science were closely intertwined, requiring large, integrated data-processing pipelines. Calibration, mapmaking, component separation, and analysis needed to be treated as a single, tightly-coupled problem.</p>
        <p>The Planck 2018 papers, including this one, represent the final word from the Planck collaboration, but do not mark the end of developments of Planck products. The activity leading to this release was circumscribed by time and funding constraints, not by perfection of the data products. We expect that contributions from individuals, both within and external to the Planck collaboration, will continue to build upon the Planck legacy and that the Planck data will prove invaluable for a wide range of future cosmological studies.</p>
        <p>Planck was the third-generation space mission dedicated to measurement of CMB anisotropies. It delivered on its promise to provide a measurement of the primary CMB temperature anisotropies between the Hubble scale and the damping scale to fundamental limits, and provides some of our most important constraints on models of cosmology and fundamental physics. The Planck temperature auto-spectrum is cosmic variance limited to 1600. In this respect, Planck has ended a phase in primary temperature anisotropy studies that was opened by COBE in 1992.</p>
        <p>The study of the CMB has been central to the story of cosmology since its discovery provided some of the earliest evidence for the hot-big-bang model of an expanding Universe. Building upon a legacy of earlier experiments and decades of theoretical development, Planck has now measured the properties of the Universe to percent-level fidelity and tested our cosmological model to high precision. Planck data provide the strongest evidence we have that dark matter cannot be entirely baryonic (luminous or dark) and that the observed fluctuations were laid down at very early times, proportionally in all of the constituents of the Universe.</p>
        <p>One of the major scientific legacies of Planck has been to test and highly constrain the ΛCDM model. The inflationary ΛCDM model was first developed in the 1980s (Peebles 1984;Vittorio &amp; Silk 1985) and rose to prominence during the 1990s (Efstathiou et al. 1990;Ostriker &amp; Steinhardt 1995;Krauss &amp; Turner 1995;Liddle et al. 1996). The discovery of the accelerated expansion of the Universe at the end of that decade (Riess et al. 1998;Perlmutter et al. 1999), and the measurement of the acoustic peaks soon after (de Bernardis et al. 2000;Balbi et al. 2000;Miller et al. 2002), cemented it as the "standard model" of cosmology. In the three decades since it was first developed, the quality and quantity of cosmological data have exploded. The model has weathered all of these challenges, and remains our best (phenomenological) description of the Universe.</p>
        <p>The Planck data have been particularly important in this regard. The ΛCDM model, with parameters fixed by pre-Planck experiments, made solid predictions for the range of anisotropy spectra that Planck would measure. The dramatic improvement in angular resolution, sensitivity, foreground cleaning, and systematics control from the Planck data provide the most stringent test of the model yet, and have allowed us to measure its parameters to high precision (Table 7).</p>
        <p>A network of tests established the consistency of the measurements and enabled many different tests of the model. The small amplitude fluctuations traced by Planck at z 1100, the gravitational potentials traced by Planck lensing at z 0.5-10, and the matter fluctuations probed by large-scale structure surveys at z &lt; 1 are part of a consistent picture.</p>
        <p>The flatness of the spatial hypersurfaces has been established at the 5×10 -3 level. Neutrino masses have been constrained to be O(0.1 eV). The number of relativistic species is consistent with three light neutrinos and disfavours any light, thermal relics that froze out after the QCD phase transition. The baryon density inferred from the acoustic oscillations up to t = 400 000 yr is consistent with that inferred from BBN at t = 3 min. Dark-matter annihilations are tightly constrained. Dark energy is consistent with being a cosmological constant that dominates only recently.</p>
        <p>The pattern of acoustic oscillations in temperature and polarization power spectra implies an early-Universe origin for the fluctuations, as in the inflationary framework. The primordial fluctuations are Gaussian to an exceptional degree. There are no gravitational waves at the 5 % level, suggesting the energy scale of an inflationary epoch was below the Planck scale.</p>
        <p>The ability of the ΛCDM model to explain the Planck data, and a wealth of other astrophysical observations, indicates that our understanding of physics is good enough to model 14 Gyr of cosmic history and explain observations out to the edges of the observable Universe. However, the surprising ingredients required by this model suggest that our understanding is highly incomplete in several areas.</p>
        <p>Despite these successes, some puzzling tensions and open question remain. While many measures of the matter perturbations at low redshift are in excellent agreement with the predictions of ΛCDM fit to the Planck data, this is not true of all of them. In particular, measurements of the fluctuation amplitude from cosmic shear tend to lie low compared to the Planck predictions. Measures of the distance scale from nearby Type Ia SNe remain discordant with the inferences from the inverse distance ladder. We expect these areas will see continued attention from the community, which will determine whether these tensions point to statistical fluctuations, misestimated systematic uncertainties, or physics beyond ΛCDM.</p>
        <p>synchrotron, free-free, thermal and spinning dust, and CO emissions for temperature, as well as the CMB, synchrotron, and thermal dust in polarization; 2. estimate the calibration factor G, including in the Galactic model both the temperature and polarization components of the sky, as well as the Solar and orbital dipoles; 3. apply gains and construct frequency maps; 4. determine a new astrophysical model from the frequency maps using 
            <rs type="software">Commander</rs> (including only LFI frequencies); 5. iterate steps (2) to (4). This approach is quite demanding computationally, and each iteration typically requires one week to complete. In practice, the iterative process was stopped after four iterations, by which point good convergence had been achieved. This approach worked well at 30 and 44 GHz but failed at 70 GHz. This is because for the foreground modelling the 30-and 44-GHz channels is signaldominated, while the 70-GHz channel is noise dominated, resulting in a diverging process (with the algorithm partly calibrating on noise rather than signal).
        </p>
        <p>Another, more minor change in the LFI DPC pipeline is a revision of the flagging procedure. This resulted in more conservative criteria, which discarded additional samples, especially in the first 200 operational days.</p>
        <p>The raw HFI data for this 2018 release are identical to those of the Planck 2015 release (see Planck Collaboration VIII 2016) with one exception, namely that approximately 22 days of data were dropped from the analyses. These data were taken in the final days of HFI observations at a time of increasing Solar activity and of some HFI end-of-life changes in the cryogenic chain operations. These 22 days correspond to 1000 rings, for which the data were affected significantly more than in any earlier period of similar length during the mission, as revealed by the statistics of the C at low multipoles ( = 3 to 20). This last period is the farthest outlier of the 27 blocks of 1000 rings.</p>
        <p>The main differences in the data processing are the use of a new map-making and calibration algorithm called SRoll. A first version of this algorithm was introduced in Planck Collaboration Int. XLVI (2016), which used the very low multipoles from HFI to extract the τ parameter. SRoll is based on a generalized polarization destriper that uses the redundancy in the data to extract a number of instrumental systematic-effect parameters directly from the sky data, for example parameters associated with intensity-to-polarization leakage. The spectral transmissions or bandpasses of the HFI band filters were measured on the ground, but with insufficient accuracy for the legacy mapmaking. Bandpass mismatch between two detectors sensitive to orthogonal polarizations results in a "leakage" of temperature foreground signals (with a different spectral energy distribution from the CMB). into polarization. This effect is taken into account in the map-making. In the 2015 release we used bandpass-mismatch coefficients computed from the ground measurements. In SRoll these are obtained from the sky data, using foreground-map templates from the previous release to derive relative values of the coefficients between detectors, and taking advantage of the redundancy of polarization measurements of the same sky pixel. This brings significant improvements, as demonstrated by the end-to-end simulations and by the reduction of the systematic effects in null tests. The power of the SRoll map-making was tested a posteriori, after the maps were frozen, by using as input templates for the CO lines two maps of the Taurus molecular cloud in the 12 CO and 13 CO molecules. After the recovery of the relative response coefficients and the reconstruction of all-sky maps of the CO foregrounds, these maps were tested on other radio-astronomy data at high latitudes, and showed a significant improvement over the 2015 maps.</p>
        <p>Similarly, CMB calibration errors between detectors sensitive to orthogonal polarization states will also induce spurious polarization. Changes in detector response over time can be measured using the large-amplitude CMB dipole signals, averaged over short periods during the mission, and show larger variations of the response with time than expected. Moreover, the nonlinear part of the analogue-to-digital-converter (ADC) response was not known with sufficient accuracy. To mitigate this, apparent gain variations per optimized time periods were extracted in SRoll using redundancy in the surveys over the mission, leading to better maps than when corrections for non-linearity of the ADCs were performed in the time-ordered data.</p>
        <p>The improved measurement of the CMB Solar dipole discussed in Sect. 2 allows us to perform an extremely accurate check of the calibration error through end-to-end simulations. In turn this shows that the dispersion between the full-missionaveraged photometric calibration of bolometers within a frequency band is also induced by the temporal variations themselves, and fully accounted for by the uncertainties in the ADC non-linearity correction. The systematic effects in relative calibration revealed by the Solar dipole between the "a" versus "b" detectors within polarization-sensitive bolometers (PSBs) of the same frequency seen in 2015 (Planck Collaboration VIII 2016) are no longer detectable in the 2018 release (see Planck Collaboration III 2018 for details).</p>
        <p>The introduction of these sky-extracted systematic-effect parameters led to a major improvement in null tests, as can be seen in Planck Collaboration III (2018) for the lower frequency CMB channels (100 to 217 GHz), especially at large scales. However, for 353 GHz the ADC non-linearity is not the dominant systematic effect. The very long time constants (around 30 s) of the bolometers (which primarily affect the dipoles and for which a correction was already implemented in 2015) also affect other low harmonics of the spin frequency. This systematic effect dominates the low multipoles of the power spectra at 353 GHz. It was detected through the SRoll destriper at 353 GHz; however, the correction introduced is not very accurate, and leaves artefacts that are still detectable in odd-even survey null tests.</p>
        <p>These main improvements introduced in the 2018 HFI data release with respect to 2015 are described in detail in Planck Collaboration III (2018).</p>
        <p>At the level of precision reached by Planck, the best method for conveying our knowledge of the maps in relation to the sky emission is through end-to-end simulations of the sky observations and data processing. Since these simulations are the best characterization of the statistical properties of the data that we have, we have made available to the community detailed simulations of the full focal plane; these are called the "FFP" series, the ones used in 2018 being "FFP10."</p>
        <p>We have used detailed instrumental simulations to estimate the level of residual systematic effects (see Fig. 3), and decide which of these needed to be included in the full end-to-end simulations. Each FFP10 simulation comprises a single "fiducial" realization (CMB, astrophysical foregrounds, and noise), together with separate Monte Carlo (MC) realizations of the CMB and noise. To mimic the Planck data as closely as possible, the sim-ulations use the actual pointing, data flags, detector bandpasses, beams, and noise properties of the mission. For the fiducial realization, maps were made of the total observation (CMB, foregrounds, and noise) at each frequency. In addition, maps were made of each component separately, of subsets of detectors at each frequency, and of half-ring and single-survey subsets of the data. The noise and CMB MC realization-sets include all detectors, as well as subsets of detectors (so-called "DetSets") at each frequency, and full and half-ringfoot_22 data sets for each detector combination.</p>
        <p>The improvements summarized in Appendices B.1 and B.2 translate directly into lower instrumental systematics in the corresponding derived sky maps (Planck Collaboration II 2018; Planck Collaboration III 2018), and thereby more robust component-separation (Planck Collaboration IV 2018) and likelihood (Planck Collaboration V 2018) results. For the purposes of CMB temperature reconstruction, these updates have a relatively minor practical impact, due to the very high signal-tonoise ratio of the Planck temperature observations, where already the Planck 2015 temperature products had residual errors significantly below the limit set by cosmic variance for nearly all cosmologically relevant angular scales.</p>
        <p>The same does not hold true for polarization reconstruction. In this case, Planck's sensitivity corresponds roughly to a signalto-noise ratio of unity or less for the (unbinned) CMB E-mode power spectrum, and a fraction thereof for the B-mode reconstruction. At the same time the astrophysical foreground signal from polarized thermal dust and synchrotron emission is brighter than the E-mode signal by more than an order of magnitude at frequencies below 40 GHz and above 200 GHz, and comparable to it even in the foreground minimum around 70-100 GHz (see Fig. 4). The greatest gains deriving from the Planck 2018 processing are therefore observed in terms of more robust polarization component-separation and likelihood products, in particular on large angular scales.</p>
        <p>Starting with the CMB component-separation products, this is immediately highlighted by the fact that the cleaned Planck 2018 CMB polarization maps include information at all angular scales, from = 2 to 3000 (Planck Collaboration IV 2018). In comparison, the corresponding 2015 products were high-pass filtered below = 40 in order to remove obvious instrumental contamination (Planck Collaboration IX 2016). Furthermore, for the first time the new CMB polarization maps appear statistically consistent with detailed end-to-end CMB-plus-noise simulations (see Sect. B.3) on large angular scales, in terms of power spectra and basic higher-order statistics.</p>
        <p>However, it is critical to note that while the new maps are consistent with end-to-end simulations, they are not consistent with naive white noise simulations. The Planck noise properties are complicated and spatially correlated, both because of intrinsic 1/ f noise and transfer function effects, and because of gain fluctuations coupled to the actual sky signal, in particular via the bright CMB dipole. In the current release, we therefore provide 1000 CMB realizations processed through the full end-to-end analysis pipeline, as well as 300 noise simulations per data split. Detailed scientific analyses of the Planck 2018 CMB products should be accompanied with a corresponding analysis of these simulations.</p>
        <p>Similar improvements are observed in terms of polarized foreground products. Indeed, the Planck 2018 maps represent the first reduction of the Planck data that allows even preliminary estimation of the spectral index of thermal dust emission location-by-location on a degree smoothing scale. Such analyses are in general highly sensitive to the presence of large-scale systematics, since they simultaneously depend on all angular scales. The fact that no obvious instrumental artefacts are seen in the polarized thermal dust spectral index map derived from the Planck 2018 observations (see figure 29 in Planck Collaboration IV 2018) provides evidence for a high degree of internal consistency between the 143, 217, and 353 GHz frequency channels.</p>
        <p>For reconstructing temperature foregrounds, the Planck 2018 data release is not an improvement, due to the lack of singlebolometer sky maps (see Sect. 3.1.2 of Planck Collaboration III 2018 for details). First, this strongly limits our ability to model and extract CO line emission, which in turn also affects the robustness of other correlated components, including thermal dust, free-free, spinning dust, and synchrotron emission. Second, it also precludes the possibility of removing single channels that are particularly strongly affected by specific instrumental systematic errors, such as bandpass-mismatch or far-sidelobe contamination. (See Planck Collaboration X (2016) for an example of such analysis based on the 2015 measurements.) For these reasons, we do not provide an updated, comprehensive Commanderbased foreground model in intensity in the 2018 release, but instead suggest continued usage of the corresponding 2015 model. We consider the 2015 thermal dust model to be more robust than the new model also for GNILC. However, for CMB temperature extraction purposes these issues are of minor concern, since the accuracy of this process only depends on the sum of the foregrounds, and not on each individual component. As shown in Planck Collaboration IV (2018), the CMB temperature maps derived from the Planck 2018 frequency products are consistent with the corresponding 2015 temperature maps.</p>
        <p>The likelihoods have seen many changes and improvements since 2015, as listed and discussed in detail in Planck Collaboration V (2018) for the CMB spectra, and Planck Collaboration VIII (2018) for lensing.</p>
        <p>As in 2013 and 2015, the cosmological constraints are obtained using an approximate likelihood. Different mathematical approximations and different data-selection choices are needed at different scales to correctly evaluate the likelihood. For this reason, the overall Planck likelihood is formed using a hybridization of different approximations, neglecting the correlations between the different parts of the likelihood. The impact of this hybrid approach has been extensively discussed in the literature (e.g., Efstathiou 2006;Planck Collaboration XI 2016). In the following, we only discuss the specific improvements and changes for each part of this hybrid approach.</p>
        <p>The 2018 baseline hybridization scheme relies on a different data mix than in 2015. In 2015, residual unresolved systematics and a conservative approach led us to recommend the use of the Commander large-scale T T map, the LFI large-scale polarization maps, and the small-scale HFI temperature maps, while the reconstructed lensing map was only used in some specific analyses and the small-scale, HFI polarization maps were used in a preliminary manner. In 2018, the baseline data for cosmology now consist of the Commander large-scale T T map, the HFI large-scale polarization maps (using the EE and BB spectra only), the HFI small-scale temperature and polarization maps, and the lensing reconstruction map. The LFI large-scale polarization map is now used for cross-validation and some specific analyses. These changes provide a very significant improvement on the constraining power of the Planck data, as seen for example in Fig. 13.</p>
        <p>The likelihoods used are labelled by the data that go into them, as described in Planck Collaboration V (2018) and Planck Collaboration VI (2018). For example TT,TE,EE+lowE uses the combination of temperature and E-mode polarization auto-spectra with the TE cross-correlation at high and the TT and EE spectra at low computed from Commander and Simall respectively. 1. The samples from the Bayesian exploration are reused to build a foreground-marginalised, large-scale temperatureonly likelihood approximation, as is described in Planck Collaboration XI (2016). This forms the largescale T T part of the hybrid likelihood, as in 2013. 2. The Commander foreground-cleaned temperature map is used with the LFI large-scale polarization maps to build the T E part of the large-scale alternative polarized likelihood.</p>
        <p>The map is also used to build a T E-based likelihood approximation with the HFI data, but its statistical characterization is shown to be too poor to build a large-scale T E likelihood.</p>
        <p>While the Commander methodology has not changed significantly since the 2015 release, we have modified our choice of data cuts and accordingly the model. In order to produce a robust and conservative product for the 2018 release, we removed the dependency on external data, namely, the WMAP and Haslam 408-MHz data sets (Bennett et al. 2013b;Haslam et al. 1982). While the HFI data processing has been greatly improved in terms of the number of systematic effects that are resolved on large scales, it no longer produces individual bolometer maps. In 2015, we used the slightly different bandpasses of the different individual bolometers and external data to constrain a more complex data model (in temperature). Because of the focus on polarization systematics, this is not possible with the 2018 data. For this reason, the usable sky fraction for Commander has shrunk from 94 % to 86 %. Nevertheless, large-scale agreement between the different foreground-cleaned maps has improved compared to 2015, and in particular for the SMICA map used for some specific applications (such as lensing or higher-order moment estimation).</p>
        <p>Following the work presented in Planck Collaboration Int. XLVI (2016), and building on the improvements described in Sects. B.2, B.3, and B.4, the level of residual systematics present in the large-scale HFI polarization data is now low enough that the 100-GHz and 143-GHz maps can be used to build a largescale EE likelihood. This likelihood allows for a roughly 6 σ determination of the reionization parameter, with τ = 0.0506 ± 0.0086, using only the low-HFI polarized data along with the Commander T T large-scale likelihood, and fitting jointly for τ and the amplitude of scalar fluctuations.</p>
        <p>The large-scale HFI polarization likelihood is based on comparison between the cross-spectrum of the foreground-cleaned 100-GHz and 143-GHz polarization maps and very detailed, end-to-end simulations of the HFI data. Due to our inability to accurately account for ADC non-linearity, our modelling of the pixel covariance matrix is not sufficient and prevents us from using a more classical pixel-based likelihood approximation, as we do for LFI. In more detail, cleaned CMB maps at 100 GHz and 143 GHz are obtained by fitting for the dust and synchrotron contamination (using the 353-GHz and 30-GHz maps, respectively, as templates). The maps are further masked to avoid the highly contaminated regions, retaining 50 % of the sky. To reduce the level of scatter and correlation induced by the mask, the power spectra are estimated using the quadratic-maximumlikelihood (QML) method. The likelihood is computed by forming the product of the probabilities of each of the QML powerspectrum multipoles, ignoring -to-correlations. This probability is estimated by counting the number of end-to-end simulations computed for different input cosmologies that fall close to the observed value. Planck Collaboration V (2018) presents a very thorough validation of this method, exploring the variations of the likelihood when changing masks, foreground-cleaning methods, data cuts, using part WMAP or LFI data, etc. To give a flavour of the robustness of the approximated likelihood, and the fidelity of our simulations, we display in Fig. B.1 the distribution of QML synthetic spectra measured from our end-to-end simulations for an input τ = 0.05, and compare this with the observed EE spectrum.</p>
        <p>The T E spectrum measured in a similar way also shows decent statistical agreement with our simulations, but fails some of our null tests (Planck Collaboration V 2018). Furthermore, our simulation-based likelihood estimation makes it very difficult to accurately take into account T E × EE and T E × T T correlations. For T E this is particularly important, to avoid double counting the constraining power of the temperature and polarization maps; however, it is much less of an issue for EE, which has a much lower correlation with T T . For these reasons we do not include the estimated, low-T E spectrum in the likelihood. Similar work was performed with the BB spectrum, but at the level of sensitivity of the HFI data, it is compatible with a null spectrum.</p>
        <p>As we did in 2015, we produce a full TEB likelihood using a pixel-based approach based on the Commander and LFI polarization maps. Given the lower sensitivity of LFI, this likelihood approximation has an overall lower constraining power on the reionization fraction than the HFI-based one, with a roughly 3 σ determination of τ = 0.063 ± 0.020. Nevertheless, the 2018 version of the LFI-based likelihood can be used when probing the TEB correlations, which may be important for specific cosmological tests.</p>
        <p>This pixel-based, low-approximation was already used in 2015, but has been improved and made more robust. Thanks to the improvements in the LFI data processing and simulation pipelines, the sky fraction retained for the cosmological analysis has been increased from 46 % to 66 %, and the second and fourth sky surveys, which were excluded from the 2015 likelihood, are now included. Robustness of the likelihood approximation has been further tested on different sky fractions, as well as through comparison with WMAP and HFI data.</p>
        <p>The methodology of the small-scale temperature and polarization likelihood approximation has not changed since 2015, and remains very close to that of 2013. We continue to describe the statistical properties of the data with a Gaussian approximation. We are still using cross-half-mission spectra of the 100, 143, and 217-GHz channel maps, masking the highly foregroundcontaminated sky regions (due to Galactic contamination and, in the case of temperature, point sources). The masks have not changed since 2015. We are also discarding some of the spectrum multipoles that have a low signal-to-noise ratio or high foreground contamination. Compared to 2015, we have improved both the data and their characterization to a level where we can now lift the reservations we had in 2015 on the usage of the polarized small-scale data (T E and EE) for cosmology.</p>
        <p>On the data side, as described in Sects. B.2 and B.4, most of the effort has translated into a decrease of the level of systematics at large scales in polarization. This also has some impact on the small-scale polarization likelihood, the most important being a reduced level of noise in the 143-GHz Q and U maps (by about 12 %).</p>
        <p>On the modelling side, the main improvements have been the correction of the so-called "beam leakage," and a better determination of the polarization efficiencies of our detectors. These two refinements have a large effect on the consistency of the different T E and EE cross-spectra, as shown in Fig. B.2. Disagreement between the polarized cross-spectra in 2015 was the reason we did not recommend the use of the polarized data for cosmology applications. With the new analysis, there is no longer such a limitation.</p>
        <p>In detail, differences between the beams, gains, polarization efficiencies, and polarization angles of the different data streams that enter the computation of a Q or U map are sources of temperature-to-polarization leakage. In 2015 we could only evaluate those effects a posteriori, with a cosmology-dependent model. In 2018, following the methodology presented in Hivon et al. (2017), we can propagate the known characteristics (from measurements made on the ground) of the different detectors and compute beam-leakage templates for each crossspectrum. We tested the fidelity of the templates against simulations and estimated their residual uncertainty. Correcting for beam leakage results in the large improvement of the T E interfrequency comparisons displayed in Fig. B.2.</p>
        <p>Temperature-to-polarization leakage corrections have a small effect on the EE cross-spectra disagreement. Corrections to the estimated polarization efficiencies of the detectors are the source of the improvement displayed in the bottom panel of Fig. B.2. Null tests performed on highly dust-contaminated regions in the high-frequency polarized channels (mainly 353 GHz, but also 217 GHz) have led us to revise upwards our previous estimate of the polarization-efficiency uncertainty by a factor of 5 to 10. Polarization-efficiency assessments performed using frequency-channel cross-spectra, with or without cosmology priors, as described in Planck Collaboration III (2018) and Planck Collaboration V (2018), translate into percent-level corrections that need to be applied to the polarization efficiencies of the 100, 143, and 217-GHz channels.</p>
        <p>While the 100 and 217-GHz polarization-efficiency measurements are relatively stable, we find a 2 σ discrepancy between the estimates performed at 143 GHz, depending on whether the estimation is made on the EE or T E spectra. This difference is somewhat worrisome, since the 143-GHz channel dominates the cosmological constraints in polarization. At this time, we cannot tell whether this difference is a statistical fluctuation or a faint sign of residual systematics projecting onto the polarization efficiency estimates. We evaluate the effect of either enforcing the EE-based polarization efficiency estimation on T E (the so-called "map-based" calibration model), which we retain for our baseline, or letting the EE and T E spectra have a different effective calibration (the so-called "spectrum-based" calibration model), which we use in an alternative likelihood implementation. The two different calibration models translate into ≤ 0.5 σ parameter shifts, which gives us an estimate of the level of possible residual systematics in the polarization analysis.</p>
        <p>Numerous other improvement have also been applied to the high-likelihood. Beam corrections have been computed specifically for each of the different masks used in temperature and polarization, and we have tightened our estimate of the beams and beam-leakage uncertainties, including effects that we neglected in previous analyses. We have significantly improved the quality of the residual Galactic contamination estimation and correction in the likelihood. Finally, we have also improved the estimation of the level of residual correlated noise in the spectra. We now include two, very small correlated-noise corrections, namely subpixel noise (due to the centroid of data samples falling in a pixel being different from the pixel centre) and a correlated-noise component in the auto-frequency EE spectra that was observed in the high fidelity end-to-end simulations (see Sect. B.3). All these refinements, while increasing the robustness of the likelihood approximation, have a much smaller impact than the beamleakage and polarization-efficiency corrections.</p>
        <p>With these improvements, the high-T T , T E, and EE CMB power spectra are found to be in good agreement with each other in the context of a common ΛCDM model, as demonstrated by the conditional predictions displayed in Fig. 17.</p>
        <p>In 2018, the CMB power spectra (that already contain some information on lensing) are complemented by the lensing power spectrum measured using the reconstructed lensing-effect map (Sect. 2.6.2). In 2013 and 2015, a lensing-power-spectrumbased likelihood was already provided, but it was only used for some specific cosmological applications. It is now systematically added into the baseline hybrid likelihood mix.</p>
        <p>The lensing estimation pipeline has been significantly improved compared to 2015. Lensing maps are reconstructed from the SMICA 2018 foreground-cleaned maps, using only a combination of the high-frequency maps. We now use inverse-noise weighting for polarization-only band powers to improve the S/N in reconstruction, a new mask to reduce point-source contamination, and a better model of the multiplicative bias.</p>
        <p>The improved filters for polarization reconstruction allow us to perform a polarization-only lensing reconstruction, as a demonstration of consistency, and a cross-check on the paradigm. The robustness of the measurement pipeline has also been checked in numerous new ways, extending greatly the already quite thorough validation suite from 2013 and 2015. In particular, SZ and CIB leakage effects are checked, different Galactic masks are used to measure the impact of any residual Galactic contamination in the SMICA maps, and alternative masks and data cuts (surveys, half missions, etc.) are used to check for any scanning-dependent feature in the lensing reconstruction maps.</p>
        <p>Thanks to our extensive validation suite, we have managed to increase the range of lensing multipoles usable for cosmological constraints, reducing the lower limit from L = 40 to L = 8. This helps to constrain some specific cosmological models. Multipoles below this are adversely affected by a large and uncertain mean-field correction (Planck Collaboration VIII 2018). The upper limit, L = 400, remains unchanged from our earlier releases, although data are provided to much smaller scales.</p>
        <p>Figure C.1 compares the LFI 70-GHz and the HFI 100-GHz maps in selected regions of the sky, when both are expressed in thermodynamic temperature units and smoothed to a common resolution of 15 . Frequency-difference (upper-right) maps demonstrate excellent consistency of the measured CMB anisotropies, and reveal diffuse foregrounds and point sources. The expected noise level is estimated (lower-left) by the difference of 70-GHz half-ring, and 100-GHz half-mission difference maps, each of which is a good noise estimate of the respective signal maps.</p>
        <p>The top four panels of Fig. C.1 show an enlargement of the north ecliptic pole region, which was scanned by Planck most frequently and is thus one of the least noisy parts of the sky. One can see in the difference map positive dust and CO emission, and negative free-free and synchrotron emission (because the lower frequency channel is subtracted from the higher frequency one). Note the large Cygnus region in the Galactic plane. The four bottom panels are focused on the south Galactic pole region, with the same layout as for the top four panels. This a region with fairly reduced foreground emission; still, the haze of dust in the top right corner of the difference map is clearly visible. We note the large, negative CMB fluctuation in the upper left of the 70and 100-GHz frequency maps, called the "Cold Spot" anomaly, which is rendered in the same way by LFI and HFI. Similar tests on the full sky, the entire equatorial, south ecliptic, and north Galactic pole regions, do not reveal any worrisome instrumental features.</p>
        <p>One can make a more quantitative comparison by using power spectra in low foreground regions, masking 40 % of the sky by combining Galaxy and point-source frequency-specific masks. Figure C.2 compares binned cross-power spectra from the 70 and 100 GHz channels. The plotted noise spectra are the auto-spectra of the respective difference maps. Also shown is the raw spectrum at 143 GHz, a channel whose noise is negligible at these angular scales (the noise spectrum is plotted, but it lies along the x-axis). We display the average power (∝ (2 + 1)C ) in each bin, and show the error on the mean as an estimate of the binned power uncertainty (inclusive of cosmic variance within each bin). For 70 and 100 GHz, the spectra are corrected for multiplicative calibration offsets with respect to the 143-GHz spectrum used as a fiducial for this check; the offsets are 0.997 for 70 GHz, and 1.001 for 100 GHz, very small corrections that indicate excellent calibration of Planck frequency maps, combined with a small amount of residual power from Poissondistributed, undetected point sources (C 70 4.5 × 10 -4 µK 2 , and C 100 1.75 × 10 -4 µK 2 ). This simple procedure is enough to bring the three spectra into good agreement. The plot also shows the best-fit model as derived by Planck multi-component likelihood fits with many nuisance parameters, including an optimal determination of calibration and various correction factors that become increasingly important at higher multipoles. In the range shown, the best fit is traced well by the 143-GHz raw spectrum.</p>
        <p>The bottom panel of Fig. C.2 shows the corresponding power ratio. The drop in the values of some ratios at &lt; 150 is due to uncorrected diffuse foreground emission that becomes brighter at 143 GHz outside the masked region of the Galaxy. The nearby 70 and 100-GHz spectra indeed do not display such a drop. For the whole &gt; 150 range, there is excellent consistency of the 143 and 100-GHz spectra. The LFI 70-GHz spectrum becomes noisy at &gt; 600 and because of that we display it only up to 800. Nevertheless, we note the remarkable consistency (at the level of a few ×10 -3 ) of all three spectra around the first acoustic peak near 220.</p>
        <p>Of course, such checks are too coarse to be directly useful for cosmology, which requires that we account for much smaller contributions than are visible by eye. Indeed, for analyses of isotropy and statistics of the CMB, one needs to resort to component separation and simulations, while for cosmological parameters one needs a likelihood analysis that directly accounts for the degeneracies between CMB and nuisance parameters of astrophysical and instrumental origin. However, the comparisons described here have the virtue of simplicity and provide a direct visual test of consistency.</p>
        <p>We end with an appendix addressing some of the principles that were followed in the Planck analysis. In particular we address the extent to which "blinding" (see, e.g., Klein &amp; Roodman 2005) was used in the production of results from Planck. We include this discussion here because the question has often come up, not least in the context of parameter tensions with other data sets.</p>
        <p>The goal of blind analysis is the avoidance of biases and errors introduced by investigators. The general principle is to shield relevant results from the view of investigators until analytical methods have been decided, implemented, debugged, and completed. Various techniques, such as "noising," "biasing," "cell scrambling," "seeding," and "item scrambling" (e.g., Maccoun &amp; Perlmutter 2015) have proven to be useful in many situations.</p>
        <p>For Planck, and indeed all CMB experiments, the importance of the goal of blind analysis can hardly be overstated, and a quantitative demonstration is required that the goal has been met to a specified level. The methods of analysis used must also satisfy another difficult requirement, that of extracting cosmological and astrophysical information from the data to a level of 10 -6 , 10 -7 , or even 10 -8 of the input signal level. The ultimate limits to this signal extraction are set by some combination of instrument noise, noise in the sky signals themselves, the separation of signals from various sources (especially the CMB from Galactic and extragalactic foregrounds), and instrumental systematic errors, which in general are time-dependent and include transients. All of these must be determined from the data themselves, in a process of disentanglement, identification, and mitigation, starting from the largest and most easily identifiable effects, and moving down to the smallest and most degenerate. Larger effects mask smaller effects, and combinations of effects may be particularly hard to recognize.</p>
        <p>An important tool for detecting systematic errors in astronomical measurements is redundancy in the observations themselves, that is, multiple observations of the same part of the sky. 24 Each of these redundancies provides null tests of the data, in other words, differences between two observations of the same 24 Of course one must take into account the changing nature of the sky itself, whether from variable objects (e.g., essentially everything, but on varying timescales), moving objects (e.g., planets), or things that vary with location and direction (e.g., the zodiacal light). Fortunately for CMB measurements, the CMB itself changes only on a cosmological timescale, and short-term changes in its characteristics that depend on the motion of the observer can be predicted with exquisite accuracy and used as a fundamental calibrator (in particular, the "orbital dipole"). Planck incorporates observational redundancy on multiple timescales, from 1-min rotations of the spacecraft, with the spin axis fixed for many rotations, to the approximately 6-month repeat coverage of the sky (with the angle of attack on a given piece of sky alternating each time), to the exact 1-year repeat coverage of the sky. sky that should be zero within the noise. A common, and initially almost inevitable, cause of null-test failures is poor knowledge of the noise. Other causes of null-test failures can sometimes be identified (e.g., Solar flares), and affected data removed from further processing. The removal process can be specified with strict criteria that are applied without reference to their effect on final results (such as cosmological parameters), that is, "blind"; this is always done in Planck data processing.</p>
        <p>Null tests are necessary, but not sufficient, in revealing problems in the data. For one thing, any systematic error that affects all of the data, such as overall calibration errors, has no effect on null tests. Equally important, and much harder to address, are systematic effects that are too small or too distributed for detection in the timeline data, but that cause problems when concentrated in further processing. These can be difficult to identify, especially in combination, although some can be predicted from a priori understanding of the instruments and mission. Nevertheless, an exhaustive search is impossible -there are simply too many possibilities. Instead, one must search all intermediate and even final data products (i.e., the parts of phase space where systematic errors really matter) for problems. Such searches cannot be technically "blind", as indeed their value lies in the sensitivity of results to specific systematics. In practice, however, they are effectively blind, for two reasons. First, no one can look at a map of the sky or an angular power spectrum and know the values of cosmological parameters that will fit them. Second, Planck's results are complex, rather than just a few numbers, and with such complexity investigator bias is inherently less of a problem than with simple outcomes. However, when apparent problems are found, by whatever method, the cause of the problem must be traced back to an instrumental or observational origin before corrective action can be taken with any sense of certainty.</p>
        <p>Still, the dangers of removing sky signal from the data along with some known but partly degenerate systematic are real. In the end, the most important tool both for finding systematics and for demonstrating that the processing of the data does not remove or bias the signals being investigated is simulations. While simulations including complex astrophysics and space-borne detectors cannot approach the level of realism encountered in particle physics experiments (which imposes fundamental limitations on how blinding can be performed), they have progressed dramatically over the lifetime of Planck. As has been described in detail in many Planck Collaboration papers, simulations have been an essential tool in the analysis of Planck data.</p>
        <p>a Velocity of the Sun relative to the CMB; Planck 2018. b Velocity of the Sun relative to the Local Standard of Rest from Schönrich et al. (2010), adding statistical and systematic uncertainties. c Rotational velocity of the LSR from McMillan (2011). d Resulting velocity, using non-relativistic velocity addition and assuming uncorrelated errors. e Velocity of the Sun relative to the Local Group from Diaz et al. (2014).</p>
        <p>a . . . . . . . . . . . . . . . . . . . . . . .</p>
        <p>6-parameter ΛCDM model that best fits the combination of data from Planck CMB temperature and polarization power spectra (including lensing reconstruction), with and without BAO data (see text). A number of convenient derived parameters are also given in the lower part of the table. These best fits can differ by small amounts from the central values of the confidence limits in Table</p>
        <p>7</p>
        <p>. Parameter Planck alone Planck + BAO Ω b h 2 . . . . . . . . . . . . . 0.022383 0.022447 Ω c h 2 . . . . . . . . . . . . . τ . . . . . . . . . . . . . . . . Λ . . . . . . . . . . . . . . m . . . . . . . . . . . . . .</p>
        <p>Λ . . . . . . . . . . . 0.6847 ± 0.0073 0.6889 ± 0.0056 Ω m . . . . . . . . . . . 0.3153 ± 0.0073 0.3111 ± 0.0056 Ω m h 2 . . . . . . . . . . 0.1430 ± 0.0011 0.14240 ± 0.00087 Ω m h 3 . . . . . . . . . . 0.09633 ± 0.00030 0.09635 ± 0.00030 σ 8 . . . . . . . . . . . . 0.8111 ± 0.0060 0.8102 ± 0.0060 σ 8 (Ω m /0.3) 0.5 . . . 0.832 ± 0.013 0.825 ± 0.011 z re . . . . . . . . . . . . 7.67 ± 0.73 7.82 ± 0.71 Age[Gyr] . . . . . . 13.797 ± 0.023 13.787 ± 0.020 r * [Mpc] . . . . . . . . 144.43 ± 0.26 144.57 ± 0.22 100θ * . . . . . . . . . 1.04110 ± 0.00031 1.04119 ± 0.00029 r drag [Mpc] . . . . . . 147.09 ± 0.26 147.57 ± 0.22 z eq . . . . . . . . . . . . 3402 ± 26 3387 ± 21 k eq [Mpc -1 ] . . . . . . 0.010384 ± 0.000081 0.010339 ± 0.000063 Ω K . . . . . . . . . . . -0.0096 ± 0.0061 0.0007 ± 0.0019 Σm ν [eV] . . . . . . . r 0.002 . . . . . . . . . . &lt; 0.101 &lt; 0.106</p>
        <p>2017); blue, WiggleZ</p>
        <p>(Blake et al. 2012)</p>
        <p>; olive, VIPERS</p>
        <p>(Pezzotta et al. 2017)</p>
        <p>; dark blue, FastSound</p>
        <p>(Okumura et al. 2016)</p>
        <p>; and orange, BOSS DR14 quasars</p>
        <p>Planck (http://www.esa.int/Planck) is a project of the European Space Agency (ESA) with instruments provided by two scientific consortia funded by ESA member states (in particular the lead countries France and Italy), with contributions from NASA (USA), and telescope reflectors provided by a collaboration between ESA and a scientific consortium led and funded by Denmark.</p>
        <p>http://pla.esac.esa.int</p>
        <p>Galactic and extragalactic foregrounds have been removed from the maps. Cosmological parameter constraints are mostly based on a likelihood analysis of the angular (cross-)power spectra of the frequency maps, which are analysed with a model of the foreground spectra whose parameters are treated as nuisance parameters, together with other parameters characterizing uncertainties of instrumental origin.</p>
        <p>The orientation is computed in the local tangent plane with respect to the local meridian, and then rotated so that the meridian would be vertical, i.e., the rods are shown in the plane of the page with the north pointing to the top of the page.</p>
        <p>Planck Collaboration: The cosmological legacy of Planck</p>
        <p>In Planck Collaboration I (2016), peak 4 did not have this feature removed before fitting, which explains the large discrepancy between our values here. Furthermore we find that the marginal detection of peak</p>
        <p>in Planck Collaboration I (2016) has become slightly poorer (even although in general the constraints have improved).</p>
        <p>The CMB literature and the galaxy lensing literature differ in the sign of α and of ψ. We follow the CMB convention here.</p>
        <p>A newer evaluation gives N eff = 3.045 (de Salas &amp; Pastor 2016). The difference is negligible for our purposes, so we keep the older number for consistency with previous results.</p>
        <p>The diffusion scale is the mean free path times the square root of the number of scatterings. Since photons travel at c, N scatter scales as c times the Hubble time divided by the mean free path, so N 1/2 scatter λ mfp is the geometric mean of the Hubble scale and λ mfp .</p>
        <p>http://lambda.gsfc.nasa.gov</p>
        <p>This is the direction predicted by the simplest models of inflation, which invoke a scalar field slowly rolling down an almost flat potential, with longer wavelength modes exiting the Hubble scale earlier.</p>
        <p>Specifically we define η slip through k 2 Φη slip Ψ = 12πGa 2 (ρ + p) σ, where σ is the anisotropic stress.</p>
        <p>Conventionally one defines f as the logarithmic growth rate of the density perturbation δ, that is, f = d ln δ/d ln a. Multiplying this by the normalization, σ 8 , converts it to a growth rate per ln a.</p>
        <p>Available at https://www.cfa.harvard.edu/ ˜dfabricant/ huchra/hubble.plot.dat.</p>
        <p>We have neglected the impact of massive neutrinos in this expression for simplicity, though they are properly included in our analyses.</p>
        <p>Modes that are smaller than the Hubble scale during radiation domination, k &gt; k eq , have their growth slowed because fluctuations in the dominant radiation component (which contribute the most to the potentials) are stabilized by pressure and oscillate, rather than growing in amplitude.</p>
        <p>Eisenstein &amp; Hu (1998) andMeiksin et al. (1999). For configuration space, seeEisenstein et al. (2007). A more recent review isWeinberg et al. (2013)</p>
        <p>In practice, the mass threshold detectable by Planck increases with redshift. The total SZ signal is not resolved by Planck at high z and it decreases with z due to the decreasing angular size of the object.</p>
        <p>Planck (http://www.esa.int/Planck) is a project of the European Space Agency (ESA) with instruments provided by two scientific consortia funded by ESA member states (in particular the lead countries:</p>
        <p>To be more specific, this neglects the residual x e from recombination, and includes singly ionized helium. In principle, τ is a massweighted quantity, whereas the porosity often used in reionization studies is a volume-weighted quantity. For a homogeneous Universe the distinction is irrelevant, but it could be important at z 6-10 when structure is well developed. Nevertheless, the distinction is not relevant for inferences based on low-CMB anisotropy.</p>
        <p>A report may be found at https://www.cosmos.esa.int/ web/planck/lessons-learned.</p>
        <p>A half-ring is the co-added data of either the first or second half of each stable pointing period; see Planck Collaboration II (2014) and Planck Collaboration VI (2014).</p>
        <p>Acknowledgements The development of Planck has been supported by: ESA; CNES and CNRS/INSU-IN2P3-INP (France); ASI, CNR, and INAF (Italy); NASA and DoE (USA); STFC and UKSA (UK); CSIC, MICINN, JA, and RES (Spain); Tekes, AoF, and CSC (Finland); DLR and MPG (Germany); CSA (Canada); DTU Space (Denmark); SER/SSO (Switzerland); RCN (Norway); SFI (Ireland); FCT/MCTES (Portugal); and PRACE (EU). A description of the Planck Collaboration and a list of its members, including the technical or scientific activities in which they have been involved, can be found at http://www.cosmos.esa.int/web/planck/ planck-collaboration. In addition, we thank Solène Chabanier and Nathalie Palanque-Delabrouille for computing the Ly α forest constraints we have used in Fig. 19 and Inigo Zubeldia for preparing Fig. 32. Planck Collaboration: The cosmological legacy of Planck INAF -OAS Bologna, Istituto Nazionale di Astrofisica -Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, Area della Ricerca del CNR, Via Gobetti 101, 40129, Bologna, Italy INAF -Osservatorio Astronomico di Padova, Vicolo dell'Osservatorio 5, Padova, Italy INAF -Osservatorio Astronomico di Trieste, Via G.B. Tiepolo 11, Trieste, Italy INAF, Istituto di Radioastronomia, Via Piero Gobetti 101, I-40129 Bologna, Italy INAF/IASF Milano, Via E. Bassini 15, Milano, Italy INFN -CNAF, viale Berti Pichat 6/2, 40127 Bologna, Italy INFN, Sezione di Bologna, viale Berti Pichat 6/2, 40127 Bologna, Italy INFN, Sezione di Ferrara, Via Saragat 1, 44122 Ferrara, Italy INFN, Sezione di Milano, Via Celoria 16, Milano, Italy INFN, Sezione di Roma 1, Università di Roma Sapienza, Piazzale Aldo Moro 2, 00185, Roma, Italy INFN, Sezione di Roma 2, Università di Roma Tor Vergata, Via della Ricerca Scientifica, 1, Roma, Italy IUCAA, Post Bag 4, Ganeshkhind, Pune University Campus, Pune 411 007, India Imperial College London, Astrophysics group, Blackett Laboratory, Prince Consort Road, London, SW7 2AZ, U.K. Infrared Processing and Analysis Center, California Institute of Technology, Pasadena, CA 91125, U.S.A. Institut d'Astrophysique Spatiale, CNRS, Univ. Paris-Sud, Université Paris-Saclay, Bât. 121, 91405 Orsay cedex, France Institut d'Astrophysique de Paris, CNRS (UMR7095), 98 bis Boulevard Arago, F-75014, Paris, France Institut für Theoretische Teilchenphysik und Kosmologie, RWTH Aachen University, D-52056 Aachen, Germany Institute Lorentz, Leiden University, PO Box 9506, Leiden 2300 RA, The Netherlands Institute of Astronomy, University of Cambridge, Madingley Road, Cambridge CB3 0HA, U.K. Institute of Theoretical Astrophysics, University of Oslo, Blindern, Oslo, Norway Instituto de Astrofísica de Canarias, C/Vía Láctea s/n, La Laguna, Tenerife, Spain Instituto de Astrofísica e Ciências do Espac ¸o, Faculdade de Ciências da Universidade de Lisboa, Campo Grande, PT1749-016 Lisboa, Portugal Instituto de Física de Cantabria (CSIC-Universidad de Cantabria), Avda. de los Castros s/n, Santander, Spain Istituto Nazionale di Fisica Nucleare, Sezione di Padova, via Marzolo 8, I-35131 Padova, Italy Jet Propulsion Laboratory, California Institute of Technology, 4800</p>
        <p>A.1. Papers in the 2018 release The characteristics, processing, and analysis of the Planck data, as well as a number of scientific results, are described in a series of papers released with the data. The titles of the papers begin with "Planck 2018 results.", followed by the specific titles given in Table A.1.</p>
        <p>While this is the last release of the Planck Collaboration, that does not mean we have reached the point at which no significant improvements would be possible. Time was simply up. In particular we believe that the frequency maps can be improved, further reducing systematic effect residuals, which would in turn permit the production of improved component maps, likelihoods, and their scientific implications.</p>
        <p>Overview and the cosmological legacy of Planck (this paper) II.</p>
        <p>Low Frequency Instrument data processing III.</p>
        <p>High Frequency Instrument data processing IV.</p>
        <p>Diffuse component separation V.</p>
        <p>Power spectra and likelihoods VI.</p>
        <p>Cosmological parameters VII.</p>
        <p>Isotropy and statistics of the CMB VIII.</p>
        <p>Gravitational lensing IX.</p>
        <p>Constraints on primordial non-Gaussianity X.</p>
        <p>Constraints on inflation XI.</p>
        <p>Polarized dust foregrounds XII.</p>
        <p>Galactic astrophysics using polarized dust emission</p>
        <p>The 2018 distribution of released products, freely accessible via the PLA interface, contains the following items.</p>
        <p>-A reduced instrument model (RIMO), containing the effective beam window functions for temperature and polarization detector assemblies for both auto-and cross-spectra.</p>
        <p>The RIMO also contains beam error eigenmodes and their covariance matrices. -Cleaned and calibrated data time-lines for each LFI detector.</p>
        <p>-Cleaned and calibrated HEALpix data rings for each HFI detector.</p>
        <p>-Maps of the sky at nine frequencies in temperature and seven frequencies in polarization. Additional products serve to quantify the characteristics of the maps to a level adequate for the science results being presented, including noise maps, masks, and instrument characteristics, as well as bandpassleakage-correction maps and gain templates for LFI, and simulated CO bias maps for HFI. -Effective beams for LFI and HFI.</p>
        <p>-High-resolution maps of the CMB sky, in temperature and polarization, from a variety of different componentseparation approaches, including an SZ-free CMB map from SMICA, and CMB maps at several frequencies from SEVEM. -A low-resolution CMB map used in the low-likelihood, with an associated set of foreground maps (in polarization) and characterization of products. -Filtered maps of polarized fluctuations in thermal dust and synchrotron emission, and thermal dust temperatures in temperature and polarization. -A map of the estimated lensing potential and several types of lensing components (SZ, CIB, and B modes). -A map of the SZ effect, i.e.,the Compton y parameter.</p>
        <p>-A suite of simulations, including noise and the CMB only, the fiducial sky and processed noise, and the CMB run through the four component-separation pipelines. -A likelihood code and data package used for testing cosmological models against the Planck data. -Markov chain Monte Carlo samples used in determining the cosmological parameters from Planck data.</p>
        <p>All of these are linked to the Planck Explanatory Supplement (Planck Collaboration ES 2018). The current data release does not include single-bolometer maps, which limits our ability to robustly perform foreground separation; thus our temperature foreground results do not supersede the corresponding 2015 products.</p>
        <p>The 2018 release uses the same raw, full-mission data as the 2015 release, but with improved data processing and analysis procedures. Here we describe the major refinements in the processing, and discuss where further improvements may still be made.</p>
        <p>The most important change to the LFI pipeline for the 2018 data release concerns the calibration approach. For the 2015 release, the main calibration source for LFI was the Planck orbital dipole convolved with a model of the 4π beam response, properly weighted according to the bandpass of each single radiometer (see Planck Collaboration V 2016 for details).</p>
        <p>The 2018 calibration procedure (see Planck Collaboration II 2018) includes Galactic emission along with the CMB dipole in the calibration model. Indeed a detailed analysis of the 2015 data demonstrated that the Galactic contribution could be important, especially near dipole minima. The new approach is iterative and involves all of the calibration, mapmaking, and componentseparation steps. Schematically: Inter-frequency null tests of CMB T E and EE power spectra. Each sub-panel shows the differences between two foreground-cleaned cross-spectra at different frequencies (horizontal minus vertical). We show the full spectra comparisons here, even though the likelihood discards some of these data (according to the multipole range). The two lines in each panel correspond to the 2015 data and nuisance model (purple) and the 2018 one (orange); for each case, foreground and nuisance cleaning is performed at the spectrum level, as is done for the likelihood, using the best-fit nuisance parameters from the baseline fit for each release.</p>
        <p>The PTE values quoted in each sub-panel correspond to the 2018 data (and nuisance model) for the full range presented in the plot and with ∆ = 100 flat binning. There is impressive improvement in the 2015-to-2018 agreement in the inter-frequency spectra, in particular in T E, due in large part to the beam-leakage corrections.</p>
    </text>
</tei>
