<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-14T14:28+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>This paper provides a concise description of the free energy principle, starting from a formulation of random dynamical systems in terms of a Langevin equation and ending with a Bayesian mechanics that can be read as a physics of sentience. It rehearses the key steps using standard results from statistical physics. These steps entail (i) establishing a particular partition of states based upon conditional independencies that inherit from sparsely coupled dynamics, (ii) unpacking the implications of this partition in terms of Bayesian inference and (iii) describing the paths of particular states with a variational principle of least action. Teleologically, the free energy principle offers a normative account of self-organisation in terms of optimal Bayesian design and decision-making, in the sense of maximising marginal likelihood or Bayesian model evidence. In summary, starting from a description of the world in terms of random dynamical systems, we end up with a description of self-organisation as sentient behaviour that can be interpreted as self-evidencing; namely, self-assembly, autopoiesis or active inference.This paper provides a concise description of the free energy principle, starting from a formulation of random dynamical systems in terms of a Langevin equation and ending with a Bayesian mechanics that can be read as a physics of sentience. It rehearses the key steps using standard results from statistical physics. These steps entail (i) establishing a particular partition of states based upon conditional independencies that inherit from sparsely coupled dynamics, (ii) unpacking the implications of this partition in terms of Bayesian inference and (iii) describing the paths of particular states with a variational principle of least action. Teleologically, the free energy principle offers a normative account of self-organisation in terms of optimal Bayesian design and decision-making, in the sense of maximising marginal likelihood or Bayesian model evidence. In summary, starting from a description of the world in terms of random dynamical systems, we end up with a description of self-organisation as sentient behaviour that can be interpreted as self-evidencing; namely, self-assembly, autopoiesis or active inference.</p>
        <p>It is said that the free energy principle is difficult to understand. This is ironic on three counts. First, the free energy principle (FEP) is so simple that it is (almost) tautological. Indeed, philosophical accounts compare its explanandum to a desert landscape, in the sense of Quine [1]. Second, a tenet of the FEP is that everything must provide an accurate account of things that is as simple as possible-including itself. Finally, the FEP rests on straightforward results from statistical physics. This review tries to present the free energy principle as simply as possible but without sacrificing too much technical detail. It steps through the formal arguments that lead from a description of the world as a random dynamical system [2,3] to a description of self-organisation in terms of active inference and self-evidencing [4]. The evidence in question is Bayesian model evidence, which speaks to the Bayesian mechanics on offer [5]. These mechanics have the same starting point as quantum, statistical and classical mechanics. The only difference is that careful attention is paid to the way that the internal states of something couple to its external states.It is said that the free energy principle is difficult to understand. This is ironic on three counts. First, the free energy principle (FEP) is so simple that it is (almost) tautological. Indeed, philosophical accounts compare its explanandum to a desert landscape, in the sense of Quine [1]. Second, a tenet of the FEP is that everything must provide an accurate account of things that is as simple as possible-including itself. Finally, the FEP rests on straightforward results from statistical physics. This review tries to present the free energy principle as simply as possible but without sacrificing too much technical detail. It steps through the formal arguments that lead from a description of the world as a random dynamical system [2,3] to a description of self-organisation in terms of active inference and self-evidencing [4]. The evidence in question is Bayesian model evidence, which speaks to the Bayesian mechanics on offer [5]. These mechanics have the same starting point as quantum, statistical and classical mechanics. The only difference is that careful attention is paid to the way that the internal states of something couple to its external states.</p>
        <p>To make the following account accessible, we use a conversational style, explaining the meaning of key mathematical expressions intuitively. Accordingly, simplifying notation and assumptions are used to foreground the basic ideas. Before starting, it might help to clarify what the free energy principle is-and why it is useful. Many theories in the biological sciences are answers to the question: ''what must things do, in order to exist?'' The FEP turns this question on its head and asks: ''if things exist, what must they do?'' More formally, if we can define what it means to be something, can we identify the physics or dynamics that a thing must possess? To answer this question, the FEP calls on some mathematical truisms that follow from each other. Much like Hamilton's principle of least action, 1 it is not a falsifiable theory about the way 'things' behave-it is a general description of 'things' that are defined in a particular way. As such, the FEP is not falsifiable as a mathematical statement, but its postulates may be falsifiable to the extent that they refer to a specific class of empirical phenomena that the principle aims to describe.To make the following account accessible, we use a conversational style, explaining the meaning of key mathematical expressions intuitively. Accordingly, simplifying notation and assumptions are used to foreground the basic ideas. Before starting, it might help to clarify what the free energy principle is-and why it is useful. Many theories in the biological sciences are answers to the question: ''what must things do, in order to exist?'' The FEP turns this question on its head and asks: ''if things exist, what must they do?'' More formally, if we can define what it means to be something, can we identify the physics or dynamics that a thing must possess? To answer this question, the FEP calls on some mathematical truisms that follow from each other. Much like Hamilton's principle of least action, 1 it is not a falsifiable theory about the way 'things' behave-it is a general description of 'things' that are defined in a particular way. As such, the FEP is not falsifiable as a mathematical statement, but its postulates may be falsifiable to the extent that they refer to a specific class of empirical phenomena that the principle aims to describe.</p>
        <p>Is such a description useful? In itself, the answer is probably no-in the sense that the principle of least action does not tell you how to throw a ball. However, the principle of least action furnishes everything we need to know to simulate the trajectory of a ball in a particular instance. In the same sense, the FEP allows one to simulate and predict the sentient behaviour of a particle, person, artefact or agent (i.e., some 'thing'). This allows one to build sentient artefacts or use simulations as observation models of particles (or people). These simulations rest upon specifying a generative model that is apt to describe the behaviour of the particle (or person) at hand. At this point, committing to a specific generative model can be taken as a commitment to a specific-and falsifiable-theory. Later, we will see some examples of these simulations.Is such a description useful? In itself, the answer is probably no-in the sense that the principle of least action does not tell you how to throw a ball. However, the principle of least action furnishes everything we need to know to simulate the trajectory of a ball in a particular instance. In the same sense, the FEP allows one to simulate and predict the sentient behaviour of a particle, person, artefact or agent (i.e., some 'thing'). This allows one to build sentient artefacts or use simulations as observation models of particles (or people). These simulations rest upon specifying a generative model that is apt to describe the behaviour of the particle (or person) at hand. At this point, committing to a specific generative model can be taken as a commitment to a specific-and falsifiable-theory. Later, we will see some examples of these simulations.</p>
        <p>The remaining sections describe the FEP. Each section focuses on an equation-or set of equations-used in subsequent sections. The ensuing narrative is meant to be concise, taking us from the beginning to the end as succinctly as possible. To avoid disrupting the narrative, we use footnotes to address questions that are commonly asked at each step. We also use figure legends to supplement the narrative with examples from neurobiology. Most of the following can be found in the literature [5,7,8]; however, there are a few simplifications that replace earlier accounts.The remaining sections describe the FEP. Each section focuses on an equation-or set of equations-used in subsequent sections. The ensuing narrative is meant to be concise, taking us from the beginning to the end as succinctly as possible. To avoid disrupting the narrative, we use footnotes to address questions that are commonly asked at each step. We also use figure legends to supplement the narrative with examples from neurobiology. Most of the following can be found in the literature [5,7,8]; however, there are a few simplifications that replace earlier accounts.</p>
        <p>We start by describing the world with a stochastic differential equation [9]. So why start here? The principal reason is that we want a description that is consistent with physics. This follows because things like the Schrödinger equation in quantum mechanics, fluctuation theorems in statistical mechanics and the Lagrangian formulation of classical mechanics can all be derived from this starting point [10]. In short, if one wants a physics of sentience, this is the place to start.We start by describing the world with a stochastic differential equation [9]. So why start here? The principal reason is that we want a description that is consistent with physics. This follows because things like the Schrödinger equation in quantum mechanics, fluctuation theorems in statistical mechanics and the Lagrangian formulation of classical mechanics can all be derived from this starting point [10]. In short, if one wants a physics of sentience, this is the place to start.</p>
        <p>We are interested in systems that have characteristic states. Technically, this means the system has a pullback attractor; namely, a set of states a system will come to occupy from any initial state [2,11]. Such systems can be described with stochastic differential equations, such as the Langevin equation describing the rate of change of some states x(τ ), in terms of their flow f (x), and random fluctuations ω(τ ). The fluctuations are usually assumed to be a normally distributed (white noise) process, with a covariance of 2Γ :We are interested in systems that have characteristic states. Technically, this means the system has a pullback attractor; namely, a set of states a system will come to occupy from any initial state [2,11]. Such systems can be described with stochastic differential equations, such as the Langevin equation describing the rate of change of some states x(τ ), in terms of their flow f (x), and random fluctuations ω(τ ). The fluctuations are usually assumed to be a normally distributed (white noise) process, with a covariance of 2Γ :</p>
        <p>The dot notation denotes a derivative with respect to time. 2 This means that time and causality are baked into everything that follows, in the sense that states cause their motion. The Langevin equation is itself an approximation to a simpler mapping from some variables to changes in those variables with time. This follows from the separation into states and random fluctuations implicit in (1), where states change slowly in relation to fast fluctuations. This (adiabatic) approximation is ubiquitous in physics [13][14][15]. In brief, it means we can ignore temporal correlations in the fast fluctuations and assume-by the central limit theorem-that they have a Gaussian distribution. This equips the fluctuations with a probability density, which means we know their statistical behaviour but not their trajectory or path, which itself is a random variable [2,3,9]. The next step, shared by all physics, is to ask whether anything can be said about the probability density over the states-the '?' in (1). A lot can be said about this probability density, which can be expressed in two complementary ways; namely, as density dynamics using the Fokker-Planck equation (a.k.a. the forward Kolmogorov equation) or in terms of the probability of a path through state-space using the path-integral formulation. The Fokker-Planck equation describes the change in the density due to random fluctuations and the flow of states through state-space [9,16]:The dot notation denotes a derivative with respect to time. 2 This means that time and causality are baked into everything that follows, in the sense that states cause their motion. The Langevin equation is itself an approximation to a simpler mapping from some variables to changes in those variables with time. This follows from the separation into states and random fluctuations implicit in (1), where states change slowly in relation to fast fluctuations. This (adiabatic) approximation is ubiquitous in physics [13][14][15]. In brief, it means we can ignore temporal correlations in the fast fluctuations and assume-by the central limit theorem-that they have a Gaussian distribution. This equips the fluctuations with a probability density, which means we know their statistical behaviour but not their trajectory or path, which itself is a random variable [2,3,9]. The next step, shared by all physics, is to ask whether anything can be said about the probability density over the states-the '?' in (1). A lot can be said about this probability density, which can be expressed in two complementary ways; namely, as density dynamics using the Fokker-Planck equation (a.k.a. the forward Kolmogorov equation) or in terms of the probability of a path through state-space using the path-integral formulation. The Fokker-Planck equation describes the change in the density due to random fluctuations and the flow of states through state-space [9,16]:</p>
        <p>The Fokker-Planck equation describes our stochastic process in terms of deterministic density dynamics-instead of specific realisations-where the density in question is over states x(τ ) = x τ . Conversely, the path-integral formulation considers the probability of a trajectory or path x[τ ] ≜ [x(t) : 0 ≤ t ≤ τ ] in terms of its action A (omitting additive constants here and throughout) 3 :The Fokker-Planck equation describes our stochastic process in terms of deterministic density dynamics-instead of specific realisations-where the density in question is over states x(τ ) = x τ . Conversely, the path-integral formulation considers the probability of a trajectory or path x[τ ] ≜ [x(t) : 0 ≤ t ≤ τ ] in terms of its action A (omitting additive constants here and throughout) 3 :</p>
        <p>Both the Fokker-Planck and path-integral formulations inherit their functional form from assumptions about the statistics of random fluctuations in (1). For example, the most likely path-or path of least action-is the path taken when the fluctuations take their most likely value of zero. This means that variations away from this path always increase the action. This is expressed mathematically by saying that its variation is zero when the action is minimised. 4 x[τ ] = arg minBoth the Fokker-Planck and path-integral formulations inherit their functional form from assumptions about the statistics of random fluctuations in (1). For example, the most likely path-or path of least action-is the path taken when the fluctuations take their most likely value of zero. This means that variations away from this path always increase the action. This is expressed mathematically by saying that its variation is zero when the action is minimised. 4 x[τ ] = arg min</p>
        <p>In short, the motion on the path of least action is just the flow without random fluctuations. Paths of least action will figure prominently below; especially, when considering systems that behave in a precise or predictable way. We will denote the most likely states and paths with a bold typeface.In short, the motion on the path of least action is just the flow without random fluctuations. Paths of least action will figure prominently below; especially, when considering systems that behave in a precise or predictable way. We will denote the most likely states and paths with a bold typeface.</p>
        <p>Although equivalent, the Fokker-Planck and path-integral formalisms provide complementary perspectives on dynamics. The former deals with time-dependent probability densities over states, while the latter considers time-independent densities over paths. The density over n states at any particular time is the time-marginal of the density over trajectories. These probabilities can be conveniently quantified in terms of their negative logarithms (or potentials) leading to surprisal 2 Question: why is the flow in (1) not a function of time? Many treatments of stochastic thermodynamics allow for time-dependent flows when coupling one system (e.g., an idealised gas) to another (e.g., a heat reservoir), where it is assumed that the other system changes very slowly, e.g., [10,12]. However, the ambition of the FEP is to describe this coupling under a partition of states. In this setting, separation of temporal scales is an emergent property, where (1) holds at any given temporal scale. See [5] for a treatment using the apparatus of the renormalisation group.Although equivalent, the Fokker-Planck and path-integral formalisms provide complementary perspectives on dynamics. The former deals with time-dependent probability densities over states, while the latter considers time-independent densities over paths. The density over n states at any particular time is the time-marginal of the density over trajectories. These probabilities can be conveniently quantified in terms of their negative logarithms (or potentials) leading to surprisal 2 Question: why is the flow in (1) not a function of time? Many treatments of stochastic thermodynamics allow for time-dependent flows when coupling one system (e.g., an idealised gas) to another (e.g., a heat reservoir), where it is assumed that the other system changes very slowly, e.g., [10,12]. However, the ambition of the FEP is to describe this coupling under a partition of states. In this setting, separation of temporal scales is an emergent property, where (1) holds at any given temporal scale. See [5] for a treatment using the apparatus of the renormalisation group.</p>
        <p>3 Question: where does the divergence in the third equality come from? This term arises from the implicit use of Stratonovich path integrals [10].3 Question: where does the divergence in the third equality come from? This term arises from the implicit use of Stratonovich path integrals [10].</p>
        <p>Note that we have assumed that the amplitude of random fluctuations is state-and therefore path-independent in (1), which means we can place it outside the integral in the second equality. 4 Omitting the contribution of the divergence term in the Lagrangian to obtain the expression for the path of least action for simplicity, cf. [17].Note that we have assumed that the amplitude of random fluctuations is state-and therefore path-independent in (1), which means we can place it outside the integral in the second equality. 4 Omitting the contribution of the divergence term in the Lagrangian to obtain the expression for the path of least action for simplicity, cf. [17].</p>
        <p>Taking this simplification at face value means that we are either: 1) considering a description on a short time-scale as the flow can be approximated by a linear function with impunity (e.g., linear response theory, see [9]); or 2) we are considering the limit where random fluctuations have vanishingly small amplitude (e.g., precise particles, see Sections 7 and 8).Taking this simplification at face value means that we are either: 1) considering a description on a short time-scale as the flow can be approximated by a linear function with impunity (e.g., linear response theory, see [9]); or 2) we are considering the limit where random fluctuations have vanishingly small amplitude (e.g., precise particles, see Sections 7 and 8).</p>
        <p>and action, respectively (omitting the divergence of the flow in the last line for simplicity):and action, respectively (omitting the divergence of the flow in the last line for simplicity):</p>
        <p>(5)(5)</p>
        <p>The second set of equalities shows that the uncertainty (or entropy) about states and their paths is the expected surprisal and action, respectively. Perhaps counterintuitively, the entropy of paths is easier to specify than the entropy of states. This follows because the only source of uncertainty about paths-given an initial state-are the random fluctuations [9,10], whose probability density does not change with time. The last pair of equalities in (5) show that the amplitude of random fluctuations determines the entropy of paths. Intuitively, if the fluctuations are large, then many distinct paths become equally plausible, and the entropy of paths increases. 5The second set of equalities shows that the uncertainty (or entropy) about states and their paths is the expected surprisal and action, respectively. Perhaps counterintuitively, the entropy of paths is easier to specify than the entropy of states. This follows because the only source of uncertainty about paths-given an initial state-are the random fluctuations [9,10], whose probability density does not change with time. The last pair of equalities in (5) show that the amplitude of random fluctuations determines the entropy of paths. Intuitively, if the fluctuations are large, then many distinct paths become equally plausible, and the entropy of paths increases. 5</p>
        <p>So far, we have equations that describe the relationship between the dynamics of a system and probability densities over fluctuations, states and their paths. This is sufficient to elaborate most physics. For example, we can use the Fokker-Planck or path-integral formalism to derive quantum mechanics, where the Fokker-Planck equation becomes the Schrödinger wave equation [18]. We could focus on systems that comprise statistical ensembles of similar states to derive stochastic and statistical mechanics in terms of fluctuation theorems [10]. Finally, we could consider large systems-in which the fluctuations are averaged away-to derive classical mechanics such as electromagnetism and-with a suitable choice of potential functions-general relativity [19,20]. All of these mechanics require some boundary conditions: for example, a Schrödinger potential in quantum mechanics, a heat bath or reservoir in statistical mechanics and a classical potential for Lagrangian mechanics. At this point, the FEP steps back and asks, where do these boundary conditions come from? Indeed, this was implicit in Schrodinger's question:So far, we have equations that describe the relationship between the dynamics of a system and probability densities over fluctuations, states and their paths. This is sufficient to elaborate most physics. For example, we can use the Fokker-Planck or path-integral formalism to derive quantum mechanics, where the Fokker-Planck equation becomes the Schrödinger wave equation [18]. We could focus on systems that comprise statistical ensembles of similar states to derive stochastic and statistical mechanics in terms of fluctuation theorems [10]. Finally, we could consider large systems-in which the fluctuations are averaged away-to derive classical mechanics such as electromagnetism and-with a suitable choice of potential functions-general relativity [19,20]. All of these mechanics require some boundary conditions: for example, a Schrödinger potential in quantum mechanics, a heat bath or reservoir in statistical mechanics and a classical potential for Lagrangian mechanics. At this point, the FEP steps back and asks, where do these boundary conditions come from? Indeed, this was implicit in Schrodinger's question:</p>
        <p>''How can the events in space and time which take place within the spatial boundary of a living organism be accounted for by physics and chemistry?'' [21].''How can the events in space and time which take place within the spatial boundary of a living organism be accounted for by physics and chemistry?'' [21].</p>
        <p>We read a boundary in a statistical sense as a Markov boundary [22]. 6 Why? Because the only thing we have at hand is a probabilistic description of the system. And the only way to separate the states of something from its boundary states is in terms of probabilistic independencies-in this instance, conditional independencies. 7 This means we need to identify a partition of states that assigns a subset to a 'thing' or particle and another subset to the boundary that separates the thing from some 'thing' else. In short, one has to define 'thingness' in terms of conditional independencies.We read a boundary in a statistical sense as a Markov boundary [22]. 6 Why? Because the only thing we have at hand is a probabilistic description of the system. And the only way to separate the states of something from its boundary states is in terms of probabilistic independencies-in this instance, conditional independencies. 7 This means we need to identify a partition of states that assigns a subset to a 'thing' or particle and another subset to the boundary that separates the thing from some 'thing' else. In short, one has to define 'thingness' in terms of conditional independencies.</p>
        <p>However, if things are defined in terms of conditional independencies and conditional independencies are attributes of a probability density, where does the density come from? The Fokker-Planck equation shows that the density over states depends upon time, even if the flow does not. This means that if we predicate 'thingness' on a probability density, it may only exist for a vanishingly small amount of time. This simple observation compels us to consider probability densities that do not change with time, namely: (i) steady-state solutions to the Fokker-Planck equation or (ii) the density over paths. We will start with the (slightly more delicate) treatment of steady-state solutions and then show that the (slightly more straightforward) treatment of densities over paths leads to the same notion of 'thingness'.However, if things are defined in terms of conditional independencies and conditional independencies are attributes of a probability density, where does the density come from? The Fokker-Planck equation shows that the density over states depends upon time, even if the flow does not. This means that if we predicate 'thingness' on a probability density, it may only exist for a vanishingly small amount of time. This simple observation compels us to consider probability densities that do not change with time, namely: (i) steady-state solutions to the Fokker-Planck equation or (ii) the density over paths. We will start with the (slightly more delicate) treatment of steady-state solutions and then show that the (slightly more straightforward) treatment of densities over paths leads to the same notion of 'thingness'.</p>
        <p>The existence of things over a particular timescale implies the density in (2) does not change over that timescale. This is what is meant by a steady-state solution to the Fokker-Planck equation. The ensuing density is known as a steady-state density and, in random dynamical systems, implies the existence of a pullback attractor [2,3]. The notion of an attractor is helpful here, in the sense that it comprises a set of characteristic states, to which the system is attracted over time. 8 In short, to talk about 'things', we are implicitly talking about a partition of states in a random dynamical system that has an attracting set-i.e., a steady-state solution to the Fokker-Planck equation. In short, we consider systems that self-organise towards a steady-state density. 9 This solution is also known as a nonequilibrium steady-state (NESS) density, where the 'nonequilibrium' aspect rests upon solenoidal flow, as we will see next.The existence of things over a particular timescale implies the density in (2) does not change over that timescale. This is what is meant by a steady-state solution to the Fokker-Planck equation. The ensuing density is known as a steady-state density and, in random dynamical systems, implies the existence of a pullback attractor [2,3]. The notion of an attractor is helpful here, in the sense that it comprises a set of characteristic states, to which the system is attracted over time. 8 In short, to talk about 'things', we are implicitly talking about a partition of states in a random dynamical system that has an attracting set-i.e., a steady-state solution to the Fokker-Planck equation. In short, we consider systems that self-organise towards a steady-state density. 9 This solution is also known as a nonequilibrium steady-state (NESS) density, where the 'nonequilibrium' aspect rests upon solenoidal flow, as we will see next.</p>
        <p>5 From a thermodynamic perspective, uncertainty about paths increases with temperature. For example, the Einstein-Smoluchowski relation relates the amplitude of random fluctuations to a mobility coefficient times the temperature Γ = µ m k B T .5 From a thermodynamic perspective, uncertainty about paths increases with temperature. For example, the Einstein-Smoluchowski relation relates the amplitude of random fluctuations to a mobility coefficient times the temperature Γ = µ m k B T .</p>
        <p>6 A Markov boundary is a subset of states of the system that renders the states of a 'thing' or particle conditionally independent from all other states [23].6 A Markov boundary is a subset of states of the system that renders the states of a 'thing' or particle conditionally independent from all other states [23].</p>
        <p>7 Noting that if two subsets of states were independent, as opposed to being conditionally independent, we would be describing two separate systems. 8 More precisely, the time-dependent solutions to the Fokker-Planck equation will tend towards the stationary solution, or steady-state. In other words, the steady-state density becomes a point attractor in the space of probability densities. 9 At this point, the formalism applies equally to steady-states with a high or low entropy, as we have not committed to a particular form of the steady-state density. Later, we will specialise to steady-states with a low entropy to characterise the sort of self-organisation that describes biological systems, e.g., swarming or flocking [14,24].7 Noting that if two subsets of states were independent, as opposed to being conditionally independent, we would be describing two separate systems. 8 More precisely, the time-dependent solutions to the Fokker-Planck equation will tend towards the stationary solution, or steady-state. In other words, the steady-state density becomes a point attractor in the space of probability densities. 9 At this point, the formalism applies equally to steady-states with a high or low entropy, as we have not committed to a particular form of the steady-state density. Later, we will specialise to steady-states with a low entropy to characterise the sort of self-organisation that describes biological systems, e.g., swarming or flocking [14,24].</p>
        <p>The existence of a solution to the Fokker-Planck equation-i.e., the existence of something-means that we can express the flow of states in terms of the steady-state density (or corresponding surprisal) using a generalisation of the Helmholtz decomposition. This decomposes the flow into conservative (rotational, divergence-free) and dissipative (irrotational, curl-free) components-with respect to the steady-state density-referred to as solenoidal and gradient flows, respectively [9,[25][26][27][28][29][30]:The existence of a solution to the Fokker-Planck equation-i.e., the existence of something-means that we can express the flow of states in terms of the steady-state density (or corresponding surprisal) using a generalisation of the Helmholtz decomposition. This decomposes the flow into conservative (rotational, divergence-free) and dissipative (irrotational, curl-free) components-with respect to the steady-state density-referred to as solenoidal and gradient flows, respectively [9,[25][26][27][28][29][30]:</p>
        <p>This can be understood intuitively as a decomposition of the flow into two parts. The first (conservative) part of the flow is a solenoidal circulation on the isocontours of the steady-state density (or surprisal). This component breaks detailed balance and renders the steady-state density a nonequilibrium steady-state density [31,32]. The second (dissipative) part performs a (natural) gradient descent on the steady-state surprisal and depends upon the amplitude of random fluctuations [33,34]. The final term, Λ, can be regarded as a correction term, which is neither curl-free nor divergence-free, and which ensures that the probability density remains constant over time [30].This can be understood intuitively as a decomposition of the flow into two parts. The first (conservative) part of the flow is a solenoidal circulation on the isocontours of the steady-state density (or surprisal). This component breaks detailed balance and renders the steady-state density a nonequilibrium steady-state density [31,32]. The second (dissipative) part performs a (natural) gradient descent on the steady-state surprisal and depends upon the amplitude of random fluctuations [33,34]. The final term, Λ, can be regarded as a correction term, which is neither curl-free nor divergence-free, and which ensures that the probability density remains constant over time [30].</p>
        <p>We now have a probabilistic description of a system in terms of a (NESS) density that admits conditional independencies among states. These conditional independencies are necessary to separate the states of things from their boundaries. In the next step, we will see how conditional independencies inherit from sparse coupling among states-and how they are used to establish a particular partition of states.We now have a probabilistic description of a system in terms of a (NESS) density that admits conditional independencies among states. These conditional independencies are necessary to separate the states of things from their boundaries. In the next step, we will see how conditional independencies inherit from sparse coupling among states-and how they are used to establish a particular partition of states.</p>
        <p>In associating some (stochastic differential) equations of motion with a unique (NESS) density, we have a somewhat special setup, in which the influences entailed by the equations of motion place constraints on the conditional independencies of the NESS density: these conditional independencies can be used to identify a particular partition of states into external, sensory, active and internal states as summarised below. This is an important move because it separates the states of a particle (i.e., internal states and their sensory and active states) from the remaining (i.e., external) states. However, to do this we have to establish how the causal dynamics in (1) underwrite conditional independencies. This can be done simply by using the curvature (Hessian) of surprisal as follows:In associating some (stochastic differential) equations of motion with a unique (NESS) density, we have a somewhat special setup, in which the influences entailed by the equations of motion place constraints on the conditional independencies of the NESS density: these conditional independencies can be used to identify a particular partition of states into external, sensory, active and internal states as summarised below. This is an important move because it separates the states of a particle (i.e., internal states and their sensory and active states) from the remaining (i.e., external) states. However, to do this we have to establish how the causal dynamics in (1) underwrite conditional independencies. This can be done simply by using the curvature (Hessian) of surprisal as follows:</p>
        <p>This says that if the uth state is conditionally independent of the vth state, given the remaining states b, then the corresponding element of the curvature-or Hessian matrix-of surprisal must be zero. Conversely, a zero entry in the Hessian implies conditional independence. In sum, any two states are conditionally independent if, and only if, the change of surprisal with one state does not depend on the other. We can now use the Helmholtz decomposition (6) to express the Jacobian-i.e., the (linear) coupling-of the flow in terms of the Hessian-that entails conditional independencies (with a slight abuse of the dot product notation):This says that if the uth state is conditionally independent of the vth state, given the remaining states b, then the corresponding element of the curvature-or Hessian matrix-of surprisal must be zero. Conversely, a zero entry in the Hessian implies conditional independence. In sum, any two states are conditionally independent if, and only if, the change of surprisal with one state does not depend on the other. We can now use the Helmholtz decomposition (6) to express the Jacobian-i.e., the (linear) coupling-of the flow in terms of the Hessian-that entails conditional independencies (with a slight abuse of the dot product notation):</p>
        <p>We can now define sparse coupling as a solution to this equation, in which all the terms are identically zero 10 :We can now define sparse coupling as a solution to this equation, in which all the terms are identically zero 10 :</p>
        <p>Sparse coupling means that the Jacobian coupling states u and v is zero, i.e., an absence of coupling from one state to another. This definition precludes solenoidal coupling with u that depends on v. Because H(x) vv and Γ u are positive definite, sparse coupling requires associated elements of the solenoidal operator and Hessian to vanish at every point in state-space, which in turn, implies conditional independence:Sparse coupling means that the Jacobian coupling states u and v is zero, i.e., an absence of coupling from one state to another. This definition precludes solenoidal coupling with u that depends on v. Because H(x) vv and Γ u are positive definite, sparse coupling requires associated elements of the solenoidal operator and Hessian to vanish at every point in state-space, which in turn, implies conditional independence:</p>
        <p>In short, sparse coupling means that any two states are conditionally independent if one state does not influence the other. This is an important observation; namely, that sparse coupling implies a NESS density with conditional independencies. In turn, this means any dynamical influence graph with absent or directed edges admits a Markov blanket (the states b above). These independencies can now be used to build a particular partition as follows:In short, sparse coupling means that any two states are conditionally independent if one state does not influence the other. This is an important observation; namely, that sparse coupling implies a NESS density with conditional independencies. In turn, this means any dynamical influence graph with absent or directed edges admits a Markov blanket (the states b above). These independencies can now be used to build a particular partition as follows:</p>
        <p>• The Markov boundary a ⊂ x of a set of internal states µ ⊂ x is the minimal set of states for which there exists a nonzero Hessian submatrix: H aµ ̸ = 0. In other words, the internal states are independent of the remaining states, when conditioned upon their Markov boundary, called active states. The combination of active and internal states will be referred to as autonomous states: α = (a, µ). • The Markov boundary s ⊂ x of autonomous states is the minimal set of states for which there exists a nonzero Hessian submatrix: H sα ̸ = 0. In other words, the autonomous states are independent of the remaining states, when conditioned upon their Markov boundary, called sensory states. The combination of active and sensory (i.e., boundary)• The Markov boundary a ⊂ x of a set of internal states µ ⊂ x is the minimal set of states for which there exists a nonzero Hessian submatrix: H aµ ̸ = 0. In other words, the internal states are independent of the remaining states, when conditioned upon their Markov boundary, called active states. The combination of active and internal states will be referred to as autonomous states: α = (a, µ). • The Markov boundary s ⊂ x of autonomous states is the minimal set of states for which there exists a nonzero Hessian submatrix: H sα ̸ = 0. In other words, the autonomous states are independent of the remaining states, when conditioned upon their Markov boundary, called sensory states. The combination of active and sensory (i.e., boundary)</p>
        <p>states constitute blanket states: b = (s, a). The internal and blanket states will be referred to as particular states: π = (s, α) = (b, µ).states constitute blanket states: b = (s, a). The internal and blanket states will be referred to as particular states: π = (s, α) = (b, µ).</p>
        <p>• The remaining states constitute external states: x = (η, π).• The remaining states constitute external states: x = (η, π).</p>
        <p>The names of active and sensory (i.e., blanket) states inherit from the literature, where they are often associated with biotic systems that act on-and sense-their external milieu. 11 In this setting, one can regard external states as influencing internal states via sensory states (directly or through active states). And internal states influence external states via active states (directly or through sensory states 12 ). We will see later how this implies a synchronisation between internal and external states, in the sense that internal states can be seen as actively inferring external states [7,8]. The ensuing conditional independencies implied by a particular partition can be summarised as follows:The names of active and sensory (i.e., blanket) states inherit from the literature, where they are often associated with biotic systems that act on-and sense-their external milieu. 11 In this setting, one can regard external states as influencing internal states via sensory states (directly or through active states). And internal states influence external states via active states (directly or through sensory states 12 ). We will see later how this implies a synchronisation between internal and external states, in the sense that internal states can be seen as actively inferring external states [7,8]. The ensuing conditional independencies implied by a particular partition can be summarised as follows:</p>
        <p>A normal form for the flow and Jacobian of a particular partition-with sparse coupling-can be expressed as follows,A normal form for the flow and Jacobian of a particular partition-with sparse coupling-can be expressed as follows,</p>
        <p>where α = (a, µ) and β = (η, s):where α = (a, µ) and β = (η, s):</p>
        <p>This normal form means that particular partitions can be defined in terms of sparse coupling. Perhaps the simplest definition-that guarantees a Markov blanket. 13 -is as follows: external states only influence sensory states and internal states only influence active states This means that sensory states are not influenced by internal states and active states are 11 Question: why does a particular partition comprises four sets of states? In other words, why does a particular partition consider two Markov boundaries; namely, sensory and active states? The reason is that this is the minimal partition that allows for directed coupling with blanket states. For example, sensory states can influence internal states-and active states can influence external states-without destroying the conditional independencies of the particular partition (these directed influences are illustrated in the upper panel of Fig. 1 as dotted arrows). 12 Question: does this mean that I can act on my world through my sense organs? Yes: much of biotic action is mediated by (active) motile cytoskeletal filaments, muscles and secretory organs that lie beneath (sensory) epithelia, such as receptors on the skin or a cell surface. 13 In the absence of solenoidal coupling between autonomous and non-autonomous states, and constraints on the partial derivatives of the solenoidal coupling in (12); i.e., solenoidal coupling among autonomous states does not depend upon external states. Similarly, for non-autonomous and internal states.This normal form means that particular partitions can be defined in terms of sparse coupling. Perhaps the simplest definition-that guarantees a Markov blanket. 13 -is as follows: external states only influence sensory states and internal states only influence active states This means that sensory states are not influenced by internal states and active states are 11 Question: why does a particular partition comprises four sets of states? In other words, why does a particular partition consider two Markov boundaries; namely, sensory and active states? The reason is that this is the minimal partition that allows for directed coupling with blanket states. For example, sensory states can influence internal states-and active states can influence external states-without destroying the conditional independencies of the particular partition (these directed influences are illustrated in the upper panel of Fig. 1 as dotted arrows). 12 Question: does this mean that I can act on my world through my sense organs? Yes: much of biotic action is mediated by (active) motile cytoskeletal filaments, muscles and secretory organs that lie beneath (sensory) epithelia, such as receptors on the skin or a cell surface. 13 In the absence of solenoidal coupling between autonomous and non-autonomous states, and constraints on the partial derivatives of the solenoidal coupling in (12); i.e., solenoidal coupling among autonomous states does not depend upon external states. Similarly, for non-autonomous and internal states.</p>
        <p>not influenced by external states,not influenced by external states,</p>
        <p>and the noise processes ω i (τ ), i ∈ {η, s, a, µ} are independent. Under this sparse coupling, it is simple to show that not only are internal and external states conditionally independent, but their paths are conditionally independent, given initial states, using the path integral formulation.and the noise processes ω i (τ ), i ∈ {η, s, a, µ} are independent. Under this sparse coupling, it is simple to show that not only are internal and external states conditionally independent, but their paths are conditionally independent, given initial states, using the path integral formulation.</p>
        <p>The uncertainty (i.e., entropy) over paths derives from random fluctuations. This means that if we knew all the influences on the flow at every point in time, we can evaluate the entropy of external and internal paths from (5):The uncertainty (i.e., entropy) over paths derives from random fluctuations. This means that if we knew all the influences on the flow at every point in time, we can evaluate the entropy of external and internal paths from (5):</p>
        <p>The final equalities say that the uncertainty about external (resp., internal) paths does not change when we know the internal (resp., external) path because external (resp., internal) states do not influence internal (resp., external) flow. This means the external and internal paths do not share any mutual information and are therefore independent when conditioned on blanket paths (and initial states). From (11), the initial external and internal states are themselves independent, when conditioned on blanket states.The final equalities say that the uncertainty about external (resp., internal) paths does not change when we know the internal (resp., external) path because external (resp., internal) states do not influence internal (resp., external) flow. This means the external and internal paths do not share any mutual information and are therefore independent when conditioned on blanket paths (and initial states). From (11), the initial external and internal states are themselves independent, when conditioned on blanket states.</p>
        <p>Note that the conditional independence of paths inherits directly from the sparse coupling, without any reference to the NESS density or Helmholtz decomposition. This can be seen clearly by replacing the partial derivatives in (7) with functional derivatives and noting, from (12), that there are no flows that depend on both internal and external states:Note that the conditional independence of paths inherits directly from the sparse coupling, without any reference to the NESS density or Helmholtz decomposition. This can be seen clearly by replacing the partial derivatives in (7) with functional derivatives and noting, from (12), that there are no flows that depend on both internal and external states:</p>
        <p>These expressions mean that the probability of an internal path, given a blanket path (and initial states), does not depend on the external path and vice versa.These expressions mean that the probability of an internal path, given a blanket path (and initial states), does not depend on the external path and vice versa.</p>
        <p>In summary, the internal dynamics (i.e., paths) of some 'thing' are conditionally independent of external paths if, and only if, the flow of internal states does not depend on external states and vice versa (given initial states). We take this as a necessary and sufficient condition for something to exist, in the sense that it can be distinguished from everything else. When the initial states are sampled from the NESS density, the internal states are conditionally independent of external states (given blanket states), under certain constraints on solenoidal flow. Fig. 1 illustrates the ensuing particular partition. Note that the edges in this graph represent the influence of one state on another, as opposed to conditional dependencies. This is important because directed influences admit conditional independence. These conditional independencies are manifest as zero entries in the Hessian matrices, which inherit from the sparse, directed coupling of the dynamics.In summary, the internal dynamics (i.e., paths) of some 'thing' are conditionally independent of external paths if, and only if, the flow of internal states does not depend on external states and vice versa (given initial states). We take this as a necessary and sufficient condition for something to exist, in the sense that it can be distinguished from everything else. When the initial states are sampled from the NESS density, the internal states are conditionally independent of external states (given blanket states), under certain constraints on solenoidal flow. Fig. 1 illustrates the ensuing particular partition. Note that the edges in this graph represent the influence of one state on another, as opposed to conditional dependencies. This is important because directed influences admit conditional independence. These conditional independencies are manifest as zero entries in the Hessian matrices, which inherit from the sparse, directed coupling of the dynamics.</p>
        <p>Equipped with a particular partition, we can now talk about things in terms of their internal states and Markov boundary; namely autonomous states. And we can talk about autonomous states and their Markov boundary; namely, particular states-the states of a particle. The next step is to characterise the flow of the autonomous states (of a particle, plant or person) in relation to external states. In other words, we consider the nature of the coupling between the outside and inside of a particle, across its Markov blanket. It is at this point that we move towards a (Bayesian) mechanics that is the special provenance of systems with particular partitions. The existence of a particular partition means that-given sensory states-one can stipulatively define the conditional density over external states as being parameterised by the most likely internal state [7]. 14 We will call this a variational density parameterised by the internal mode µ(τ ) 15 :Equipped with a particular partition, we can now talk about things in terms of their internal states and Markov boundary; namely autonomous states. And we can talk about autonomous states and their Markov boundary; namely, particular states-the states of a particle. The next step is to characterise the flow of the autonomous states (of a particle, plant or person) in relation to external states. In other words, we consider the nature of the coupling between the outside and inside of a particle, across its Markov blanket. It is at this point that we move towards a (Bayesian) mechanics that is the special provenance of systems with particular partitions. The existence of a particular partition means that-given sensory states-one can stipulatively define the conditional density over external states as being parameterised by the most likely internal state [7]. 14 We will call this a variational density parameterised by the internal mode µ(τ ) 15 :</p>
        <p>As with the paths of least action, we will use bold typeface to denote a mode or most likely state, given all the states necessary to specify its likelihood. For autonomous states, we only need the sensory states, because the autonomous states are conditionally independent of external states.As with the paths of least action, we will use bold typeface to denote a mode or most likely state, given all the states necessary to specify its likelihood. For autonomous states, we only need the sensory states, because the autonomous states are conditionally independent of external states.</p>
        <p>Inducing the variational density is an important move. It means that for every sensory state there is a corresponding active mode and an internal mode (or an autonomous mode in the joint space of active and internal states). The active a(τ ), internal µ(τ ) and autonomous α(τ ) modes evolve on active, internal and autonomous manifolds, 16 respectively, whose dimensionality is the same as the sensory states. 17 We will see later that these manifolds play the role of centre manifolds; namely, manifolds on which dynamics do not diverge (or converge) exponentially fast [13].Inducing the variational density is an important move. It means that for every sensory state there is a corresponding active mode and an internal mode (or an autonomous mode in the joint space of active and internal states). The active a(τ ), internal µ(τ ) and autonomous α(τ ) modes evolve on active, internal and autonomous manifolds, 16 respectively, whose dimensionality is the same as the sensory states. 17 We will see later that these manifolds play the role of centre manifolds; namely, manifolds on which dynamics do not diverge (or converge) exponentially fast [13].</p>
        <p>Crucially, the internal manifold is also a statistical manifold because its states are sufficient statistics for the variational density. In turn, this means that it is equipped with a metric and implicit information geometry [39][40][41]. Indeed, the Fisher information metric tensor, which measures changes in the Kullback-Leibler (KL) divergence resulting from infinitesimal changes in the internal mode, is a Riemannian metric that yields an information distance [42,Appendix B]. This means we can interpret dynamics on the internal manifold as updating Bayesian beliefs about external states. This interpretation can be unpacked in terms of Bayesian inference as follows.Crucially, the internal manifold is also a statistical manifold because its states are sufficient statistics for the variational density. In turn, this means that it is equipped with a metric and implicit information geometry [39][40][41]. Indeed, the Fisher information metric tensor, which measures changes in the Kullback-Leibler (KL) divergence resulting from infinitesimal changes in the internal mode, is a Riemannian metric that yields an information distance [42,Appendix B]. This means we can interpret dynamics on the internal manifold as updating Bayesian beliefs about external states. This interpretation can be unpacked in terms of Bayesian inference as follows.</p>
        <p>Eq. ( 16) means that for every sensory state there is a conditional density over external states and a corresponding internal mode with the smallest surprisal. This mode specifies the variational density, where-by definition-the KL divergence between the variational density and the conditional density over external states is zero. 18 This means we 14 In other words, the internal mode supplies the sufficient statistics of the conditional density over external states.Eq. ( 16) means that for every sensory state there is a conditional density over external states and a corresponding internal mode with the smallest surprisal. This mode specifies the variational density, where-by definition-the KL divergence between the variational density and the conditional density over external states is zero. 18 This means we 14 In other words, the internal mode supplies the sufficient statistics of the conditional density over external states.</p>
        <p>15 Question: what if the conditional densities are not well-behaved, e.g., what if there are no unique modes? The answer is that well-behaved densities are generally guaranteed when increasing the dimensionality of state-spaces using generalised coordinates of motion [35][36][37]. In other words, instead of just dealing with states, we consider states and their generalised motion to arbitrarily high order. We will see examples of this later. 16 A manifold is a topological (state-) space where each state has a neighbourhood that is homeomorphic to a portion of an Euclidean space of the same dimension [38]. Intuitively, it is a curved space, such as a smooth surface, in a possibly large but finite number of dimensions. In this instance, the states are conditional modes. 17 The dimensionality of the active, internal and autonomous manifolds corresponds to the number of sensory states. This means that both the number of active and internal states must be greater than the number of sensory states. In turn, this limits the straightforward application of the free energy principle to particular partitions where the number of active states-and the number of internal states-exceeds the number of sensory states. In other words, the FEP applies to large particles with a nontrivial internal dynamics. 18 Since the variational and conditional densities over external states are equal, any divergence between them will vanish, see [43,Section 3.2].15 Question: what if the conditional densities are not well-behaved, e.g., what if there are no unique modes? The answer is that well-behaved densities are generally guaranteed when increasing the dimensionality of state-spaces using generalised coordinates of motion [35][36][37]. In other words, instead of just dealing with states, we consider states and their generalised motion to arbitrarily high order. We will see examples of this later. 16 A manifold is a topological (state-) space where each state has a neighbourhood that is homeomorphic to a portion of an Euclidean space of the same dimension [38]. Intuitively, it is a curved space, such as a smooth surface, in a possibly large but finite number of dimensions. In this instance, the states are conditional modes. 17 The dimensionality of the active, internal and autonomous manifolds corresponds to the number of sensory states. This means that both the number of active and internal states must be greater than the number of sensory states. In turn, this limits the straightforward application of the free energy principle to particular partitions where the number of active states-and the number of internal states-exceeds the number of sensory states. In other words, the FEP applies to large particles with a nontrivial internal dynamics. 18 Since the variational and conditional densities over external states are equal, any divergence between them will vanish, see [43,Section 3.2].</p>
        <p>can express the autonomous flow as a gradient flow on a free energy functional of the variational density. 19 From ( 12)can express the autonomous flow as a gradient flow on a free energy functional of the variational density. 19 From ( 12)</p>
        <p>where the free energy in question is (an upper bound on) the surprisal of particular states:where the free energy in question is (an upper bound on) the surprisal of particular states:</p>
        <p>This variational free energy 20 can be rearranged in several ways. First, it can be expressed as expected energy minus the entropy of the variational density, which licences the name free energy. 21 In this decomposition, minimising variational free energy corresponds to the maximum entropy principle, under the constraint that the expected energy is minimised [46,47]. The expected energy is a functional of the NESS density that plays the role of a generative model; namely, a joint distribution over causes (external states) and their consequences (particular states). 22 Second, variational free energy can be decomposed into the (negative) log likelihood of particular states (i.e., negative accuracy) and the KL divergence between posterior and prior densities (i.e., complexity). Finally, it can be written as the selfinformation associated with particular states (i.e., surprisal) plus the KL divergence between the variational and conditional (i.e., posterior) density, which-by construction-is zero. In variational Bayesian inference [48], negative surprisal is read as a log marginal likelihood or model evidence, having marginalised over external states. In this setting, negative free energy is an evidence lower bound or ELBO [44,49].This variational free energy 20 can be rearranged in several ways. First, it can be expressed as expected energy minus the entropy of the variational density, which licences the name free energy. 21 In this decomposition, minimising variational free energy corresponds to the maximum entropy principle, under the constraint that the expected energy is minimised [46,47]. The expected energy is a functional of the NESS density that plays the role of a generative model; namely, a joint distribution over causes (external states) and their consequences (particular states). 22 Second, variational free energy can be decomposed into the (negative) log likelihood of particular states (i.e., negative accuracy) and the KL divergence between posterior and prior densities (i.e., complexity). Finally, it can be written as the selfinformation associated with particular states (i.e., surprisal) plus the KL divergence between the variational and conditional (i.e., posterior) density, which-by construction-is zero. In variational Bayesian inference [48], negative surprisal is read as a log marginal likelihood or model evidence, having marginalised over external states. In this setting, negative free energy is an evidence lower bound or ELBO [44,49].</p>
        <p>So, in what sense can we interpret (17) in terms of inference? Let us start by considering the response of autonomous states to some sensory perturbation: that is, the path of autonomous states conditioned upon sensory states. If sensory states change slowly, then the autonomous states will flow towards their most likely value (i.e., their conditional mode) and stay there. 23 However, if sensory states are changing, the autonomous states will look as if they are trying to hit a moving target. One can formulate this along the lines of the centre manifold theorem [13,50], where we have a (fast) flow off the centre manifold and a (slow) flow of the autonomous mode on the manifold.So, in what sense can we interpret (17) in terms of inference? Let us start by considering the response of autonomous states to some sensory perturbation: that is, the path of autonomous states conditioned upon sensory states. If sensory states change slowly, then the autonomous states will flow towards their most likely value (i.e., their conditional mode) and stay there. 23 However, if sensory states are changing, the autonomous states will look as if they are trying to hit a moving target. One can formulate this along the lines of the centre manifold theorem [13,50], where we have a (fast) flow off the centre manifold and a (slow) flow of the autonomous mode on the manifold.</p>
        <p>19 A functional is a function of a function, here, the free energy is a function of a conditional density parameterised by the internal mode.19 A functional is a function of a function, here, the free energy is a function of a conditional density parameterised by the internal mode.</p>
        <p>20 Question: why is this functional called variational free energy? More generally (for instance in engineering applications where the free energy in question is also called an evidence lower bound [44]) the free energy is a functional of an approximate posterior density q that is an approximation to the Bayesian posterior, as follows:20 Question: why is this functional called variational free energy? More generally (for instance in engineering applications where the free energy in question is also called an evidence lower bound [44]) the free energy is a functional of an approximate posterior density q that is an approximation to the Bayesian posterior, as follows:</p>
        <p>The variational density considered in this article is the minimiser of (19), and the free energy evaluated at the variational density is the variational free energy. The term 'variational' inherits from the use of the calculus of variations in variational Bayes (a.k.a., approximate Bayesian inference), applied in the context of a mean field approximation or factorised form of the variational density. The term 'free energy' inherits from Richard Feynman's path integral formulation, in the setting of quantum electrodynamics. 21 Question: is variational free energy the same kind of free energy found in statistical mechanics? The answer is no: the entropy term in the variational free energy is the entropy of a variational density-over external states-parameterised by internal states. This entropy is distinct from the entropy of internal states. Minimising variational free energy increases the entropy of the variational density and, usually, reduces the entropy of internal states (see [45] for an example). Mathematically, we can express the different kind of entropies as H[q(η(τThe variational density considered in this article is the minimiser of (19), and the free energy evaluated at the variational density is the variational free energy. The term 'variational' inherits from the use of the calculus of variations in variational Bayes (a.k.a., approximate Bayesian inference), applied in the context of a mean field approximation or factorised form of the variational density. The term 'free energy' inherits from Richard Feynman's path integral formulation, in the setting of quantum electrodynamics. 21 Question: is variational free energy the same kind of free energy found in statistical mechanics? The answer is no: the entropy term in the variational free energy is the entropy of a variational density-over external states-parameterised by internal states. This entropy is distinct from the entropy of internal states. Minimising variational free energy increases the entropy of the variational density and, usually, reduces the entropy of internal states (see [45] for an example). Mathematically, we can express the different kind of entropies as H[q(η(τ</p>
        <p>22 Question: in practical applications, variational free energy is usually a function of data or observed (sensory) states. So, why is variational free energy a function of particular states? Later, we will see that practical applications correspond to Bayesian filtering, under the assumption that particular dynamics are very precise. This means that there is no uncertainty about autonomous paths given sensory paths, and the action of a particular path is the action of a sensory path. In generalised coordinates of motion-used in Bayesian filtering-the action of a path becomes the surprisal of a state. In this setting, the variational free energy of particular states is the same as the variational free energy of sensory states.22 Question: in practical applications, variational free energy is usually a function of data or observed (sensory) states. So, why is variational free energy a function of particular states? Later, we will see that practical applications correspond to Bayesian filtering, under the assumption that particular dynamics are very precise. This means that there is no uncertainty about autonomous paths given sensory paths, and the action of a particular path is the action of a sensory path. In generalised coordinates of motion-used in Bayesian filtering-the action of a path becomes the surprisal of a state. In this setting, the variational free energy of particular states is the same as the variational free energy of sensory states.</p>
        <p>23 Or, at least in the vicinity, if there are random fluctuations on its motion.23 Or, at least in the vicinity, if there are random fluctuations on its motion.</p>
        <p>In effect, this is a decomposition in a frame of reference that moves with the autonomous mode, whose path lies on the centre manifold. We further describe the off manifold flow using a Taylor expansion around the (time-varying) autonomous mode24In effect, this is a decomposition in a frame of reference that moves with the autonomous mode, whose path lies on the centre manifold. We further describe the off manifold flow using a Taylor expansion around the (time-varying) autonomous mode24</p>
        <p>Flow parallel to the manifoldFlow parallel to the manifold</p>
        <p>This means that the flow at the expansion point is zero, leaving the second term of the expansion as the first non-vanishing term. This is the Jacobian of the autonomous flow times the displacement of the current autonomous state from its corresponding mode. The second-order derivatives of the free energy arise from the Jacobian of the flow, i.e., substituting (17) into (8). Therefore, the off manifold flow has a component that flows towards the centre manifold, 25afforded by the gradient flow, and a component that is parallel to the manifold, afforded by the solenoidal flow, cf. (6). Taken together, this means that the autonomous states flow in ever-decreasing circles towards the centre manifold, as illustrated in Fig. 2.This means that the flow at the expansion point is zero, leaving the second term of the expansion as the first non-vanishing term. This is the Jacobian of the autonomous flow times the displacement of the current autonomous state from its corresponding mode. The second-order derivatives of the free energy arise from the Jacobian of the flow, i.e., substituting (17) into (8). Therefore, the off manifold flow has a component that flows towards the centre manifold, 25afforded by the gradient flow, and a component that is parallel to the manifold, afforded by the solenoidal flow, cf. (6). Taken together, this means that the autonomous states flow in ever-decreasing circles towards the centre manifold, as illustrated in Fig. 2.</p>
        <p>But what about the flow on the centre manifold? We know from ( 17) that the flow of the autonomous mode can be expressed in terms of free energy gradients:But what about the flow on the centre manifold? We know from ( 17) that the flow of the autonomous mode can be expressed in terms of free energy gradients:</p>
        <p>This expression unpacks the centre manifold flow in terms of the accuracy and complexity parts of free energy, where the accuracy part depends upon the sensory states, while the complexity part is a function of, and only of, autonomous states. In short, the flow on the centre manifold will look as if it is trying to maximise the accuracy of its predictions, while complying with prior (Bayesian) beliefs. 26 Here, predictions are read as the expected sensory states, under posterior (Bayesian) beliefs about their causes afforded by the variational density over external states.This expression unpacks the centre manifold flow in terms of the accuracy and complexity parts of free energy, where the accuracy part depends upon the sensory states, while the complexity part is a function of, and only of, autonomous states. In short, the flow on the centre manifold will look as if it is trying to maximise the accuracy of its predictions, while complying with prior (Bayesian) beliefs. 26 Here, predictions are read as the expected sensory states, under posterior (Bayesian) beliefs about their causes afforded by the variational density over external states.</p>
        <p>In summary, a particular partition of a nonequilibrium steady-state density implies that autonomous dynamics can be interpreted as performing a particular kind of inference. This entails a fast flow towards an autonomous centre manifold and a slow flow on the centre manifold. The centre manifold flow can be interpreted as Bayesian belief updating, where posterior (Bayesian) beliefs are encoded by points on an internal (statistical) manifold. In other words, for every point on the statistical manifold, there is a corresponding variational density or Bayesian belief over external states. We are now in a position to express this belief updating as a variational principle of least action:In summary, a particular partition of a nonequilibrium steady-state density implies that autonomous dynamics can be interpreted as performing a particular kind of inference. This entails a fast flow towards an autonomous centre manifold and a slow flow on the centre manifold. The centre manifold flow can be interpreted as Bayesian belief updating, where posterior (Bayesian) beliefs are encoded by points on an internal (statistical) manifold. In other words, for every point on the statistical manifold, there is a corresponding variational density or Bayesian belief over external states. We are now in a position to express this belief updating as a variational principle of least action:</p>
        <p>This is a basis of the free energy principle. Put simply, it means that the internal states of a particular partition can be cast as encoding conditional or posterior Bayesian beliefs about external states. Equivalently, the autonomous path of least action can be expressed as a gradient flow on a variational free energy that can be read as log evidence. This licences a somewhat poetic description of self-organisation as self-evidencing [4], in the sense that the surprisal or self-information is known as log model evidence or marginal likelihood in Bayesian statistics. 27 Interestingly, because of the symmetric setup of the Markov blanket, it would be possible to repeat everything above but switch the labels of internal and external states-and active and sensory states-and tell the same story about external states tracking internal states. This evinces a form of generalised synchrony [7,[53][54][55], where internal and external states track each other. Technically, if we consider the (internal and external) manifolds in the joint space of internal and external states, we have something called a synchronisation manifold that offers another perspective on the coupling between the inside and outside [7,39,56].This is a basis of the free energy principle. Put simply, it means that the internal states of a particular partition can be cast as encoding conditional or posterior Bayesian beliefs about external states. Equivalently, the autonomous path of least action can be expressed as a gradient flow on a variational free energy that can be read as log evidence. This licences a somewhat poetic description of self-organisation as self-evidencing [4], in the sense that the surprisal or self-information is known as log model evidence or marginal likelihood in Bayesian statistics. 27 Interestingly, because of the symmetric setup of the Markov blanket, it would be possible to repeat everything above but switch the labels of internal and external states-and active and sensory states-and tell the same story about external states tracking internal states. This evinces a form of generalised synchrony [7,[53][54][55], where internal and external states track each other. Technically, if we consider the (internal and external) manifolds in the joint space of internal and external states, we have something called a synchronisation manifold that offers another perspective on the coupling between the inside and outside [7,39,56].</p>
        <p>These teleological interpretations cast particular paths of least action as an optimisation process, where different readings of free energy link nicely to various normative (i.e., optimisation) theories of sentient behaviour. Some cardinal examples are summarised in Fig. 3; see [5,[57][58][59] for some formal accounts of these relationships. Because internal states do not influence sensory (or external) states, they will look as if they are concerned purely with inference, in the sense that they parameterise the variational density over external states. However, active states influence sensory (and external) states and will look as if they play an active role in configuring (and causing) the sensory states that underwrite inference. In the neurosciences, this is known as active inference [60][61][62].These teleological interpretations cast particular paths of least action as an optimisation process, where different readings of free energy link nicely to various normative (i.e., optimisation) theories of sentient behaviour. Some cardinal examples are summarised in Fig. 3; see [5,[57][58][59] for some formal accounts of these relationships. Because internal states do not influence sensory (or external) states, they will look as if they are concerned purely with inference, in the sense that they parameterise the variational density over external states. However, active states influence sensory (and external) states and will look as if they play an active role in configuring (and causing) the sensory states that underwrite inference. In the neurosciences, this is known as active inference [60][61][62].</p>
        <p>The link between optimisation and inference is simply that inference is belief optimisation. However, it is worth unpacking the gradients that 'drive' this optimisation. In statistics, variational free energy is used to score the divergence between a variational density and the conditional density over external (i.e., hidden) states, given blanket states [49]. Unlike the definition in (18), these densities are not assumed to be equivalent. Variational inference proceeds by optimising the variational density such that it minimises free energy-often using the gradient flows in (17). However, there is a subtle difference between the dynamics of ( 17) and variational inference. In the former, there is no contribution from the KL-divergence as it is stipulated to be zero. In the latter, it is only the divergence term that contributes to free energy gradients. So, is it tenable to interpret gradient flows on variational free energy as variational inference, or is this just teleological window-dressing? The next section addresses this question through the lens of Bayesian filtering. In brief, we will see that the autonomous paths of least action-implied by a particular partition-are the paths of least action of a Bayesian filter. This takes us beyond 'as if' arguments by establishing a formal connection between particular dynamics and variational inference.The link between optimisation and inference is simply that inference is belief optimisation. However, it is worth unpacking the gradients that 'drive' this optimisation. In statistics, variational free energy is used to score the divergence between a variational density and the conditional density over external (i.e., hidden) states, given blanket states [49]. Unlike the definition in (18), these densities are not assumed to be equivalent. Variational inference proceeds by optimising the variational density such that it minimises free energy-often using the gradient flows in (17). However, there is a subtle difference between the dynamics of ( 17) and variational inference. In the former, there is no contribution from the KL-divergence as it is stipulated to be zero. In the latter, it is only the divergence term that contributes to free energy gradients. So, is it tenable to interpret gradient flows on variational free energy as variational inference, or is this just teleological window-dressing? The next section addresses this question through the lens of Bayesian filtering. In brief, we will see that the autonomous paths of least action-implied by a particular partition-are the paths of least action of a Bayesian filter. This takes us beyond 'as if' arguments by establishing a formal connection between particular dynamics and variational inference.</p>
        <p>Now, say we wanted to emulate or simulate active inference. Given some equations of motion and statistics of random fluctuations, we could find the stationary solution to the Fokker Planck equation and accompanying Helmholtz decomposition. We could then solve (23) for the autonomous paths of least action that characterise the expected behaviour 27 Question: this Bayesian mechanics seems apt for inference but what about learning over time? We have been dealing with states in a generic sense. However, one can have states that change over different timescales. One can read slowly changing states as special states that play the role of parameters; either parameters of the flow or, implicitly, the generative model. In mathematical and numerical analyses, states and parameters are usually treated identically; i.e., as minimising variational free energy. Indeed, in practical applications of Bayesian filtering schemes that learn, the parameters are treated as slowly changing states. See [36,52] for worked examples. Fig. 3. Markov blankets and self-evidencing. This schematic illustrates various points of contact between minimising variational free energy and other normative theories of optimal behaviour. The existence of a Markov blanket entails a certain lack of influences among internal, blanket and external states. These have an important consequence-internal and active states are not influenced by external states, which means their dynamics (i.e., perception and action) are a function of, and only of, particular states, given by a variational (free energy) bound on surprisal. This has a number of interesting interpretations. Given surprisal is the negative log probability of finding a particle or creature in a particular state, minimising surprise corresponds to maximising the value of that state. This interpretation is licensed by the fact that the states with a high probability are, by definition, characteristic of the particle in question. On this view, one could relate this to dynamics in reinforcement learning [63], optimal control theory [64] and, in economics, expected utility theory [65,66]. Gradient flows that minimise surprisal (i.e., self-information) lead to a series of influential accounts of neuronal dynamics; including the principle of maximum mutual information [67,68], the principles of minimum redundancy and maximum efficiency [69] and the free energy principle [70]. Crucially, the average or expected surprise (over time of particular states) corresponds to entropy. This means that action and perception look as if they are bounding the entropy of particular states. This links nicely with theories of self-organisation, such as synergetics in physics [14,24,71] or homoeostasis in physiology [72][73][74]. Finally, the probability of a particular state, is, on a statistical view, model evidence or marginal likelihood [75,76], marginalising over the causes of particular states (i.e., external states). This means that all the above formulations are internally consistent with things like the Bayesian brain hypothesis, evidence accumulation and predictive coding [57,58,77]. Most of these formulations inherit from Helmholtz's motion of unconscious inference [78], later unpacked in terms of perception as hypothesis testing in psychology [79] and machine learning [80]. Although not depicted here, the minimisation of complexity-inherent in the minimisation of free energy-enables thermodynamic and metabolic efficiency via Landauer's principle [81]. of this kind of particle, and obtain realisations of synchronisation and inference. See [8] for a worked example using a system of coupled Lorentz attractors.Now, say we wanted to emulate or simulate active inference. Given some equations of motion and statistics of random fluctuations, we could find the stationary solution to the Fokker Planck equation and accompanying Helmholtz decomposition. We could then solve (23) for the autonomous paths of least action that characterise the expected behaviour 27 Question: this Bayesian mechanics seems apt for inference but what about learning over time? We have been dealing with states in a generic sense. However, one can have states that change over different timescales. One can read slowly changing states as special states that play the role of parameters; either parameters of the flow or, implicitly, the generative model. In mathematical and numerical analyses, states and parameters are usually treated identically; i.e., as minimising variational free energy. Indeed, in practical applications of Bayesian filtering schemes that learn, the parameters are treated as slowly changing states. See [36,52] for worked examples. Fig. 3. Markov blankets and self-evidencing. This schematic illustrates various points of contact between minimising variational free energy and other normative theories of optimal behaviour. The existence of a Markov blanket entails a certain lack of influences among internal, blanket and external states. These have an important consequence-internal and active states are not influenced by external states, which means their dynamics (i.e., perception and action) are a function of, and only of, particular states, given by a variational (free energy) bound on surprisal. This has a number of interesting interpretations. Given surprisal is the negative log probability of finding a particle or creature in a particular state, minimising surprise corresponds to maximising the value of that state. This interpretation is licensed by the fact that the states with a high probability are, by definition, characteristic of the particle in question. On this view, one could relate this to dynamics in reinforcement learning [63], optimal control theory [64] and, in economics, expected utility theory [65,66]. Gradient flows that minimise surprisal (i.e., self-information) lead to a series of influential accounts of neuronal dynamics; including the principle of maximum mutual information [67,68], the principles of minimum redundancy and maximum efficiency [69] and the free energy principle [70]. Crucially, the average or expected surprise (over time of particular states) corresponds to entropy. This means that action and perception look as if they are bounding the entropy of particular states. This links nicely with theories of self-organisation, such as synergetics in physics [14,24,71] or homoeostasis in physiology [72][73][74]. Finally, the probability of a particular state, is, on a statistical view, model evidence or marginal likelihood [75,76], marginalising over the causes of particular states (i.e., external states). This means that all the above formulations are internally consistent with things like the Bayesian brain hypothesis, evidence accumulation and predictive coding [57,58,77]. Most of these formulations inherit from Helmholtz's motion of unconscious inference [78], later unpacked in terms of perception as hypothesis testing in psychology [79] and machine learning [80]. Although not depicted here, the minimisation of complexity-inherent in the minimisation of free energy-enables thermodynamic and metabolic efficiency via Landauer's principle [81]. of this kind of particle, and obtain realisations of synchronisation and inference. See [8] for a worked example using a system of coupled Lorentz attractors.</p>
        <p>In this section, we take a somewhat pragmatic excursion to suggest a simpler way to recover the paths of least action; namely, as the solution to a generic (Bayesian) filtering scheme that is widely used in the engineering literature.In this section, we take a somewhat pragmatic excursion to suggest a simpler way to recover the paths of least action; namely, as the solution to a generic (Bayesian) filtering scheme that is widely used in the engineering literature.</p>
        <p>Let us go back to the Langevin equation governing our system ẋ(τ ) = f (x) + ω(τ ). (24) In this section, we assume that the random fluctuations driving the motion have smooth (analytic) sample paths; thus, the Langevin equation considered in the rest of the article can be seen as the limit of (24) as the fluctuations become rough [82]. This setup speaks nicely to the fact that, in biology, fluctuations are often smooth up to a certain ordercontrariwise to thermal (white noise) fluctuations-as they are the output of other random dynamical systems. As before, we assume that the fluctuations are state-independent, and a stationary Gaussian process, e.g., the smoothing of white noise fluctuations with a Gaussian kernel. Just like in the case of white noise, Gaussianity can be motivated by the central limit theorem-fluctuations should be normally distributed at each point in time.Let us go back to the Langevin equation governing our system ẋ(τ ) = f (x) + ω(τ ). (24) In this section, we assume that the random fluctuations driving the motion have smooth (analytic) sample paths; thus, the Langevin equation considered in the rest of the article can be seen as the limit of (24) as the fluctuations become rough [82]. This setup speaks nicely to the fact that, in biology, fluctuations are often smooth up to a certain ordercontrariwise to thermal (white noise) fluctuations-as they are the output of other random dynamical systems. As before, we assume that the fluctuations are state-independent, and a stationary Gaussian process, e.g., the smoothing of white noise fluctuations with a Gaussian kernel. Just like in the case of white noise, Gaussianity can be motivated by the central limit theorem-fluctuations should be normally distributed at each point in time.</p>
        <p>We denote the autocovariance of fluctuations byWe denote the autocovariance of fluctuations by</p>
        <p>The underlying dynamical systems giving rise to this generic type of smooth noise can be recovered through a procedure known as stochastic realisation [7,83,84].The underlying dynamical systems giving rise to this generic type of smooth noise can be recovered through a procedure known as stochastic realisation [7,83,84].</p>
        <p>The solution to the Langevin Eq. ( 24) can be approximated, on a suitably small interval of time, by a linear Langevin equation in generalised coordinates of motion ⃗ x = ( x, x ′ , x ′′ , . . . )The solution to the Langevin Eq. ( 24) can be approximated, on a suitably small interval of time, by a linear Langevin equation in generalised coordinates of motion ⃗ x = ( x, x ′ , x ′′ , . . . )</p>
        <p>[85, Section 4] 2829 :[85, Section 4] 2829 :</p>
        <p>Here, the different variables ⃗ x = ( x, x ′ , x ′′ , . . . , x (n) , . . . )Here, the different variables ⃗ x = ( x, x ′ , x ′′ , . . . , x (n) , . . . )</p>
        <p>can be seen as the position, velocity, acceleration, jerk, and higher orders of motion of the process, which are treated as separate (generalised) states that are coupled through the Jacobian J. These are driven by smooth fluctuations ⃗ ω (i.e., the serial derivatives of ω) whose covariance 2Γ can be expressed in terms of the serial derivatives of the autocovariance [88, Appendix A.5.3].can be seen as the position, velocity, acceleration, jerk, and higher orders of motion of the process, which are treated as separate (generalised) states that are coupled through the Jacobian J. These are driven by smooth fluctuations ⃗ ω (i.e., the serial derivatives of ω) whose covariance 2Γ can be expressed in terms of the serial derivatives of the autocovariance [88, Appendix A.5.3].</p>
        <p>The generalised states are the coefficients of a Taylor series expansion of the solution to the Langevin Eq. ( 24):The generalised states are the coefficients of a Taylor series expansion of the solution to the Langevin Eq. ( 24):</p>
        <p>where ( 26) holds, typically, only on a small time-interval to which we restrict ourselves henceforth. In other words, the generalised states at any time-point determine the system's trajectory, and vice versa; that is, there is an isomorphism between generalised states and paths. This line of reasoning has two advantages. First, it means one can relax white noise assumptions on the random fluctuations and deal with smooth or analytic fluctuations. Second, the linear expansion in generalised coordinates of motion (25) means that the distribution of generalised states has a simple Gaussian formwhere ( 26) holds, typically, only on a small time-interval to which we restrict ourselves henceforth. In other words, the generalised states at any time-point determine the system's trajectory, and vice versa; that is, there is an isomorphism between generalised states and paths. This line of reasoning has two advantages. First, it means one can relax white noise assumptions on the random fluctuations and deal with smooth or analytic fluctuations. Second, the linear expansion in generalised coordinates of motion (25) means that the distribution of generalised states has a simple Gaussian form</p>
        <p>Here, M can be read as a mass matrix. This suggests that precise particles, with low amplitude random fluctuations, behave like massive bodies. Furthermore, ( 27) is seen as the Lagrangian in generalised coordinates of motion, due to its formal similarity with (3). Under the isomorphism between points and paths in generalised coordinates, the Lagrangian is equivalent to the action; it scores the likelihood of paths of (24), as a path corresponds to a point in generalised coordinates of motion. 30 We will reason about the trajectories of the system by analysing the Lagrangian of generalised states henceforth. The path of least action corresponds to the minimiser of the Lagrangian, which can be expressed as follows:Here, M can be read as a mass matrix. This suggests that precise particles, with low amplitude random fluctuations, behave like massive bodies. Furthermore, ( 27) is seen as the Lagrangian in generalised coordinates of motion, due to its formal similarity with (3). Under the isomorphism between points and paths in generalised coordinates, the Lagrangian is equivalent to the action; it scores the likelihood of paths of (24), as a path corresponds to a point in generalised coordinates of motion. 30 We will reason about the trajectories of the system by analysing the Lagrangian of generalised states henceforth. The path of least action corresponds to the minimiser of the Lagrangian, which can be expressed as follows:</p>
        <p>We can recover the path of least action by solving the following equation of motionWe can recover the path of least action by solving the following equation of motion</p>
        <p>Indeed, this motion can be interpreted as a gradient descent on the Lagrangian, in a frame of reference that moves with the mode of the distribution of generalised states [36]. Thus, the convexity of the Lagrangian means that any solution to (29) converges to the path of least action. In this setting, the divergence-free flow (i.e., the first term) is known as a prediction of the generalised state based upon generalised motion, while the curl-free, gradient flow (i.e., the second term) is called an update. 28 The expansion ( 25) is a linear approximation of (24) [86], obtained by recursively differentiating (24) and ignoring the contribution of the derivatives of the flow of order higher than one. In other words, the expansion is exact when the flow is linear, and it is accurate on a short time-scale when the flow is non-linear. 29 The curvature (i.e., second derivative) of the autocovariance Γ ′′ 0 is a ubiquitous measure of roughness of a stochastic process [87]. Note that in the limit where the fluctuations ω are uncorrelated (e.g., white noise fluctuations), Γ ′′ 0 (and higher derivatives) become infinitely large. 30 Question: how can a point be a path? The generalised states (i.e., temporal derivatives) approximate the path of the solution to (24) on a suitably small time interval because they are the coefficients of a Taylor expansion of the path as a function of time (26).Indeed, this motion can be interpreted as a gradient descent on the Lagrangian, in a frame of reference that moves with the mode of the distribution of generalised states [36]. Thus, the convexity of the Lagrangian means that any solution to (29) converges to the path of least action. In this setting, the divergence-free flow (i.e., the first term) is known as a prediction of the generalised state based upon generalised motion, while the curl-free, gradient flow (i.e., the second term) is called an update. 28 The expansion ( 25) is a linear approximation of (24) [86], obtained by recursively differentiating (24) and ignoring the contribution of the derivatives of the flow of order higher than one. In other words, the expansion is exact when the flow is linear, and it is accurate on a short time-scale when the flow is non-linear. 29 The curvature (i.e., second derivative) of the autocovariance Γ ′′ 0 is a ubiquitous measure of roughness of a stochastic process [87]. Note that in the limit where the fluctuations ω are uncorrelated (e.g., white noise fluctuations), Γ ′′ 0 (and higher derivatives) become infinitely large. 30 Question: how can a point be a path? The generalised states (i.e., temporal derivatives) approximate the path of the solution to (24) on a suitably small time interval because they are the coefficients of a Taylor expansion of the path as a function of time (26).</p>
        <p>We now reintroduce the distinction between internal, external, sensory and active states x = (η, s, a, µ). Briefly, as before, we assume that the Langevin Eq. ( 24) is sparsely coupled as in (13). This implies that the trajectories internal and external to the particle are conditionally independent given the trajectories of the blanket (15). The same sparse coupling structure carries through the expansion in generalised coordinates (25) so that the motion of generalised states entails trajectories with the same conditional independencies. Since paths correspond to generalised states, this yields conditional independence between generalised states, as follows:We now reintroduce the distinction between internal, external, sensory and active states x = (η, s, a, µ). Briefly, as before, we assume that the Langevin Eq. ( 24) is sparsely coupled as in (13). This implies that the trajectories internal and external to the particle are conditionally independent given the trajectories of the blanket (15). The same sparse coupling structure carries through the expansion in generalised coordinates (25) so that the motion of generalised states entails trajectories with the same conditional independencies. Since paths correspond to generalised states, this yields conditional independence between generalised states, as follows:</p>
        <p>We can now recover paths of least action of the particle by equating the Lagrangian with the variational free energy of generalised states. This allows us to express the internal path of least action as a gradient flow on variational free energy, which can itself be expressed in terms of generalised prediction errors. From (29), we haveWe can now recover paths of least action of the particle by equating the Lagrangian with the variational free energy of generalised states. This allows us to express the internal path of least action as a gradient flow on variational free energy, which can itself be expressed in terms of generalised prediction errors. From (29), we have</p>
        <p>where the free energy of generalised states is analogous to ( 18)where the free energy of generalised states is analogous to ( 18)</p>
        <p>The variational free energy of generalised states is easy to evaluate, given a generative model in the form of a state-space model [36]; that is, the generalised flow of external and sensory states f ⃗ η , f ⃗ s , and the covariance of their generalised fluctuations Γ η , Γ s . Note that the parameterisation of the variational density is very simple: the internal states parameterise the expected external states. Furthermore, the quadratic form of the Lagrangian means that the variational density over the generalised motion of external states is Gaussian. 31 This licenses a ubiquitous assumption in variational Bayes called the Laplace assumption. Please see [89] for a discussion of the simplifications afforded by the Laplace assumption.The variational free energy of generalised states is easy to evaluate, given a generative model in the form of a state-space model [36]; that is, the generalised flow of external and sensory states f ⃗ η , f ⃗ s , and the covariance of their generalised fluctuations Γ η , Γ s . Note that the parameterisation of the variational density is very simple: the internal states parameterise the expected external states. Furthermore, the quadratic form of the Lagrangian means that the variational density over the generalised motion of external states is Gaussian. 31 This licenses a ubiquitous assumption in variational Bayes called the Laplace assumption. Please see [89] for a discussion of the simplifications afforded by the Laplace assumption.</p>
        <p>Crucially, in the absence of active states, the dynamic in (31) coincides with a generalised Bayesian filter. Generalised filtering is a generic Bayesian filtering scheme for nonlinear state-space models formulated in generalised coordinates of motion [36]; special cases include variational filtering [90], dynamic expectation maximisation [91], extended Kalman filtering [92], and generalised predictive coding.Crucially, in the absence of active states, the dynamic in (31) coincides with a generalised Bayesian filter. Generalised filtering is a generic Bayesian filtering scheme for nonlinear state-space models formulated in generalised coordinates of motion [36]; special cases include variational filtering [90], dynamic expectation maximisation [91], extended Kalman filtering [92], and generalised predictive coding.</p>
        <p>Furthermore, if the autonomous paths are conditionally independent from external paths, given sensory paths, 32 the autonomous paths of least action can be recovered from a generalised gradient descent on variational free energy:Furthermore, if the autonomous paths are conditionally independent from external paths, given sensory paths, 32 the autonomous paths of least action can be recovered from a generalised gradient descent on variational free energy:</p>
        <p>In this case, the most likely paths of both internal and active states can be recovered by a gradient descent on variational free energy, and one can simulate active inference using generalisations of linear quadratic control or model predictive control [93,94]:In this case, the most likely paths of both internal and active states can be recovered by a gradient descent on variational free energy, and one can simulate active inference using generalisations of linear quadratic control or model predictive control [93,94]:</p>
        <p>This is effectively a (generalised) version of the particular dynamics in (23).This is effectively a (generalised) version of the particular dynamics in (23).</p>
        <p>31 Question: why is the covariance of the variational density only a function of the internal mode? This follows from the quadratic Lagrangian that furnishes an analytic solution to the free energy minimum. Please see [89] for details. 32 This is the case for precise particles, which are defined by particular fluctuations of infinitesimally small amplitude-see next Section and [37].31 Question: why is the covariance of the variational density only a function of the internal mode? This follows from the quadratic Lagrangian that furnishes an analytic solution to the free energy minimum. Please see [89] for details. 32 This is the case for precise particles, which are defined by particular fluctuations of infinitesimally small amplitude-see next Section and [37].</p>
        <p>This section has taken a somewhat pragmatic excursion from the FEP narrative to consider generalised coordinates of motion. This excursion is important because it suggests that the gradient flows in systems with attracting sets are the paths of least action in Bayesian filters used to assimilate data in statistics [92] and, indeed, control theory [95].This section has taken a somewhat pragmatic excursion from the FEP narrative to consider generalised coordinates of motion. This excursion is important because it suggests that the gradient flows in systems with attracting sets are the paths of least action in Bayesian filters used to assimilate data in statistics [92] and, indeed, control theory [95].</p>
        <p>Working in generalised coordinates of motion is effectively working with paths and the path integral formulation. Practically, this is useful because one can use the density over paths directly to evaluate the requisite free energy gradients, as opposed to solving the Fokker-Planck equation to find the NESS density. Effectively, the generative model becomes a state-space model, specified with flows and the statistics of random fluctuations: see (32). These are the sufficient statistics of the joint density over external and sensory paths.Working in generalised coordinates of motion is effectively working with paths and the path integral formulation. Practically, this is useful because one can use the density over paths directly to evaluate the requisite free energy gradients, as opposed to solving the Fokker-Planck equation to find the NESS density. Effectively, the generative model becomes a state-space model, specified with flows and the statistics of random fluctuations: see (32). These are the sufficient statistics of the joint density over external and sensory paths.</p>
        <p>Hitherto, we have largely ignored random fluctuations in the motion of particular states to focus on the underlying flows. Are these flows ever realised or does the principle of least action in (23) only apply to the most likely autonomous paths? In what follows, we will consider a special class of systems, where we suppress particular fluctuations to recover the behaviour of particles that show a precise or predictable response to external states. For this kind of particle, the particular paths are always the paths of least action.Hitherto, we have largely ignored random fluctuations in the motion of particular states to focus on the underlying flows. Are these flows ever realised or does the principle of least action in (23) only apply to the most likely autonomous paths? In what follows, we will consider a special class of systems, where we suppress particular fluctuations to recover the behaviour of particles that show a precise or predictable response to external states. For this kind of particle, the particular paths are always the paths of least action.</p>
        <p>So far, we have a Bayesian mechanics that would be apt to describe a particle or person with a pullback attractor. But what is the difference between a particle and a person? This question speaks to distinct classes of things to which the free energy principle could apply; e.g., molecular versus biological. Here, we associate biotic self-organisation with the precise and predictable dynamics of large particles. Thanks to the Helmholtz decomposition ( 6), it is known that when random fluctuations are large, dissipative flow dominates conservative flow, and we have ensembles described by statistical mechanics (i.e., small particles). Conversely, when random fluctuations have a low amplitude, solenoidal flow 33 dominates and we have classical mechanics and deterministic chaos (i.e., of heavenly and n-body problems). Here, we consider the distinction between statistical and classical mechanics in the setting of a particular partition.So far, we have a Bayesian mechanics that would be apt to describe a particle or person with a pullback attractor. But what is the difference between a particle and a person? This question speaks to distinct classes of things to which the free energy principle could apply; e.g., molecular versus biological. Here, we associate biotic self-organisation with the precise and predictable dynamics of large particles. Thanks to the Helmholtz decomposition ( 6), it is known that when random fluctuations are large, dissipative flow dominates conservative flow, and we have ensembles described by statistical mechanics (i.e., small particles). Conversely, when random fluctuations have a low amplitude, solenoidal flow 33 dominates and we have classical mechanics and deterministic chaos (i.e., of heavenly and n-body problems). Here, we consider the distinction between statistical and classical mechanics in the setting of a particular partition.</p>
        <p>It is often said that the free energy principle explains why biological systems resist the second law and a natural tendency to dissipation and disorder [96]. However, this is disingenuous on two counts. First, the second law only applies to closed systems, while the free energy principle describes open systems in which internal states are exposed to-and exchange with-external states through blanket states. Second, there is nothing, so far, to suggest that the entropy of particular states or paths is small. Everything we have done would apply equally to particles with high and low entropy densities. So, what distinguishes between high and low entropy systems (e.g., between candle flames and concierges), respectively?It is often said that the free energy principle explains why biological systems resist the second law and a natural tendency to dissipation and disorder [96]. However, this is disingenuous on two counts. First, the second law only applies to closed systems, while the free energy principle describes open systems in which internal states are exposed to-and exchange with-external states through blanket states. Second, there is nothing, so far, to suggest that the entropy of particular states or paths is small. Everything we have done would apply equally to particles with high and low entropy densities. So, what distinguishes between high and low entropy systems (e.g., between candle flames and concierges), respectively?</p>
        <p>One answer can be found in the path-integral formulation: from (5), we can associate the entropy of a path (i.e., history or trajectory of particular states) with the amplitude of random fluctuations. This licences the notion of precise particles that are characterised by low or vanishing random fluctuations. 34 In essence, precise particles are simply 'things' that are subject to the classical laws of nature; i.e., Lagrangian mechanics. In the accompanying limit of small fluctuations on particular states, every autonomous trajectory is a path of least action. From ( 5) and (23) this can be expressed as follows:One answer can be found in the path-integral formulation: from (5), we can associate the entropy of a path (i.e., history or trajectory of particular states) with the amplitude of random fluctuations. This licences the notion of precise particles that are characterised by low or vanishing random fluctuations. 34 In essence, precise particles are simply 'things' that are subject to the classical laws of nature; i.e., Lagrangian mechanics. In the accompanying limit of small fluctuations on particular states, every autonomous trajectory is a path of least action. From ( 5) and (23) this can be expressed as follows:</p>
        <p>This suggests that precise particles-such as you and me-will respond to environmental flows and fluctuations in a precise and predictable fashion. Fig. 4 illustrates the difference between generic and precise particles using an information diagram. Note that for precise particles, there is no uncertainty about autonomous states, given sensory states. This follows because the flow of autonomous states depends only on sensory states and themselves. Is the behaviour of precise particles a sufficient description of sentient behaviour?This suggests that precise particles-such as you and me-will respond to environmental flows and fluctuations in a precise and predictable fashion. Fig. 4 illustrates the difference between generic and precise particles using an information diagram. Note that for precise particles, there is no uncertainty about autonomous states, given sensory states. This follows because the flow of autonomous states depends only on sensory states and themselves. Is the behaviour of precise particles a sufficient description of sentient behaviour?</p>
        <p>On one reading, perhaps: one can reproduce biological behaviour by numerically integrating (23) or (34) under a suitable generative (state-space) model specifying the motion of external and sensory states. 35 Fig. 5 illustrates the 33 And its accompanying correction term Λ, see (6).On one reading, perhaps: one can reproduce biological behaviour by numerically integrating (23) or (34) under a suitable generative (state-space) model specifying the motion of external and sensory states. 35 Fig. 5 illustrates the 33 And its accompanying correction term Λ, see (6).</p>
        <p>34 Question: but surely my neurons are noisy? There is a substantial literature that refers to neuronal and synaptic noise: e.g., [100]. However, the population dynamics of neuronal ensembles or assemblies are virtually noiseless by the central limit theorem (because they comprise thousands of neurons), when averaged over suitable spatial and temporal scales. For example, in electrophysiology, averaging several fluctuating single trial responses yields surprisingly stable and reproducible event-related potentials. From the perspective of the FEP, studying single neurons (or trials) is like studying single molecules to characterise fluid dynamics. 35 A generative model can be specified through the flow of external or sensory states, and the random fluctuations of their motion; that is, the first two lines of (34). Observing that the free energy ( 31) is only a function of these flows and the covariance of fluctuations, it is sufficient to specify those covariances, rather than the whole structure of the fluctuations. Fig. 4. Generic and precise particles. These information diagrams depict the entropy of external, sensory and autonomous paths, where intersections correspond to shared or mutual information. A conditional entropy corresponds to an area that is outside the variable upon which the entropy is conditioned. The diagram on the left shows the generic case, in which uncertainty about paths inherits from random fluctuations that determine the conditional entropies of paths. When the amplitude of random fluctuations on the motion of particular states is very small, we have precise particles in which there is no uncertainty about autonomous paths, given sensory paths (the right information diagram). Similarly, there is no uncertainty about sensory paths given external and autonomous paths. Note that because we are dealing with continuous states, we are implicitly interpreting the entropies as the limiting density of discrete points (LDDP), which have a lower bound of zero [46]. (LDDP is an adjustment to differential entropy which ensures that entropy is lower bounded by zero. LDDP equals the negative KL-divergence between the density in question and a uniform density). Two relative entropies (information gain and risk) are highlighted as areas of intersection. These will play an important role later, when decomposing the action (i.e., expected free energy) of autonomous paths. implicit computational architecture used to simulate sentient behaviour by integrating (23). This scheme allows one to simulate the internal and active states through sensory states caused by external dynamics. Fig. 6 showcases an example from the active inference literature, that integrates (34) under a suitably specified generative model, to simulate sentient behaviour that looks like handwriting. The details of the simulation and the details of the generative model are not relevant here but are summarised in the figure legend; what is important is to get a sense of the kind of behaviour that can be reproduced by integrating (34).34 Question: but surely my neurons are noisy? There is a substantial literature that refers to neuronal and synaptic noise: e.g., [100]. However, the population dynamics of neuronal ensembles or assemblies are virtually noiseless by the central limit theorem (because they comprise thousands of neurons), when averaged over suitable spatial and temporal scales. For example, in electrophysiology, averaging several fluctuating single trial responses yields surprisingly stable and reproducible event-related potentials. From the perspective of the FEP, studying single neurons (or trials) is like studying single molecules to characterise fluid dynamics. 35 A generative model can be specified through the flow of external or sensory states, and the random fluctuations of their motion; that is, the first two lines of (34). Observing that the free energy ( 31) is only a function of these flows and the covariance of fluctuations, it is sufficient to specify those covariances, rather than the whole structure of the fluctuations. Fig. 4. Generic and precise particles. These information diagrams depict the entropy of external, sensory and autonomous paths, where intersections correspond to shared or mutual information. A conditional entropy corresponds to an area that is outside the variable upon which the entropy is conditioned. The diagram on the left shows the generic case, in which uncertainty about paths inherits from random fluctuations that determine the conditional entropies of paths. When the amplitude of random fluctuations on the motion of particular states is very small, we have precise particles in which there is no uncertainty about autonomous paths, given sensory paths (the right information diagram). Similarly, there is no uncertainty about sensory paths given external and autonomous paths. Note that because we are dealing with continuous states, we are implicitly interpreting the entropies as the limiting density of discrete points (LDDP), which have a lower bound of zero [46]. (LDDP is an adjustment to differential entropy which ensures that entropy is lower bounded by zero. LDDP equals the negative KL-divergence between the density in question and a uniform density). Two relative entropies (information gain and risk) are highlighted as areas of intersection. These will play an important role later, when decomposing the action (i.e., expected free energy) of autonomous paths. implicit computational architecture used to simulate sentient behaviour by integrating (23). This scheme allows one to simulate the internal and active states through sensory states caused by external dynamics. Fig. 6 showcases an example from the active inference literature, that integrates (34) under a suitably specified generative model, to simulate sentient behaviour that looks like handwriting. The details of the simulation and the details of the generative model are not relevant here but are summarised in the figure legend; what is important is to get a sense of the kind of behaviour that can be reproduced by integrating (34).</p>
        <p>The example in Fig. 6 illustrates an application of the free energy principle. Here, instead of describing a system by deriving its NESS density, we have specified some equations of motion (and covariance of random fluctuations) to realise particular dynamics using (32) and (34). In effect, we have simulated self-evidencing, starting from a definition (i.e., state-space generative model) of paths that characterise this kind of particle. 36 These simulations speak to a key aspect in the applications of the FEP. Hitherto, we have simply defined the variational density as the conditional density over external states given a sensory state. However, when simulating precise particles through a gradient flow on variational free energy, as in (23) or (34), the requisite gradients have to be evaluated. In turn, this requires the functional form of the variational density or posterior distribution, which may be difficult to compute exactly. 37 In this case, we take a variational density that approximates the true posterior, whence the variational free energy becomes an upper bound on surprisal: see (19). From the perspective of Bayesian inference, this takes us from (computationally costly) exact Bayesian inference to (computationally cheap) approximate Bayesian inference [48,49,104]. On one reading of its inception, this is why variational free energy was introduced [105]; namely, to convert a computationally expensive marginalisation problem into a computationally manageable optimisation problem. Note that when using generalised coordinates to realise active inference; i.e., (34), we are generally employing approximate Bayesian inference: the functional form of the variational density inherits directly from Gaussian assumptions about random fluctuations, however the expansion in generalised coordinates on which it is based upon (29) is generally an approximation to the underlying dynamic (cf. 28). 36 The example in Eq. ( 6) used (34) with generalised coordinates of motion up to fourth order. Numerical analyses suggest that simulating generalised motion up to order six (i.e., ignoring all subsequent orders of motions) is sufficient in most circumstances [91]. 37 In Bayesian inference, it is well-known that computing the posterior distribution given data and a generative model p(η | π ) = p(η, π)/p(π ) is computationally costly as it involves computing a (typically) high-dimensional integral p(π ) = ∫ p(η, π)dη (i.e., a partition function). These are the paths taken by a precise particle or the paths of least action of a generic particle. It illustrates a simple form of (active) inference that has been used in a variety of applications and simulations; ranging from handwriting and action observation [97], through to birdsong and generalised synchrony in communication [56]. In brief, sensory states furnish free energy gradients (often expressed as prediction errors), under some generative model. Neuronal dynamics are simulated as a flow on the resulting gradients to produce internal states that parameterise posterior beliefs about external states. Similarly, active states are simulated as a flow on free energy gradients that generally play the role of prediction errors.The example in Fig. 6 illustrates an application of the free energy principle. Here, instead of describing a system by deriving its NESS density, we have specified some equations of motion (and covariance of random fluctuations) to realise particular dynamics using (32) and (34). In effect, we have simulated self-evidencing, starting from a definition (i.e., state-space generative model) of paths that characterise this kind of particle. 36 These simulations speak to a key aspect in the applications of the FEP. Hitherto, we have simply defined the variational density as the conditional density over external states given a sensory state. However, when simulating precise particles through a gradient flow on variational free energy, as in (23) or (34), the requisite gradients have to be evaluated. In turn, this requires the functional form of the variational density or posterior distribution, which may be difficult to compute exactly. 37 In this case, we take a variational density that approximates the true posterior, whence the variational free energy becomes an upper bound on surprisal: see (19). From the perspective of Bayesian inference, this takes us from (computationally costly) exact Bayesian inference to (computationally cheap) approximate Bayesian inference [48,49,104]. On one reading of its inception, this is why variational free energy was introduced [105]; namely, to convert a computationally expensive marginalisation problem into a computationally manageable optimisation problem. Note that when using generalised coordinates to realise active inference; i.e., (34), we are generally employing approximate Bayesian inference: the functional form of the variational density inherits directly from Gaussian assumptions about random fluctuations, however the expansion in generalised coordinates on which it is based upon (29) is generally an approximation to the underlying dynamic (cf. 28). 36 The example in Eq. ( 6) used (34) with generalised coordinates of motion up to fourth order. Numerical analyses suggest that simulating generalised motion up to order six (i.e., ignoring all subsequent orders of motions) is sufficient in most circumstances [91]. 37 In Bayesian inference, it is well-known that computing the posterior distribution given data and a generative model p(η | π ) = p(η, π)/p(π ) is computationally costly as it involves computing a (typically) high-dimensional integral p(π ) = ∫ p(η, π)dη (i.e., a partition function). These are the paths taken by a precise particle or the paths of least action of a generic particle. It illustrates a simple form of (active) inference that has been used in a variety of applications and simulations; ranging from handwriting and action observation [97], through to birdsong and generalised synchrony in communication [56]. In brief, sensory states furnish free energy gradients (often expressed as prediction errors), under some generative model. Neuronal dynamics are simulated as a flow on the resulting gradients to produce internal states that parameterise posterior beliefs about external states. Similarly, active states are simulated as a flow on free energy gradients that generally play the role of prediction errors.</p>
        <p>In other words, active states mediate motor or autonomic reflexes [98,99]. An example of this kind of active inference is provided in the next figure.In other words, active states mediate motor or autonomic reflexes [98,99]. An example of this kind of active inference is provided in the next figure.</p>
        <p>Precise particles, immersed in an imprecise world, respond (almost) deterministically to external fluctuations. 38 This means, given a generative model (i.e., NESS density), one can solve the equations of motion in (34) to predict how autonomous states evolve as they pursue their path of least action. So, why might this limiting behaviour be characteristically biological?Precise particles, immersed in an imprecise world, respond (almost) deterministically to external fluctuations. 38 This means, given a generative model (i.e., NESS density), one can solve the equations of motion in (34) to predict how autonomous states evolve as they pursue their path of least action. So, why might this limiting behaviour be characteristically biological?</p>
        <p>Precise particles may be the kind of particles that show lifelike or biotic behaviour, in the sense they respond predictably, given their initial states and the history of external influences. The distinction between imprecise (e.g., statistical) and precise (e.g., classical) particles rests on the relative contribution of dissipative and conservative flow to their path through state-space, where solenoidal flow predominates in the precise setting. This means precise particles exhibit solenoidal behaviour such as oscillatory and (quasi) periodic orbits-and an accompanying loss of detailed balance, i.e., turbulent and time-irreversible dynamics [30,106,107]. On this view, one might associate precise particles with living systems with characteristic biorhythms [108][109][110][111]; ranging from gamma oscillations in neuronal populations, through slower respiratory and diurnal cycles to, perhaps, lifecycles per se. Turning this on its head, one can argue that living systems are a certain kind of particle that, in virtue of being precise, evince conservative dynamics, biorhythms and time irreversibility.Precise particles may be the kind of particles that show lifelike or biotic behaviour, in the sense they respond predictably, given their initial states and the history of external influences. The distinction between imprecise (e.g., statistical) and precise (e.g., classical) particles rests on the relative contribution of dissipative and conservative flow to their path through state-space, where solenoidal flow predominates in the precise setting. This means precise particles exhibit solenoidal behaviour such as oscillatory and (quasi) periodic orbits-and an accompanying loss of detailed balance, i.e., turbulent and time-irreversible dynamics [30,106,107]. On this view, one might associate precise particles with living systems with characteristic biorhythms [108][109][110][111]; ranging from gamma oscillations in neuronal populations, through slower respiratory and diurnal cycles to, perhaps, lifecycles per se. Turning this on its head, one can argue that living systems are a certain kind of particle that, in virtue of being precise, evince conservative dynamics, biorhythms and time irreversibility.</p>
        <p>One might ask if solenoidal flow confounds the gradient flows that underwrite self-evidencing. In fact, solenoidal flow generally augments gradient flows-or at least this is what it looks like. In brief, the mixing afforded by solenoidal flow can render gradient descent more efficient [112][113][114][115][116]. An intuitive example is stirring sugar into coffee. The mixing afforded by the solenoidal stirring facilitates the dispersion of the sugar molecules down their concentration gradients. On this 38 Question: does the absence of random fluctuations preclude dissipative gradient flows? No, because the gradients can increase with the precision of random fluctuations. In the limit of no random fluctuations, the steady-state density tends towards a delta function (i.e., a fixed-point attractor) and the dissipative gradients tend towards infinity. Fig. 6. Sentient behaviour and action observation. This figure illustrates a simulation of active inference (here, writing) evinced by a precise particle, in terms of inferences about external states of the world, consequent predictions about sensory input, and ensuing action. The autonomous dynamics that underwrite this behaviour rest upon a generative model of sensory states in the form of Lotka-Volterra dynamics; see sample sensory trajectories as (arbitrarily) coloured lines in the upper left inset. The generative model defines the joint density under which internal trajectories can be seen as parameterising external states. This model is not a description of the true external states (which here are simply the positions of the joints in the simulated arm-with dynamics given by simple Newtonian rules). In this generative model, external trajectories are assumed to follow predator-prey like dynamics such that a succession of peaks are generated for a subset of external states (or coordinates) in turn. Each coordinate is associated with a location in Euclidean space that attracts the agent's finger (the active states); i.e., with a trajectory towards that attracting point. The resulting attracting point is thus a weighted sum of each possible attracting point weighted by the coordinates following the Lotka-Volterra trajectory. In turn, the internal states supply predictions of what sensory states should register if the agent's beliefs were true. Active states (i.e., the forces driving changes in the angular velocities of the limb joints) try to suppress the ensuing prediction error by adjusting expected changes in sensed angular velocity, through exerting forces on the agent's joints (not shown). The subsequent movement of the arm is traced out in the lower-left panel. This trajectory has been plotted in a moving frame of reference so that it looks like handwriting (e.g., a succession of 'j' and 'a' letters). The lower right panels show the activity of one internal state during distinct phases of 'action', and 'action-observation'. During the action phase, sensory states register the visual and proprioceptive consequences of movement, while under action observation, only visual sensations are available-as if the agent was watching another agent. The red dots correspond to the times during which this internal state exceeded an arbitrary threshold. The key thing to note here is that this internal state responds preferentially when, and only when, the motor trajectory produces a down-stroke, but not an up-stroke-evincing a cardinal feature of neuronal responses, namely, their functional selectivity. Furthermore, with a slight delay, this internal state responds during action and action observation. From a biological perspective, this is interesting because it speaks to an empirical phenomenon known as mirror neuron activity [101][102][103]. Please see [97] for further details.One might ask if solenoidal flow confounds the gradient flows that underwrite self-evidencing. In fact, solenoidal flow generally augments gradient flows-or at least this is what it looks like. In brief, the mixing afforded by solenoidal flow can render gradient descent more efficient [112][113][114][115][116]. An intuitive example is stirring sugar into coffee. The mixing afforded by the solenoidal stirring facilitates the dispersion of the sugar molecules down their concentration gradients. On this 38 Question: does the absence of random fluctuations preclude dissipative gradient flows? No, because the gradients can increase with the precision of random fluctuations. In the limit of no random fluctuations, the steady-state density tends towards a delta function (i.e., a fixed-point attractor) and the dissipative gradients tend towards infinity. Fig. 6. Sentient behaviour and action observation. This figure illustrates a simulation of active inference (here, writing) evinced by a precise particle, in terms of inferences about external states of the world, consequent predictions about sensory input, and ensuing action. The autonomous dynamics that underwrite this behaviour rest upon a generative model of sensory states in the form of Lotka-Volterra dynamics; see sample sensory trajectories as (arbitrarily) coloured lines in the upper left inset. The generative model defines the joint density under which internal trajectories can be seen as parameterising external states. This model is not a description of the true external states (which here are simply the positions of the joints in the simulated arm-with dynamics given by simple Newtonian rules). In this generative model, external trajectories are assumed to follow predator-prey like dynamics such that a succession of peaks are generated for a subset of external states (or coordinates) in turn. Each coordinate is associated with a location in Euclidean space that attracts the agent's finger (the active states); i.e., with a trajectory towards that attracting point. The resulting attracting point is thus a weighted sum of each possible attracting point weighted by the coordinates following the Lotka-Volterra trajectory. In turn, the internal states supply predictions of what sensory states should register if the agent's beliefs were true. Active states (i.e., the forces driving changes in the angular velocities of the limb joints) try to suppress the ensuing prediction error by adjusting expected changes in sensed angular velocity, through exerting forces on the agent's joints (not shown). The subsequent movement of the arm is traced out in the lower-left panel. This trajectory has been plotted in a moving frame of reference so that it looks like handwriting (e.g., a succession of 'j' and 'a' letters). The lower right panels show the activity of one internal state during distinct phases of 'action', and 'action-observation'. During the action phase, sensory states register the visual and proprioceptive consequences of movement, while under action observation, only visual sensations are available-as if the agent was watching another agent. The red dots correspond to the times during which this internal state exceeded an arbitrary threshold. The key thing to note here is that this internal state responds preferentially when, and only when, the motor trajectory produces a down-stroke, but not an up-stroke-evincing a cardinal feature of neuronal responses, namely, their functional selectivity. Furthermore, with a slight delay, this internal state responds during action and action observation. From a biological perspective, this is interesting because it speaks to an empirical phenomenon known as mirror neuron activity [101][102][103]. Please see [97] for further details.</p>
        <p>view, the solenoidal flow can be regarded as circumnavigating the contours of the steady-state density to find a path of steepest descent.view, the solenoidal flow can be regarded as circumnavigating the contours of the steady-state density to find a path of steepest descent.</p>
        <p>The emerging picture here is that biotic systems feature solenoidal flow, in virtue of being sufficiently large to average away random fluctuations, when coarse-graining their dynamics [5]. From the perspective of the information geometry induced by the FEP, this means biological behaviour may be characterised by internal solenoidal flows that do not change variational free energy-or surprisal-and yet move on the internal (statistical) manifold to continually update Bayesian beliefs about external states. Biologically, this may be a description of central pattern generators [110,117] that underwrite rhythmical activity (e.g., walking and talking) that is characteristic of biological systems [118]. The example in Fig. 6 was chosen to showcase the role of solenoidal flows in Bayesian mechanics that-in this example-arise from the use of Lotka-Volterra dynamics in the generative model. In psychology, this kind of conservative active inference may be the homologue of being in a 'flow state' [119].The emerging picture here is that biotic systems feature solenoidal flow, in virtue of being sufficiently large to average away random fluctuations, when coarse-graining their dynamics [5]. From the perspective of the information geometry induced by the FEP, this means biological behaviour may be characterised by internal solenoidal flows that do not change variational free energy-or surprisal-and yet move on the internal (statistical) manifold to continually update Bayesian beliefs about external states. Biologically, this may be a description of central pattern generators [110,117] that underwrite rhythmical activity (e.g., walking and talking) that is characteristic of biological systems [118]. The example in Fig. 6 was chosen to showcase the role of solenoidal flows in Bayesian mechanics that-in this example-arise from the use of Lotka-Volterra dynamics in the generative model. In psychology, this kind of conservative active inference may be the homologue of being in a 'flow state' [119].</p>
        <p>In short, precise particles may be the kind of particles we associate with living systems. And precise particles have low entropy paths. If so, the question now becomes: what long-term behaviour does this class of particle show? In other words, instead of asking which behaviours lead to low entropy dynamics, we can now ask which behaviours follow from low entropy dynamics? We will see next that precise particles appear to plan their actions and, perhaps more interestingly, show information and goal-seeking behaviour.In short, precise particles may be the kind of particles we associate with living systems. And precise particles have low entropy paths. If so, the question now becomes: what long-term behaviour does this class of particle show? In other words, instead of asking which behaviours lead to low entropy dynamics, we can now ask which behaviours follow from low entropy dynamics? We will see next that precise particles appear to plan their actions and, perhaps more interestingly, show information and goal-seeking behaviour.</p>
        <p>While the handwriting example in Fig. 6 offers a compelling simulation of self-evidencing-in the sense of an artefact creating its own sensorium-there is something missing as a complete account of sentient behaviour. This is because we have only considered the response of autonomous states to sensory states over limited periods of time. To disclose a deeper Bayesian mechanics, we need to consider the paths of autonomous states over extended periods. This takes us to the final step and back to the path-integral formulation.While the handwriting example in Fig. 6 offers a compelling simulation of self-evidencing-in the sense of an artefact creating its own sensorium-there is something missing as a complete account of sentient behaviour. This is because we have only considered the response of autonomous states to sensory states over limited periods of time. To disclose a deeper Bayesian mechanics, we need to consider the paths of autonomous states over extended periods. This takes us to the final step and back to the path-integral formulation.</p>
        <p>In the previous section, we focused on linking dynamics to densities over (generalised) states. In brief, we saw that internal states can be construed as parameterising (Bayesian) beliefs about external states at any point in time. In what follows, we move from densities over states to densities over paths-to characterise the behaviour of particles in terms of their trajectories.In the previous section, we focused on linking dynamics to densities over (generalised) states. In brief, we saw that internal states can be construed as parameterising (Bayesian) beliefs about external states at any point in time. In what follows, we move from densities over states to densities over paths-to characterise the behaviour of particles in terms of their trajectories.</p>
        <p>In what follows, we will be dealing with predictive posterior densities over external and particular paths, given (initial) particular states, which can be expressed in terms of the variational density parameterised by the current (initial) internal state 39 :In what follows, we will be dealing with predictive posterior densities over external and particular paths, given (initial) particular states, which can be expressed in terms of the variational density parameterised by the current (initial) internal state 39 :</p>
        <p>All this equation says is that, given the initial particular states, we can evaluate the joint density over external and particular paths, because we know the density over the initial external states, which is parameterised by the initial internal state.All this equation says is that, given the initial particular states, we can evaluate the joint density over external and particular paths, because we know the density over the initial external states, which is parameterised by the initial internal state.</p>
        <p>We are interested in characterising autonomous responses to initial particular states. This is given by the action of autonomous paths as a function of particular states. In other words, we seek an expression for the probability of an autonomous path that (i) furnishes a teleological description of self-organisation and (ii) allows us to simulate the sentient trajectories of particles, given their sensory streams. Getting from the action of particular paths to the action of autonomous paths requires a marginalisation over sensory paths. This is where the precise particle assumption comes in: it allows us to eschew this (computationally costly) marginalisation by expressing the action of particular paths as an expected free energy.We are interested in characterising autonomous responses to initial particular states. This is given by the action of autonomous paths as a function of particular states. In other words, we seek an expression for the probability of an autonomous path that (i) furnishes a teleological description of self-organisation and (ii) allows us to simulate the sentient trajectories of particles, given their sensory streams. Getting from the action of particular paths to the action of autonomous paths requires a marginalisation over sensory paths. This is where the precise particle assumption comes in: it allows us to eschew this (computationally costly) marginalisation by expressing the action of particular paths as an expected free energy.</p>
        <p>Recall that when random fluctuations on the motion of particular states vanish, there is no uncertainty about autonomous paths, given external and sensory paths. And there is no uncertainty about sensory paths given external and autonomous paths. If we interpret entropies as the limiting density of discrete points (see Fig. 4), then the uncertainty about particular, autonomous and sensory paths, given external paths, become interchangeable:Recall that when random fluctuations on the motion of particular states vanish, there is no uncertainty about autonomous paths, given external and sensory paths. And there is no uncertainty about sensory paths given external and autonomous paths. If we interpret entropies as the limiting density of discrete points (see Fig. 4), then the uncertainty about particular, autonomous and sensory paths, given external paths, become interchangeable:</p>
        <p>We can leverage this exchangeability to express the action of autonomous paths in terms of an expected free energy. From ( 36) and (37), we have (dropping the conditioning on initial states for clarity):We can leverage this exchangeability to express the action of autonomous paths in terms of an expected free energy. From ( 36) and (37), we have (dropping the conditioning on initial states for clarity):</p>
        <p>39 Question: Why is the variational density parameterised by the initial internal state rather than the initial internal mode? The answer is that in precise particles, the absence of fluctuations on particular dynamics means that the internal states always coincides with the internal mode. that entail a description of planning as inference [120][121][122]. When simulating active inference, posterior beliefs about external paths, under plausible policies, are optimised by a gradient flow on the variational (free energy) bound on log evidence-as in Fig. 3. These beliefs are then used to evaluate the expected free energy of allowable policies, from which actions can be selected [123][124][125]. Crucially, expected free energy contains terms that arise in various formulations of optimal behaviour that predominate in cognitive science, engineering and economics. These terms are disclosed when one removes certain sources of uncertainty. For example, if we remove ambiguity, decision-making minimises risk, which corresponds to aligning predictions with preferences about the external course of events. This underwrites prospect theory of human choice behaviour in economics [126] and modern approaches to control as inference [127][128][129], variously known as Kalman duality [94,130], KL control [131] and maximum entropy reinforcement learning [132]. If we further remove preferences, decision-making maximises the entropy of external trajectories. This maximum entropy principle [46,47] can be interpreted as least committing to a presupposed external trajectory and therefore keeping options open [133]. If we reintroduce ambiguity, but ignore preferences, decision-making maximises intrinsic value or expected information gain [76]. This underwrites Bayesian experimental design [134] and active learning in statistics [135], intrinsic motivation and artificial curiosity in machine learning and robotics [136][137][138][139][140]. This is mathematically equivalent to optimising expected Bayesian surprise and mutual information, which underwrites visual search [141,142] and the organisation of our visual apparatus [67][68][69]. Lastly, if we remove intrinsic value, we are left with maximising extrinsic value or expected utility, which underwrites expected utility theory [66], game theory, optimal control [143,144] and reinforcement learning [63]. Bayesian formulations of maximising expected utility under uncertainty are also known as Bayesian decision theory [145]. The expressions for variational and expected free energy are arranged to illustrate the relationship between complexity and accuracy, which become risk and ambiguity in the path integral formulation. This suggests that risk-averse policies minimise expected complexity or computational cost [137].39 Question: Why is the variational density parameterised by the initial internal state rather than the initial internal mode? The answer is that in precise particles, the absence of fluctuations on particular dynamics means that the internal states always coincides with the internal mode. that entail a description of planning as inference [120][121][122]. When simulating active inference, posterior beliefs about external paths, under plausible policies, are optimised by a gradient flow on the variational (free energy) bound on log evidence-as in Fig. 3. These beliefs are then used to evaluate the expected free energy of allowable policies, from which actions can be selected [123][124][125]. Crucially, expected free energy contains terms that arise in various formulations of optimal behaviour that predominate in cognitive science, engineering and economics. These terms are disclosed when one removes certain sources of uncertainty. For example, if we remove ambiguity, decision-making minimises risk, which corresponds to aligning predictions with preferences about the external course of events. This underwrites prospect theory of human choice behaviour in economics [126] and modern approaches to control as inference [127][128][129], variously known as Kalman duality [94,130], KL control [131] and maximum entropy reinforcement learning [132]. If we further remove preferences, decision-making maximises the entropy of external trajectories. This maximum entropy principle [46,47] can be interpreted as least committing to a presupposed external trajectory and therefore keeping options open [133]. If we reintroduce ambiguity, but ignore preferences, decision-making maximises intrinsic value or expected information gain [76]. This underwrites Bayesian experimental design [134] and active learning in statistics [135], intrinsic motivation and artificial curiosity in machine learning and robotics [136][137][138][139][140]. This is mathematically equivalent to optimising expected Bayesian surprise and mutual information, which underwrites visual search [141,142] and the organisation of our visual apparatus [67][68][69]. Lastly, if we remove intrinsic value, we are left with maximising extrinsic value or expected utility, which underwrites expected utility theory [66], game theory, optimal control [143,144] and reinforcement learning [63]. Bayesian formulations of maximising expected utility under uncertainty are also known as Bayesian decision theory [145]. The expressions for variational and expected free energy are arranged to illustrate the relationship between complexity and accuracy, which become risk and ambiguity in the path integral formulation. This suggests that risk-averse policies minimise expected complexity or computational cost [137].</p>
        <p>All we have done here is to exchange the density over autonomous paths, conditioned on external paths, with the corresponding density over sensory paths (in the second line) thanks to the precise particle assumption. By gathering terms into a functional of autonomous paths, we recover autonomous action as an expected free energy. By analogy with the expression for variational free energy (18), the expressions for the expected free energy in (38) suggest that accuracy becomes ambiguity, while complexity becomes risk. So why have we called these terms ambiguity and risk? Ambiguity is just the expected precision or conditional uncertainty about sensory states given external states. A heuristic example of an imprecise likelihood mapping-between external and sensory paths-would be a dark room, where there is no precise information at hand. Indeed, according to (38), sensory paths into dark rooms should be highly unlikely. However, this is not the complete story, in the sense that the risk puts certain constraints on any manifest tendency to minimise ambiguity.All we have done here is to exchange the density over autonomous paths, conditioned on external paths, with the corresponding density over sensory paths (in the second line) thanks to the precise particle assumption. By gathering terms into a functional of autonomous paths, we recover autonomous action as an expected free energy. By analogy with the expression for variational free energy (18), the expressions for the expected free energy in (38) suggest that accuracy becomes ambiguity, while complexity becomes risk. So why have we called these terms ambiguity and risk? Ambiguity is just the expected precision or conditional uncertainty about sensory states given external states. A heuristic example of an imprecise likelihood mapping-between external and sensory paths-would be a dark room, where there is no precise information at hand. Indeed, according to (38), sensory paths into dark rooms should be highly unlikely. However, this is not the complete story, in the sense that the risk puts certain constraints on any manifest tendency to minimise ambiguity.</p>
        <p>Here, risk is simply the divergence between external paths given an autonomous path (i.e., policy or plan), relative to external states of affairs. The marginal density over external paths is often referred to in terms of prior preferences, because they constitute the priors of the generative model characterising the particle's behaviour [146]. In short, the expression for expected free energy, suggests that particles will look as if they are (i) minimising the risk of incurring external trajectories that diverge from prior preferences, while (ii) resolving ambiguity in response to external events. In this formulation, autonomous paths play the dual role of registering the influences of external events (via ambiguity), while also causing those events (via risk).Here, risk is simply the divergence between external paths given an autonomous path (i.e., policy or plan), relative to external states of affairs. The marginal density over external paths is often referred to in terms of prior preferences, because they constitute the priors of the generative model characterising the particle's behaviour [146]. In short, the expression for expected free energy, suggests that particles will look as if they are (i) minimising the risk of incurring external trajectories that diverge from prior preferences, while (ii) resolving ambiguity in response to external events. In this formulation, autonomous paths play the dual role of registering the influences of external events (via ambiguity), while also causing those events (via risk).</p>
        <p>The autonomous path with the least expected free energy is the most likely path taken by the autonomous states.The autonomous path with the least expected free energy is the most likely path taken by the autonomous states.</p>
        <p>In short, expected free energy scores the autonomous action of particles that do not admit noisy dynamics. Expected free energy has a specific form that inherits from the assumption that the amplitude of particular fluctuations is small, which is the case for precise articles by definition. Although variational and expected free energy are formally similar, they are fundamentally different kinds of functionals: variational free energy is a functional of a density over states, while expected free energy is a functional of a density over paths. Variational free energy can also be read as a function of particular states, while expected free energy is a function of an autonomous path. Finally, variational free energy is a bound on surprisal, while expected free energy is not a bound-it is the action of autonomous trajectories.In short, expected free energy scores the autonomous action of particles that do not admit noisy dynamics. Expected free energy has a specific form that inherits from the assumption that the amplitude of particular fluctuations is small, which is the case for precise articles by definition. Although variational and expected free energy are formally similar, they are fundamentally different kinds of functionals: variational free energy is a functional of a density over states, while expected free energy is a functional of a density over paths. Variational free energy can also be read as a function of particular states, while expected free energy is a function of an autonomous path. Finally, variational free energy is a bound on surprisal, while expected free energy is not a bound-it is the action of autonomous trajectories.</p>
        <p>Expected free energy plays a definitive role in active inference, where it can be regarded as a fairly universal objective function for selecting autonomous paths of least action. Fig. 7 shows that the expected free energy contains terms that arise in various formulations of optimal behaviour; ranging from optimal Bayesian design [134] through to control as inference [127,132]. We refer the reader to [147][148][149][150][151] for formal investigations of the relationship between these formulations.Expected free energy plays a definitive role in active inference, where it can be regarded as a fairly universal objective function for selecting autonomous paths of least action. Fig. 7 shows that the expected free energy contains terms that arise in various formulations of optimal behaviour; ranging from optimal Bayesian design [134] through to control as inference [127,132]. We refer the reader to [147][148][149][150][151] for formal investigations of the relationship between these formulations.</p>
        <p>Equipped with a specification of the most likely autonomous path-in terms of expected free energy-we can simulate fairly lifelike behaviour, given a suitable generative model. An example is provided in Fig. 9-relying upon the computational architecture in Fig. 8-which illustrates the ambiguity resolving part of the expected free energy in a simulation of visual epistemic foraging.Equipped with a specification of the most likely autonomous path-in terms of expected free energy-we can simulate fairly lifelike behaviour, given a suitable generative model. An example is provided in Fig. 9-relying upon the computational architecture in Fig. 8-which illustrates the ambiguity resolving part of the expected free energy in a simulation of visual epistemic foraging.</p>
        <p>This epistemic aspect of expected free energy can be seen more clearly if we replace the conditional uncertainty about sensory paths with conditional uncertainty about particular paths, noting that they are the same by (37). After rearrangement, we can express expected free energy in terms of expected value and expected information gain [125,149]:This epistemic aspect of expected free energy can be seen more clearly if we replace the conditional uncertainty about sensory paths with conditional uncertainty about particular paths, noting that they are the same by (37). After rearrangement, we can express expected free energy in terms of expected value and expected information gain [125,149]:</p>
        <p>Bayes optimal design (40) This provides a complementary interpretation of expected free energy. The first term can be construed as expected cost in the sense it is the expected action of particular paths. This marginal likelihood scores the plausibility of a particle pursuing this kind of path and is usually interpreted in terms of expected loss (i.e., negative expected reward or utility) [63,66], and pragmatic affordance [123,153]. The second term corresponds to the expected divergence between posterior beliefs about external paths, given autonomous paths, with and without sensory paths. In other words, it scores the resolution of uncertainty or expected information gain afforded by sensory trajectories arising from a commitment to an autonomous path. In this sense, it is sometimes referred to as epistemic affordance [158].Bayes optimal design (40) This provides a complementary interpretation of expected free energy. The first term can be construed as expected cost in the sense it is the expected action of particular paths. This marginal likelihood scores the plausibility of a particle pursuing this kind of path and is usually interpreted in terms of expected loss (i.e., negative expected reward or utility) [63,66], and pragmatic affordance [123,153]. The second term corresponds to the expected divergence between posterior beliefs about external paths, given autonomous paths, with and without sensory paths. In other words, it scores the resolution of uncertainty or expected information gain afforded by sensory trajectories arising from a commitment to an autonomous path. In this sense, it is sometimes referred to as epistemic affordance [158].</p>
        <p>When simulating the kind of planning and active inference afforded by the path integral formulation, one usually works with discrete state-spaces and belief updating over discrete epochs of time [123,124]. One can see this as a coarse-graining of continuous space-time into discrete space and time bins, where trajectories of continuous states become sequences of discrete states x[τ ] = (x 1 , . . . , x τ ). In discrete state-spaces, the generative model is usually formulated as a partially observed Markov decision process [88,124,147,159], in which the paths of autonomous states constitute policies, which determine transitions among external states. Plausible policies can then be scored with their expected free energy and Fig. 8. Bayesian mechanics and active inference. This graphic summarises the belief updating implicit in the minimisation of variational and expected free energy. It describes active inference based upon autonomous paths or policies and has been used in a variety of applications and simulations; ranging from games in behavioural economics [152] and reinforcement learning [153,154] through to language understanding [155] and scene construction [156]. In this setup, actions solicit a sensory outcome that informs approximate posterior beliefs about hidden or external states of the world-via minimisation of variational free energy under a set of plausible policies (i.e., perceptual inference). The approximate posterior beliefs are then used to evaluate expected free energy and subsequent action (i.e., active inference). A key insight from simulations is that the form of the generative model can be quite different from the process by which external states generate sensory states. In effect, this enables agents (i.e., particles) to author their own sensorium in a fashion that has close connections with econiche construction [157]. Please see [124,158] for technical details and for a heuristic discussion of how the belief updating could be implemented in the brain.When simulating the kind of planning and active inference afforded by the path integral formulation, one usually works with discrete state-spaces and belief updating over discrete epochs of time [123,124]. One can see this as a coarse-graining of continuous space-time into discrete space and time bins, where trajectories of continuous states become sequences of discrete states x[τ ] = (x 1 , . . . , x τ ). In discrete state-spaces, the generative model is usually formulated as a partially observed Markov decision process [88,124,147,159], in which the paths of autonomous states constitute policies, which determine transitions among external states. Plausible policies can then be scored with their expected free energy and Fig. 8. Bayesian mechanics and active inference. This graphic summarises the belief updating implicit in the minimisation of variational and expected free energy. It describes active inference based upon autonomous paths or policies and has been used in a variety of applications and simulations; ranging from games in behavioural economics [152] and reinforcement learning [153,154] through to language understanding [155] and scene construction [156]. In this setup, actions solicit a sensory outcome that informs approximate posterior beliefs about hidden or external states of the world-via minimisation of variational free energy under a set of plausible policies (i.e., perceptual inference). The approximate posterior beliefs are then used to evaluate expected free energy and subsequent action (i.e., active inference). A key insight from simulations is that the form of the generative model can be quite different from the process by which external states generate sensory states. In effect, this enables agents (i.e., particles) to author their own sensorium in a fashion that has close connections with econiche construction [157]. Please see [124,158] for technical details and for a heuristic discussion of how the belief updating could be implemented in the brain.</p>
        <p>the next action is selected from the most likely policy α = (α 0 , . . . , α τ )40 a = arg min a G(a, µ)the next action is selected from the most likely policy α = (α 0 , . . . , α τ )40 a = arg min a G(a, µ)</p>
        <p>The conditional independencies among states implicit in partially observed Markov decision processes entail the above functional forms for variational and expected free energies [123,124]. Crucially, the posterior over external states uses a mean-field approximation, in which the joint distribution over current and future states factorises into marginal distributions at each point in time [this approximation can be finessed by conditioning on previous states, leading to a different (Bethe) variational free energy [160,161]]. Note that the discrete version of variational free energy is a functional of a distribution over a sequence of states and can be regarded as the discrete homologue of the variational free energy of generalised states in (32). The ensuing minimisation of free energy can be formulated as gradient flows following (17)-between the discrete arrival of new sensory input-in a way that relates comfortably to neuronal dynamics [42,123,124]. In some simulations, Fig. 9. Epistemic foraging. This figure shows the results of a numerical simulation where a face was presented to an agent, whose responses were obtained by selecting active states that minimised expected free energy following an eye movement. The agent had three internal images or hypotheses (i.e., internal states) about the external state she might sample (an upright face (blue), an inverted face (magenta) and a rotated face (green)-shown at the bottom). The agent was presented with sensory samples of an upright face and her variational posterior over the external state was obtained by descending variational free energy over a 12 ms time bin until the next saccade (i.e., action) was emitted. This perception-action cycle was repeated eight times. The agent's eye movements are shown as red dots at the end of each saccade in the upper row. The corresponding sequence of eye movements is shown in the upper-left inset, where the red circles correspond roughly to the proportion of the visual image sampled. These saccades are driven by the salience maps in the second row, which correspond to the expected free energy as a function of the policies; namely, the next saccade or where to look next. As expected free energies are defined in terms of trajectories, it is best to see the locations of on these salience maps as expressing the expected free energy of a trajectory that ends in that location. Note that these maps change with successive saccades as variational posterior beliefs become progressively more confident about the external state. Note also that salience is depleted in locations that were foveated in the previous saccade because these locations no longer have epistemic affordance or expected information gain (i.e., the ability to reduce uncertainty in the expected free energy). In neuroscience, this empirical phenomenon is known as inhibition of return. Oculomotor responses are shown in the third row in terms of the two oculomotor states corresponding to vertical and horizontal eye movements. The associated portions of the image sampled (at the end of each saccade) are shown in the fourth row. The fifth row shows the evolution of variational posterior beliefs about external (a.k.a. hidden) in terms of the log probability they assign to each possible external state (colour coded) and 90% confidence intervals. The key thing to note is that the credence about the true external state supervenes over alternative expectations and, as a result, confidence about the category increases (and confidence intervals shrink to the mode). This illustrates the nature of evidence accumulation when selecting a hypothesis or percept that best explains sensory states. Please see [162] for further details. one can mix discrete and continuous state-space models by placing the former on top of the latter, to produce deep generative models that, through active inference, can be used to simulate many known aspects of computational anatomy and physiology in the brain [158].The conditional independencies among states implicit in partially observed Markov decision processes entail the above functional forms for variational and expected free energies [123,124]. Crucially, the posterior over external states uses a mean-field approximation, in which the joint distribution over current and future states factorises into marginal distributions at each point in time [this approximation can be finessed by conditioning on previous states, leading to a different (Bethe) variational free energy [160,161]]. Note that the discrete version of variational free energy is a functional of a distribution over a sequence of states and can be regarded as the discrete homologue of the variational free energy of generalised states in (32). The ensuing minimisation of free energy can be formulated as gradient flows following (17)-between the discrete arrival of new sensory input-in a way that relates comfortably to neuronal dynamics [42,123,124]. In some simulations, Fig. 9. Epistemic foraging. This figure shows the results of a numerical simulation where a face was presented to an agent, whose responses were obtained by selecting active states that minimised expected free energy following an eye movement. The agent had three internal images or hypotheses (i.e., internal states) about the external state she might sample (an upright face (blue), an inverted face (magenta) and a rotated face (green)-shown at the bottom). The agent was presented with sensory samples of an upright face and her variational posterior over the external state was obtained by descending variational free energy over a 12 ms time bin until the next saccade (i.e., action) was emitted. This perception-action cycle was repeated eight times. The agent's eye movements are shown as red dots at the end of each saccade in the upper row. The corresponding sequence of eye movements is shown in the upper-left inset, where the red circles correspond roughly to the proportion of the visual image sampled. These saccades are driven by the salience maps in the second row, which correspond to the expected free energy as a function of the policies; namely, the next saccade or where to look next. As expected free energies are defined in terms of trajectories, it is best to see the locations of on these salience maps as expressing the expected free energy of a trajectory that ends in that location. Note that these maps change with successive saccades as variational posterior beliefs become progressively more confident about the external state. Note also that salience is depleted in locations that were foveated in the previous saccade because these locations no longer have epistemic affordance or expected information gain (i.e., the ability to reduce uncertainty in the expected free energy). In neuroscience, this empirical phenomenon is known as inhibition of return. Oculomotor responses are shown in the third row in terms of the two oculomotor states corresponding to vertical and horizontal eye movements. The associated portions of the image sampled (at the end of each saccade) are shown in the fourth row. The fifth row shows the evolution of variational posterior beliefs about external (a.k.a. hidden) in terms of the log probability they assign to each possible external state (colour coded) and 90% confidence intervals. The key thing to note is that the credence about the true external state supervenes over alternative expectations and, as a result, confidence about the category increases (and confidence intervals shrink to the mode). This illustrates the nature of evidence accumulation when selecting a hypothesis or percept that best explains sensory states. Please see [162] for further details. one can mix discrete and continuous state-space models by placing the former on top of the latter, to produce deep generative models that, through active inference, can be used to simulate many known aspects of computational anatomy and physiology in the brain [158].</p>
        <p>In summary, we now have at hand a way of identifying the most likely autonomous trajectory from any initial particular state that can be used to simulate the sentient behaviour of precise particles that we have associated with biotic systems. The expected free energy absorbs two aspects of Bayes optimal behaviour into the same (objective) functional [149]. On a Bayesian reading, the expected information gain is exactly the same quantity that underwrites the principles of optimal Bayesian design [76,134,163]. In other words, the principles that prescribe the best way to solicit evidence that reduces uncertainty about various hypotheses. The second imperative comes from Bayesian decision theory, where the objective is to minimise some expected cost function expected under a choice or decision [145,164,165].In summary, we now have at hand a way of identifying the most likely autonomous trajectory from any initial particular state that can be used to simulate the sentient behaviour of precise particles that we have associated with biotic systems. The expected free energy absorbs two aspects of Bayes optimal behaviour into the same (objective) functional [149]. On a Bayesian reading, the expected information gain is exactly the same quantity that underwrites the principles of optimal Bayesian design [76,134,163]. In other words, the principles that prescribe the best way to solicit evidence that reduces uncertainty about various hypotheses. The second imperative comes from Bayesian decision theory, where the objective is to minimise some expected cost function expected under a choice or decision [145,164,165].</p>
        <p>Teleologically, it is worth reflecting upon the differences between the generative models that underwrite state-wise and path-wise descriptions of Bayesian mechanics, respectively. For the state-wise formulation (23), the generative model is just a joint density over external and particular states, supplied by-or supplying-the NESS density. For the pathwise formulation (34), (41), the generative model is a joint distribution over the paths of external and sensory states. In other words, there is an implicit state-space model of dynamics that can be summarised heuristically as modelling the consequences of an action on external and sensory dynamics. Because consequences follow causes, the generative model acquires a temporal depth [155,166]. This depth required to describe any given particle may, of course, be another characteristic that distinguishes different kinds of particles. In short, the path-wise formulation describes particles that plan, under a proximal or distal horizon.Teleologically, it is worth reflecting upon the differences between the generative models that underwrite state-wise and path-wise descriptions of Bayesian mechanics, respectively. For the state-wise formulation (23), the generative model is just a joint density over external and particular states, supplied by-or supplying-the NESS density. For the pathwise formulation (34), (41), the generative model is a joint distribution over the paths of external and sensory states. In other words, there is an implicit state-space model of dynamics that can be summarised heuristically as modelling the consequences of an action on external and sensory dynamics. Because consequences follow causes, the generative model acquires a temporal depth [155,166]. This depth required to describe any given particle may, of course, be another characteristic that distinguishes different kinds of particles. In short, the path-wise formulation describes particles that plan, under a proximal or distal horizon.</p>
        <p>There are many points of contact between the variational formulation above and other normative theories of selforganisation and purposeful behaviour. However, to focus the narrative we have deliberately suppressed demonstrating precedents, variants and special cases. Fig. 3 highlights a few relationships between the free energy principle and various formulations of self-organisation and sentient behaviour. In brief, this casts things like reinforcement learning and optimal control theory as optimising the marginal likelihood of particular states, conditioned upon a generative model supplied by a nonequilibrium steady-state density. It could be argued that the link between the free energy principle and established formulations is most direct for synergetics [14,167] and related treatments of dissipative structures [168]. There is also a formal and direct link to information theoretic formulations and Bayesian statistics. Furthermore, the free energy principle can be regarded as dual to the constrained maximum entropy principle [169], where the constraints are supplied by the generative model. Please see [148,150] for a treatment of things like empowerment [170], information bottleneck [171] and predictive information [172,173].There are many points of contact between the variational formulation above and other normative theories of selforganisation and purposeful behaviour. However, to focus the narrative we have deliberately suppressed demonstrating precedents, variants and special cases. Fig. 3 highlights a few relationships between the free energy principle and various formulations of self-organisation and sentient behaviour. In brief, this casts things like reinforcement learning and optimal control theory as optimising the marginal likelihood of particular states, conditioned upon a generative model supplied by a nonequilibrium steady-state density. It could be argued that the link between the free energy principle and established formulations is most direct for synergetics [14,167] and related treatments of dissipative structures [168]. There is also a formal and direct link to information theoretic formulations and Bayesian statistics. Furthermore, the free energy principle can be regarded as dual to the constrained maximum entropy principle [169], where the constraints are supplied by the generative model. Please see [148,150] for a treatment of things like empowerment [170], information bottleneck [171] and predictive information [172,173].</p>
        <p>In a similar vein, there are several accounts of optimal behaviour-in both its epistemic and pragmatic aspects-that are closely related to the path integral formulation of active inference. Some key relationships are highlighted in Fig. 7, such as intrinsic motivation, artificial curiosity [136][137][138] and optimal control [93,95,131]. The interesting thing about these other theories is that they are predicated on optimising some objective function that can be recovered from expected free energy by taking various sources of uncertainty off the table. This discloses things like the objective optimised in reinforcement learning and expected utility theory in behavioural psychology and economics, respectively [65,174].In a similar vein, there are several accounts of optimal behaviour-in both its epistemic and pragmatic aspects-that are closely related to the path integral formulation of active inference. Some key relationships are highlighted in Fig. 7, such as intrinsic motivation, artificial curiosity [136][137][138] and optimal control [93,95,131]. The interesting thing about these other theories is that they are predicated on optimising some objective function that can be recovered from expected free energy by taking various sources of uncertainty off the table. This discloses things like the objective optimised in reinforcement learning and expected utility theory in behavioural psychology and economics, respectively [65,174].</p>
        <p>This paper has focused on a single particle and has largely ignored the (external) context that leads to generalised synchrony among internal and external states. This synchronisation goes hand-in-hand with existence per se and the Bayesian mechanics supplied by the free energy principle. The very fact that this mechanics rests upon synchronisation may speak to the emergence of synchronisation among formally similar particles; namely, populations or ensembles. In other words, an individual member of an ensemble or ecosystem owes its existence to the ensemble of which it is a member-at the level of multicellular organisation or indeed its conspecifics in evolutionary biology [175]. In a similar vein, the context established by supra-and subordinate scales plays an existential role. In brief, particles at one scale can only exist if there is a nonequilibrium steady-state density at a higher scale that entails Markov blankets of Markov blankets [176]. Due to a separation of temporal scales, much of the self-evidencing at one scale is absorbed into the fast, random fluctuations at the scale above. For example, the fast electrophysiological fluctuations of a neuron become, random fluctuations from the point of view of neuronal population dynamics and sensory motor coordination in the brain [177][178][179]. This follows in a straightforward way from applying the apparatus of the renormalisation group. Please see [5] for further discussion.This paper has focused on a single particle and has largely ignored the (external) context that leads to generalised synchrony among internal and external states. This synchronisation goes hand-in-hand with existence per se and the Bayesian mechanics supplied by the free energy principle. The very fact that this mechanics rests upon synchronisation may speak to the emergence of synchronisation among formally similar particles; namely, populations or ensembles. In other words, an individual member of an ensemble or ecosystem owes its existence to the ensemble of which it is a member-at the level of multicellular organisation or indeed its conspecifics in evolutionary biology [175]. In a similar vein, the context established by supra-and subordinate scales plays an existential role. In brief, particles at one scale can only exist if there is a nonequilibrium steady-state density at a higher scale that entails Markov blankets of Markov blankets [176]. Due to a separation of temporal scales, much of the self-evidencing at one scale is absorbed into the fast, random fluctuations at the scale above. For example, the fast electrophysiological fluctuations of a neuron become, random fluctuations from the point of view of neuronal population dynamics and sensory motor coordination in the brain [177][178][179]. This follows in a straightforward way from applying the apparatus of the renormalisation group. Please see [5] for further discussion.</p>
        <p>For brevity and focus, we have not considered applications of the free energy principle and active inference in detail. A brief review of the literature in this area will show that the majority of applications are in the neurosciences [124] with some exceptions: e.g., [180,181]. Recently, there has been an increasing focus on active inference in the setting of machine learning and artificial intelligence [61,147,150,[182][183][184][185]. Much of this literature deals with simulation and modelling and, specifically, scaling active inference to real-world problems. These developments speak to the shift in focus from the foundational issues addressed in this article to their applications. It is quite possible that the foundational aspects of the free energy principle may also shift as simpler interpretations and perspectives reveal themselves.For brevity and focus, we have not considered applications of the free energy principle and active inference in detail. A brief review of the literature in this area will show that the majority of applications are in the neurosciences [124] with some exceptions: e.g., [180,181]. Recently, there has been an increasing focus on active inference in the setting of machine learning and artificial intelligence [61,147,150,[182][183][184][185]. Much of this literature deals with simulation and modelling and, specifically, scaling active inference to real-world problems. These developments speak to the shift in focus from the foundational issues addressed in this article to their applications. It is quite possible that the foundational aspects of the free energy principle may also shift as simpler interpretations and perspectives reveal themselves.</p>
        <p>Perhaps a better analogy would be Noether's theorem (Beren Millidge-personal communication)[6].Perhaps a better analogy would be Noether's theorem (Beren Millidge-personal communication)[6].</p>
        <p>This implicitly precludes edge cases, in which some non-zero terms cancel.This implicitly precludes edge cases, in which some non-zero terms cancel.</p>
        <p>Physics Reports 1024 (2023)Physics Reports 1024 (2023)</p>
        <p>Note that we are performing a Taylor expansion of a (generally rough) stochastic process ε, see[51, Chapter 5]. Alternatively, it may be possible to instead consider motion in generalised coordinates to introduce smooth random fluctuations (see next Section), so that ε becomes smooth and the usual Taylor expansion applies.Note that we are performing a Taylor expansion of a (generally rough) stochastic process ε, see[51, Chapter 5]. Alternatively, it may be possible to instead consider motion in generalised coordinates to introduce smooth random fluctuations (see next Section), so that ε becomes smooth and the usual Taylor expansion applies.</p>
        <p>We know that the flow must be towards the centre manifold because the covariance of random fluctuations is positive definite, and the curvature of the free energy is positive definite at its minima: i.e., around the expansion point.We know that the flow must be towards the centre manifold because the covariance of random fluctuations is positive definite, and the curvature of the free energy is positive definite at its minima: i.e., around the expansion point.</p>
        <p>The covariance of random fluctuations Γ α is positive definite and the solenoidal matrix field Q αα is skew-symmetric, therefore the flow in(22) will seek to minimise complexity minus accuracy.The covariance of random fluctuations Γ α is positive definite and the solenoidal matrix field Q αα is skew-symmetric, therefore the flow in(22) will seek to minimise complexity minus accuracy.</p>
        <p>See[88,124] for a derivation of these functional forms in partially observable Markov decision processes.See[88,124] for a derivation of these functional forms in partially observable Markov decision processes.</p>
        <p>We would like to thank Maxwell Ramstead-and participants in his International Physics Reading Group-who went through [5] in the forensic detail, generating many of the issues and questions addressed in this paper. We thank our excellent reviewer for detailed and helpful feedback that significantly improved the manuscript.We would like to thank Maxwell Ramstead-and participants in his International Physics Reading Group-who went through [5] in the forensic detail, generating many of the issues and questions addressed in this paper. We thank our excellent reviewer for detailed and helpful feedback that significantly improved the manuscript.</p>
        <p>The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p>
    </text>
</tei>
