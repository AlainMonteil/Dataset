<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-14T14:24+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>Euclid is a mission of the European Space Agency that is designed to constrain the properties of dark energy and gravity via weak gravitational lensing and galaxy clustering. It will carry out a wide area imaging and spectroscopy survey (the Euclid Wide Survey: EWS) in visible and near-infrared bands, covering approximately 15 000 deg 2 of extragalactic sky in six years. The wide-field telescope and instruments are optimised for pristine point spread function and reduced stray light, producing very crisp images. This paper presents the building of the Euclid reference survey: the sequence of pointings of EWS, deep fields, and calibration fields, as well as spacecraft movements followed by Euclid as it operates in a step-and-stare mode from its orbit around the Lagrange point L2. Each EWS pointing has four dithered frames; we simulated the dither pattern at the pixel level to analyse the effective coverage. We used up-to-date models for the sky background to define the Euclid region-of-interest (RoI). The building of the reference survey is highly constrained from calibration cadences, spacecraft constraints, and background levels; synergies with ground-based coverage were also considered. Via purposely built software, we first generated a schedule for the calibrations and deep fields observations. On a second stage, the RoI was tiled and scheduled with EWS observations, using an algorithm optimised to prioritise the best sky areas, produce a compact coverage, and ensure thermal stability. The result is the optimised reference survey RSD_2021A, which fulfils all constraints and is a good proxy for the final solution. The current EWS covers ≈14 500 deg 2 . The limiting AB magnitudes (5σ point-like source) achieved in its footprint are estimated to be 26.2 (visible band I E ) and 24.5 (for near infrared bands Y E , J E , H E ); for spectroscopy, the Hα line flux limit is 2 × 10 -16 erg -1 cm -2 s -1 at 1600 nm; and for diffuse emission, the surface brightness limits are 29.8 (visible band) and 28.4 (near infrared bands) mag arcsec -2 .Euclid is a mission of the European Space Agency that is designed to constrain the properties of dark energy and gravity via weak gravitational lensing and galaxy clustering. It will carry out a wide area imaging and spectroscopy survey (the Euclid Wide Survey: EWS) in visible and near-infrared bands, covering approximately 15 000 deg 2 of extragalactic sky in six years. The wide-field telescope and instruments are optimised for pristine point spread function and reduced stray light, producing very crisp images. This paper presents the building of the Euclid reference survey: the sequence of pointings of EWS, deep fields, and calibration fields, as well as spacecraft movements followed by Euclid as it operates in a step-and-stare mode from its orbit around the Lagrange point L2. Each EWS pointing has four dithered frames; we simulated the dither pattern at the pixel level to analyse the effective coverage. We used up-to-date models for the sky background to define the Euclid region-of-interest (RoI). The building of the reference survey is highly constrained from calibration cadences, spacecraft constraints, and background levels; synergies with ground-based coverage were also considered. Via purposely built software, we first generated a schedule for the calibrations and deep fields observations. On a second stage, the RoI was tiled and scheduled with EWS observations, using an algorithm optimised to prioritise the best sky areas, produce a compact coverage, and ensure thermal stability. The result is the optimised reference survey RSD_2021A, which fulfils all constraints and is a good proxy for the final solution. The current EWS covers ≈14 500 deg 2 . The limiting AB magnitudes (5σ point-like source) achieved in its footprint are estimated to be 26.2 (visible band I E ) and 24.5 (for near infrared bands Y E , J E , H E ); for spectroscopy, the Hα line flux limit is 2 × 10 -16 erg -1 cm -2 s -1 at 1600 nm; and for diffuse emission, the surface brightness limits are 29.8 (visible band) and 28.4 (near infrared bands) mag arcsec -2 .</p>
        <p>Observations of distant type Ia supernovae (e.g. Riess et al. 1998;Perlmutter et al. 1999) together with those of the cosmic microwave background (CMB; e.g. de Bernardis et al. 2000de Bernardis et al. , 2002;;Hanany et al. 2000;Pryke et al. 2002;Hinshaw et al. 2013;Planck Collaboration I 2020;Planck Collaboration VI 2020) suggest that the spatial curvature of the Universe is close to zero. Despite the large contribution of dark matter (DM), however, the total matter density is still much lower than the critical matter density. As a consequence, a non-zero value for the cosmological constant, Λ, is usually introduced to complete the cosmological model. Although a cosmological constant can describe the data, it is not generally appealing (Weinberg 1989), and alternative solutions have been investigated, such as an evolving quantum field -dark energy (DE) -and a modification to general relativity on cosmological scales. We refer to Amendola et al. (2018) for an extensive review of theoretical models.Observations of distant type Ia supernovae (e.g. Riess et al. 1998;Perlmutter et al. 1999) together with those of the cosmic microwave background (CMB; e.g. de Bernardis et al. 2000de Bernardis et al. , 2002;;Hanany et al. 2000;Pryke et al. 2002;Hinshaw et al. 2013;Planck Collaboration I 2020;Planck Collaboration VI 2020) suggest that the spatial curvature of the Universe is close to zero. Despite the large contribution of dark matter (DM), however, the total matter density is still much lower than the critical matter density. As a consequence, a non-zero value for the cosmological constant, Λ, is usually introduced to complete the cosmological model. Although a cosmological constant can describe the data, it is not generally appealing (Weinberg 1989), and alternative solutions have been investigated, such as an evolving quantum field -dark energy (DE) -and a modification to general relativity on cosmological scales. We refer to Amendola et al. (2018) for an extensive review of theoretical models.</p>
        <p>To learn more about the nature of DE and DM, we need to quantify their impact on cosmological observations. In particular, we need to determine H(z), the expansion history of the Universe as a function of redshift, z, using geometrical tests and to measure the growth of large-scale structures through gravitational instability. The latter can be captured using the time derivative of the matter density contrast δ ≡ δρ/ρ,To learn more about the nature of DE and DM, we need to quantify their impact on cosmological observations. In particular, we need to determine H(z), the expansion history of the Universe as a function of redshift, z, using geometrical tests and to measure the growth of large-scale structures through gravitational instability. The latter can be captured using the time derivative of the matter density contrast δ ≡ δρ/ρ,</p>
        <p>where a ≡ 1/(1 + z) is the cosmic scale factor and Ω m is the mean density divided by the critical density. For the canonical Λ cold dark matter (CDM) model in linear theory, γ 0.55, whereas it differs for other models of DE (Amendola et al. 2018). We note that the growth of cosmic structures is also influenced by the DM characteristics.where a ≡ 1/(1 + z) is the cosmic scale factor and Ω m is the mean density divided by the critical density. For the canonical Λ cold dark matter (CDM) model in linear theory, γ 0.55, whereas it differs for other models of DE (Amendola et al. 2018). We note that the growth of cosmic structures is also influenced by the DM characteristics.</p>
        <p>The exact nature of DE can be tested via its equation-ofstate, w = p/(ρc 2 ), which directly influences the expansion history. In the general case, w is a function of the scale factor, w = w(a), and simplifies to w = -1 in the case of a cosmological constant. Using a truncated Taylor expansion, one can write w = w 0 + w a (1a) and seek constraints on the possible values in the w 0 -w a plane. Ideally, we should have a model that describes the redshift dependence of w(a) and predicts how the structure growth is affected by a modification of gravity. Nonetheless, γ, w 0 , and w a provide convenient generic parameterisations that can be used to compare the expected performance of various cosmological probes. When Fisher matrix techniques are used (Euclid Collaboration 2020a), the confidence areas in twodimensional parameter spaces are ellipses. The inverse of the area of the 2σ ellipse in the w 0 -w a plane, after marginalisation over all other cosmological and nuisance parameters, defines the DE figure of merit (FoM; Albrecht et al. 2006;Laureijs et al. 2011). Hence, the larger the FoM, the better (more informative) the experiment is.The exact nature of DE can be tested via its equation-ofstate, w = p/(ρc 2 ), which directly influences the expansion history. In the general case, w is a function of the scale factor, w = w(a), and simplifies to w = -1 in the case of a cosmological constant. Using a truncated Taylor expansion, one can write w = w 0 + w a (1a) and seek constraints on the possible values in the w 0 -w a plane. Ideally, we should have a model that describes the redshift dependence of w(a) and predicts how the structure growth is affected by a modification of gravity. Nonetheless, γ, w 0 , and w a provide convenient generic parameterisations that can be used to compare the expected performance of various cosmological probes. When Fisher matrix techniques are used (Euclid Collaboration 2020a), the confidence areas in twodimensional parameter spaces are ellipses. The inverse of the area of the 2σ ellipse in the w 0 -w a plane, after marginalisation over all other cosmological and nuisance parameters, defines the DE figure of merit (FoM; Albrecht et al. 2006;Laureijs et al. 2011). Hence, the larger the FoM, the better (more informative) the experiment is.</p>
        <p>Two of the best cosmological probes are galaxy clustering (GC) and weak gravitational lensing (WL), especially once combined in the so-called 3 × 2 pt statistics. These are the two-point correlation of galaxies positions (GC uses galaxies as test particles in the expanding space-time to map the mass density contrast, δ, over time), the shear two-point correlations (WL exploits the cumulative distortion effect of the tidal gravitational fields along the line of sight on the shapes of the galaxy images; see e.g. Kilbinger 2015, for a review), and the cross-correlation of the lens positions with the shear of the source galaxies, known as galaxy-galaxy lensing. Despite tremendous progress in GC and WL experiments in recent years (e.g. BOSS Collaboration 2017;Dark Energy Survey Collaboration 2022;Gil-Marin et al. 2020;Hildebrandt et al. 2020), much larger cosmological volumes need to be surveyed.Two of the best cosmological probes are galaxy clustering (GC) and weak gravitational lensing (WL), especially once combined in the so-called 3 × 2 pt statistics. These are the two-point correlation of galaxies positions (GC uses galaxies as test particles in the expanding space-time to map the mass density contrast, δ, over time), the shear two-point correlations (WL exploits the cumulative distortion effect of the tidal gravitational fields along the line of sight on the shapes of the galaxy images; see e.g. Kilbinger 2015, for a review), and the cross-correlation of the lens positions with the shear of the source galaxies, known as galaxy-galaxy lensing. Despite tremendous progress in GC and WL experiments in recent years (e.g. BOSS Collaboration 2017;Dark Energy Survey Collaboration 2022;Gil-Marin et al. 2020;Hildebrandt et al. 2020), much larger cosmological volumes need to be surveyed.</p>
        <p>Even though a clear 'target precision' is lacking, Laureijs et al. (2011) argues that a FoM ≥ 400 provides constraints on w(a) and γ that can test key aspects of our current cosmological model. This target FoM ≥ 400 has driven the design of Euclid, a medium class mission of the European Space Agency (ESA) that combines GC and WL.Even though a clear 'target precision' is lacking, Laureijs et al. (2011) argues that a FoM ≥ 400 provides constraints on w(a) and γ that can test key aspects of our current cosmological model. This target FoM ≥ 400 has driven the design of Euclid, a medium class mission of the European Space Agency (ESA) that combines GC and WL.</p>
        <p>To meet its primary science goal, Euclid (Laureijs et al. 2011;Racca et al. 2016) has to observe a large fraction of the extra-galactic sky with both multi-band imaging and slitless spectroscopy. The sky area and mean number density of galaxies are specified by the scientific requirements of the GC and WL experiments (Laureijs et al. 2011;Rassat et al. 2008;Cropper et al. 2013;Massey et al. 2013):To meet its primary science goal, Euclid (Laureijs et al. 2011;Racca et al. 2016) has to observe a large fraction of the extra-galactic sky with both multi-band imaging and slitless spectroscopy. The sky area and mean number density of galaxies are specified by the scientific requirements of the GC and WL experiments (Laureijs et al. 2011;Rassat et al. 2008;Cropper et al. 2013;Massey et al. 2013):</p>
        <p>(i) a 15 000 deg 2 survey of the extra-galactic sky, jointly for WL and GC, to be completed in six years with all the necessary calibrations; (ii) an average galaxy number density of 30 arcmin -2 that is useful for WL in the optical imaging data; and (iii) an average galaxy number density of 1700 deg 2 with reliable redshifts from the Hα emission line spectroscopic data, useful for GC 1 .(i) a 15 000 deg 2 survey of the extra-galactic sky, jointly for WL and GC, to be completed in six years with all the necessary calibrations; (ii) an average galaxy number density of 30 arcmin -2 that is useful for WL in the optical imaging data; and (iii) an average galaxy number density of 1700 deg 2 with reliable redshifts from the Hα emission line spectroscopic data, useful for GC 1 .</p>
        <p>Moreover, we want to minimise systematic residuals in the error budget by maximising the uniformity in covering the observed sky by using the same observation sequence (see Sect. 4.1 and Fig. 8) as much as possible (Laureijs et al. 2011;Scaramella et al. 2015). The resulting survey is the Euclid Wide Survey (EWS), which will cover 15 000 deg 2 to a minimum depth of m AB = 24.5 mag in the visible band I E with a signal-to-noise ratio (S/N) of 10 for extended sources such as the z ∼ 1 galaxies (details in Sect. 5.2.2 and Laureijs et al. 2011;Cropper et al. 2016). In the near-infrared (NIR) Y E , J E and H E bands, a depth of m AB = 24.0 mag will be reached with a minimum S/N of 5 for point sources (Laureijs et al. 2011). This is sufficient to complement ground-based multi-band observations that will be used to determine photometric redshifts (photo zs) for the WL sources (Euclid Collaboration 2020b). Using slitless spectroscopy, Euclid will detect line emission with a sensitivity of f Hα ≥ 2 × 10 -16 erg s -1 cm -2 and a S/N of 3.5 for a typical source of size 0 . 5 (Maciaszek et al. 2014(Maciaszek et al. , 2016)). Space-based observations provide excellent and consistent image quality at visible wavelengths for WL and sufficient depth in the NIR bands, both of which are unattainable from the ground for this type of survey.Moreover, we want to minimise systematic residuals in the error budget by maximising the uniformity in covering the observed sky by using the same observation sequence (see Sect. 4.1 and Fig. 8) as much as possible (Laureijs et al. 2011;Scaramella et al. 2015). The resulting survey is the Euclid Wide Survey (EWS), which will cover 15 000 deg 2 to a minimum depth of m AB = 24.5 mag in the visible band I E with a signal-to-noise ratio (S/N) of 10 for extended sources such as the z ∼ 1 galaxies (details in Sect. 5.2.2 and Laureijs et al. 2011;Cropper et al. 2016). In the near-infrared (NIR) Y E , J E and H E bands, a depth of m AB = 24.0 mag will be reached with a minimum S/N of 5 for point sources (Laureijs et al. 2011). This is sufficient to complement ground-based multi-band observations that will be used to determine photometric redshifts (photo zs) for the WL sources (Euclid Collaboration 2020b). Using slitless spectroscopy, Euclid will detect line emission with a sensitivity of f Hα ≥ 2 × 10 -16 erg s -1 cm -2 and a S/N of 3.5 for a typical source of size 0 . 5 (Maciaszek et al. 2014(Maciaszek et al. , 2016)). Space-based observations provide excellent and consistent image quality at visible wavelengths for WL and sufficient depth in the NIR bands, both of which are unattainable from the ground for this type of survey.</p>
        <p>With this design, Fisher matrix analyses forecast that EWS 3 × 2 pt datasets will obtain a DE FoM of 500 for a nonflat w 0 -w a CDM model in an optimistic setting (defined by the range of scales used; see Euclid Collaboration 2020a). It is interesting to compare Euclid 3 × 2 pt forecasts with the constraints obtained by DES, which can be considered as representative of ongoing Stage-III surveys. In DES Year 1 constraints for a w 0 -w a CDM model (Dark Energy Survey Collaboration 2019), the uncertainties on w 0 and w a are a factor of 10 larger than the Euclid forecasts in the pessimistic setting (roughly translating to a factor of 100 in the FoM). The DES DE FoM from the DES Year 3 analysis of a more complete dataset is not yet available, but we can use instead the results on S 8 = σ 8 (Ω m/0.3 ) 1/2 to compare Stage-III constraints with Stage-IV Euclid forecasts. Using a 3 × 2 pt dataset and Fig. 1. Euclid timeline. The EWS has to be carried out within the six year mission baseline and will start 3 months after the launch, following a commissioning period of 1 month and a PV period of 2 months. An extension of operations beyond the six years is possible and will be decided in due time. During the first six months of the main mission (the early operations phase) a faster replanning of the survey is allowed. The three main data releases (DR#) are shown. The plan is to have 2500 deg 2 made public in DR1, to grow to 7500 in DR2, and be complete at DR3 for 15 000 deg 2 . In addition, four quick data releases (Q#) are foreseen, each of ∼50 deg 2 . marginalising over 25 nuisance parameters and 7 cosmological parameters of a flat wCDM model, DES Year 3 gets 3.2% errors on S 8 (Dark Energy Survey Collaboration 2022). Using the Fisher matrix for 3 × 2 pt obtained in Euclid Collaboration (2020a) for a w 0 -w a CDM model, and adding an additional ten nuisance parameters to represent the uncertainty on the shear multiplicative bias of each redshift bin (in order to increase the number of nuisance parameters to have a fair comparison with DES), we marginalise over a total of 25 nuisance and cosmological parameters, getting 1.25% errors on S 8 in a pessimistic setting and 0.68% errors in an optimistic setting. Although the comparison is not completely fair -because of the different intrinsic alignments and bias models, the fewer nuisance parameters considered in the Euclid forecast, and a slightly different set of cosmological parameters -these numbers are roughly in agreement with what one would obtain by simply scaling the DES Year 3 results for the Euclid increase in area and source number density.With this design, Fisher matrix analyses forecast that EWS 3 × 2 pt datasets will obtain a DE FoM of 500 for a nonflat w 0 -w a CDM model in an optimistic setting (defined by the range of scales used; see Euclid Collaboration 2020a). It is interesting to compare Euclid 3 × 2 pt forecasts with the constraints obtained by DES, which can be considered as representative of ongoing Stage-III surveys. In DES Year 1 constraints for a w 0 -w a CDM model (Dark Energy Survey Collaboration 2019), the uncertainties on w 0 and w a are a factor of 10 larger than the Euclid forecasts in the pessimistic setting (roughly translating to a factor of 100 in the FoM). The DES DE FoM from the DES Year 3 analysis of a more complete dataset is not yet available, but we can use instead the results on S 8 = σ 8 (Ω m/0.3 ) 1/2 to compare Stage-III constraints with Stage-IV Euclid forecasts. Using a 3 × 2 pt dataset and Fig. 1. Euclid timeline. The EWS has to be carried out within the six year mission baseline and will start 3 months after the launch, following a commissioning period of 1 month and a PV period of 2 months. An extension of operations beyond the six years is possible and will be decided in due time. During the first six months of the main mission (the early operations phase) a faster replanning of the survey is allowed. The three main data releases (DR#) are shown. The plan is to have 2500 deg 2 made public in DR1, to grow to 7500 in DR2, and be complete at DR3 for 15 000 deg 2 . In addition, four quick data releases (Q#) are foreseen, each of ∼50 deg 2 . marginalising over 25 nuisance parameters and 7 cosmological parameters of a flat wCDM model, DES Year 3 gets 3.2% errors on S 8 (Dark Energy Survey Collaboration 2022). Using the Fisher matrix for 3 × 2 pt obtained in Euclid Collaboration (2020a) for a w 0 -w a CDM model, and adding an additional ten nuisance parameters to represent the uncertainty on the shear multiplicative bias of each redshift bin (in order to increase the number of nuisance parameters to have a fair comparison with DES), we marginalise over a total of 25 nuisance and cosmological parameters, getting 1.25% errors on S 8 in a pessimistic setting and 0.68% errors in an optimistic setting. Although the comparison is not completely fair -because of the different intrinsic alignments and bias models, the fewer nuisance parameters considered in the Euclid forecast, and a slightly different set of cosmological parameters -these numbers are roughly in agreement with what one would obtain by simply scaling the DES Year 3 results for the Euclid increase in area and source number density.</p>
        <p>The EWS has to be carried out within the six-year mission baseline and will start 3 months after the launch, following a commissioning period (1 month) and a performance verification (PV) period (2 months). Figure 1 shows the Euclid timeline with the data release planning. The first major data release (DR1), corresponding to 2500 deg 2 of the EWS, is planned to take place one year after T 1 (T 1 = 14 months after launch), the second data release (DR2) is expected to release 7500 deg 2 three years after T 1 , and the final one (DR3) will release the full survey (15 000 deg 2 ) six years after T 1 . In between, there will be other 'quick data releases': Q1 of 50 deg 2 is planned at T 1 , and Q2, Q3, and Q4 will take place two, four, and five years after Q1, respectively.The EWS has to be carried out within the six-year mission baseline and will start 3 months after the launch, following a commissioning period (1 month) and a performance verification (PV) period (2 months). Figure 1 shows the Euclid timeline with the data release planning. The first major data release (DR1), corresponding to 2500 deg 2 of the EWS, is planned to take place one year after T 1 (T 1 = 14 months after launch), the second data release (DR2) is expected to release 7500 deg 2 three years after T 1 , and the final one (DR3) will release the full survey (15 000 deg 2 ) six years after T 1 . In between, there will be other 'quick data releases': Q1 of 50 deg 2 is planned at T 1 , and Q2, Q3, and Q4 will take place two, four, and five years after Q1, respectively.</p>
        <p>In addition to the main survey, a significant fraction of time will be spent on calibrating the instruments and characterising the target galaxies. As a result, some fields will be observed to greater depths than with the wide survey (typically two magnitudes deeper). These deep fields have a great legacy value beyond the cosmological core science. While aspects of noncore science did not influence the design of the spacecraft and instruments, they are taken into account in the design of the EWS to maximise the Euclid scientific return. In fact, it must be noticed that the large decrease in the background with the wavelength dramatically increases the S/N in the NIR bands when compared to Earth-based observations affected by airglow, which instead increases with wavelength. This makes even a small space telescope competitive with a large ground telescope that suffers from a background dominated by atmospheric emission in the NIR bands. The relative gain is such that, in order to cover the same areas planned for Euclid and at the same depths, a ground-based NIR survey on existing facilities would need to observe for several centuries. Regarding other space-based facilities, we notice that the James Webb Space Telescope (JWST) will be in orbit as well and, with its diameter of 6.5 m, will go much deeper and faster than Euclid, although only on very small areas (the JWST field of view is 75 times smaller than the Euclid one). Hence, the two facilities are complementary and, moreover, JWST will likely benefit from targets selected from the Euclid surveys.In addition to the main survey, a significant fraction of time will be spent on calibrating the instruments and characterising the target galaxies. As a result, some fields will be observed to greater depths than with the wide survey (typically two magnitudes deeper). These deep fields have a great legacy value beyond the cosmological core science. While aspects of noncore science did not influence the design of the spacecraft and instruments, they are taken into account in the design of the EWS to maximise the Euclid scientific return. In fact, it must be noticed that the large decrease in the background with the wavelength dramatically increases the S/N in the NIR bands when compared to Earth-based observations affected by airglow, which instead increases with wavelength. This makes even a small space telescope competitive with a large ground telescope that suffers from a background dominated by atmospheric emission in the NIR bands. The relative gain is such that, in order to cover the same areas planned for Euclid and at the same depths, a ground-based NIR survey on existing facilities would need to observe for several centuries. Regarding other space-based facilities, we notice that the James Webb Space Telescope (JWST) will be in orbit as well and, with its diameter of 6.5 m, will go much deeper and faster than Euclid, although only on very small areas (the JWST field of view is 75 times smaller than the Euclid one). Hence, the two facilities are complementary and, moreover, JWST will likely benefit from targets selected from the Euclid surveys.</p>
        <p>The challenge is to fit all these observations into a finite time allocation set by the limitation of the mission, which is six years, whilst fulfilling a wide range of constraints, which are reviewed in detail in this paper. Part of the survey optimisation involves selecting the best areas of the sky to use, which in turn relies on a good model of the properties of the observable sky, such as Galactic extinction and the zodiacal background. We also need to model the distribution of (bright) stars as their stray light lowers the observed galaxy number density.The challenge is to fit all these observations into a finite time allocation set by the limitation of the mission, which is six years, whilst fulfilling a wide range of constraints, which are reviewed in detail in this paper. Part of the survey optimisation involves selecting the best areas of the sky to use, which in turn relies on a good model of the properties of the observable sky, such as Galactic extinction and the zodiacal background. We also need to model the distribution of (bright) stars as their stray light lowers the observed galaxy number density.</p>
        <p>This paper focuses on the design of the EWS, and the deep fields will be described in a companion paper (Scaramella et al.,in prep.,hereafter [Sc23]). The EWS design takes into account the main backgrounds that impact any large area survey, the sequence of operations, and the many limitations to the pointing of the telescope. The EWS is at an advanced stage, fulfilling the key survey requirements over the full mission. Survey scenarios at this stage therefore show the detailed feasibility of the mission but are subject to further optimisation. Nevertheless, the results we present and their discussion are instructive and useful for any future large area survey from space or the ground that aims to combine imaging and spectroscopy.This paper focuses on the design of the EWS, and the deep fields will be described in a companion paper (Scaramella et al.,in prep.,hereafter [Sc23]). The EWS design takes into account the main backgrounds that impact any large area survey, the sequence of operations, and the many limitations to the pointing of the telescope. The EWS is at an advanced stage, fulfilling the key survey requirements over the full mission. Survey scenarios at this stage therefore show the detailed feasibility of the mission but are subject to further optimisation. Nevertheless, the results we present and their discussion are instructive and useful for any future large area survey from space or the ground that aims to combine imaging and spectroscopy.</p>
        <p>The paper is organised as follows. The spacecraft is described in Sect. 2, followed by a summary of Euclid's instruments in Sect. 3. In Sect. 4 the reference observation sequence (ROS) is introduced, including a study of dithering scenarios. Models of zodiacal light, stray light effects, and other environmental properties define the region of interest (RoI) used as input for the implementation of the Euclid reference survey definition (RSD). These effects and the properties of the resulting RoI are presented in Sect. 5, where we also discuss complementary ground-based observations. Section 6 describes the implementation of the calibration programme. Observations of sample characterisation fields and the Euclid Deep Survey (EDS) are briefly mentioned in this context. The construction of the EWS is presented in Sect. 7. We present the most recent outcome of the survey optimisation (mid 2021) in Sect. 8. This solution is a good proxy for the actual survey. We conclude in Sect. 9.The paper is organised as follows. The spacecraft is described in Sect. 2, followed by a summary of Euclid's instruments in Sect. 3. In Sect. 4 the reference observation sequence (ROS) is introduced, including a study of dithering scenarios. Models of zodiacal light, stray light effects, and other environmental properties define the region of interest (RoI) used as input for the implementation of the Euclid reference survey definition (RSD). These effects and the properties of the resulting RoI are presented in Sect. 5, where we also discuss complementary ground-based observations. Section 6 describes the implementation of the calibration programme. Observations of sample characterisation fields and the Euclid Deep Survey (EDS) are briefly mentioned in this context. The construction of the EWS is presented in Sect. 7. We present the most recent outcome of the survey optimisation (mid 2021) in Sect. 8. This solution is a good proxy for the actual survey. We conclude in Sect. 9.</p>
        <p>In the appendix we provide a list of the acronyms used in this paper.In the appendix we provide a list of the acronyms used in this paper.</p>
        <p>The spacecraft comprises a service module (SVM) and a payload module (PLM), connected by an interface structure designed to maximise thermal decoupling. The PLM includes the main instruments, the folded beam optical components of the telescope, the radiators, and the fine guidance system (FGS). The A112, page 3 of 41 A&amp;A 662, A112 (2022) Fig. 2. Euclid reference frames. Left panel: Euclid spacecraft reference frame. X SC points towards the Sun disk centre. The edge and centre of the joint FoV are offset by 0 • .47 and 0 • .82, respectively. The longer side of the FoV is typically aligned with ecliptic meridians during observations. Right panel: Euclid optical reference frame. We note that the X opt Y opt plane is defined as looking onto the sky with ẑ towards the spacecraft. There are four additional chips used as fine guidance sensors that are placed on each side of the VIS FoV.The spacecraft comprises a service module (SVM) and a payload module (PLM), connected by an interface structure designed to maximise thermal decoupling. The PLM includes the main instruments, the folded beam optical components of the telescope, the radiators, and the fine guidance system (FGS). The A112, page 3 of 41 A&amp;A 662, A112 (2022) Fig. 2. Euclid reference frames. Left panel: Euclid spacecraft reference frame. X SC points towards the Sun disk centre. The edge and centre of the joint FoV are offset by 0 • .47 and 0 • .82, respectively. The longer side of the FoV is typically aligned with ecliptic meridians during observations. Right panel: Euclid optical reference frame. We note that the X opt Y opt plane is defined as looking onto the sky with ẑ towards the spacecraft. There are four additional chips used as fine guidance sensors that are placed on each side of the VIS FoV.</p>
        <p>SVM provides the main spacecraft services -power generation, conditioning and distribution, Sun shield and solar array, telecommunication with the ground (low and high gain antenna), and attitude and orbit control system (AOCS; including the FGS) -and support the instruments' warm electronics. Details are given in Laureijs et al. (2011) and Racca et al. (2016).SVM provides the main spacecraft services -power generation, conditioning and distribution, Sun shield and solar array, telecommunication with the ground (low and high gain antenna), and attitude and orbit control system (AOCS; including the FGS) -and support the instruments' warm electronics. Details are given in Laureijs et al. (2011) and Racca et al. (2016).</p>
        <p>Euclid has severe constraints in pointing to ensure maximal thermal stability, which are described in this paper and limit the standard operations. Therefore, it is important to describe in detail the attitude of the spacecraft. The Euclid spacecraft reference frame (O SC , X SC , Y SC , Z SC ) is defined as follows (see Fig. 2 for a graphical representation): (i) O SC , the origin is at the point of intersection of the longitudinal launcher axis with the launcher adapter interface plane (the plane of separation of the spacecraft from the launcher); (ii) +Z SC in the direction perpendicular to the launcher interface plane, positive in the direction of the launch; (iii) +X SC in the launcher interface plane, directed to a physical mark on the interface ring nominally aligned with the solar array such that the +X SC vector is perpendicular to the solar array and pointing towards the Sun; and (iv) +Y SC in the remaining direction of the right-handed orthogonal triad.Euclid has severe constraints in pointing to ensure maximal thermal stability, which are described in this paper and limit the standard operations. Therefore, it is important to describe in detail the attitude of the spacecraft. The Euclid spacecraft reference frame (O SC , X SC , Y SC , Z SC ) is defined as follows (see Fig. 2 for a graphical representation): (i) O SC , the origin is at the point of intersection of the longitudinal launcher axis with the launcher adapter interface plane (the plane of separation of the spacecraft from the launcher); (ii) +Z SC in the direction perpendicular to the launcher interface plane, positive in the direction of the launch; (iii) +X SC in the launcher interface plane, directed to a physical mark on the interface ring nominally aligned with the solar array such that the +X SC vector is perpendicular to the solar array and pointing towards the Sun; and (iv) +Y SC in the remaining direction of the right-handed orthogonal triad.</p>
        <p>The orientation of the telescope optical reference frame, projected onto the sky, is also specified in Fig. 2. The field of view (FoV) reference frame is centred on the centre of the FoV itself and is such that X FoV = -X OPT and Y FoV = Y OPT -0 • .82, taking into account the shift of the edge of the FoV of 0 • .47, and its half size of 0 • .35 (see Fig. 2).The orientation of the telescope optical reference frame, projected onto the sky, is also specified in Fig. 2. The field of view (FoV) reference frame is centred on the centre of the FoV itself and is such that X FoV = -X OPT and Y FoV = Y OPT -0 • .82, taking into account the shift of the edge of the FoV of 0 • .47, and its half size of 0 • .35 (see Fig. 2).</p>
        <p>Euclid's PLM (Racca et al. 2016) is designed around a threemirror anastigmat Korsch design telescope with silicon carbide (SiC) mirrors and truss (Korsch 1972;Pamplona et al. 2016). The sizes of the telescope components are: primary pupil R 1 = 0.6 m, primary mirror (M1) stopper R 2 = 0.1975 m, spider arm mean length R 3 = 0.44 m, spider arm thickness L = 0.012 m. This provides a total collecting area of A = π R2 1 -R 2 2 -3R 3 L = 0.99 m 2 . Euclid has two instruments on board, the visible imager (VIS; Sect. 3.1) and the near-infrared spectrometer and photome-Euclid's PLM (Racca et al. 2016) is designed around a threemirror anastigmat Korsch design telescope with silicon carbide (SiC) mirrors and truss (Korsch 1972;Pamplona et al. 2016). The sizes of the telescope components are: primary pupil R 1 = 0.6 m, primary mirror (M1) stopper R 2 = 0.1975 m, spider arm mean length R 3 = 0.44 m, spider arm thickness L = 0.012 m. This provides a total collecting area of A = π R2 1 -R 2 2 -3R 3 L = 0.99 m 2 . Euclid has two instruments on board, the visible imager (VIS; Sect. 3.1) and the near-infrared spectrometer and photome-</p>
        <p>This document is not to be reproduced, modified, adapted, published, translated in any material form in whole or in part nor disclosed to any third party without the prior written permission of Thales Alenia Space.This document is not to be reproduced, modified, adapted, published, translated in any material form in whole or in part nor disclosed to any third party without the prior written permission of Thales Alenia Space.</p>
        <p>Template 83230326-DOC-TAS-EN/003Template 83230326-DOC-TAS-EN/003</p>
        <p>AA comprised between -8 and +8 degrees (EUCL-SYS-MIS-REQ-060);AA comprised between -8 and +8 degrees (EUCL-SYS-MIS-REQ-060);</p>
        <p>The previous attitude domain will be used for the survey of the sky, but two different domains have been introduced for non-scientific objectives, in particular: Slightly increasing the maximum achievable SAA (from 121 to 136 deg) would make possible to increase significantly the geometrical efficiency for the execution of ΔV maneuver, in particular for the Transfer Correction Maneuver #1 (TCM#1, see for details); Allowing the S/C to arrive at a SAA of 45 deg, it would be possible to illuminate the upper side of the telescope baffle, with the objective to heat up that zone for decontamination purposes (i.e. ice removal). Fig. 3. Illustration of the relevant pointing angles defined in the text. In the top right image the minimal SAA (pointing towards the Sun) is indicated, while the maximum SAA (pointing away from the Sun) adopted in the survey is 110 • (see also Sect. 2.5). In the lower right image, AA is shown; the maximum range allowed for the survey is ±5 • , which corresponds to a large margin with respect to the spacecraft capabilities. ter (NISP; Sect. 3.2). The wavelength separation at ∼920 nm between the two instruments is performed by a dichroic plate located at the exit pupil of the telescope. The two focal planes image the same part of the sky, allowing multiple data acquisition with a single telescope pointing (see Sect. 4.1). The coordinates of the focal plane as projected on the sky are shown in Fig. 2.The previous attitude domain will be used for the survey of the sky, but two different domains have been introduced for non-scientific objectives, in particular: Slightly increasing the maximum achievable SAA (from 121 to 136 deg) would make possible to increase significantly the geometrical efficiency for the execution of ΔV maneuver, in particular for the Transfer Correction Maneuver #1 (TCM#1, see for details); Allowing the S/C to arrive at a SAA of 45 deg, it would be possible to illuminate the upper side of the telescope baffle, with the objective to heat up that zone for decontamination purposes (i.e. ice removal). Fig. 3. Illustration of the relevant pointing angles defined in the text. In the top right image the minimal SAA (pointing towards the Sun) is indicated, while the maximum SAA (pointing away from the Sun) adopted in the survey is 110 • (see also Sect. 2.5). In the lower right image, AA is shown; the maximum range allowed for the survey is ±5 • , which corresponds to a large margin with respect to the spacecraft capabilities. ter (NISP; Sect. 3.2). The wavelength separation at ∼920 nm between the two instruments is performed by a dichroic plate located at the exit pupil of the telescope. The two focal planes image the same part of the sky, allowing multiple data acquisition with a single telescope pointing (see Sect. 4.1). The coordinates of the focal plane as projected on the sky are shown in Fig. 2.</p>
        <p>The main reference frames are shown in Fig. 2. The following angles (see Fig. 3) have operational ranges that constrain a pointing and therefore target visibility: (i) solar aspect angle (SAA), which is the angle between the spacecraft's +Z SC axis (telescope pointing direction) and the direction to the centre of the Solar disk; (ii) alpha angle (AA), which is the angle between the Sun vector projected onto the X SC -Y SC plane and the +X SC axis, increasing as the spacecraft rotates clockwise about its +Z SC axis; and (iii) solar panel solar aspect angle (SPSAA), which is the angle between the spacecraft +X SC axis and the direction to the centre of the Solar disk.The main reference frames are shown in Fig. 2. The following angles (see Fig. 3) have operational ranges that constrain a pointing and therefore target visibility: (i) solar aspect angle (SAA), which is the angle between the spacecraft's +Z SC axis (telescope pointing direction) and the direction to the centre of the Solar disk; (ii) alpha angle (AA), which is the angle between the Sun vector projected onto the X SC -Y SC plane and the +X SC axis, increasing as the spacecraft rotates clockwise about its +Z SC axis; and (iii) solar panel solar aspect angle (SPSAA), which is the angle between the spacecraft +X SC axis and the direction to the centre of the Solar disk.</p>
        <p>Euclid will operate at the Sun-Earth Lagrangian point L2, following a yearly orbit with a libration within ±0 • .41 across the ecliptic plane (Fig. 4). The Lissajous orbit is dynamically unstable and requires regular orbital maintenance, currently planned to last one day every four weeks (i.e. ∼3% of the total mission time). This orbit offers a very stable thermal environment and maximises the visible sky at any time.Euclid will operate at the Sun-Earth Lagrangian point L2, following a yearly orbit with a libration within ±0 • .41 across the ecliptic plane (Fig. 4). The Lissajous orbit is dynamically unstable and requires regular orbital maintenance, currently planned to last one day every four weeks (i.e. ∼3% of the total mission time). This orbit offers a very stable thermal environment and maximises the visible sky at any time.</p>
        <p>Euclid employs a step-and-stare mode, acquiring data on a fixed sky field and then slewing to the next pointing. Slews come in two types, depending on the value of the eigenslew defined as the angle between one field quaternion 2 and the next, which can be decomposed in an arc connecting two separate pointings on the sky plus a rotation around Z SC ). Eigenslews ≤ 3 • .6 are considered 'small slews', and &gt; 3 • .6 are 'large slews'. Euclid has adopted a specific hybrid on-board AOCS architecture, where slews are performed using four reaction wheels in stop and go mode, and pointing stabilisation is achieved using low-noise cold gas micro-thrusters. With this solution, slew time is reduced thanks to the high torque provided by the reaction wheels. Slews only consume cold gas for the tranquilisation transient phase, large slews requiring longer tranquilisation periods. Therefore, Euclid's lifetime slew budget is limited to 950 large and 2.5 × 10 5 small slews. The latter are weighted in the budget: for ≤ 1 • .2 they count as a single slew, and for 1 • .2 &lt; ≤ 3 • .6 a penalty occurs proportional to . The slew constraints imply that the EWS must be implemented mostly with small slews (preferably with ≤ 1 • .2), and that fields observed consecutively in time must be spatially adjacent.Euclid employs a step-and-stare mode, acquiring data on a fixed sky field and then slewing to the next pointing. Slews come in two types, depending on the value of the eigenslew defined as the angle between one field quaternion 2 and the next, which can be decomposed in an arc connecting two separate pointings on the sky plus a rotation around Z SC ). Eigenslews ≤ 3 • .6 are considered 'small slews', and &gt; 3 • .6 are 'large slews'. Euclid has adopted a specific hybrid on-board AOCS architecture, where slews are performed using four reaction wheels in stop and go mode, and pointing stabilisation is achieved using low-noise cold gas micro-thrusters. With this solution, slew time is reduced thanks to the high torque provided by the reaction wheels. Slews only consume cold gas for the tranquilisation transient phase, large slews requiring longer tranquilisation periods. Therefore, Euclid's lifetime slew budget is limited to 950 large and 2.5 × 10 5 small slews. The latter are weighted in the budget: for ≤ 1 • .2 they count as a single slew, and for 1 • .2 &lt; ≤ 3 • .6 a penalty occurs proportional to . The slew constraints imply that the EWS must be implemented mostly with small slews (preferably with ≤ 1 • .2), and that fields observed consecutively in time must be spatially adjacent.</p>
        <p>The SAA and AA ranges define how much the spacecraft can deviate from observing at 'transit' meridian, which are the two ecliptic meridians defined by the perpendicular to the spacecraft's X SC axis (for a transit SAA = 90 • ). The size and geometry of the Sun shield limit the SAA and AA ranges that can be used for observations. The ranges (and variations in) SAA and AA are constrained further by the fact that Euclid needs great thermal stability to minimise temporal point spread function (PSF) variations. The SAA limits allow the telescope to 'depoint' (i.e. to rotate around Y SC ) from transit to a maximum of 3 • towards the Sun (SAA = 87 • ), and up to 20 • away from the Sun (SAA = 110 • ), while the AA limits allow the telescope to rotate around Z SC up to |AA| ≤ 5 • .The SAA and AA ranges define how much the spacecraft can deviate from observing at 'transit' meridian, which are the two ecliptic meridians defined by the perpendicular to the spacecraft's X SC axis (for a transit SAA = 90 • ). The size and geometry of the Sun shield limit the SAA and AA ranges that can be used for observations. The ranges (and variations in) SAA and AA are constrained further by the fact that Euclid needs great thermal stability to minimise temporal point spread function (PSF) variations. The SAA limits allow the telescope to 'depoint' (i.e. to rotate around Y SC ) from transit to a maximum of 3 • towards the Sun (SAA = 87 • ), and up to 20 • away from the Sun (SAA = 110 • ), while the AA limits allow the telescope to rotate around Z SC up to |AA| ≤ 5 • .</p>
        <p>In addition, the orbit libration mentioned in Sect. 2.4 imposes an additional 0 • .41 buffer for the spacecraft orientation angles with respect to the Sun. This decreases the allowed ranges of both SAA and AA by 0 • .41 on each side of their range intervals.In addition, the orbit libration mentioned in Sect. 2.4 imposes an additional 0 • .41 buffer for the spacecraft orientation angles with respect to the Sun. This decreases the allowed ranges of both SAA and AA by 0 • .41 on each side of their range intervals.</p>
        <p>The allowed ranges of SAA and AA define the instantaneous sky visibility, shaped along the full circle defined by the two meridian transits (see Fig. 5). The orbit progresses with Euclid's revolution around the Sun, continuously changing the visible sky enabling a full sky survey. Given the symmetry of the transit meridians, the spacecraft has access to the same region of the sky every six months by pointing in the 'leading' direction (towards the direction of motion around the Sun) or, flipping the telescope, six months later pointing in the 'trailing' direction. Figure 5 shows an example of the instantaneous sky visibility for a generic transit. It is evident that two small regions located at the ecliptic poles have perennial (continuous) visibility, whereas the lowest ecliptic latitudes can be observed only when crossed by a transit meridian. In practice, at any given time (or from a given position in the orbit) Euclid can scan an annulus on the sky, and consequently most of the sky must be observed at or close to transit. Observations that require long and regular visibility (such as for the EDS) can only be fulfilled in a very limited area on the sky at high ecliptic latitudes.The allowed ranges of SAA and AA define the instantaneous sky visibility, shaped along the full circle defined by the two meridian transits (see Fig. 5). The orbit progresses with Euclid's revolution around the Sun, continuously changing the visible sky enabling a full sky survey. Given the symmetry of the transit meridians, the spacecraft has access to the same region of the sky every six months by pointing in the 'leading' direction (towards the direction of motion around the Sun) or, flipping the telescope, six months later pointing in the 'trailing' direction. Figure 5 shows an example of the instantaneous sky visibility for a generic transit. It is evident that two small regions located at the ecliptic poles have perennial (continuous) visibility, whereas the lowest ecliptic latitudes can be observed only when crossed by a transit meridian. In practice, at any given time (or from a given position in the orbit) Euclid can scan an annulus on the sky, and consequently most of the sky must be observed at or close to transit. Observations that require long and regular visibility (such as for the EDS) can only be fulfilled in a very limited area on the sky at high ecliptic latitudes.</p>
        <p>In general, a de-pointing (SAA 90 • ) induces a rotation of the focal plane with respect to the transit ecliptic meridian. To counterbalance this, the spacecraft must rotate around the +Z SC axis to keep the alignment with the transit meridian. The amplitude of this rotation must stay within |AA| ≤ 4 • .59 to fulfil the thermal and orbit libration constraints. This effect becomes larger with increasing ecliptic latitudes and requires ad hoc solutions for the scheduling (see Sect. 7.4.2).In general, a de-pointing (SAA 90 • ) induces a rotation of the focal plane with respect to the transit ecliptic meridian. To counterbalance this, the spacecraft must rotate around the +Z SC axis to keep the alignment with the transit meridian. The amplitude of this rotation must stay within |AA| ≤ 4 • .59 to fulfil the thermal and orbit libration constraints. This effect becomes larger with increasing ecliptic latitudes and requires ad hoc solutions for the scheduling (see Sect. 7.4.2).</p>
        <p>The VIS instrument contains a focal plane array (FPA) that consists of 6 × 6 Teledyne e2v charge-coupled devices (CCDs; 4k × 4k pixels each) with a Nyquist driven plate scale of 0 . 1 pixel -1 , yielding a field-of-view (FoV) of 0.56 deg 2 , including detector gaps (for details, see Table 1 and the left panel of Fig. 6). In addition to the gaps, the central four rows in each detector serve as charge injection lines (which cannot be read out).The VIS instrument contains a focal plane array (FPA) that consists of 6 × 6 Teledyne e2v charge-coupled devices (CCDs; 4k × 4k pixels each) with a Nyquist driven plate scale of 0 . 1 pixel -1 , yielding a field-of-view (FoV) of 0.56 deg 2 , including detector gaps (for details, see Table 1 and the left panel of Fig. 6). In addition to the gaps, the central four rows in each detector serve as charge injection lines (which cannot be read out).</p>
        <p>The VIS is optimised to detect spatially resolved images of galaxies in the 550-900 nm passband (hereafter referred to as the 'VIS band'; Cropper et al. 2014Cropper et al. , 2016)). The VIS nominal survey images (dithered; see Sect. 4) will have at least a S/N of 10σ for extended sources at the detection limit of I E = 24.5 AB mag, the average S/N being 15.8σ (see Sect. 5.2.2). We note that an extended source has a full width at half maximum (FWHM) such that FWHM gal &gt; 1.25 FWHM PSF 0 . 225. This feature will enable accurate galaxy shape measurements for an average of 30 arcmin -2 galaxies over the survey area (Laureijs et al. 2011;Massey et al. 2013). Besides WL shape measurement, VIS data are also used to improve photo-z estimation, by enabling optimal photometric extraction of the less resolved, complementary ground observations thanks to its diffraction-limited image quality. To maximise the S/N for the shape measurements, the VIS band I E is rather broad (see Fig. 7), encompassing the Sloan Digital Sky Survey (SDSS) r and i bands, and the bluer half of the z band.The VIS is optimised to detect spatially resolved images of galaxies in the 550-900 nm passband (hereafter referred to as the 'VIS band'; Cropper et al. 2014Cropper et al. , 2016)). The VIS nominal survey images (dithered; see Sect. 4) will have at least a S/N of 10σ for extended sources at the detection limit of I E = 24.5 AB mag, the average S/N being 15.8σ (see Sect. 5.2.2). We note that an extended source has a full width at half maximum (FWHM) such that FWHM gal &gt; 1.25 FWHM PSF 0 . 225. This feature will enable accurate galaxy shape measurements for an average of 30 arcmin -2 galaxies over the survey area (Laureijs et al. 2011;Massey et al. 2013). Besides WL shape measurement, VIS data are also used to improve photo-z estimation, by enabling optimal photometric extraction of the less resolved, complementary ground observations thanks to its diffraction-limited image quality. To maximise the S/N for the shape measurements, the VIS band I E is rather broad (see Fig. 7), encompassing the Sloan Digital Sky Survey (SDSS) r and i bands, and the bluer half of the z band.</p>
        <p>The VIS central data processing unit constructs the images from the pixel data and compresses them in a lossless manner in approximately 250 s No additional image processing will be done on board to maintain full control over systematic errors. The data will be transferred to the ground with a rate of approximately 520 Gbit/day (Racca et al. 2016).The VIS central data processing unit constructs the images from the pixel data and compresses them in a lossless manner in approximately 250 s No additional image processing will be done on board to maintain full control over systematic errors. The data will be transferred to the ground with a rate of approximately 520 Gbit/day (Racca et al. 2016).</p>
        <p>NISP (Maciaszek et al. 2014(Maciaszek et al. , 2016) ) contains an array of 4 × 4 HAWAII-2RGs detectors (2k × 2k pixels each) with a plate scale of 0 . 3 pixel -1 , under-sampling its diffraction limited PSF (Fig. 6, right panel). Table 1 shows the size of the FPA, FoV, and gaps between the detectors. It should be noted that in the Y direction of the focal plane, the central gap (86 . 1 wide) is narrower than the two outer gaps (101 . 4 wide).NISP (Maciaszek et al. 2014(Maciaszek et al. , 2016) ) contains an array of 4 × 4 HAWAII-2RGs detectors (2k × 2k pixels each) with a plate scale of 0 . 3 pixel -1 , under-sampling its diffraction limited PSF (Fig. 6, right panel). Table 1 shows the size of the FPA, FoV, and gaps between the detectors. It should be noted that in the Y direction of the focal plane, the central gap (86 . 1 wide) is narrower than the two outer gaps (101 . 4 wide).</p>
        <p>NISP is designed to carry out slitless spectroscopy (NISP-S) and imaging photometry (NISP-P) at NIR wavelengths (see Fig. 7). By using its grism and filter wheel assemblies (GWA and FWA, respectively), NISP can switch between slitless spectroscopy and imaging modes, which are detailed in the following. NISP will transfer data to the ground with a rate of approximately 290 Gbit/day, for a total of 810 Gbit/day, smaller than the spacecraft allocation of 850 Gbit/day.NISP is designed to carry out slitless spectroscopy (NISP-S) and imaging photometry (NISP-P) at NIR wavelengths (see Fig. 7). By using its grism and filter wheel assemblies (GWA and FWA, respectively), NISP can switch between slitless spectroscopy and imaging modes, which are detailed in the following. NISP will transfer data to the ground with a rate of approximately 290 Gbit/day, for a total of 810 Gbit/day, smaller than the spacecraft allocation of 850 Gbit/day.</p>
        <p>Euclid has a 'blue' grism (BGS000) covering the 0.92-1.25 µm wavelength range, and three 'red' grisms (RGS000, RGS180, and RGS270) covering RG E band, 1. 25-1.85 µm (Costille et al. 2016). The blue grism, covering the BG E band, is not used for the EWS observations, and will be only employed for part of the EDS. The numeric labels indicate the dispersion directions, offset by 90 • for the red grisms. Different dispersion directions are required to disentangle the spectra of various objects in the slitless spectroscopic exposures of the EWS. Due to a non-conformity discovered in 2020 (Laureijs et al. 2020), the RGS270 will not be used in the survey observations. Instead, the RGS000 and RGS180 will be rotated in the ROS by -4 • and +4 • , respectively (see Sect. 4.1 for details).Euclid has a 'blue' grism (BGS000) covering the 0.92-1.25 µm wavelength range, and three 'red' grisms (RGS000, RGS180, and RGS270) covering RG E band, 1. 25-1.85 µm (Costille et al. 2016). The blue grism, covering the BG E band, is not used for the EWS observations, and will be only employed for part of the EDS. The numeric labels indicate the dispersion directions, offset by 90 • for the red grisms. Different dispersion directions are required to disentangle the spectra of various objects in the slitless spectroscopic exposures of the EWS. Due to a non-conformity discovered in 2020 (Laureijs et al. 2020), the RGS270 will not be used in the survey observations. Instead, the RGS000 and RGS180 will be rotated in the ROS by -4 • and +4 • , respectively (see Sect. 4.1 for details).</p>
        <p>The red grisms disperse the light with nearly constant spectral resolution of 1.354 nm px -1 , which gives R = λ/∆λ ∼ 450 for an object of diameter 0 . 5. This is larger than the minimum required value of 380 to achieve an error on the measured redshift of σ(z) &lt; 0.001(1 + z). The spectroscopic observations support the GC probe and are optimised to detect the redshifted Hα emission of galaxies at z = 0.9-1.8. With a detection limit of 2 × 10 -16 erg s -1 cm -2 (3.5σ) for a typical source of size 0 . 5 at 1600 nm (see Sect. 5.2.2), NISP should be able to determine spectroscopic redshifts for at least 1700 galaxies deg -2 on average in the corresponding wavelength range 1250-1850 nm. This estimate, however, strongly depends on the intrinsic luminosity function of Hα emitters, which is still uncertain in the redshift range observed by Euclid (Pozzetti et al. 2016). Because the redshift is based on an emission line, passive galaxies will be underrepresented in the spectroscopic sample, with a bias against dense environments.The red grisms disperse the light with nearly constant spectral resolution of 1.354 nm px -1 , which gives R = λ/∆λ ∼ 450 for an object of diameter 0 . 5. This is larger than the minimum required value of 380 to achieve an error on the measured redshift of σ(z) &lt; 0.001(1 + z). The spectroscopic observations support the GC probe and are optimised to detect the redshifted Hα emission of galaxies at z = 0.9-1.8. With a detection limit of 2 × 10 -16 erg s -1 cm -2 (3.5σ) for a typical source of size 0 . 5 at 1600 nm (see Sect. 5.2.2), NISP should be able to determine spectroscopic redshifts for at least 1700 galaxies deg -2 on average in the corresponding wavelength range 1250-1850 nm. This estimate, however, strongly depends on the intrinsic luminosity function of Hα emitters, which is still uncertain in the redshift range observed by Euclid (Pozzetti et al. 2016). Because the redshift is based on an emission line, passive galaxies will be underrepresented in the spectroscopic sample, with a bias against dense environments.</p>
        <p>Photometry will be measured for objects down to a minimum of m AB = 24 AB mag for 5σ point-like source in the J E , Y E , and H E passbands. The photometric data support the GC experiment by providing the reference images needed to extract the spectra in the (slitless) dispersed images. The NIR photometric data, however, critically complement the ground-based observations A112, page 6 of 41 (Sect. 5.5) in getting accurate photometric redshift estimates, at the primary probe level mainly needed for the WL experiment and essential for many other astronomical science aspects.Photometry will be measured for objects down to a minimum of m AB = 24 AB mag for 5σ point-like source in the J E , Y E , and H E passbands. The photometric data support the GC experiment by providing the reference images needed to extract the spectra in the (slitless) dispersed images. The NIR photometric data, however, critically complement the ground-based observations A112, page 6 of 41 (Sect. 5.5) in getting accurate photometric redshift estimates, at the primary probe level mainly needed for the WL experiment and essential for many other astronomical science aspects.</p>
        <p>The intersection of the VIS and NISP FoVs defines the Euclid joint FoV, with the X and Y dimensions defined by VIS and NISP, respectively. The Euclid FoV is 0.53 deg 2 . Its borders are shown by the dashed lines in Fig. 6, resulting from the overlap of the VIS and NISP FoVs aligned on an edge. The left and right edges of the NISP FoV and the top and bottom edges of the VIS FoV are outside the joint Euclid FoV.The intersection of the VIS and NISP FoVs defines the Euclid joint FoV, with the X and Y dimensions defined by VIS and NISP, respectively. The Euclid FoV is 0.53 deg 2 . Its borders are shown by the dashed lines in Fig. 6, resulting from the overlap of the VIS and NISP FoVs aligned on an edge. The left and right edges of the NISP FoV and the top and bottom edges of the VIS FoV are outside the joint Euclid FoV.</p>
        <p>Euclid executes a highly optimised ROS (see Fig. 8) at every survey field, exploiting the instruments' inter-operability. The ROS visits four nearby pointings at every field, covering an area of 0.53 deg 2 (see Sect. 3.3) common to both instruments and fulfilling the galaxy number density and S/N requirements detailed in Laureijs et al. (2011). Small 'dither slews' are performed between the pointings, taking 66 s.Euclid executes a highly optimised ROS (see Fig. 8) at every survey field, exploiting the instruments' inter-operability. The ROS visits four nearby pointings at every field, covering an area of 0.53 deg 2 (see Sect. 3.3) common to both instruments and fulfilling the galaxy number density and S/N requirements detailed in Laureijs et al. (2011). Small 'dither slews' are performed between the pointings, taking 66 s.</p>
        <p>At each pointing, VIS takes an image and NISP a simultaneous spectral exposure with the red grism, both lasting about 570 s (we note that these times are not frozen yet). Once the VIS shutter is closed, the GWA and FWA move for the three NISP images of 112 s each. A 2 s margin is allocated between the end of a NISP exposure and the wheel actuation, ensuring the NISP exposure is completed before the wheel is moving to avoid compromising the last frame. Moreover, a stabilisation time of 10 s is considered between a wheel movement and the following exposure. During the NISP imaging, VIS takes biases, flats, and other calibration frames; these 'parallel' observations are highly synchronised and optimised so that the instrument operations do not interfere with each other. In addition, VIS also takes a shorter science exposure of 108 s during the H E exposure in the first pointing, in order to help with the PSF dynamic range on relatively bright stars that saturate during the standard, longer exposures. Details of these sequences are given in, for example, Cropper et al. (2016) and Maciaszek et al. (2016).At each pointing, VIS takes an image and NISP a simultaneous spectral exposure with the red grism, both lasting about 570 s (we note that these times are not frozen yet). Once the VIS shutter is closed, the GWA and FWA move for the three NISP images of 112 s each. A 2 s margin is allocated between the end of a NISP exposure and the wheel actuation, ensuring the NISP exposure is completed before the wheel is moving to avoid compromising the last frame. Moreover, a stabilisation time of 10 s is considered between a wheel movement and the following exposure. During the NISP imaging, VIS takes biases, flats, and other calibration frames; these 'parallel' observations are highly synchronised and optimised so that the instrument operations do not interfere with each other. In addition, VIS also takes a shorter science exposure of 108 s during the H E exposure in the first pointing, in order to help with the PSF dynamic range on relatively bright stars that saturate during the standard, longer exposures. Details of these sequences are given in, for example, Cropper et al. (2016) and Maciaszek et al. (2016).</p>
        <p>After each pointing a dither step is applied and a new grism position is selected. The ROS uses the RGS000 and RGS180 at two angles each, offset by four degrees, to allow for sufficient decontamination of the overlapping slitless spectra.After each pointing a dither step is applied and a new grism position is selected. The ROS uses the RGS000 and RGS180 at two angles each, offset by four degrees, to allow for sufficient decontamination of the overlapping slitless spectra.</p>
        <p>The total duration of the ROS, including dither slews and overheads is 4214 s. At the end of the ROS a slew towards the next field is performed. Most of these slews are small ( ≤ 3 • .6) and referred to as 'field slews'. The slew duration is a function of the (eigen-) angular rotation. On average it is 182 s, implying a total length of 4396 s for the ROS (slews included). This is less than the upper limit of 4400 s as defined at mission system level during budget allocation. On occasion, the Euclid Reference Survey (ERS) requires larger slews that are limited to a maximum number of 950 over the full mission. In the most recent EWS solution (see Sect. 8), the 'large slews' comprise 1% of all nondither slews applied.The total duration of the ROS, including dither slews and overheads is 4214 s. At the end of the ROS a slew towards the next field is performed. Most of these slews are small ( ≤ 3 • .6) and referred to as 'field slews'. The slew duration is a function of the (eigen-) angular rotation. On average it is 182 s, implying a total length of 4396 s for the ROS (slews included). This is less than the upper limit of 4400 s as defined at mission system level during budget allocation. On occasion, the Euclid Reference Survey (ERS) requires larger slews that are limited to a maximum number of 950 over the full mission. In the most recent EWS solution (see Sect. 8), the 'large slews' comprise 1% of all nondither slews applied.</p>
        <p>For each field, the ROS obtains multiple exposures with dithered pointings to mitigate detector defects and cosmic rays, and to meet the required depth. The depth will vary across the field, not only because of masked defects, but predominantly because the NISP and VIS focal planes have different detector and gap sizes (see Fig. 6, and Table 1). The dithering strategy between pointings, used for the ERS, must meet the following requirements: (i) 95% of the survey area shall be covered with at least three exposures in I E . 90% of the survey area shall be covered by at least three exposures in each of the NISP bands Y E , J E , H E ; (ii) 90% of A112, page 7 of 41 A&amp;A 662, A112 (2022) each survey field shall be covered by three or more RG E spectroscopic exposures, and 50% by four or more RG E spectroscopic exposures (using different grism orientations); and (iii) the NISP imaging of the fields covered by the NISP spectroscopic channel in the EWS shall be acquired over the whole image with depth on average fainter than m AB = 24 mag for 5σ point-like source.For each field, the ROS obtains multiple exposures with dithered pointings to mitigate detector defects and cosmic rays, and to meet the required depth. The depth will vary across the field, not only because of masked defects, but predominantly because the NISP and VIS focal planes have different detector and gap sizes (see Fig. 6, and Table 1). The dithering strategy between pointings, used for the ERS, must meet the following requirements: (i) 95% of the survey area shall be covered with at least three exposures in I E . 90% of the survey area shall be covered by at least three exposures in each of the NISP bands Y E , J E , H E ; (ii) 90% of A112, page 7 of 41 A&amp;A 662, A112 (2022) each survey field shall be covered by three or more RG E spectroscopic exposures, and 50% by four or more RG E spectroscopic exposures (using different grism orientations); and (iii) the NISP imaging of the fields covered by the NISP spectroscopic channel in the EWS shall be acquired over the whole image with depth on average fainter than m AB = 24 mag for 5σ point-like source.</p>
        <p>To analyse the sky coverage of a given dither pattern, we simulated the ROS observations at the pixel level for a nearly square sky region. The latter covers several FoVs in each of the two dimensions (N × N joint FoVs, where 3 ≤ N ≤ 8) to avoid boundary effects. The pixel count statistics (number of exposures per sky area) are then computed with an integration time map calculator.To analyse the sky coverage of a given dither pattern, we simulated the ROS observations at the pixel level for a nearly square sky region. The latter covers several FoVs in each of the two dimensions (N × N joint FoVs, where 3 ≤ N ≤ 8) to avoid boundary effects. The pixel count statistics (number of exposures per sky area) are then computed with an integration time map calculator.</p>
        <p>In the various dither patterns, the minimum dither step in each of the two directions is sized so as to ensure that the slew is larger than the largest of the detector gaps in that direction (which, according to Table 1 are the NISP gaps). The maximum dither step is sized to prevent gaps of one line or row of detectors to overlap with the next gaps after the three dithers. In our simulations, we used values for the detector gaps reflecting the ones present in the as-built instruments (see Table 1). For VIS, we used 13 . 6 in the X direction, 67 . 6 in the Y direction and 0 . 4 for the width of the charge injection lines, while for NISP we used 50 in X and 100 in Y. Subsequent fields are shifted by about 0.7 • , setting in the simulation an overlapping of 1% (in area) between contiguous FoVs. This constitutes the basic set-up of our simulations.In the various dither patterns, the minimum dither step in each of the two directions is sized so as to ensure that the slew is larger than the largest of the detector gaps in that direction (which, according to Table 1 are the NISP gaps). The maximum dither step is sized to prevent gaps of one line or row of detectors to overlap with the next gaps after the three dithers. In our simulations, we used values for the detector gaps reflecting the ones present in the as-built instruments (see Table 1). For VIS, we used 13 . 6 in the X direction, 67 . 6 in the Y direction and 0 . 4 for the width of the charge injection lines, while for NISP we used 50 in X and 100 in Y. Subsequent fields are shifted by about 0.7 • , setting in the simulation an overlapping of 1% (in area) between contiguous FoVs. This constitutes the basic set-up of our simulations.</p>
        <p>The dither step size is affected by errors, namely after a dither slew there is a required absolute pointing error (APE) smaller than 7 . 5 at 3σ in both X FoV and Y FoV , for a total displacement error of 11 . Also the overlap between contiguous FoVs is also affected by APE as well. The line of sight has an uncertainty offset introduced by the rotation of the filter and grism wheels (that is compensated by the spacecraft AOCS).The dither step size is affected by errors, namely after a dither slew there is a required absolute pointing error (APE) smaller than 7 . 5 at 3σ in both X FoV and Y FoV , for a total displacement error of 11 . Also the overlap between contiguous FoVs is also affected by APE as well. The line of sight has an uncertainty offset introduced by the rotation of the filter and grism wheels (that is compensated by the spacecraft AOCS).</p>
        <p>We produce coverage maps in two ways. The first method is deterministic (method D). In this case, we consider the basic set-up and add a deterministic small shift (of 11 ) to each step of the dithering pattern. The implementation of this further displacement is necessary to be safe in filling the gaps when considering the estimate of the uncertainties in the dithering step. No random errors are considered in this method. In the second method, the Monte Carlo (MC) method, we consider uncertainties on dithering steps and directions (a pointing error of 11 at 3σ), on off-set repeatability, and other relevant parameters. In this method, the actual overlapping between contiguous FoVs is affected by the APE uncertainty; we simulate an APE with a Gaussian random amplitude of 3 . 5 at 1σ and uniform random orientation. Monte Carlo iterations are then run on a representative patch to extract the coverage maps and the statistics of pixel numbers for the desired area inside the simulated patch for each of the dither patterns presented in Sects. 4.2.1 and 4.2.2.We produce coverage maps in two ways. The first method is deterministic (method D). In this case, we consider the basic set-up and add a deterministic small shift (of 11 ) to each step of the dithering pattern. The implementation of this further displacement is necessary to be safe in filling the gaps when considering the estimate of the uncertainties in the dithering step. No random errors are considered in this method. In the second method, the Monte Carlo (MC) method, we consider uncertainties on dithering steps and directions (a pointing error of 11 at 3σ), on off-set repeatability, and other relevant parameters. In this method, the actual overlapping between contiguous FoVs is affected by the APE uncertainty; we simulate an APE with a Gaussian random amplitude of 3 . 5 at 1σ and uniform random orientation. Monte Carlo iterations are then run on a representative patch to extract the coverage maps and the statistics of pixel numbers for the desired area inside the simulated patch for each of the dither patterns presented in Sects. 4.2.1 and 4.2.2.</p>
        <p>The dither pattern defined in Laureijs et al. (2011) was minimal in the sense that it only respected the stringent constraints on the size of a dither step. The latter is constrained to a minimum of 100 by the reaction wheels to prevent mechanical damage to wheel ball bearings in small rotation regime, and to a maximum of 396 by the size of the star catalogue available to the AOCS. The theoretical pattern (referred to as a 'J' pattern given its shape; see Fig. 9) is defined as follows, starting from the pointing of the first exposure: (i) dither step 1: ∆X SC = 50 , Fig. 9. Seven dither patterns that we have analysed shown in the spacecraft reference frame (see Fig. 2). For clarity, a shift of 5 (or of -5 ) in the Xsc direction is applied to the 'J' (or to the 'N') pattern in the figure so as to distinguish it from the 'S' pattern. Only the 'J' and the 'S' patterns, the first two steps of which are identical, are fully compliant with the stringent survey requirements.The dither pattern defined in Laureijs et al. (2011) was minimal in the sense that it only respected the stringent constraints on the size of a dither step. The latter is constrained to a minimum of 100 by the reaction wheels to prevent mechanical damage to wheel ball bearings in small rotation regime, and to a maximum of 396 by the size of the star catalogue available to the AOCS. The theoretical pattern (referred to as a 'J' pattern given its shape; see Fig. 9) is defined as follows, starting from the pointing of the first exposure: (i) dither step 1: ∆X SC = 50 , Fig. 9. Seven dither patterns that we have analysed shown in the spacecraft reference frame (see Fig. 2). For clarity, a shift of 5 (or of -5 ) in the Xsc direction is applied to the 'J' (or to the 'N') pattern in the figure so as to distinguish it from the 'S' pattern. Only the 'J' and the 'S' patterns, the first two steps of which are identical, are fully compliant with the stringent survey requirements.</p>
        <p>∆Y SC = 100 ; (ii) dither step 2: ∆X SC = 0 , ∆Y SC = 100 ; (iii) dither step 3: ∆X SC = 0 , ∆Y SC = 100 .∆Y SC = 100 ; (ii) dither step 2: ∆X SC = 0 , ∆Y SC = 100 ; (iii) dither step 3: ∆X SC = 0 , ∆Y SC = 100 .</p>
        <p>These are the minimum values that need to be ensured by the AOCS. As discussed earlier, in order to account for the error in the dithering step, the dither is commanded to be 11 larger than the minimum step.These are the minimum values that need to be ensured by the AOCS. As discussed earlier, in order to account for the error in the dithering step, the dither is commanded to be 11 larger than the minimum step.</p>
        <p>In method D, uncertainties in the telescope pointing were not considered. In total, we simulated 3 × 3 joint FoVs (i.e. nine adjacent executions of the ROS). For a simple visualisation of the integration time map, we simulated the sky coverage with the resolution of the VIS and NISP FPAs degraded to 1 . The width of the VIS charge injection lines were increased to 1 to be included in the simulation. The top panels in Fig. 10 show, for VIS and NISP, the central 50 .0 × 56 .7 of the 'J' integration time map, that is, a single survey field and its boundaries (containing 10 7 simulated pixels).In method D, uncertainties in the telescope pointing were not considered. In total, we simulated 3 × 3 joint FoVs (i.e. nine adjacent executions of the ROS). For a simple visualisation of the integration time map, we simulated the sky coverage with the resolution of the VIS and NISP FPAs degraded to 1 . The width of the VIS charge injection lines were increased to 1 to be included in the simulation. The top panels in Fig. 10 show, for VIS and NISP, the central 50 .0 × 56 .7 of the 'J' integration time map, that is, a single survey field and its boundaries (containing 10 7 simulated pixels).</p>
        <p>In the MC method, the statistics on the number of exposures per map pixel were evaluated with the same tool, but now considering random errors on some pointing parameters. We simulated a larger sky area (7 × 7 joint FoVs) to allow a corresponding increase in the number of realisations and a better characterisation of the overlapping regions between the FoVs. Here, we adopted a resolution of 0 . 2 to accurately quantify the effect of the finer geometric characteristics of the VIS and NISP FoVs. Statistics extracted for areas of different sizes (for example of 4 • .0 × 4 • .0) around the central joint FoV show that the coverage requirements are fulfilled at a global level. On a field-tofield basis, the coverage can vary within the associated standard deviations.In the MC method, the statistics on the number of exposures per map pixel were evaluated with the same tool, but now considering random errors on some pointing parameters. We simulated a larger sky area (7 × 7 joint FoVs) to allow a corresponding increase in the number of realisations and a better characterisation of the overlapping regions between the FoVs. Here, we adopted a resolution of 0 . 2 to accurately quantify the effect of the finer geometric characteristics of the VIS and NISP FoVs. Statistics extracted for areas of different sizes (for example of 4 • .0 × 4 • .0) around the central joint FoV show that the coverage requirements are fulfilled at a global level. On a field-tofield basis, the coverage can vary within the associated standard deviations.</p>
        <p>Looking for a potentially better dither pattern, we analysed six other patterns with four vertices (Fig. 9). Two cases were proposed by Arendt, Kashlinski, and Mosley based on previous experience (priv. comm.; labelled as AKM2 and AKM3), and four cases ('S', 'R', 'N', and 'X') were taken from A112, page 8 of 41 Table 2. Statistics (mean and standard deviation) on the number, X, of exposures per pixel for the 'S' dither pattern: percentages of covering for individual (X = 0, 1, 2, 3, 4) and cumulative (X &gt; 4, X ≥ 3, X ≥ 4) bins. The two AKM patterns exceed the maximum step size, with only AKM3 satisfying the constraint on the joint visibility. Among the four possibilities suggested in Markovič et al. (2017), only the 'S' pattern, which is the one closest to the reference 'J', meets all constraints. Its statistics on the number of exposures per pixel derived from simulations performed considering the most relevant sources of uncertainty are given in Table 2. The 'S' pattern improves, particularly for NISP, upon the 'J' pattern, decreasing the fraction of pixels with a single The red frame is the first to be observed, and the dots mark the centre of each frame. We note how the pattern on the sky is invariant if the telescope is flipped. exposure (from 0.59% to 0.23% in the case of VIS and from 3.47% to 0.99% in the case of NISP) while increasing the fraction of pixels with two exposures (from 3.91% to 4.34% in the case of VIS and from 4.79% to 8.13% in the case of NISP). For the 'S' pattern, the percentages of X ≥ 3 covering are 95.43 ± 0.03 and 90.88 ± 0.05 for VIS and NISP, respectively, while the percentage of X ≥ 4 covering for NISP is 50.42 ± 0.06 (the statistics reported in Table 2 are extracted from 500 realisations). Thus, at least under the considered uncertainty in specifications, the requirement 1 of Sect. 4.2 for VIS and NISP imaging is satisfied at ∼14.3σ level and at ∼17.6σ level, respectively, while the requirement 2 of Sect. 4.2 for NISP spectroscopy is satisfied at ∼17.6σ level and at ∼7σ level for the X ≥ 3 covering and X ≥ 4 covering, respectively. We note that the standard deviation of the cumulative case (X ≥ 3 or X ≥ 4) covering cannot be derived by a simple analytical propagation of the standard deviations of simpler cases because of the presence of mutual correlations. These, however, are taken into account in the numerical simulation.Looking for a potentially better dither pattern, we analysed six other patterns with four vertices (Fig. 9). Two cases were proposed by Arendt, Kashlinski, and Mosley based on previous experience (priv. comm.; labelled as AKM2 and AKM3), and four cases ('S', 'R', 'N', and 'X') were taken from A112, page 8 of 41 Table 2. Statistics (mean and standard deviation) on the number, X, of exposures per pixel for the 'S' dither pattern: percentages of covering for individual (X = 0, 1, 2, 3, 4) and cumulative (X &gt; 4, X ≥ 3, X ≥ 4) bins. The two AKM patterns exceed the maximum step size, with only AKM3 satisfying the constraint on the joint visibility. Among the four possibilities suggested in Markovič et al. (2017), only the 'S' pattern, which is the one closest to the reference 'J', meets all constraints. Its statistics on the number of exposures per pixel derived from simulations performed considering the most relevant sources of uncertainty are given in Table 2. The 'S' pattern improves, particularly for NISP, upon the 'J' pattern, decreasing the fraction of pixels with a single The red frame is the first to be observed, and the dots mark the centre of each frame. We note how the pattern on the sky is invariant if the telescope is flipped. exposure (from 0.59% to 0.23% in the case of VIS and from 3.47% to 0.99% in the case of NISP) while increasing the fraction of pixels with two exposures (from 3.91% to 4.34% in the case of VIS and from 4.79% to 8.13% in the case of NISP). For the 'S' pattern, the percentages of X ≥ 3 covering are 95.43 ± 0.03 and 90.88 ± 0.05 for VIS and NISP, respectively, while the percentage of X ≥ 4 covering for NISP is 50.42 ± 0.06 (the statistics reported in Table 2 are extracted from 500 realisations). Thus, at least under the considered uncertainty in specifications, the requirement 1 of Sect. 4.2 for VIS and NISP imaging is satisfied at ∼14.3σ level and at ∼17.6σ level, respectively, while the requirement 2 of Sect. 4.2 for NISP spectroscopy is satisfied at ∼17.6σ level and at ∼7σ level for the X ≥ 3 covering and X ≥ 4 covering, respectively. We note that the standard deviation of the cumulative case (X ≥ 3 or X ≥ 4) covering cannot be derived by a simple analytical propagation of the standard deviations of simpler cases because of the presence of mutual correlations. These, however, are taken into account in the numerical simulation.</p>
        <p>The 'S' pattern was therefore chosen as the baseline dither pattern for the ERS (see also Markovič et al. 2017). The coverage map is shown in the bottom panels of Fig. 10, and in Fig. 11 we display the 'S' pattern as it appears on sky. It is defined as follows: (i) dither step 1: ∆X sc = 50 , ∆Y sc = 100 ; (ii) dither step 2: ∆X sc = 0 , ∆Y sc = 100 ; (iii) dither step 3: ∆X sc = 50 , ∆Y sc = 100 . However, the random errors present in pointing could cause the actual shifts to be smaller than nominal and so be insufficient to cover the gaps. Therefore, in order to be on the conservative side, to each move of this nominal 'S' pattern a buffer of 11 is added to each ∆X sc and ∆Y sc , resulting in the operational 'S' which has: (i) dither step 1: ∆X sc = 61 , ∆Y sc = 111 ; (ii) dither step 2: ∆X sc = 11 , ∆Y sc = 111 ; (iii) dither step 3: ∆X sc = 61 , ∆Y sc = 111 . We note that while the latter sequence has been used in the simulations to get the statistics presented in Table 2, the ERS presented in Sect. 8 was built with the nominal 'S' pattern.The 'S' pattern was therefore chosen as the baseline dither pattern for the ERS (see also Markovič et al. 2017). The coverage map is shown in the bottom panels of Fig. 10, and in Fig. 11 we display the 'S' pattern as it appears on sky. It is defined as follows: (i) dither step 1: ∆X sc = 50 , ∆Y sc = 100 ; (ii) dither step 2: ∆X sc = 0 , ∆Y sc = 100 ; (iii) dither step 3: ∆X sc = 50 , ∆Y sc = 100 . However, the random errors present in pointing could cause the actual shifts to be smaller than nominal and so be insufficient to cover the gaps. Therefore, in order to be on the conservative side, to each move of this nominal 'S' pattern a buffer of 11 is added to each ∆X sc and ∆Y sc , resulting in the operational 'S' which has: (i) dither step 1: ∆X sc = 61 , ∆Y sc = 111 ; (ii) dither step 2: ∆X sc = 11 , ∆Y sc = 111 ; (iii) dither step 3: ∆X sc = 61 , ∆Y sc = 111 . We note that while the latter sequence has been used in the simulations to get the statistics presented in Table 2, the ERS presented in Sect. 8 was built with the nominal 'S' pattern.</p>
        <p>We note that by increasing the number of dithers and their step size, a more uniform coverage can be achieved (see e.g. Rowe et al. 2011). However, this needs to be balanced against the total survey area, the mission duration, readout overheads etc. Other patterns can still be studied and implemented in case of a revision of the current survey and hardware limitations.We note that by increasing the number of dithers and their step size, a more uniform coverage can be achieved (see e.g. Rowe et al. 2011). However, this needs to be balanced against the total survey area, the mission duration, readout overheads etc. Other patterns can still be studied and implemented in case of a revision of the current survey and hardware limitations.</p>
        <p>A112, page 9 of 41 A&amp;A 662, A112 (2022)A112, page 9 of 41 A&amp;A 662, A112 (2022)</p>
        <p>The constraints that drive the implementation of the Euclid survey areas fall into three main categories (see Sect. 1): (i) environmental; (ii) calibration needs; and (iii) spacecraft constraints.The constraints that drive the implementation of the Euclid survey areas fall into three main categories (see Sect. 1): (i) environmental; (ii) calibration needs; and (iii) spacecraft constraints.</p>
        <p>Environmental properties are external physical constraints of the observable sky, namely zodiacal background, Galactic extinction, foreground stellar density and blinding stars. The zodiacal background and extinction affect the S/N, as does the stray light from bright stars and Galactic plane. The star density also affects the number of useful objects, because their light is dispersed and overlaps with the galaxy spectra of interest, or affects the ability to measure shapes reliably. Moreover, an increased star density also increase the multiplicative bias in weak lensing shear estimates, if unaccounted for (Hoekstra et al. 2017).Environmental properties are external physical constraints of the observable sky, namely zodiacal background, Galactic extinction, foreground stellar density and blinding stars. The zodiacal background and extinction affect the S/N, as does the stray light from bright stars and Galactic plane. The star density also affects the number of useful objects, because their light is dispersed and overlaps with the galaxy spectra of interest, or affects the ability to measure shapes reliably. Moreover, an increased star density also increase the multiplicative bias in weak lensing shear estimates, if unaccounted for (Hoekstra et al. 2017).</p>
        <p>Together, these constraints lead to the definition of the EWS RoI, a collection of four contours enclosing two larger 'mainlands' and two smaller 'islands'. Each contour is defined by a series of joint segments derived from the zodiacal light (ecliptic latitude segment), dust extinction (Galactic caps segment), or the stellar density (Galactic latitude segment).Together, these constraints lead to the definition of the EWS RoI, a collection of four contours enclosing two larger 'mainlands' and two smaller 'islands'. Each contour is defined by a series of joint segments derived from the zodiacal light (ecliptic latitude segment), dust extinction (Galactic caps segment), or the stellar density (Galactic latitude segment).</p>
        <p>The cosmological measurements are strongly mediated by the nature of the areas of the sky selected for the survey. In the following, we discuss the models of the environment used in the survey planning.The cosmological measurements are strongly mediated by the nature of the areas of the sky selected for the survey. In the following, we discuss the models of the environment used in the survey planning.</p>
        <p>A large amount of literature is available on this subject and several models and estimates have been proposed over the years. Updating previous work done by the DUNE consortium (Refregier &amp; Douspis 2008), we used a lean and conservative model of the zodiacal background obtained by combining the spectral dependence proposed by Aldering (2001) for the proposal for the SNAP satellite (Aldering et al. 2002) and the angular dependence found in Leinert et al. (1998). This 'basic' model assumes a cylindrical symmetry with respect to the Sun. In this time-invariant and symmetrical model, the zodiacal background flux density ζ depends solely on wavelength λ and ecliptic latitude β,A large amount of literature is available on this subject and several models and estimates have been proposed over the years. Updating previous work done by the DUNE consortium (Refregier &amp; Douspis 2008), we used a lean and conservative model of the zodiacal background obtained by combining the spectral dependence proposed by Aldering (2001) for the proposal for the SNAP satellite (Aldering et al. 2002) and the angular dependence found in Leinert et al. (1998). This 'basic' model assumes a cylindrical symmetry with respect to the Sun. In this time-invariant and symmetrical model, the zodiacal background flux density ζ depends solely on wavelength λ and ecliptic latitude β,</p>
        <p>For the spectral dependence, Aldering (2001) suggestsFor the spectral dependence, Aldering (2001) suggests</p>
        <p>with λ ref = 0.61 µm. The normalisation constant κ fixes the flux density to the north ecliptic pole (NEP; β = 90 • ), such that κ = 1.76 × 10 -18 erg cm -2 Å -1 arcsec -2 , corresponding to m AB = 23.05 mag arcsec -2 . For comparison, this is just 3% lower than the value given by Leinert et al. (1998) for the NEP at 0.50 µm.with λ ref = 0.61 µm. The normalisation constant κ fixes the flux density to the north ecliptic pole (NEP; β = 90 • ), such that κ = 1.76 × 10 -18 erg cm -2 Å -1 arcsec -2 , corresponding to m AB = 23.05 mag arcsec -2 . For comparison, this is just 3% lower than the value given by Leinert et al. (1998) for the NEP at 0.50 µm.</p>
        <p>For the dependence on ecliptic latitude β, we have g(|β|) as a dimensionless, monotonically decreasing function over the interval β ∈ [0 • , 90 • ], normalised to g(90 • ) = 1. Leinert et al. (1998) report values for ζ (their Table 17) as a function of β and elongation from the Sun, for a wavelength of 0.50 µm. We reproduce their values for an elongation of 90 • (applicable to Euclid) in Table 3, showing that at β = 20 • (10 • ) the zodiacal background is 2 times (3 times) higher than at the NEP. This dependence on Notes. Here, ζ is in units of 10 -8 W m -2 s -1 µm -1 sr -1 .For the dependence on ecliptic latitude β, we have g(|β|) as a dimensionless, monotonically decreasing function over the interval β ∈ [0 • , 90 • ], normalised to g(90 • ) = 1. Leinert et al. (1998) report values for ζ (their Table 17) as a function of β and elongation from the Sun, for a wavelength of 0.50 µm. We reproduce their values for an elongation of 90 • (applicable to Euclid) in Table 3, showing that at β = 20 • (10 • ) the zodiacal background is 2 times (3 times) higher than at the NEP. This dependence on Notes. Here, ζ is in units of 10 -8 W m -2 s -1 µm -1 sr -1 .</p>
        <p>latitude is in good agreement with values measured by the Solar Mass Ejection Imager (SMEI) satellite (Buffington et al. 2016).latitude is in good agreement with values measured by the Solar Mass Ejection Imager (SMEI) satellite (Buffington et al. 2016).</p>
        <p>Euclid uses fixed integration times and thus does not compensate for increased background. We therefore limit the EWS to |β| ≥ 10 • , corresponding to a reduction of 20/30% in VIS/J S/N compared to the NEP when taking into account also the stray light (see Sect. 5.1.3 and Fig. 19). This still allows for a suitable number density of detected galaxies for WL and GC averaged over the survey. This basic model results in a background that is constant in time, depends on the ecliptic latitude as in Leinert et al. (1998), and follows an exponential decay for λ ≥ 0.61 µm. In Table 4 we report corresponding numeric values and magnitudes for the various Euclid bands. Here we used the simple average wavelength of a band, defined asEuclid uses fixed integration times and thus does not compensate for increased background. We therefore limit the EWS to |β| ≥ 10 • , corresponding to a reduction of 20/30% in VIS/J S/N compared to the NEP when taking into account also the stray light (see Sect. 5.1.3 and Fig. 19). This still allows for a suitable number density of detected galaxies for WL and GC averaged over the survey. This basic model results in a background that is constant in time, depends on the ecliptic latitude as in Leinert et al. (1998), and follows an exponential decay for λ ≥ 0.61 µm. In Table 4 we report corresponding numeric values and magnitudes for the various Euclid bands. Here we used the simple average wavelength of a band, defined as</p>
        <p>where T (λ) is the end-of-life (EOL) throughput (see Fig. 7). For background-limited observations, we could instead weight the integrals in Eq. ( 4) by the background flux density; this would slightly change the values of λ * , as we will discuss in a separate paper.where T (λ) is the end-of-life (EOL) throughput (see Fig. 7). For background-limited observations, we could instead weight the integrals in Eq. ( 4) by the background flux density; this would slightly change the values of λ * , as we will discuss in a separate paper.</p>
        <p>Better fits to the dust emission detected by the COsmic Background Explorer (COBE) Differential Microwave Radiometer, can be obtained by considering more sophisticated models, such as the ones of Kelsall et al. (1998). These models include a slab model that is not centred on the ecliptic plane and add inhomogeneous clouds. These result in a zodiacal background that depends not only on the wavelength and direction of observation, but also on the observation's epoch. In such models the minimum background no longer coincides with the ecliptic poles. Instead, it circles the poles with a yearly period, and the value at the NEP has a corresponding sinusoidal variation with a 20% peak-to-peak variation (see also Pyo et al. 2012).Better fits to the dust emission detected by the COsmic Background Explorer (COBE) Differential Microwave Radiometer, can be obtained by considering more sophisticated models, such as the ones of Kelsall et al. (1998). These models include a slab model that is not centred on the ecliptic plane and add inhomogeneous clouds. These result in a zodiacal background that depends not only on the wavelength and direction of observation, but also on the observation's epoch. In such models the minimum background no longer coincides with the ecliptic poles. Instead, it circles the poles with a yearly period, and the value at the NEP has a corresponding sinusoidal variation with a 20% peak-to-peak variation (see also Pyo et al. 2012).</p>
        <p>We implemented such a model (Maris et al. 2006(Maris et al. , 2016)), which includes time dependence, differences in trailing and leading directions and possible deviations of the pointing directions from the orthogonal direction to the Sun. The model is evaluated for 10 3 random fields of the reference survey binned in ecliptic latitude, and shows scattering due to different observation epochs. It predicts for all bands on average 15-20% lower background values than the basic model, and 30% less flux at the NEP (see Fig. 12). We use this more complex model for more precise estimates done a posteriori once a reference pointing solution is obtained using the basic model as an input.We implemented such a model (Maris et al. 2006(Maris et al. , 2016)), which includes time dependence, differences in trailing and leading directions and possible deviations of the pointing directions from the orthogonal direction to the Sun. The model is evaluated for 10 3 random fields of the reference survey binned in ecliptic latitude, and shows scattering due to different observation epochs. It predicts for all bands on average 15-20% lower background values than the basic model, and 30% less flux at the NEP (see Fig. 12). We use this more complex model for more precise estimates done a posteriori once a reference pointing solution is obtained using the basic model as an input.</p>
        <p>We adopted the basic model as our baseline to define the ecliptic latitude exclusion zone presented in Sect. 5.2, because it is more conservative, whilst providing reasonable margins. This model is also the reference model adopted for Mission Performance Evaluations, and hence Euclid might detect a slightly larger number density of usable galaxies than our current predictions. We note that among the different models in the literature some could yield background values larger than the A112, page 10 of 41 R. Scaramella et al.: The Euclid Wide Survey Table 4. Normalisation of the basic zodiacal model at the average wavelength of Euclid bands (see Fig. 7).We adopted the basic model as our baseline to define the ecliptic latitude exclusion zone presented in Sect. 5.2, because it is more conservative, whilst providing reasonable margins. This model is also the reference model adopted for Mission Performance Evaluations, and hence Euclid might detect a slightly larger number density of usable galaxies than our current predictions. We note that among the different models in the literature some could yield background values larger than the A112, page 10 of 41 R. Scaramella et al.: The Euclid Wide Survey Table 4. Normalisation of the basic zodiacal model at the average wavelength of Euclid bands (see Fig. 7).</p>
        <p>[µJy arcsec -2 ] adopted basic model, because of a different normalisation (see e.g. Wright 1998).[µJy arcsec -2 ] adopted basic model, because of a different normalisation (see e.g. Wright 1998).</p>
        <p>Extinction by interstellar dust is estimated from the E(B-V) reddening maps3 produced by the Planck Collaboration XI (2014). The map's resolution of 5 is high compared to the linear size of Euclid's FoV of ∼0 • .7 ∼44 . We smoothed the map with a 2 deg wide Gaussian kernel, such that the segments of the RoI boundary that are determined by E(B -V) have a comparable smoothness as the segments determined by Galactic and ecliptic latitude.Extinction by interstellar dust is estimated from the E(B-V) reddening maps3 produced by the Planck Collaboration XI (2014). The map's resolution of 5 is high compared to the linear size of Euclid's FoV of ∼0 • .7 ∼44 . We smoothed the map with a 2 deg wide Gaussian kernel, such that the segments of the RoI boundary that are determined by E(B -V) have a comparable smoothness as the segments determined by Galactic and ecliptic latitude.</p>
        <p>To apply rigidly the original E(B -V) = 0.08 mag limit of Laureijs et al. (2011) would cause highly convoluted RoI (see Sect. 5.2) contours and holes inside the contiguous survey areas. To achieve a larger RoI with compact regions, a slightly adjusted upper limit of E(B -V) = 0.09 mag was chosen, while allow- ing local excursions up to 0.17 mag to simplify contours and avoid local holes. These settings define a first version of the Galactic exclusion zone. The introduction of the ecliptic exclusion zone (Sect. 5.1.1) in the two resulting Galactic caps, divides them into two larger mainlands and two smaller islands, as discussed in Sect. 5.2. The median value of E(B -V) over the RoI is 0.037 mag (more statistics are given in Sect. 5.2.2). This approach meets the performance requirement on mean galaxy number density, while preserving a connected survey that optimally complements ground-based data (Sect. 5.5).To apply rigidly the original E(B -V) = 0.08 mag limit of Laureijs et al. (2011) would cause highly convoluted RoI (see Sect. 5.2) contours and holes inside the contiguous survey areas. To achieve a larger RoI with compact regions, a slightly adjusted upper limit of E(B -V) = 0.09 mag was chosen, while allow- ing local excursions up to 0.17 mag to simplify contours and avoid local holes. These settings define a first version of the Galactic exclusion zone. The introduction of the ecliptic exclusion zone (Sect. 5.1.1) in the two resulting Galactic caps, divides them into two larger mainlands and two smaller islands, as discussed in Sect. 5.2. The median value of E(B -V) over the RoI is 0.037 mag (more statistics are given in Sect. 5.2.2). This approach meets the performance requirement on mean galaxy number density, while preserving a connected survey that optimally complements ground-based data (Sect. 5.5).</p>
        <p>We also use the smoothed E(B -V) to estimate the S/N in the RoI. To this end we must compute the total extinction in magnitude for an Euclid band of central wavelength λ:We also use the smoothed E(B -V) to estimate the S/N in the RoI. To this end we must compute the total extinction in magnitude for an Euclid band of central wavelength λ:</p>
        <p>Here, F obs is the observed flux and F 0 is the flux in the absence of extinction. The total extinction in the V band is quantified byHere, F obs is the observed flux and F 0 is the flux in the absence of extinction. The total extinction in the V band is quantified by</p>
        <p>1 parameterises the dust extinction in our Galaxy. We infer the extinction scaling coefficient A λ with respect to the V band from the dust extinction curves of Gordon et al. (2003) for the Euclid channels (I E , Y E , J E , H E , RG E ) based on their central wavelength. Results are given in Table 5 for the NEP with E(B -V) = 0.07 mag.1 parameterises the dust extinction in our Galaxy. We infer the extinction scaling coefficient A λ with respect to the V band from the dust extinction curves of Gordon et al. (2003) for the Euclid channels (I E , Y E , J E , H E , RG E ) based on their central wavelength. Results are given in Table 5 for the NEP with E(B -V) = 0.07 mag.</p>
        <p>The EWS allows for 15% of its area to be lost due to various effects such as dead pixels, cosmic rays, etc. This masking budget allocates 2% for bright stars and an additional 2% for their ghost images. Stars brighter than m AB ∼ 17.5 mag for VIS and 16.0 mag for NISP will saturate the detectors for the baseline integration times, and we refer to them as 'bright' stars. Due to image persistence constraints for NISP, stars with m AB ≤ 4 mag must never be present within the FoV for all three photometric bands. We also apply this rule to the VIS instrument due to stray light considerations as discussed below. In the following, we refer to both cases as 'blinding' stars. We selected A112, page 11 of 41 (Skrutskie et al. 2006). In total, there are 1034 blinding stars within the RoI (Fig. 13). 1003 of those stars were first selected through the Y &lt; 4 or J &lt; 4 or H &lt; 4 AB mag NISP criteria, and 31 stars with Y, J, H &gt; 4 mag were added through the i &lt; 4 mag VIS criteria (there are 275 i &lt; 4 mag stars within the RoI, the majority already selected through the NISP criteria). The blinding star catalog will be refined when color terms for conversion to the Euclid bands will be available. Survey fields with blinding stars will be skipped on all instruments, amounting to 3% of the RoI area. Bright (non-blinding) stars will be observed but locally masked during data reduction. The observed area lost in this way is accounted for in the pre-allocated masking budget, which does not incorporate areas skipped on purpose because of the presence of blinding stars.The EWS allows for 15% of its area to be lost due to various effects such as dead pixels, cosmic rays, etc. This masking budget allocates 2% for bright stars and an additional 2% for their ghost images. Stars brighter than m AB ∼ 17.5 mag for VIS and 16.0 mag for NISP will saturate the detectors for the baseline integration times, and we refer to them as 'bright' stars. Due to image persistence constraints for NISP, stars with m AB ≤ 4 mag must never be present within the FoV for all three photometric bands. We also apply this rule to the VIS instrument due to stray light considerations as discussed below. In the following, we refer to both cases as 'blinding' stars. We selected A112, page 11 of 41 (Skrutskie et al. 2006). In total, there are 1034 blinding stars within the RoI (Fig. 13). 1003 of those stars were first selected through the Y &lt; 4 or J &lt; 4 or H &lt; 4 AB mag NISP criteria, and 31 stars with Y, J, H &gt; 4 mag were added through the i &lt; 4 mag VIS criteria (there are 275 i &lt; 4 mag stars within the RoI, the majority already selected through the NISP criteria). The blinding star catalog will be refined when color terms for conversion to the Euclid bands will be available. Survey fields with blinding stars will be skipped on all instruments, amounting to 3% of the RoI area. Bright (non-blinding) stars will be observed but locally masked during data reduction. The observed area lost in this way is accounted for in the pre-allocated masking budget, which does not incorporate areas skipped on purpose because of the presence of blinding stars.</p>
        <p>In the following we show how stray light from stellar sources inside and outside the FoV affects the observations and dictates the RoI Galactic latitude threshold. Stray light is generated in various ways, such as reflections on mechanical structures, scattering on contaminated optical surfaces and their intrinsic surface roughness, by diffraction on the edges of mechanical parts such as baffles, spider arms, or by multiple internal reflections between optical elements. Stray light creates an additional background contribution that can be diffuse or structured (ghosts).In the following we show how stray light from stellar sources inside and outside the FoV affects the observations and dictates the RoI Galactic latitude threshold. Stray light is generated in various ways, such as reflections on mechanical structures, scattering on contaminated optical surfaces and their intrinsic surface roughness, by diffraction on the edges of mechanical parts such as baffles, spider arms, or by multiple internal reflections between optical elements. Stray light creates an additional background contribution that can be diffuse or structured (ghosts).</p>
        <p>Up to 2014, the stray light was expected to be a minor fraction of the total diffuse background (this was initially specified to be less than 20% of the zodiacal background at the NEP).Up to 2014, the stray light was expected to be a minor fraction of the total diffuse background (this was initially specified to be less than 20% of the zodiacal background at the NEP).</p>
        <p>However, with lessons learned from the Gaia mission, a study on stray light contamination was carried out by ESA and the industry for Euclid. Venancio et al. (2020) have studied the stray light aspects extending the analysis from pure in-field (dominated by the mirrors particulate contamination) to the far outof-field domain (dominated by the internal structural multiple reflections). Both can contribute significantly to the stray light level, as out-of-field stray light, though largely attenuated by diffuse scattering process, integrates over the full sky and becomes dominant when getting close to the Galactic plane. They found that particulate contamination on the mirrors will be the main contributor: stray light in some sky areas can become comparable and even exceed the local zodiacal background. Consequently, Euclid must stay clear of the Galactic plane, since sources both inside and outside the FoV (in-field and out-field stray light, respectively) contribute.However, with lessons learned from the Gaia mission, a study on stray light contamination was carried out by ESA and the industry for Euclid. Venancio et al. (2020) have studied the stray light aspects extending the analysis from pure in-field (dominated by the mirrors particulate contamination) to the far outof-field domain (dominated by the internal structural multiple reflections). Both can contribute significantly to the stray light level, as out-of-field stray light, though largely attenuated by diffuse scattering process, integrates over the full sky and becomes dominant when getting close to the Galactic plane. They found that particulate contamination on the mirrors will be the main contributor: stray light in some sky areas can become comparable and even exceed the local zodiacal background. Consequently, Euclid must stay clear of the Galactic plane, since sources both inside and outside the FoV (in-field and out-field stray light, respectively) contribute.</p>
        <p>The normalised diffusion irradiance profile (NDI; Venancio et al. 2016) describes the profile of the scattered light in the telescope focal plane for a point source at a given position either within the FoV or up to 20 • away from the optical axis. Euclid's Korsch optical design (Korsch 1972) effectively suppresses scattered light. For Euclid and its enhanced baffling (Venancio et al. 2020), in-field stray light will impact the S/N of faint galaxies from our science goal defined limit of I E = 24.5 AB mag, causing them to fall below the minimal value of S /N = 10. To ensure such a S/N level is realised through the mission science pipeline involving all the steps of data processing and signal extraction, the system team in charge of scaling the mission design built margins by adopting a conservative goal of S /N = 14 using their own internal radiometric S/N metric. The S/N of a I E = 24.5 AB mag galaxy degrades from the mission median value of 17.5 to 14 if the galaxy is at an angular separation of 6.8, 4.1, 2.5, 1. 1.0 arcmin from a bright star of I E = 4, 5, 6, 7 and 8 AB mag, respectively. The left panel in Fig. 14 illustrates the case for a I E = 4 star, the impacted area representing just 9% of the entire FoV, a truly remarkable performance made possible by the Korsch optical design. For fainter stars, of magnitude 9 and 10, the radius of S/N degradation to a level of 14 is reached at a 8 and 1.5 arcsec radius, respectively. As shown in the right panel of Fig. 14 the impact of these stars is negligible beyond the core of the PSF. The average density of the 8, 9, and 10 mag stars (Zakharov et al. 2013) over the RoI amounts to 0.6, 1.6, and 3.8 in-field stars per FoV for the VIS: their collected impact will be limited to a tenth of a percent of area loss of the Euclid FoV on average across the RoI. Accounting for the sparse 4 to 7 AB mag stars does not alter these statistics. A comparable performance is expected from the NISP as the mission design drove an NDI dominated by the telescope, not by the instruments.The normalised diffusion irradiance profile (NDI; Venancio et al. 2016) describes the profile of the scattered light in the telescope focal plane for a point source at a given position either within the FoV or up to 20 • away from the optical axis. Euclid's Korsch optical design (Korsch 1972) effectively suppresses scattered light. For Euclid and its enhanced baffling (Venancio et al. 2020), in-field stray light will impact the S/N of faint galaxies from our science goal defined limit of I E = 24.5 AB mag, causing them to fall below the minimal value of S /N = 10. To ensure such a S/N level is realised through the mission science pipeline involving all the steps of data processing and signal extraction, the system team in charge of scaling the mission design built margins by adopting a conservative goal of S /N = 14 using their own internal radiometric S/N metric. The S/N of a I E = 24.5 AB mag galaxy degrades from the mission median value of 17.5 to 14 if the galaxy is at an angular separation of 6.8, 4.1, 2.5, 1. 1.0 arcmin from a bright star of I E = 4, 5, 6, 7 and 8 AB mag, respectively. The left panel in Fig. 14 illustrates the case for a I E = 4 star, the impacted area representing just 9% of the entire FoV, a truly remarkable performance made possible by the Korsch optical design. For fainter stars, of magnitude 9 and 10, the radius of S/N degradation to a level of 14 is reached at a 8 and 1.5 arcsec radius, respectively. As shown in the right panel of Fig. 14 the impact of these stars is negligible beyond the core of the PSF. The average density of the 8, 9, and 10 mag stars (Zakharov et al. 2013) over the RoI amounts to 0.6, 1.6, and 3.8 in-field stars per FoV for the VIS: their collected impact will be limited to a tenth of a percent of area loss of the Euclid FoV on average across the RoI. Accounting for the sparse 4 to 7 AB mag stars does not alter these statistics. A comparable performance is expected from the NISP as the mission design drove an NDI dominated by the telescope, not by the instruments.</p>
        <p>In summary, for individual bright stars Euclid will skip observing tiles in which at least one of the four exposures will contain a m AB ≤ 4 mag star in any of the Euclid bands. For a handful of extremely bright stars also nearby tiles will be skipped, according to an avoidance radius for the tile centre set at a level of stray light yielding a 15% degradation in S/N (NDI model). Areas affected by in-field stars fainter than m AB = 4 mag will be masked during the data reduction phase, as well as ghosts originating from the dichroic.In summary, for individual bright stars Euclid will skip observing tiles in which at least one of the four exposures will contain a m AB ≤ 4 mag star in any of the Euclid bands. For a handful of extremely bright stars also nearby tiles will be skipped, according to an avoidance radius for the tile centre set at a level of stray light yielding a 15% degradation in S/N (NDI model). Areas affected by in-field stars fainter than m AB = 4 mag will be masked during the data reduction phase, as well as ghosts originating from the dichroic.</p>
        <p>All the stars outside the telescope FoV will also contribute globally to the background level of stray light. Their combined effect is to add a diffuse cumulative component that depends on the pointing direction of the telescope. In consequence, this effects scales with the Galactic latitude, the NDI defining an intensity ratio of the collected brightness of the Galaxy. The outfield stray light two-dimensional map adopted in this paper is a Besançon model of the Galaxy flux (Robin et al. 2012(Robin et al. , 2014)). The model is scaled at the relevant wavelength to match at the one percent level the out-field stray light level computed at 12 selected points across the whole sky. The levels were estimated by the system team for the 2018 mission critical design review (MCDR) effort.All the stars outside the telescope FoV will also contribute globally to the background level of stray light. Their combined effect is to add a diffuse cumulative component that depends on the pointing direction of the telescope. In consequence, this effects scales with the Galactic latitude, the NDI defining an intensity ratio of the collected brightness of the Galaxy. The outfield stray light two-dimensional map adopted in this paper is a Besançon model of the Galaxy flux (Robin et al. 2012(Robin et al. , 2014)). The model is scaled at the relevant wavelength to match at the one percent level the out-field stray light level computed at 12 selected points across the whole sky. The levels were estimated by the system team for the 2018 mission critical design review (MCDR) effort.</p>
        <p>A spacecraft stray light model based on the estimation of the NDI was then used by the system team to describe the stray light due to the diffusion in the telescope and gauge its effects on the PSF and local background level on the focal plane (Venancio et al. 2016(Venancio et al. , 2020)). Assuming the entrance of the telescope is illuminated by a distant point source (collimated light), then the NDI is defined as the ratio of light irradiance (power per unit area) on the image plane to the source irradiance in object space at the entrance of the telescope. The NDI is computed for both VIS and NISP using the 
            <rs type="software">ASAP</rs> optical software 4 , a ray-tracing program that uses a statistical MC approach. The computation is done with telescope and instrument optical and mechanical models and associated contamination assumptions. Then the NDI is applied on the sky for a mesh of pointing directions on the sky (with sampling equal to the Euclid FoV) over the full sky in order to estimate for each possible pointing direction the cumulative out-of-field stray light maps.
        </p>
        <p>Conservative estimates of these contaminants established by the mission system team are adopted for the background and associated noise computations presented in this paper. This drives in particular the RoI definition with respect to Galactic latitude (from a minimum of |β| ≥ 23 • to nominal |β| ≥ 25 • ), and how close the EWS can get to the Galactic bulge, refining the Galactic exclusion zone.Conservative estimates of these contaminants established by the mission system team are adopted for the background and associated noise computations presented in this paper. This drives in particular the RoI definition with respect to Galactic latitude (from a minimum of |β| ≥ 23 • to nominal |β| ≥ 25 • ), and how close the EWS can get to the Galactic bulge, refining the Galactic exclusion zone.</p>
        <p>Finally, an additional concern is that due to stray light: Euclid must avoid pointing within a circle centred on the position of Solar system planets, Mars and Jupiter having the largest radius, of 13 deg.Finally, an additional concern is that due to stray light: Euclid must avoid pointing within a circle centred on the position of Solar system planets, Mars and Jupiter having the largest radius, of 13 deg.</p>
        <p>The dominant factors that determine the RoI are the zodiacal background, the Galactic extinction, and stray light due to the Galactic stellar density. Minor contributors such as emission from Galactic cirrus were ignored, being at least five magnitudes fainter than the total background over most of the RoI (Sect. 5.3). The EWS will also skip fields containing blinding stars (Sect. 5.1.3), leaving only their faint effect imprinted on the out-field stray light.The dominant factors that determine the RoI are the zodiacal background, the Galactic extinction, and stray light due to the Galactic stellar density. Minor contributors such as emission from Galactic cirrus were ignored, being at least five magnitudes fainter than the total background over most of the RoI (Sect. 5.3). The EWS will also skip fields containing blinding stars (Sect. 5.1.3), leaving only their faint effect imprinted on the out-field stray light.</p>
        <p>The main outline of the RoI is defined by the extinction limits, an ecliptic latitude threshold of |β| ≤ 10 • , and a Galactic latitude threshold of |b| ≤ 23 • . We note that for declination δ ≥ +30 • we set |b| ≤ 25 • , since the Euclid complementary ground surveys were designed and started in 2017 with this value from Laureijs et al. (2011). Section 5.5 describes how the RoI is affected by these ground-based surveys.The main outline of the RoI is defined by the extinction limits, an ecliptic latitude threshold of |β| ≤ 10 • , and a Galactic latitude threshold of |b| ≤ 23 • . We note that for declination δ ≥ +30 • we set |b| ≤ 25 • , since the Euclid complementary ground surveys were designed and started in 2017 with this value from Laureijs et al. (2011). Section 5.5 describes how the RoI is affected by these ground-based surveys.</p>
        <p>The RoI fragments into four quadrants delimited by the yellow contours in Fig. 15 and detailed in Table 6. The RoI is best presented on this equi-rectangular projection. We use elliptical projections when highlighting aspects of area conservation. Our sky projections were produced with 
            <rs type="creator">IPAC</rs>'s 
            <rs type="software">Montage</rs> package 5 and the 
            <rs type="creator">University of Groningen</rs>'s 
            <rs type="software">Kapteyn</rs> package for Python 6 .
        </p>
        <p>The environment limits and their impact on the RoI are shown in Fig. 15, while Fig. 16 shows the distribution of extinction, stellar counts from Gaia (limited at mag = 20) and zodiacal background within the RoI. In total, the present RoI encompasses 17 354 deg 2 that are compliant for Euclid's core cosmology science. The EWS can be constructed from any 15 000 deg 2 within. Some parts of the EWS will inevitably be A112, page 13 of 41 of lower quality for cosmology, yet their legacy value is high. For example, the Small Magellanic Cloud (SMC) is inside the RoI, although clearly at odds with the survey constraints. Pushing further into the Galactic plane, though, would rapidly reach extinction levels unacceptable for Euclid's core science, as is evident from Fig. 17 that shows the combination of all constraints, highlighting the best parts of the Euclid sky.The environment limits and their impact on the RoI are shown in Fig. 15, while Fig. 16 shows the distribution of extinction, stellar counts from Gaia (limited at mag = 20) and zodiacal background within the RoI. In total, the present RoI encompasses 17 354 deg 2 that are compliant for Euclid's core cosmology science. The EWS can be constructed from any 15 000 deg 2 within. Some parts of the EWS will inevitably be A112, page 13 of 41 of lower quality for cosmology, yet their legacy value is high. For example, the Small Magellanic Cloud (SMC) is inside the RoI, although clearly at odds with the survey constraints. Pushing further into the Galactic plane, though, would rapidly reach extinction levels unacceptable for Euclid's core science, as is evident from Fig. 17 that shows the combination of all constraints, highlighting the best parts of the Euclid sky.</p>
        <p>From Fig. 17 it is clear that the area of the RoI changes with ecliptic longitude. Figure 18 shows the area of the RoI as a function of ecliptic longitude (in bins of 1 • of ecliptic longitude). The plot contains two global maxima, which coincide with the longitudes that cross both a mainland and an island, and two global minima, which coincide with the intersection of the ecliptic and Galactic planes.From Fig. 17 it is clear that the area of the RoI changes with ecliptic longitude. Figure 18 shows the area of the RoI as a function of ecliptic longitude (in bins of 1 • of ecliptic longitude). The plot contains two global maxima, which coincide with the longitudes that cross both a mainland and an island, and two global minima, which coincide with the intersection of the ecliptic and Galactic planes.</p>
        <p>Given that one degree of longitude is scanned by one day of orbit and that in one day ∼10 deg 2 of EWS are observed, in a six year mission it is only possible to observe a maximum of 60 deg 2 of EWS sky, per degree of longitude. In practice, this time must be shared with calibrations and Euclid deep field (EDF) observations that collectively take ∼20% of the total time. This lowers the EWS allocation to a maximum average value of 48 deg 2 per degree of longitude. From the analysis of Figs. 17 and 18, it is clear that the sky in the RoI is not uniform enough to fill this quota. Given the limited pointing range of the telescope, with observations at or close to transit, this inevitably leads to the depletion of the available (i.e. yet unobserved) sky in some ecliptic longitudes. This reveals an intrinsic limitation to the maximum efficiency attainable by the EWS, in which in some parts of the year there will be unallocated time periods that increase in duration towards the end of the mission. This is an important feature of EWS solutions, as discussed in Sect. 8.2.Given that one degree of longitude is scanned by one day of orbit and that in one day ∼10 deg 2 of EWS are observed, in a six year mission it is only possible to observe a maximum of 60 deg 2 of EWS sky, per degree of longitude. In practice, this time must be shared with calibrations and Euclid deep field (EDF) observations that collectively take ∼20% of the total time. This lowers the EWS allocation to a maximum average value of 48 deg 2 per degree of longitude. From the analysis of Figs. 17 and 18, it is clear that the sky in the RoI is not uniform enough to fill this quota. Given the limited pointing range of the telescope, with observations at or close to transit, this inevitably leads to the depletion of the available (i.e. yet unobserved) sky in some ecliptic longitudes. This reveals an intrinsic limitation to the maximum efficiency attainable by the EWS, in which in some parts of the year there will be unallocated time periods that increase in duration towards the end of the mission. This is an important feature of EWS solutions, as discussed in Sect. 8.2.</p>
        <p>Figure 17 highlights the best parts of the Euclid sky. In the following, we compute the corresponding S/N maps, which provide the quantitative context.Figure 17 highlights the best parts of the Euclid sky. In the following, we compute the corresponding S/N maps, which provide the quantitative context.</p>
        <p>For our S/N computations we take into account the following aspects at the hardware level: telescope and instruments' internal backgrounds, photometric zero points (encoding the total throughput), read noise and dark current. These are independent of sky position and were taken from the latest available ground characterisation measurements. At the environmental level, we include all-sky maps for the zodiacal background, extinction, and stray light from the Galaxy as detailed in Sect. 5.1.For our S/N computations we take into account the following aspects at the hardware level: telescope and instruments' internal backgrounds, photometric zero points (encoding the total throughput), read noise and dark current. These are independent of sky position and were taken from the latest available ground characterisation measurements. At the environmental level, we include all-sky maps for the zodiacal background, extinction, and stray light from the Galaxy as detailed in Sect. 5.1.</p>
        <p>At the operational level, we allow for three exposures (VIS and NISP imaging) and four exposures for NISP spectroscopy, the FPA geometries, integration times, and the size of the measurement apertures. This is motivated by the fact that 90% (50%) of the survey area is covered with at least three (four) imaging exposures (see Table 1). The S/N measurement metrics are evaluated as follows: for VIS, we consider an extended source with a total magnitude of I E = 24.5 AB mag in a 1 . 3 diameter aperture, capturing 94% of the flux. For NISP photometry, we consider a point-like source with a total magnitude of m AB = 24.0 mag in the Y E , J E , H E bands in a 0 . 9 × 0 . 9 (3 × 3 pixel) aperture, capturing ∼80% of the flux for Y E and J E , 70% for H E . For NISP spectroscopy, we consider an emission line with a flux of 2 × 10 -16 erg s -1 cm -2 at an observed wavelength of 1600 nm, measured in a 4 × 4 pixel wide aperture in the dispersed images. In this way we verify that the scientific requirements of the Euclid project are met. Global statistics of the S/N are summarised in Table 7. The median survey depths converted and scaled to a 5σ point-like source (5σ point-like source) performance metric for imaging are listed.At the operational level, we allow for three exposures (VIS and NISP imaging) and four exposures for NISP spectroscopy, the FPA geometries, integration times, and the size of the measurement apertures. This is motivated by the fact that 90% (50%) of the survey area is covered with at least three (four) imaging exposures (see Table 1). The S/N measurement metrics are evaluated as follows: for VIS, we consider an extended source with a total magnitude of I E = 24.5 AB mag in a 1 . 3 diameter aperture, capturing 94% of the flux. For NISP photometry, we consider a point-like source with a total magnitude of m AB = 24.0 mag in the Y E , J E , H E bands in a 0 . 9 × 0 . 9 (3 × 3 pixel) aperture, capturing ∼80% of the flux for Y E and J E , 70% for H E . For NISP spectroscopy, we consider an emission line with a flux of 2 × 10 -16 erg s -1 cm -2 at an observed wavelength of 1600 nm, measured in a 4 × 4 pixel wide aperture in the dispersed images. In this way we verify that the scientific requirements of the Euclid project are met. Global statistics of the S/N are summarised in Table 7. The median survey depths converted and scaled to a 5σ point-like source (5σ point-like source) performance metric for imaging are listed.</p>
        <p>The resulting S/N maps for VIS and NISP are shown on Fig. 19. All four quadrants are fully green, within specifications, for all channels for their respective depth metrics.The resulting S/N maps for VIS and NISP are shown on Fig. 19. All four quadrants are fully green, within specifications, for all channels for their respective depth metrics.</p>
        <p>We note that the S/N computations do not consider the contamination of galaxy samples by stars; to this end we introduced the thresholds to Galactic latitude. The greyed areas in Fig. 19 illustrate where a certain component (such as extinction) is out of range. These may appear inside the RoI (e.g. at the location of the SMC). Non greyed areas outside the RoI reflect an evolution of the criteria that led to the RoI definition, for example by tightening the Galactic latitude threshold from |b| ≥ 23 • to |b| ≥ 25 • after the northern ground-based surveys had been defined for |b| ≥ 25 • .We note that the S/N computations do not consider the contamination of galaxy samples by stars; to this end we introduced the thresholds to Galactic latitude. The greyed areas in Fig. 19 illustrate where a certain component (such as extinction) is out of range. These may appear inside the RoI (e.g. at the location of the SMC). Non greyed areas outside the RoI reflect an evolution of the criteria that led to the RoI definition, for example by tightening the Galactic latitude threshold from |b| ≥ 23 • to |b| ≥ 25 • after the northern ground-based surveys had been defined for |b| ≥ 25 • .</p>
        <p>Our more complex zodiacal model (Sect. 5.1.1) predicts a lower background that varies with time and position along the orbit. This modulation happens at a level far below the typical range of zodiacal background within the RoI (Fig. 12), and hence we do not expect the median performance to change with this model.Our more complex zodiacal model (Sect. 5.1.1) predicts a lower background that varies with time and position along the orbit. This modulation happens at a level far below the typical range of zodiacal background within the RoI (Fig. 12), and hence we do not expect the median performance to change with this model.</p>
        <p>In summary, Fig. 19 shows that the S/N in the VIS band exceeds the requirement of S /N ≥ 10 over the whole RoI, with a median value of nearly 16. This gain is mostly related to longer than required integration times, driven by the needs of the spectroscopic channel. Likewise, the Y JH photometric data are well above the S /N ≥ 5 requirement. A negligible area (less than 50 deg 2 ) of the NISP spectroscopy is below the S /N ≥ 3.5 requirement (Fig. 19 spectroscopy is 4.5, a comfortable margin. Hence all specifications are exceeded, and on average Euclid will go deeper than initially planned.In summary, Fig. 19 shows that the S/N in the VIS band exceeds the requirement of S /N ≥ 10 over the whole RoI, with a median value of nearly 16. This gain is mostly related to longer than required integration times, driven by the needs of the spectroscopic channel. Likewise, the Y JH photometric data are well above the S /N ≥ 5 requirement. A negligible area (less than 50 deg 2 ) of the NISP spectroscopy is below the S /N ≥ 3.5 requirement (Fig. 19 spectroscopy is 4.5, a comfortable margin. Hence all specifications are exceeded, and on average Euclid will go deeper than initially planned.</p>
        <p>The areas of sky where the largest S/N can be achieved on average are offset from the ecliptic poles due to the out of field stray light from the Galaxy and the Large Magellanic Cloud (LMC). The S/N in these areas is close to the maximum values listed in Table 7. Figure 20 shows yellow and orange filled areas that were derived from an average of the VIS, Y, J and H S/N maps. The boundaries have been smoothed in this representation. The areas shown in yellow represent the best 1300 deg 2 in each Galactic cap (or celestial hemisphere), and the orange area the best 2600 deg 2 (including the yellow area). The EWS seeks to cover these best areas first.The areas of sky where the largest S/N can be achieved on average are offset from the ecliptic poles due to the out of field stray light from the Galaxy and the Large Magellanic Cloud (LMC). The S/N in these areas is close to the maximum values listed in Table 7. Figure 20 shows yellow and orange filled areas that were derived from an average of the VIS, Y, J and H S/N maps. The boundaries have been smoothed in this representation. The areas shown in yellow represent the best 1300 deg 2 in each Galactic cap (or celestial hemisphere), and the orange area the best 2600 deg 2 (including the yellow area). The EWS seeks to cover these best areas first.</p>
        <p>As described above, we have a complete knowledge of the background reaching Euclid's focal planes. Similarly to what we did for faint compact sources, we can derive the detection performance for diffuse emission such as non-resolved stellar populations in tidal streams of galaxies, intracluster light, and the cosmic infrared background (CIB). In the following, we do this considering the same noise properties as before, assuming a stack of three exposures for both VIS and NISP, as this applies to the 90% level coverage of the imaging survey (see Sect. 4).As described above, we have a complete knowledge of the background reaching Euclid's focal planes. Similarly to what we did for faint compact sources, we can derive the detection performance for diffuse emission such as non-resolved stellar populations in tidal streams of galaxies, intracluster light, and the cosmic infrared background (CIB). In the following, we do this considering the same noise properties as before, assuming a stack of three exposures for both VIS and NISP, as this applies to the 90% level coverage of the imaging survey (see Sect. 4).</p>
        <p>We use the limiting surface brightness metric adopted by Mihos et al. (2013), which is based on the asinh magnitude introduced by Lupton et al. (1999). This conservative metric is a good description of the actual signal properties at very low σ-levels relevant for such science. It has the merit of reflecting an actual science performance: the determination of the light profile of Messier 101 down to a surface brightness of µ B = 29.5 mag arcsec -2 corresponds to the 1σ limit in the Mihos et al. (2013) study. At 1σ, the asinh magnitude is 0.5 mag smaller than the corresponding standard magnitude. This limiting surface brightness is computed directly from the photometric zero point of the system and the background noise property from our S/N study. Because of the very limited contamination of bright stars (see Sect. 5.1.3) here we only need to consider the diffuse A112, page 16 of 41 background. The limiting surface brightness expressed at the pixel scale isWe use the limiting surface brightness metric adopted by Mihos et al. (2013), which is based on the asinh magnitude introduced by Lupton et al. (1999). This conservative metric is a good description of the actual signal properties at very low σ-levels relevant for such science. It has the merit of reflecting an actual science performance: the determination of the light profile of Messier 101 down to a surface brightness of µ B = 29.5 mag arcsec -2 corresponds to the 1σ limit in the Mihos et al. (2013) study. At 1σ, the asinh magnitude is 0.5 mag smaller than the corresponding standard magnitude. This limiting surface brightness is computed directly from the photometric zero point of the system and the background noise property from our S/N study. Because of the very limited contamination of bright stars (see Sect. 5.1.3) here we only need to consider the diffuse A112, page 16 of 41 background. The limiting surface brightness expressed at the pixel scale is</p>
        <p>where, at the native resolution, ZP is the photometric zero point in electrons per second; b is the noise per pixel in the image, assumed to be the Poisson standard deviation of the background counts per pixel, B (i.e. b = √ B; a = 2.5 log 10 (e) = 1.08574); and f is the level in electrons per pixel of the extended astronomical source.where, at the native resolution, ZP is the photometric zero point in electrons per second; b is the noise per pixel in the image, assumed to be the Poisson standard deviation of the background counts per pixel, B (i.e. b = √ B; a = 2.5 log 10 (e) = 1.08574); and f is the level in electrons per pixel of the extended astronomical source.</p>
        <p>Given Euclid's small plate scales (0 . 1 and 0 . 3 pixel -1 for VIS and NISP, respectively), the depth metric relation must be brought to the physical scale of common features encountered in the near-field (galaxies, streams, shells, dwarfs, etc): we adopt a generic 10 × 10 scale while conforming to the standard performance unit for extended emissions in magnitude per square arcsecond. We shift from the pixel scale to our scale of interest considering a square area of n native pixels on the side. By averaging over the larger area, the estimate for the noise is scaled down by a factor √ n × n while the zero point gets shifted by -2.5 log 10 (n × n) for flux conservation. Scaling to the magnitude per square arcsecond unit adds -2.5 log 10 (p), with p the area of the native pixel in square arcsecond (0.01 for VIS, 0.09 for NISP). For the adopted 10 × 10 scale (n = 100 for VIS, 33.33 for NISP) the combined effects on the limiting surface brightness amount to -2.5 log 10 (1/(0.01 × 100)) = 0 for VIS, and -2.5 log 10 (1/(0.09 × 33.33)) = +1.193 for NISP (the larger the physical scale, the lower the noise and the greater the performance).Given Euclid's small plate scales (0 . 1 and 0 . 3 pixel -1 for VIS and NISP, respectively), the depth metric relation must be brought to the physical scale of common features encountered in the near-field (galaxies, streams, shells, dwarfs, etc): we adopt a generic 10 × 10 scale while conforming to the standard performance unit for extended emissions in magnitude per square arcsecond. We shift from the pixel scale to our scale of interest considering a square area of n native pixels on the side. By averaging over the larger area, the estimate for the noise is scaled down by a factor √ n × n while the zero point gets shifted by -2.5 log 10 (n × n) for flux conservation. Scaling to the magnitude per square arcsecond unit adds -2.5 log 10 (p), with p the area of the native pixel in square arcsecond (0.01 for VIS, 0.09 for NISP). For the adopted 10 × 10 scale (n = 100 for VIS, 33.33 for NISP) the combined effects on the limiting surface brightness amount to -2.5 log 10 (1/(0.01 × 100)) = 0 for VIS, and -2.5 log 10 (1/(0.09 × 33.33)) = +1.193 for NISP (the larger the physical scale, the lower the noise and the greater the performance).</p>
        <p>We can now explore the Euclid RoI at the asinh 1σ level ( f = b). The result is a map of limiting surface brightness for each band. The VIS and NISP maps show essentially the same structures (shape, amplitude, location), and in Fig. 21 they are combined in a single map (see the colour bar for the amplitudes in I E and J E band). The maximum range from the best area to the worst, at the ecliptic plane limit, is ∼0.4 mag arcsec -2 , corresponding to the total background level ratio of 2.25 between these best and worst areas. The median limiting surface brightness across the four bands over the RoI is: 4, H E = 28.4 AB mag arcsec -2 , 1σ asinh magnitude at the 10 × 10 scale (-0.25 mag for the minimum performance, +0.15 mag for the maximum over the RoI). We note that our various background components are conservative estimates and these levels can be considered a safe performance. Our more complex zodiacal background model presented in Sect. 5.1.1 indicates how intensity varies with time and position along the orbit. This will in consequence modulate the total background, hence the depth, although at a level lower than the 0.4 mag range depth seen here over the RoI (Fig. 12). The median performance is not expected to change. We also note that a depth metric based on the integrated Sersic radial profile over a whole galaxy, digging deep into the noise, typically adds at least two magnitudes with respect to this contrast-oriented metric. This is taking particularly into account Euclid's pristine image quality that will enable an effective masking of the foreground and background compact sources.We can now explore the Euclid RoI at the asinh 1σ level ( f = b). The result is a map of limiting surface brightness for each band. The VIS and NISP maps show essentially the same structures (shape, amplitude, location), and in Fig. 21 they are combined in a single map (see the colour bar for the amplitudes in I E and J E band). The maximum range from the best area to the worst, at the ecliptic plane limit, is ∼0.4 mag arcsec -2 , corresponding to the total background level ratio of 2.25 between these best and worst areas. The median limiting surface brightness across the four bands over the RoI is: 4, H E = 28.4 AB mag arcsec -2 , 1σ asinh magnitude at the 10 × 10 scale (-0.25 mag for the minimum performance, +0.15 mag for the maximum over the RoI). We note that our various background components are conservative estimates and these levels can be considered a safe performance. Our more complex zodiacal background model presented in Sect. 5.1.1 indicates how intensity varies with time and position along the orbit. This will in consequence modulate the total background, hence the depth, although at a level lower than the 0.4 mag range depth seen here over the RoI (Fig. 12). The median performance is not expected to change. We also note that a depth metric based on the integrated Sersic radial profile over a whole galaxy, digging deep into the noise, typically adds at least two magnitudes with respect to this contrast-oriented metric. This is taking particularly into account Euclid's pristine image quality that will enable an effective masking of the foreground and background compact sources.</p>
        <p>For an illustration of the scientific potential, the map in Fig. 21 features the nearby extra-galactic Universe up to a redshift of z = 0.03: more than 10 000 bright (K-band magnitude &lt;12) galaxies (2MRS catalogue; Huchra et al. 2012), including several members from the Local Group, and four nearby clusters of galaxies all falling within the Euclid RoI (some additional targets that are located outside the RoI might be observed during the unallocated time; see Sect. 8.2). The three EDFs are shown in yellow on the map of Fig. 21. They are designed to be +2 mag deeper than the EWS for compact sources, but the gain in depth is comparable for the diffuse emission (for specific details, see our companion paper on the EDFs, [Sc23]).For an illustration of the scientific potential, the map in Fig. 21 features the nearby extra-galactic Universe up to a redshift of z = 0.03: more than 10 000 bright (K-band magnitude &lt;12) galaxies (2MRS catalogue; Huchra et al. 2012), including several members from the Local Group, and four nearby clusters of galaxies all falling within the Euclid RoI (some additional targets that are located outside the RoI might be observed during the unallocated time; see Sect. 8.2). The three EDFs are shown in yellow on the map of Fig. 21. They are designed to be +2 mag deeper than the EWS for compact sources, but the gain in depth is comparable for the diffuse emission (for specific details, see our companion paper on the EDFs, [Sc23]).</p>
        <p>Such a capacity for detecting faint nebulous objects will make the diffuse galactic light (DGL; cirrus) an ubiquitous component of the background over the entire RoI as it averages to a level of 27.1 mag arcsec -2 in I E (derived from multi-band dedicated CFHT-MegaCam observations to help characterise the RoI). Based on the scaling of the DGL's albedo (Gordon 2004), we derive an average of 27.9 mag arcsec -2 over the RoI in the NISP J E band. This extra background is shown in the map in Fig. 22. We note that it is included in our derivation of the limiting surface brightness, but it has no impact since it is more than five magnitudes fainter than the combination of zodiacal background and out-field stray light. We know that structures exist in the DGL down to the arcsecond scale even at high Galactic latitude (Miville-Deschênes et al. 2016). The DGL is, however, truly diffuse over the great majority of the RoI, although as shown in Fig. 22 some parts of the Euclid sky are inevitably worse than others. The two islands of the RoI (regions II and III; see Sect. 5.2.1) correspond to the worst parts of the Euclid sky due to their proximity to the Galactic plane and a considerable presence of cirrus.Such a capacity for detecting faint nebulous objects will make the diffuse galactic light (DGL; cirrus) an ubiquitous component of the background over the entire RoI as it averages to a level of 27.1 mag arcsec -2 in I E (derived from multi-band dedicated CFHT-MegaCam observations to help characterise the RoI). Based on the scaling of the DGL's albedo (Gordon 2004), we derive an average of 27.9 mag arcsec -2 over the RoI in the NISP J E band. This extra background is shown in the map in Fig. 22. We note that it is included in our derivation of the limiting surface brightness, but it has no impact since it is more than five magnitudes fainter than the combination of zodiacal background and out-field stray light. We know that structures exist in the DGL down to the arcsecond scale even at high Galactic latitude (Miville-Deschênes et al. 2016). The DGL is, however, truly diffuse over the great majority of the RoI, although as shown in Fig. 22 some parts of the Euclid sky are inevitably worse than others. The two islands of the RoI (regions II and III; see Sect. 5.2.1) correspond to the worst parts of the Euclid sky due to their proximity to the Galactic plane and a considerable presence of cirrus.</p>
        <p>The expected counts of galaxies that satisfy the WL requirements in terms of S /N &gt; 10 (as measured by 
            <rs type="software">SourceExtractor</rs>, Bertin &amp; Arnouts 1996) and size (FWHM gal &gt; 1.25 FWHM PSF ) can be inferred using realistic image simulations. In our analysis, we used sky simulations produced with SkyLens 7 , in which the input galaxies magnitude, spectro-morphological, and redshift distributions were drawn from the HST Ultra Deep Field (HUDF). Since the HUDF is a very small field (11 square arcmin), the galaxies therein may not be representative of the mean properties of galaxies on the whole sky. Given the larger size of the Cosmic Evolution Survey (COSMOS) field, its counts are more robust. We thus corrected the HUDF counts so as to reproduce the magnitude distribution in the COSMOS field. We also estimated the S/N based on the specified throughput of the VIS instrument and including Galactic extinction and the zodiacal background. We note that these estimates are conservative because the latest throughput estimates for the VIS S/N are larger than the initially specified ones that we used.
        </p>
        <p>By simulating images under various conditions, and extracting the sources from them, the dependences of the galaxy density with extinction and background were determined, as shown in Fig. 23. The results were interpolated from each pointing to derive an estimate of the spatial map of number counts, shown in Fig. 24. These estimates are currently being updated to include stray light, which is quite dependent on the local environment of bright stars and their spectral energy distribution (SED; cf. Sect. 5.1.3), and to include the latest instrument parameters and data reduction methods.By simulating images under various conditions, and extracting the sources from them, the dependences of the galaxy density with extinction and background were determined, as shown in Fig. 23. The results were interpolated from each pointing to derive an estimate of the spatial map of number counts, shown in Fig. 24. These estimates are currently being updated to include stray light, which is quite dependent on the local environment of bright stars and their spectral energy distribution (SED; cf. Sect. 5.1.3), and to include the latest instrument parameters and data reduction methods.</p>
        <p>A similar approach was carried out for GC, where spectra were simulated, then extracted and finally measured A112, page 18 of 41 Fig. 23. Expected average number density of I E galaxies that satisfy the WL requirements (we notice that the local impact of foreground galaxies or clusters is not considered here). Upper panel: counts as a function of the local background (in mag arcsec -2 ) for different levels of E(B-V) reddening. Lower panel: counts as a function of reddening for different levels of the background. Lines are linear fits to the simulations. Fig. 24. Expected counts of WL galaxies in arcmin -2 (see text; we note that the local impact of foreground galaxies is not considered here) in ecliptic coordinates with the Galactic plane removed (black). The decrease in the number counts is evident going towards the ecliptic plane, where the zodiacal background is higher. See also Scaramella et al. (2015). (Zoubian et al. 2014), yielding a similar sky map of expected number of reliable redshifts over the sky (see Jamal et al. 2018, other methods are being developed). Figure 25 shows an updated version from the science performance verification #2 (SPV2) GC simulation (SPV is an end-to-end simulated exercise of the whole data reduction chain 8 ). As for the WL case, the GC simulations are currently being updated to include the latest estimated effects of stray light, instrument characteristics and data reduc- 8 A summary of the SPV2 exercise can be found in pages 4 and 5 of the EC newsletter at: https://www.euclid-ec.org/Documents/ Newsletter/EC-Newsletter_issue08.pdf Fig. 25. Expected counts of GC galaxies (with reliable spectroscopic redshifts) in deg -2 (see text) in ecliptic coordinates. Here the number counts decrease faster with latitude than for the WL counts (cf. Fig. 24) since the impact of stars (spectra) from our Galaxy on the GC onedimensional spectra is more severe than the impact of stars (point-like) on the two-dimensional WL data. tion procedures. We expect that the overall fraction of recovered redshifts in simulations will increase with updated models and throughput, coupled with better simulations and data reduction, since the simple but up to date estimates for spectra now yield S /N &gt; 3.5 almost everywhere (see Fig. 19). The indicative expected number of reliable redshifts of each field (used as a relative weight) as a function of time for a typical EWS (see Sect. meet the initial Euclid specification of 1700 deg -2 would require the redshifts of half of the underlying population to be reliably measured.A similar approach was carried out for GC, where spectra were simulated, then extracted and finally measured A112, page 18 of 41 Fig. 23. Expected average number density of I E galaxies that satisfy the WL requirements (we notice that the local impact of foreground galaxies or clusters is not considered here). Upper panel: counts as a function of the local background (in mag arcsec -2 ) for different levels of E(B-V) reddening. Lower panel: counts as a function of reddening for different levels of the background. Lines are linear fits to the simulations. Fig. 24. Expected counts of WL galaxies in arcmin -2 (see text; we note that the local impact of foreground galaxies is not considered here) in ecliptic coordinates with the Galactic plane removed (black). The decrease in the number counts is evident going towards the ecliptic plane, where the zodiacal background is higher. See also Scaramella et al. (2015). (Zoubian et al. 2014), yielding a similar sky map of expected number of reliable redshifts over the sky (see Jamal et al. 2018, other methods are being developed). Figure 25 shows an updated version from the science performance verification #2 (SPV2) GC simulation (SPV is an end-to-end simulated exercise of the whole data reduction chain 8 ). As for the WL case, the GC simulations are currently being updated to include the latest estimated effects of stray light, instrument characteristics and data reduc- 8 A summary of the SPV2 exercise can be found in pages 4 and 5 of the EC newsletter at: https://www.euclid-ec.org/Documents/ Newsletter/EC-Newsletter_issue08.pdf Fig. 25. Expected counts of GC galaxies (with reliable spectroscopic redshifts) in deg -2 (see text) in ecliptic coordinates. Here the number counts decrease faster with latitude than for the WL counts (cf. Fig. 24) since the impact of stars (spectra) from our Galaxy on the GC onedimensional spectra is more severe than the impact of stars (point-like) on the two-dimensional WL data. tion procedures. We expect that the overall fraction of recovered redshifts in simulations will increase with updated models and throughput, coupled with better simulations and data reduction, since the simple but up to date estimates for spectra now yield S /N &gt; 3.5 almost everywhere (see Fig. 19). The indicative expected number of reliable redshifts of each field (used as a relative weight) as a function of time for a typical EWS (see Sect. meet the initial Euclid specification of 1700 deg -2 would require the redshifts of half of the underlying population to be reliably measured.</p>
        <p>Weak lensing tomography and the need to account for the contamination by galaxy intrinsic alignments require solid estimates of the redshifts of the galaxies used as sources in the weak lensing analysis. Euclid will exploit galaxies up to a redshift of z ∼ 2 with the majority of galaxies, at the lensing goal of m VIS = 24.5, lying at a redshift z ∼ 1. A typical SED of such a galaxy is shown on the simulated spectrum of Fig. 27. The NISP depth goals (Y E , J E , H E = 24.0 AB mag; see Sect. 3.2.2) were scaled to capture the flux of this galaxy population at the required S/N for proper photometric redshift derivation. However, since the weak lensing imaging band through the broad VIS band I E does not sample key features of a z = 1 galaxy energy distribution, in particular the 4000 Å break that falls within the i band (Fig. 27), complementary bands are needed to reach the required redshift precision. The g, r, i, z bands are critical in particular, as introduced by Laureijs et al. (2011).Weak lensing tomography and the need to account for the contamination by galaxy intrinsic alignments require solid estimates of the redshifts of the galaxies used as sources in the weak lensing analysis. Euclid will exploit galaxies up to a redshift of z ∼ 2 with the majority of galaxies, at the lensing goal of m VIS = 24.5, lying at a redshift z ∼ 1. A typical SED of such a galaxy is shown on the simulated spectrum of Fig. 27. The NISP depth goals (Y E , J E , H E = 24.0 AB mag; see Sect. 3.2.2) were scaled to capture the flux of this galaxy population at the required S/N for proper photometric redshift derivation. However, since the weak lensing imaging band through the broad VIS band I E does not sample key features of a z = 1 galaxy energy distribution, in particular the 4000 Å break that falls within the i band (Fig. 27), complementary bands are needed to reach the required redshift precision. The g, r, i, z bands are critical in particular, as introduced by Laureijs et al. (2011).</p>
        <p>Large projects aiming at obtaining photometry through the Sloan bands over large parts of the sky were on the rise at the time of the Euclid mission definition. Since photometry in those bands does not require the observing conditions of a space observatory, this critical part of the mission was left for external up-and-coming photometric surveys by ground-based facilities located across the two celestial hemispheres in order to reach the entire Euclid sky. The minimal depths needed to derive photometric redshifts for the WL probe are 25.7, 25.1, 24.8, 24.6 AB mag in the g, r, i, z bands, respectively, for 5σ pointlike source. These levels were first introduced in Laureijs et al. (2011) and later on fine tuned to optimally match the SED of the z = 1 I E = 24.5 galaxy populations anchored on the Y E , J E , H E depths of 24.0 that will be achieved by Euclid.Large projects aiming at obtaining photometry through the Sloan bands over large parts of the sky were on the rise at the time of the Euclid mission definition. Since photometry in those bands does not require the observing conditions of a space observatory, this critical part of the mission was left for external up-and-coming photometric surveys by ground-based facilities located across the two celestial hemispheres in order to reach the entire Euclid sky. The minimal depths needed to derive photometric redshifts for the WL probe are 25.7, 25.1, 24.8, 24.6 AB mag in the g, r, i, z bands, respectively, for 5σ pointlike source. These levels were first introduced in Laureijs et al. (2011) and later on fine tuned to optimally match the SED of the z = 1 I E = 24.5 galaxy populations anchored on the Y E , J E , H E depths of 24.0 that will be achieved by Euclid.</p>
        <p>At the time of the mission selection in 2012, Laureijs et al. (2011) commented on ground surveys that were still speculative: only the Dark Energy Survey (DES) was about to start on its broadband imaging effort, with nearly 4500 deg 2 of its of 5000 deg 2 goal overlapping the EWS. As of the end of 2020, the now completed DES has secured in the g, r, i, z bands coverage of nearly a third of the EWS area over the south Galactic cap while the rest of the Euclid RoI is an on-going effort. Together, the following six most powerful ground-based wide-field telescopes will eventually deliver the photometry needed by Euclid across the u, g, r, i, z bands from the northern and southern hemispheres (Fig. 28), the u band being a solid bonus for photometric redshifts at any depth.At the time of the mission selection in 2012, Laureijs et al. (2011) commented on ground surveys that were still speculative: only the Dark Energy Survey (DES) was about to start on its broadband imaging effort, with nearly 4500 deg 2 of its of 5000 deg 2 goal overlapping the EWS. As of the end of 2020, the now completed DES has secured in the g, r, i, z bands coverage of nearly a third of the EWS area over the south Galactic cap while the rest of the Euclid RoI is an on-going effort. Together, the following six most powerful ground-based wide-field telescopes will eventually deliver the photometry needed by Euclid across the u, g, r, i, z bands from the northern and southern hemispheres (Fig. 28), the u band being a solid bonus for photometric redshifts at any depth.</p>
        <p>Extensive community-based actions led to the Canada-France Imaging Survey (CFIS; Ibata et al. 2017), which ought to cover by 2025 the northernmost 4800 deg 2 of the Euclid RoI in the u and r band, using 314 MegaCam nights on the 3.6 m Canada-France-Hawaii Telescope (CFHT). Spain's 2.6 m Javalambre Survey Telescope (Cenarro et al. 2018) should start in 2021 covering that area with the Javalambre-Euclid Deep Imaging Survey in the g band (JEDIS-g; 100 nights). Pan-STARRS (USA, 2 × 1.8 m telescopes, Chambers et al. 2016) joined in 2018 to provide the i band by 2025 as a result of their on-going near-Earth object (NEO) search. Finally, a group of Japanese scientists joined the Euclid Consortium in 2020 through the contribution of Subaru Hyper Suprime-Cam (HSC; Miyazaki et al. 2018) time (40 nights). WISHES (Wide Imaging with Subaru HSC of the Euclid Sky) will cover the northern area in the z band, the most demanding band in terms of depth, hence requiring an 8 m class telescope. The telescopes actively collecting data are now working in concert as part of the Ultraviolet Near-Infrared Optical Northern Survey (UNIONS), an independent consortium motivated by the shared effort for Euclid, to cover the northernmost sky over the complete set of photometric bands, with a completion date around 2025. Canadian and University of Hawaii UNIONS members launched an effort in 2019 to gather g-band data with Subaru-HSC to complement the Spanish effort. We note that since CFHT and Subaru cannot effectively observe from Hawai'i at declinations δ ≥ +80 • , the EWS RoI has been trimmed around the equatorial pole by a few tens of degrees, a minor hit since the area was already mostly rejected due to high dust extinction.Extensive community-based actions led to the Canada-France Imaging Survey (CFIS; Ibata et al. 2017), which ought to cover by 2025 the northernmost 4800 deg 2 of the Euclid RoI in the u and r band, using 314 MegaCam nights on the 3.6 m Canada-France-Hawaii Telescope (CFHT). Spain's 2.6 m Javalambre Survey Telescope (Cenarro et al. 2018) should start in 2021 covering that area with the Javalambre-Euclid Deep Imaging Survey in the g band (JEDIS-g; 100 nights). Pan-STARRS (USA, 2 × 1.8 m telescopes, Chambers et al. 2016) joined in 2018 to provide the i band by 2025 as a result of their on-going near-Earth object (NEO) search. Finally, a group of Japanese scientists joined the Euclid Consortium in 2020 through the contribution of Subaru Hyper Suprime-Cam (HSC; Miyazaki et al. 2018) time (40 nights). WISHES (Wide Imaging with Subaru HSC of the Euclid Sky) will cover the northern area in the z band, the most demanding band in terms of depth, hence requiring an 8 m class telescope. The telescopes actively collecting data are now working in concert as part of the Ultraviolet Near-Infrared Optical Northern Survey (UNIONS), an independent consortium motivated by the shared effort for Euclid, to cover the northernmost sky over the complete set of photometric bands, with a completion date around 2025. Canadian and University of Hawaii UNIONS members launched an effort in 2019 to gather g-band data with Subaru-HSC to complement the Spanish effort. We note that since CFHT and Subaru cannot effectively observe from Hawai'i at declinations δ ≥ +80 • , the EWS RoI has been trimmed around the equatorial pole by a few tens of degrees, a minor hit since the area was already mostly rejected due to high dust extinction.</p>
        <p>Meanwhile the Vera C. Rubin Observatory (USA, Ivezić et al. 2019) is approaching first light and the start of the Legacy Survey of Space and Time (LSST) should be in phase with Euclid. When on the sky, Rubin will be the most powerful wide-field imager ever built and the Euclid minimal depths in the ugriz bands will be reached within one year of normal Rubin LSST operations over the 8000 deg 2 overlapping the Euclid RoI in the southern sky; this will supersede the DES dataset. The Rubin Observatory being such a powerful machine, the Euclid Consortium is investigating with the Rubin community a northern survey extension serving various strategic Rubin scientific niches (Rhodes et al. 2017). Such an extension (3000 deg 2 of Euclid RoI area) would fill the +2 to +30 deg declination gap between the main component of the LSST and the on-going Euclid northernmost sky effort (Fig. 28).Meanwhile the Vera C. Rubin Observatory (USA, Ivezić et al. 2019) is approaching first light and the start of the Legacy Survey of Space and Time (LSST) should be in phase with Euclid. When on the sky, Rubin will be the most powerful wide-field imager ever built and the Euclid minimal depths in the ugriz bands will be reached within one year of normal Rubin LSST operations over the 8000 deg 2 overlapping the Euclid RoI in the southern sky; this will supersede the DES dataset. The Rubin Observatory being such a powerful machine, the Euclid Consortium is investigating with the Rubin community a northern survey extension serving various strategic Rubin scientific niches (Rhodes et al. 2017). Such an extension (3000 deg 2 of Euclid RoI area) would fill the +2 to +30 deg declination gap between the main component of the LSST and the on-going Euclid northernmost sky effort (Fig. 28).</p>
        <p>Euclid's three major modes of observation (VIS, NISP-P, and NISP-S) and their tight scientific requirements imply a thorough and extensive calibration programme throughout the mission, which serves two main purposes, namely the calibration of the flight hardware (instrument calibrations; see Sect. 6.1) and the characterisation of the target galaxies and quantification of any biases that may arise in the WL and GC experiments (sample characterisation; see Sect. 6.2).Euclid's three major modes of observation (VIS, NISP-P, and NISP-S) and their tight scientific requirements imply a thorough and extensive calibration programme throughout the mission, which serves two main purposes, namely the calibration of the flight hardware (instrument calibrations; see Sect. 6.1) and the characterisation of the target galaxies and quantification of any biases that may arise in the WL and GC experiments (sample characterisation; see Sect. 6.2).</p>
        <p>The hardware calibration focuses on the properties of the optics, detectors, electronics, and the opto-mechanical aspects of structural components. The associated performance regarding PSF, throughput, quantum efficiency, noise, and bias is subject to change due either to variations in operational conditions (orbit, de-pointing, on-board power dissipation) or to long-term ageing (micro meteorite pitting, particles and UV radiation damage) The optical performance is furthermore affected by contamination from material outgassing. Monitoring and accurate correction of these effects is paramount to the scientific success of Euclid and requires repeated execution of calibration observations with varying cadences.The hardware calibration focuses on the properties of the optics, detectors, electronics, and the opto-mechanical aspects of structural components. The associated performance regarding PSF, throughput, quantum efficiency, noise, and bias is subject to change due either to variations in operational conditions (orbit, de-pointing, on-board power dissipation) or to long-term ageing (micro meteorite pitting, particles and UV radiation damage) The optical performance is furthermore affected by contamination from material outgassing. Monitoring and accurate correction of these effects is paramount to the scientific success of Euclid and requires repeated execution of calibration observations with varying cadences.</p>
        <p>The hardware calibrations can be divided into on-sky (e.g. transmission) and off-sky calibrations (e.g. flat fields). The latter have the least constraints as they can be executed independently of the spacecraft's pointing; the scheduling must merely respect the required cadence within some tolerance. On-sky calibrations have the additional constraint that they must minimally disturb the thermal equilibrium of the spacecraft. To this end, a selection of targets is available, from which we choose those that optimally merge with the scientific observations.The hardware calibrations can be divided into on-sky (e.g. transmission) and off-sky calibrations (e.g. flat fields). The latter have the least constraints as they can be executed independently of the spacecraft's pointing; the scheduling must merely respect the required cadence within some tolerance. On-sky calibrations have the additional constraint that they must minimally disturb the thermal equilibrium of the spacecraft. To this end, a selection of targets is available, from which we choose those that optimally merge with the scientific observations.</p>
        <p>In the following we provide a summary of the main aspects of the calibrations that impact the building of the EWS (excluding the additional calibration data taken during the PV phase, and shorter instrumental calibrations that are integrated in the ROS; see Sect. 4.1).In the following we provide a summary of the main aspects of the calibrations that impact the building of the EWS (excluding the additional calibration data taken during the PV phase, and shorter instrumental calibrations that are integrated in the ROS; see Sect. 4.1).</p>
        <p>Quite important for hardware calibrations are the self-calibration observations, a block of about 18 h observing a field near the NEP with perennial visibility (for details about this field see [Sc23]). Besides monitoring the total system transmission, these observa-tions provide the data for a large range of additional calibration products. The self-calibration observations are scheduled eleven times per year, approximately on a monthly basis, and back-toback with a VIS non-linearity sequence of about 9 h duration.Quite important for hardware calibrations are the self-calibration observations, a block of about 18 h observing a field near the NEP with perennial visibility (for details about this field see [Sc23]). Besides monitoring the total system transmission, these observa-tions provide the data for a large range of additional calibration products. The self-calibration observations are scheduled eleven times per year, approximately on a monthly basis, and back-toback with a VIS non-linearity sequence of about 9 h duration.</p>
        <p>Another large calibration block is a sequence of VIS PSF observations lasting 20.5 h, targeting one of about a dozen stellar fields featuring a suitable range of magnitudes and SEDs, while minimising Galactic extinction and polarisation effects on the PSF ellipticity. The Euclid VIS PSF has in fact a weak dependence on polarisation of the incident light. Most fields in the EWS and EDS have low levels of Galactic polarisation at VIS wavelengths, but we must ensure that the PSF calibration fields are also selected to have low polarisation. Additional dedicated observations of polarised regions are separately planned to measure the PSF polarisation dependence, in orbit. These observations are used to routinely update and validate the VIS PSF model, and must be taken with the spacecraft in thermal equilibrium. This condition is met after about one week without large changes in the SAA and AA attitude angles (i.e. as close as possible to the values used in the preceding days of EWS observations). The VIS PSF calibration data hence need to be embedded in the currently executed EWS patch. In the global schedule (Fig. 29), the longitudes of the PSF calibration fields are marked on the top row, and the related observations are shown by the red strips within the EWS observation blocks.Another large calibration block is a sequence of VIS PSF observations lasting 20.5 h, targeting one of about a dozen stellar fields featuring a suitable range of magnitudes and SEDs, while minimising Galactic extinction and polarisation effects on the PSF ellipticity. The Euclid VIS PSF has in fact a weak dependence on polarisation of the incident light. Most fields in the EWS and EDS have low levels of Galactic polarisation at VIS wavelengths, but we must ensure that the PSF calibration fields are also selected to have low polarisation. Additional dedicated observations of polarised regions are separately planned to measure the PSF polarisation dependence, in orbit. These observations are used to routinely update and validate the VIS PSF model, and must be taken with the spacecraft in thermal equilibrium. This condition is met after about one week without large changes in the SAA and AA attitude angles (i.e. as close as possible to the values used in the preceding days of EWS observations). The VIS PSF calibration data hence need to be embedded in the currently executed EWS patch. In the global schedule (Fig. 29), the longitudes of the PSF calibration fields are marked on the top row, and the related observations are shown by the red strips within the EWS observation blocks.</p>
        <p>Two types of NISP calibrations are relevant in the description of the EWS. First, the NISP nonlinearity calibration requires a dataintensive special readout mode and must be done one detector at A112, page 21 of 41 A&amp;A 662, A112 (2022) a time, requiring a total of 49 h. In the current implementation of the EWS, these calibrations are scheduled approximately every six months. In a future version of the EWS, these observations might be partially executed in parallel with one of the VIS onsky calibrations, pending a confirmation of the instrument interoperability.Two types of NISP calibrations are relevant in the description of the EWS. First, the NISP nonlinearity calibration requires a dataintensive special readout mode and must be done one detector at A112, page 21 of 41 A&amp;A 662, A112 (2022) a time, requiring a total of 49 h. In the current implementation of the EWS, these calibrations are scheduled approximately every six months. In a future version of the EWS, these observations might be partially executed in parallel with one of the VIS onsky calibrations, pending a confirmation of the instrument interoperability.</p>
        <p>The second set of NISP calibrations is a one-time check of the NISP-S wavelength dispersion solution (NISP-S-PN-1 in the 2nd year of Fig. 29). This is initially obtained during the PV phase prior to the beginning of the survey, and repeated once, about one year after the start of the EWS. The dispersion solution is obtained from compact planetary nebulae (PNe) with strong emission lines, being stepped across a larger number of positions in the NISP focal plane. The dispersion solution is transferred to the self-cal field (Sect. 6.1.1) to establish a set of secondary standards to monitor the stability of the dispersion. Currently, the PN can be chosen from a list of 24 suitably compact PNe, which will be down-selected to some extent pending further ground-based spectroscopy.The second set of NISP calibrations is a one-time check of the NISP-S wavelength dispersion solution (NISP-S-PN-1 in the 2nd year of Fig. 29). This is initially obtained during the PV phase prior to the beginning of the survey, and repeated once, about one year after the start of the EWS. The dispersion solution is obtained from compact planetary nebulae (PNe) with strong emission lines, being stepped across a larger number of positions in the NISP focal plane. The dispersion solution is transferred to the self-cal field (Sect. 6.1.1) to establish a set of secondary standards to monitor the stability of the dispersion. Currently, the PN can be chosen from a list of 24 suitably compact PNe, which will be down-selected to some extent pending further ground-based spectroscopy.</p>
        <p>The Euclid schedule devotes much time to deep observations for galaxy sample characterisation. For GC, one needs to quantify biases in redshift measurements due to contamination and emission line misclassification (completeness-purity calibrations). For WL one needs to quantify biases in shear estimation due to noise (Viola et al. 2014), colour gradients (Semboloni et al. 2013;Er et al. 2018), and the calibration of photo zs. To this end, Euclid will observe three types of fields: (i) deep observations of six well-known fields for photometric redshift calibration and colour gradient calibration purposes (CDFS, COSMOS-Wide, SXDS, VVDS-Deep, CANDELS/AEGIS, and CANDELS/GOODS), hereafter known as the Euclid auxiliary fields (EAFs), which have extensive ground-and space-based multi-wavelength photometric and spectroscopic coverage, and are covered with 1-4 Euclid FoVs (i.e. spanning 0.5-2.0 deg 2 ); (ii) repeated observations of two 20 deg 2 fields at different times to obtain different dispersion angles to calibrate spectral confusion, named the completeness-purity-calibration fields (CPC); and (iii) deep observations of large (10-20 deg 2 ) fields, two magnitudes deeper than the EWS, for calibration of the noise bias, that constitute the three EDFs (EDF-North, EDF-South, and EDF-Fornax).The Euclid schedule devotes much time to deep observations for galaxy sample characterisation. For GC, one needs to quantify biases in redshift measurements due to contamination and emission line misclassification (completeness-purity calibrations). For WL one needs to quantify biases in shear estimation due to noise (Viola et al. 2014), colour gradients (Semboloni et al. 2013;Er et al. 2018), and the calibration of photo zs. To this end, Euclid will observe three types of fields: (i) deep observations of six well-known fields for photometric redshift calibration and colour gradient calibration purposes (CDFS, COSMOS-Wide, SXDS, VVDS-Deep, CANDELS/AEGIS, and CANDELS/GOODS), hereafter known as the Euclid auxiliary fields (EAFs), which have extensive ground-and space-based multi-wavelength photometric and spectroscopic coverage, and are covered with 1-4 Euclid FoVs (i.e. spanning 0.5-2.0 deg 2 ); (ii) repeated observations of two 20 deg 2 fields at different times to obtain different dispersion angles to calibrate spectral confusion, named the completeness-purity-calibration fields (CPC); and (iii) deep observations of large (10-20 deg 2 ) fields, two magnitudes deeper than the EWS, for calibration of the noise bias, that constitute the three EDFs (EDF-North, EDF-South, and EDF-Fornax).</p>
        <p>Defining the exact locations and footprints of the three EDFs required substantial effort9 EDF-North, located at the NEP, is visited 40 times with the ROS to reach a depth two magnitudes deeper than the EWS, while the other two EDFs, at lower latitudes and larger local background, need more visits to reach the required depth. To maximise synergy, EDF-North and EDF-South are chosen to have the same centres of CPC-North and CPC-South, respectively.Defining the exact locations and footprints of the three EDFs required substantial effort9 EDF-North, located at the NEP, is visited 40 times with the ROS to reach a depth two magnitudes deeper than the EWS, while the other two EDFs, at lower latitudes and larger local background, need more visits to reach the required depth. To maximise synergy, EDF-North and EDF-South are chosen to have the same centres of CPC-North and CPC-South, respectively.</p>
        <p>The EDFs and EAFs will have great scientific and legacy value due to the depth of the observations. A detailed description of their planned observations is presented in [Sc23].The EDFs and EAFs will have great scientific and legacy value due to the depth of the observations. A detailed description of their planned observations is presented in [Sc23].</p>
        <p>
            <rs type="software">ECTile</rs> is the software purposely developed to generate the scheduling of the EWS. It has two major stages. In the preparatory stage-1, 
            <rs type="software">ECTile</rs> computes the schedule of the various cal-ibrations, EDFs and EAFs. We review stage-1 in this section. The core of 
            <rs type="software">ECTile</rs> is stage-2, which computes the EWS; it is described in Sect. 7.
        </p>
        <p>The observations of calibration fields, EDFs, EAFs, and also ecliptic 'polar caps' (see below), hereafter called 'targets', share the same traits: most are only visible during a short interval at a given time (apart from the poles themselves), must observe a specific region (some with a specific orientation), and some must be re-observed with a fixed cadence. Given these restrictive properties, their schedule is computed in stage-1, followed by the scheduling of the EWS in stage-2 in the remaining time available. When scheduling the targets we need to make sure to leave enough time for EWS in each year, in order to fulfil the planned public delivery of reduced data to the community (Sect. 1) .The observations of calibration fields, EDFs, EAFs, and also ecliptic 'polar caps' (see below), hereafter called 'targets', share the same traits: most are only visible during a short interval at a given time (apart from the poles themselves), must observe a specific region (some with a specific orientation), and some must be re-observed with a fixed cadence. Given these restrictive properties, their schedule is computed in stage-1, followed by the scheduling of the EWS in stage-2 in the remaining time available. When scheduling the targets we need to make sure to leave enough time for EWS in each year, in order to fulfil the planned public delivery of reduced data to the community (Sect. 1) .</p>
        <p>We note that for the reasons explained in Sect. 7.4.2, the polar caps at high ecliptic latitudes (|β| ≥ 79 • ) are also part of the stage-1 schedule. Each of the two polar caps is covered with a fixed number of patches (thirteen in the northern polar cap, six in the southern polar cap), defining targets that are scheduled with a locally fixed patch area and sequence (i.e. these two regions of the EWS are observed with the same strategy as the EDFs and EAFs).We note that for the reasons explained in Sect. 7.4.2, the polar caps at high ecliptic latitudes (|β| ≥ 79 • ) are also part of the stage-1 schedule. Each of the two polar caps is covered with a fixed number of patches (thirteen in the northern polar cap, six in the southern polar cap), defining targets that are scheduled with a locally fixed patch area and sequence (i.e. these two regions of the EWS are observed with the same strategy as the EDFs and EAFs).</p>
        <p>The resulting schedule is called the 'stage-1 schedule', and its computation consists of three steps: (i) analysis of each target (strategy and visibility); (ii) placement of each target in longitude and year; and (iii) assignment of timestamps to each placement.The resulting schedule is called the 'stage-1 schedule', and its computation consists of three steps: (i) analysis of each target (strategy and visibility); (ii) placement of each target in longitude and year; and (iii) assignment of timestamps to each placement.</p>
        <p>In general, a target has four types of constraints: a fixed location on the sky, a specific observation sequence, a minimum depth, and a cadence (or other time constraints). From these we compute the target's 'window of visibility', namely, the range of ecliptic longitudes (of the Sun) in which the target may be observed (on the leading or on the trailing side of the orbit). Typically, each target has two windows of visibility per year.In general, a target has four types of constraints: a fixed location on the sky, a specific observation sequence, a minimum depth, and a cadence (or other time constraints). From these we compute the target's 'window of visibility', namely, the range of ecliptic longitudes (of the Sun) in which the target may be observed (on the leading or on the trailing side of the orbit). Typically, each target has two windows of visibility per year.</p>
        <p>The computation of each target window of visibility reveals its flexibility in placement and, more important, possible conflicts (of placement) with other targets. The procedure is essentially manual (aided by software tools). Three cases are of particular interest (see [Sc23] for details).The computation of each target window of visibility reveals its flexibility in placement and, more important, possible conflicts (of placement) with other targets. The procedure is essentially manual (aided by software tools). Three cases are of particular interest (see [Sc23] for details).</p>
        <p>The first case is the EDF-Fornax, which is planned to be observed gradually along the mission for a total of 52 times, taking into account the larger local background. It can be observed twice per year. However, the window of visibility of the EDF-Fornax partially collides with that of the EDF-South, and with some orientations of the CPC-South. This means that scheduling one of these targets strongly restricts the placement of the others. To overcome this conflict, the visits to CPC-South are all scheduled in the first year, leaving those longitudes free for EDF-Fornax, in the following years (5 times once every six months, plus a short 2 times visit on the first year, as required). Likewise, the EDF-South is observed from the second year onwards (but offset from EDF-Fornax).The first case is the EDF-Fornax, which is planned to be observed gradually along the mission for a total of 52 times, taking into account the larger local background. It can be observed twice per year. However, the window of visibility of the EDF-Fornax partially collides with that of the EDF-South, and with some orientations of the CPC-South. This means that scheduling one of these targets strongly restricts the placement of the others. To overcome this conflict, the visits to CPC-South are all scheduled in the first year, leaving those longitudes free for EDF-Fornax, in the following years (5 times once every six months, plus a short 2 times visit on the first year, as required). Likewise, the EDF-South is observed from the second year onwards (but offset from EDF-Fornax).</p>
        <p>The second case is the scheduling of the COSMOS and SXDS photo-z calibration targets. These require an observation of a 2 × 2 pattern that, if observed in one go, would take 15 days each. This would pose a great difficulty for the scheduling of the EWS, by adding a long interruption. In general, when scheduling the EWS, it is possible to bridge over interruptions (such as calibrations), if shorter than five days. Long interruptions are not bridgeable, forcing a interruption of the EWS buildup, A112, page 22 of 41 something that must be compensated in the next passage (at least a half-year later). It also reduces the opportunity to place PSF calibrations (that require a week of EWS observations prior to calibration). The solution is to observe these fields in four visits, observing half of it each time, first to an intermediate depth, and then a second time to the final depth.The second case is the scheduling of the COSMOS and SXDS photo-z calibration targets. These require an observation of a 2 × 2 pattern that, if observed in one go, would take 15 days each. This would pose a great difficulty for the scheduling of the EWS, by adding a long interruption. In general, when scheduling the EWS, it is possible to bridge over interruptions (such as calibrations), if shorter than five days. Long interruptions are not bridgeable, forcing a interruption of the EWS buildup, A112, page 22 of 41 something that must be compensated in the next passage (at least a half-year later). It also reduces the opportunity to place PSF calibrations (that require a week of EWS observations prior to calibration). The solution is to observe these fields in four visits, observing half of it each time, first to an intermediate depth, and then a second time to the final depth.</p>
        <p>The third case are the self-calibration and VIS non-linearity calibrations, which both require approximately a monthly cadence of observations. In order to decrease the number of interruptions to the EWS observations and the number of large slews used, these observations are always scheduled in sequence and executed at the same sky field, defining a 'recurring calibration block'.The third case are the self-calibration and VIS non-linearity calibrations, which both require approximately a monthly cadence of observations. In order to decrease the number of interruptions to the EWS observations and the number of large slews used, these observations are always scheduled in sequence and executed at the same sky field, defining a 'recurring calibration block'.</p>
        <p>Finally, every four weeks starting on Mondays at noon (UTC) ±1.2 h, there is one block of 12 h that is reserved for spacecraft orbit maintenance operations (SOP). During SOP time survey data cannot be taken.Finally, every four weeks starting on Mondays at noon (UTC) ±1.2 h, there is one block of 12 h that is reserved for spacecraft orbit maintenance operations (SOP). During SOP time survey data cannot be taken.</p>
        <p>The second part of the computation of the stage-1 schedule consists on placing each target in a table (named the 'design schedule'), at a given longitude and year, striving to avoid collisions with other targets. In that table, choices have to be made such as what target goes into each year, and at what longitude to place it. There is some freedom in this procedure. For instance, many targets do not need to be observed in a specific year. However, some targets are more stringent than others (i.e. they have shorter visibility windows or have a single annual visibility). Therefore, for simplicity, it is preferable to place the targets by decreasing order of perceived difficulty, filling the table year by year. This process is performed manually.The second part of the computation of the stage-1 schedule consists on placing each target in a table (named the 'design schedule'), at a given longitude and year, striving to avoid collisions with other targets. In that table, choices have to be made such as what target goes into each year, and at what longitude to place it. There is some freedom in this procedure. For instance, many targets do not need to be observed in a specific year. However, some targets are more stringent than others (i.e. they have shorter visibility windows or have a single annual visibility). Therefore, for simplicity, it is preferable to place the targets by decreasing order of perceived difficulty, filling the table year by year. This process is performed manually.</p>
        <p>While being manual, the process does not need to be very precise: some overlap in longitude between targets is allowed. Any overlaps are rectified in the next step and the longitudes are converted to timestamps, transforming the design schedule into the stage-1 schedule.While being manual, the process does not need to be very precise: some overlap in longitude between targets is allowed. Any overlaps are rectified in the next step and the longitudes are converted to timestamps, transforming the design schedule into the stage-1 schedule.</p>
        <p>The design schedule is filled according to a strategy that prioritises the placement of the targets with the most constraining observing conditions. In the first year the order of placement is as follows: (i) place all ten CPC-South visits at transit longitude (we note these are the most demanding targets); (ii) place recurring calibration blocks (self-cal+VIS non-linearity) at an approximate step of 360 • /11 = 32 • .73, which promotes a synergy with CPC-North; (iii) place the ten CPC-North visits (at orientations differing by steps of 32 • .73); (iv) place eleven of the thirteen targets of the northern polar cap, so that the width of these patches and the angular offset matches the placement of the CPC-North targets (i.e. they are observed immediately before or after), we note that the remaining two targets are placed in the second year; (v) place all eight targets of the southern polar cap; (vi) place the first two targets of the COSMOS-wide, covering half of the area needed on this target in the first year; (vii) place a ×2 pass visit to EDF-Fornax, slightly offset from its ideal placement, to avoid collision with one of the CPC-South targets; (viii) place the AEGIS target (required for the first year); (ix) place the two NISP non-linearity targets (we note that because these are freely placeable, the choice is to place them on the slot of longitudes where there is less area of EWS within the RoI); and (x) place a double visit to EDF-North to avoid a small gap of time between other targets (we note that since it can be placed all year round, the visits to EDF-North may be used as a filler).The design schedule is filled according to a strategy that prioritises the placement of the targets with the most constraining observing conditions. In the first year the order of placement is as follows: (i) place all ten CPC-South visits at transit longitude (we note these are the most demanding targets); (ii) place recurring calibration blocks (self-cal+VIS non-linearity) at an approximate step of 360 • /11 = 32 • .73, which promotes a synergy with CPC-North; (iii) place the ten CPC-North visits (at orientations differing by steps of 32 • .73); (iv) place eleven of the thirteen targets of the northern polar cap, so that the width of these patches and the angular offset matches the placement of the CPC-North targets (i.e. they are observed immediately before or after), we note that the remaining two targets are placed in the second year; (v) place all eight targets of the southern polar cap; (vi) place the first two targets of the COSMOS-wide, covering half of the area needed on this target in the first year; (vii) place a ×2 pass visit to EDF-Fornax, slightly offset from its ideal placement, to avoid collision with one of the CPC-South targets; (viii) place the AEGIS target (required for the first year); (ix) place the two NISP non-linearity targets (we note that because these are freely placeable, the choice is to place them on the slot of longitudes where there is less area of EWS within the RoI); and (x) place a double visit to EDF-North to avoid a small gap of time between other targets (we note that since it can be placed all year round, the visits to EDF-North may be used as a filler).</p>
        <p>At this point, the first year is filled. It would be possible to pack more targets into it, but that would reduce the size and num-ber of EWS windows, which in turn reduces the opportunity to place VIS PSF calibration fields. The latter need to be scheduled within EWS windows larger than seven days (see Sect. 6.1.2).At this point, the first year is filled. It would be possible to pack more targets into it, but that would reduce the size and num-ber of EWS windows, which in turn reduces the opportunity to place VIS PSF calibration fields. The latter need to be scheduled within EWS windows larger than seven days (see Sect. 6.1.2).</p>
        <p>With all CPC observations placed on the design schedule, the most demanding target left to be scheduled is EDF-Fornax. Unlike the EDF-South, the EDF-Fornax cannot be reached far from transit through a large de-pointing because of its low ecliptic latitude. The remaining years follow a common strategy, with most of the targets (EDF-Fornax, EDF-South, recurring calibration blocks, EDF-North, NISP wavelength dispersion) being scheduled almost exactly the same way. The exception are the EAF targets that vary from year to year: In the current schedule, the SXDS is placed in the third and fourth years, and the VVDS and GOODS-North in the fifth year.With all CPC observations placed on the design schedule, the most demanding target left to be scheduled is EDF-Fornax. Unlike the EDF-South, the EDF-Fornax cannot be reached far from transit through a large de-pointing because of its low ecliptic latitude. The remaining years follow a common strategy, with most of the targets (EDF-Fornax, EDF-South, recurring calibration blocks, EDF-North, NISP wavelength dispersion) being scheduled almost exactly the same way. The exception are the EAF targets that vary from year to year: In the current schedule, the SXDS is placed in the third and fourth years, and the VVDS and GOODS-North in the fifth year.</p>
        <p>The strategy for the remaining years is as follows: (i) place two ×5 passes to EDF-Fornax at their transits; (ii) place two pairs of visits to EDF-South, clustered around the two EDF-Fornax pointings, consisting of a first pair of a one pass visit and a ×2 pass visit, separated by 5 • , and a second pair of two ×2 pass visits, also separated by 5 • (so to ensure survey windows not smaller than 5 days, given an average orbital progression of 1 • per day). Each group is clustered around each EDF-Fornax pointing; (iii) place the 11 recurring calibration blocks, slightly offset from a nominal cadence to avoid conflicts with the EDF-Fornax and EDF-South observations; (iv) place the two remaining northern polar targets (second year only); (v) place the large block of NISP wavelength dispersion target (second year only); (vi) place EAF targets (these vary from year to year); (vii) place two visits to EDF-North, one ×4 pass and another ×2 pass, near the centre of the range of EWS RoI scarcity, matching surrounding recurring calibration blocks; and (viii) place the two NISP non-linearity targets.The strategy for the remaining years is as follows: (i) place two ×5 passes to EDF-Fornax at their transits; (ii) place two pairs of visits to EDF-South, clustered around the two EDF-Fornax pointings, consisting of a first pair of a one pass visit and a ×2 pass visit, separated by 5 • , and a second pair of two ×2 pass visits, also separated by 5 • (so to ensure survey windows not smaller than 5 days, given an average orbital progression of 1 • per day). Each group is clustered around each EDF-Fornax pointing; (iii) place the 11 recurring calibration blocks, slightly offset from a nominal cadence to avoid conflicts with the EDF-Fornax and EDF-South observations; (iv) place the two remaining northern polar targets (second year only); (v) place the large block of NISP wavelength dispersion target (second year only); (vi) place EAF targets (these vary from year to year); (vii) place two visits to EDF-North, one ×4 pass and another ×2 pass, near the centre of the range of EWS RoI scarcity, matching surrounding recurring calibration blocks; and (viii) place the two NISP non-linearity targets.</p>
        <p>The last stage of the computation of the intermediate schedule is the automated conversion of the year-by-year longitudes into timestamps. Given a starting date to the survey routine phase (currently but not frozen yet, this is expected to start on 8392.5 modified Julian date, or 2022-12-23T11:59:23Z), it is easy to compute the corresponding Sun longitude (271 • .30). Then, it is a simple matter of 'reading' the design schedule, year-wise.The last stage of the computation of the intermediate schedule is the automated conversion of the year-by-year longitudes into timestamps. Given a starting date to the survey routine phase (currently but not frozen yet, this is expected to start on 8392.5 modified Julian date, or 2022-12-23T11:59:23Z), it is easy to compute the corresponding Sun longitude (271 • .30). Then, it is a simple matter of 'reading' the design schedule, year-wise.</p>
        <p>The first target following the starting longitude is a recurring calibration block at 290 • , approximately two days after the beginning. This timestamp is assigned to the first target found. Practically, this involves only computing the next timestamp when the Sun is at a given longitude. The process continues, assigning timestamps to targets of the first year, by order of longitude (wrapping around at longitude 360 • ). Once the traversing reaches the initial longitude, the process continues in the second year, starting at the same longitude where the first year ended. Once the second year is completed, the process continues on the third year and so on, until the intermediate schedule is completed. There is a possibility that the initial longitude for traversing any year coincides with the middle of a target. In those cases, the traversing continues after that target.The first target following the starting longitude is a recurring calibration block at 290 • , approximately two days after the beginning. This timestamp is assigned to the first target found. Practically, this involves only computing the next timestamp when the Sun is at a given longitude. The process continues, assigning timestamps to targets of the first year, by order of longitude (wrapping around at longitude 360 • ). Once the traversing reaches the initial longitude, the process continues in the second year, starting at the same longitude where the first year ended. Once the second year is completed, the process continues on the third year and so on, until the intermediate schedule is completed. There is a possibility that the initial longitude for traversing any year coincides with the middle of a target. In those cases, the traversing continues after that target.</p>
        <p>Besides converting longitudes to timestamps, an algorithm disentangles overlaps between targets and prevents, when possible, the occurrence of too small EWS windows. The overlap of two or more targets (allowed in the previous stage), is fixed by offsetting those targets from their initial placement, minimising the overall offset, within the range allowed by their window of visibility. In most cases, this process is sufficient to resolve overlaps. In case of failure, the solution is to go back to the previous A112, page 23 stage and fix the overlap manually. The same process is applied to eliminate the occurrence of small windows. Except that, now, the offsetting is in the opposite direction, pushing targets closer to each other.Besides converting longitudes to timestamps, an algorithm disentangles overlaps between targets and prevents, when possible, the occurrence of too small EWS windows. The overlap of two or more targets (allowed in the previous stage), is fixed by offsetting those targets from their initial placement, minimising the overall offset, within the range allowed by their window of visibility. In most cases, this process is sufficient to resolve overlaps. In case of failure, the solution is to go back to the previous A112, page 23 stage and fix the overlap manually. The same process is applied to eliminate the occurrence of small windows. Except that, now, the offsetting is in the opposite direction, pushing targets closer to each other.</p>
        <p>Figure 29 shows an example of the full Euclid schedule. The result of the stage-1 procedure, in this diagram, is the sequence of coloured boxes. The time allocated for each observation of a target is represented by a labelled box of a unique colour. The pink and white boxes represent the periods available to observe the EWS (at the end of the stage-1 scheduling they are all still unallocated). During the stage-2 scheduling (Sect. 7) the EWS is scheduled in part of the available time (shown by the pink boxes), while some time periods remain unallocated (shown by the white boxes that are increasingly longer towards the final years of the survey, cf. Sect. 8.2).Figure 29 shows an example of the full Euclid schedule. The result of the stage-1 procedure, in this diagram, is the sequence of coloured boxes. The time allocated for each observation of a target is represented by a labelled box of a unique colour. The pink and white boxes represent the periods available to observe the EWS (at the end of the stage-1 scheduling they are all still unallocated). During the stage-2 scheduling (Sect. 7) the EWS is scheduled in part of the available time (shown by the pink boxes), while some time periods remain unallocated (shown by the white boxes that are increasingly longer towards the final years of the survey, cf. Sect. 8.2).</p>
        <p>The alignment of boxes with the same colour across years indicates that the respective targets are scheduled at the same time every year. The labels (and widths) of the boxes indicate when consecutive visits are made to the same field. The EDFs are often scheduled with more than one visit in a row, in particular EDF-Fornax is usually visited five times to efficiently use its short time visibility that occurs twice per year.The alignment of boxes with the same colour across years indicates that the respective targets are scheduled at the same time every year. The labels (and widths) of the boxes indicate when consecutive visits are made to the same field. The EDFs are often scheduled with more than one visit in a row, in particular EDF-Fornax is usually visited five times to efficiently use its short time visibility that occurs twice per year.</p>
        <p>Differently from the other calibrations, PSF calibrations are scheduled within the pink boxes: the EWS observation is interrupted to point to a PSF field (for ∼20.5 h) and then returns to the same position. This allows for a much better stability of the SAA and AA values used (that will match the ones used on that observation of the EWS), than if they were scheduled in the recurring calibration block, always together with the other targets of approximately monthly cadence. The visibility windows of twenty preliminary PSF fields are shown as horizontal red bars within the pink EWS boxes, while the vertical red bars show the actual scheduled time of the PSF observations (the corresponding Sun longitude for each of the fields is indicated by the numbers 1 to 20 on the axes at the edges of the Fig. 29).Differently from the other calibrations, PSF calibrations are scheduled within the pink boxes: the EWS observation is interrupted to point to a PSF field (for ∼20.5 h) and then returns to the same position. This allows for a much better stability of the SAA and AA values used (that will match the ones used on that observation of the EWS), than if they were scheduled in the recurring calibration block, always together with the other targets of approximately monthly cadence. The visibility windows of twenty preliminary PSF fields are shown as horizontal red bars within the pink EWS boxes, while the vertical red bars show the actual scheduled time of the PSF observations (the corresponding Sun longitude for each of the fields is indicated by the numbers 1 to 20 on the axes at the edges of the Fig. 29).</p>
        <p>Table 8 summarises the time allocated to make all calibration, EDF and EAF observations, which is 427 days. We note that the time allocated for the self-cal field is here included in the EAFs budget and not in the instrument calibrations, since its repeated observations will make it the deepest of the Euclid fields. We also note that due to the synergy between CPC and EDFs, 36 of the 48 days needed for CPC calibrations also con-tribute for the completion of the EDS. Details are given in [Sc23].Table 8 summarises the time allocated to make all calibration, EDF and EAF observations, which is 427 days. We note that the time allocated for the self-cal field is here included in the EAFs budget and not in the instrument calibrations, since its repeated observations will make it the deepest of the Euclid fields. We also note that due to the synergy between CPC and EDFs, 36 of the 48 days needed for CPC calibrations also con-tribute for the completion of the EDS. Details are given in [Sc23].</p>
        <p>The breakdown of the time-allocation by observing type is: (i) instrument calibrations, 25%; (ii) auxiliary fields, 21%; and (iii) deep fields, 54%.The breakdown of the time-allocation by observing type is: (i) instrument calibrations, 25%; (ii) auxiliary fields, 21%; and (iii) deep fields, 54%.</p>
        <p>The computation of the EWS is a complex optimisation problem, for which we developed the scheduling tool 
            <rs type="software">ECTile</rs>. After the preliminary stage-1 described in Sect. 6.3 that determines the schedule of the various calibrations, EDFs, EAFs, and polar caps targets, ECTile proceeds with the computation of the EWS in its stage-2. Before turning to a detailed description of stage-2 of ECTile from Sect. 7.2 onwards, we give a brief description of pre-ECTile explorations.
        </p>
        <p>The derivation of the optimal survey is a complex process, and ECTile is one of many possible solutions. It is, however, worth stressing that it is the outcome of a lengthy process, in which alternatives have been explored, but ultimately rejected. For instance, the first solutions of the EWS were delivered by industry to demonstrate the feasibility of the survey, but ignored some important additional considerations, such as observing areas with low zodiacal background first (see Sect. 5.1.1). Other solutions (Amiaux et al. 2012) were produced using 
            <rs type="creator">ESA</rs>'s 
            <rs type="software">Euclid Sky Survey Planning Tool (ESSPT</rs>; Gómez-Alvarez et al. 2018), which allows the user to manually place patches on a sky map and fill them with Euclid FoVs. In this section we provide a brief overview of the prior investigations that led to ECTile as it is today.
        </p>
        <p>To cover a maximum area with minimum overlap between single observations, a pre-determined tiling is almost unavoidable. The early approaches (see Tereno et al. 2015) therefore defined rigid FoVs placed parallel to the ecliptic meridians. The fields were scheduled starting at high latitudes and moving up and down along ecliptic meridians, observing in transit, that is, with SAA = 90 • (and AA = 0 • ) when the local meridian coincides with the Y SC direction defined in Sect. 2.1 (see also Sect. 2.5). The extent to which we move across latitudes before moving to the next longitude, defines a latitude band, to be observed in one year. Due to the convergence towards the poles, the number of fields per band decreases with latitude, and conversely the height of the bands increase with latitude.To cover a maximum area with minimum overlap between single observations, a pre-determined tiling is almost unavoidable. The early approaches (see Tereno et al. 2015) therefore defined rigid FoVs placed parallel to the ecliptic meridians. The fields were scheduled starting at high latitudes and moving up and down along ecliptic meridians, observing in transit, that is, with SAA = 90 • (and AA = 0 • ) when the local meridian coincides with the Y SC direction defined in Sect. 2.1 (see also Sect. 2.5). The extent to which we move across latitudes before moving to the next longitude, defines a latitude band, to be observed in one year. Due to the convergence towards the poles, the number of fields per band decreases with latitude, and conversely the height of the bands increase with latitude.</p>
        <p>Whenever there is an interruption in the EWS schedule due to an observation of calibration or EDF targets, a corresponding gap is left in the band. After one revolution in the orbit, a latitude band is finished and the scheduling of the next band, on a lower latitude, starts. The gaps can be recovered in the following year when in transit again. For this, the height of the next latitude band needs to be smaller, in order to create a time buffer that allows one to cover the gaps while not creating new gaps in the lower band. This way, the missing area can be observed slightly off-transit, tilting the telescope arouns X SC . The tilt must be accompanied by a rotation around the Z SC axis (hence changing AA) to compensate and keep the field aligned with the tiling. However, given the very stringent constraints on AA (|AA| &lt; 1 • at the time of the early explorations) the time buffers are necessarily small, and it is only possible to partially cover the gaps. This process is illustrated in Fig. 30 more gaps elsewhere. It was thus concluded that the use of a fixed tesselation and fixed latitude bands was not viable.Whenever there is an interruption in the EWS schedule due to an observation of calibration or EDF targets, a corresponding gap is left in the band. After one revolution in the orbit, a latitude band is finished and the scheduling of the next band, on a lower latitude, starts. The gaps can be recovered in the following year when in transit again. For this, the height of the next latitude band needs to be smaller, in order to create a time buffer that allows one to cover the gaps while not creating new gaps in the lower band. This way, the missing area can be observed slightly off-transit, tilting the telescope arouns X SC . The tilt must be accompanied by a rotation around the Z SC axis (hence changing AA) to compensate and keep the field aligned with the tiling. However, given the very stringent constraints on AA (|AA| &lt; 1 • at the time of the early explorations) the time buffers are necessarily small, and it is only possible to partially cover the gaps. This process is illustrated in Fig. 30 more gaps elsewhere. It was thus concluded that the use of a fixed tesselation and fixed latitude bands was not viable.</p>
        <p>The AA limit was eventually relaxed to 3 • at the preliminary design review (PDR) and later to 6 • at the critical design review (CDR), being currently fixed at 5 • . This makes the use of a fixed tessellation a viable approach, enabling an efficient coverage of the sky. However, the use of fixed latitude bands remains not viable and more complex strategies needed to be developed, as described in the next sections.The AA limit was eventually relaxed to 3 • at the preliminary design review (PDR) and later to 6 • at the critical design review (CDR), being currently fixed at 5 • . This makes the use of a fixed tessellation a viable approach, enabling an efficient coverage of the sky. However, the use of fixed latitude bands remains not viable and more complex strategies needed to be developed, as described in the next sections.</p>
        <p>The computation of the EWS revolves around the concept of a patch, which may be loosely defined as a compact set of fields with a valid observation sequence. This is the basic building block for this computation. This section describes the steps that precede the computation of a patch, summarised in Fig. 31. The first step is the computation of the tessellated RoI, a set of tiles covering the designed RoI. In parallel, survey windows are computed from the stage-1 schedule, defining the intervals of time left to EWS observations. These two elements are then combined into patch sources, compact sub-sets of each quadrant of the tessellated RoI within reach of a given survey window. A patch source is, in general, further divided into one or more patch segments, which are sets of tiles guaranteed to be not only compact but also having their contour shaped like a lat-long rectangle (an essential property for the computation that follows it). Patch segments from the same patch source are then transformed into a patch by establishing upon them an ordered sequence of observations.The computation of the EWS revolves around the concept of a patch, which may be loosely defined as a compact set of fields with a valid observation sequence. This is the basic building block for this computation. This section describes the steps that precede the computation of a patch, summarised in Fig. 31. The first step is the computation of the tessellated RoI, a set of tiles covering the designed RoI. In parallel, survey windows are computed from the stage-1 schedule, defining the intervals of time left to EWS observations. These two elements are then combined into patch sources, compact sub-sets of each quadrant of the tessellated RoI within reach of a given survey window. A patch source is, in general, further divided into one or more patch segments, which are sets of tiles guaranteed to be not only compact but also having their contour shaped like a lat-long rectangle (an essential property for the computation that follows it). Patch segments from the same patch source are then transformed into a patch by establishing upon them an ordered sequence of observations.</p>
        <p>In this section we present the main inputs and associated constraints for the EWS optimisation algorithm, and briefly review their impact on the current solution.In this section we present the main inputs and associated constraints for the EWS optimisation algorithm, and briefly review their impact on the current solution.</p>
        <p>We define a tile as the largest rectangle in latitude-longitude that is completely contained in a single FoV (see Fig. 32). The survey area must then be observed through geometrically contiguous tiles, with an overlap of boundaries between adjacent tiles of a 0.5% wide strip (1% overlap, overall), to cope with the non-null pointing error. The goal of this requirement is to enable efficient coverage of the sky, whilst ensuring a minimum overlap between adjacent fields. This can be achieved with a tessellation of tiles laid out along parallels of latitude, with adjacent tiles on the same row and tiles between adjacent rows overlapping by 1%. Due to the convergence towards the poles, the number of tiles per row decreases with latitude at the same time that the overlap between adjacent fields increases, as shown in Fig. 32. This source of overlap is inevitable and a consequence of tessellating a sphere with a rectangle (i.e. a FoV). Nevertheless, this overlap is only significant at latitudes closer to the poles (above ±79 • ). A second source of overlap comes from the placement of tiles per row. Each row requires an integer number of tiles. However, in general, this integer number of tiles covers slightly more than the 360 • of a full circle. This excess contributes to an increase in the overlap between adjacent tiles (shared evenly along the row) but, being no more than one tile per row, its amortised cost is relatively small. . This shows that the need to observe fields aligned with meridians strongly restricts visibility (see Fig. 5).We define a tile as the largest rectangle in latitude-longitude that is completely contained in a single FoV (see Fig. 32). The survey area must then be observed through geometrically contiguous tiles, with an overlap of boundaries between adjacent tiles of a 0.5% wide strip (1% overlap, overall), to cope with the non-null pointing error. The goal of this requirement is to enable efficient coverage of the sky, whilst ensuring a minimum overlap between adjacent fields. This can be achieved with a tessellation of tiles laid out along parallels of latitude, with adjacent tiles on the same row and tiles between adjacent rows overlapping by 1%. Due to the convergence towards the poles, the number of tiles per row decreases with latitude at the same time that the overlap between adjacent fields increases, as shown in Fig. 32. This source of overlap is inevitable and a consequence of tessellating a sphere with a rectangle (i.e. a FoV). Nevertheless, this overlap is only significant at latitudes closer to the poles (above ±79 • ). A second source of overlap comes from the placement of tiles per row. Each row requires an integer number of tiles. However, in general, this integer number of tiles covers slightly more than the 360 • of a full circle. This excess contributes to an increase in the overlap between adjacent tiles (shared evenly along the row) but, being no more than one tile per row, its amortised cost is relatively small. . This shows that the need to observe fields aligned with meridians strongly restricts visibility (see Fig. 5).</p>
        <p>As described in Sect. 2.5, the limited range of the pointing angles implies that most of the sky must be observed at, or at least close to transit. As we motivate later, most of the EWS is observed with fields aligned with the ecliptic meridians. In general, these fields are almost never observed at transit, thus requiring a rotation around Z SC to realign the FoV with the local meridian. However, the constraints on AA and SAA severely limit the extent to which a field may be observed away from transit. This is highlighted in Fig. 33, which shows the region of the sky that is observable at a given transit. It is mostly constrained by the AA range, except at lower latitudes, where the constraint on SAA dominates.As described in Sect. 2.5, the limited range of the pointing angles implies that most of the sky must be observed at, or at least close to transit. As we motivate later, most of the EWS is observed with fields aligned with the ecliptic meridians. In general, these fields are almost never observed at transit, thus requiring a rotation around Z SC to realign the FoV with the local meridian. However, the constraints on AA and SAA severely limit the extent to which a field may be observed away from transit. This is highlighted in Fig. 33, which shows the region of the sky that is observable at a given transit. It is mostly constrained by the AA range, except at lower latitudes, where the constraint on SAA dominates.</p>
        <p>The limitations associated with the cost of a slew (see Sect. 2.4), imply that EWS fields observed consecutively in time must also be, as much as possible, spatially adjacent to each other. In this way, large slews are mostly reserved for moving between EWS fields and deep or calibration fields or between patches of the EWS.The limitations associated with the cost of a slew (see Sect. 2.4), imply that EWS fields observed consecutively in time must also be, as much as possible, spatially adjacent to each other. In this way, large slews are mostly reserved for moving between EWS fields and deep or calibration fields or between patches of the EWS.</p>
        <p>Figure 34 shows the reach from a given field, when slewing with a small-slew within a limit of 1 • .2 and 3 • .6, for a field placed at two different latitudes. The example demonstrates that, at low latitude, it is possible to slew to all adjacent tiles; if con- sidering slews up to 3 • .6, it is possible to slew to tiles two rows away (we recall that the slew can be depicted as the arc separating two different directions on the sky plus a rotation around the latter). However, at high latitude, the slew between adjacent tiles is much more limited by the size of the not small change in AA needed to keep the alignment with the local meridian of the tessellation. There, adjacent tiles on the same row are farther apart, strongly limiting the field-to-field slewing, which, in this case, is performed by a rotation around the Z SC -axis. For example, given the FoV width of 0 • .701, tiles placed at latitude of 79 • .08 are separated exactly by 3 • .6 of longitude. Thus, above 79 • , it is not possible to slew sideways between two adjacent fields (aligned with the tessellation).Figure 34 shows the reach from a given field, when slewing with a small-slew within a limit of 1 • .2 and 3 • .6, for a field placed at two different latitudes. The example demonstrates that, at low latitude, it is possible to slew to all adjacent tiles; if con- sidering slews up to 3 • .6, it is possible to slew to tiles two rows away (we recall that the slew can be depicted as the arc separating two different directions on the sky plus a rotation around the latter). However, at high latitude, the slew between adjacent tiles is much more limited by the size of the not small change in AA needed to keep the alignment with the local meridian of the tessellation. There, adjacent tiles on the same row are farther apart, strongly limiting the field-to-field slewing, which, in this case, is performed by a rotation around the Z SC -axis. For example, given the FoV width of 0 • .701, tiles placed at latitude of 79 • .08 are separated exactly by 3 • .6 of longitude. Thus, above 79 • , it is not possible to slew sideways between two adjacent fields (aligned with the tessellation).</p>
        <p>The generation of the tessellated RoI begins with the computation of a global tessellation on the sphere, covering the sphere without polar caps from latitudes ±79 • towards the equator, with non-overlapping tiles aligned with the meridians. This tessellation is then filtered by selecting tiles that have at least one of their corners inside the RoI. This represents the tessellated RoI and specifies the FoVs eligible to be observed (see Fig. 35). Figure 36 shows two zoomed views, highlighting the dependence of overlap with latitude. The EWS solution schedules a large subset of the tessellated RoI, which then becomes the Euclid 'footprint'. 37. Coverage of the northern and southern ecliptic polar caps (left and right panels, respectively), with the design of polar caps drawn in red and patches drawn in blue. Extra patches below 79 • are also added to polar caps (two in the north and one in the south) to observe corners of the RoI that would be difficult to observe with the regular wide strategy. The presence of the Galactic plane affects both caps. In addition, the southern boundary avoids the LMC. Blinding stars are also shown; in particular, the small gap in the southern cap is due to the presence of the extremely bright star R-Doradus.The generation of the tessellated RoI begins with the computation of a global tessellation on the sphere, covering the sphere without polar caps from latitudes ±79 • towards the equator, with non-overlapping tiles aligned with the meridians. This tessellation is then filtered by selecting tiles that have at least one of their corners inside the RoI. This represents the tessellated RoI and specifies the FoVs eligible to be observed (see Fig. 35). Figure 36 shows two zoomed views, highlighting the dependence of overlap with latitude. The EWS solution schedules a large subset of the tessellated RoI, which then becomes the Euclid 'footprint'. 37. Coverage of the northern and southern ecliptic polar caps (left and right panels, respectively), with the design of polar caps drawn in red and patches drawn in blue. Extra patches below 79 • are also added to polar caps (two in the north and one in the south) to observe corners of the RoI that would be difficult to observe with the regular wide strategy. The presence of the Galactic plane affects both caps. In addition, the southern boundary avoids the LMC. Blinding stars are also shown; in particular, the small gap in the southern cap is due to the presence of the extremely bright star R-Doradus.</p>
        <p>As discussed in Sect. 7.3.3, above 79 • it is not possible to slew sideways, when traversing fields aligned with the tessellation. Indeed, at high latitudes, the centres of adjacent fields on the same row of the tessellation are separated by an eigenslew larger than 3 • .7. As the amplitude of an eigenslew includes the rotations needed to align the fields and not only the angular separation between the fields centres, the part of the EWS above +79 • and below -79 • , the polar caps, are not part of the global tessellation.As discussed in Sect. 7.3.3, above 79 • it is not possible to slew sideways, when traversing fields aligned with the tessellation. Indeed, at high latitudes, the centres of adjacent fields on the same row of the tessellation are separated by an eigenslew larger than 3 • .7. As the amplitude of an eigenslew includes the rotations needed to align the fields and not only the angular separation between the fields centres, the part of the EWS above +79 • and below -79 • , the polar caps, are not part of the global tessellation.</p>
        <p>Instead, each polar cap is covered by a fixed number of patches of fixed area, as shown in Fig. 37. The northern cap is covered with 13 patches, while there are six patches covering the southern cap. The southern polar cap is smaller due to the presence of the LMC, which lies outside the EWS RoI. Each patch of the polar caps is a target field scheduled during stage-1 with the strategy used for observing the EDFs and calibration fields.Instead, each polar cap is covered by a fixed number of patches of fixed area, as shown in Fig. 37. The northern cap is covered with 13 patches, while there are six patches covering the southern cap. The southern polar cap is smaller due to the presence of the LMC, which lies outside the EWS RoI. Each patch of the polar caps is a target field scheduled during stage-1 with the strategy used for observing the EDFs and calibration fields.</p>
        <p>At high latitudes, overlap between neighbouring fields cannot be avoided, because there is longer room for a rotation of the FoV. The average FoV overlap on the polar caps is ∼18%, while the average overlap on the regular wide is under 3%. This leads to a small loss in survey efficiency.At high latitudes, overlap between neighbouring fields cannot be avoided, because there is longer room for a rotation of the FoV. The average FoV overlap on the polar caps is ∼18%, while the average overlap on the regular wide is under 3%. This leads to a small loss in survey efficiency.</p>
        <p>The next step in the computation of the EWS is to match the global tessellation with the survey windows defined by the stage-1 schedule. A 'survey window' is the span of time between consecutive calibration blocks. It defines uninterrupted time intervals available for observing the RoI. Currently, there are approximately 100 survey windows. As explained later, these are processed in chronological order, one at a time. But we first show how a single survey window intersects with the RoI and how it is populated with EWS observations.The next step in the computation of the EWS is to match the global tessellation with the survey windows defined by the stage-1 schedule. A 'survey window' is the span of time between consecutive calibration blocks. It defines uninterrupted time intervals available for observing the RoI. Currently, there are approximately 100 survey windows. As explained later, these are processed in chronological order, one at a time. But we first show how a single survey window intersects with the RoI and how it is populated with EWS observations.</p>
        <p>A survey window begins at the end of the last pointing of a calibration block, and lasts until the first pointing of the following calibration block. Let a and b be the two pointings delimiting a survey window, and ∆t a nominal observation time, defined as ROS time, including the typical field-to-field slew time. The approximate number of FoVs possible to observe within a survey window (i.e. its capacity) is then given by n = (ba)/∆t.A survey window begins at the end of the last pointing of a calibration block, and lasts until the first pointing of the following calibration block. Let a and b be the two pointings delimiting a survey window, and ∆t a nominal observation time, defined as ROS time, including the typical field-to-field slew time. The approximate number of FoVs possible to observe within a survey window (i.e. its capacity) is then given by n = (ba)/∆t.</p>
        <p>During the slot of time defined by a survey window, spanning from a to b, two transit meridians scan two opposite sectors of the sphere, representing the areas within reach of the survey window. In turn, both of these sectors intersect with two or more of the four quadrants of the RoI, identifying the eligible FoVs within reach of a given survey window. The intersection of each of these sectors with a single quadrant of the RoI defines a 'patch source' (i.e. a contiguous subset of the tessellated RoI within reach of a survey window, as exemplified in Fig. 38). The number of patch sources per survey window varies from two, intersecting only the mainlands, to four, intersecting all quadrants. In rare configurations, a survey window intersects the same mainland twice, defining two separate patch sources.During the slot of time defined by a survey window, spanning from a to b, two transit meridians scan two opposite sectors of the sphere, representing the areas within reach of the survey window. In turn, both of these sectors intersect with two or more of the four quadrants of the RoI, identifying the eligible FoVs within reach of a given survey window. The intersection of each of these sectors with a single quadrant of the RoI defines a 'patch source' (i.e. a contiguous subset of the tessellated RoI within reach of a survey window, as exemplified in Fig. 38). The number of patch sources per survey window varies from two, intersecting only the mainlands, to four, intersecting all quadrants. In rare configurations, a survey window intersects the same mainland twice, defining two separate patch sources.</p>
        <p>A patch source provides a simplification of the wide survey time window ('survey window'). Given the need to observe fields in sequence, ones near each other (within the slew constraints), the observations within a wide survey window must necessarily form a contiguous compact set. As described below, these compact sets of tiles defines a patch.A patch source provides a simplification of the wide survey time window ('survey window'). Given the need to observe fields in sequence, ones near each other (within the slew constraints), the observations within a wide survey window must necessarily form a contiguous compact set. As described below, these compact sets of tiles defines a patch.</p>
        <p>A 'patch' is the building block of the survey. It constitutes a unit of observation of the wide, using some of the time budget for the wide (which may all or part of a survey window) and covering some of the RoI. By construction, different patches do not intersect, neither in time nor space. Moreover, the RoI is covered as much as possible in an orderly fashion, with patches stacking one on top of each other. In that respect, the EWS may be seen as a long sequence of patches (scheduled around the calibration blocks).A 'patch' is the building block of the survey. It constitutes a unit of observation of the wide, using some of the time budget for the wide (which may all or part of a survey window) and covering some of the RoI. By construction, different patches do not intersect, neither in time nor space. Moreover, the RoI is covered as much as possible in an orderly fashion, with patches stacking one on top of each other. In that respect, the EWS may be seen as a long sequence of patches (scheduled around the calibration blocks).</p>
        <p>Patch sources of the same survey window compete for the same time, with each one (potentially) generating a patch. Hence, in general, several candidate patches are available, with the actual choice of one among the possible ones determined by several aspects. In the simplest scenario, one or more patches fill all the time available and, in that case, it suffices to choose one of them (and discard the rest). In more complex scenarios, a survey window only intersects a quadrant partially, producing a patch source that does not consume all the available time. In these cases, the solution is to fill the survey window with patches from several patch sources. One patch is selected, reducing the extent of the survey window. Then, the process is restarted, recomputing the patch sources and generating a new set of patches. The process is iterated until all available time is exhausted.Patch sources of the same survey window compete for the same time, with each one (potentially) generating a patch. Hence, in general, several candidate patches are available, with the actual choice of one among the possible ones determined by several aspects. In the simplest scenario, one or more patches fill all the time available and, in that case, it suffices to choose one of them (and discard the rest). In more complex scenarios, a survey window only intersects a quadrant partially, producing a patch source that does not consume all the available time. In these cases, the solution is to fill the survey window with patches from several patch sources. One patch is selected, reducing the extent of the survey window. Then, the process is restarted, recomputing the patch sources and generating a new set of patches. The process is iterated until all available time is exhausted.</p>
        <p>Inevitably, due to the cyclic nature of the scanning of the sky, the selection of a patch reduces the RoI available for the Fig. 39. Example of a patch source reduced by previously scheduled patches (plot of region IV only, no star skipping for clarity). Previously scheduled patches are shown in blue, with the red region depicting the patch source of some windows. We notice how the bottom side of this quadrant acquired a lat-long shape after the stacking of some patches. generation of later patches. This does not cause any problem and it is easily coped with by flagging observed tiles as they are scheduled, thus avoiding selecting them again in subsequent compilations of patch sources. However, cyclic placement of patches around the sphere creates a 'dented' boundary of observed tiles. Over time, this leads some of the observed regions in the RoI to acquire a boundary shaped like a polyline in latitude and longitude (see Fig. 39).Inevitably, due to the cyclic nature of the scanning of the sky, the selection of a patch reduces the RoI available for the Fig. 39. Example of a patch source reduced by previously scheduled patches (plot of region IV only, no star skipping for clarity). Previously scheduled patches are shown in blue, with the red region depicting the patch source of some windows. We notice how the bottom side of this quadrant acquired a lat-long shape after the stacking of some patches. generation of later patches. This does not cause any problem and it is easily coped with by flagging observed tiles as they are scheduled, thus avoiding selecting them again in subsequent compilations of patch sources. However, cyclic placement of patches around the sphere creates a 'dented' boundary of observed tiles. Over time, this leads some of the observed regions in the RoI to acquire a boundary shaped like a polyline in latitude and longitude (see Fig. 39).</p>
        <p>In the previous section, the process of extracting a patch from a patch source was simplified, for the sake of clarity. Actually, the process is slightly more complex, requiring the definition of the concept of a patch segment. First, tiles are selected on the condition that tiles observed in the same time slot should also be close to each other. However, because the contour line of the unscheduled part of the RoI may become irregular, the condition on proximity might not be feasible to meet. The solution is to partition the tiles of a patch source into patch segments, where a patch segment is simply a group of tiles amenable to be visited with a sequence of small-slews.In the previous section, the process of extracting a patch from a patch source was simplified, for the sake of clarity. Actually, the process is slightly more complex, requiring the definition of the concept of a patch segment. First, tiles are selected on the condition that tiles observed in the same time slot should also be close to each other. However, because the contour line of the unscheduled part of the RoI may become irregular, the condition on proximity might not be feasible to meet. The solution is to partition the tiles of a patch source into patch segments, where a patch segment is simply a group of tiles amenable to be visited with a sequence of small-slews.</p>
        <p>When creating a patch segment, tiles must be selected evenly across longitude, matching the rate of fields observable per unit of time (approximately, 20 fields per day ≡ per degree of longitude). The first time a patch is extracted from a patch source, the base of the corresponding RoI is bounded by a straight line (the side of the mainlands close to the poles), resulting in a single, possibly large, patch segment of tiles. But, after a few iterations, the base becomes a polyline (see Fig. 39). Then, the process of selecting tiles evenly across longitude may, potentially, produce a fragmented selection, made of two or more separate patch segments (Fig. 40 shows an example of this). This fragmentation is inevitable, but it is not an obstacle. In general, a patch source produces several patch segments in order to fill its span of time. In the case of multiple patch segments, the solution is to schedule them separately, followed by a merge into a continuous single schedule.When creating a patch segment, tiles must be selected evenly across longitude, matching the rate of fields observable per unit of time (approximately, 20 fields per day ≡ per degree of longitude). The first time a patch is extracted from a patch source, the base of the corresponding RoI is bounded by a straight line (the side of the mainlands close to the poles), resulting in a single, possibly large, patch segment of tiles. But, after a few iterations, the base becomes a polyline (see Fig. 39). Then, the process of selecting tiles evenly across longitude may, potentially, produce a fragmented selection, made of two or more separate patch segments (Fig. 40 shows an example of this). This fragmentation is inevitable, but it is not an obstacle. In general, a patch source produces several patch segments in order to fill its span of time. In the case of multiple patch segments, the solution is to schedule them separately, followed by a merge into a continuous single schedule.</p>
        <p>This section describes the core scheduling functionality for the computation of the EWS. We describe two algorithms that we used. Each algorithm takes a patch segment as input and produces an ordering of the tiles (i.e. a sequence) that is geomet- Fig. 40. Example of sibling patch segments from a fragmented patch source (of Fig. 39). New patch segments are displayed in shades of light blue, while previously observed patches are in dark blue. The discontinuities in longitude of the previously observed patches induce the fragmentation of this patch source. Tiles containing a blinding star are excluded from the observation, here displayed in orange. Tiles in the vicinity of an extremely bright star are also excluded (even if not containing it), as is the case of the star marked with a circle at ∼ (323, -36).This section describes the core scheduling functionality for the computation of the EWS. We describe two algorithms that we used. Each algorithm takes a patch segment as input and produces an ordering of the tiles (i.e. a sequence) that is geomet- Fig. 40. Example of sibling patch segments from a fragmented patch source (of Fig. 39). New patch segments are displayed in shades of light blue, while previously observed patches are in dark blue. The discontinuities in longitude of the previously observed patches induce the fragmentation of this patch source. Tiles containing a blinding star are excluded from the observation, here displayed in orange. Tiles in the vicinity of an extremely bright star are also excluded (even if not containing it), as is the case of the star marked with a circle at ∼ (323, -36).</p>
        <p>rically appropriate for observation (within the constraints of the spacecraft). We then describe how several patch segments, properly ordered, are combined in a single schedule.rically appropriate for observation (within the constraints of the spacecraft). We then describe how several patch segments, properly ordered, are combined in a single schedule.</p>
        <p>We describe first the 'look-ahead' algorithm and later on the 'diffusion' algorithm that replaced the former.We describe first the 'look-ahead' algorithm and later on the 'diffusion' algorithm that replaced the former.</p>
        <p>The look-ahead algorithm was the first successful attempt at scheduling a patch segment of tiles, within mission constraints, allowing the generation of a compliant survey. While superseded by the diffusion algorithm (Sect. 7.5.2), it gave much insight into the key factors at play, and paved the way for the design of the latest algorithm.The look-ahead algorithm was the first successful attempt at scheduling a patch segment of tiles, within mission constraints, allowing the generation of a compliant survey. While superseded by the diffusion algorithm (Sect. 7.5.2), it gave much insight into the key factors at play, and paved the way for the design of the latest algorithm.</p>
        <p>The look-ahead algorithm was designed around the idea that a scheduling sequence must traverse a patch segment of tiles following a 'natural' zigzag scheme, monotonously across ecliptic longitudes. At its core, the algorithm traverses the patch segment from right to left (longitude), going up and down (latitude), with minimal reversing of direction. The natural ordering is computed iteratively, moving from a given position and given direction of traversal (going-up or going-down) to the next. If the current direction is going-up, the next tile in the sequence is the first unvisited tile of the row above found by scanning the patch segment from right to left. Should that tile not exist, then the tile on the same row immediately to the left is selected. In the latter case, the direction is reversed from going-up to going-down, setting a flag that the top border of the patch segment was reached. If the current direction is going-down, the choices are reversed; the next tile in the sequence is the first unvisited tile of the row below found by scanning the patch segment from right to left or, if this does not exists, it is the tile on the same row immediately to the left. Likewise, in the later case, the direction is reversed from going-down to going-up, setting a flag that the bottom border was reached.The look-ahead algorithm was designed around the idea that a scheduling sequence must traverse a patch segment of tiles following a 'natural' zigzag scheme, monotonously across ecliptic longitudes. At its core, the algorithm traverses the patch segment from right to left (longitude), going up and down (latitude), with minimal reversing of direction. The natural ordering is computed iteratively, moving from a given position and given direction of traversal (going-up or going-down) to the next. If the current direction is going-up, the next tile in the sequence is the first unvisited tile of the row above found by scanning the patch segment from right to left. Should that tile not exist, then the tile on the same row immediately to the left is selected. In the latter case, the direction is reversed from going-up to going-down, setting a flag that the top border of the patch segment was reached. If the current direction is going-down, the choices are reversed; the next tile in the sequence is the first unvisited tile of the row below found by scanning the patch segment from right to left or, if this does not exists, it is the tile on the same row immediately to the left. Likewise, in the later case, the direction is reversed from going-down to going-up, setting a flag that the bottom border was reached.</p>
        <p>With this algorithm one can then define the full process. At the beginning, a starting tile is chosen (i.e. a tile on the rightmost side of the patch segment), as well as an initial direction, and a starting timestamp. Typically, there are many tiles close to A112, page 29 of 41 A&amp;A 662, A112 (2022) or at the same longitude as the rightmost tile; all are suitable as starting tiles. Afterwards, the algorithm computes a path to traverse the patch segment, propagating along timestamps for the observations of each tile.With this algorithm one can then define the full process. At the beginning, a starting tile is chosen (i.e. a tile on the rightmost side of the patch segment), as well as an initial direction, and a starting timestamp. Typically, there are many tiles close to A112, page 29 of 41 A&amp;A 662, A112 (2022) or at the same longitude as the rightmost tile; all are suitable as starting tiles. Afterwards, the algorithm computes a path to traverse the patch segment, propagating along timestamps for the observations of each tile.</p>
        <p>In general, this algorithm does not cover the patch segment completely. It may get stuck in one of three ways: (i) a dead-end is reached, with no unvisited tiles to jump to; (ii) an unvisited adjacent tile is identified, but it cannot be observed within the slew constraints; and (iii) a non-valid observation is encountered because an observation went outside the valid range of AA or SAA when assigning timestamps.In general, this algorithm does not cover the patch segment completely. It may get stuck in one of three ways: (i) a dead-end is reached, with no unvisited tiles to jump to; (ii) an unvisited adjacent tile is identified, but it cannot be observed within the slew constraints; and (iii) a non-valid observation is encountered because an observation went outside the valid range of AA or SAA when assigning timestamps.</p>
        <p>This can be understood as follows. Due to convergence towards the ecliptic poles, patch segments at high latitudes are very asymmetric, having most of their tiles either at the top or the bottom. In this case, a sequence of observations should spend more time at latitudes with many tiles, making only occasional excursions to less populated latitudes. However, the algorithm is designed for full vertical excursions (whenever possible). Also, some patch segments have unique geometric features; or corners odd enough to trap the single path of the traversing strategy.This can be understood as follows. Due to convergence towards the ecliptic poles, patch segments at high latitudes are very asymmetric, having most of their tiles either at the top or the bottom. In this case, a sequence of observations should spend more time at latitudes with many tiles, making only occasional excursions to less populated latitudes. However, the algorithm is designed for full vertical excursions (whenever possible). Also, some patch segments have unique geometric features; or corners odd enough to trap the single path of the traversing strategy.</p>
        <p>The solution is to extend the algorithm in two ways: making it explore more paths and allowing changes of direction in mid-excursion. The first should promote sequences that adapt to odd shapes, while the second should be able to cope with the asymmetry of patch segments at high latitudes. To these ends a 'probing step' is implemented. Instead of blindly progressing up and down, inverting direction only at the boundaries, the algorithm first runs two probes to determine if, in the next step, the sequence should advance by going-up or going-down (i.e. whether it should continue or invert direction).The solution is to extend the algorithm in two ways: making it explore more paths and allowing changes of direction in mid-excursion. The first should promote sequences that adapt to odd shapes, while the second should be able to cope with the asymmetry of patch segments at high latitudes. To these ends a 'probing step' is implemented. Instead of blindly progressing up and down, inverting direction only at the boundaries, the algorithm first runs two probes to determine if, in the next step, the sequence should advance by going-up or going-down (i.e. whether it should continue or invert direction).</p>
        <p>The probing step is simple. Before advancing, the algorithm first computes the natural sequence for the remaining unvisited tiles for two scenarios: first, for a natural sequence that continues going-up, and then for a natural sequence that continues goingdown. The direction to take for the next step is then given by the length of the two natural sequences just computed. If the lengths are different, it takes the direction of the longest sequence (possibly inverting direction), otherwise, it just keeps going in the same direction as before. The resulting sequence is obtained by applying this probing process iteratively, until all tiles are visited (returning success) or until the algorithm gets stuck (returning failure). As an optimisation, if one of the probing sequences traverses all of the remaining tiles, that sequence is taken and completes the schedule. If the above run fails, the process is repeated by trying other starting tiles (from the subset of tiles with longitude close to the rightmost tile). Varying the starting point explores different configurations, greatly improving the chances of success. Figure 41 illustrates this process.The probing step is simple. Before advancing, the algorithm first computes the natural sequence for the remaining unvisited tiles for two scenarios: first, for a natural sequence that continues going-up, and then for a natural sequence that continues goingdown. The direction to take for the next step is then given by the length of the two natural sequences just computed. If the lengths are different, it takes the direction of the longest sequence (possibly inverting direction), otherwise, it just keeps going in the same direction as before. The resulting sequence is obtained by applying this probing process iteratively, until all tiles are visited (returning success) or until the algorithm gets stuck (returning failure). As an optimisation, if one of the probing sequences traverses all of the remaining tiles, that sequence is taken and completes the schedule. If the above run fails, the process is repeated by trying other starting tiles (from the subset of tiles with longitude close to the rightmost tile). Varying the starting point explores different configurations, greatly improving the chances of success. Figure 41 illustrates this process.</p>
        <p>This algorithm was used to generate the EWS from the period of time between the mission PDR to the CDR. However, following the CDR it was realised that the resulting surveys exhibited uncontrolled excursions over the full AA range (visible in Fig. 41 and the left panel of Fig. 43), degrading the thermal stability of the telescope and thus affecting the PSF estimation. This was particularly acute for patch segments at high latitudes. Part of this failure is due to the restrictiveness of small slews, limited (at the time this was developed) to a maximum of 1 • .2. The slew range was then relaxed, allowing now for a small number of slews up to 3 • .6. However, the look-ahead algorithm is intrinsically limited by its simplicity and lack of flexibility (low number of parameters), making it difficult to accommodate new constraints such as skipping tiles with bright stars. These disadvantages prompted the development of a more capable algorithm, as explained in the following section.This algorithm was used to generate the EWS from the period of time between the mission PDR to the CDR. However, following the CDR it was realised that the resulting surveys exhibited uncontrolled excursions over the full AA range (visible in Fig. 41 and the left panel of Fig. 43), degrading the thermal stability of the telescope and thus affecting the PSF estimation. This was particularly acute for patch segments at high latitudes. Part of this failure is due to the restrictiveness of small slews, limited (at the time this was developed) to a maximum of 1 • .2. The slew range was then relaxed, allowing now for a small number of slews up to 3 • .6. However, the look-ahead algorithm is intrinsically limited by its simplicity and lack of flexibility (low number of parameters), making it difficult to accommodate new constraints such as skipping tiles with bright stars. These disadvantages prompted the development of a more capable algorithm, as explained in the following section.</p>
        <p>Following analysis of the full satellite structural thermal optical performance (STOP) made by Euclid's industrial prime contractor, we analysed the impact of the spacecraft attitude on the PSF stability. It was found that that, in addition to the applicable limitations on SAA and AA, a further minimisation of the field to field variation in these angles was desirable.Following analysis of the full satellite structural thermal optical performance (STOP) made by Euclid's industrial prime contractor, we analysed the impact of the spacecraft attitude on the PSF stability. It was found that that, in addition to the applicable limitations on SAA and AA, a further minimisation of the field to field variation in these angles was desirable.</p>
        <p>The new diffusion algorithm, which is presented here, achieves this goal, whilst also facilitating the avoidance of bright stars. To minimise the angle variations, the patch segment must be traversed in columns of alternating directions. This strategy avoids lateral slews on the same row that would cause spikes in δ AA and δ SAA , detrimental to PSF stability. Moreover, since the slew reach is longer in the vertical direction (see Sect. 2.5), moving mostly in the vertical direction increases the chances of successfully skipping across rows. This feature allows the algorithm to skip adjacent tiles (if already observed), and jump over holes created by bright stars.The new diffusion algorithm, which is presented here, achieves this goal, whilst also facilitating the avoidance of bright stars. To minimise the angle variations, the patch segment must be traversed in columns of alternating directions. This strategy avoids lateral slews on the same row that would cause spikes in δ AA and δ SAA , detrimental to PSF stability. Moreover, since the slew reach is longer in the vertical direction (see Sect. 2.5), moving mostly in the vertical direction increases the chances of successfully skipping across rows. This feature allows the algorithm to skip adjacent tiles (if already observed), and jump over holes created by bright stars.</p>
        <p>To illustrate the diffusion algorithm, we consider an input patch segment in the northern hemisphere close to the polar cap. The proximity to the pole highlights the patch segment convergence, which is relevant in this context. The same strategy is easily adapted to other latitudes (with less convergence) and the southern hemisphere (by swapping up and down). The algorithm is divided in two steps. The first step computes parts of the final sequence, called 'threads', which connects tiles along columns. The second step obtains the final sequence by tying adjacent threads together.To illustrate the diffusion algorithm, we consider an input patch segment in the northern hemisphere close to the polar cap. The proximity to the pole highlights the patch segment convergence, which is relevant in this context. The same strategy is easily adapted to other latitudes (with less convergence) and the southern hemisphere (by swapping up and down). The algorithm is divided in two steps. The first step computes parts of the final sequence, called 'threads', which connects tiles along columns. The second step obtains the final sequence by tying adjacent threads together.</p>
        <p>The computation of the threads begins by selecting the widest row of the patch segment (not necessarily the one at the bottom), assigning a thread to each of its tiles. Then, the threads A112, page 30 of 41 are computed in parallel, sequentially joining tiles of the current row with tiles of the row immediately above, until the top row is reached. The algorithm then returns to the starting point (the widest row), extending the threads downwards and thus completing the threads.The computation of the threads begins by selecting the widest row of the patch segment (not necessarily the one at the bottom), assigning a thread to each of its tiles. Then, the threads A112, page 30 of 41 are computed in parallel, sequentially joining tiles of the current row with tiles of the row immediately above, until the top row is reached. The algorithm then returns to the starting point (the widest row), extending the threads downwards and thus completing the threads.</p>
        <p>The double step approach is needed because, in general, the widest row is not at the bottom or at the top. Typically, a patch is bounded by a lat-long rectangle, like the examples of Figs. 41 and 42. However, patches alongside the RoI boundary may get asymmetrical shapes, acquiring some of the shape of the adjoining boundary. In those cases, the widest row is usually some row in the middle.The double step approach is needed because, in general, the widest row is not at the bottom or at the top. Typically, a patch is bounded by a lat-long rectangle, like the examples of Figs. 41 and 42. However, patches alongside the RoI boundary may get asymmetrical shapes, acquiring some of the shape of the adjoining boundary. In those cases, the widest row is usually some row in the middle.</p>
        <p>The computation of threads is based on two parameters of the rows: row length and row capacity. The length of a row i, len(i), is the number of tiles of that row. The capacity of a row i, cap(i), is the maximum length of a row or of any row above it, defining the minimum number of threads that must cross a given row. If cap(i) = len(i), then all threads visit all tiles in row i. If cap(i) &gt; len(i), then cap(i)-len(i) threads do not touch row i, and must skip it, but participate in some row above it. Due to the convergence towards the poles, the patch segments in the northern hemisphere funnel on the upper part. Similarly, the rows capacity reduces with increase in latitude.The computation of threads is based on two parameters of the rows: row length and row capacity. The length of a row i, len(i), is the number of tiles of that row. The capacity of a row i, cap(i), is the maximum length of a row or of any row above it, defining the minimum number of threads that must cross a given row. If cap(i) = len(i), then all threads visit all tiles in row i. If cap(i) &gt; len(i), then cap(i)-len(i) threads do not touch row i, and must skip it, but participate in some row above it. Due to the convergence towards the poles, the patch segments in the northern hemisphere funnel on the upper part. Similarly, the rows capacity reduces with increase in latitude.</p>
        <p>Let k be the row (or one of the rows) of largest length, being also the starting row for computing the threads. Each thread is initialised with exactly one tile, of row k. Let n thread be the initial number of threads. The process then begins by extending the threads, now at row k, to the tiles of row k + 1, guided by the following criteria that depend on len(k + 1) and cap(k + 1): (i) if len(k + 1) = n thread , then we have the simplest case with a one to one correspondence. It suffices to extend each thread to row k + 1 by making an ordered assignment, from right to left (ensuring the threads do not cross); (ii) if cap(k + 1) &lt; n thread ∧ cap(k + 1) &gt; n thread -2, then it is not possible to extend all threads, since the number of tiles of the row above is smaller than the number of threads. In this case, we extend the threads closely aligned to some tile of the row above it. This is performed by trying all combinations of ordered (non-crossing) assignments between a subset of len(k + 1) threads and all of the len(k + 1) tiles of row k + 1. For each trial combination that was accepted, we compute the cumulative variation in longitude ('verticality') of the thread. The combination with the lowest variation in longitude is selected, extending len(k + 1) threads (and leaving the rest unchanged); (iii) if cap(k + 2) &lt; n thread -2, it is also not possible to extend all the threads but, unlike the previous case, it is possible to eliminate a pair of threads (leaving n thread -2 threads). Actually, it is necessary to eliminate threads to avoid the risk of having threads stalled (i.e. not reaching the top of the patch). A pair of threads may be eliminated if they are adjacent in the list of threads. To eliminate them, it suffices to merge the two threads together, short-circuiting their paths, by connecting the two adjacent threads to the same tile (of row k + 1, creating an inverted 'v'). This case is slightly more complex than the previous one. Now, it needs to try all combinations of ordered (non-crossing) assignments between a subset of len(k + 1) + 1 threads and all of the len(k +1) tiles of row k +1, considering that pairs of consecutive threads extend to the same tile (merging those threads). Like before, all combinations are scored against verticality, selecting the one with lowest cumulative variation in longitude. It extends len(k + 1)-2 threads, leaving n thread -2 active threads, and merges two threads (ending their progress).Let k be the row (or one of the rows) of largest length, being also the starting row for computing the threads. Each thread is initialised with exactly one tile, of row k. Let n thread be the initial number of threads. The process then begins by extending the threads, now at row k, to the tiles of row k + 1, guided by the following criteria that depend on len(k + 1) and cap(k + 1): (i) if len(k + 1) = n thread , then we have the simplest case with a one to one correspondence. It suffices to extend each thread to row k + 1 by making an ordered assignment, from right to left (ensuring the threads do not cross); (ii) if cap(k + 1) &lt; n thread ∧ cap(k + 1) &gt; n thread -2, then it is not possible to extend all threads, since the number of tiles of the row above is smaller than the number of threads. In this case, we extend the threads closely aligned to some tile of the row above it. This is performed by trying all combinations of ordered (non-crossing) assignments between a subset of len(k + 1) threads and all of the len(k + 1) tiles of row k + 1. For each trial combination that was accepted, we compute the cumulative variation in longitude ('verticality') of the thread. The combination with the lowest variation in longitude is selected, extending len(k + 1) threads (and leaving the rest unchanged); (iii) if cap(k + 2) &lt; n thread -2, it is also not possible to extend all the threads but, unlike the previous case, it is possible to eliminate a pair of threads (leaving n thread -2 threads). Actually, it is necessary to eliminate threads to avoid the risk of having threads stalled (i.e. not reaching the top of the patch). A pair of threads may be eliminated if they are adjacent in the list of threads. To eliminate them, it suffices to merge the two threads together, short-circuiting their paths, by connecting the two adjacent threads to the same tile (of row k + 1, creating an inverted 'v'). This case is slightly more complex than the previous one. Now, it needs to try all combinations of ordered (non-crossing) assignments between a subset of len(k + 1) + 1 threads and all of the len(k +1) tiles of row k +1, considering that pairs of consecutive threads extend to the same tile (merging those threads). Like before, all combinations are scored against verticality, selecting the one with lowest cumulative variation in longitude. It extends len(k + 1)-2 threads, leaving n thread -2 active threads, and merges two threads (ending their progress).</p>
        <p>This process is illustrated in Fig. 42. Figure 42a shows the first step, extending threads from the initial row (in blue) to the row immediately above. Given the difference in row length, one thread is held up. After a few iterations, Fig. 42b shows a case where a thread on the left-side jumps over four threads (approximately at longitude 210 • , latitude 60-68 • ), and a thread in the middle (approximately at longitude 209 • , latitude 66-68 • ) is kept straightly vertical by skipping a row. This is an example of the capability of the diffusion process to adjust to a varying row length, by 'squeezing' more threads than the length of each individual row, promoting straighter threads. After a few more iterations, Fig. 42c shows two mergers of two neighbouring threads (rows at latitudes 70 • and 71 • ). This reduces the number of threads from seven to five (which is enough to cover the tiles of the rows above). This mechanism ensures a monotonous decrease in the number of threads, keeping it close to the row's capacity. Figure 42d shows the threads fully extended upwards (with two pair of threads ended being merged in the process). In this case, there is no need to extend the threads downwards also, since the starting row is also the bottom row. Lastly, Fig. 42e shows the final sequence, obtained after connecting adjacent threads (arrows show the temporal sequence of the covering).This process is illustrated in Fig. 42. Figure 42a shows the first step, extending threads from the initial row (in blue) to the row immediately above. Given the difference in row length, one thread is held up. After a few iterations, Fig. 42b shows a case where a thread on the left-side jumps over four threads (approximately at longitude 210 • , latitude 60-68 • ), and a thread in the middle (approximately at longitude 209 • , latitude 66-68 • ) is kept straightly vertical by skipping a row. This is an example of the capability of the diffusion process to adjust to a varying row length, by 'squeezing' more threads than the length of each individual row, promoting straighter threads. After a few more iterations, Fig. 42c shows two mergers of two neighbouring threads (rows at latitudes 70 • and 71 • ). This reduces the number of threads from seven to five (which is enough to cover the tiles of the rows above). This mechanism ensures a monotonous decrease in the number of threads, keeping it close to the row's capacity. Figure 42d shows the threads fully extended upwards (with two pair of threads ended being merged in the process). In this case, there is no need to extend the threads downwards also, since the starting row is also the bottom row. Lastly, Fig. 42e shows the final sequence, obtained after connecting adjacent threads (arrows show the temporal sequence of the covering).</p>
        <p>The net effect of the above strategy is to grow threads upwards, striving to be as vertical as possible, and merging adjacent threads when necessary, to cope with the reduction of rows capacity (with latitude). In a way, this growth resembles a diffusion process, hence its name. It should be noticed that the number of threads crossing each row may be larger than the actual number of tiles at that row. This is desirable. It is the mechanism that enables the threads to accommodate to the slight irregularities of the patch segment, while still be vertically aligned. In addition, this same mechanism allows the threads to skip tiles containing blinding stars (to be implemented in a future release).The net effect of the above strategy is to grow threads upwards, striving to be as vertical as possible, and merging adjacent threads when necessary, to cope with the reduction of rows capacity (with latitude). In a way, this growth resembles a diffusion process, hence its name. It should be noticed that the number of threads crossing each row may be larger than the actual number of tiles at that row. This is desirable. It is the mechanism that enables the threads to accommodate to the slight irregularities of the patch segment, while still be vertically aligned. In addition, this same mechanism allows the threads to skip tiles containing blinding stars (to be implemented in a future release).</p>
        <p>The input patch segment is bounded, by construction, to a lat-long rectangle. Therefore, in general, all the threads traverse the full extent of the patch segment, from top to bottom (the exception being the cases truncated by the RoI boundary). So, the thread endpoints (top and bottom) are expected to be close to each other meridian-wise. The final step of the computation is to pairwise connect the threads from right to left. This last step creates larger moves in longitude, detrimental for PSF stability. However, these moves are limited to the number of threads, which is much lower than the length of the patch segment).The input patch segment is bounded, by construction, to a lat-long rectangle. Therefore, in general, all the threads traverse the full extent of the patch segment, from top to bottom (the exception being the cases truncated by the RoI boundary). So, the thread endpoints (top and bottom) are expected to be close to each other meridian-wise. The final step of the computation is to pairwise connect the threads from right to left. This last step creates larger moves in longitude, detrimental for PSF stability. However, these moves are limited to the number of threads, which is much lower than the length of the patch segment).</p>
        <p>The diffusion algorithm is by far the most expensive part of the EWS computation, with the combinatorial exploration taking most of its cost. However, it has so far proven to be stable and robust, solving a large number of diverse patch segment configurations while optimising thermal stability, thus yielding a much more stable PSF. Figure 43 shows a comparison of the resulting AA field to field variation in the same patch, when scheduling it with the look-ahead algorithm versus diffusion algorithm. The time behaviour of AA in the latter case is much smoother and with fewer spikes than the previous results. This improvement translates into a better thermal stability and an overall decrease in time variations in the PSF, which therefore can be better modelled.The diffusion algorithm is by far the most expensive part of the EWS computation, with the combinatorial exploration taking most of its cost. However, it has so far proven to be stable and robust, solving a large number of diverse patch segment configurations while optimising thermal stability, thus yielding a much more stable PSF. Figure 43 shows a comparison of the resulting AA field to field variation in the same patch, when scheduling it with the look-ahead algorithm versus diffusion algorithm. The time behaviour of AA in the latter case is much smoother and with fewer spikes than the previous results. This improvement translates into a better thermal stability and an overall decrease in time variations in the PSF, which therefore can be better modelled.</p>
        <p>The diffusion algorithm proposes a sequence of observations for a pattern of tiles, which is a segment of a patch. This is the building block for computing a patch. First, the diffusion algorithm is applied to all patch segments of a patch source. Then, if all are successful, the resulting patch segments are linked together in a single observation sequence, by assigning timestamps for observation, generating a single sequence that covers the time slot of a survey window (i.e. a patch; see Fig. 44).The diffusion algorithm proposes a sequence of observations for a pattern of tiles, which is a segment of a patch. This is the building block for computing a patch. First, the diffusion algorithm is applied to all patch segments of a patch source. Then, if all are successful, the resulting patch segments are linked together in a single observation sequence, by assigning timestamps for observation, generating a single sequence that covers the time slot of a survey window (i.e. a patch; see Fig. 44).</p>
        <p>Timestamps are assigned adding observation and slew times along the order of the sequence, checking compliance with constraints. This is performed first forwards in time, starting at the pointing (quaternion and timestamp) that defines the start of the survey window. Next, the timestamp of the first observation is computed by adding the slew time from the start pointing. Then, the timestamp of the second time observation is computed by adding the ROS observation time (a fixed value) plus the slew time from the previous observation (a variable value). The process is repeated throughout the sequence, assigning timestamps sequentially. In this process, slew-times are computed according to the slew-time estimator. By construction, slews within a patch segment are expected to be small slews. In contrast, jumps between patch segments are considered to be large slews, adding to the large-slew budget. However, this number of large slews is relatively small. Typically, survey windows are filled with patches generated from one or two patch sources, with each patch being split in a low number of patch segments, at most. Hence, the initial ∼100 survey windows produce no more than a few hundred patch segments in the end.Timestamps are assigned adding observation and slew times along the order of the sequence, checking compliance with constraints. This is performed first forwards in time, starting at the pointing (quaternion and timestamp) that defines the start of the survey window. Next, the timestamp of the first observation is computed by adding the slew time from the start pointing. Then, the timestamp of the second time observation is computed by adding the ROS observation time (a fixed value) plus the slew time from the previous observation (a variable value). The process is repeated throughout the sequence, assigning timestamps sequentially. In this process, slew-times are computed according to the slew-time estimator. By construction, slews within a patch segment are expected to be small slews. In contrast, jumps between patch segments are considered to be large slews, adding to the large-slew budget. However, this number of large slews is relatively small. Typically, survey windows are filled with patches generated from one or two patch sources, with each patch being split in a low number of patch segments, at most. Hence, the initial ∼100 survey windows produce no more than a few hundred patch segments in the end.</p>
        <p>As explained above, the algorithm first attempts to assign timestamps from the beginning of the survey window forwards. If this succeeds, it creates a patch flushed backwards in time, leaving some idle time at the end of the window. This is because in general, an integer number of observations with varying slewtimes does not fit perfectly into the slot of time previously defined by a survey window. If this succeeds, this is the preferable solution. If it fails, then a reverse assignment is attempted, assigning timestamps from the end of the survey window backwards (and reversing the computations of slew-time). If this succeeds, it may leave some idle-time at the beginning of the window.As explained above, the algorithm first attempts to assign timestamps from the beginning of the survey window forwards. If this succeeds, it creates a patch flushed backwards in time, leaving some idle time at the end of the window. This is because in general, an integer number of observations with varying slewtimes does not fit perfectly into the slot of time previously defined by a survey window. If this succeeds, this is the preferable solution. If it fails, then a reverse assignment is attempted, assigning timestamps from the end of the survey window backwards (and reversing the computations of slew-time). If this succeeds, it may leave some idle-time at the beginning of the window.</p>
        <p>Usually, there is a sufficient number of tiles distributed along the range of longitudes (covered by a patch source) to generate a patch covering all the time slot of a survey window. However, in some cases, such as when a patch source intersects only a corner of a quadrant, it is not possible to have a path extending the full width of the respective survey window. Trying to flush a patch to both end-sides of a survey window enables patching those odd cases, promoting also the generation of patches that adapt to the boundary of the RoI.Usually, there is a sufficient number of tiles distributed along the range of longitudes (covered by a patch source) to generate a patch covering all the time slot of a survey window. However, in some cases, such as when a patch source intersects only a corner of a quadrant, it is not possible to have a path extending the full width of the respective survey window. Trying to flush a patch to both end-sides of a survey window enables patching those odd cases, promoting also the generation of patches that adapt to the boundary of the RoI.</p>
        <p>In the process of assigning timestamps, an observation of a field with a given timestamp may fail to comply with the constraints of SAA and/or AA. If, at any point, a failure of compliance is encountered, the computation is terminated and all segments are discarded. The rationale for this strategy is simple: if a sequence, computed as parallel to meridians as possible, fails the timestamp assignment, then it might not be viable in the first place. Most likely, in those cases, the patch has some geometry feature that stretches the scheduling flexibility too far. The result of this stage is a patch that is flushed, time-wise, to the beginning or to the end of the interval of time allotted to it. The path is thus a composite structure, made by a string of segments.In the process of assigning timestamps, an observation of a field with a given timestamp may fail to comply with the constraints of SAA and/or AA. If, at any point, a failure of compliance is encountered, the computation is terminated and all segments are discarded. The rationale for this strategy is simple: if a sequence, computed as parallel to meridians as possible, fails the timestamp assignment, then it might not be viable in the first place. Most likely, in those cases, the patch has some geometry feature that stretches the scheduling flexibility too far. The result of this stage is a patch that is flushed, time-wise, to the beginning or to the end of the interval of time allotted to it. The path is thus a composite structure, made by a string of segments.</p>
        <p>The EWS is computed sequentially, covering the RoI by placing one patch at a time. In some way, it is like solving a jigsaw puzzle on a surface of a sphere, but where the shapes of the pieces are not fixed from the start, instead being computed as the scheduling progresses. Two objectives guide the buildup of the EWS, which can be summarised as: 'observe as much as possible, as early as possible'. More specifically: (i) we want a compact footprint (per quadrant), so that the footprint of observations forms a single, continuous region, implying that patches should match perfectly next to each other, with no holes in between 10 ; and (ii) we want to observe fields as early as possible, which means that all slots in survey windows are assigned to observations, provided there is an unobserved part of the RoI within reach. We note that, given the cyclic nature of the process, after a few iter-ations, the RoI within reach of some of the survey windows is typically scheduled.The EWS is computed sequentially, covering the RoI by placing one patch at a time. In some way, it is like solving a jigsaw puzzle on a surface of a sphere, but where the shapes of the pieces are not fixed from the start, instead being computed as the scheduling progresses. Two objectives guide the buildup of the EWS, which can be summarised as: 'observe as much as possible, as early as possible'. More specifically: (i) we want a compact footprint (per quadrant), so that the footprint of observations forms a single, continuous region, implying that patches should match perfectly next to each other, with no holes in between 10 ; and (ii) we want to observe fields as early as possible, which means that all slots in survey windows are assigned to observations, provided there is an unobserved part of the RoI within reach. We note that, given the cyclic nature of the process, after a few iter-ations, the RoI within reach of some of the survey windows is typically scheduled.</p>
        <p>Eventually, either no area is left to schedule (within a range of latitudes of the RoI) or there is no time left (within the six years of the mission). When no suitable area can be scheduled for a given period, the schedule just leaves it unassigned, giving rise to unallocated time. This highlights that presently it is not possible to assign it to particular observations, but that it can be done at a later time.Eventually, either no area is left to schedule (within a range of latitudes of the RoI) or there is no time left (within the six years of the mission). When no suitable area can be scheduled for a given period, the schedule just leaves it unassigned, giving rise to unallocated time. This highlights that presently it is not possible to assign it to particular observations, but that it can be done at a later time.</p>
        <p>The EWS is computed by filling the RoI one survey window at the time, in chronological order. At each step, a survey window is processed by assigning observations to its time slot. As explained below, this may require a few iterations. Only when all possible assignments are handled, the computation moves on to the next survey window.The EWS is computed by filling the RoI one survey window at the time, in chronological order. At each step, a survey window is processed by assigning observations to its time slot. As explained below, this may require a few iterations. Only when all possible assignments are handled, the computation moves on to the next survey window.</p>
        <p>As discussed in Sect. 7.4.3, each survey window generates one or more patch sources, which in turn may generate one patch (made of a single patch segment or of a string of several patch segments), flushed to the beginning or to the end of its survey window. All the patches are continuously linked to a particular stage-1 observation (e.g. a calibration, deep-field, or polar cap patch). All these patches compete for the same slot of time, and we need to decide which patch to add to the survey. In general, the choice is to build the EWS layer by layer of ecliptic latitude, striving to go from high to low S/N regions. When this criteria is not decisive, the choice is to select the patch that better matches (horizontally, along ecliptic latitudes) some previously selected adjacent patch.As discussed in Sect. 7.4.3, each survey window generates one or more patch sources, which in turn may generate one patch (made of a single patch segment or of a string of several patch segments), flushed to the beginning or to the end of its survey window. All the patches are continuously linked to a particular stage-1 observation (e.g. a calibration, deep-field, or polar cap patch). All these patches compete for the same slot of time, and we need to decide which patch to add to the survey. In general, the choice is to build the EWS layer by layer of ecliptic latitude, striving to go from high to low S/N regions. When this criteria is not decisive, the choice is to select the patch that better matches (horizontally, along ecliptic latitudes) some previously selected adjacent patch.</p>
        <p>The last step in the processing of a survey window is to place PSF calibrations and SOPs. At most, one PSF calibrations is inserted per window. This is achieved by analysing the patches just selected, identifying the timestamps where a PSF calibration target is within reach. A jump to a PSF calibration takes place at the end of some wide observation. Typically, a single patch generates several such candidates. In parallel, candidate timestamps for the required SOPs are identified. Again, these are timestamps of the end of some wide observation. There are one to two SOP candidates per window, at most. Then, the two types of candidates are considered, inserting them in chronological order; one PSF calibration, if available, and one or two required SOPs. Among all PSF candidates, preference is given to the ones occurring between patch segments or between a preceding SOP and a following patch segment, in order to save large slews. The insertion is performed by cutting a wide patch at the required timestamp, adding the PSF calibration or the SOP, and pushing the remaining of the patch forwards in time. This process may require also an adjustment of the following calibration block, pushing it forwards in time (if now overlapped by the preceding patch). The process of SOP insertion is also applied to the following calibration block before processing the next survey window.The last step in the processing of a survey window is to place PSF calibrations and SOPs. At most, one PSF calibrations is inserted per window. This is achieved by analysing the patches just selected, identifying the timestamps where a PSF calibration target is within reach. A jump to a PSF calibration takes place at the end of some wide observation. Typically, a single patch generates several such candidates. In parallel, candidate timestamps for the required SOPs are identified. Again, these are timestamps of the end of some wide observation. There are one to two SOP candidates per window, at most. Then, the two types of candidates are considered, inserting them in chronological order; one PSF calibration, if available, and one or two required SOPs. Among all PSF candidates, preference is given to the ones occurring between patch segments or between a preceding SOP and a following patch segment, in order to save large slews. The insertion is performed by cutting a wide patch at the required timestamp, adding the PSF calibration or the SOP, and pushing the remaining of the patch forwards in time. This process may require also an adjustment of the following calibration block, pushing it forwards in time (if now overlapped by the preceding patch). The process of SOP insertion is also applied to the following calibration block before processing the next survey window.</p>
        <p>The islands are located at lower latitudes and comprise less area. Consequently, most of the survey buildup is shared between the two mainlands (I and IV; see Fig. 17) with the islands (II and III) becoming relevant in the last year of the survey. This can be seen in Fig. 45, which shows an example of the buildup of EWS patches over the duration of the mission, coloured from deep blue to light blue as time progresses. This strategy does not only forces the two mainlands to grow at an equal rate but, more importantly, it is crucial to guarantee a compact survey footprint.The islands are located at lower latitudes and comprise less area. Consequently, most of the survey buildup is shared between the two mainlands (I and IV; see Fig. 17) with the islands (II and III) becoming relevant in the last year of the survey. This can be seen in Fig. 45, which shows an example of the buildup of EWS patches over the duration of the mission, coloured from deep blue to light blue as time progresses. This strategy does not only forces the two mainlands to grow at an equal rate but, more importantly, it is crucial to guarantee a compact survey footprint.</p>
        <p>The height of a patch is dictated by the speed of the orbit, which varies slightly with latitude. It roughly corresponds to the time the orbit takes to scan the width of a FoV divided by the nominal observation time. To some degree, the height (and In the main panel the EWS patches are coloured according to different years, in correspondence to the time bars below. The part of the RoI that is not observed is in light green (we recall that the RoI covers an area larger than the one needed to be observed). Under the main panel, the progression over the six years is unfolded, with two rows for each year indicating the trailing and leading directions of the telescope. Different colours represent the progression in time, from deep blue to light blue, whereas the thin line segments represent time intervals reserved for calibrations and deep fields. The light grey boxes for the leading or trailing directions mark when the telescope is actually observing in the opposite direction (for each grey box there is a corresponding coloured box). Towards the end of the mission, some of the survey windows are completely or partially light red, showing that that particular time slot has run out of sky areas to observe. width) may vary slightly from its natural size (approximately, ±2 rows). Hence, in practice the height of a patch is more or less fixed, making the layer approach optimal. It guarantees a maximum of free RoI above previously computed patches, giving ample space (i.e. height) for the generation of each new patch. The sole exception is when the top layer of the survey reaches the boundary of the RoI. If the available height is less than the minimum patch height, the patch generation fails. Due to the layering approach, this obstacle arises only for a small part of the RoI, namely the top layer of each quadrant. For the rest of the RoI, the stacking of patches ensures a compact filling.The height of a patch is dictated by the speed of the orbit, which varies slightly with latitude. It roughly corresponds to the time the orbit takes to scan the width of a FoV divided by the nominal observation time. To some degree, the height (and In the main panel the EWS patches are coloured according to different years, in correspondence to the time bars below. The part of the RoI that is not observed is in light green (we recall that the RoI covers an area larger than the one needed to be observed). Under the main panel, the progression over the six years is unfolded, with two rows for each year indicating the trailing and leading directions of the telescope. Different colours represent the progression in time, from deep blue to light blue, whereas the thin line segments represent time intervals reserved for calibrations and deep fields. The light grey boxes for the leading or trailing directions mark when the telescope is actually observing in the opposite direction (for each grey box there is a corresponding coloured box). Towards the end of the mission, some of the survey windows are completely or partially light red, showing that that particular time slot has run out of sky areas to observe. width) may vary slightly from its natural size (approximately, ±2 rows). Hence, in practice the height of a patch is more or less fixed, making the layer approach optimal. It guarantees a maximum of free RoI above previously computed patches, giving ample space (i.e. height) for the generation of each new patch. The sole exception is when the top layer of the survey reaches the boundary of the RoI. If the available height is less than the minimum patch height, the patch generation fails. Due to the layering approach, this obstacle arises only for a small part of the RoI, namely the top layer of each quadrant. For the rest of the RoI, the stacking of patches ensures a compact filling.</p>
        <p>In this section we present the latest version of the Euclid RSD, RSD_2021A. This is the result of the stage-1 and stage-2 scheduling procedures (cf. Sects. 6.3 and 7), and the corresponding ECTile outputs are the ones shown in Figs. 29 and45.In this section we present the latest version of the Euclid RSD, RSD_2021A. This is the result of the stage-1 and stage-2 scheduling procedures (cf. Sects. 6.3 and 7), and the corresponding ECTile outputs are the ones shown in Figs. 29 and45.</p>
        <p>We recall that the RSD observations start three months after launch. They are preceded by a one-month commissioning phase, followed by a two-month PV phase. During the PV phase the first survey-like data will be obtained, which are used to verify the data processing, and to validate and eventually tune or adjust the nominal sequence of operations (possible minor changes to the RSD can be implemented in less than one week time, producing a new version of the RSD; more complex changes of course require more time). Moreover, during PV some survey specific observations will be carried out. The latter will, for instance, provide direct measurements of the zodiacal light and stray light to verify and refine our models.We recall that the RSD observations start three months after launch. They are preceded by a one-month commissioning phase, followed by a two-month PV phase. During the PV phase the first survey-like data will be obtained, which are used to verify the data processing, and to validate and eventually tune or adjust the nominal sequence of operations (possible minor changes to the RSD can be implemented in less than one week time, producing a new version of the RSD; more complex changes of course require more time). Moreover, during PV some survey specific observations will be carried out. The latter will, for instance, provide direct measurements of the zodiacal light and stray light to verify and refine our models.</p>
        <p>Figure 46 shows the footprint of RSD_2021A The different colours indicate different observing epochs of the EWS. The three EDFs and the six EAFs (cf. Sect. 6.2) are tied into the EWS. In the two mainlands of the EWS, the observations start from the ecliptic poles and progress towards the equator. The best sky areas around both Galactic caps are covered within the first three years of the mission. The observations of the two EWS islands only take place in the final two years of the mission. We note that some of the worst parts of the RoI (totalling an A112, page 34 of 41 , are observable at the same time since they are separated by 180 • . They contain much area within the RoI, and moreover the EDF-F and EDF-S are also located there. This means that there is not enough time for the EWS to observe all that area in the six years of the mission and hence their worst-quality regions are not observed.Figure 46 shows the footprint of RSD_2021A The different colours indicate different observing epochs of the EWS. The three EDFs and the six EAFs (cf. Sect. 6.2) are tied into the EWS. In the two mainlands of the EWS, the observations start from the ecliptic poles and progress towards the equator. The best sky areas around both Galactic caps are covered within the first three years of the mission. The observations of the two EWS islands only take place in the final two years of the mission. We note that some of the worst parts of the RoI (totalling an A112, page 34 of 41 , are observable at the same time since they are separated by 180 • . They contain much area within the RoI, and moreover the EDF-F and EDF-S are also located there. This means that there is not enough time for the EWS to observe all that area in the six years of the mission and hence their worst-quality regions are not observed.</p>
        <p>The RSD contains 44 065 fields (28 080 to build the EWS and 15 985 for EDFs, EAFs and calibration targets observations). The EWS fields are contained in 256 patches (seen in Figs. 45 and46). The vast majority of the field slews, used to point the telescope, are below 1 • .2, as shown in the right panel of Fig. 47. This is the most efficient slew regime in terms of propellant usage. As shown in Fig. 47, all telescope rotations are done within the allowed SAA and AA limits. Most of the observations are done close to transit, with 90% of the SAA values used between 88 • and 94 • . The statistics of AA usage shows that 71% of the telescope rotations are done with |AA| &lt; 1 • . Even though SAA and AA values spread over the full range allowed, the field-to-field variations (between consecutive observations) of SAA and AA are very small throughout the survey: smaller than 1 • in 97.4% (SAA) and 98.6% (AA) of the field-to-field transitions over the full mission. This feature is extremely important for the thermal stability, which ensures a stable PSF for WL shape measurements. It was possible to achieve this performance thanks to the implementation of the diffusion algorithm described in Sect. 7.5.2.The RSD contains 44 065 fields (28 080 to build the EWS and 15 985 for EDFs, EAFs and calibration targets observations). The EWS fields are contained in 256 patches (seen in Figs. 45 and46). The vast majority of the field slews, used to point the telescope, are below 1 • .2, as shown in the right panel of Fig. 47. This is the most efficient slew regime in terms of propellant usage. As shown in Fig. 47, all telescope rotations are done within the allowed SAA and AA limits. Most of the observations are done close to transit, with 90% of the SAA values used between 88 • and 94 • . The statistics of AA usage shows that 71% of the telescope rotations are done with |AA| &lt; 1 • . Even though SAA and AA values spread over the full range allowed, the field-to-field variations (between consecutive observations) of SAA and AA are very small throughout the survey: smaller than 1 • in 97.4% (SAA) and 98.6% (AA) of the field-to-field transitions over the full mission. This feature is extremely important for the thermal stability, which ensures a stable PSF for WL shape measurements. It was possible to achieve this performance thanks to the implementation of the diffusion algorithm described in Sect. 7.5.2.</p>
        <p>The existence of a deficit of area on some longitudes (see Sect. 5.2.1), compared to the available observing time, is evi-dent from Fig. 48. The blue curve is the area available in the RoI at a given ecliptic longitude (in bins of 1 • ). The RoI areas in longitudes separated by 180 • are added, since that pair of longitudes can be observed at the same time, from the trailing or the leading direction. Due to this six-month periodicity, the x-axis range only extends to 180 • . The red curve denotes the cumulated number of days during which a given longitude is visible for EWS observations, assuming transit observations, and converted to equivalent area (1 day corresponding to 10 deg 2 ). The available time is not uniform, it is determined after the stage-1 schedule is defined (see Sect. 6.3), which creates a strong variation along the year (i.e. wiggles in the red curve). For example, the absolute minimum corresponds to the highly booked longitudes of the EDFF and EDFS, where less time is left for EWS observations.The existence of a deficit of area on some longitudes (see Sect. 5.2.1), compared to the available observing time, is evi-dent from Fig. 48. The blue curve is the area available in the RoI at a given ecliptic longitude (in bins of 1 • ). The RoI areas in longitudes separated by 180 • are added, since that pair of longitudes can be observed at the same time, from the trailing or the leading direction. Due to this six-month periodicity, the x-axis range only extends to 180 • . The red curve denotes the cumulated number of days during which a given longitude is visible for EWS observations, assuming transit observations, and converted to equivalent area (1 day corresponding to 10 deg 2 ). The available time is not uniform, it is determined after the stage-1 schedule is defined (see Sect. 6.3), which creates a strong variation along the year (i.e. wiggles in the red curve). For example, the absolute minimum corresponds to the highly booked longitudes of the EDFF and EDFS, where less time is left for EWS observations.</p>
        <p>In longitudes where the red curve is above the blue curve, there is a deficit of area for the time available for EWS, leading to unallocated time. Conversely, in longitudes where the blue curve is above the red curve, there is an excess of area for the time available for EWS, leading to unobserved areas in the RoI. In Fig. 46 this corresponds to the areas with no patches, which clearly are on the areas of the RoI of worst quality.In longitudes where the red curve is above the blue curve, there is a deficit of area for the time available for EWS, leading to unallocated time. Conversely, in longitudes where the blue curve is above the red curve, there is an excess of area for the time available for EWS, leading to unobserved areas in the RoI. In Fig. 46 this corresponds to the areas with no patches, which clearly are on the areas of the RoI of worst quality.</p>
        <p>We note that the presence of unallocated time in the EWS schedule does not mean that there will be any idle time, because some areas of the EWS may be re-observed or new areas that do not qualify for the EWS, but have scientific value nonetheless, may be observed instead. In doing so, we can either consider fields that are observable within the thermal and pointing constraints enforced for the EWS, or we can operate outside these constraints, thus with the risk of perturbing the continuation of the EWS afterwards. Therefore, one needs to have the real inflight characteristics to get a solid picture of the possibilities and constraints.We note that the presence of unallocated time in the EWS schedule does not mean that there will be any idle time, because some areas of the EWS may be re-observed or new areas that do not qualify for the EWS, but have scientific value nonetheless, may be observed instead. In doing so, we can either consider fields that are observable within the thermal and pointing constraints enforced for the EWS, or we can operate outside these constraints, thus with the risk of perturbing the continuation of the EWS afterwards. Therefore, one needs to have the real inflight characteristics to get a solid picture of the possibilities and constraints.</p>
        <p>Fig. 48. Area of the RoI as a function of (folded) longitude (blue). The equivalent area is visible as a function of (folded) longitude (red). The area is the available RoI area at transit per degree of longitude. The red curve assumes that the EWS observations are done at transit. Unallocated time arises when the red curve is above the blue curve. See text for details. Some examples that maintain the strict survey limitations are: (i) possible multiple exposures (4) on areas in the ecliptic plane that do not qualify for S/N with ROS single visit; (ii) possible decontamination procedures; (iii) repeat some suitable but lower-quality EWS regions to boost their S/N, or fill possible gaps due to unexpected events that might interrupt the basic scheduling; (iv) increase the depth of the self-cal field, which could become a reference field for a dedicated supernova programme in a possible extension of the mission; (v) build a Euclid medium deep field (EMDF) covering 200-300 deg 2 ; (vi) that is one magnitude deeper than the EWS (this would require five additional visits that would preferentially be done once every year); observe suitable astronomical objects that are located outside the RoI that would benefit from localised revisits, such as observations on the ecliptic or Galactic plane, Galactic bulge (e.g. microlensing), specific low surface brightness objects, nearby galaxies, or clusters of galaxies; (vii) use of the blue grism on targets during new or repeated visits on specific targets. How to best use the time that cannot be used for single pass EWS will be decided at a later stage upon a consolidated scenario by the Euclid Science Team and ESA.Fig. 48. Area of the RoI as a function of (folded) longitude (blue). The equivalent area is visible as a function of (folded) longitude (red). The area is the available RoI area at transit per degree of longitude. The red curve assumes that the EWS observations are done at transit. Unallocated time arises when the red curve is above the blue curve. See text for details. Some examples that maintain the strict survey limitations are: (i) possible multiple exposures (4) on areas in the ecliptic plane that do not qualify for S/N with ROS single visit; (ii) possible decontamination procedures; (iii) repeat some suitable but lower-quality EWS regions to boost their S/N, or fill possible gaps due to unexpected events that might interrupt the basic scheduling; (iv) increase the depth of the self-cal field, which could become a reference field for a dedicated supernova programme in a possible extension of the mission; (v) build a Euclid medium deep field (EMDF) covering 200-300 deg 2 ; (vi) that is one magnitude deeper than the EWS (this would require five additional visits that would preferentially be done once every year); observe suitable astronomical objects that are located outside the RoI that would benefit from localised revisits, such as observations on the ecliptic or Galactic plane, Galactic bulge (e.g. microlensing), specific low surface brightness objects, nearby galaxies, or clusters of galaxies; (vii) use of the blue grism on targets during new or repeated visits on specific targets. How to best use the time that cannot be used for single pass EWS will be decided at a later stage upon a consolidated scenario by the Euclid Science Team and ESA.</p>
        <p>The area of the RSD_2021A Euclid footprint is 14 514 deg 2 . Table 9 lists the observed EWS area at the end of each year of the mission, while the growth with time of the area covered by the EWS is shown in Fig. 49.The area of the RSD_2021A Euclid footprint is 14 514 deg 2 . Table 9 lists the observed EWS area at the end of each year of the mission, while the growth with time of the area covered by the EWS is shown in Fig. 49.</p>
        <p>During the first year many calibration observations are scheduled to support the first data releases. As a result, the EWS initially progresses slower than in the second and third year, but it still reaches an area in excess of 2500 deg 2 . At the end of the third year, more periods occur when standard EWS A112, page 36 of 41 observations cannot be made due to the increasing paucity of available unobserved areas within the RoI; the slope of the growth in time flattens there, causing the staircase-like pattern seen in Fig. 49. These periods of 'unallocated time' (see Sect. 8.2) have a 6-month periodicity due to the intersection of the Galactic plane with the ecliptic plane, have an increasing duration and slow down the progression of the EWS.During the first year many calibration observations are scheduled to support the first data releases. As a result, the EWS initially progresses slower than in the second and third year, but it still reaches an area in excess of 2500 deg 2 . At the end of the third year, more periods occur when standard EWS A112, page 36 of 41 observations cannot be made due to the increasing paucity of available unobserved areas within the RoI; the slope of the growth in time flattens there, causing the staircase-like pattern seen in Fig. 49. These periods of 'unallocated time' (see Sect. 8.2) have a 6-month periodicity due to the intersection of the Galactic plane with the ecliptic plane, have an increasing duration and slow down the progression of the EWS.</p>
        <p>The time available to implement the EWS, once the other mandatory observations are carried out and the geometry of the RoI is taken into account, is an important input for the construction of the EWS and the final covered areas. In RSD_2021A this time is 2190 -427 -39 -292 = 1432 days, where 427 days are used for calibrations, EDF and EAF observations, 39 days are reserved for SOP and there are 292 unallocated days (Fig. 50 depicts the time allocation breakdown). Given the length of the ROS, close to 4400 s per field (Sect. 4.1), and the FoV of 0.53 deg 2 (Sect. 3.3), the effective EWS area increases by 10.1 deg 2 per day, (considering the effective average field overlap of 3%). This means that, with the current calibration, EDFs, EAFs, and SOP required times, the EWS can reach an area of 15 000 deg 2 only if the unallocated time is shorter than 240 days.The time available to implement the EWS, once the other mandatory observations are carried out and the geometry of the RoI is taken into account, is an important input for the construction of the EWS and the final covered areas. In RSD_2021A this time is 2190 -427 -39 -292 = 1432 days, where 427 days are used for calibrations, EDF and EAF observations, 39 days are reserved for SOP and there are 292 unallocated days (Fig. 50 depicts the time allocation breakdown). Given the length of the ROS, close to 4400 s per field (Sect. 4.1), and the FoV of 0.53 deg 2 (Sect. 3.3), the effective EWS area increases by 10.1 deg 2 per day, (considering the effective average field overlap of 3%). This means that, with the current calibration, EDFs, EAFs, and SOP required times, the EWS can reach an area of 15 000 deg 2 only if the unallocated time is shorter than 240 days.</p>
        <p>The time available for the EWS has generally decreased over the years, as the mission matured. Figure 51 depicts this evolution, indicating the driving changing factor for each transition (modifications in calibrations, RoI or ROS). In earlier surveys, such as the RSD_2015A prepared for PDR, the time needed for calibrations was small and the RoI was larger (driven by WL counts). In early 2018, RSD_2018A used for SPV2 introduced a smaller RoI based on the more restrictive conditions for GC, which led to a larger distance from the Galactic plane (because of effects from star density on spectra), with a smaller area to be observed and an increase in unallocated time (cf. Sect. 8.2). Shortly after, a major redefinition of the calibration plan, increased its allocated time by 100 days. At the same time the redefinition of the slew concept (see Sect. 7.4.2) made it no longer possible to schedule the EWS at high latitudes with the global tessellation, leading to a faster filling of the EWS and a faster buildup of unallocated time. These two factors led to a strong decrease in the EWS available time in RSD_2018B for CDR (Laureijs et al. 2020). In 2019, RSD_2019A introduced a new algorithm to schedule the high-latitude regions. Given the fact that the throughputs were measured to be larger than specified, the RoI was reverted to the limits defined in Laureijs et al. (2011). The larger area of this RoI led to an increase in the available time for the EWS, and to a solution that covered 15 000 deg 2 . The year 2020 introduced the new, better highquality RoI, described in Sect. 5, based on the latest estimates of S/N. This again decreased the available EWS time, now causing the RSD_2020A to barely reach 15 000 deg 2 . In RSD_2020B the diffusion algorithm was introduced to increase thermal stability. This was achieved without decreasing the schedule efficiency and the available time for the EWS. Nevertheless the EWS time decreased due to a further increase in time needed for the calibrations. Finally, in RSD_2021A we implemented the skipping of bright stars, together with the latest revised times for both ROS (significant increase in the duration of the dither steps) and SOP (halved).The time available for the EWS has generally decreased over the years, as the mission matured. Figure 51 depicts this evolution, indicating the driving changing factor for each transition (modifications in calibrations, RoI or ROS). In earlier surveys, such as the RSD_2015A prepared for PDR, the time needed for calibrations was small and the RoI was larger (driven by WL counts). In early 2018, RSD_2018A used for SPV2 introduced a smaller RoI based on the more restrictive conditions for GC, which led to a larger distance from the Galactic plane (because of effects from star density on spectra), with a smaller area to be observed and an increase in unallocated time (cf. Sect. 8.2). Shortly after, a major redefinition of the calibration plan, increased its allocated time by 100 days. At the same time the redefinition of the slew concept (see Sect. 7.4.2) made it no longer possible to schedule the EWS at high latitudes with the global tessellation, leading to a faster filling of the EWS and a faster buildup of unallocated time. These two factors led to a strong decrease in the EWS available time in RSD_2018B for CDR (Laureijs et al. 2020). In 2019, RSD_2019A introduced a new algorithm to schedule the high-latitude regions. Given the fact that the throughputs were measured to be larger than specified, the RoI was reverted to the limits defined in Laureijs et al. (2011). The larger area of this RoI led to an increase in the available time for the EWS, and to a solution that covered 15 000 deg 2 . The year 2020 introduced the new, better highquality RoI, described in Sect. 5, based on the latest estimates of S/N. This again decreased the available EWS time, now causing the RSD_2020A to barely reach 15 000 deg 2 . In RSD_2020B the diffusion algorithm was introduced to increase thermal stability. This was achieved without decreasing the schedule efficiency and the available time for the EWS. Nevertheless the EWS time decreased due to a further increase in time needed for the calibrations. Finally, in RSD_2021A we implemented the skipping of bright stars, together with the latest revised times for both ROS (significant increase in the duration of the dither steps) and SOP (halved).</p>
        <p>RSD_2021A falls short of covering the desired 15 000 deg 2 area for the EWS by ∼3%. The missing 486 deg 2 are the equivalent of one and a half months of EWS observing time. In part this can be recovered by making local tessellations, to allow shifting the position of the centre of the tiles affected by stars, so as to avoid the blinding stars falling on the detectors, instead of skipping the whole tile. Moreover, it is expected that the EWS available time will further decrease sightly with the insertion of the complete set of PSF calibrations. In fact, the expected cadence is not yet fully respected in RSD_2021A, because the stringent stability constraints could not always be fulfilled, especially in the final years of the survey. Study is underway to tackle this issue and, once this problem will be solved, the time needed amounts to ≈10 days (100 deg 2 ) to be taken off from the EWS present coverage. It must be noticed, however, that a 3% reduction in survey area translates into a comparable reduction in the final DE FoM (actually even less since the still uncovered areas of the RoI are of lower quality than the average). An area a few percent lower than originally expected is therefore of no consequence for achieving the original goal of the mission, that is, a FoM larger than 400 from the two main probes for a w 0 -w a CDM model with no other prior information (Laureijs et al. 2011). Indeed, for the present coverage, one preliminarily expects the FoM to scale down from 500 (Euclid Collaboration 2020a) to ≈480.RSD_2021A falls short of covering the desired 15 000 deg 2 area for the EWS by ∼3%. The missing 486 deg 2 are the equivalent of one and a half months of EWS observing time. In part this can be recovered by making local tessellations, to allow shifting the position of the centre of the tiles affected by stars, so as to avoid the blinding stars falling on the detectors, instead of skipping the whole tile. Moreover, it is expected that the EWS available time will further decrease sightly with the insertion of the complete set of PSF calibrations. In fact, the expected cadence is not yet fully respected in RSD_2021A, because the stringent stability constraints could not always be fulfilled, especially in the final years of the survey. Study is underway to tackle this issue and, once this problem will be solved, the time needed amounts to ≈10 days (100 deg 2 ) to be taken off from the EWS present coverage. It must be noticed, however, that a 3% reduction in survey area translates into a comparable reduction in the final DE FoM (actually even less since the still uncovered areas of the RoI are of lower quality than the average). An area a few percent lower than originally expected is therefore of no consequence for achieving the original goal of the mission, that is, a FoM larger than 400 from the two main probes for a w 0 -w a CDM model with no other prior information (Laureijs et al. 2011). Indeed, for the present coverage, one preliminarily expects the FoM to scale down from 500 (Euclid Collaboration 2020a) to ≈480.</p>
        <p>A112, page 37 of 41 A&amp;A 662, A112 (2022) Nevertheless, the final area of the Euclid footprint is not yet fixed and its value can change in either direction. On the one hand, possible further synergies between targets and optimisations will likely increase the area covered by the EWS. On the other hand, modifications in the ROS, the calibrations plan, and in the amount of overlap between tiles might further reduce the final area.A112, page 37 of 41 A&amp;A 662, A112 (2022) Nevertheless, the final area of the Euclid footprint is not yet fixed and its value can change in either direction. On the one hand, possible further synergies between targets and optimisations will likely increase the area covered by the EWS. On the other hand, modifications in the ROS, the calibrations plan, and in the amount of overlap between tiles might further reduce the final area.</p>
        <p>We have presented the status of the reference survey for the Euclid mission at the beginning of the year 2021. The reference survey encompasses all six years of the mission baseline, fulfilling all the constraints while combining observations of the EWS, EDFs, EAFs and other calibration fields, as well as all the slews. We discussed and provided models of the main backgrounds that affect the space observations. We also presented the complementary ground-based observations needed for photometric redshifts.We have presented the status of the reference survey for the Euclid mission at the beginning of the year 2021. The reference survey encompasses all six years of the mission baseline, fulfilling all the constraints while combining observations of the EWS, EDFs, EAFs and other calibration fields, as well as all the slews. We discussed and provided models of the main backgrounds that affect the space observations. We also presented the complementary ground-based observations needed for photometric redshifts.</p>
        <p>This is a non-trivial achievement, because of the complex nature of the mission: the Euclid step-and-stare strategy is severely constrained by pointing limitations with respect to the Sun, whilst it also has to carry out a large number of dedicated observations for calibration purposes and sample characterisation. This leads to a complex interplay of timing observations, visibilities, and manoeuvres. Although the two main instruments are operated in concert, they require three separate calibration strategies, thus adding to the complexity. This makes Euclid not only different from a typical observatory mission (e.g. Herschel) but also from all-sky missions that have a single scanning strategy (e.g. Planck and Gaia).This is a non-trivial achievement, because of the complex nature of the mission: the Euclid step-and-stare strategy is severely constrained by pointing limitations with respect to the Sun, whilst it also has to carry out a large number of dedicated observations for calibration purposes and sample characterisation. This leads to a complex interplay of timing observations, visibilities, and manoeuvres. Although the two main instruments are operated in concert, they require three separate calibration strategies, thus adding to the complexity. This makes Euclid not only different from a typical observatory mission (e.g. Herschel) but also from all-sky missions that have a single scanning strategy (e.g. Planck and Gaia).</p>
        <p>Despite these challenges, we have found a highly optimised solution that takes into account the main spacecraft and instrument characteristics and limitations, the current models for the expected background, the various calibrations, the dithering pattern, and the methods to cover the wide area expected to be observed. The latest version of the Euclid RSD (RSD_2021A) fulfils practically all requirements, resulting in an EWS that covers ≈14 500 deg 2 of the extragalactic sky. This is 3% short of the initial target, mainly because of the paucity of good sky for Euclid and of the severe constraints on the pointing (if feasible, 10 months of presently unallocated time would in principle allow 3000 square degrees to be added to the EWS). A companion paper will detail the rationale and results for the EDFs that cover about 40 deg 2 but at much greater depth.Despite these challenges, we have found a highly optimised solution that takes into account the main spacecraft and instrument characteristics and limitations, the current models for the expected background, the various calibrations, the dithering pattern, and the methods to cover the wide area expected to be observed. The latest version of the Euclid RSD (RSD_2021A) fulfils practically all requirements, resulting in an EWS that covers ≈14 500 deg 2 of the extragalactic sky. This is 3% short of the initial target, mainly because of the paucity of good sky for Euclid and of the severe constraints on the pointing (if feasible, 10 months of presently unallocated time would in principle allow 3000 square degrees to be added to the EWS). A companion paper will detail the rationale and results for the EDFs that cover about 40 deg 2 but at much greater depth.</p>
        <p>The definition of the reference survey is an ongoing process, and some of the results presented will continue to evolve because the Euclid Consortium has developed both the expertise and the specific tools that allow one to probe significant variations in any of the multiple boundary conditions that originate from the knowledge of the spacecraft, the instruments, or the astronomical environment. The current solution is, however, a close proxy for the final survey. Crucially, it demonstrates the feasibility of the core mission within the numerous constraints. Future plans include:The definition of the reference survey is an ongoing process, and some of the results presented will continue to evolve because the Euclid Consortium has developed both the expertise and the specific tools that allow one to probe significant variations in any of the multiple boundary conditions that originate from the knowledge of the spacecraft, the instruments, or the astronomical environment. The current solution is, however, a close proxy for the final survey. Crucially, it demonstrates the feasibility of the core mission within the numerous constraints. Future plans include:</p>
        <p>-further optimisations to reach the nominal 15 000 deg 2 (e.g. double exposures on the ecliptic plane to compensate for the local high background); -implementation of refined simulations; -implementation of refined background models; -incorporation of possible future changes in parameters (e.g. changes in ROS or in the calibration plan); -consideration of 'what if' scenarios for non-recurrent operations (decontamination, phase diversity calibrations) and possible failures (electronics or other systems);-further optimisations to reach the nominal 15 000 deg 2 (e.g. double exposures on the ecliptic plane to compensate for the local high background); -implementation of refined simulations; -implementation of refined background models; -incorporation of possible future changes in parameters (e.g. changes in ROS or in the calibration plan); -consideration of 'what if' scenarios for non-recurrent operations (decontamination, phase diversity calibrations) and possible failures (electronics or other systems);</p>
        <p>-revisions and updates based on real measurements and inflight performance. These further improvements will present challenges in their own right, but given the current level of maturity, there is little doubt that Euclid will dramatically advance our understanding of the nature of DM and DE whilst impacting many aspects of astronomy thanks to the tremendous legacy value of these unique data.-revisions and updates based on real measurements and inflight performance. These further improvements will present challenges in their own right, but given the current level of maturity, there is little doubt that Euclid will dramatically advance our understanding of the nature of DM and DE whilst impacting many aspects of astronomy thanks to the tremendous legacy value of these unique data.</p>
        <p>Fig. 7Fig. 7</p>
        <p>. Total sensitivity of Euclid's photometric I E , Y E , J E , and H E , and spectroscopic BG E , RG E (solid and dashed lines, respectively). The sensitivity (in electrons per photon) includes all optical surfaces as well as the detectors' average quantum efficiency, all considered at their expected EOL performance after six years at L2 (degraded by radiation damage and contamination; see e.g.. Total sensitivity of Euclid's photometric I E , Y E , J E , and H E , and spectroscopic BG E , RG E (solid and dashed lines, respectively). The sensitivity (in electrons per photon) includes all optical surfaces as well as the detectors' average quantum efficiency, all considered at their expected EOL performance after six years at L2 (degraded by radiation damage and contamination; see e.g.</p>
        <p>Venancio et al. 2020Venancio et al. 2020</p>
        <p>).).</p>
        <p>Notes. The total area is 17 354 deg 2 .Notes. The total area is 17 354 deg 2 .</p>
        <p>E band (boldface values refer to extended objects), NIR bands (J E , Y E , and H E values refer to point-like objects), and red grism band, RG E (italic values in the last column refer to 0 . 5 diameter sources).E band (boldface values refer to extended objects), NIR bands (J E , Y E , and H E values refer to point-like objects), and red grism band, RG E (italic values in the last column refer to 0 . 5 diameter sources).</p>
        <p>In three-dimensional space, according to Euler's rotation theorem, any rotation or sequence of rotations of a rigid body or coordinate system about a fixed point is equivalent to a single rotation by a given angle θ about a fixed axis (called the Euler axis) that runs through the fixed point. Therefore, the quaternion fully describes the spacecraft attitude and a single rotation quaternion relates one pointing to another.In three-dimensional space, according to Euler's rotation theorem, any rotation or sequence of rotations of a rigid body or coordinate system about a fixed point is equivalent to a single rotation by a given angle θ about a fixed axis (called the Euler axis) that runs through the fixed point. Therefore, the quaternion fully describes the spacecraft attitude and a single rotation quaternion relates one pointing to another.</p>
        <p>In particular Ebv_xgal_ns2048_REL5.fits, found at http:// hyperstars.lmpa.eu/mamd/planck_dust_model.html.In particular Ebv_xgal_ns2048_REL5.fits, found at http:// hyperstars.lmpa.eu/mamd/planck_dust_model.html.</p>
        <p>https://breault.com/asap/https://breault.com/asap/</p>
        <p>http://montage.ipac.caltech.edu/http://montage.ipac.caltech.edu/</p>
        <p>https://www.astro.rug.nl/software/kapteyn/https://www.astro.rug.nl/software/kapteyn/</p>
        <p>The properties of the three EDFs can be found at https://www. cosmos.esa.int/web/euclid/euclid-surveyThe properties of the three EDFs can be found at https://www. cosmos.esa.int/web/euclid/euclid-survey</p>
        <p>The only planned 'holes' are the tiles skipped because of the presence of blinding stars.The only planned 'holes' are the tiles skipped because of the presence of blinding stars.</p>
        <p>Acknowledgements. The Euclid Consortium acknowledges the European Space Agency and a number of agencies and institutes that have supported the development of Euclid, in particular the Academy of Finland, the Agenzia Spaziale Italiana, the Belgian Science Policy, the Canadian Euclid Consortium, the Centre National d'Etudes Spatiales, the Deutsches Zentrum für Luft-und Raumfahrt, the Danish Space Research Institute, the Fundação para a Ciência e a Tecnologia, the Ministerio de Economia y Competitividad, the National Aeronautics and Space Administration, the National Astronomical Observatory of Japan, the Netherlandse Onderzoekschool Voor Astronomie, the Norwegian Space Agency, the Romanian Space Agency, the State Secretariat for Education, Research and Innovation (SERI) at the Swiss Space Office (SSO), and the United Kingdom Space Agency. A complete and detailed list is available on the Euclid website (http://www.euclid-ec.org).Acknowledgements. The Euclid Consortium acknowledges the European Space Agency and a number of agencies and institutes that have supported the development of Euclid, in particular the Academy of Finland, the Agenzia Spaziale Italiana, the Belgian Science Policy, the Canadian Euclid Consortium, the Centre National d'Etudes Spatiales, the Deutsches Zentrum für Luft-und Raumfahrt, the Danish Space Research Institute, the Fundação para a Ciência e a Tecnologia, the Ministerio de Economia y Competitividad, the National Aeronautics and Space Administration, the National Astronomical Observatory of Japan, the Netherlandse Onderzoekschool Voor Astronomie, the Norwegian Space Agency, the Romanian Space Agency, the State Secretariat for Education, Research and Innovation (SERI) at the Swiss Space Office (SSO), and the United Kingdom Space Agency. A complete and detailed list is available on the Euclid website (http://www.euclid-ec.org).</p>
        <p>A112, page 40 of 41 R. Scaramella et al.: The Euclid Wide SurveyA112, page 40 of 41 R. Scaramella et al.: The Euclid Wide Survey</p>
    </text>
</tei>
