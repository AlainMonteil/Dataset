<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-14T14:27+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>Over the last decades, cosmological simulations of galaxy formation have been instrumental for advancing our understanding of structure and galaxy formation in the Universe. These simulations follow the nonlinear evolution of galaxies modeling a variety of physical processes over an enormous range of scales. A better understanding of the physics relevant for shaping galaxies, improved numerical methods, and increased computing power have led to simulations that can reproduce a large number of observed galaxy properties. Modern simulations model dark matter, dark energy, and ordinary matter in an expanding space-time starting from well-defined initial conditions. The modeling of ordinary matter is most challenging due to the large array of physical processes affecting this matter component. Cosmological simulations have also proven useful to study alternative cosmological models and their impact on the galaxy population. This review presents a concise overview of the methodology of cosmological simulations of galaxy formation and their different applications.Over the last decades, cosmological simulations of galaxy formation have been instrumental for advancing our understanding of structure and galaxy formation in the Universe. These simulations follow the nonlinear evolution of galaxies modeling a variety of physical processes over an enormous range of scales. A better understanding of the physics relevant for shaping galaxies, improved numerical methods, and increased computing power have led to simulations that can reproduce a large number of observed galaxy properties. Modern simulations model dark matter, dark energy, and ordinary matter in an expanding space-time starting from well-defined initial conditions. The modeling of ordinary matter is most challenging due to the large array of physical processes affecting this matter component. Cosmological simulations have also proven useful to study alternative cosmological models and their impact on the galaxy population. This review presents a concise overview of the methodology of cosmological simulations of galaxy formation and their different applications.</p>
        <p>Modern astronomical surveys provide enormous amounts of observational data confronting our theories of structure and galaxy formation. Interpreting these observations demands accurate theoretical predictions. However, galaxy formation is a challenging problem due to its intrinsic multi-scale and multi-physics character. Cosmological computer simulations are, hence, the method of choice for tackling these complexities when studying the properties, growth and evolution of galaxies. These simulations are important to understand the detailed workings of structure and galaxy formation. Dark matter builds the backbone for structure formation and is therefore a key ingredient of these simulations. In addition, dark energy is responsible for the accelerated expansion of the Universe and must also be considered. Despite the fact that the nature of dark matter and dark energy are not known, simulations can make detailed and reliable predictions for these dark components based on their general characteristics. Ordinary matter, e.g. stars and gas, contribute only about five percent to the energy budget of the Universe. Nevertheless, simulating this matter component is essential to study galaxies, but, unfortunately, it is also the most challenging aspect of galaxy formation. Recent simulations follow the formation of individual galaxies and galaxy populations from well-defined initial conditions and yield realistic galaxy properties 1 . Visual representations of the predictions of some of these simulations are shown in Figure 1. At the heart of these simulations are detailed galaxy formation models. Among others, these models describe the cooling of gas, the formation of stars, and the energy and momentum injection caused by supermassive black holes and massive stars 2 . More recent simulations also model the impact of radiation fields, relativistic particles, and magnetic fields leading to a more and more complex description of the galactic ecosystem and the detailed evolution of galaxies in the cosmological context. Galaxy formation simulations have alsoModern astronomical surveys provide enormous amounts of observational data confronting our theories of structure and galaxy formation. Interpreting these observations demands accurate theoretical predictions. However, galaxy formation is a challenging problem due to its intrinsic multi-scale and multi-physics character. Cosmological computer simulations are, hence, the method of choice for tackling these complexities when studying the properties, growth and evolution of galaxies. These simulations are important to understand the detailed workings of structure and galaxy formation. Dark matter builds the backbone for structure formation and is therefore a key ingredient of these simulations. In addition, dark energy is responsible for the accelerated expansion of the Universe and must also be considered. Despite the fact that the nature of dark matter and dark energy are not known, simulations can make detailed and reliable predictions for these dark components based on their general characteristics. Ordinary matter, e.g. stars and gas, contribute only about five percent to the energy budget of the Universe. Nevertheless, simulating this matter component is essential to study galaxies, but, unfortunately, it is also the most challenging aspect of galaxy formation. Recent simulations follow the formation of individual galaxies and galaxy populations from well-defined initial conditions and yield realistic galaxy properties 1 . Visual representations of the predictions of some of these simulations are shown in Figure 1. At the heart of these simulations are detailed galaxy formation models. Among others, these models describe the cooling of gas, the formation of stars, and the energy and momentum injection caused by supermassive black holes and massive stars 2 . More recent simulations also model the impact of radiation fields, relativistic particles, and magnetic fields leading to a more and more complex description of the galactic ecosystem and the detailed evolution of galaxies in the cosmological context. Galaxy formation simulations have also</p>
        <p>Dark matter builds the backbone for the formation of galaxies, which are expected to form at the centers of dark matter overdensities, so-called halos. The continuum limit of non-interacting dark matter particles is described by the collisionless Boltzmann equation coupled to Poisson's equation. This pair of equations has to be solved in an expanding background Universe dictated by the Friedmann equations, which are derived from the field equations of general relativity. Most cosmological simulations employ Newtonian rather than relativistic gravity, which provides a good approximation since linear structure growth is identical in the matter dominated regime in the two theories, and non-linear large-scale structure induces velocities far below the speed of light. Cosmological simulations are also typically performed with periodic boundary conditions to mimic the large-scale homogeneity and isotropy of the matter distribution of the Universe, i.e. the cosmological principle.Dark matter builds the backbone for the formation of galaxies, which are expected to form at the centers of dark matter overdensities, so-called halos. The continuum limit of non-interacting dark matter particles is described by the collisionless Boltzmann equation coupled to Poisson's equation. This pair of equations has to be solved in an expanding background Universe dictated by the Friedmann equations, which are derived from the field equations of general relativity. Most cosmological simulations employ Newtonian rather than relativistic gravity, which provides a good approximation since linear structure growth is identical in the matter dominated regime in the two theories, and non-linear large-scale structure induces velocities far below the speed of light. Cosmological simulations are also typically performed with periodic boundary conditions to mimic the large-scale homogeneity and isotropy of the matter distribution of the Universe, i.e. the cosmological principle.</p>
        <p>Modeling dark matter collisionless Boltzmann equation:Modeling dark matter collisionless Boltzmann equation:</p>
        <p>The collisionless Boltzmann equation describes the evolution of the phase-space density or distribution function of dark matter, f = f (r, v,t), under the influence of the collective gravitational potential, Φ, given by Poisson's equation. The collisionless Boltzmann equation states the conservation of the local phase-space density; i.e. Liouville's theorem.The collisionless Boltzmann equation describes the evolution of the phase-space density or distribution function of dark matter, f = f (r, v,t), under the influence of the collective gravitational potential, Φ, given by Poisson's equation. The collisionless Boltzmann equation states the conservation of the local phase-space density; i.e. Liouville's theorem.</p>
        <p>The high dimensionality of the collisionless Boltzmann equation prohibits efficient numerical solution methods based on standard discretization techniques for partial differential equations. Therefore, over the past decades, other numerical techniques have been developed to solve this problem more efficiently. An overview of some selected simulation codes and the employed dark matter simulation techniques is presented in Table 1.The high dimensionality of the collisionless Boltzmann equation prohibits efficient numerical solution methods based on standard discretization techniques for partial differential equations. Therefore, over the past decades, other numerical techniques have been developed to solve this problem more efficiently. An overview of some selected simulation codes and the employed dark matter simulation techniques is presented in Table 1.</p>
        <p>The N-Body method: N-body methods are often employed to follow the collisionless dynamics of dark matter, where the phase-space density is sampled by an ensemble of N phase-space points r i , ṙi , i = 1 . . . N with masses m i . The conservation of f along the flow implies that the masses m i remain unchanged along each trajectory. N-body methods therefore solve the collisionless Boltzmann equation by the method of characteristics. Alternatively, this method can also be interpreted as a Monte Carlo technique since any initial sample of N phase-space points drawn from the same phase-space density at t = 0 results in an N-body model for the time evolution of f (r, ṙ,t). The ensemble of all N particles together represents the coarse grained phase-space density f ≈ ∑ i m i f (r i (t), ṙi (t)). The latter represents a typical Monte Carlo estimate that can be applied also to other quantities, like the configuration space density. This Visual representations of some selected recent structure and galaxy formation simulations. The simulations are divided in large volume simulations providing statistical samples of galaxies, and zoom simulations resolving smaller scales in more detail. Furthermore, they are also divided in dark matter-only, i.e. N-body, and dark matter plus baryons, i.e. hydrodynamical simulations. Dark matter-only simulations have now converged on a wide range of predictions for the large-scale clustering of dark matter and the dark matter distribution within gravitationally bound dark matter halos. Recent hydrodynamical simulations reproduce galaxy populations that agree remarkably well with observational data. However, many detailed predictions of these simulations are still sensitive to the underlying implementation of baryonic physics.The N-Body method: N-body methods are often employed to follow the collisionless dynamics of dark matter, where the phase-space density is sampled by an ensemble of N phase-space points r i , ṙi , i = 1 . . . N with masses m i . The conservation of f along the flow implies that the masses m i remain unchanged along each trajectory. N-body methods therefore solve the collisionless Boltzmann equation by the method of characteristics. Alternatively, this method can also be interpreted as a Monte Carlo technique since any initial sample of N phase-space points drawn from the same phase-space density at t = 0 results in an N-body model for the time evolution of f (r, ṙ,t). The ensemble of all N particles together represents the coarse grained phase-space density f ≈ ∑ i m i f (r i (t), ṙi (t)). The latter represents a typical Monte Carlo estimate that can be applied also to other quantities, like the configuration space density. This Visual representations of some selected recent structure and galaxy formation simulations. The simulations are divided in large volume simulations providing statistical samples of galaxies, and zoom simulations resolving smaller scales in more detail. Furthermore, they are also divided in dark matter-only, i.e. N-body, and dark matter plus baryons, i.e. hydrodynamical simulations. Dark matter-only simulations have now converged on a wide range of predictions for the large-scale clustering of dark matter and the dark matter distribution within gravitationally bound dark matter halos. Recent hydrodynamical simulations reproduce galaxy populations that agree remarkably well with observational data. However, many detailed predictions of these simulations are still sensitive to the underlying implementation of baryonic physics.</p>
        <p>sampling is subject to Poisson noise, and high particle numbers are therefore desirable to reduce noise in these estimates. To avoid unphysical two-body scatterings between nearby particles, gravitational interactions are softened on small scales so that the particle collection represents a smoothed density field.sampling is subject to Poisson noise, and high particle numbers are therefore desirable to reduce noise in these estimates. To avoid unphysical two-body scatterings between nearby particles, gravitational interactions are softened on small scales so that the particle collection represents a smoothed density field.</p>
        <p>A variety of kernel-based smoothing techniques are implemented, and some simulations also implement adaptive softening schemes to reduce the softening length in high density regions to reach higher spatial force resolution 17 . The main challenge of N-body simulations is to efficiently calculate the gravitational force that governs the motion of the dark matter sample particles. Once the forces have been calculated, the particles are advanced based on symplectic integration schemes commonly implemented through a Leapfrog integrator. Symplectic integrators exactly solve an approximate Hamiltonian such that the numerical time evolution is a canonical map and preserves certain conserved quantities, such as the total angular momentum, and the phase-space volume. Cosmological simulations are further confronted with a large dynamic range in timescales; i.e. in high-density regions orders of magnitude smaller timesteps are required than in low-density regions. Integration schemes with individual timesteps are therefore typically employed. The time integration is no longer symplectic in a formal sense when individual short-range timesteps are chosen for different particles. Methods to calculate gravitational forces of the N-body system can roughly be divided in two groups: approaches to accelerate the direct summation problem through approximations, or mesh-based methods to calculate the forces. The former approaches aim for efficient numerical solutions of the integral form of Poisson's equation. The latter methods aim for efficient techniques to solve the differential form of Poisson's equation. Solving this problem directly results in the so-called particle-particle scheme, and the earliest simulations employed this brute-force approach. The most common method to accelerate the direct summation through approximations is the so-called tree approach 18 . Here, contributions to the gravitational potential from distant particles are approximated by the lowest order terms in a multipole expansion of the mass distribution at a coarse level of the tree reducing the computational cost to O(N log N). The approximation used in the tree method is formally obtained by Taylor expanding the force around some expansion center of the particle group. Often an octree is implemented in cosmological simulations, where each cubic cell is split into up to eight child cells resulting in a tree-like hierarchy of cubic nodes with the root node containing all particles at its bottom. The particles within each of the tree nodes constitute a well-defined and localized group that build the basis for the tree force calculation. A further improvement to O(N) complexity is possible through the use of the fast multipole method, where forces are calculated between two tree nodes rather than between individual particles and nodes. This method is best implemented using a tree structure 19 , although the original proposed method was based on a fixed mesh 20 . Implementing periodic boundary conditions for these direct summation-based schemes typically requires Ewald summation techniques 21 originally developed for solid-state physics 22 .A variety of kernel-based smoothing techniques are implemented, and some simulations also implement adaptive softening schemes to reduce the softening length in high density regions to reach higher spatial force resolution 17 . The main challenge of N-body simulations is to efficiently calculate the gravitational force that governs the motion of the dark matter sample particles. Once the forces have been calculated, the particles are advanced based on symplectic integration schemes commonly implemented through a Leapfrog integrator. Symplectic integrators exactly solve an approximate Hamiltonian such that the numerical time evolution is a canonical map and preserves certain conserved quantities, such as the total angular momentum, and the phase-space volume. Cosmological simulations are further confronted with a large dynamic range in timescales; i.e. in high-density regions orders of magnitude smaller timesteps are required than in low-density regions. Integration schemes with individual timesteps are therefore typically employed. The time integration is no longer symplectic in a formal sense when individual short-range timesteps are chosen for different particles. Methods to calculate gravitational forces of the N-body system can roughly be divided in two groups: approaches to accelerate the direct summation problem through approximations, or mesh-based methods to calculate the forces. The former approaches aim for efficient numerical solutions of the integral form of Poisson's equation. The latter methods aim for efficient techniques to solve the differential form of Poisson's equation. Solving this problem directly results in the so-called particle-particle scheme, and the earliest simulations employed this brute-force approach. The most common method to accelerate the direct summation through approximations is the so-called tree approach 18 . Here, contributions to the gravitational potential from distant particles are approximated by the lowest order terms in a multipole expansion of the mass distribution at a coarse level of the tree reducing the computational cost to O(N log N). The approximation used in the tree method is formally obtained by Taylor expanding the force around some expansion center of the particle group. Often an octree is implemented in cosmological simulations, where each cubic cell is split into up to eight child cells resulting in a tree-like hierarchy of cubic nodes with the root node containing all particles at its bottom. The particles within each of the tree nodes constitute a well-defined and localized group that build the basis for the tree force calculation. A further improvement to O(N) complexity is possible through the use of the fast multipole method, where forces are calculated between two tree nodes rather than between individual particles and nodes. This method is best implemented using a tree structure 19 , although the original proposed method was based on a fixed mesh 20 . Implementing periodic boundary conditions for these direct summation-based schemes typically requires Ewald summation techniques 21 originally developed for solid-state physics 22 .</p>
        <p>Solving the differential form of Poisson's equation: Mesh-based methods aim to solve the differential form of Poisson's equation, ∇ 2 Φ(r) = 4πGρ(r). This equation can be solved efficiently through fast Fourier transform-based methods, with Poisson's equation in Fourier space k 2 Φ(k) = -4πG ρ(k), leading to the so-called particle-mesh method 23 . To obtain forces, the potential is then differentiated using a finite difference approximation and the forces are interpolated to the particle positions. The calculation of the gravitational forces via a fast Fourier transform has only a O(N log N) complexity, where N is the number of mesh cells. The computational cost does not depend on the details of the particle distribution, and no explicit force softening is necessary for this scheme since the force is automatically softened on the grid scale. Combining the particle-mesh method with a set of nested grids of increasing resolution enables an efficient force solver for inhomogeneous systems resulting in adaptive-mesh-refinement schemes. Multigrid or multilevel methods, which solve the discretized form of Poisson's equation using relaxation methods, such as Gauss-Seidel iterations, are also commonly employed 24 . The advantage of this technique over the fast Fourier transform approach is that the grid does not need to be equidistant, but can be locally adapted according to the particle density. The structure of such an adaptively refined mesh is identical to that of a shallow octree.Solving the differential form of Poisson's equation: Mesh-based methods aim to solve the differential form of Poisson's equation, ∇ 2 Φ(r) = 4πGρ(r). This equation can be solved efficiently through fast Fourier transform-based methods, with Poisson's equation in Fourier space k 2 Φ(k) = -4πG ρ(k), leading to the so-called particle-mesh method 23 . To obtain forces, the potential is then differentiated using a finite difference approximation and the forces are interpolated to the particle positions. The calculation of the gravitational forces via a fast Fourier transform has only a O(N log N) complexity, where N is the number of mesh cells. The computational cost does not depend on the details of the particle distribution, and no explicit force softening is necessary for this scheme since the force is automatically softened on the grid scale. Combining the particle-mesh method with a set of nested grids of increasing resolution enables an efficient force solver for inhomogeneous systems resulting in adaptive-mesh-refinement schemes. Multigrid or multilevel methods, which solve the discretized form of Poisson's equation using relaxation methods, such as Gauss-Seidel iterations, are also commonly employed 24 . The advantage of this technique over the fast Fourier transform approach is that the grid does not need to be equidistant, but can be locally adapted according to the particle density. The structure of such an adaptively refined mesh is identical to that of a shallow octree.</p>
        <p>Hybrid schemes: A variety of schemes combine direct summation-based techniques, for short range forces, with Fourier transform-based methods, for long range forces. The most basic example of this is the particle-particle plus particle-mesh method 25 . A common hybrid scheme is the tree-particle-mesh method 26 where the direct summation for short range interactions is approximated by a tree-like method.Hybrid schemes: A variety of schemes combine direct summation-based techniques, for short range forces, with Fourier transform-based methods, for long range forces. The most basic example of this is the particle-particle plus particle-mesh method 25 . A common hybrid scheme is the tree-particle-mesh method 26 where the direct summation for short range interactions is approximated by a tree-like method.</p>
        <p>Combinations of the multigrid method with the fast Fourier transform are also employed, where the Fourier transform is used as a force solver on the coarsest grid 27 . Most modern simulations implement these hybrid solvers to achieve high efficiency.Combinations of the multigrid method with the fast Fourier transform are also employed, where the Fourier transform is used as a force solver on the coarsest grid 27 . Most modern simulations implement these hybrid solvers to achieve high efficiency.</p>
        <p>Beyond N-Body method: Conceptually different methods to solve the collisionless Boltzmann equation have also been developed. However, none of these alternatives have so far been widely used for general structure formation simulations. These different methods are motivated, among others, by the desire to resolve the fine-grained structure of the phase-space density and to avoid numerical inaccuracies of the N-body approach like the artificial clumping of simulation particles for dark matter models with a cut-off in the initial power spectrum 28 . Among the methodological alternatives to the N-body method are, for example, a reformulation of the Boltzmann-Poisson system as a Schrödinger equation [29][30][31] , the waterbag method 32,33 , geodesic deviation equation-based methods 34,35 , Lagrangian tessellation techniques 36 , and direct integration schemes using finite volume approaches based on positive flux conservation methods of plasma physics 37 . a PM: particle-mesh; TreePM: tree + PM, FM: fast multipole, P 3 M: particle-particle-particle-mesh; ML: multilevel; MG: multigrid b SPH: smoothed particle hydrodynamics, CRK-SPH: conservative reproducing kernel smoothed particle hydrodynamics , AMR: adaptive-meshrefinement, MMFV: moving-mesh finite volume, MLFM/MLFV: mesh-free finite mass / finite volume c data-based: data parallelism focuses on distributing data across different nodes, which operate on the data in parallel; task-based: task parallelism focuses on distributing tasks concurrently performed d private: private code; public: publicly available code (in some cases with limited functionality) e gravity solver is based on 
            <rs type="software">PKDGRAV3 f</rs> based on the 
            <rs type="software">GADGET</rs>-
            <rs type="version">3</rs> code
        </p>
        <p>The earliest dark matter simulations studied halo population models 50 , the assembly of massive clusters 51 , and the growth of large-scale structure 52,53 . Since then the resolution of these simulations has grown exponentially starting from a few thousand to multi-trillion particle simulations today 54 . Table 2 presents some selected recent structure and galaxy formation simulations. The findings of these simulations can roughly be divided in two categories: the large-scale distribution of dark matter and the structure of dark matter halos. The interaction between baryons and dark matter does affect the structure of dark matter on smaller scales, which is especially important for the internal structure of dark matter halos [55][56][57][58][59][60][61] . Studying these phenomena requires, however, simulations that model both dark matter and baryons.The earliest dark matter simulations studied halo population models 50 , the assembly of massive clusters 51 , and the growth of large-scale structure 52,53 . Since then the resolution of these simulations has grown exponentially starting from a few thousand to multi-trillion particle simulations today 54 . Table 2 presents some selected recent structure and galaxy formation simulations. The findings of these simulations can roughly be divided in two categories: the large-scale distribution of dark matter and the structure of dark matter halos. The interaction between baryons and dark matter does affect the structure of dark matter on smaller scales, which is especially important for the internal structure of dark matter halos [55][56][57][58][59][60][61] . Studying these phenomena requires, however, simulations that model both dark matter and baryons.</p>
        <p>The large-scale distribution of dark matter: Cold dark matter simulations predict that the large-scale distribution of dark matter is not completely homogeneous, but instead exhibits a web-like structure consisting of voids, walls, filaments, and halos quantified through, among others, the halo mass and matter correlation functions.The large-scale distribution of dark matter: Cold dark matter simulations predict that the large-scale distribution of dark matter is not completely homogeneous, but instead exhibits a web-like structure consisting of voids, walls, filaments, and halos quantified through, among others, the halo mass and matter correlation functions.</p>
        <p>The halo mass function quantifies the comoving number density of dark matter halos as a function of their virial mass, M vir , typically defined as the mass, M 200 , enclosed within a radius r 200 containing a mean density 200 times the critical density of the Universe. Recently, also other halo boundary definitions like the splashback radius 62,63 , which corresponds to the outermost caustic originally discussed in symmetric analytic halo formation models 64,65 , have been proposed to avoid, for example, the pseudo-evolution of the halo mass and radius 66 . In simulations, dark matter halos are identified through cluster finding methods like the friend-of-friends algorithm 67 and extensions of this based on gravitational unbinding 68 or phase-space structure finding taking into account also velocity space information 69 . In the cold dark matter cosmogony, structure forms through the hierarchical merging of dark matter halos 67 , and the corresponding evolution of the halo mass function has been studied extensively 50,[70][71][72][73][74][75][76][77] . Most importantly these studies revealed that the low-mass end of the halo mass function has a power law slope close to -2. Furthermore, the high mass end of the halo mass function is exponentially suppressed. The halo mass function is also an important probe of the nature of dark matter since many particle candidates predict strong, scale-dependent deviations from the expectations of the cold dark matter model 78,79 . The high mass shape and evolution of the halo mass functions also constrains cosmological parameters 80 . Simulation-based empirical halo mass functions are often expressed as Mdn/dM = ρ 0 d ln σ -1 /dM f (σ (M)), where ρ 0 is the mean mass density of the Universe, σ (M) is the variance of the linear density field within a top-hat filter containing mass M, and f (σ ) is a function that is determined empirically by fitting the simulation results. This functional form of the halo mass function is motivated and also predicted by the analytic Press-Schechter model 50 . However, the shape of f (σ ) found in simulations differs significantly from the analytic model originally proposed, agreeing much better with a version motivated by ellipsoidal rather than spherical collapse 81 . The detailed form of f (σ ) depends, among others, on simulation details and halo mass definitions, and a variety of empirical fitting functions have been published 77,[82][83][84][85] .The halo mass function quantifies the comoving number density of dark matter halos as a function of their virial mass, M vir , typically defined as the mass, M 200 , enclosed within a radius r 200 containing a mean density 200 times the critical density of the Universe. Recently, also other halo boundary definitions like the splashback radius 62,63 , which corresponds to the outermost caustic originally discussed in symmetric analytic halo formation models 64,65 , have been proposed to avoid, for example, the pseudo-evolution of the halo mass and radius 66 . In simulations, dark matter halos are identified through cluster finding methods like the friend-of-friends algorithm 67 and extensions of this based on gravitational unbinding 68 or phase-space structure finding taking into account also velocity space information 69 . In the cold dark matter cosmogony, structure forms through the hierarchical merging of dark matter halos 67 , and the corresponding evolution of the halo mass function has been studied extensively 50,[70][71][72][73][74][75][76][77] . Most importantly these studies revealed that the low-mass end of the halo mass function has a power law slope close to -2. Furthermore, the high mass end of the halo mass function is exponentially suppressed. The halo mass function is also an important probe of the nature of dark matter since many particle candidates predict strong, scale-dependent deviations from the expectations of the cold dark matter model 78,79 . The high mass shape and evolution of the halo mass functions also constrains cosmological parameters 80 . Simulation-based empirical halo mass functions are often expressed as Mdn/dM = ρ 0 d ln σ -1 /dM f (σ (M)), where ρ 0 is the mean mass density of the Universe, σ (M) is the variance of the linear density field within a top-hat filter containing mass M, and f (σ ) is a function that is determined empirically by fitting the simulation results. This functional form of the halo mass function is motivated and also predicted by the analytic Press-Schechter model 50 . However, the shape of f (σ ) found in simulations differs significantly from the analytic model originally proposed, agreeing much better with a version motivated by ellipsoidal rather than spherical collapse 81 . The detailed form of f (σ ) depends, among others, on simulation details and halo mass definitions, and a variety of empirical fitting functions have been published 77,[82][83][84][85] .</p>
        <p>Dark matter distribution: A major success of cold dark matter simulations is their ability to predict the matter distribution on large scales 86 , which is described through the two-point correlation function ξ (r). For a set of points this function is defined as ξ (r) = N p /N m -1, where N p indicates the average number of pairs in a thin shell of radius r centered on one point of the set and N m the expected number of pairs in the same shell given a uniform distribution of points. Although this function can be estimated analytically in the linear regime, dark matter simulations are needed to probe its evolution into the non-linear regime. The dark matter correlation function signal grows with time and develops a characteristic shoulder at small scales 87 . This effect can be explained by the relative contribution of the one-halo term, i.e. pairs composed of particles within the same halo, and the two-halo term, i.e. pairs formed by particles in different halos, to the clustering signal 88 . Finally, the dark matter correlation function has a markedly different shape than the galaxy correlation function. The latter has a power law shape over a significant range of scales and an amplitude nearly constant at all redshifts 86 . Indeed, galaxies trace the highest peaks of the dark matter distribution, and their clustering does not change significantly with time, as more and more dark matter structures grow. This bias needs to be taken properly into account when estimating the large-scale total matter distribution using galaxy tracers 89 .Dark matter distribution: A major success of cold dark matter simulations is their ability to predict the matter distribution on large scales 86 , which is described through the two-point correlation function ξ (r). For a set of points this function is defined as ξ (r) = N p /N m -1, where N p indicates the average number of pairs in a thin shell of radius r centered on one point of the set and N m the expected number of pairs in the same shell given a uniform distribution of points. Although this function can be estimated analytically in the linear regime, dark matter simulations are needed to probe its evolution into the non-linear regime. The dark matter correlation function signal grows with time and develops a characteristic shoulder at small scales 87 . This effect can be explained by the relative contribution of the one-halo term, i.e. pairs composed of particles within the same halo, and the two-halo term, i.e. pairs formed by particles in different halos, to the clustering signal 88 . Finally, the dark matter correlation function has a markedly different shape than the galaxy correlation function. The latter has a power law shape over a significant range of scales and an amplitude nearly constant at all redshifts 86 . Indeed, galaxies trace the highest peaks of the dark matter distribution, and their clustering does not change significantly with time, as more and more dark matter structures grow. This bias needs to be taken properly into account when estimating the large-scale total matter distribution using galaxy tracers 89 .</p>
        <p>Structure of dark matter halos: Cold dark matter simulations have also established multiple characteristics of the dark matter distribution within collapsed and virialized dark matter halos. This has most importantly led to the discovery of a nearly universal radial density profile of dark matter halos.Structure of dark matter halos: Cold dark matter simulations have also established multiple characteristics of the dark matter distribution within collapsed and virialized dark matter halos. This has most importantly led to the discovery of a nearly universal radial density profile of dark matter halos.</p>
        <p>Internal halo structure: The dark matter mass distribution within halos is well described by a nearuniversal spherically averaged density profile, the so-called Navarro-Frenk-White profile 90,91 : ρ(r) = ρ s /[(r/r s )(1 + (r/r s )) 2 ] with a characteristic density ρ s , and a transition radius r s . This form of density profiles has been shown to arise also in the absence of hierarchical growth like, for example, in hot dark matter models 28 , or models with truncated initial power spectra 92 . The central slope of dark matter halos has been debated for a long time and is also affected by baryonic physics effects that require hydrodynamical simulations. More recent higher resolution simulations found a central slope shallower than -1, indicating that the density profile is better described by a functional form with a gradually changing slope profile 93 : ln(ρ(r)/ρ -2 ) = (-2/α)[(r/r -2 ) α -1] with slope α and transition radius r -2 . This profile had previously been used to fit star counts in the Milky Way 94 , and is known as the Einasto profile. The adjustable shape parameter, α, shows considerable scatter but increases systematically with halo mass at z = 0. The ratio of the virial radius, r vir , and the transition radius, r s , is called the concentration parameter, c, that correlates with the mass of the halo leading to the mass-concentration relation [95][96][97] (c ∝ M -δ , δ ≈ 0.1). Simulations demonstrated that the dependence of halo concentration on mass, initial fluctuation spectrum and cosmological parameters all reflect a dependence of concentration on the actual halo formation time 91 . Specifically, lower mass halos typically assemble earlier, and thus have higher concentration, due to the higher density of the Universe at the time of their formation. The shapes of halos have also been studied, and those depart from sphericity, with halos typically being prolate and increasingly so towards their centers. Major-to-minor axis ratios of two or greater are not uncommon, and more massive halos tend to be less spherical than lower mass halos [98][99][100] . The exact shapes of dark matter halos also depend on the dark matter particle physics model. Simulations also provide information on the velocity structure of halos. The averaged velocity anisotropy profile, β (r) = 1 -0.5σ 2 t /σ 2 r , grows from zero, i.e. isotropic, to about 0.5, i.e. mild radial anisotropy, towards the outer regions 101,102 . Here, σ t denotes the tangential and σ r the radial velocity dispersion, with the total velocity dispersion being σ 2 = σ 2 t + σ 2 r . A β value of 1 and β → -∞ correspond to systems where dark matter particles have purely radial and purely circular orbits, respectively. Simulated dark matter halos therefore turn out to be almost isotropic in their inner regions and to be somewhat radially biased at larger radii. Although both ρ(r) and σ (r) are not close to a power law, the combination f (r) = ρ(r)/σ 3 (r) , also called pseudo-phase-space density, is remarkably close to a power law, with slope ≈ -1.875 102 . This power law index is identical to that of solutions for self-similar infall onto a point mass from an otherwise uniform Einstein-de Sitter Universe 65 .Internal halo structure: The dark matter mass distribution within halos is well described by a nearuniversal spherically averaged density profile, the so-called Navarro-Frenk-White profile 90,91 : ρ(r) = ρ s /[(r/r s )(1 + (r/r s )) 2 ] with a characteristic density ρ s , and a transition radius r s . This form of density profiles has been shown to arise also in the absence of hierarchical growth like, for example, in hot dark matter models 28 , or models with truncated initial power spectra 92 . The central slope of dark matter halos has been debated for a long time and is also affected by baryonic physics effects that require hydrodynamical simulations. More recent higher resolution simulations found a central slope shallower than -1, indicating that the density profile is better described by a functional form with a gradually changing slope profile 93 : ln(ρ(r)/ρ -2 ) = (-2/α)[(r/r -2 ) α -1] with slope α and transition radius r -2 . This profile had previously been used to fit star counts in the Milky Way 94 , and is known as the Einasto profile. The adjustable shape parameter, α, shows considerable scatter but increases systematically with halo mass at z = 0. The ratio of the virial radius, r vir , and the transition radius, r s , is called the concentration parameter, c, that correlates with the mass of the halo leading to the mass-concentration relation [95][96][97] (c ∝ M -δ , δ ≈ 0.1). Simulations demonstrated that the dependence of halo concentration on mass, initial fluctuation spectrum and cosmological parameters all reflect a dependence of concentration on the actual halo formation time 91 . Specifically, lower mass halos typically assemble earlier, and thus have higher concentration, due to the higher density of the Universe at the time of their formation. The shapes of halos have also been studied, and those depart from sphericity, with halos typically being prolate and increasingly so towards their centers. Major-to-minor axis ratios of two or greater are not uncommon, and more massive halos tend to be less spherical than lower mass halos [98][99][100] . The exact shapes of dark matter halos also depend on the dark matter particle physics model. Simulations also provide information on the velocity structure of halos. The averaged velocity anisotropy profile, β (r) = 1 -0.5σ 2 t /σ 2 r , grows from zero, i.e. isotropic, to about 0.5, i.e. mild radial anisotropy, towards the outer regions 101,102 . Here, σ t denotes the tangential and σ r the radial velocity dispersion, with the total velocity dispersion being σ 2 = σ 2 t + σ 2 r . A β value of 1 and β → -∞ correspond to systems where dark matter particles have purely radial and purely circular orbits, respectively. Simulated dark matter halos therefore turn out to be almost isotropic in their inner regions and to be somewhat radially biased at larger radii. Although both ρ(r) and σ (r) are not close to a power law, the combination f (r) = ρ(r)/σ 3 (r) , also called pseudo-phase-space density, is remarkably close to a power law, with slope ≈ -1.875 102 . This power law index is identical to that of solutions for self-similar infall onto a point mass from an otherwise uniform Einstein-de Sitter Universe 65 .</p>
        <p>Halo substructure: As the resolution of dark matter simulations increased, halos within halos, so-called subhalos, could be resolved 92,103 . Subhalos have cuspy, Navarro-Frenk-White-like density profiles but they tend to be less extended than comparable halos in the field due to tidal stripping 101,104 . Bound subhalos with µ = M sub /M vir &gt; 10 -7 contain about 10% of the halo mass within the virial radius 104 . Lower mass halos tend to have fewer subhalos and lower subhalo mass fractions at a given µ. This shift is due to the difference in the relative dynamical age of halos; e.g. substructure is more effectively destroyed by tides in older, galactic halos compared to more massive galaxy cluster halos. The cumulative subhalo mass function is a power law N(&gt; µ) ∝ µ -s for µ 1, with s close to the critical value of unity 104,105 . For s = 1 each logarithmic mass bin contributes equally to the total mass in substructure. This is logarithmically divergent as µ approaches zero, and implies that a significant fraction of the mass could, in principle, be locked in halos too small to be resolved by the simulations. This can, for example, have important implications for the prediction of dark matter annihilation signals since these small unresolved halos can boost the overall resolved annihilation emission 106 . The abundance of subhalos also varies systematically with other properties of the parent halo, like, for example, the concentration leading to a lower amount of substructure with increasing halo concentration 107 . The radial distribution of subhalos varies only little with the mass or concentration of the parent halo. It is much less centrally concentrated than the overall dark matter profile 104 .Halo substructure: As the resolution of dark matter simulations increased, halos within halos, so-called subhalos, could be resolved 92,103 . Subhalos have cuspy, Navarro-Frenk-White-like density profiles but they tend to be less extended than comparable halos in the field due to tidal stripping 101,104 . Bound subhalos with µ = M sub /M vir &gt; 10 -7 contain about 10% of the halo mass within the virial radius 104 . Lower mass halos tend to have fewer subhalos and lower subhalo mass fractions at a given µ. This shift is due to the difference in the relative dynamical age of halos; e.g. substructure is more effectively destroyed by tides in older, galactic halos compared to more massive galaxy cluster halos. The cumulative subhalo mass function is a power law N(&gt; µ) ∝ µ -s for µ 1, with s close to the critical value of unity 104,105 . For s = 1 each logarithmic mass bin contributes equally to the total mass in substructure. This is logarithmically divergent as µ approaches zero, and implies that a significant fraction of the mass could, in principle, be locked in halos too small to be resolved by the simulations. This can, for example, have important implications for the prediction of dark matter annihilation signals since these small unresolved halos can boost the overall resolved annihilation emission 106 . The abundance of subhalos also varies systematically with other properties of the parent halo, like, for example, the concentration leading to a lower amount of substructure with increasing halo concentration 107 . The radial distribution of subhalos varies only little with the mass or concentration of the parent halo. It is much less centrally concentrated than the overall dark matter profile 104 .</p>
        <p>• inflation generated initial perturbations on top of homogeneous Friedmann model• inflation generated initial perturbations on top of homogeneous Friedmann model</p>
        <p>Overview of the key ingredients of cosmological simulations. These simulations are performed within a given cosmological framework, and start from specific initial conditions. This framework includes physical models for gravity, dark matter, dark energy, and the type of initial conditions. Two types of simulations are typically performed: either large volume simulations or zoom simulations. The evolution equations of the main matter components, dark matter and gas, are discretized using different techniques and evolved forward in time. The dark matter component follows the equations of collisionless gravitational dynamics that are in most cases solved through the N-body method using different techniques to calculate the gravitational forces. The gas component of baryons is described through the equations of hydrodynamics that are solved, for example, with Lagrangian or Eulerian methods. Various astrophysical processes must also be considered to achieve a realistic galaxy population. Many of these are implemented through effective sub-resolution models.Overview of the key ingredients of cosmological simulations. These simulations are performed within a given cosmological framework, and start from specific initial conditions. This framework includes physical models for gravity, dark matter, dark energy, and the type of initial conditions. Two types of simulations are typically performed: either large volume simulations or zoom simulations. The evolution equations of the main matter components, dark matter and gas, are discretized using different techniques and evolved forward in time. The dark matter component follows the equations of collisionless gravitational dynamics that are in most cases solved through the N-body method using different techniques to calculate the gravitational forces. The gas component of baryons is described through the equations of hydrodynamics that are solved, for example, with Lagrangian or Eulerian methods. Various astrophysical processes must also be considered to achieve a realistic galaxy population. Many of these are implemented through effective sub-resolution models.</p>
        <p>Dark matter and dark energy dominate the energy budget of the Universe, but the visible components of galaxies consist of baryons. Simulating baryons is therefore crucial to make predictions for the visible Universe. Initially, the baryon component is solely comprised of gas, mostly hydrogen and helium. Some of this gas eventually turns into stars during structure formation. Astrophysical gases in cosmological simulations are typically described as inviscid ideal gases following the Euler equations, which can be expressed in different forms leading to different numerical discretization schemes. Hydrodynamics in cosmological simulations is numerically demanding due to the large dynamic range, highly supersonic flows, and large Reynolds numbers.Dark matter and dark energy dominate the energy budget of the Universe, but the visible components of galaxies consist of baryons. Simulating baryons is therefore crucial to make predictions for the visible Universe. Initially, the baryon component is solely comprised of gas, mostly hydrogen and helium. Some of this gas eventually turns into stars during structure formation. Astrophysical gases in cosmological simulations are typically described as inviscid ideal gases following the Euler equations, which can be expressed in different forms leading to different numerical discretization schemes. Hydrodynamics in cosmological simulations is numerically demanding due to the large dynamic range, highly supersonic flows, and large Reynolds numbers.</p>
        <p>Eulerian formulation: Lagrangian formulation: Arbitrary Lagrangian-Eulerian formulation:Eulerian formulation: Lagrangian formulation: Arbitrary Lagrangian-Eulerian formulation:</p>
        <p>Different forms of the hydrodynamical equations. D/dt ≡ ∂ /∂t + v • ∇ denotes the Lagrangian derivative and e = u + v 2 /2 the total energy per unit mass. The equations are closed through P = (γ -1)ρu with γ = 5/3. For the arbitrary Lagrangian-Eulerian formulation the grid moves with velocity w and cell volumes evolve as dV /dt = V (∇ • w) dV .Different forms of the hydrodynamical equations. D/dt ≡ ∂ /∂t + v • ∇ denotes the Lagrangian derivative and e = u + v 2 /2 the total energy per unit mass. The equations are closed through P = (γ -1)ρu with γ = 5/3. For the arbitrary Lagrangian-Eulerian formulation the grid moves with velocity w and cell volumes evolve as dV /dt = V (∇ • w) dV .</p>
        <p>The hydrodynamical equations can be discretized in different ways employing methods that roughly fall into three classes: Lagrangian, Eulerian or arbitrary Lagrange-Eulerian techniques. The Lagrangian specification of the field assumes an observer that follows an individual fluid parcel, with its own properties like density, as it moves through space and time. The Eulerian specification, on the other hand, focuses on specific locations in space through which the fluid flows as time passes. In addition, numerical approaches can also be distinguished between mesh-free and mesh-based algorithms. Mesh-free methods do not require connections between nodes, but are rather based on interactions of each node with its neighbors. An overview of some selected simulation codes and the employed hydrodynamical simulation techniques is shown in Table 1.The hydrodynamical equations can be discretized in different ways employing methods that roughly fall into three classes: Lagrangian, Eulerian or arbitrary Lagrange-Eulerian techniques. The Lagrangian specification of the field assumes an observer that follows an individual fluid parcel, with its own properties like density, as it moves through space and time. The Eulerian specification, on the other hand, focuses on specific locations in space through which the fluid flows as time passes. In addition, numerical approaches can also be distinguished between mesh-free and mesh-based algorithms. Mesh-free methods do not require connections between nodes, but are rather based on interactions of each node with its neighbors. An overview of some selected simulation codes and the employed hydrodynamical simulation techniques is shown in Table 1.</p>
        <p>Eulerian Methods: Eulerian methods are the traditional method to solve the system of hyperbolic partial differential equations that constitute ideal hydrodynamics. The most common approaches include finite volume, finite difference, finite element, spectral or wavelet methods. For example, accurate Godunov finite volume schemes offer high-order spatial accuracy, have negligible post-shock oscillations and low numerical diffusivity. For these methods a Riemann problem is solved across cell faces, which yields the required fluxes at each cell face to update the conserved quantities. If the cell is assumed to have uniform properties, this is called a first-order Godunov solver. Modern implementations employ parabolic interpolation, known as the piecewise parabolic method 108,109 . The large dynamic range of cosmological simulations requires adaptive meshes, where the mesh size can be reduced based on some refinement criterion. This leads to the class of adaptive-mesh-refinement schemes [110][111][112][113] , which were first developed for solving general problems involving hyperbolic partial differential equations, and then later were also applied to cosmological simulations. Recently also discontinuous Galerkin methods [114][115][116] became more popular in computational astrophysics since they offer a framework for discretizing hyperbolic problems at any order of spatial accuracy, together with attractive data locality by combining features of spectral element and finite volume methods.Eulerian Methods: Eulerian methods are the traditional method to solve the system of hyperbolic partial differential equations that constitute ideal hydrodynamics. The most common approaches include finite volume, finite difference, finite element, spectral or wavelet methods. For example, accurate Godunov finite volume schemes offer high-order spatial accuracy, have negligible post-shock oscillations and low numerical diffusivity. For these methods a Riemann problem is solved across cell faces, which yields the required fluxes at each cell face to update the conserved quantities. If the cell is assumed to have uniform properties, this is called a first-order Godunov solver. Modern implementations employ parabolic interpolation, known as the piecewise parabolic method 108,109 . The large dynamic range of cosmological simulations requires adaptive meshes, where the mesh size can be reduced based on some refinement criterion. This leads to the class of adaptive-mesh-refinement schemes [110][111][112][113] , which were first developed for solving general problems involving hyperbolic partial differential equations, and then later were also applied to cosmological simulations. Recently also discontinuous Galerkin methods [114][115][116] became more popular in computational astrophysics since they offer a framework for discretizing hyperbolic problems at any order of spatial accuracy, together with attractive data locality by combining features of spectral element and finite volume methods.</p>
        <p>Lagrangian Methods: Smoothed particle hydrodynamics is a widely used mesh-free Lagrangian technique for approximating the continuum dynamics of fluids through the use of sampling particles, which may also be viewed as interpolation points, following the equations of motion derived from the hydrodynamical equations [117][118][119][120] . Energy, linear momentum, angular momentum, mass, and entropy, assuming no artificial viscosity operates, are all simultaneously conserved. The local resolution follows the mass flow, which is convenient to represent large density contrasts. Over the last years various improved formulations of the smoothed particle hydrodynamics method have been developed and applied to cosmological simulations [121][122][123][124][125][126] . A few cosmological simulations have also employed Lagrangian mesh-based hydrodynamics schemes, which are based on grid deformation techniques 127,128 . However, mesh-tangling effects are a major problem of such multi-dimensional mesh-based Lagrangian hydrodynamics methods.Lagrangian Methods: Smoothed particle hydrodynamics is a widely used mesh-free Lagrangian technique for approximating the continuum dynamics of fluids through the use of sampling particles, which may also be viewed as interpolation points, following the equations of motion derived from the hydrodynamical equations [117][118][119][120] . Energy, linear momentum, angular momentum, mass, and entropy, assuming no artificial viscosity operates, are all simultaneously conserved. The local resolution follows the mass flow, which is convenient to represent large density contrasts. Over the last years various improved formulations of the smoothed particle hydrodynamics method have been developed and applied to cosmological simulations [121][122][123][124][125][126] . A few cosmological simulations have also employed Lagrangian mesh-based hydrodynamics schemes, which are based on grid deformation techniques 127,128 . However, mesh-tangling effects are a major problem of such multi-dimensional mesh-based Lagrangian hydrodynamics methods.</p>
        <p>Arbitrary Lagrangian-Eulerian Methods: For arbitrary Lagrangian-Eulerian methods, the grid velocity can be freely chosen. For astrophysical applications, such a scheme has recently been realized through a Voronoi tessellation of a set of discrete mesh-generating points, which are allowed to move freely 40 . A finite volume hydrodynamic scheme with the Voronoi cells as control volumes can then be consistently defined. Most importantly, due to the mathematical properties of the Voronoi tessellation, the mesh continuously deforms and changes its topology as a result of the point motion, without ever leading to problematic mesh-tangling effects. Similar methods have over the last years also been implemented in other simulation codes 129,130 . Most recently new types of arbitrary Lagrangian-Eulerian, mesh-free, finite mass and finite volume methods have been successfully applied to astrophysical and galaxy formation problems 45 .Arbitrary Lagrangian-Eulerian Methods: For arbitrary Lagrangian-Eulerian methods, the grid velocity can be freely chosen. For astrophysical applications, such a scheme has recently been realized through a Voronoi tessellation of a set of discrete mesh-generating points, which are allowed to move freely 40 . A finite volume hydrodynamic scheme with the Voronoi cells as control volumes can then be consistently defined. Most importantly, due to the mathematical properties of the Voronoi tessellation, the mesh continuously deforms and changes its topology as a result of the point motion, without ever leading to problematic mesh-tangling effects. Similar methods have over the last years also been implemented in other simulation codes 129,130 . Most recently new types of arbitrary Lagrangian-Eulerian, mesh-free, finite mass and finite volume methods have been successfully applied to astrophysical and galaxy formation problems 45 .</p>
        <p>The hydrodynamical equations have to be complemented by various astrophysical processes that shape the galaxy population. Most of these processes are implemented through effective, so-called sub-resolution models, which are necessary due to the limited numerical resolution of simulations.The hydrodynamical equations have to be complemented by various astrophysical processes that shape the galaxy population. Most of these processes are implemented through effective, so-called sub-resolution models, which are necessary due to the limited numerical resolution of simulations.</p>
        <p>Gas cooling: Gas dissipates its internal energy through cooling processes, like collisional excitation and ionization, inverse Compton, recombination and free-free emission. Cooling processes are coupled to the energy equation using cooling functions that are either tabulated or extracted from chemical networks. Cosmological simulations often assume that the gas is optically thin and in ionization equilibrium and neglect three-body processes that are typically unimportant. In addition to primordial cooling also cooling due to heavy elements, so-called metals, is important. Metal line cooling dominates for temperatures 10 5 T 10 7 K. Early simulations typically employed cooling rates assuming collisional ionization equilibrium 131 , but most later galaxy formation models account for the photo-ionization of metals by the metagalactic radiation field 132 . For most post-reionization simulations this metagalactic radiation field is assumed to be spatially uniform but time-dependent 133 . Simulations that resolve the cold phase of the interstellar medium also include gas cooling below 10 4 K via fine-structure and molecular cooling. In neutral atomic gas, the efficiency of cooling is sensitive to the residual ionization degree. In molecular gas (n &gt; ∼ 100 cm -3 , T &lt; ∼ 50 K), the CO molecule dominates the cooling at low densities while at higher densities CI, O 2 and H 2 O start to contribute 134 . Gas cooling is a direct physical process that is not implemented through a sub-resolution model. However, following all cooling processes in detail requires sufficient numerical resolution to resolve the different gas phases.Gas cooling: Gas dissipates its internal energy through cooling processes, like collisional excitation and ionization, inverse Compton, recombination and free-free emission. Cooling processes are coupled to the energy equation using cooling functions that are either tabulated or extracted from chemical networks. Cosmological simulations often assume that the gas is optically thin and in ionization equilibrium and neglect three-body processes that are typically unimportant. In addition to primordial cooling also cooling due to heavy elements, so-called metals, is important. Metal line cooling dominates for temperatures 10 5 T 10 7 K. Early simulations typically employed cooling rates assuming collisional ionization equilibrium 131 , but most later galaxy formation models account for the photo-ionization of metals by the metagalactic radiation field 132 . For most post-reionization simulations this metagalactic radiation field is assumed to be spatially uniform but time-dependent 133 . Simulations that resolve the cold phase of the interstellar medium also include gas cooling below 10 4 K via fine-structure and molecular cooling. In neutral atomic gas, the efficiency of cooling is sensitive to the residual ionization degree. In molecular gas (n &gt; ∼ 100 cm -3 , T &lt; ∼ 50 K), the CO molecule dominates the cooling at low densities while at higher densities CI, O 2 and H 2 O start to contribute 134 . Gas cooling is a direct physical process that is not implemented through a sub-resolution model. However, following all cooling processes in detail requires sufficient numerical resolution to resolve the different gas phases.</p>
        <p>Interstellar medium: Carefully modeling the interstellar medium is important since its properties directly impact star formation. However, simulating the interstellar medium is challenging due to its complex multiphase structure including magnetic fields and relativistic particles. Especially modeling the cold phase is technically difficult because of the short timescales associated with the dense gas. These timescales require very small time-steps to reliably follow the cold gas evolution. Moreover, the implementation of additional physical processes is needed to accurately model such a phase. To circumvent this problem, this dense gas phase is often not directly modeled but rather described by an effective polytropic equation of state [135][136][137] ; i.e. T ∝ ρ γ(ρ) , which naturally emerges from an equilibrium two-phase interstellar medium where a hot, supernova-heated and volume-filling phase co-exists with a colder phase containing the bulk of the mass 135 . More recent modeling efforts started to abandon the effective equation of state approach and instead aimed towards resolving the multi-phase structure directly. Such simulations are starting to be able to resolve the Jeans mass of gas, corresponding to the scale of molecular cloud complexes. Therefore, a more direct modeling of the multi-phase interstellar medium is possible 138 . In such simulations, the gas density and temperature distributions follow a multi-modal distribution [138][139][140] . Generally, the cold gas phase dominates (∼ 90%) the gas mass budget, but occupies a very small volume fraction (∼ 1%), which is mostly comprised of hotter gas 141 . Simulating the molecular phase of the interstellar medium is challenging because it requires detailed modeling of the interaction between gas, dust, and radiation, which tends to destroy molecules unless gas is able to effectively self-shield from ionizing radiation 142 . Detailed models of the interstellar medium have also to take into account the various feedback sources that ultimately shape the structure of the interstellar medium. Thus, future simulations have to consider how this complex interplay of such a wide range of physical processes affects the properties of the interstellar medium.Interstellar medium: Carefully modeling the interstellar medium is important since its properties directly impact star formation. However, simulating the interstellar medium is challenging due to its complex multiphase structure including magnetic fields and relativistic particles. Especially modeling the cold phase is technically difficult because of the short timescales associated with the dense gas. These timescales require very small time-steps to reliably follow the cold gas evolution. Moreover, the implementation of additional physical processes is needed to accurately model such a phase. To circumvent this problem, this dense gas phase is often not directly modeled but rather described by an effective polytropic equation of state [135][136][137] ; i.e. T ∝ ρ γ(ρ) , which naturally emerges from an equilibrium two-phase interstellar medium where a hot, supernova-heated and volume-filling phase co-exists with a colder phase containing the bulk of the mass 135 . More recent modeling efforts started to abandon the effective equation of state approach and instead aimed towards resolving the multi-phase structure directly. Such simulations are starting to be able to resolve the Jeans mass of gas, corresponding to the scale of molecular cloud complexes. Therefore, a more direct modeling of the multi-phase interstellar medium is possible 138 . In such simulations, the gas density and temperature distributions follow a multi-modal distribution [138][139][140] . Generally, the cold gas phase dominates (∼ 90%) the gas mass budget, but occupies a very small volume fraction (∼ 1%), which is mostly comprised of hotter gas 141 . Simulating the molecular phase of the interstellar medium is challenging because it requires detailed modeling of the interaction between gas, dust, and radiation, which tends to destroy molecules unless gas is able to effectively self-shield from ionizing radiation 142 . Detailed models of the interstellar medium have also to take into account the various feedback sources that ultimately shape the structure of the interstellar medium. Thus, future simulations have to consider how this complex interplay of such a wide range of physical processes affects the properties of the interstellar medium.</p>
        <p>Star formation: Cold and dense gas eventually forms stars, and simulations therefore transform a portion of this gas into collisionless star particles, representing co-eval, single-metallicity stellar populations described by an underlying initial stellar mass function. Observations support a nearly universal star formation efficiency in molecular gas, where about 1% of the gas is converted into stars per free fall time 143,144 . Based on a calculated star formation rate, the gas is converted into star particles typically using a probabilistic sampling scheme. The star formation rate is usually computed based on a Kennicutt-Schmidt type relation as dM /dt = εM g /t ff , where M g is the gas cell/particle mass, t ff is the gravitational free fall time and ε is a conversion efficiency typically in the range 0.01 -1 135,145,146 . However, not all the gas elements are eligible for star formation. Commonly adopted criteria are based on: a density threshold 124,125,135,[145][146][147][148][149][150] , restricting star formation to gravitationally bound regions identified via the virial parameter -that quantifies the degree of pressure support against gravitational collapse 146,151 , Jeans length-based criteria -that is gas must be prone to gravitational instability 146,148,152,153 , restricting star formation to the molecular gas phase 145,146,[154][155][156][157][158] or converging flows (∇ • v &lt; 0 147 ). Alternative to the probabilistic sampling scheme, and to better model the clustered nature of star formation, a few simulations also consider star clusters as the unit of star formation by allowing the growth of star particles through accretion from the ambient medium 159 . Once stellar particles have been formed, modern galaxy formation models also track the stellar evolution and mass return of these stars to the gas component. This leads to an enrichment of the gas with metals. Early models tracked only Type II supernova enrichment, but recent models also follow asymptotic giant branch stars 160 , Type Ia supernovae, which are important for iron enrichment 161 , and neutron star mergers for r-process element enrichment 162 . The actual enrichment is based on metal yield models derived from detailed stellar evolution calculations. These yields are however still rather uncertain, at least by a factor of two, particularly at low metallicities and for more massive stars. This uncertainty then propagates into predictions for metal abundances in simulations. Future cosmological simulations will still have to implement star formation as sub-resolution models with individual stars as their building blocks.Star formation: Cold and dense gas eventually forms stars, and simulations therefore transform a portion of this gas into collisionless star particles, representing co-eval, single-metallicity stellar populations described by an underlying initial stellar mass function. Observations support a nearly universal star formation efficiency in molecular gas, where about 1% of the gas is converted into stars per free fall time 143,144 . Based on a calculated star formation rate, the gas is converted into star particles typically using a probabilistic sampling scheme. The star formation rate is usually computed based on a Kennicutt-Schmidt type relation as dM /dt = εM g /t ff , where M g is the gas cell/particle mass, t ff is the gravitational free fall time and ε is a conversion efficiency typically in the range 0.01 -1 135,145,146 . However, not all the gas elements are eligible for star formation. Commonly adopted criteria are based on: a density threshold 124,125,135,[145][146][147][148][149][150] , restricting star formation to gravitationally bound regions identified via the virial parameter -that quantifies the degree of pressure support against gravitational collapse 146,151 , Jeans length-based criteria -that is gas must be prone to gravitational instability 146,148,152,153 , restricting star formation to the molecular gas phase 145,146,[154][155][156][157][158] or converging flows (∇ • v &lt; 0 147 ). Alternative to the probabilistic sampling scheme, and to better model the clustered nature of star formation, a few simulations also consider star clusters as the unit of star formation by allowing the growth of star particles through accretion from the ambient medium 159 . Once stellar particles have been formed, modern galaxy formation models also track the stellar evolution and mass return of these stars to the gas component. This leads to an enrichment of the gas with metals. Early models tracked only Type II supernova enrichment, but recent models also follow asymptotic giant branch stars 160 , Type Ia supernovae, which are important for iron enrichment 161 , and neutron star mergers for r-process element enrichment 162 . The actual enrichment is based on metal yield models derived from detailed stellar evolution calculations. These yields are however still rather uncertain, at least by a factor of two, particularly at low metallicities and for more massive stars. This uncertainty then propagates into predictions for metal abundances in simulations. Future cosmological simulations will still have to implement star formation as sub-resolution models with individual stars as their building blocks.</p>
        <p>Stellar feedback: Stars interact with their surrounding gas through the injection of energy and momentum leading to a feedback loop regulating star formation. To regulate star formation, stellar feedback must be efficient in launching galactic-scale outflows to eject gas from galaxies, and a plethora of sub-resolution schemes exists to achieve an efficient generation of galactic winds. Those differ in the way energy and momentum, most notably in the form of supernova explosions, are coupled to the surrounding gas. Essentially the energy can be deposited thermally or kinetically. In the first case, excessive radiative gas cooling must be avoided. While cooling in dense and cold gas is physically expected, at the comparatively low resolution of cosmological simulations it cannot be modeled reliably. The result is then an artificial excessive cooling of the gas, which leads to the unphysical loss of the supernova feedback energy via radiation and greatly reduces its effectiveness. Some approaches therefore disable the radiative cooling of the affected gas for a prescribed amount of time (∼ 10 7 yr) 147 , or heat the gas probabilistically to reach high enough temperatures (T ∼ 10 6 K) for radiative cooling to become ineffective on time scales of ∼ 10 7 yr 137 . In the second case, kinetic energy cannot be radiated away until it thermalizes. However, the use of hydrodynamically-decoupled wind particles, to realize a non-local injection of momentum in the gas surrounding active star forming regions, can still be necessary to obtain large-scale galactic outflows 135,150,161,163 . Recently, more explicit models for stellar feedback have been developed. In addition to supernova feedback they also take into account other feedback channels, such as energy and momentum injection by stellar winds and photoionization and radiation pressure due to radiation emitted by young, massive stars 139,145,146,164,165 . The combination of these processes then leads to a regulation of star formation to the observed low gas to star conversion efficiency of 1% per free-fall time 143,144 . Stellar feedback must be efficient in launching galactic-scale outflows to eject gas from galaxies, thereby also explaining the low baryon retention fraction in galaxies 166,167 . Recent explicit feedback models can make direct predictions for the outflow rates of these outflows 168 , whereas older models typically prescribe the mass loading of these galactic-scale outflows close to the galaxies. Sub-resolution models of stellar feedback vary widely among different galaxy formation models. More work is required to understand in detail which stellar feedback channels are most important for shaping the different types of galaxies.Stellar feedback: Stars interact with their surrounding gas through the injection of energy and momentum leading to a feedback loop regulating star formation. To regulate star formation, stellar feedback must be efficient in launching galactic-scale outflows to eject gas from galaxies, and a plethora of sub-resolution schemes exists to achieve an efficient generation of galactic winds. Those differ in the way energy and momentum, most notably in the form of supernova explosions, are coupled to the surrounding gas. Essentially the energy can be deposited thermally or kinetically. In the first case, excessive radiative gas cooling must be avoided. While cooling in dense and cold gas is physically expected, at the comparatively low resolution of cosmological simulations it cannot be modeled reliably. The result is then an artificial excessive cooling of the gas, which leads to the unphysical loss of the supernova feedback energy via radiation and greatly reduces its effectiveness. Some approaches therefore disable the radiative cooling of the affected gas for a prescribed amount of time (∼ 10 7 yr) 147 , or heat the gas probabilistically to reach high enough temperatures (T ∼ 10 6 K) for radiative cooling to become ineffective on time scales of ∼ 10 7 yr 137 . In the second case, kinetic energy cannot be radiated away until it thermalizes. However, the use of hydrodynamically-decoupled wind particles, to realize a non-local injection of momentum in the gas surrounding active star forming regions, can still be necessary to obtain large-scale galactic outflows 135,150,161,163 . Recently, more explicit models for stellar feedback have been developed. In addition to supernova feedback they also take into account other feedback channels, such as energy and momentum injection by stellar winds and photoionization and radiation pressure due to radiation emitted by young, massive stars 139,145,146,164,165 . The combination of these processes then leads to a regulation of star formation to the observed low gas to star conversion efficiency of 1% per free-fall time 143,144 . Stellar feedback must be efficient in launching galactic-scale outflows to eject gas from galaxies, thereby also explaining the low baryon retention fraction in galaxies 166,167 . Recent explicit feedback models can make direct predictions for the outflow rates of these outflows 168 , whereas older models typically prescribe the mass loading of these galactic-scale outflows close to the galaxies. Sub-resolution models of stellar feedback vary widely among different galaxy formation models. More work is required to understand in detail which stellar feedback channels are most important for shaping the different types of galaxies.</p>
        <p>Supermassive black holes: Supermassive black holes are observed in massive galaxies 169,170 , in small, bulge-less disc galaxies 171,172 as well as in dwarf galaxies 173,174 . Simulations therefore include models for supermassive black holes, and numerically seed them typically in dark matter haloes with masses 10 10 -10 11 M since the true seeds cannot be resolved, and their origin is not yet fully understood. They then accrete mass often based on an Eddington-rate-capped Bondi-Hoyle-like accretion rate:Supermassive black holes: Supermassive black holes are observed in massive galaxies 169,170 , in small, bulge-less disc galaxies 171,172 as well as in dwarf galaxies 173,174 . Simulations therefore include models for supermassive black holes, and numerically seed them typically in dark matter haloes with masses 10 10 -10 11 M since the true seeds cannot be resolved, and their origin is not yet fully understood. They then accrete mass often based on an Eddington-rate-capped Bondi-Hoyle-like accretion rate:</p>
        <p>, where ρ and c s are the gas density and gas sound speed, respectively, and v rel denotes the relative velocity between the gas and the black hole. Depending on the numerical resolution this accretion rate is sometimes artificially increased, possibly in a density-dependent fashion, to compensate for the inability of simulations to resolve the multi-phase structure of gas 175 . Many simulations also explored variations of the Bondi-Hoyle model to overcome its limitations. The Bondi model, for example, implicitly assumes that the accreting gas has negligible angular momentum, which is most likely unrealistic. Some models therefore assume that black holes might be primarily fed by gas driven to the centers by gravitational torques from non-axisymmetric perturbations 176 , which have more recently been explored in simulations [177][178][179][180][181][182] . Black holes also grow through mergers, which are modeled in cosmological simulations as well. Due to resolution limitations, general relativistic effects are not taken into account and it is assumed that the black holes of the two galaxies merge instantly once they come close enough, i.e. within their numerical accretion radius, which is typically calculated based on a local gas resolution element nearest neighbor search., where ρ and c s are the gas density and gas sound speed, respectively, and v rel denotes the relative velocity between the gas and the black hole. Depending on the numerical resolution this accretion rate is sometimes artificially increased, possibly in a density-dependent fashion, to compensate for the inability of simulations to resolve the multi-phase structure of gas 175 . Many simulations also explored variations of the Bondi-Hoyle model to overcome its limitations. The Bondi model, for example, implicitly assumes that the accreting gas has negligible angular momentum, which is most likely unrealistic. Some models therefore assume that black holes might be primarily fed by gas driven to the centers by gravitational torques from non-axisymmetric perturbations 176 , which have more recently been explored in simulations [177][178][179][180][181][182] . Black holes also grow through mergers, which are modeled in cosmological simulations as well. Due to resolution limitations, general relativistic effects are not taken into account and it is assumed that the black holes of the two galaxies merge instantly once they come close enough, i.e. within their numerical accretion radius, which is typically calculated based on a local gas resolution element nearest neighbor search.</p>
        <p>Feedback from active galactic nuclei: Active galactic nuclei are related to observational phenomena associated with accreting supermassive black holes including electromagnetic radiation, relativistic jets, and less-collimated non-relativistic outflows 183 . The resulting energy and momentum couple with the surrounding gas leading to a regulation of black hole growth and star formation in more massive halos (M &gt; ∼ 10 12 M ). This feedback is commonly divided in two modes that are implemented differently in simulations: quasar and radio mode. However, some galaxy formation models do not make this distinction arguing that cosmological simulations lack the resolution to properly distinguish the two feedback modes, and to limit the number of feedback channels to the minimum required to match the observational data 124 . Quasar mode feedback is associated with the radiatively efficient mode of black hole growth and is often implemented through energy or momentum injection assuming that the bolometric luminosity is proportional to the accretion rate, and a fixed fraction of this luminosity is deposited into the neighboring gas 184,185 . Recent works have also implemented momentum-driven winds via radiation pressure on dust [186][187][188] and via broad-line-region winds 189 . Radio mode feedback is caused by highly-collimated jets of relativistic particles, which are often associated with X-ray bubbles with enough energy to offset cooling losses. Therefore, this feedback mode is assumed to be important for the regulation of star formation in massive galaxies. Radio mode feedback is often implemented as a second sub-resolution feedback channel once the accretion rate is below a critical value 190,191 . Jets themselves cover an enormous dynamic range, being launched at several Schwarzschild radii, and propagating outwards to tens of kpc. Directly resolving them in detail in cosmological simulations is therefore currently not feasible. The sub-resolution models for supermassive black holes are therefore still very uncertain since they have to bridge a very large scale gap between the actual accretion and feedback, and the scales that can be resolved with simulations.Feedback from active galactic nuclei: Active galactic nuclei are related to observational phenomena associated with accreting supermassive black holes including electromagnetic radiation, relativistic jets, and less-collimated non-relativistic outflows 183 . The resulting energy and momentum couple with the surrounding gas leading to a regulation of black hole growth and star formation in more massive halos (M &gt; ∼ 10 12 M ). This feedback is commonly divided in two modes that are implemented differently in simulations: quasar and radio mode. However, some galaxy formation models do not make this distinction arguing that cosmological simulations lack the resolution to properly distinguish the two feedback modes, and to limit the number of feedback channels to the minimum required to match the observational data 124 . Quasar mode feedback is associated with the radiatively efficient mode of black hole growth and is often implemented through energy or momentum injection assuming that the bolometric luminosity is proportional to the accretion rate, and a fixed fraction of this luminosity is deposited into the neighboring gas 184,185 . Recent works have also implemented momentum-driven winds via radiation pressure on dust [186][187][188] and via broad-line-region winds 189 . Radio mode feedback is caused by highly-collimated jets of relativistic particles, which are often associated with X-ray bubbles with enough energy to offset cooling losses. Therefore, this feedback mode is assumed to be important for the regulation of star formation in massive galaxies. Radio mode feedback is often implemented as a second sub-resolution feedback channel once the accretion rate is below a critical value 190,191 . Jets themselves cover an enormous dynamic range, being launched at several Schwarzschild radii, and propagating outwards to tens of kpc. Directly resolving them in detail in cosmological simulations is therefore currently not feasible. The sub-resolution models for supermassive black holes are therefore still very uncertain since they have to bridge a very large scale gap between the actual accretion and feedback, and the scales that can be resolved with simulations.</p>
        <p>Magnetic fields: Magnetic fields permeate the Universe on all scales and impact the motion of ionized gas. Conversely, gas dynamics affects the topology and strength of magnetic fields. Cosmological simulations typically employ the ideal magnetohydrodynamics approach, which is a good approximation for cosmological magnetic fields. This approach assumes that the plasma is perfectly conducting and that relativistic effects, i.e. terms ∝ (v/c) 2 such as the displacement current c -1 ∂ E/∂t, are negligible. However, for other situations the ideal magnetohydrodynamics approximation breaks down and non-ideal terms, such as ohmic resistivity, ambipolar diffusion and the Hall effect, must be taken into account. These effects are important especially at very small spatial scales, e.g. for individual star formation, causing a diffusion of the magnetic field. On large cosmological scales the impact of magnetic fields on the dynamics of gas is rather limited 192 . However, magnetic fields are an essential constituent of the interstellar medium, providing both pressure support against gravity 193 and influencing the propagation of cosmic rays 194 . Cosmological simulations including magnetic fields through the ideal magnetohydrodynamics are typically initialized with a certain magnetic seed field, since the approximations and assumptions of ideal magnetohydrodynamics do not permit the self-consistent generation of magnetic fields. Some simulations also consider source terms like the Biermann battery effect or field injection from stellar winds as the source for initial magnetic fields 195 . In most cases, the initial conditions of such cosmological simulations contain however a small seed field of the order of roughly 10 -10 Gauss at a redshift of around z ∼ 100. The simulation results are not sensitive to this seed field as long as its value is not significantly too large, close to violating observational constraints 192,196 , or vanishingly small. The reason for this insensitivity lies in the strong amplification processes that occur during structure formation. This amplification typically occurs in two phases. At high redshifts, a turbulent dynamo leads to an exponential amplification of the magnetic fields in halos. Once the initial turbulent amplification phase has saturated, a second phase of magnetic field amplification starts leading to a linear growth caused by a galactic dynamo 197 . The numerical discretization of the ideal magnetohydrodynamics equations is challenging because of the solenoidal constraint ∇ • B = 0. Two main families of discretization techniques exist: divergence cleaning schemes and constrained transport. For the cleaning approach, source terms are added to the underlying magnetohydrodynamics equations to correct for divergence errors 198,199 . Constrained transport discretizations 200 , on the other hand, guarantee that the divergence is zero by construction. However, a more complex implementation is required in that case. For instance, either vector potentials 201 , Euler potentials 202,203 or staggered discretizations of the magnetic field components [204][205][206][207][208] must be employed.Magnetic fields: Magnetic fields permeate the Universe on all scales and impact the motion of ionized gas. Conversely, gas dynamics affects the topology and strength of magnetic fields. Cosmological simulations typically employ the ideal magnetohydrodynamics approach, which is a good approximation for cosmological magnetic fields. This approach assumes that the plasma is perfectly conducting and that relativistic effects, i.e. terms ∝ (v/c) 2 such as the displacement current c -1 ∂ E/∂t, are negligible. However, for other situations the ideal magnetohydrodynamics approximation breaks down and non-ideal terms, such as ohmic resistivity, ambipolar diffusion and the Hall effect, must be taken into account. These effects are important especially at very small spatial scales, e.g. for individual star formation, causing a diffusion of the magnetic field. On large cosmological scales the impact of magnetic fields on the dynamics of gas is rather limited 192 . However, magnetic fields are an essential constituent of the interstellar medium, providing both pressure support against gravity 193 and influencing the propagation of cosmic rays 194 . Cosmological simulations including magnetic fields through the ideal magnetohydrodynamics are typically initialized with a certain magnetic seed field, since the approximations and assumptions of ideal magnetohydrodynamics do not permit the self-consistent generation of magnetic fields. Some simulations also consider source terms like the Biermann battery effect or field injection from stellar winds as the source for initial magnetic fields 195 . In most cases, the initial conditions of such cosmological simulations contain however a small seed field of the order of roughly 10 -10 Gauss at a redshift of around z ∼ 100. The simulation results are not sensitive to this seed field as long as its value is not significantly too large, close to violating observational constraints 192,196 , or vanishingly small. The reason for this insensitivity lies in the strong amplification processes that occur during structure formation. This amplification typically occurs in two phases. At high redshifts, a turbulent dynamo leads to an exponential amplification of the magnetic fields in halos. Once the initial turbulent amplification phase has saturated, a second phase of magnetic field amplification starts leading to a linear growth caused by a galactic dynamo 197 . The numerical discretization of the ideal magnetohydrodynamics equations is challenging because of the solenoidal constraint ∇ • B = 0. Two main families of discretization techniques exist: divergence cleaning schemes and constrained transport. For the cleaning approach, source terms are added to the underlying magnetohydrodynamics equations to correct for divergence errors 198,199 . Constrained transport discretizations 200 , on the other hand, guarantee that the divergence is zero by construction. However, a more complex implementation is required in that case. For instance, either vector potentials 201 , Euler potentials 202,203 or staggered discretizations of the magnetic field components [204][205][206][207][208] must be employed.</p>
        <p>Ideal magnetohydrodynamics equations:Ideal magnetohydrodynamics equations:</p>
        <p>MHD Maxwell equations:MHD Maxwell equations:</p>
        <p>The evolution of the magnetic field, B, is given by the induction equation, ∂ B/∂t = ∇ × (v × B). Magnetic fields act on gas through the Lorentz force, J × B/c with the current density, J = c∇ × B/(4π). The energy equation contains the magnetic energy density, e B = ||B|| 2 /8π, and the Poynting vector, c(E × B/4π), in the flux part.The evolution of the magnetic field, B, is given by the induction equation, ∂ B/∂t = ∇ × (v × B). Magnetic fields act on gas through the Lorentz force, J × B/c with the current density, J = c∇ × B/(4π). The energy equation contains the magnetic energy density, e B = ||B|| 2 /8π, and the Poynting vector, c(E × B/4π), in the flux part.</p>
        <p>Cosmic rays: Relativistic nuclei and electrons, known as cosmic rays, are another important component of the galactic ecosystem. They are accelerated through diffusive shock acceleration mostly in supernova remnants and jets of active galactic nuclei (first-order Fermi acceleration) and turbulence (second-order Fermi acceleration). Cosmic rays contribute to the pressure in the interstellar medium 209,210 , provide an important heating channel 211,212 , and potentially play a role in driving galactic gas outflows [213][214][215][216][217][218][219][220][221][222] due to their shallow equation of state (P cr ∝ ρ 4/3 cr ), their long cooling time, and their ability to transfer energy to outflows outside of star-forming discs 223 . The propagation of cosmic rays is dictated by the strength and topology of the underlying magnetic fields.Cosmic rays: Relativistic nuclei and electrons, known as cosmic rays, are another important component of the galactic ecosystem. They are accelerated through diffusive shock acceleration mostly in supernova remnants and jets of active galactic nuclei (first-order Fermi acceleration) and turbulence (second-order Fermi acceleration). Cosmic rays contribute to the pressure in the interstellar medium 209,210 , provide an important heating channel 211,212 , and potentially play a role in driving galactic gas outflows [213][214][215][216][217][218][219][220][221][222] due to their shallow equation of state (P cr ∝ ρ 4/3 cr ), their long cooling time, and their ability to transfer energy to outflows outside of star-forming discs 223 . The propagation of cosmic rays is dictated by the strength and topology of the underlying magnetic fields.</p>
        <p>Reliably modeling the propagation of cosmic rays therefore requires a detailed modeling of magnetic fields. To capture all these effects self-consistently, the injection, acceleration and the transport of cosmic rays, through anisotropic diffusion and streaming, must be included in simulations. This requires, in principle, a detailed knowledge of the cosmic ray energy spectrum to accurately estimate energy losses and heating rates. The discretization of the cosmic ray transport terms is difficult. For example, anisotropic diffusion requires discretization techniques that avoid the violation of the entropy condition by limiting the transverse fluxes 217,[224][225][226] . Modeling cosmic ray streaming is particularly challenging because of the discontinuous dependence of the streaming velocity on the sign of the scalar product between the magnetic field and the cosmic ray pressure gradient in the one-moment formulation of cosmic ray hydrodynamics. This leads to unphysical oscillations of the solution and small time steps especially near cosmic ray pressure maxima if not addressed in form of regularization techniques -such as replacing the sign function with the hyperbolic tangent function that ensures a smooth dependence of the streaming velocity on cosmic rays and gas properties 219,226,227 , albeit at the expense of a dependence of the solution on a numerical parameter. An elegant solution of this problem is to replace the equation for the cosmic ray energy by two equations for cosmic ray energy and flux that are coupled to the MHD system of equations 228,229 . This two-moment formulation can be derived from quasi-linear theory of cosmic ray transport and describes cosmic ray streaming and diffusion self-consistently with a hyperbolic set of equations, which also contains the evolution equations for Alfvén waves that are self-generated by the streaming cosmic rays 229 .Reliably modeling the propagation of cosmic rays therefore requires a detailed modeling of magnetic fields. To capture all these effects self-consistently, the injection, acceleration and the transport of cosmic rays, through anisotropic diffusion and streaming, must be included in simulations. This requires, in principle, a detailed knowledge of the cosmic ray energy spectrum to accurately estimate energy losses and heating rates. The discretization of the cosmic ray transport terms is difficult. For example, anisotropic diffusion requires discretization techniques that avoid the violation of the entropy condition by limiting the transverse fluxes 217,[224][225][226] . Modeling cosmic ray streaming is particularly challenging because of the discontinuous dependence of the streaming velocity on the sign of the scalar product between the magnetic field and the cosmic ray pressure gradient in the one-moment formulation of cosmic ray hydrodynamics. This leads to unphysical oscillations of the solution and small time steps especially near cosmic ray pressure maxima if not addressed in form of regularization techniques -such as replacing the sign function with the hyperbolic tangent function that ensures a smooth dependence of the streaming velocity on cosmic rays and gas properties 219,226,227 , albeit at the expense of a dependence of the solution on a numerical parameter. An elegant solution of this problem is to replace the equation for the cosmic ray energy by two equations for cosmic ray energy and flux that are coupled to the MHD system of equations 228,229 . This two-moment formulation can be derived from quasi-linear theory of cosmic ray transport and describes cosmic ray streaming and diffusion self-consistently with a hyperbolic set of equations, which also contains the evolution equations for Alfvén waves that are self-generated by the streaming cosmic rays 229 .</p>
        <p>Ideal magnetohydrodynamics equations with cosmic rays: MHD Maxwell equations:Ideal magnetohydrodynamics equations with cosmic rays: MHD Maxwell equations:</p>
        <p>Cosmic rays energy density evolution:Cosmic rays energy density evolution:</p>
        <p>Cosmic rays exhibit a force on the gas through ∇P cr . Their energy density is influenced by streaming with velocityCosmic rays exhibit a force on the gas through ∇P cr . Their energy density is influenced by streaming with velocity</p>
        <p>, and adiabatic processes due to the compression of the Alfvèn frame (P cr ∇ • [v + v st ]). The terms Λ th , Λ cr , Γ th and Γ cr , represent non-adiabatic source and sink terms., and adiabatic processes due to the compression of the Alfvèn frame (P cr ∇ • [v + v st ]). The terms Λ th , Λ cr , Γ th and Γ cr , represent non-adiabatic source and sink terms.</p>
        <p>Radiation Hydrodynamics: Radiation alters the thermal, kinetic, and chemical state of the gas. Radiation hydrodynamics simulations are required to capture this self-consistently. In the context of cosmological simulations, radiation hydrodynamics simulations have so far primarily been employed to study the epoch of reionization 153,230,231 . These simulations are aimed at exploring the high redshift Universe and are typically not evolved towards the low redshift regime. Consequently, the employed galaxy formation models within these simulations can also not be tested against low redshift predictions. Only a limited number of simulations have studied the impact of radiation in the context of galaxy formation simulations 140,232 . The main reason for this lack of detailed radiation hydrodynamics studies is that numerical radiative transfer is challenging because of the high dimensionality caused by the frequency and directional dependencies of photon propagation. Even more challenging is the fact that in general the speed of light poses severe constraints on the timesteps of these simulations, which can however be circumvented to some degree through the application of a reduced speed of light approximation [233][234][235][236] . The most common numerical methods for radiation hydrodynamics are ray-tracing, Monte Carlo, and moment-based methods. The ray-tracing method discretizes the radiative transfer equation along individual directions from each source. Long characteristic ray-tracing schemes [237][238][239] , cast rays from the source through the whole simulation domain, and the transport, absorption and emission of radiation is computed along each ray. Long characteristic schemes are accurate but computationally expensive, since they scale as O(N s × N p c ), where N s is the number of sources, N c is the number of underling discretization resolution elements, for example cells, and p is a method-and geometry-dependent exponent 240,241 . Short characteristic methods [242][243][244][245] , on the other hand, solve the radiative transport only along rays that connect nearby cells allowing an efficient parallelization and merging procedures to break the O(N s × N p c ) scaling. Monte Carlo methods [246][247][248][249][250][251] , often only applied in post-processing, emit photon packets and propagate them probing the gas opacity, interaction lengths and scattering angles from underlying probability density functions thus stochastically solving the radiative transfer equation. One drawback of Monte Carlo schemes is that the signal-to-noise ratio improves only as the square root of the number of photon packets due to Poisson noise. Still, Monte Carlo is highly accurate and photon weighting, path-based estimators, and discrete diffusion schemes help overcome the efficiency barriers that inhibit convergence [252][253][254][255] . Moment-based methods became popular over the last years due to superior scalability 140,[256][257][258][259] . They are based on a fluid-like description of radiation fields by taking zeroth, first and second moments of the radiation specific intensity with respect to the angular variable. This defines a radiation energy density E ν , flux F ν , pressure tensor P ν and hyperbolic conservation laws for the energy density and the radiation flux. Similar to the hydrodynamical case, where an equation of state is required to relate gas pressure and density, a non-unique closure relation is required to relate P ν to E ν and F ν . A widely used approach is to define P ν ≡ E ν D, where D is the Eddington tensor that can be estimated with different methods, for example through flux-limited diffusion 117,260 , the optically thin variable Eddington tensor approach 233,261,262 or the M1 closure 140,256,259,263,264 . For the former methods D is estimated assuming that the gas between sources of radiation is always optically thick or thin. The M1 method, instead, computes the Eddington tensor by using local radiation quantities.Radiation Hydrodynamics: Radiation alters the thermal, kinetic, and chemical state of the gas. Radiation hydrodynamics simulations are required to capture this self-consistently. In the context of cosmological simulations, radiation hydrodynamics simulations have so far primarily been employed to study the epoch of reionization 153,230,231 . These simulations are aimed at exploring the high redshift Universe and are typically not evolved towards the low redshift regime. Consequently, the employed galaxy formation models within these simulations can also not be tested against low redshift predictions. Only a limited number of simulations have studied the impact of radiation in the context of galaxy formation simulations 140,232 . The main reason for this lack of detailed radiation hydrodynamics studies is that numerical radiative transfer is challenging because of the high dimensionality caused by the frequency and directional dependencies of photon propagation. Even more challenging is the fact that in general the speed of light poses severe constraints on the timesteps of these simulations, which can however be circumvented to some degree through the application of a reduced speed of light approximation [233][234][235][236] . The most common numerical methods for radiation hydrodynamics are ray-tracing, Monte Carlo, and moment-based methods. The ray-tracing method discretizes the radiative transfer equation along individual directions from each source. Long characteristic ray-tracing schemes [237][238][239] , cast rays from the source through the whole simulation domain, and the transport, absorption and emission of radiation is computed along each ray. Long characteristic schemes are accurate but computationally expensive, since they scale as O(N s × N p c ), where N s is the number of sources, N c is the number of underling discretization resolution elements, for example cells, and p is a method-and geometry-dependent exponent 240,241 . Short characteristic methods [242][243][244][245] , on the other hand, solve the radiative transport only along rays that connect nearby cells allowing an efficient parallelization and merging procedures to break the O(N s × N p c ) scaling. Monte Carlo methods [246][247][248][249][250][251] , often only applied in post-processing, emit photon packets and propagate them probing the gas opacity, interaction lengths and scattering angles from underlying probability density functions thus stochastically solving the radiative transfer equation. One drawback of Monte Carlo schemes is that the signal-to-noise ratio improves only as the square root of the number of photon packets due to Poisson noise. Still, Monte Carlo is highly accurate and photon weighting, path-based estimators, and discrete diffusion schemes help overcome the efficiency barriers that inhibit convergence [252][253][254][255] . Moment-based methods became popular over the last years due to superior scalability 140,[256][257][258][259] . They are based on a fluid-like description of radiation fields by taking zeroth, first and second moments of the radiation specific intensity with respect to the angular variable. This defines a radiation energy density E ν , flux F ν , pressure tensor P ν and hyperbolic conservation laws for the energy density and the radiation flux. Similar to the hydrodynamical case, where an equation of state is required to relate gas pressure and density, a non-unique closure relation is required to relate P ν to E ν and F ν . A widely used approach is to define P ν ≡ E ν D, where D is the Eddington tensor that can be estimated with different methods, for example through flux-limited diffusion 117,260 , the optically thin variable Eddington tensor approach 233,261,262 or the M1 closure 140,256,259,263,264 . For the former methods D is estimated assuming that the gas between sources of radiation is always optically thick or thin. The M1 method, instead, computes the Eddington tensor by using local radiation quantities.</p>
        <p>Radiative transfer equation:Radiative transfer equation:</p>
        <p>The radiative transfer equation relates the specific radiation intensity, I ν , with the absorption coefficient, κ ν , and the specific emissivity, j ν . The radiation direction of propagation is represented by the unit vector n. Λ is the cooling function, Γ p and Γ E are source terms that describe the transfer of momentum and energy from the radiation to the gas.The radiative transfer equation relates the specific radiation intensity, I ν , with the absorption coefficient, κ ν , and the specific emissivity, j ν . The radiation direction of propagation is represented by the unit vector n. Λ is the cooling function, Γ p and Γ E are source terms that describe the transfer of momentum and energy from the radiation to the gas.</p>
        <p>Other physics: Additional physical processes considered in some cosmological simulations of galaxy formation are, for example, dust physics [265][266][267][268][269][270][271][272][273] , thermal conduction 188,225,[274][275][276][277][278] , and viscosity [279][280][281][282] .Other physics: Additional physical processes considered in some cosmological simulations of galaxy formation are, for example, dust physics [265][266][267][268][269][270][271][272][273] , thermal conduction 188,225,[274][275][276][277][278] , and viscosity [279][280][281][282] .</p>
        <p>Dust has typically been neglected in galaxy formation simulations since it contributes only about ∼ 1% to the mass budget of the interstellar medium. However, dust plays an important role for the evolution of the interstellar medium affecting the thermochemistry and radiation processing. Therefore, recently galaxy formation began to incorporate first simple dust models to follow its production, growth and destruction in the interstellar medium. Most of these implementations treat dust as a passive scalar and model the processes affecting the dust population through effective rate equations. Thermal conduction is another physical effect that is often neglected in cosmological simulations of galaxy formation. However, in hot plasmas of galaxy clusters, conduction can affect the thermodynamic properties of galaxy clusters as has recently been demonstrated 278,[283][284][285] . Simulating thermal conduction requires a precise numerical magnetohydrodynamics implementation to resolve the strength and topology of the magnetic field, and an efficient anisotropic diffusion solver to model the conduction 225 .Dust has typically been neglected in galaxy formation simulations since it contributes only about ∼ 1% to the mass budget of the interstellar medium. However, dust plays an important role for the evolution of the interstellar medium affecting the thermochemistry and radiation processing. Therefore, recently galaxy formation began to incorporate first simple dust models to follow its production, growth and destruction in the interstellar medium. Most of these implementations treat dust as a passive scalar and model the processes affecting the dust population through effective rate equations. Thermal conduction is another physical effect that is often neglected in cosmological simulations of galaxy formation. However, in hot plasmas of galaxy clusters, conduction can affect the thermodynamic properties of galaxy clusters as has recently been demonstrated 278,[283][284][285] . Simulating thermal conduction requires a precise numerical magnetohydrodynamics implementation to resolve the strength and topology of the magnetic field, and an efficient anisotropic diffusion solver to model the conduction 225 .</p>
        <p>Caveats and limitations: Simulations of the dark matter component typically boil down to implementing efficient N-body methods and parallelization schemes. Simulations of the baryonic matter component are however more challenging, since they require reliable hydrodynamics numerical schemes and well-posed sub-resolution models. These additional complications lead to some caveats and limitations of such simulations.Caveats and limitations: Simulations of the dark matter component typically boil down to implementing efficient N-body methods and parallelization schemes. Simulations of the baryonic matter component are however more challenging, since they require reliable hydrodynamics numerical schemes and well-posed sub-resolution models. These additional complications lead to some caveats and limitations of such simulations.</p>
        <p>Calibration: The numerical implementation of baryonic physics is based on sub-resolution models due to the intrinsic resolution limitations of any simulation. These effective models depend on a certain number of adjustable parameters. Depending on the exact galaxy formation model implementation, these parameters can either be chosen based on physical arguments or they require a certain calibration procedure. The latter approach is often employed in large volume simulations, where the sub-resolution models are less detailed compared to those of zoom simulations. The calibration process consists of a parameter exploration for the effective models through a large number of simulations. These simulations typically cover a smaller volume compared to production simulations. The calibration is then based on a comparison to some key observables of the galaxy population like the star formation rate density as a function of cosmic time, the galaxy stellar mass function at z = 0 and the present-day stellar-to-halo mass relation. Numerical convergence: Cosmological simulations have to cover a wide range of spatial and time scales. This implies that simulations have to aim for the highest possible number of resolution elements. However, even state-of-the-art simulations cannot capture all relevant scales. Simulations are therefore often performed at different resolution levels to understand the exact dependence of the results on the number of resolution elements. A simulation prediction is then said to be converged once this prediction does not significantly change anymore if the numerical resolution is further increased.Calibration: The numerical implementation of baryonic physics is based on sub-resolution models due to the intrinsic resolution limitations of any simulation. These effective models depend on a certain number of adjustable parameters. Depending on the exact galaxy formation model implementation, these parameters can either be chosen based on physical arguments or they require a certain calibration procedure. The latter approach is often employed in large volume simulations, where the sub-resolution models are less detailed compared to those of zoom simulations. The calibration process consists of a parameter exploration for the effective models through a large number of simulations. These simulations typically cover a smaller volume compared to production simulations. The calibration is then based on a comparison to some key observables of the galaxy population like the star formation rate density as a function of cosmic time, the galaxy stellar mass function at z = 0 and the present-day stellar-to-halo mass relation. Numerical convergence: Cosmological simulations have to cover a wide range of spatial and time scales. This implies that simulations have to aim for the highest possible number of resolution elements. However, even state-of-the-art simulations cannot capture all relevant scales. Simulations are therefore often performed at different resolution levels to understand the exact dependence of the results on the number of resolution elements. A simulation prediction is then said to be converged once this prediction does not significantly change anymore if the numerical resolution is further increased.</p>
        <p>Diverging results: Various simulations now agree on a wide range of predictions. This is especially the case for predictions of the stellar content of galaxies and related observables. However, there is also a wide range of predictions that diverge among different simulations. For example, the characteristics of gas around galaxies are very sensitive to the feedback implementations used in the different galaxy formation models. This can lead to rather different outcomes for the thermodynamic structure of gas around galaxies. Such difference can then be used to differentiate and test galaxy formation models.Diverging results: Various simulations now agree on a wide range of predictions. This is especially the case for predictions of the stellar content of galaxies and related observables. However, there is also a wide range of predictions that diverge among different simulations. For example, the characteristics of gas around galaxies are very sensitive to the feedback implementations used in the different galaxy formation models. This can lead to rather different outcomes for the thermodynamic structure of gas around galaxies. Such difference can then be used to differentiate and test galaxy formation models.</p>
        <p>The results of hydrodynamical simulations can directly be confronted with observational data providing important tests for galaxy formation models. This often involves the construction of detailed mock observations based on the simulated data 286,287 . Early simulations successfully reproduced properties of the intergalactic medium such as the column density distribution of the Lyman-α forest 288 . Many simulations also focused on the formation of individual galaxies [289][290][291][292][293] . However, such simulations suffered for a long time from, for example, inconsistent stellar masses, galaxy sizes, star formation histories and galaxy morphologies 163,[294][295][296] . Only recently simulations began to produce realistic galaxies 87,124,125,146,149,297,298 . However, different sub-resolution implementations of astrophysical processes remain a major source of uncertainties. Results of hydrodynamical simulations can be grouped into those for global properties for the whole galaxy population, and those for the properties of individual galaxies.The results of hydrodynamical simulations can directly be confronted with observational data providing important tests for galaxy formation models. This often involves the construction of detailed mock observations based on the simulated data 286,287 . Early simulations successfully reproduced properties of the intergalactic medium such as the column density distribution of the Lyman-α forest 288 . Many simulations also focused on the formation of individual galaxies [289][290][291][292][293] . However, such simulations suffered for a long time from, for example, inconsistent stellar masses, galaxy sizes, star formation histories and galaxy morphologies 163,[294][295][296] . Only recently simulations began to produce realistic galaxies 87,124,125,146,149,297,298 . However, different sub-resolution implementations of astrophysical processes remain a major source of uncertainties. Results of hydrodynamical simulations can be grouped into those for global properties for the whole galaxy population, and those for the properties of individual galaxies.</p>
        <p>Global Properties: Large volume simulations are ideally suited to explore global properties of the galaxy population due to their large statistical sample size. This enables direct comparisons to astronomical galaxy surveys. Table 2 presents some selected recent structure and galaxy formation simulations. Stellar content of galaxies: One of the most fundamental properties of the galaxy population is the galaxy stellar mass function, which quantifies the comoving number density of galaxies as a function of galaxy stellar mass. Stellar mass functions are frequently described by a Schechter function 299 with parameter M * , a characteristic mass scale above which the distribution is exponentially suppressed, a normalization φ * , and α * setting the low-mass slope. Observed low redshift parameters are roughly given by log(M * /M ) ≈ 11, log(Φ * /Mpc -3 ) ≈ -2.7, α * ≈ -1.2 300 . However, double Schechter functions provide an even better description of low redshift galaxy stellar mass functions [301][302][303][304][305] . The halo mass function exhibits a steeper low-mass slope, ≈ -2, than the galaxy stellar mass function and the exponential suppression occurs at a lower volume density. Reproducing the observed stellar mass function therefore requires a strong suppression of star formation at both the low and high mass ends. Galaxy formation models assume that supernova feedback flattens out the low-mass (M &lt; ∼ 10 12 M ) slope by suppressing star formation [306][307][308] while the suppression of bright and high-mass (M &gt; ∼ 10 12 M ) galaxies is regulated by feedback from active galactic nuclei. Energetically plausible forms of supernova and active galactic nuclei feedback in simulations resulted in galaxy stellar mass functions that are consistent with observational data. Simulation predictions are also often confronted with empirical constraints on the relationship between stellar mass and halo mass, which are derived based on various galaxy-halo mapping techniques 166,167 . This ratio of stellar mass to halo mass peaks around halo masses of roughly ∼ 10 12 M , where star formation is most efficient. For higher and lower halo masses, the star formation rates are reduced due to feedback processes. Modern large volume simulations reproduce the stellar to halo mass relationship at low and high redshifts reasonably well 124,309 .Global Properties: Large volume simulations are ideally suited to explore global properties of the galaxy population due to their large statistical sample size. This enables direct comparisons to astronomical galaxy surveys. Table 2 presents some selected recent structure and galaxy formation simulations. Stellar content of galaxies: One of the most fundamental properties of the galaxy population is the galaxy stellar mass function, which quantifies the comoving number density of galaxies as a function of galaxy stellar mass. Stellar mass functions are frequently described by a Schechter function 299 with parameter M * , a characteristic mass scale above which the distribution is exponentially suppressed, a normalization φ * , and α * setting the low-mass slope. Observed low redshift parameters are roughly given by log(M * /M ) ≈ 11, log(Φ * /Mpc -3 ) ≈ -2.7, α * ≈ -1.2 300 . However, double Schechter functions provide an even better description of low redshift galaxy stellar mass functions [301][302][303][304][305] . The halo mass function exhibits a steeper low-mass slope, ≈ -2, than the galaxy stellar mass function and the exponential suppression occurs at a lower volume density. Reproducing the observed stellar mass function therefore requires a strong suppression of star formation at both the low and high mass ends. Galaxy formation models assume that supernova feedback flattens out the low-mass (M &lt; ∼ 10 12 M ) slope by suppressing star formation [306][307][308] while the suppression of bright and high-mass (M &gt; ∼ 10 12 M ) galaxies is regulated by feedback from active galactic nuclei. Energetically plausible forms of supernova and active galactic nuclei feedback in simulations resulted in galaxy stellar mass functions that are consistent with observational data. Simulation predictions are also often confronted with empirical constraints on the relationship between stellar mass and halo mass, which are derived based on various galaxy-halo mapping techniques 166,167 . This ratio of stellar mass to halo mass peaks around halo masses of roughly ∼ 10 12 M , where star formation is most efficient. For higher and lower halo masses, the star formation rates are reduced due to feedback processes. Modern large volume simulations reproduce the stellar to halo mass relationship at low and high redshifts reasonably well 124,309 .</p>
        <p>Gas around galaxies: One of the key advantages of hydrodynamical simulations compared to semianalytic models (see Box 1) is their ability to make detailed predictions for the distribution and properties of gas around galaxies including the circumgalactic medium, the intracluster medium, and the intergalactic medium. The circumgalactic and intergalactic media are quite diffuse (n ∼ 10 -3 -10 -7 cm -3 ) and cool (T ∼ 10 4-6 K) and observations in emission, like Lyman-α and metal lines, are therefore rather challenging. However, absorption line observations from background quasars can probe the distribution, enrichment, and ionization state of this gas. One of the first successes of hydrodynamical simulations has been the reproduction of the declining trend of the number of absorbing clouds per unit redshift and linear interval of HI column density with column density in the Lyman-α forest 288 . Reproducing properties of the circumgalactic medium, however, is significantly more challenging. Observations of this gas indicate that it features a rich multi-phase structure where individual lines of sight simultaneously contain highly ionized, warm, and cool atomic species 310,311 . The coolest and densest parts of this gas have spatial scales of 10 -100 pc 312 , although the coherence scale can reach up to ∼ 1 kpc 313 . These spatial scales are below the typical circumgalactic gas resolution limits of galaxy formation simulations. More recently, cosmological simulations with special circumgalactic gas refinement schemes have been employed to overcome some of the resolution limitations. Such simulations increase the numerical resolution in the circumgalactic gas reaching smaller spatial scales [314][315][316][317] . At z = 2 such simulations can reach a spatial resolution below ∼ 100 pc 316 , and at z = 0 below ∼ 1 kpc within the circumgalactic medium 315 . In addition to resolution concerns, the circumgalactic medium is influenced by feedback-driven outflows from galaxies, whose characteristics are not yet properly understood and modeled. The circumgalactic medium can therefore also be used to constrain feedback mechanisms. The intracluster medium can directly be observed via X-ray observations due to the much higher gas temperatures (T ∼ 10 7-8 K). Many properties of the intracluster medium , like X-ray and Sunyaev-Zeldovich scaling relations or the iron distribution, can be accurately modeled in simulations [318][319][320][321] . However, significant challenges remain for galaxy formation models to reproduce cluster entropy profiles and, in particular, distinct cool-core, and non cool-core clusters 126,322 .Gas around galaxies: One of the key advantages of hydrodynamical simulations compared to semianalytic models (see Box 1) is their ability to make detailed predictions for the distribution and properties of gas around galaxies including the circumgalactic medium, the intracluster medium, and the intergalactic medium. The circumgalactic and intergalactic media are quite diffuse (n ∼ 10 -3 -10 -7 cm -3 ) and cool (T ∼ 10 4-6 K) and observations in emission, like Lyman-α and metal lines, are therefore rather challenging. However, absorption line observations from background quasars can probe the distribution, enrichment, and ionization state of this gas. One of the first successes of hydrodynamical simulations has been the reproduction of the declining trend of the number of absorbing clouds per unit redshift and linear interval of HI column density with column density in the Lyman-α forest 288 . Reproducing properties of the circumgalactic medium, however, is significantly more challenging. Observations of this gas indicate that it features a rich multi-phase structure where individual lines of sight simultaneously contain highly ionized, warm, and cool atomic species 310,311 . The coolest and densest parts of this gas have spatial scales of 10 -100 pc 312 , although the coherence scale can reach up to ∼ 1 kpc 313 . These spatial scales are below the typical circumgalactic gas resolution limits of galaxy formation simulations. More recently, cosmological simulations with special circumgalactic gas refinement schemes have been employed to overcome some of the resolution limitations. Such simulations increase the numerical resolution in the circumgalactic gas reaching smaller spatial scales [314][315][316][317] . At z = 2 such simulations can reach a spatial resolution below ∼ 100 pc 316 , and at z = 0 below ∼ 1 kpc within the circumgalactic medium 315 . In addition to resolution concerns, the circumgalactic medium is influenced by feedback-driven outflows from galaxies, whose characteristics are not yet properly understood and modeled. The circumgalactic medium can therefore also be used to constrain feedback mechanisms. The intracluster medium can directly be observed via X-ray observations due to the much higher gas temperatures (T ∼ 10 7-8 K). Many properties of the intracluster medium , like X-ray and Sunyaev-Zeldovich scaling relations or the iron distribution, can be accurately modeled in simulations [318][319][320][321] . However, significant challenges remain for galaxy formation models to reproduce cluster entropy profiles and, in particular, distinct cool-core, and non cool-core clusters 126,322 .</p>
        <p>Galaxy clustering: Galaxy clustering varies as a function of galaxy mass and galaxy properties, e.g. formation time, star formation rate, color. Simulations now reproduce a number of features in the galaxy clustering signal including the mass dependent two-point correlation length 87 , which increases with increasing masses [323][324][325] , the clustering signal for non-and star-forming galaxies 87,326 , and the steepening of the power law slope γ of the galaxy correlation function with declining redshift (γ ∼ 1.8 at z 0 and γ ∼ 1.6 at z 1 87,327 ). Scaling relations: Galaxies exhibit a wide range of scaling relations linking various observables constituting another important test for galaxy formation models. Modern large volume hydrodynamical simulations broadly reproduce many galaxy scaling relations including the mass-size 328 , the supermassive black hole mass-stellar velocity dispersion relation 329 , and the mass-metallicity 330 relation [331][332][333][334] . Also other galaxy characteristics like the color of galaxies as a function of galaxy stellar mass can now be reasonably well reproduced by cosmological simulations 298,335,336 . However, there are still points of tension including, for example, the magnitude of the scatter, the detailed shape, or the dependence on additional galaxy properties.Galaxy clustering: Galaxy clustering varies as a function of galaxy mass and galaxy properties, e.g. formation time, star formation rate, color. Simulations now reproduce a number of features in the galaxy clustering signal including the mass dependent two-point correlation length 87 , which increases with increasing masses [323][324][325] , the clustering signal for non-and star-forming galaxies 87,326 , and the steepening of the power law slope γ of the galaxy correlation function with declining redshift (γ ∼ 1.8 at z 0 and γ ∼ 1.6 at z 1 87,327 ). Scaling relations: Galaxies exhibit a wide range of scaling relations linking various observables constituting another important test for galaxy formation models. Modern large volume hydrodynamical simulations broadly reproduce many galaxy scaling relations including the mass-size 328 , the supermassive black hole mass-stellar velocity dispersion relation 329 , and the mass-metallicity 330 relation [331][332][333][334] . Also other galaxy characteristics like the color of galaxies as a function of galaxy stellar mass can now be reasonably well reproduced by cosmological simulations 298,335,336 . However, there are still points of tension including, for example, the magnitude of the scatter, the detailed shape, or the dependence on additional galaxy properties.</p>
        <p>Studying baryonic physics through hydrodynamical simulations is computationally expensive compared to dark matter-only N-body simulations. An alternative approach is to model baryonic physics on top of N-body dark matter simulations through analytic models. This combination of numerical dark matter-only simulations, and analytic models for the prescription of baryonic physics, is known as semi-analytic modeling [337][338][339][340][341] . These semi-analytic models track, for example, how much gas accretes onto halos, how much hot gas cools and turns into stars, or how feedback processes remove cold gas from the galaxy or heat the halo gas. The models are based on the merger history of dark matter halos extracted from N-body simulations. The result of such a calculation is a predicted galaxy population that can be compared to observational data in a similar way as the output of full hydrodynamical simulations. The key advantage of semi-analytical models is their efficiency. It is therefore possible to perform a wide range of calculations, using different model variations. However, a disadvantage of semi-analytic models is that they are less self-consistent compared to hydrodynamical simulations. Furthermore, studying detailed gas properties, for example, the circumgalactic gas with these models is not directly possible since the gas component is not resolved.Studying baryonic physics through hydrodynamical simulations is computationally expensive compared to dark matter-only N-body simulations. An alternative approach is to model baryonic physics on top of N-body dark matter simulations through analytic models. This combination of numerical dark matter-only simulations, and analytic models for the prescription of baryonic physics, is known as semi-analytic modeling [337][338][339][340][341] . These semi-analytic models track, for example, how much gas accretes onto halos, how much hot gas cools and turns into stars, or how feedback processes remove cold gas from the galaxy or heat the halo gas. The models are based on the merger history of dark matter halos extracted from N-body simulations. The result of such a calculation is a predicted galaxy population that can be compared to observational data in a similar way as the output of full hydrodynamical simulations. The key advantage of semi-analytical models is their efficiency. It is therefore possible to perform a wide range of calculations, using different model variations. However, a disadvantage of semi-analytic models is that they are less self-consistent compared to hydrodynamical simulations. Furthermore, studying detailed gas properties, for example, the circumgalactic gas with these models is not directly possible since the gas component is not resolved.</p>
        <p>Galaxy Properties: The detailed properties of late-type disc-like and early-type spheroid-dominated galaxies have been studied extensively using simulations.Galaxy Properties: The detailed properties of late-type disc-like and early-type spheroid-dominated galaxies have been studied extensively using simulations.</p>
        <p>Properties of late-type galaxies: Simulating the formation of star-forming, late-type galaxies has been one of the most pressing challenges of computational galaxy formation. For a long time, simulations struggled to form galaxies with extended and rotationally-supported stellar and gaseous discs as observed in the Universe. These discs are expected to form through angular momentum conservation of the cooling gas in dark matter halos 342,343 . However, realizing this mechanism in cosmological simulations turned out to be difficult, and early works produced galaxies dominated by a stellar spheroidal component, with a sub-dominant disc only 294,344 . More efficient stellar feedback schemes were required to offset runaway radiative losses of the star-forming gas, the so-called overcooling catastrophe 345 , and to eject the low-angular momentum material responsible for the creation of the dominant stellar bulge , the so-called angular momentum catastrophe 346 . The success of modern simulations in producing late-type disc galaxies is largely due to the ability of stellar feedback to regulate star formation efficiently 125,145,146,164,297,[347][348][349][350][351][352] .Properties of late-type galaxies: Simulating the formation of star-forming, late-type galaxies has been one of the most pressing challenges of computational galaxy formation. For a long time, simulations struggled to form galaxies with extended and rotationally-supported stellar and gaseous discs as observed in the Universe. These discs are expected to form through angular momentum conservation of the cooling gas in dark matter halos 342,343 . However, realizing this mechanism in cosmological simulations turned out to be difficult, and early works produced galaxies dominated by a stellar spheroidal component, with a sub-dominant disc only 294,344 . More efficient stellar feedback schemes were required to offset runaway radiative losses of the star-forming gas, the so-called overcooling catastrophe 345 , and to eject the low-angular momentum material responsible for the creation of the dominant stellar bulge , the so-called angular momentum catastrophe 346 . The success of modern simulations in producing late-type disc galaxies is largely due to the ability of stellar feedback to regulate star formation efficiently 125,145,146,164,297,[347][348][349][350][351][352] .</p>
        <p>More recently, magnetic fields in late-type galaxies have also been studied to understand their topology and field strengths 197,[353][354][355][356][357] . Furthermore, the impact of cosmic rays in galaxies has been studied in more detail over the last years 217,219 . These results indicate that cosmic rays are potentially important for driving galactic outflows.More recently, magnetic fields in late-type galaxies have also been studied to understand their topology and field strengths 197,[353][354][355][356][357] . Furthermore, the impact of cosmic rays in galaxies has been studied in more detail over the last years 217,219 . These results indicate that cosmic rays are potentially important for driving galactic outflows.</p>
        <p>Properties of early-type galaxies: Simulations can also reproduce spheroid-dominated early-type systems, which broadly match the early formation history 358 , scaling relations (e.g. the mass and size or velocity dispersion) 359,360 , and the metallicity distribution 361 of observed early-type galaxies. The assembly of such large objects proceeds in two phases [362][363][364][365] . At high redshift (z &gt; ∼ 1.5), galaxies grow predominantly in-situ by efficiently converting gas into stars. At later times, mass is predominantly gained through accretion of smaller substructures, i.e. mergers, which also considerably increases galaxy sizes. Spatiallyresolved spectral observations have shown that spheroid-dominated galaxies have diverse kinematics and shapes. The kinematics is usually described through the so-called spin parameter λ R . This quantity is used to split galaxies into fast (λ R &gt; 0.1) and slow (λ R &lt; 0.1) rotator classes. The ellipticity ε, instead, is used to define the spheroid's shape. Simulations have played a major role in building a physical picture to explain the diversity in kinematics and shapes of spheroid-dominating galaxies that are produced based on their formation histories 358,366,367 , in particular through gas dissipation, which builds rotationally-supported a PM: particle-mesh; TreePM: tree + PM; FM: fast multipole; P 3 M: particle-particle-particle-mesh; ML: multilevel; SPH: smoothed particle hydrodynamics; AMR: adaptive-mesh-refinement; MMFV: moving-mesh finite volume; MLFM: mesh-free finite mass b highest resolution quoted (dark matter/gas) c for particle based codes, the minimum softening length is reported; for mesh codes, the minimum cell size is quoted (dark matter/gas) d final redshift z = 8; spatial resolution is in physical units at that redshift e IllustrisTNG consists of three main simulations: TNG50, TNG100, TNG300; numbers are quoted for TNG100 f numbers for largest volume simulation quoted g in physical units at z = 3 h for baryons the minimum physical softening is reported 21/34 5Properties of early-type galaxies: Simulations can also reproduce spheroid-dominated early-type systems, which broadly match the early formation history 358 , scaling relations (e.g. the mass and size or velocity dispersion) 359,360 , and the metallicity distribution 361 of observed early-type galaxies. The assembly of such large objects proceeds in two phases [362][363][364][365] . At high redshift (z &gt; ∼ 1.5), galaxies grow predominantly in-situ by efficiently converting gas into stars. At later times, mass is predominantly gained through accretion of smaller substructures, i.e. mergers, which also considerably increases galaxy sizes. Spatiallyresolved spectral observations have shown that spheroid-dominated galaxies have diverse kinematics and shapes. The kinematics is usually described through the so-called spin parameter λ R . This quantity is used to split galaxies into fast (λ R &gt; 0.1) and slow (λ R &lt; 0.1) rotator classes. The ellipticity ε, instead, is used to define the spheroid's shape. Simulations have played a major role in building a physical picture to explain the diversity in kinematics and shapes of spheroid-dominating galaxies that are produced based on their formation histories 358,366,367 , in particular through gas dissipation, which builds rotationally-supported a PM: particle-mesh; TreePM: tree + PM; FM: fast multipole; P 3 M: particle-particle-particle-mesh; ML: multilevel; SPH: smoothed particle hydrodynamics; AMR: adaptive-mesh-refinement; MMFV: moving-mesh finite volume; MLFM: mesh-free finite mass b highest resolution quoted (dark matter/gas) c for particle based codes, the minimum softening length is reported; for mesh codes, the minimum cell size is quoted (dark matter/gas) d final redshift z = 8; spatial resolution is in physical units at that redshift e IllustrisTNG consists of three main simulations: TNG50, TNG100, TNG300; numbers are quoted for TNG100 f numbers for largest volume simulation quoted g in physical units at z = 3 h for baryons the minimum physical softening is reported 21/34 5</p>
        <p>Cosmological simulations of galaxy formation have also been used to explore alternative cosmological models. At the most basic level the cosmological model can be altered in three different ways: alternative forms of dark matter, alternative forms of dark energy, or alternative forms of gravity. We note that many simulations of alternative cosmological models typically only consider the dark matter component and do not model baryons. However, these simulations then neglect the important backreaction between baryons and dark matter. Similarly, simulations including baryons are also now important to infer cosmological parameters. For example, DESI, LSST and Euclid will rely on models based on galaxy formation simulations to achieve their forecasted precision. Future explorations of alternative cosmologies have to consider and include these effects by also modeling the baryon component. The cold dark matter paradigm correctly describes the large-scale distribution of galaxies. On sub-galactic scales however, some problems have been identified over the last decades 392 . Among the most relevant challenges are: the under-abundance of dwarf galaxies in the Milky Way and in the field (the missing satellites problem 92,[393][394][395][396] ), the inconsistency of inner dark matter density profiles in low surface brightness and dwarf galaxies (the cuspcore problem 397,398 ), the deficit of dark matter in the inner regions of massive dwarf galaxies (the too-big-to-fail problem 399,400 ), and the large variety of shapes of dwarf rotation curves (the diversity problem 401 ). Most of these problems have been found by contrasting dark matter-only simulations with observations, which do not take into account the complex baryonic dark matter interactions. It is therefore possible that these challenges can be solved through the proper modeling of baryonic physics. For instance, the existence of dark matter cores can potentially be explained by the gravitational transfer of energy from supernovae into the orbits of dark matter particles [402][403][404][405][406] . Alternatively, these discrepancies between observations and cold dark matter simulations can also be explored through alternative dark matter models. These small-scale problems have therefore generated significant interest in the exploration of alternative dark matter scenarios.Cosmological simulations of galaxy formation have also been used to explore alternative cosmological models. At the most basic level the cosmological model can be altered in three different ways: alternative forms of dark matter, alternative forms of dark energy, or alternative forms of gravity. We note that many simulations of alternative cosmological models typically only consider the dark matter component and do not model baryons. However, these simulations then neglect the important backreaction between baryons and dark matter. Similarly, simulations including baryons are also now important to infer cosmological parameters. For example, DESI, LSST and Euclid will rely on models based on galaxy formation simulations to achieve their forecasted precision. Future explorations of alternative cosmologies have to consider and include these effects by also modeling the baryon component. The cold dark matter paradigm correctly describes the large-scale distribution of galaxies. On sub-galactic scales however, some problems have been identified over the last decades 392 . Among the most relevant challenges are: the under-abundance of dwarf galaxies in the Milky Way and in the field (the missing satellites problem 92,[393][394][395][396] ), the inconsistency of inner dark matter density profiles in low surface brightness and dwarf galaxies (the cuspcore problem 397,398 ), the deficit of dark matter in the inner regions of massive dwarf galaxies (the too-big-to-fail problem 399,400 ), and the large variety of shapes of dwarf rotation curves (the diversity problem 401 ). Most of these problems have been found by contrasting dark matter-only simulations with observations, which do not take into account the complex baryonic dark matter interactions. It is therefore possible that these challenges can be solved through the proper modeling of baryonic physics. For instance, the existence of dark matter cores can potentially be explained by the gravitational transfer of energy from supernovae into the orbits of dark matter particles [402][403][404][405][406] . Alternatively, these discrepancies between observations and cold dark matter simulations can also be explored through alternative dark matter models. These small-scale problems have therefore generated significant interest in the exploration of alternative dark matter scenarios.</p>
        <p>A wide range of alternative dark matter models have been proposed over the last decades. However, not all of these models have been studied in detail through simulations. Mostly three main classes of alternative dark matter models have been simulated: warm dark matter, self-interacting dark matter, and fuzzy dark matter. Many of these models have been invoked to address small-scale problems of the cold dark matter paradigm (see Box 2).A wide range of alternative dark matter models have been proposed over the last decades. However, not all of these models have been studied in detail through simulations. Mostly three main classes of alternative dark matter models have been simulated: warm dark matter, self-interacting dark matter, and fuzzy dark matter. Many of these models have been invoked to address small-scale problems of the cold dark matter paradigm (see Box 2).</p>
        <p>Warm Dark Matter: Cold dark matter models exhibit a high-k cut-off in the initial power spectrum due to free-streaming or collisional damping. For a canonical weakly interactive massive particle this cut-off is of the order of 1 comoving parsec corresponding to a mass scale of 10 -6 M 407 . Warm dark matter models, on the other hand, have an effective free-streaming length λ fs that scales inversely with particle mass 408 . For recent cosmologies 3 , this relation is approximately λ fs = 33(m WDM /1 keV) -1.11 kpc and the corresponding free-streaming mass is M fs = 2 × 10 7 (m WDM /1 keV) -3.33 M . The reduction of small-scale power within warm dark matter models has two consequences: first, a reduction of low mass halos, and second a reduction of the central density of halos. Simulations of warm dark matter models are typically carried out with the same numerical methods as cold dark matter simulations, but with modified initial conditions. However, the power spectrum cut-off leads to artificial and numerical discreteness effects in N-body simulations 28 . Special care is then required to avoid a contamination of results in that case. More recently alternative methods based on phase-space tessellation techniques have been employed to study warm dark matter models avoiding these numerical artifacts 78 .Warm Dark Matter: Cold dark matter models exhibit a high-k cut-off in the initial power spectrum due to free-streaming or collisional damping. For a canonical weakly interactive massive particle this cut-off is of the order of 1 comoving parsec corresponding to a mass scale of 10 -6 M 407 . Warm dark matter models, on the other hand, have an effective free-streaming length λ fs that scales inversely with particle mass 408 . For recent cosmologies 3 , this relation is approximately λ fs = 33(m WDM /1 keV) -1.11 kpc and the corresponding free-streaming mass is M fs = 2 × 10 7 (m WDM /1 keV) -3.33 M . The reduction of small-scale power within warm dark matter models has two consequences: first, a reduction of low mass halos, and second a reduction of the central density of halos. Simulations of warm dark matter models are typically carried out with the same numerical methods as cold dark matter simulations, but with modified initial conditions. However, the power spectrum cut-off leads to artificial and numerical discreteness effects in N-body simulations 28 . Special care is then required to avoid a contamination of results in that case. More recently alternative methods based on phase-space tessellation techniques have been employed to study warm dark matter models avoiding these numerical artifacts 78 .</p>
        <p>Self-Interacting Dark Matter: Dark matter models that involve dark matter self-interactions 409,410 have also been explored extensively. Self-interactions are commonly quantified in terms of the cross section per unit particle mass, σ /m. Models with constant and velocity-dependent cross sections have both been studied with simulations 411 . The high central dark matter densities observed in clusters exclude self-interacting dark matter models with σ /m 0.5 cm 2 /g for these cluster mass scales. Recently, more general self-interacting dark matter models have been suggested. Those have both truncated power spectra and self-interactions 412,413 . Such models affect the internal structure of dark matter halos through the scattering of particles that cause the formation of density cores. On the other hand, the truncated power spectra also lead, similar to warm dark matter models, to a suppression of halo substructure. Various recent simulations have demonstrated that models with σ /m ≈ 0.5-10 cm 2 /g produce dark matter cores in dwarf galaxies with sizes ∼ 0.3 -1.5 kpc and central densities 2 -0.2 × 10 8 M /kpc 3 = 7.4 -0.74 GeV/cm 3 that can alleviate some cold dark matter small-scale problems [414][415][416][417] . Simulations of self-interacting dark matter are based on the N-body approach coupled to a local Monte Carlo-based probabilistic scattering scheme to model particle self-interactions.Self-Interacting Dark Matter: Dark matter models that involve dark matter self-interactions 409,410 have also been explored extensively. Self-interactions are commonly quantified in terms of the cross section per unit particle mass, σ /m. Models with constant and velocity-dependent cross sections have both been studied with simulations 411 . The high central dark matter densities observed in clusters exclude self-interacting dark matter models with σ /m 0.5 cm 2 /g for these cluster mass scales. Recently, more general self-interacting dark matter models have been suggested. Those have both truncated power spectra and self-interactions 412,413 . Such models affect the internal structure of dark matter halos through the scattering of particles that cause the formation of density cores. On the other hand, the truncated power spectra also lead, similar to warm dark matter models, to a suppression of halo substructure. Various recent simulations have demonstrated that models with σ /m ≈ 0.5-10 cm 2 /g produce dark matter cores in dwarf galaxies with sizes ∼ 0.3 -1.5 kpc and central densities 2 -0.2 × 10 8 M /kpc 3 = 7.4 -0.74 GeV/cm 3 that can alleviate some cold dark matter small-scale problems [414][415][416][417] . Simulations of self-interacting dark matter are based on the N-body approach coupled to a local Monte Carlo-based probabilistic scattering scheme to model particle self-interactions.</p>
        <p>Fuzzy Dark Matter: An ultralight bosonic scalar field is a completely different alternative to the cold dark matter paradigm 418 , where a bosonic fluid with a particle mass of m ∼ 10 -22 eV suppresses small-scale structure owing to macroscopic quantum properties [419][420][421] with a typical de Broglie wavelength of λ DB ∼ 1 kpc 422,423 . The dark matter fluid forms in this case a cosmological Bose-Einstein condensate [424][425][426] . Such an ultralight scalar field of spin-0 at zero temperature is described in the non-relativistic limit by the Schrödinger-Poisson equations 419,420,427,428 : ih∂ ψ/∂t = -h 2 /2m∇ 2 ψ + mV ψ and ∇ 2 V = 4πG(ρ -ρ), where ρ = |ψ| 2 is the fluid density, ρ is the mean density, and V is the potential. One consequence of the macroscopic quantum behavior of the fluid is that the fluid admits stable, minimum-energy soliton configurations forming at the centers of self-gravitating halos. These kpc-scale soliton cores offer one possible solution to the cusp-core problem of cold dark matter. Numerically, the Schrödinger-Poisson equations can, for example, be solved through adaptive spectral methods or through a reformulation into a hydrodynamics problem, that can be solved with hydrodynamical discretization techniques, based on the Madelung formulation 429,430 .Fuzzy Dark Matter: An ultralight bosonic scalar field is a completely different alternative to the cold dark matter paradigm 418 , where a bosonic fluid with a particle mass of m ∼ 10 -22 eV suppresses small-scale structure owing to macroscopic quantum properties [419][420][421] with a typical de Broglie wavelength of λ DB ∼ 1 kpc 422,423 . The dark matter fluid forms in this case a cosmological Bose-Einstein condensate [424][425][426] . Such an ultralight scalar field of spin-0 at zero temperature is described in the non-relativistic limit by the Schrödinger-Poisson equations 419,420,427,428 : ih∂ ψ/∂t = -h 2 /2m∇ 2 ψ + mV ψ and ∇ 2 V = 4πG(ρ -ρ), where ρ = |ψ| 2 is the fluid density, ρ is the mean density, and V is the potential. One consequence of the macroscopic quantum behavior of the fluid is that the fluid admits stable, minimum-energy soliton configurations forming at the centers of self-gravitating halos. These kpc-scale soliton cores offer one possible solution to the cusp-core problem of cold dark matter. Numerically, the Schrödinger-Poisson equations can, for example, be solved through adaptive spectral methods or through a reformulation into a hydrodynamics problem, that can be solved with hydrodynamical discretization techniques, based on the Madelung formulation 429,430 .</p>
        <p>Cosmological simulations must include at least a cosmological constant to account for the accelerated expansion of the Universe. A wide range of alternative dark energy models have, however, been considered in the literature 431 and a number of these have also been studied with simulations 432 .Cosmological simulations must include at least a cosmological constant to account for the accelerated expansion of the Universe. A wide range of alternative dark energy models have, however, been considered in the literature 431 and a number of these have also been studied with simulations 432 .</p>
        <p>The most simple extension in the dark energy sector is to assume a dark energy density that is time dependent but still spatially homogeneous -at least on sub-horizon scales. This behavior can, for example, be obtained in scalar field models of dark energy 432 . Cosmic structure growth is then only affected via an altered background expansion. The only change required to perform cosmological simulations of such models is then to modify the calculation of the Hubble expansion rate in the numerical integration 433,434 . As the growth function is different than in ΛCDM, extra care is also required when choosing the amplitude of matter density fluctuations in the initial conditions, i.e. taking into account at what redshift observational constraints on the amount of fluctuations are aimed to be matched. For example, models with a higher dark energy density at early times suppress structure growth and have hence a lower amplitude of fluctuations at redshift zero for the same scalar amplitude in the cosmic microwave background 433,434 . Dynamical dark energy can have a surprisingly large impact on galaxy properties in simulations 435 . In practice, this results in degeneracies between cosmology and the feedback physics that is required to match observations. Inhomogeneous dark energy: Models of dark energy that exhibit sizable spatial fluctuations within the horizon represent the next level of complexity. For such models, and even more so for the coupled dark energy models, a clear distinction between dark energy and modified gravity is often not possible as accelerations arising from spatial fluctuations in the dark energy field can also be interpreted as modifications to the laws of gravity. Relatively little simulation work has been done on models in which inhomogeneous dark energy interacts with matter only gravitationally, such as, for example, in the clustering dark energy scenario 436 .The most simple extension in the dark energy sector is to assume a dark energy density that is time dependent but still spatially homogeneous -at least on sub-horizon scales. This behavior can, for example, be obtained in scalar field models of dark energy 432 . Cosmic structure growth is then only affected via an altered background expansion. The only change required to perform cosmological simulations of such models is then to modify the calculation of the Hubble expansion rate in the numerical integration 433,434 . As the growth function is different than in ΛCDM, extra care is also required when choosing the amplitude of matter density fluctuations in the initial conditions, i.e. taking into account at what redshift observational constraints on the amount of fluctuations are aimed to be matched. For example, models with a higher dark energy density at early times suppress structure growth and have hence a lower amplitude of fluctuations at redshift zero for the same scalar amplitude in the cosmic microwave background 433,434 . Dynamical dark energy can have a surprisingly large impact on galaxy properties in simulations 435 . In practice, this results in degeneracies between cosmology and the feedback physics that is required to match observations. Inhomogeneous dark energy: Models of dark energy that exhibit sizable spatial fluctuations within the horizon represent the next level of complexity. For such models, and even more so for the coupled dark energy models, a clear distinction between dark energy and modified gravity is often not possible as accelerations arising from spatial fluctuations in the dark energy field can also be interpreted as modifications to the laws of gravity. Relatively little simulation work has been done on models in which inhomogeneous dark energy interacts with matter only gravitationally, such as, for example, in the clustering dark energy scenario 436 .</p>
        <p>Coupled dark energy: In the hope to alleviate the puzzle of the similar energy density of matter and dark energy at the present cosmic epoch, additional non-gravitational couplings between these sectors have been proposed 437 . Such a coupling of dark energy to matter could either be universal, i.e. involving all matter species, or non-universal, with dark energy, for example, coupling only to dark matter but not to baryons. Models with a universal coupling typically require a screening mechanism that hides its effects in dense environments like the solar system, where experimental tests of gravity tightly constrain a direct coupling to baryons. In contrast, models with a coupling only to dark matter are observationally much less constrained. In both cases, growing perturbations in the matter density field can naturally give rise to corresponding fluctuations in the coupled dark energy field. Coupled dark energy scenarios have been widely studied with simulations, either avoiding 438,439 or including 440,441 a treatment of the spatial fluctuations of dark energy. In the former case, the main effects of coupling terms are a time dependence of the gravitating particle mass of the coupled matter species, as well as a velocity dependent friction term. Accounting for the spatial fluctuation additionally results in a fifth force proportional to the gradient of the dark energy field. These effects have, for example, been found to lower the concentrations and baryon fraction of halos 439 , thereby reducing potential tensions compared to a ΛCDM cosmology.Coupled dark energy: In the hope to alleviate the puzzle of the similar energy density of matter and dark energy at the present cosmic epoch, additional non-gravitational couplings between these sectors have been proposed 437 . Such a coupling of dark energy to matter could either be universal, i.e. involving all matter species, or non-universal, with dark energy, for example, coupling only to dark matter but not to baryons. Models with a universal coupling typically require a screening mechanism that hides its effects in dense environments like the solar system, where experimental tests of gravity tightly constrain a direct coupling to baryons. In contrast, models with a coupling only to dark matter are observationally much less constrained. In both cases, growing perturbations in the matter density field can naturally give rise to corresponding fluctuations in the coupled dark energy field. Coupled dark energy scenarios have been widely studied with simulations, either avoiding 438,439 or including 440,441 a treatment of the spatial fluctuations of dark energy. In the former case, the main effects of coupling terms are a time dependence of the gravitating particle mass of the coupled matter species, as well as a velocity dependent friction term. Accounting for the spatial fluctuation additionally results in a fifth force proportional to the gradient of the dark energy field. These effects have, for example, been found to lower the concentrations and baryon fraction of halos 439 , thereby reducing potential tensions compared to a ΛCDM cosmology.</p>
        <p>While general relativity has been tested to high precision within the solar system, constraints on galactic and intergalactic scales are much weaker. Indeed, additional components that have so far not been directly observed, dark matter and dark energy, need to be added to allow a viable description of cosmology by general relativity. As an alternative, modifications of the laws of gravity have been proposed, which could make at least one of these components obsolete.While general relativity has been tested to high precision within the solar system, constraints on galactic and intergalactic scales are much weaker. Indeed, additional components that have so far not been directly observed, dark matter and dark energy, need to be added to allow a viable description of cosmology by general relativity. As an alternative, modifications of the laws of gravity have been proposed, which could make at least one of these components obsolete.</p>
        <p>Modified gravity as an alternative to dark matter: Dark matter models successfully explain observations on many different scales, including the cosmic microwave background, the Lyman-α forest, the clustering of galaxies, and the internal dynamics of galaxies and galaxy clusters. Most work aimed at replacing the role of dark matter by a modification of the laws of gravity has focused only on a subset of these areas. For example, modified Newtonian dynamics 442,443 , a change in Newton's second law at small acceleration values ( F = mµ(| a|/a 0 ) a, with a 0 ∼ 10 -10 m s -2 and µ(x) → 1 for x 1 and µ(x) → x for x 1), or alternatively a change in Poisson's equation of Newtonian gravity ( ∇ • (µ(| a|/a 0 ) a) = 4πρ), has been proposed to account for the flat rotation curves of galaxies at large radii. Since this modified Poisson's equation is non-linear, gravity algorithms that are based on the principle of linear force superposition such as direct summation, tree and Fourier transform-based schemes are not suitable to simulate these kinds of models. Simulations have therefore been performed with the multigrid method with the full approximation scheme 24 . The non-linear partial differential equation is then discretized on a grid with a finite difference representation of the differential operator and iteratively solved using Gauss-Seidel relaxation. Since modified Newtonian dynamics is not a relativistic theory, relativistic extensions of it have also been proposed, for example, tensor-vector-scalar gravity (TeVeS) 444,445 . Here gravity is mediated by a tensor (metric), vector and scalar field. However, these models have not been widely studied in full cosmological simulations yet. Models without a dark matter component such as modified Newtonian dynamics also naturally account for the tight observed relation between the gravitational acceleration inferred from galaxy rotation curves and that expected from the observed baryonic mass 446,447 . However, galaxy formation simulations within the ΛCDM framework can also produce a sufficiently tight relation [448][449][450] .Modified gravity as an alternative to dark matter: Dark matter models successfully explain observations on many different scales, including the cosmic microwave background, the Lyman-α forest, the clustering of galaxies, and the internal dynamics of galaxies and galaxy clusters. Most work aimed at replacing the role of dark matter by a modification of the laws of gravity has focused only on a subset of these areas. For example, modified Newtonian dynamics 442,443 , a change in Newton's second law at small acceleration values ( F = mµ(| a|/a 0 ) a, with a 0 ∼ 10 -10 m s -2 and µ(x) → 1 for x 1 and µ(x) → x for x 1), or alternatively a change in Poisson's equation of Newtonian gravity ( ∇ • (µ(| a|/a 0 ) a) = 4πρ), has been proposed to account for the flat rotation curves of galaxies at large radii. Since this modified Poisson's equation is non-linear, gravity algorithms that are based on the principle of linear force superposition such as direct summation, tree and Fourier transform-based schemes are not suitable to simulate these kinds of models. Simulations have therefore been performed with the multigrid method with the full approximation scheme 24 . The non-linear partial differential equation is then discretized on a grid with a finite difference representation of the differential operator and iteratively solved using Gauss-Seidel relaxation. Since modified Newtonian dynamics is not a relativistic theory, relativistic extensions of it have also been proposed, for example, tensor-vector-scalar gravity (TeVeS) 444,445 . Here gravity is mediated by a tensor (metric), vector and scalar field. However, these models have not been widely studied in full cosmological simulations yet. Models without a dark matter component such as modified Newtonian dynamics also naturally account for the tight observed relation between the gravitational acceleration inferred from galaxy rotation curves and that expected from the observed baryonic mass 446,447 . However, galaxy formation simulations within the ΛCDM framework can also produce a sufficiently tight relation [448][449][450] .</p>
        <p>Modified gravity as an alternative to dark energy: Dark energy has only been observed through its impact on the background expansion of the Universe. Replacing dark energy with a modification to the laws of gravity is, compared to replacing dark matter, easier. In fact, a cosmological constant in the Einstein field equations can also be interpreted as modified gravity rather than an unexpectedly small zero-point energy of a quantum field. In the literature, a wide range of much more sophisticated modified gravity theories have been considered. While many of these can account for the observed accelerated expansion of the Universe, Occam's razor would typically disfavor them compared to a cosmological constant in the absence of observational evidence beyond the observed background expansion. Cosmological simulations have been widely used to investigate the observational signatures of such extended gravity models to guide observational searches for potential modifications of gravity over a wide range of scales. Many modified gravity models that exhibit interesting behavior on, for example, galactic and intergalactic scales have been designed such that they approach general relativity in dense environments such as the solar system to avoid violating experimental constraints. Such screening mechanisms typically involve non-linear partial differential equations, which renders them numerically challenging and requires tailored techniques 451 . Most schemes resort to the multigrid method with the full approximation scheme 24 , e.g. employed on an adaptively refining mesh [452][453][454] . With such methods cosmological simulations have been carried out for a number of screened modified gravity models, including Chameleon-f (R), DGP, symmetron, dilaton, and Galileon gravity [455][456][457] . Most such studies focused on collisionless simulations. Semi-analytical galaxy formation models combined with Chameleon-f (R) gravity demonstrated that the gravity modification effects on basic properties such as galaxy stellar mass functions and cosmic star formation rate densities are rather small and comparable to the uncertainties of the semi-analytical models 458 . Clustering signals and relative velocities of halo pairs can, however, change notably 458,459 . Post-processing ΛCDM galaxy formation simulations with a modified gravity solver suggests that there should be characteristic changes in the internal kinematics of galaxies such as features in their rotation curves near the screening threshold 460 , which can also result in degeneracies with the core/cusp problem 461 . Fully self-consistent simulation studies of galaxy formation in such screened modified gravity models have only started very recently 462 . Such simulations should in principle also take into account effects that modified gravity has on stellar physics 463 .Modified gravity as an alternative to dark energy: Dark energy has only been observed through its impact on the background expansion of the Universe. Replacing dark energy with a modification to the laws of gravity is, compared to replacing dark matter, easier. In fact, a cosmological constant in the Einstein field equations can also be interpreted as modified gravity rather than an unexpectedly small zero-point energy of a quantum field. In the literature, a wide range of much more sophisticated modified gravity theories have been considered. While many of these can account for the observed accelerated expansion of the Universe, Occam's razor would typically disfavor them compared to a cosmological constant in the absence of observational evidence beyond the observed background expansion. Cosmological simulations have been widely used to investigate the observational signatures of such extended gravity models to guide observational searches for potential modifications of gravity over a wide range of scales. Many modified gravity models that exhibit interesting behavior on, for example, galactic and intergalactic scales have been designed such that they approach general relativity in dense environments such as the solar system to avoid violating experimental constraints. Such screening mechanisms typically involve non-linear partial differential equations, which renders them numerically challenging and requires tailored techniques 451 . Most schemes resort to the multigrid method with the full approximation scheme 24 , e.g. employed on an adaptively refining mesh [452][453][454] . With such methods cosmological simulations have been carried out for a number of screened modified gravity models, including Chameleon-f (R), DGP, symmetron, dilaton, and Galileon gravity [455][456][457] . Most such studies focused on collisionless simulations. Semi-analytical galaxy formation models combined with Chameleon-f (R) gravity demonstrated that the gravity modification effects on basic properties such as galaxy stellar mass functions and cosmic star formation rate densities are rather small and comparable to the uncertainties of the semi-analytical models 458 . Clustering signals and relative velocities of halo pairs can, however, change notably 458,459 . Post-processing ΛCDM galaxy formation simulations with a modified gravity solver suggests that there should be characteristic changes in the internal kinematics of galaxies such as features in their rotation curves near the screening threshold 460 , which can also result in degeneracies with the core/cusp problem 461 . Fully self-consistent simulation studies of galaxy formation in such screened modified gravity models have only started very recently 462 . Such simulations should in principle also take into account effects that modified gravity has on stellar physics 463 .</p>
        <p>Cosmological simulations of galaxy formation play a crucial role for our understanding of galaxy formation. Especially, the last years have seen enormous progress on two fronts: large volume simulations modeling large samples of galaxies, and zoom simulations with refined galaxy formation models that resolve the physical processes in more detail. Modern galaxy formation simulations reproduce now a plethora of observational results and create virtual universes that are to first order nearly identical to the real Universe. At the same time, these simulations are also employed to explore alternative cosmological models with modifications to the nature of dark matter, dark energy and gravity. This progress in the field of galaxy formation simulations has mostly been driven by a better understanding of galaxy formation physics, refined numerical methods, and the steady growth of computing power.Cosmological simulations of galaxy formation play a crucial role for our understanding of galaxy formation. Especially, the last years have seen enormous progress on two fronts: large volume simulations modeling large samples of galaxies, and zoom simulations with refined galaxy formation models that resolve the physical processes in more detail. Modern galaxy formation simulations reproduce now a plethora of observational results and create virtual universes that are to first order nearly identical to the real Universe. At the same time, these simulations are also employed to explore alternative cosmological models with modifications to the nature of dark matter, dark energy and gravity. This progress in the field of galaxy formation simulations has mostly been driven by a better understanding of galaxy formation physics, refined numerical methods, and the steady growth of computing power.</p>
        <p>Cosmological simulations of galaxy formation use a variety of different numerical methods, and different implementations of galaxy formation physics. Despite these differences, such simulations have now converged on a wide range of predictions for the evolution of galaxies. It therefore seems that the basic physical mechanisms that shape the galaxy population have been identified, and that their current modeling is sufficient to produce realistic galaxy populations. However, these physical processes are implemented through still rather crude sub-resolution models. Sub-resolution models aim to capture the relevant physics through an effective description. In fact, cosmological simulations will always have to rely on these sub-resolution models since truly ab initio cosmological simulations of galaxy formation are and will remain impossible. One danger associated with the application of sub-resolution models is the belief that the reproduction of large amounts of observational data automatically implies a correct and physically plausible effective model and therefore detailed understanding of galaxy formation. This is problematic since sub-resolution models contain per construction a certain number of adjustable and degenerate parameters, and at the same time do not really capture the detailed physics at play but only provide an effective coarse description. Caution is therefore required to not over-interpret some of the recent successes generated by these models.Cosmological simulations of galaxy formation use a variety of different numerical methods, and different implementations of galaxy formation physics. Despite these differences, such simulations have now converged on a wide range of predictions for the evolution of galaxies. It therefore seems that the basic physical mechanisms that shape the galaxy population have been identified, and that their current modeling is sufficient to produce realistic galaxy populations. However, these physical processes are implemented through still rather crude sub-resolution models. Sub-resolution models aim to capture the relevant physics through an effective description. In fact, cosmological simulations will always have to rely on these sub-resolution models since truly ab initio cosmological simulations of galaxy formation are and will remain impossible. One danger associated with the application of sub-resolution models is the belief that the reproduction of large amounts of observational data automatically implies a correct and physically plausible effective model and therefore detailed understanding of galaxy formation. This is problematic since sub-resolution models contain per construction a certain number of adjustable and degenerate parameters, and at the same time do not really capture the detailed physics at play but only provide an effective coarse description. Caution is therefore required to not over-interpret some of the recent successes generated by these models.</p>
        <p>One of the next goals of computational galaxy formation is to understand which detailed physical processes drive the outcomes of effective physical models. For example, many simulations employ rather crude and incomplete models for the generation of galactic outflows without a detailed modeling of the driving process. Future simulations should aim at understanding these processes in more detail to illuminate the true physical processes at work going beyond the crude effective models to gain more fundamental insights. This will also lead to a better understanding of what physics actually drives the overall behavior of currently existing coarse-grained effective sub-resolution models. While constructing new models and simulations, it is important to keep in mind that the major goal of simulations is not primarily to fit observed data, but rather to gain insights into galaxy formation physics. Advances in this direction benefit often more from failures of certain ideas or models, rather than a perfect reproduction of observational data that is to some degree subject to the calibration of free model parameters and the coarse-grained nature of the employed models. Another frontier of cosmological galaxy formation simulations is the desire to provide large volume simulations that match the statistical sample sizes of upcoming large observational surveys. This requires very large volume simulations with well-understood sub-resolution models. The development and better understanding of refined sub-resolution models, the desire to achieve higher numerical resolution, and simulations with larger volumes represent the main challenges of cosmological simulations of the next decade.One of the next goals of computational galaxy formation is to understand which detailed physical processes drive the outcomes of effective physical models. For example, many simulations employ rather crude and incomplete models for the generation of galactic outflows without a detailed modeling of the driving process. Future simulations should aim at understanding these processes in more detail to illuminate the true physical processes at work going beyond the crude effective models to gain more fundamental insights. This will also lead to a better understanding of what physics actually drives the overall behavior of currently existing coarse-grained effective sub-resolution models. While constructing new models and simulations, it is important to keep in mind that the major goal of simulations is not primarily to fit observed data, but rather to gain insights into galaxy formation physics. Advances in this direction benefit often more from failures of certain ideas or models, rather than a perfect reproduction of observational data that is to some degree subject to the calibration of free model parameters and the coarse-grained nature of the employed models. Another frontier of cosmological galaxy formation simulations is the desire to provide large volume simulations that match the statistical sample sizes of upcoming large observational surveys. This requires very large volume simulations with well-understood sub-resolution models. The development and better understanding of refined sub-resolution models, the desire to achieve higher numerical resolution, and simulations with larger volumes represent the main challenges of cosmological simulations of the next decade.</p>
        <p>• Arbitrary Lagrangian-Eulerian methods (e.g. moving mesh) • Mesh-free / mesh-based • cold dark matter • warm dark matter • self-interacting dark matter • fuzzy dark matter • ..• cosmological constant • dynamical dark energy • inhomogeneous dark energy • coupled dark energy • ... • Newtonian• Arbitrary Lagrangian-Eulerian methods (e.g. moving mesh) • Mesh-free / mesh-based • cold dark matter • warm dark matter • self-interacting dark matter • fuzzy dark matter • ..• cosmological constant • dynamical dark energy • inhomogeneous dark energy • coupled dark energy • ... • Newtonian</p>
        <p>••</p>
        <p>......</p>
        <p>We thank David Barnes, Mike Boylan-Kolchin, Lars Hernquist, Rahul Kannan, Hui Li, Stephanie O'Neil, Rüdiger Pakmor, Christoph Pfrommer, Laura Sales, Aaron Smith, Volker Springel, and Rainer Weinberger for useful comments. We also thank the reviewers for helpful feedback. MV acknowledges support through an MIT RSC award, a Kavli Research Investment Fund, NASA ATP grant NNX17AG29G, and NSF grants AST-1814053 and AST-1814259. FM acknowledges support through the Program "Rita Levi Montalcini" of the Italian MIUR.We thank David Barnes, Mike Boylan-Kolchin, Lars Hernquist, Rahul Kannan, Hui Li, Stephanie O'Neil, Rüdiger Pakmor, Christoph Pfrommer, Laura Sales, Aaron Smith, Volker Springel, and Rainer Weinberger for useful comments. We also thank the reviewers for helpful feedback. MV acknowledges support through an MIT RSC award, a Kavli Research Investment Fund, NASA ATP grant NNX17AG29G, and NSF grants AST-1814053 and AST-1814259. FM acknowledges support through the Program "Rita Levi Montalcini" of the Italian MIUR.</p>
        <p>structures, and mergers, which set the late-time spin parameter.structures, and mergers, which set the late-time spin parameter.</p>
    </text>
</tei>
