<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-25T06:55+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>The signals emanating from complex systems are usually composed of a mixture of different oscillations which, for a reliable analysis, should be separated from each other and from the inevitable background of noise.</p>
        <p>Here we introduce an adaptive decomposition tool-nonlinear mode decomposition (NMD)-which decomposes a given signal into a set of physically meaningful oscillations for any wave form, simultaneously removing the noise. NMD is based on the powerful combination of time-frequency analysis techniques-which, together with the adaptive choice of their parameters, make it extremely noise robust-and surrogate data tests used to identify interdependent oscillations and to distinguish deterministic from random activity. We illustrate the application of NMD to both simulated and real signals and demonstrate its qualitative and quantitative superiority over other approaches, such as (ensemble) empirical mode decomposition, Karhunen-Loève expansion, and independent component analysis. We point out that NMD is likely to be applicable and useful in many different areas of research, such as geophysics, finance, and the life sciences. The necessary 
            <rs type="software">MATLAB</rs>
            <rs type="software">codes</rs> for running 
            <rs type="software">NMD</rs> are freely available for download.
        </p>
        <p>Complex systems in real life are commonly studied by analysis of the signals that they generate. Such signals typically include many different superimposed oscillations, giving rise to complicated wave forms, and these oscillations are often characterized by time-varying amplitudes and frequencies. These oscillations, which are also referred to as modes, contain a great deal of valuable information about the originating system. Their properties can be used, e.g., to predict earthquakes from geophysical signals [1] or to assess health from signals generated by the human body [2,3]. However, to gain access to all of the properties of a particular mode, it should be first extracted from the signal. For a reliable analysis, therefore, one should decompose the signal, i.e., recover the individual oscillations that are present in it, separating them both from each other and from the inevitable background of noise.</p>
        <p>How best to accomplish this decomposition is a problem of long standing, and many different approaches have been proposed. However, to the best of the authors' knowledge, each of the current methods has at least two of the following flaws.</p>
        <p>(1) The method contains user-defined parameters and is quite sensitive to their choice. These parameters cannot be adaptively chosen and there are no more-or-less universal settings.</p>
        <p>(2) The method is not noise robust.</p>
        <p>(3) If an individual mode has a complex (nonsinusoidal) wave form, the method will decompose it into a few oscillations with simpler wave forms.</p>
        <p>(4) The modes returned by the method are not always physically meaningful. For example, the method will decompose even a random signal, such as Brownian noise, onto a set of oscillations.</p>
        <p>To the best of the authors' knowledge, issue (4) has not been addressed previously, so that this drawback is common to all current methods (and thus will not be mentioned again in what follows). Next, the popular empirical mode decomposition (EMD) [4] method suffers additionally from disadvantage (2) [5], as well as from (3) (with the latter manifesting itself only in cases where the corresponding oscillation has a wave form with multiple peaks, as can easily be verified numerically).</p>
        <p>To reduce the sensitivity of EMD to noise, Wu and Huang [5] recently proposed a variant called ensemble empirical mode decomposition (EEMD). The idea is to add independent realizations of white Gaussian noise to the signal and apply EMD each time, with the final modes being obtained as the ensemble averages of the modes for each noise realization. Even so, however, EEMD still cannot be regarded as noise-robust method (at least in comparison with other approaches), as seen in the examples below. Additionally, it contains a nonadaptive parameter [drawback (1)] controlling the standard deviation of the added noise, though its choice does not seem to exert a strong influence on the results [5].</p>
        <p>For multivariate time series the most widely used decomposition methods are principal component analysis (PCA) [6,7] and independent component analysis (ICA) [8,9]. In the present work, however, we restrict our consideration to univariate signals, i.e., those represented by a single time series. To apply PCA and ICA in this case, one should first construct a multivariate signal from the original (univariate) one, which can be accomplished by using its time-shifted blocks. PCA and ICA can then be applied to this collection of original signal parts, in which case they are called single-channel PCA (also known as Karhunen-Loève expansion) and single-channel ICA [10], respectively. However, both of these methods are generally susceptible to the time shifts and the number of blocks used to create the multivariate signal from the original one (as was demonstrated, e.g., in [11] for the Karhunen-Loève expansion), thus suffering from the drawback (1).</p>
        <p>Another approach, which is now becoming increasingly popular, is to use a particular time-frequency representation (TFR) [12][13][14][15][16][17] of the signal, e.g., the wavelet transform, for decomposing it into separate modes. Qualitatively, the signal is first mapped onto the time-frequency plane, where its oscillatory components appear in the form of "curves," formed by the sequences of amplitude peaks. Having identified these curves, one can then recover the corresponding oscillations, thereby decomposing the signal. Many different techniques for realizing this idea have been proposed [18][19][20][21][22][23], with the great advantage of such approaches being their high noise robustness [12,24]. However, any TFR-based decomposition also suffers from drawback (3), because oscillation with a nonsinusoidal wave form is typically represented by a number of curves in the time-frequency plane [25].</p>
        <p>The flaws mentioned greatly restrict the applicability of the approaches currently in use, so that only for a very small class of signals can the decomposition be carried out successfully. To overcome these limitations, we now introduce nonlinear [26] mode decomposition (NMD). It is based on the powerful combination of the time-frequency analysis techniques reviewed and developed in [12,19], surrogate data tests [27][28][29][30], and the idea of harmonic identification [25]. NMD has proven to be extremely noise robust, and it returns only the physically meaningful oscillations with any wave forms, at the same time removing the noise. Furthermore, we develop a set of criteria in which almost all NMD settings can be adapted automatically to the signal, greatly improving its performance and making it a kind of superadaptive approach. The application of NMD and its advantages over the other existing approaches are demonstrated on both simulated and real data.</p>
        <p>The structure of the work is as follows. In Sec. II we summarize the notation used and review the necessary background. The basic idea of the NMD and its implementation are considered in Sec. III. In Sec. IV we introduce some important upgrades to improve the NMD performance, while the choice of its parameters is considered in Sec. V. We demonstrate the power of the method by applying it to simulated signals in Sec. VI and to real signals in Sec. VII. We mention some other contexts where NMD can prove useful in Sec. VIII. The work is concluded in Sec. IX and the full NMD procedure is summarized in the Appendix.</p>
        <p>Given some function f (t), we denote its Fourier transform, positive frequency part, time average, and standard deviation as f (ξ ), f + (t), f (t) , and std[f (t)], respectively,</p>
        <p>where T denotes the overall time duration of f (t) (in theory, T → ∞).</p>
        <p>Next, the amplitude and/or frequency modulated component (in short AM and/or FM component, or simply component) is defined as the function of time t having the form x(t) = A(t) cos φ(t), [A(t) &gt; 0, ν(t) = φ (t) &gt; 0 ∀ t], (2) where A(t), φ(t), and ν(t) are respectively the instantaneous amplitude, phase, and frequency of the component. We restrict the consideration to components satisfying the analytic approximation [A(t) cos φ(t)] + ≈ 1 2 A(t)e iφ (t) (3) because, otherwise, the amplitude and phase are not uniquely defined and cannot, in principle, be recovered reliably by time-frequency analysis methods [12]. For a more detailed discussion of the definitions of A(t),φ(t),ν(t) and of some related issues, see, e.g., [31][32][33].</p>
        <p>In real cases, a signal usually contains many components of the form (2). Moreover, some of them typically do not correspond to an independent activity, but arise due to a complex wave form of a particular mode to which they are related (see below). This is because real oscillations are rarely purely sinusoidal, but have more complicated shapes as the result of nonlinearities in the generating system and/or the measurement apparatus. For example, the AM and FM component (2) raised to the third power [A(t) cos φ(t)] 3 = 3 4 A 3 (t)[cos φ(t) + 3 cos 3φ(t)] consists already of two components, although there is obviously only one meaningful oscillation.</p>
        <p>It is therefore better to consider the full nonlinear modes, defined as the sum of all components corresponding to the same activity,</p>
        <p>where v[φ(t)] = v[φ(t) + 2π ] is some periodic function of phase (also called the "wave-shape function" [34]), which, due to its periodicity, can always be expanded in the Fourier series (4). Without loss of generality, we fix the normalization of A(t) and φ(t) in (4) by setting a 1 = 1, ϕ 1 = 0. Then the instantaneous phase and frequency of the whole nonlinear mode (NM) are φ(t) and ν(t) = φ (t), respectively [34]. In what follows, the components composing the NM are referred to as harmonics, with the hth harmonic being represented by a term ∼ a h cos[hφ(t) + ϕ h ] in (4). We assume that the signal is composed of the NMs c i (t) of form (4) plus some noise η(t) (the class of noise is considered later, in Sec. III E):</p>
        <p>(</p>
        <p>Our ultimate goal is then to extract all the NMs present in the signal and to find their characteristics, such as their amplitudes A(t), phases φ(t), and frequencies ν(t), as well as the amplitude scaling factors a h and phase shifts ϕ h of the harmonics. It is important to note that the representation ( 5) is not unique (e.g., any harmonic of the NM can always be represented as a separate mode), but, among all possible choices, one wants to find the sparsest decomposition, i.e., the one characterized by the smallest number of modes subject to the constraints on the amplitude and frequency modulation of the components (2) and the resolution restrictions of the time-frequency methods (see below).</p>
        <p>The TFR of the signal is constructed by projecting it onto the time-frequency plane, which allows us to visualize and follow the evolution of the signal's spectral content in time. Depending on how the projection is constructed, there are many different types of TFRs. In our case, however, we need those from which the components present in the signal can be extracted and reconstructed in a straightforward way. TFRs meeting this criterion are the windowed Fourier transform (WFT) G s (ω,t) and the wavelet transform (WT) W s (ω,t). All aspects of their use in practice, and our implementation of them, are discussed in [12] (see also the classical reviews and books [13][14][15][16][17]), to which we refer the reader for detail; here we just review briefly the minimal necessary background.</p>
        <p>Given a real signal s(t), its WFT and WT are constructed as</p>
        <p>where g(t) and ψ(t) are respectively the chosen window and wavelet functions, with the latter satisfying the admissibility condition ψ(0) = 0; the ω ψ = argmax | ψ(ξ )| denotes wavelet peak frequency, while for the WFT we assume ĝ(ξ ) to be centered around its peak:</p>
        <p>We choose a Gaussian window for the WFT and a log-normal wavelet for the WT,</p>
        <p>where f 0 is the resolution parameter determining the trade-off between time and frequency resolution of the resultant transform (by default we are using f 0 = 1). The forms (7) appear to be the most useful ones in terms of the joint time-frequency resolution and the reconstruction of components [12]. All of the considerations that follow, however, are applicable for any ĝ(ξ ) and ψ(ξ &gt; 0), which are real, positive, and unimodal around the single peak.</p>
        <p>Note that the appropriate choice of window or wavelet function, which for the parametrization (7) is equivalent to the choice of f 0 , is of paramount importance for time-frequency analysis based on the WFT/WT and therefore for any method that utilizes it. Thus, the window or wavelet should be well matched to the signal properties. The resultant representation is then able to resolve separate components and at the same time represent well their amplitude and frequency modulations. This is thoroughly discussed in [12] (see also Sec. V A).</p>
        <p>The difference between the WFT and WT lies in the way they resolve the components present in the signal. The WFT has linear frequency resolution, i.e., distinguishes components on the basis of their frequency differences, whereas the WT has logarithmic frequency resolution, distinguishing components on the basis of ratios (or the differences between the logarithms) of their frequencies. As a result, the time resolution of the WT increases with frequency, so that the time variability of the higher frequency components is represented better than that for the components of lower frequency, while the time resolution of the WFT is the same at all frequencies.</p>
        <p>In theory, the WFT and WT (6) depend on continuous ω, but in practice they are calculated at particular discrete ω k . The latter can be chosen as ω k = (kk 0 ) ω for the WFT and ln ω k = (kk 0 ) ln 2 n v for the WT, reflecting the linear and logarithmic frequency resolution of the corresponding TFRs; the discretization parameters ω and n v can be selected using the criteria established in [12]. Due to the finite time length of real signals, all TFRs suffer from boundary distortions and, to reduce them, we use the predictive padding also suggested in [12].</p>
        <p>The main goal of NMD is to decompose a given signal into a set of nonlinear modes (4). To do this, four steps are necessary:</p>
        <p>(a) extract the fundamental harmonic of an NM accurately from the signal's TFR;</p>
        <p>(b) find candidates for all its possible harmonics, based on its properties;</p>
        <p>(c) identify the true harmonics (i.e., corresponding to the same NM) among them;</p>
        <p>(d) subtract the resultant NM (obtained by summing together all the true harmonics) from the signal and iterate the procedure on the residual until a preset stopping criterion is met.</p>
        <p>These individual subprocedures are explained in detail in the sections below, while the full NMD algorithm, including various improvements and related issues, is summarized in the Appendix.</p>
        <p>Note that NMD can be based either on the WFT or on the WT, although in what follows (Sec. V B) we combine them to make the procedure more adaptive. Nevertheless, for the time being we assume that we have selected one of these TFR types and that we will use it for all operations.</p>
        <p>Provided that the TFR has sufficient resolution in time and frequency to resolve components that are close in frequency and, at the same time, to portray reliably their amplitude and frequency modulations, each component is represented by a unique sequence of TFR amplitude peaks (also called ridge points). We call such a sequence a ridge curve and denote it as ω p (t); an illustrative example showing the WFT and WT of a signal and the ridge curves of its components is presented in Fig. 1. Note that oscillations with a nonsinusoidal wave form ; the third oscillation is represented by two curves because of its complex wave form, while the apparent distortions in the ridge frequency profiles are due to noise; note also the logarithmic frequency scale for the WT, which is natural for it. The signal was sampled at 100 Hz for 100 s.</p>
        <p>appear as two or more components in a TFR, consisting of the fundamental and its harmonics.</p>
        <p>To extract a particular component from the TFR, one needs first to find its ridge curve. This is a nontrivial task, because in real cases it is not always clear which sequence of peaks corresponds to which component and which peaks are just noise-induced artifacts. The procedures for ridge curve extraction are discussed and developed in [19]. By default we use here scheme II(1,1) from the latter, as it appears to be very universal in applicability. In short, in the case of WFT we select the ridge curve ω p (t) as being that sequence of peaks (among all those that are possible) which maximizes the path functional</p>
        <p>where</p>
        <p>denote the median and 50% range, respectively. In the case of the WT, one uses the same functional (8), except that now all is taken on a logarithmic frequency scale (ω p → ln ω p , ω p → ln ω p ). The approximate optimal ω p (t) in terms of (8) can be found in O(N ln N ) steps as described in [19].</p>
        <p>Having found the ridge curve ω p (t), the amplitude A(t), phase φ(t), and frequency ν(t) ≡ φ (t) of the corresponding component x(t) = A(t) cos φ(t) can be reconstructed by either of two methods, ridge and direct [12]. The ridge method utilizes only the TFR values at the peak, and the corresponding formulas read ridge[WFT]:</p>
        <p>where δν d (t) and δ ln ν d (t) are the corrections for discretization effects which can be found, e.g., by parabolic interpolation. Another way is to reconstruct the component from the full time-frequency region into which it is mapped for a given TFR. We call this region the time-frequency support [ω -(t),ω + (t)] and estimate it as the widest region of unimodal and nonzero TFR amplitude around the ridge point ω p (t) at each time [12]. Based on estimated ω ± (t), the parameters of the component can be reconstructed as direct [WFT], (1) p (t). At each time, starting from the expected ridge frequency hω (1) p (t) of the harmonic (blue diamonds), one climbs (i.e., follows in the direction of TFR amplitude increase) to the nearest peak, which is then assigned to ω (h) p (t) (red circles).</p>
        <p>[ω g = 0 for symmetric ĝ(ξ ), e.g., Gaussian window]; (10) direct[WT]:</p>
        <p>The difference and relative performance of the two reconstruction methods were studied in [12]. In brief, the direct method better recovers the time variations of the component's amplitude and frequency but is less robust to noise and interferences than the ridge method. Assume for now that we reconstruct everything by a particular method, e.g., ridge; its adaptive choice is discussed in Sec. V.</p>
        <p>The component extracted in the previous step will generally represent a harmonic of some NM. For simplicity, however, in this and the next section we assume that it corresponds to a fundamental, i.e., the first, harmonic (we get rid of this assumption in Sec. III D). Then, given the component's ridge frequency ω (1) p (t), its hth harmonic is expected to lie near hω (1) p (t). Therefore, the ridge curve ω (h) p (t) corresponding to the hth harmonic can be extracted simply as the sequence of peaks which are located in the same time-frequency support (region of unimodal TFR amplitude at each time) as hω (1) p (t); or, in other words, the sequence of peaks nearest to hω (1) p (t) in the direction of TFR amplitude increase. This is illustrated in Fig. 2. Having found ω (h) p (t), the parameters of the harmonic A (h) (t),φ (h) (t),ν (h) (t) can be reconstructed as discussed in the previous section.</p>
        <p>In general, the procedure of the previous section yields what is not necessarily a genuine harmonic, but just a candidate for one. Thus, even if the NM does not contain a particular harmonic, one will still obtain some signal for it, consisting of noise or components lying near the frequency of the putative harmonic. Hence, having extracted the hth harmonic candidate, we must next determine whether it is a true harmonic or not. To tackle this problem, we use the method of surrogate data [27,28], testing against the null hypothesis of independence between the first harmonic and the extracted harmonic candidate. Thus, we first select a measure to quantify the degree of dependence between the dynamics of two harmonics, and we then calculate it for the original harmonic and for a collection of surrogates, a specially constructed time series consistent with the null hypothesis being tested. If the original value of the selected measure lies outside the distribution of its surrogate values, this indicates genuine interdependence and the harmonic is regarded as true; otherwise, it is discarded as false.</p>
        <p>The amplitude, phase, and frequency dynamics of a true harmonic should depend on those for the first harmonic (fundamental) as A (h) (t)/A (1) (t) ≡ a h = const, φ (h) (t)hφ (1) (1) (t). One can introduce measures q (h) A,φ,ν ∈ [0,1] quantifying the degree of consistency with these laws (0, no consistency; 1, full consistency), i.e., the dependence of the parameters of the hth harmonic on the corresponding parameters of the first one:</p>
        <p>The overall measure of interdependence between the harmonics can then be taken as</p>
        <p>with the parameters w A,φ,ν giving weights to each of the consistencies q (h) A,φ,ν . By default, we use ρ (h) ≡ ρ (h) (1,1,0), giving equal weights to the amplitude and phase consistencies and no weight to the frequency consistency. The latter is because the procedure of harmonic extraction (see Sec. III B), being based on the instantaneous frequency of the first harmonic, in itself introduces a dependence of ν (h) (t) on ν (1) (t), so it is better not to base any conclusions on it.</p>
        <p>Ideally, for true harmonics one should have q (h) A,φ,ν = 1, but noise and interference with the other components introduce errors, making the consistencies smaller than unity. Hence, one cannot identify harmonics based only on the value of ρ (h) but also needs to use the surrogate test. We employ the idea of time-shifted surrogates [29,30], using as a first harmonic surrogate its time-shifted version and as the other harmonic surrogate the corresponding candidate harmonic extracted from the time-shifted TFR. Such time delay destroys any temporal correlations between the signals while preserving all other their properties, thus creating surrogates consistent with the null hypothesis of independence.</p>
        <p>Given the maximal time-shift (in samples) M, the surrogate parameters for the first harmonic are taken as shifted backwards by T d /2, A (1) d (τ ) = A (1) (τ -T d /2), φ (1) d (τ ) = φ (1) (τ -T d /2), ν (1)</p>
        <p>where f s is the signal sampling frequency and N is its total length in samples (note that the length of the surrogate time series is smaller than the original ones, being N -M). Using ν (1) d (τ ) (13) as a reference profile, the surrogate hth harmonic and its parameters A (h) d (τ ),φ (h) d (τ ),ν (h) d (τ ) are extracted in the same way as described in Sec. III B, but from the signal's TFR shifted on T d /2 forward in time [G(ω,τ + T d /2) or W (ω,τ + T d /2)]. The procedure can greatly be accelerated by initial preprocessing of the TFR, constructing its "skeleton" [12] at the beginning and utilizing it for each surrogate.</p>
        <p>Summarizing, we calculate the amplitude-phase consistencies ρ (h) d=1,...,N d (1,1,0) (12) for the surrogate parameters (13) and compare them with the value ρ (h) 0 (1,1,0) calculated in the same way but for the zero time shift T 0 = 0. The probability measure (although mathematically not the true probability) that the extracted hth harmonic curve is a true harmonic of the main one is then quantified by the significance of the surrogate test, i.e., by the relative part of surrogates for which ρ (h) d &lt; ρ (h) 0 . For example, if we found 1000 surrogate amplitude-phase consistencies ρ (h) d=1,...,1000 and 792 of them are smaller than the original value ρ (h) 0 , then the rough probability that the extracted curve represents a true harmonic is 79.2%. We regard a harmonic as true if the probability calculated in this way is 95%. By default we use N d = 100 surrogates and a maximum time shift that equals a quarter length of the signal M = N/4, so that the surrogates are of N -M = 3N/4 length each.</p>
        <p>Note that the significance of the surrogate test does not depend on the magnitude of ρ (h) (12). Thus, there might be an independent component located at the frequency of a possible harmonic, so that the amplitude-phase consistency would be high but, because it does not fully adjust its amplitude and phase to that of the fundamental harmonic, the surrogate test will not reject the null hypothesis of independence (e.g., see below, Table I). Thus, the possibility of picking up a spurious component that is nearby in frequency is largely eliminated.</p>
        <p>It should be noted that, since we test many harmonic candidates, it is natural to expect that sometimes we will encounter false positives, i.e., the surrogate test will regard as true a harmonic which is actually false. Thus, for some noise realizations the parameters of the TFR around the expected harmonic frequency might indeed appear to be correlated with the parameters of the fundamental harmonic. However, in such cases the extracted harmonic candidate will usually have quite small amplitude-phase consistency ρ (h) (12). To reduce the probability of false positives, therefore, we introduce some threshold ρ min and regard the harmonic as true only if it both passes the surrogate test and at the same time is characterized by ρ (h) ρ min . Empirically, we set this threshold as</p>
        <p>where w A ,w φ are the weightings used in ( 12) (as mentioned, we use w A = w φ = 1); the value ( 14) was found to be quite universal and to work well in most cases. Note that for a true harmonic one can also have ρ (h) &lt; ρ min , but this will usually mean that it is badly damaged by noise or other influences and cannot be recovered without large errors.</p>
        <p>Extracting in order. To improve the accuracy of reconstruction, each harmonic which is identified as true should be subtracted from the signal before extracting and testing the next one. This decreases the errors related to interference between the harmonics and makes all procedures more accurate. The same consideration applies to the first harmonic which, after being found by the methods described in Sec. III A, should be subtracted from the signal before extraction of any of the other harmonics.</p>
        <p>How many harmonics to extract? Clearly, the maximum number of harmonics one can extract, in principle, is h max = (f s /2)/ ν (1) (t)/2π , where f s is the sampling frequency of the signal (so that f s /2 is the maximally achievable, Nyquist frequency) and ν (1) (t) denotes the extracted instantaneous frequency of the first harmonic. However, checking all harmonics might be computationally very expensive and is often not needed. In practice, it is better to stop the search after some chosen number of sequential harmonics has been identified as false, making it likely that there are no more true harmonics. We choose this number to be S = 3 by default.</p>
        <p>What if the extracted component is not the first harmonic? Although intuitively the first harmonic should have the highest amplitude (and will therefore be extracted as the dominant curve), for some complicated wave forms (e.g., with sharp peaks) this might be untrue. Therefore, before starting extraction of the harmonics, one should first ensure that one is starting with the first harmonic and, if not, then find it and switch to it. To do this, we apply the same procedure described for harmonic extraction and identification, but in the reverse direction, i.e., using h = 1/2,1/3,1/4, . . .. Then if some of these are identified as true, we switch to the one with the TABLE I. Summary of the results of NMD applied to the signal shown in Fig. 9. For each NM the significance of the surrogate test against noise (see Sec. III E) was based on 100 surrogates. The columns left to right provide information for the hth harmonic: the value of the consistency ρ (h) (1,1,0) (12); the significance of the test against independence (see Sec. III C); the method chosen for reconstruction of the harmonic (see Sec. V C); the resolution parameter f (h) 0 adapted for the harmonic considered (see Sec. IV A); the true amplitude ratio a h ≡ A (h) (t)/A (1) (t); the extracted amplitude ratio; the true phase shift ϕ h ≡ φ (h) (t)hφ (1) (t); the extracted phase shift. Harmonic was identified as true if both ρ (h) ρ min = 0.25 (14) and the significance level is 95%, with the corresponding rows being shaded with gray. The numbers of real harmonics are in bold type, and it can be seen that only they were identified as being true. For simplicity, the results for h = 1/n harmonics (which are tested to check whether the extracted component is the first harmonic) are not shown; in each case all three consecutive h = 1/2,1/3,1/4 harmonics were identified as false. smallest frequency and start from there. The minimal h one can go for can be set as h min = (1/T )/ ν (1) (t)/2π , although the statistics will be bad already for h &lt; 5h min , when the related oscillation has less than five cycles over the whole signal time duration [12]. Nevertheless, it is better to stop after S 0 = 3 consecutive 1/n harmonics have been identified as false, in the same manner as is done for the usual harmonics.</p>
        <p>Once all harmonics are identified and reconstructed, they are summed up into the NM, which is then subtracted from the signal and the procedure is repeated on the residual. The natural question arises, therefore, of how many NMs to extract, i.e., when to stop the decomposition. Obviously, decomposition of any noise, e.g., white, Brownian, any other correlated or not, does not make much sense, so the reasonable goal is to extract all oscillatory components present in the signal and leave the noise and trends as the residual. Therefore, after extraction of each NM one needs to decide whether what is left contains any more meaningful oscillations, in which case one continues the decomposition, or whether it just represents noise, in which case one should stop. The problem is thus reduced to distinguishing deterministic from random dynamics.</p>
        <p>To solve it, one can use the surrogate test against the null hypothesis of linear noise [27,28], which includes white and colored noises (e.g., Brownian). The surrogates for this task, called Fourier transform (FT) surrogates, are constructed by taking the inverse FT of the signal's FT with randomized phases of the Fourier coefficients: s s (t) = (2π ) -1 [ŝ(ξ )e iϕ s (ξ ) ]e iξ t dξ , where ϕ s (ξ ) = -ϕ s (-ξ ) denote the phases taken at random uniformly on [0,2π ] for each frequency ξ &gt; 0. The reason for this is that any linear noise [an AutoRegressive Moving Average or ARMA process</p>
        <p>, where η W (t n ) denotes Gaussian white noise of unit variance] is characterized only by the amplitudes of the Fourier coefficients. Randomization of the Fourier phases preserves the power spectrum, so that the surrogate time series will represent another realization of the same random process if the original time series is noise, thus being consistent with the tested null hypothesis. On the other hand, if some meaningful NMs are present in the signal, the randomization of the phases will destroy the particular phase relationships responsible for the amplitude and frequency modulations, making their behavior less deterministic [35].</p>
        <p>One now needs to select the discriminating statistics, which is calculated for the original signal and the surrogates, so that the null hypothesis of linear noise is accepted if the original value lies within the surrogate values and rejected otherwise. The commonly used statistics involve one of the generalized Renyi dimensions [37][38][39], with the correlation dimension calculated by Grassberger-Procaccia approach [40][41][42] remaining the most popular choice. However, we find that the surrogate test based on such measures is extremely sensitive to noise, prohibiting their use in the NMD which is intended to be noise robust.</p>
        <p>Therefore, we need to devise another discriminating statistics. There are virtually no restrictions on its choice [43], so that almost any measure can be used. The only question to be asked is how powerful it is, i.e., how good in distinguishing the deterministic dynamics from noise. Given that NMD is based on the WFT/WT, it seems reasonable to select statistics based on the properties of the TFR obtained. Namely, since at the first step of the NMD process we extract the component from the signal's TFR (see Sec. III A), we can base our statistics on the properties of the components extracted (in the same way) from the original signal and from its FT surrogates. Thus, if the original component is true (and not just formed from noise peaks picked in the time-frequency plane), then it is expected to have more deterministic amplitude and frequency modulation than the surrogate components, which should be more stochastic; otherwise, there will be no difference.</p>
        <p>The degree of order in the extracted amplitude A(t) or frequency ν(t) can be quantified by their spectral entropies</p>
        <p>, so that the discriminating statistics D for the surrogate test can be taken as their combination,</p>
        <p>Note that, in practice, due to the finite sampling frequency f s and sample length N of real signals, the integrals over frequency 15) are discretized into sums over the discrete FT frequencies</p>
        <p>In the present context, we have found the statistics D(α A ,α ν ) (15) to be more meaningful and much more powerful than other choices (e.g., the popular correlation dimension [40][41][42]). This statistics is directly related to the quality of the representation of component in the signal's TFR, so that the significance of the surrogate test based on it reflects the proportion of the "deterministic" part in the extracted amplitude and frequency dynamics. Thus, if the residual does not pass the surrogate test (null hypothesis is not rejected), this might mean either that the residual is indeed noise, or that the component simply cannot be reliably extracted from the TFR (e.g., because resolution characteristics of the TFR are not appropriate to reliably represent the related amplitude and frequency modulations and/or to segregate the component from noise).</p>
        <p>The power of D(α A ,α ν ), i.e., its ability to distinguish deterministic from random dynamics, depends strongly on the complexity of the component's amplitude and frequency modulations: The lower the original spectral entropies Q[ Â(ξ )],Q[ν(ξ )] are, the more powerful is the test. However, even in the (quite unrealistic) case when the signal contains a meaningful component without any amplitude or frequency modulation, i.e., a pure tone A cos νt, due to numerical issues [44,45] the surrogate test will still be quite powerful in rejecting the null hypothesis (unless this tone has an integer number of cycles over the time-length of the signal). The power of the test is also inversely proportional to the spread of Â(ξ ),ν(ξ ): The more concentrated they are, the narrower is the frequency band that the component A(t) cos φ(t) occupies, so that the less is the noise power that is contained in it.</p>
        <p>As to the choice of α A ,α ν in (15), we have found that the powers of D(1,0) = Q[ Â(ξ )] and D(0,1) = Q[ν(ξ )] are often inversely proportional to the strengths of the amplitude and frequency modulation, respectively. Thus, D(1,0) is preferable for components with relatively small amplitude variability and considerable frequency variability, while D(0,1) is better otherwise. Although the procedure is not fully rigorous mathematically, we therefore perform three tests, using D(1,0), D(0,1), and D(1,1), and then select the significance as the maximum among them. It remains to be established, however, whether some better statistics not having the drawback mentioned can be found.</p>
        <p>Summarizing, we extract the components from the TFR of the original signal and compute the corresponding D 0 (α A ,α ν ) (15); then we create N s FT surrogates of the signal, for each of them calculate the corresponding TFR, extract the component from it, and compute the respective D s=1,...,N s (α A ,α ν ). We use N s = 40 surrogates and set the significance level to 95%, rejecting the tested null hypothesis of noise if the number of surrogates with D s &gt; D 0 is equal or higher than 0.95 × 40 = 38. The test is performed for three different (α A ,α ν ) in (15), using D(1,1), D(0,1), and D(1,0) as a discriminating statistic; if at least for one of them the null hypothesis is rejected, we regard the signal as not noise and continue the decomposition.</p>
        <p>Note that, at the very start of each NMD iteration, the signal should be detrended, which we do by subtracting a third order polynomial fit from it. This is especially important for the surrogate test, as trends might greatly affect its performance, In particular, the FT surrogates should be constructed using an already detrended signal as a base, because otherwise one might end up with testing the trend against noise rather than the oscillatory component of interest. Additionally, to guarantee that the boundary distortions are of the same nature in the original TFR and those for the surrogates, it is recommended to use padding with zeros [12]; the original D 0 should thus be recalculated using parameters of the component extracted from the TFR of the zero-padded signal. This issue, however, concerns only the surrogate test, while in all other cases we use the more accurate (but at the same time more computationally expensive) predictive padding [12].</p>
        <p>The NMD as described in the previous section already represents a very powerful decomposition tool. However, it may be made even better with the help of the upgrades outlined below, although at the expense of greatly increased computational cost for some of them [though it still remains O(N ln N )].</p>
        <p>Even if the first harmonic of some NM is well represented in the TFR and can be accurately extracted and reconstructed, it does not mean that the same applies to all the other harmonics, too. For example, harmonics of an NM with only amplitude modulation require the same time and frequency resolution, so that the WFT can represent them all well, while for the WT, where time and frequency resolution scale with frequency, one will need to adjust the resolution parameter f 0 for each harmonic. Thus, consider an NM with simple sinusoidal amplitude modulation:</p>
        <p>Clearly, all harmonics have the same amplitude variability (in relative terms), so that the TFR time resolution should also be the same for them. This is reflected in the fact that each harmonic x (h) (t) is composed of three Fourier terms, which all have identical amplitude ratios, frequency differences, and phase relationships for each h. Furthermore, the frequency distance between two consecutive harmonics remains the same, meaning that the frequency resolution also should not be changed for harmonics. Therefore, the WFT, having constant time and frequency resolution, will be a perfect match for this case. This means, first, that if the amplitude modulation of the first harmonic is represented reliably in the WFT, then the same will also apply to all other harmonics and, second, that if two first harmonics do not interfere in the WFT, then any two harmonics will also be well-separated. For the WT, the former is also true, as the time resolution, i.e., the ability to reflect changes in time, increases with frequency for this type of TFR. However, the frequency resolution of the WT progressively worsens with the increase of frequency, so that the higher are the harmonics, the harder it is to resolve them. This is illustrated in Fig. 3, where from panels (b) and (c) it is clear that all harmonics can be well represented in the WFT, but for the WT higher harmonics begin to interfere. This issue is explained schematically in Figs. 3(d) and 3(e). Thus, both the WFT and the WT can be seen as convolutions in the frequency domain of the signal with a window ĝ(ωξ ) and wavelet ψ * (ω ψ ξ/ω), as seen from ( 6). Figures 3(d) and 3(e) show the signal's discrete FT ŝ(ξ ) together with the (rescaled and centered at the mean frequencies of the harmonics ω/2π = 1, 2, 5, 6 Hz) window and wavelet FTs ĝ(ωξ ) and ψ * (ω ψ ξ/ω) (7), with which ŝ(ξ ) is convoluted while constructing the WFT and WT, respectively.</p>
        <p>Roughly speaking, the quality of the representation of time variability (the amplitude modulation in the present case) for each harmonic can be estimated based from the proportion of the corresponding Fourier coefficients lying below the shown window or wavelet FTs. For both the WFT and the WT, each harmonic has three Fourier coefficients (16), all of which lie in the correspondingly shaded areas, meaning that the time resolution in each case is sufficient to represent amplitude modulation appropriately. The degree of interference between the harmonics in the WFT and WT can be estimated from the area of overlap between the corresponding window/wavelet FTs. For the WFT [Fig. 3(d)] the interference between harmonics does not depend on their frequency, while for the WT [Fig. 3(e)] it increases for the higher harmonics, which results in the fifth and sixth harmonics being represented as a single component [Fig. 3(c)]. This is because the minimal frequency difference between two harmonics is equal to the frequency of the first harmonic, thus being defined on a linear scale (which is natural for the WFT), but not on a logarithmic one (natural for the WT).</p>
        <p>The situation changes when there is frequency modulation. In this case neither the WFT nor the WT provide optimal representation of the harmonics; in addition, some harmonics cannot, in principle, be reliably resolved with time-frequency analysis methods. Thus, consider an NM with simple sinusoidal frequency modulation,</p>
        <p>where we have used the formula e ia sin φ = ∞ n=-∞ J n (a)e inφ , with J n (a) = (-1) n J -n (a) denoting a Bessel function of the first kind. Since after some |n| all terms in (17) become negligible, one can, in practice, restrict the summation to |n| n J (ha), with the maximum non-negligible order n J being determined as n J (a) :</p>
        <p>where p denote a chosen accuracy threshold. The value of n J (a) increases with a, being (for p = 0.001): n J (0 a 0.3) = 2, n J (0.3 a 0.65) = 3, n J (0.65 a 1.13) = 4, etc. As a result, the higher the harmonic, the larger the frequency range it occupies, i.e., the larger is the number of non-negligible terms in (17). Consequently, to reflect reliably the frequency modulation of the higher harmonics, one needs higher time resolution for them, a requirement that is satisfied by the WT, but not by the WFT. This issue is illustrated in Fig. 4, where it can be seen that the WT can represent reliably both the first and the third harmonics, while the WFT reflects appropriately only the first one. However, the increased time-resolution of the WT is provided at the expense of decreased frequency resolution, leading to stronger interference between harmonics, as seen from the previous case (Fig. 3). Figure 4 also shows that in some cases it might, in principle, be impossible to represent reliably two harmonics in the TFR. Thus, as can be seen from Figs. 4(d) and 4(e), the FTs x(h) (ξ ) of the sixth and seventh harmonics are "entangled;" i.e., the frequency regions in which they are contained overlap. Therefore, unless specifically designed for this case, any window or wavelet function which picks the Fourier coefficients of one harmonic will inevitably also pick those corresponding to the other one, too [46].</p>
        <p>Summarizing, for the general case where both amplitude and frequency modulation are present in the NM, accurate representation of higher harmonics requires higher time resolution, but the same frequency resolution. However, an increase in time resolution inevitably leads to a decrease of frequency resolution, so usually one needs to search for some compromise. Due to this, it is often the case that neither the WFT nor the WT with a constant resolution parameter f 0 in (7) can represent all harmonics reliably.</p>
        <p>To tackle this problem, one can adaptively adjust f 0 for each harmonic individually. Assuming that the extracted first harmonic is reconstructed well, the quality of the representation of the hth harmonic can be assessed through its consistency ρ (h) (12) with the first one. Therefore, the optimal resolution parameter for the hth harmonic, f (h) 0 , can be selected as that for which ρ (h) (12) achieves its maximum and at the same time the harmonic passes the surrogate test, i.e., is identified as a true harmonic.</p>
        <p>The remaining question is the region within which to search for f (h) 0 . To find it, we first need to understand in what frequency band [ω (h) fω (h) f /2,ω (h) f + ω (h) f /2] the hth harmonic FT x(h) (ξ ) is concentrated, given the frequency band of the first harmonic. We define ω (h) f and ω (h) f as</p>
        <p>where</p>
        <p>dt is the total energy of the harmonic and p denotes the chosen accuracy threshold [note that, as everywhere else, we assume that the analytic approximation (3) holds for x (h)</p>
        <p>Then it can be shown that, given ω (1) f , ω (1) f , the frequency range for the hth harmonic will be [ω (h) f -</p>
        <p>with</p>
        <p>It is clear from the preceding discussion that, for the simple AM mode (16), one has ω (h) f = hω (1) f , ω (h) f = ω (1) f . The same is true for any AM mode, as can be shown by representing the amplitude modulation through the Fourier series A(t) = n r n cos(ν n t + ϕ n ) and expanding each harmonic in the same way as in (16). For the FM mode (17), the expression (20) follows from the fact that, at least for small enough p (e.g., 0.001) in the definition (18), one has for most a, as can be confirmed numerically. Then, taking into account (21) in the expansion (17), one obtains (20). For the hth harmonic of the NM with a more complicated doublesinusoidal frequency modulation, one has</p>
        <p>Clearly, it can be viewed as a sum of components with singesinusoidal frequency modulation, but amplitudes AJ n (hr 1 ) and frequencies (hν + nν 1 ). The frequency range of each of these components, and the number of them with a non-negligible amplitudes, both scale with harmonic number h according to (20) and (21). Therefore, the frequency range of the whole x (h) (t) (22) satisfies (20). Since frequency modulation can always be expanded in a Fourier series, using the same trick as with (22), it can be shown by induction that (20) holds for any FM mode. The generalization to the case of any joint amplitude and frequency modulation is then straightforward.</p>
        <p>Based on (20) and the scaling properties of the WFT/WT, one can now determine the region within which the optimal resolution parameter f (h) 0 for the hth harmonic lies. Given that the first harmonic was extracted from the TFR calculated with resolution parameter f (1) 0 , and assuming that the corresponding time and frequency resolutions are appropriate for this first harmonic, one has WFT: f (h) 0 ∈ f (1) 0 /h,f (1) 0 ; WT: f (h) 0 ∈ f (1) 0 ,hf (1) 0</p>
        <p>The optimal f (h) 0 is searched for by first breaking the region (23) into N r values f (h) r=1,...,N r (we use N r = 10). For each of them, one calculates the TFR, extracts the harmonic from it (see Sec. III B), estimates the corresponding consistency ρ (h) r (12), and tests the harmonic for being true (see Sec. III C). Among the f (h) r for which the harmonic is identified as true, the one characterized by the highest ρ (h) r is selected. It is then used as the initial value for an iterative golden section search of the optimal f (h) 0 (with default accuracy being f = 0.01), maximizing the consistency ρ (h) (12).</p>
        <p>Note that (23) does not take into account the interference between harmonics and with the other components which might lie nearby in frequency, so that in some cases the upper bound on f (h) 0 might be higher than (23); the same consideration applies to the lower bound. Therefore, if near the minimum or maximum of the tested f (h) 0 the consistency ρ (h) is found to grow, we continue the search in that direction until the peak appears. We perform an identical procedure when we check whether the extracted component represents a first or a higher harmonic by extracting and testing its h = 1/2,1/3, . . . harmonic candidates (see Sec. III D). The formulas (20) and ( 23) remain valid in this case, but the upper and lower bounds for ω (h) f in (20) and f (h) 0 in (23) change places.</p>
        <p>Given the reconstructed amplitudes A (h) (t), phases φ (h) (t), and frequencies ν (h) (t) of all the true harmonics, the most straightforward way to reconstruct the full NM is just to add all A (h) cos φ (h) (t) together. However, in this way the NM picks up noise contributions from all harmonics, which can make it quite inaccurate.</p>
        <p>Fortunately, there is a more clever way to perform the reconstruction, also yielding more accurate parameters for the individual harmonics. Thus, one can utilize the theoretical amplitude, phase, and frequency relationships between the harmonics, i.e., A (h) = a h A (1) (t), φ (h)hφ (1) = ϕ h , and ν (h) (t) = hν (1) (t). Then, because the components with the higher amplitudes are expected to be less noise corrupted, one can refine the parameters of each harmonic by weighted averaging over the parameters of all harmonics:</p>
        <p>,</p>
        <p>and</p>
        <p>denotes rounding to the nearest integer, so that I [0.8] = 1, I [-0.6] = -1 (the corresponding term is needed to eliminate possible noise-induced phase slips, i.e., the rapid growth by 2π in the phase differences). Note also the multiplier min(1,h /h), appearing for phase and frequency refinement in (24). It is needed to account for the scaling of phase and frequency errors of lower harmonics when they are mapped to higher ones. Thus, if ν (1) (t) has an error ε(t), then hν (1) (t) will have error hε(t).</p>
        <p>The refinement (24) not only makes the reconstructed NM much more accurate, solving the problem of picking up the cumulative noise of all the harmonics, but also reduces the noise level in each harmonic separately. Thus, noiseinduced variations in the parameters of different harmonics are expected to be mutually independent, and so they average out being added together. As a result, the more harmonics are contained in the NM, the more accurately it can be reconstructed. While NMD is generally noise robust, due to being based on time-frequency methods for which only the spectral power of noise in the vicinity of components' frequencies matters, NM reconstruction by (24) raises this robustness to an extreme extent.</p>
        <p>To extract a particular harmonic candidate, one does not need to calculate the TFR over the whole frequency range, which would be computationally expensive. Rather, one can calculate it only in the range where the possible harmonic is expected to lie. As discussed previously, given the frequency range [ω (1) min ,ω (1) max ] ≡ [ω (1) cω (1) c ,ω (1) c + ω (1) c ], where the first harmonic is concentrated in TFR, it is clear from (20) that the appropriate frequency range for the hth harmonic will be characterized by ω (h) min , max = hω (1) c ∓ max(1,h) ω (1) c . The multiplier max(1,h) takes into account that h can be smaller than unity, since we use h = 1/2,1/3, . . . when checking whether the extracted component is first (or higher) harmonic (see Sec. III D); the frequency range should not be squeezed for h &lt; 1 because, e.g., for NM with only amplitude modulation all harmonics will have the same bandwidth (see Sec. IV A).</p>
        <p>Given the extracted time-frequency support of the first harmonic [ω -(t),ω + (t)], the required frequency range for it to be fully contained in the TFR can be estimated as [ω (1) min ,ω (1) max ] = [min ω -(t), max ω + (t)]. However, the maximum value of the ω + (t) might be excessively large (it is, in theory, infinite, e.g., if the signal is represented by a single tone); the same applies to minimum ω -(t). Therefore, for determination of the harmonic frequency range it is better to use a support [ ω-(t), ω+ (t)] that is narrower in frequency, determined as the maximum region where the TFR amplitude of the first harmonic is non-negligible. Mathematically, it can be defined as ω-(t) : Using (25), the frequency range for the hth harmonic can be estimated as ω (h) min , max = h ω (1) p (t) + max(1,h) ω (1) min , maxω (1) p (t) , ω (1) where perc p denotes the pth percentage largest value of the argument (with perc 0 and perc 1 corresponding to usual minimum and maximum, respectively). The 95% largest value of ω+ (t) instead of the overall maximum is taken in (26) to prevent selection of an excessively wide region, because, due to noise, ω+ (t) might sometimes be too large; the same applies to ω-(t). In the process of harmonic extraction for h &gt; 1 (h &lt; 1) it is also useful to restrict ω (h) min (ω (h) max ) to be higher than the 5% (smaller than the 95%) value of the instantaneous frequency of the last true harmonic being extracted.</p>
        <p>The range [ω (h) min ,ω (h) max ] can, however, be more compressed or stretched, depending on the window or wavelet resolution parameter f (h) 0 used for the analysis of the hth harmonic. The expression ( 26) is optimal only for WFT:</p>
        <p>Indeed, as discussed previously, if the FT of the first harmonic is contained in the band [ω (1) 1 ,ω (1) 2 ], the largest band where hth harmonic can be contained is the one within ω (h) 1,2 = h ω (1) 2 +ω (1)</p>
        <p>. However, the range [ω (h) min ,ω (h) max ] where harmonic lies in the TFR is larger due to the finite frequency resolution, being [ω (h) 1 -/f 0 ,ω (h) 2 + /f 0 ] for the WFT with a Gaussian window (7) and [ω (h) 1 e -/f 0 ,ω (h) 2 e /f 0 ] for the WT with a log-normal wavelet (7), where is a particular constant. As a result, for hf (h) 0 &gt; f (1) 0 min(1,h) (WFT) or f (h) 0 &gt; f (1) 0 min(1,h) (WT), the range (26) is too large; although one can, in principle, "squeeze" it in this case, due to noise, the appropriate squeezing cannot always be estimated well, so it is better to leave all as it is. On the other hand, for hf (h) 0 &lt; f (1) 0 min(1,h) (WFT), or f (h) 0 &lt; f (1) 0 min(1,h) (WT), one might need a wider range than (26), so it should be stretched. Therefore, if (27) is not the case, the values (26) should be updated as WFT:</p>
        <p>(28) WT:</p>
        <p>where ω (h) ≡ h ω (1) p (t) , and ω (h) min , max are the estimates given by (26). The expressions ( 26) and ( 28) together give the frequency range in which to calculate the WFT/WT [based on the window or wavelet (7) with the resolution parameter f (h) 0 ] for the hth harmonic.</p>
        <p>To reduce the computational cost of the surrogate test against noise, utilized for the stopping criterion (see Sec. III E), one can use the same trick as above, calculating TFRs for surrogates in the frequency range where the original component resides. After extracting the component from the original TFR, this range can be estimated by (26) with h = 1.</p>
        <p>There are different settings that can be used while applying NMD. However, many of the parameters are either set at wellestablished values, or can be chosen adaptively, thus removing the ambiguity and making NMD a kind of superadaptive method. The settings and their choice are discussed below.</p>
        <p>The resolution parameter f 0 of the window or wavelet (7) determines the time and frequency resolution of the WFT/WT; i.e., how fast time changes can be reflected and how close in frequency components can be resolved, respectively. Time and frequency resolutions are not independent, being inversely proportional to each other, and an increase of f 0 increases the frequency resolution but decreases the time resolution. This inability to locate the component precisely in both time and frequency is a general issue, which manifests itself in nearly every aspect of signal analysis and represents the timefrequency analog of the Heisenberg uncertainty principle in quantum mechanics [13,15,49,50].</p>
        <p>Although we have discussed how to choose f 0 for harmonics given the extracted component, it is still unclear how to choose it at the first step, when we extract the main component. Generally, one needs to select f 0 based on a compromise between better reflecting time variability and better resolving components in frequency, so the optimal choice depends on the characteristics of the components contained in the signal. Unfortunately, at present there does not seem to be any universal approach enabling one to choose f 0 appropriately for any given signal (see [12,13] for a discussion of this issue and the effects of different choices), so it remains the only important parameter of NMD that cannot be adaptively selected. Its choice, however, seems to be slightly more universal for the WT, as the latter adjusts its resolution in relation to the frequency band being studied; for it, one usually uses f 0 = 1, setting some standard limits on the allowable relative amplitude and frequency modulations of the components and the frequency distances between them.</p>
        <p>Nevertheless, the very possibility of adjusting the time and frequency resolution is a great advantage of TFR-based methods. For example, as discussed previously in Ref. [46], the (E)EMD has time and frequency resolution properties similar to WT but, in contrast to the latter, its resolutions are set around some implicit values and cannot be changed. The choice of f 0 therefore gives NMD more flexibility in comparison to methods not possessing such a parameter.</p>
        <p>The difference between the WFT and the WT lies in the type of frequency resolution, which is linear for the former and logarithmic for the latter. Thus, the ability of the WT to resolve components in frequency worsens with increasing frequency, while its ability to reflect time variations improves; in contrast, the WFT does not discriminate between components based on their characteristic frequencies. Preference for one type of TFR over the other therefore depends on the signal structure. The WT is especially suitable if the higher frequency components contained in the signal are more distant in frequency and have higher time variability than those at lower frequencies, which is the case for some types of signals; otherwise, the WFT is preferable.</p>
        <p>Without some a priori knowledge, it is hard to select adaptively (i.e., automatically) the most appropriate type, especially given the associated problems related to the choice of the resolution parameter, as discussed above. However, after one component has been extracted (even roughly), selection of the optimal resolution type can be made based on its properties. Thus, if the time variability of the component's parameters increases with frequency, then the WT is the most suitable, whereas otherwise one should prefer the WFT. Given the initially extracted component's amplitude A(t), phase φ(t), and frequency ν(t), an empirical condition for selecting the most appropriate TFR type can be stated as</p>
        <p>Thus, the values of V [∂ t A(t),ν(t)] and V [∂ t ν(t),ν(t)] quantify whether the amplitude and frequency modulation of the component become stronger with increasing frequency (V &lt; 1) or not (V &gt; 1). In the former case a reliable representation of the component requires higher time resolution for higher frequencies, so the WT is preferred, while for the latter case the WFT should be used. For example, for linear [ν(t) = ν 0 + at] and hyperbolic [ν(t) = exp(at)] chirps one has V [∂ t ν(t),ν(t)] = ∞ and V [∂ t ν(t),ν(t)] = 0, reflecting the well-known [13] fact that the WFT and WT are most appropriate for their representation, respectively. The derivatives ∂ t ν(t) and ∂ t A(t) in ( 29) can be estimated by numerical differentiation. However, when noise is present in A(t) and ν(t), it will be greatly amplified in such estimates, so they will be generally quite noisy. Consequently, instead of standard deviations std[x(t)] in (29), it is better to use 75 percentiles, i.e., the width of the range within which 75% of the values of x(t) are contained. Alternatively, one can reconstruct ∂ t ν(t) and ∂ t A(t) by deriving the direct reconstruction formulas for them as explained in [12].</p>
        <p>The remaining question is which TFR type to use for the preliminary signal exploration, i.e., extraction of the component's parameters to be used in (29). As was discussed, the answer depends on the signal structure, and there is no universal criterion. However, since the WT is usually faster to calculate (due to its logarithmic scale) and generally has a more universal choice of the resolution parameter, we use it. Additionally, the threshold for R in ( 29) is changed from 1 to 1.1 (with this value being established empirically); such a change is done to account for the artificial correlation between ν(t) and ∂ t ν(t),∂ t A(t) estimated from the WT, which appears as a result of the logarithmic frequency resolution of the latter.</p>
        <p>Summarizing, we calculate the WT of the signal and extract from it the component and its parameters. Then we utilize the criterion ( 29) and determine which is the best type of TFR to use in the given case. If this is the WT, we retain the component already extracted; otherwise, we calculate the WFT of the signal in the corresponding frequency range (26) and re-extract all the parameters from it. To preserve the time and frequency resolution properties for which the component was extracted from the WT (which we assume to be appropriate for it), the resolution parameter for the WFT f (W F T ) 0 should be adjusted accordingly. If the WFT and WT are calculated using a Gaussian window and log-normal wavelet (7), the rule is</p>
        <p>It follows from the fact that, for window and wavelet (7) and not too small f (W T ) 0 , the frequency resolution of the WT around ω = 2π (if "linearized") is similar to the frequency resolution of the WFT for the same resolution parameter [12]; taking into account the scaling nature of the WT, i.e., its frequency-dependent resolution, one then obtains (30). Since for all harmonics, by definition, one would have identical (29), the same type of frequency resolution (linear or logarithmic) is appropriate for all of them. Hence, for the extraction of harmonics we use the same TFR type as was selected for the original component.</p>
        <p>As mentioned in Sec. III A, one can use either of two alternative methods for reconstruction of the components from the WFT/WT: direct (10) or ridge (9). The differences and errors of each method were studied in detail in [12]. It was found that the ridge method is more noise robust, but that the direct method allows the time variability in the component's parameters at low noise levels to be followed more accurately.</p>
        <p>For some parts of the NMD procedure it is inherently better to use a particular reconstruction method. Thus, in the criterion for selecting the TFR type (29) we always use the parameters reconstructed by the ridge method due to the noise robustness of such estimates. Additionally, while testing the signal against noise in the stopping criterion (Sec. III E) we also use the ridge estimates for calculating the discriminating statistics D (15). This seems natural because the curve extraction is based on the amplitudes and frequencies of the peaks (see Sec. III A), and we have found such an approach to be more stable than using the direct estimates; the noise-robustness of ridge reconstruction is advantageous here as well.</p>
        <p>For the other parts of the procedure, the reconstruction method can be chosen adaptively. To choose it at the first step, when we have extracted the time-frequency support [ω -(t),ω + (t)] of some component and need to reconstruct its parameters, one can use the approach suggested in [12]. Thus, we first reconstruct the parameters by both methods, getting A (d,r) (t), φ (d,r) (t), ν (d,r) (t), where "d" and "r" denote direct and ridge estimates, respectively. Then we compute the TFR (using the same parameters as originally) of the signal s (d) (t) = A (d) cos φ (d) , extract the ridge curve from it [taking simple maxima</p>
        <p>and reconstruct by direct method the "refined" parameters Ã(d) , φ(d) , ν(d) . We do the same for the "ridge" signal s (r) (t) = A (r) cos φ (r) , now using ridge method to reconstruct the refined estimates. Then we compute inconsistencies ε (d,r) a,φ,ν between the original and refined estimates for each method,</p>
        <p>where κ (d,r) A,φ,ν are the coefficients to tune the performance of the approach (we empirically found κ (d) A,φ,ν = {3,4,2}, κ (r) A,φ,ν = 1). Obviously, for the exact estimates one has ε A,φ,ν = 0, so it is natural to assess the relative performance of the reconstruction methods based on their inconsistencies (31). Therefore, we use the direct amplitude estimate if ε (d) A &lt; ε (r) A , and the ridge amplitude estimate otherwise; the same applies to the phase and frequency estimates. Although empirical, this approach works very well in practice.</p>
        <p>For harmonics the appropriate reconstruction method can be determined simply as that giving the highest consistency ρ (h) (12). Therefore, while adapting the resolution parameter for the harmonic, at each f 0 we reconstruct its parameters by both methods and at the end select the one characterized by highest ρ (h) .</p>
        <p>An adaptive choice of reconstruction method, as outlined above, ensures that in most cases we get the best possible estimates: When the amplitude and frequency modulations are low and noise is high, the noise-robust ridge reconstruction method is used, while in the opposite case the direct method is applied, giving more accurate estimates of amplitude and frequency variations. This approach further increases the noise robustness and the accuracy of the NMD.</p>
        <p>All the other parameters can be partitioned into two groups: some prefixed settings and the parameters of numerical accuracy. The former group includes the significance levels for the two surrogate tests (used for identification of the harmonics, Sec. III C, and for the stopping criterion, Sec. III E), the minimal consistency ρ min (14), etc. Each of these parameters is set to a well-established value, either corresponding to a standard convention (such as 95% significance of the surrogate tests [27,28]) or found empirically [e.g., the expression (14) for ρ min ].</p>
        <p>The second group includes the accuracy with which to determine the optimal f 0 while adapting it to the harmonics, the precision s to use for determining the minimal support (25), etc. Here one faces the usual trade-off between accuracy and computational cost. The default values, however, are sufficient in most cases and further increase of precision leads to only a slight improvement in the accuracy of the method.</p>
        <p>Having described all parts of the NMD procedure, we now illustrate the method by consideration of some specific examples. In this section we consider simulated signals whose composition is precisely known, so that one can assess reliably the performance of NMD and compare it to that of the other methods.</p>
        <p>As a first, simple, and illustrative example, we take the signal depicted in Fig. 5 WT they interfere strongly and cannot be resolved; in contrast, the WT has high enough time resolution at 7 Hz to represent the frequency modulation of the corresponding harmonic, while in the WFT this highest harmonic self-interferes (there appear the "bridges" between consecutive frequency modulation cycles), indicating that the time resolution is insufficient. Therefore, for the present case one cannot appropriately extract all harmonics using either WFT or WT with constant f 0 . However, adaptive representation of the harmonics, as discussed in Sec. IV A, solves the problem.</p>
        <p>The NMD proceeds as follows. First, the WT of the signal is calculated, and the dominant component is extracted from it, as described in Sec. III A; in result one obtains the first harmonic of the NM (located around 1 Hz). The extracted component is then tested with the surrogates against noise (see Sec. III E); in the present case, it passes the test (100% significance) and is therefore regarded as genuine. By application of the criteria (29), the WFT is determined to be more suitable for the representation of this component than the WT and is used in what follows. Thus, the component is reextracted from the corresponding signal's WFT (see Sec. V B), and its parameters are reconstructed by both the direct (10) and the ridge (9) methods. Using (31), it is established that the ridge estimates of amplitude, phase, and frequency seem to be the more accurate in the present case and are therefore taken as the ones to be used.</p>
        <p>Next we test whether the extracted component is the first harmonic by checking its possible 1/h harmonics. Thus, first the 1/2 harmonic is extracted and tested for being true (see Sec. III C) using different resolution parameters f 0 within the range (23); among the direct and ridge estimates obtained for f 0 at which the harmonic was identified as true, we choose those maximizing the consistency (12). In the present case, the 1/2 harmonic is identified as false for all tested f 0 , so it is discarded. We do the same for 1/3 and 1/4 harmonics, which are both identified as false. Since there are S 0 = 3 consecutive false harmonics (1/2, 1/3, and 1/4), we stop the procedure and correctly conclude that the extracted component is first (and not higher) harmonic of the NM.</p>
        <p>We then extract and test the higher harmonics h = 2,3, . . . in qualitatively the same way as was done for h = 1/2,1/3, . . .. If some harmonic is identified as true, we subtract it from the signal to remove its interference with higher harmonics. As a result of the procedure, all genuine harmonics h = 3,4,7 were correctly identified as true, and all the others as false. The resolution parameters were adapted for each harmonic so as to optimally represent and reconstruct it, as discussed in Sec. IV A and illustrated in Fig. 6 for the present case. Harmonic extraction was stopped when S = 3 consecutive harmonics h = 8,9,10 were identified as false.</p>
        <p>We then refine the harmonics' parameters using ( 24) and reconstruct the full NM. This NM is then subtracted from the signal, and the procedure is repeated. However, when we extract the next component, it does not pass the surrogate test against noise (see Sec. III E), and therefore NMD is stopped, with one NM being extracted and the residual correctly identified as noise (in the present case Brownian). The result of NMD is shown in Fig. 7, from which one can see that even the residual Brownian noise is well recovered.</p>
        <p>For example, the results of EMD [4] and EEMD [5] procedures are shown in Fig. 8. In contrast to NMD, (E)EMD produces 13 distinct components, with only the first harmonic of the NM being more-or-less reliably recovered in one of them. Thus, in Fig. 8 C4 for EMD and C5 for EEMD represent the first harmonic, C3 for EMD and C4 for EEMD is the noisespoiled mix of the 3 and 4 harmonics, C2 for EMD, and C3 for EEMD is the badly corrupted seventh harmonic (with influence from harmonics 3 and 4 in the case of EEMD), while none of the other "components" has any physical meaning at all.</p>
        <p>To demonstrate the exceptional noise robustness of NMD and the power of the surrogate test in distinguishing true from false harmonics, we consider the signal shown together with its WFT and WT in Fig. 9. As can be seen, the harmonics of the second NM are located exactly at the places where the harmonics of the first NM are expected to be, so that they can easily be confused with them. Moreover, it is very hard to distinguish true from false harmonics in the present case because each NM has constant amplitudes and only very small frequency modulation (the absolute deviation between the expected frequency of the second harmonic of the first NM and the frequency of the first harmonic of the second NM is only |2ν (1) 1 (t)ν (1) 2 |/2π = 0.016 ± 0.014 Hz). Furthermore, the noise is exceedingly strong, in standard deviation being 1.5 times that of the full noise-free signal, 1.8 times that of the first NM, 2.7 times that of the second NM, and 12.2 times that of the smallest (third) harmonic of the second NM, located at around 6 Hz [the latter is buried under the noise and not even visible in the WFT shown in Fig. 9(b)].</p>
        <p>Because the noise is white in the present case, its power in the WT grows with frequency, as seen from Fig. 9 (note, however, that such a situation rarely arises for real signals). Consequently, instead of using the WT and then adaptively selecting the appropriate type of TFR, for the present case we use the WFT from the very beginning. Nonlinear mode decomposition then proceeds as usual. It first extracts the dominant component and tests it against noise. If it passes the test, NMD extracts its harmonics and identifies the true ones. Then the full NM is reconstructed and subtracted from the signal, after which the procedure is repeated on the residual until it does not pass the surrogate test against noise.</p>
        <p>The relevant information about the NMD outcome is summarized in Table I. As can be seen, NMD correctly identifies all harmonics and joins them into two distinct modes. Moreover, the amplitude ratios a h and phase shifts ϕ h for each NM [see ( 4)], calculated from the reconstructed amplitude and phases as a h = A (h) / A (1) and ϕ h ≡ arg [ e i(φ (h) -hφ (1) ) ], are very close to their actual values; this is true even for the (buried in noise) third harmonic of the second NM. The ridge method is automatically selected for reconstructing of all harmonics, which is indeed the preferable choice due to its noise robustness [12]. 5. Thin red lines, where present, show the real first harmonic (in C4 for EMD and C5 for EEMD), sum of the third and fourth harmonics (in C3 for EMD and C4 for EEMD), and the seventh harmonic (in C2 for EMD and C3 for EEMD). The bottom panels show the sum of components 7 to 13. For EEMD, we have used 1000 noise realizations with standard deviations ten times smaller than that of the signal. From Table I it can be noted that, for all true harmonics, the resolution parameter f 0 used is higher than the original. This is because the higher the f 0 , the easier it is to segregate the component from noise [12]. However, increasing f 0 at the same time worsens the accuracy of representation of amplitude or frequency modulation of the component [12], so its choice is determined by a compromise between reflecting well the time variability of component's parameters and suppressing the noise; the adaptive scheme that we use, described in Sec. IV A, effectively implements this criterion.</p>
        <p>The final results of NMD are shown in Fig. 10. Both NMs are reconstructed with great accuracy, which is like a miracle given such strong noise corruption of the original signal (see Fig. 9); even the residual noise is recovered almost exactly. Such performance is unachievable with the other existing methods; e.g., (E)EMD in the present case produces 13 components, and none of them reliably represent any harmonic Reconstructed Nonlinear Mode 1 (not shown). Note that NMD can produce even more accurate results if the resolution parameter is adjusted from the very beginning, i.e., for the first harmonics (and not only the higher ones). However, as mentioned in Sec. V A, at present there does not seem to be a good and universal way of doing this.</p>
        <p>After demonstrating its success in the analysis of simulated signals, we now apply NMD to real data.</p>
        <p>The decomposition of skin blood flow signals, measured noninvasively by laser-Doppler flowmetry (LDF) [51], is a very tough task, with no method at present being able to do it well. This was demonstrated in [11] for the example of Karhunen-Loève decomposition, while (E)EMD usually also fails. Thus, blood flow signals contain a large amount of "physiological" noise, as well as having components with amplitude or frequency modulation whose strength and speed change with time. Nonetheless, as will be seen, NMD can often tackle even such complicated cases.</p>
        <p>Blood flow signals exhibit oscillatory activity at multiple frequencies, and the WT has been found especially useful in studies of their structure [52]. Six oscillations have been identified in blood flow and attributed to different physiological mechanisms [3,[52][53][54], with characteristic frequency ranges of (approximately): 0.6-2 Hz (I), 0.15-0.6 Hz (II), 0.04-0.15 Hz (III), 0.02-0.04 Hz (IV), 0.01-0.02 Hz (V), and 0.005-0.01 Hz (VI). Range I corresponds to cardiac oscillations, which originate from rhythmical pumping of the heart. Range II corresponds to respiratory oscillations, which are the consequence of the mechanical influence of respiration on the cardiac output and, to a smaller extent, the respiratory modulation of the heart rate [55,56]. The mechanism underlying range III oscillations, which are present in most hemodynamic signals, is not generally agreed: In studies of cardiac activity and blood pressure variability they are usually attributed to the sympathetic nerve activity, being regarded as a result of time delays in the baroreflex feedback loop [57,58], while the many authors studying microvascular blood flow relate these oscillations to myogenic activity of the smooth muscle cells [3,52,53]. Finally, the oscillations in the IV, V, and VI ranges were attributed to the neurogenic, NO-dependent endothelial, and NO-independent endothelial activity [3,[52][53][54], respectively.</p>
        <p>Armed with this knowledge, we now apply NMD. To better utilize the prior information, we apply the procedure to each of the above-mentioned physiological frequency ranges individually, starting from the first one. Thus, for a given range we extract the dominant component and test it against noise. If it passes the test, we then extract its harmonics, reconstruct the NM and subtract it from the signal.We then repeat the procedure for the same range until the next extracted component does not pass the test against noise.</p>
        <p>The results of the procedure are shown in Figs. 11 and12 for the examples of two blood flows. Clearly, NMD is able to decompose these signals into a physically meaningful oscillations with complex wave forms (and it also returns their amplitudes, phases, and frequencies). In both cases, we were able to extract the cardiac component (around 1 Hz), while activity in ranges IV, V, and VI did not pass the test against noise. However, in the example of Fig. 11 there are strong myogenic oscillations (around 0.1 Hz), which were extracted, while we see no activity in the frequency range II (respiratory) [Fig. 11(b)]. In contrast, for the example of Fig. 11 the respiratory oscillations are present and the myogenic oscillations are buried under noise. The wave forms of the cardiac oscillations are also different in two cases.</p>
        <p>In general, the properties and presence of the oscillations in blood flow vary from subject to subject, being influenced by many factors, such as the state of the microvasculature (which might be influenced by age and gender), properties of the skin, etc. As was demonstrated, NMD can be very useful for the study and classification of these effects; e.g., it can be used to investigate the relationship between the cardiac wave form (as well as other blood flow properties) and the health conditions.</p>
        <p>It is important to note that, as discussed in Sec. III E, even if the component extracted from a particular frequency range does not pass the surrogate test against noise (as, e.g., for ranges IV, V, and VI in the above examples), this does not necessarily mean that there is no physiologically meaningful activity there. Thus, the underlying oscillations might be simply very small so that they are easily masked by noise, which is often the case for the respiratory oscillations. The other possibility is that the resolution parameter used is not appropriate to represent reliably the component of interest. This is often the case for myogenic oscillations, which might change their amplitude and/or frequency very rapidly at certain times. In fact, the best choice in such situations would be probably some time-varying f 0 (t), but its form is generally very hard to choose.</p>
        <p>We have found that, in practice, NMD is almost always able to extract the cardiac component accurately from the blood flow signal using the default settings, though, to improve the accuracy and speed of the method, it is advisable to filter the signal in the corresponding frequency range before applying NMD. The respiratory component, on the other hand, can be extracted only in a limited number of cases on account of often being very small in amplitude compared to the physiological noise inherent in blood flow signals. Thus, one can always obtain "some" component from the corresponding frequency range, but it is often very inaccurate and consequently fails the surrogate test. Nevertheless, if the respiratory signal is also available, then one can use it as a reference signal for extracting the corresponding oscillations accurately from the blood flow signal even where they are very weak. An approach for doing this is discussed in the next section; it can also be used to improve the extraction of cardiac oscillations if the corresponding ECG, from which cardiac phase can be extracted more accurately than from the blood flow signal, is available. Finally, although we were able to extract myogenic oscillations (range III) in some cases, they are, in general, very hard to extract, as are also those at even lower frequencies (ranges IV-VI).</p>
        <p>Nonlinear mode decomposition can also be used to filter the signal from an extraneous oscillatory activity, provided that there is an associated signal from which the phase and frequency of the latter can accurately be extracted. Thus, using the NMD harmonic extraction procedure, the fundamental harmonic of the extraneous mode can be extracted as the h = 1 harmonic of the reference component based on its (reference) phase and frequency. In this way the resolution parameter is adjusted from the start, allowing one to represent this fundamental oscillation well, even if it is strongly corrupted by noise or other influences. We illustrate this alternative use of NMD through the example of removing cardiac artifacts from the human electroencephalogram (EEG) recording, using the electrocardiogram (ECG) as the reference signal.</p>
        <p>The EEG often contains artifacts related to heart activity, which arise due to blood flow pulsations underneath the probes (the so-called ballistocardiogram (BCG) artifacts [61]) and possibly also due to direct pick up of heart electrical activity. The BCG artifacts are extremely prominent in the EEG measured in a magnetic field (e.g., simultaneously with a magnetic resonance imaging scan), in which case they are usually filtered out by ICA [8,9]. However, ICA requires as many simultaneous EEG measurements as possible, with cardiac artifacts being prominent and taking a similar form in most of them, which is not always the case in practice. It will obviously fail to remove the artifacts if only one EEG and one ECG signal are available, because the form taken by cardiac activity in the EEG is completely different from its form in the ECG signal (see below), contradicting the assumption of linear mixing on which ICA is based. In fact, we have found that ICA fails even given four EEGs, which is probably because the artifacts in them are relatively small, being hard to distinguish (although still capable of affecting some timefrequency measures), and because the form and magnitude of these artifacts might be different in different EEGs (perhaps dependent on probe position). The (E)EMD method, too, fails to provide meaningful results in the present case.</p>
        <p>Simultaneously measured EEG and ECG time series for the same subject are presented in Figs. 13(a) and 13(b), with their WFTs for the default resolution parameter f 0 = 1 being shown in (c) and (d), respectively. Clearly, for f 0 = 1 the cardiac harmonics are not well distinguishable in the EEG's WFT [Fig. 13(c)], so that the extracted curve might not be very accurate. However, the cardiac phase φ (1) (t) and frequency ν (1) (t) can, of course, be extracted directly from the WFT of the ECG [Fig. 13(d)]. They should be the same for the first cardiac harmonic in the EEG and in ECG, because both activities obviously have the same rhythmicity; however, the corresponding amplitudes might be different and perhaps not even proportional to each other. This is because, depending on the measurement and the environment, the same activity might undergo various transformations that can change its amplitude dynamics and the corresponding wave form, but leave phase dynamics largely unaltered. For example, NMs c(t) = A(t)[cos φ(t) + a cos 2φ(t)] and exp[c(t)] will have the same fundamental phase and frequency, but different amplitude dynamics (i.e., the ratio between the amplitudes of the corresponding fundamental components will be time varying) and different relationships between the harmonics. Therefore, we use the cardiac phase φ (1) (t) and frequency ν (1) (t) extracted from the ECG as the parameters of the reference component and extract the main cardiac component from the EEG as its h = 1 harmonic. This is done in the same way as discussed in Sec. III B, i.e., selecting the peaks nearest to the expected frequency ν (1) (t). We test this harmonic for being true (Sec. III C) and adapt the resolution parameter for its best representation (Sec. IV A) in the usual way, except that now we use everywhere the phase consistency ρ (1) (0,1,0) (12) instead of the usual amplitude-phase consistency ρ (1) (1,1,0). This is because of the possible discrepancy between the amplitude dynamics of the components mentioned above [note that the threshold ( 14) also becomes ρ min = 0.5]. If the extracted first harmonic is regarded as true, we use its parameters to extract the higher cardiac harmonics from EEG (now using unmodified procedures) and reconstruct the corresponding NM.</p>
        <p>The EEG's WFT adapted [by maximizing phase consistency ρ (1) (0,1,0)] for representation of the cardiac component is shown in Fig. 13(e). Clearly, the corresponding ridge curves became much more visible than in the default WFT presented in Fig. 13(c). The cardiac artifacts extracted from the EEG are shown in Fig. 13(f). Their wave form, presented in Fig. 13(g), very much resembles the shape of the cardiac waves in the blood flow (cf. Fig. 12), but not that of the ECG. This is an indication of the BCG mechanism by which these cardiac artifacts are generated, which is also supported by the fact that their strength (and even their shape) might be different in EEGs from different probes for the same subject. Note that, depending on the particular EEG measurement, the artifacts might be inverted.</p>
        <p>There are many other possible applications of NMD-based filtering. Thus, as discussed in the previous section, one can use this approach to extract the cardiac and respiratory components from the blood flow signal more accurately by utilizing reference phases obtained from the corresponding ECG and respiration signals. NMD can also be used to check whether a given signal contains oscillatory activity related to another one: If there is no oscillation originating from the same source as the reference signal, then the corresponding first harmonic extracted from a given signal based on the reference phase and frequency will be regarded as false. For example, we have not found any respiratory-related activity in the EEG, implying that the measurement process is almost unaffected by breathing.</p>
        <p>In general, the situation when one signal contains components related to other signals is ubiquitous in real life, so that the NMD-based filtering is expected to be very useful in many situations. A great advantage of this approach is that it does not require the related oscillations in different signals to be of the same form (as is the case of, e.g., ICA), but only to have the same phase dynamics.</p>
        <p>There are many other contexts where NMD can prove useful. For example, it can serve as an initial preprocessing which needs to be performed prior to applying any of the numerous existing methods for studying monocomponent signals or their sets (for a review, see [62]). Thus, having first decomposed the original signal into its constituent NMs, one can then investigate the latter using one or some of the huge diversity of available techniques. For example, the structure of the interactions between different modes can be recovered by applying Bayesian inference to the extracted phases [63,64], as was done in [2] to reconstruct the cardiorespiratory interaction; in this application, the high accuracy of the phases returned by NMD is especially advantageous.</p>
        <p>Another important application is the classification of the oscillations present in the signal, which is of particular interest because it might yield valuable insights into the nature and properties of the underlying phenomena. Following the recent introduction of chronotaxic systems [65,66], it is clearly desirable to be able to determine whether the originating systems generating the different modes are chronotaxic or not. Roughly speaking (see [65,66] for a more detailed definition), the system is chronotaxic if it is (a) oscillatory (i.e., characterized by a limit cycle) and (b) its phase φ(t) does not just move freely along the cycle, as in self-sustained oscillators, but is attracted to a particular deterministically time-varying fixed point φ A (t), conferring an ability to resist external perturbations. This is exactly what one often observes in living systems, which are able to maintain their activity within physiological ranges even when strongly perturbed, so that chronotaxic behavior is expected to be abundant within the life sciences.</p>
        <p>To establish which oscillations contained in the signal are chronotaxic, one needs to study them separately; i.e., the signal should be first decomposed into its NMs. This can conveniently and accurately be achieved with NMD. Subsequently, for each mode one can apply the approach suggested by Clemson et al. [66]. Basically, by applying different types of filters to the extracted phase, one estimates the expected difference φ(t)φ A (t) and uses detrended fluctuation analysis [3,67] to analyze the associated correlations, which are expected to differ between chronotaxic and nonchronotaxic systems. We have applied this method to the NMs of both of the examples in Figs. 11 and12, but have not found clear evidence of chronotaxicity in any of the corresponding oscillations. However, since the method being used is based on a particular set of assumptions, these oscillations could, in principle, still be chronotaxic though falling outside the model considered in [66]; note also that the respiratory modulation of the cardiac frequency was shown to demonstrate signs of chronotaxicity [66].</p>
        <p>The decomposition method that we have introduced-NMD-is based on the time-frequency analysis techniques [12,19], surrogate data tests [27][28][29][30], and the idea of identification of the time-variable harmonics [25]. NMD consists of a number of ingredients, as described in Sec. III, each of which is a useful technique in its own right. For example, one can use the approach discussed in Sec. III E for testing the signal against noise (within a large class; see Sec. III E), which proves to be more noise robust than the conventional tests based on the correlation dimension or other nonlinearity measures [27,28,68].</p>
        <p>We have successfully applied NMD to both simulated and real data and demonstrated its advantages over the existing approaches. Unlike many previous methods, NMD recovers the full underlying oscillations of any wave form. It is also extremely noise robust and in a sense superadaptive, meaning that most of its settings are automatically adapted to the properties of the particular signal under investigation. Finally, in contrast to the other methods, NMD returns only physically meaningful modes, stopping the decomposition when the residual is just noise.</p>
        <p>The area of applicability of NMD is extremely wide. For example, it would now be reasonable to reconsider all those cases where (E)EMD has been applied to date (e.g., see references in [5,69]). Furthermore, as demonstrated above, the exceptional noise robustness of NMD and its other advantages allow one to apply it even in cases where all the other methods fail completely. Thus, it can be applied to almost all multicomponent signals of the kind that are ubiquitous in the life sciences, geophysics, astrophysics, econometrics, etc. We therefore expect that, with time, NMD will become a standard method in the field.</p>
        <p>The latest 
            <rs type="software">MATLAB</rs>
            <rs type="software">codes</rs> needed for running NMD are freely available [70], together with detailed instructions and examples, in both text and video formats.
        </p>
        <p>We are grateful to Philip Clemson for valuable discussions and to Valentina Ticcinelli for testing the codes and for useful comments. The work was supported by the Engineering and Physical Sciences Research Council (UK) [Grant No. EP/100999X1].</p>
        <p>The algorithm for performing NMD, including all the steps and improvements described above, can be summarized as follows.</p>
        <p>(1) Calculate the WT of the given signal using the wavelet (7) with the chosen resolution parameter f 0 (see Sec. V A).</p>
        <p>(2) Extract the dominant component (in what follows, the reference component) from the signal's WT (see Sec. III A), and reconstruct its characteristics (see Secs. III A and V C).</p>
        <p>(3) Test the reference component against noise using surrogates, as described in Sec. III E. Stop the decomposition if it does not pass this test.</p>
        <p>(4) Check whether the WT is the "right" representation for the reference component and, if not, switch to using the WFT and reextract the component from it (see Sec. V B). In what follows, TFR denotes the chosen representation: WT or WFT.</p>
        <p>(5) For h = 1/2,1/3, . . . do the following. (a) Calculate the signal's TFR within the frequency range determined by (28) using different values of the resolution parameter f (h) 0 [see (23) and related discussion], for each of which (i) extract the hth harmonic of the reference component from the TFR and reconstruct its amplitude, phase, and frequency (see Secs. III B and V C);</p>
        <p>(ii) test the current harmonic for being true as described in Sec. III C. (b) If for some f (h) 0 the harmonic was identified as true, then set its characteristics to those reconstructed for the f (h) 0 that is characterized by the highest consistency (11) with the reference component among f (h) 0 for which the harmonic was identified as true.</p>
        <p>(c) Stop when a prechosen number (default = 3) of consequent harmonics were identified as false for all tested f (h) 0 . (6) If some harmonic was identified as true in the previous step, take the true harmonic with the smallest h as the reference component. The reference component is therefore guaranteed to be the first harmonic of the corresponding NM now.</p>
        <p>(7) Perform step 5 for h = 1,2, . . ., remembering the reconstructed parameters of the harmonics.</p>
        <p>(8) Using the parameters of the harmonics that were identified as true in the previous step, reconstruct the full NM as described in Sec. IV B.</p>
        <p>(9) Subtract the reconstructed NM from the signal, and repeat steps 1-8 on the residual.</p>
    </text>
</tei>
