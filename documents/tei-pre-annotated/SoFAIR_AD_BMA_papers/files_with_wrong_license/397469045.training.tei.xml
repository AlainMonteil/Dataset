<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T09:40+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>David Christian Rose 1 , Jessica Lyon 1 , Auvikki de Boon 1 , Marc Hanheide 2 , Simon Pearson 2</p>
        <p>Despite the promise of autonomous robots to contribute to agricultural sustainability, a number of social, legal, and ethical issues threaten adoption. To understand these challenges, we discuss how responsible innovation principles can be embedded into the user-centred design of autonomous robots and identify areas for further empirical research.</p>
        <p>Adding to the list of environmental challenges facing agriculture, COVID-19 and the demographics of age, migration and urbanisation poses a serious threat to the sustainability of farm businesses and food security 1 . In particular, farm businesses across the world are struggling to fill vacancies and provide safe working conditions for labourers.</p>
        <p>Autonomous robots could help address these immediate challenges 2 . Whilst their physical manifestation comprises hardware, such as a vehicle combined with manipulators, their autonomy is derived from sophisticated algorithms routed in artificial intelligence. These algorithms fuse sensor data to enable control and real-time decision support. Autonomous robots perform tasks with a high degree of autonomy and may work collaboratively alongside human workers (so-called co-bots) or on their own 3 . Apart from isolated examples of these technologies being demonstrated on-farm, autonomous platforms with robotic mobility which fuse multiple technologies across a single fleet (e.g. crop forecasting, planting, harvesting, packing) are not yet fully implementable, and substantial barriers need to be overcome before they will be. However, there is already adoption of static robotic milking technologies in the dairy sector, and in-field deployment of tractor mounted robotic manipulators to remove weeds and protect crops from pests and diseases 2 , for example.</p>
        <p>We know, however, that the history of innovation in agriculture is littered with examples of failure or slow adoption, and the legal, ethical, and social concerns associated with autonomous agriculture are controversial 4,5 . Potential challenges, opportunities and consequences of autonomous agriculture, illustrated in Figure 1, are interlinked and depend on how technologies are designed and implemented. Many of these aspects have been discussed in the burgeoning literature on the social and ethical impacts of digitalisation in agriculture 6,7.</p>
        <p>The most widely used framework for responsible innovation was proposed by Stilgoe and colleagues 8 and involves four key components: anticipating the impacts of innovation; reflecting on one's work and adapt accordingly (reflexivity); including a wide range of stakeholders in the design process; and responding to stakeholders' concerns, ideas and knowledge by constructing appropriate institutional structures.</p>
        <p>Sciences Research Council 9 , InnovateUK 10 , and the European Commissionencourages companies to be cognisant of their responsibility and committed to RRI principles, by exploring the challenges that could arise from innovation and acting on their findings in a transparent, inclusive, and timely manner. Despite frequent calls for companies to conduct a transparent and iterative process of responsible innovation, there is a lack of either a commitment to, or reporting of, the steps taken in technology development in the agriculture industry.</p>
        <p>In the following sections we discuss how the four key components mentioned above can be operationalised to guide technology development in agriculture 11 , outlining key research needs to better understand how to operationalise the idea. Examples referenced in this paper and the guidance from Stilgoe et al. 8 and Eastwood et al .11 provide a good overview of techniques that can be used to apply responsible innovation principles.</p>
        <p>With the objective of minimising negative, unintended outcomes 8 , 'anticipation' involves identifying, predicting, and exploring the potential short-and long-term consequences of future innovation across society and is therefore essential for the responsible development of autonomous robots.</p>
        <p>There has been little empirical anticipatory work for autonomous robots in farming that has included a variety of stakeholders in the process, though a recent paper by Legun and Burch 12 begins to describe a process of co-design in the context of robotic apple orchards in New Zealand.</p>
        <p>Empirical studies have otherwise been limited to the narrow use of foresight exercises in the form of technology use and acceptance surveys and farmer 13 or public opinion surveys 14 using online questionnaires and short interviews. Foresight is also used to elucidate future benefits and challenges associated with a technology in combination with other methods, such as the Delphi technique (which relies on anonymous rounds of voting) 15 . Other anticipatory processes include 'horizon scanning' (scanning data sources to detect early developments 16 ) and 'socio-literary techniques' (using science fiction as a tool to encourage dialogue about technology futures 17 , possibly through 'Ag-Tech movie nights' 18 ). A typical methodology in robotics and human-robotic interaction are "Wizard of Oz" studies 19 , where autonomy is "fake"; robots are usually remotecontrolled, anticipating the abilities they may have once fully implemented. Another useful technique often employed are video studies 20 , where participants are presented with recordings of robot behaviour and assess it from a third person perspective.</p>
        <p>One further method to consider is backcasting, which involves building an (ideal) future scenario, and working backwards to identify the steps needed to get to that scenario. This is done in anticipatory governance approaches, for example. A key area for future research will be to use different anticipatory methods with diverse stakeholders specifically on the subject of autonomous robots in agriculture. Those included in the process of anticipation should be those directly affected by the adoption of robotics, including farmers, farm workers, and consumers of food produced in that way. Including such a wide range of stakeholders will create a number of practical challenges related to power inequality (farm managers v farm workers) and language barriers (migrant farm workers) and these will need to be managed sensitively by trained facilitators.</p>
        <p>Reflexivity entails 'holding a mirror up to one's own activities, commitments and assumptions, being aware of the limits of knowledge and being mindful that a particular framing of an issue may not be universally held' 8 . Constant analysis and critique of one's work among peers is an embedded practice of rigorous science. However, scientists and engineers typically carry out reflexivity and other responsible innovation practices 'behind closed doors', in the lab, and do not recognise these processes as 'reflexivity' in responsible innovation terms 21 . Opening these conversations up to the public and acknowledging and listening to other actors can improve the quality of reflexivity.</p>
        <p>Reflexivity in the realm of autonomous robots in agriculture has mostly come from the usercentred design (UCD) process. Work to date in this space has recognised that robotic systems interacting with humans need to undergo an iterative development approach 22 , bringing together subjective user experience with actual system logs. After including stakeholders and seeking their information requirements and preferences for autonomous robots through surveys 23 , workshops 24 , and field experiments 25,26,27 , designers have altered prototypes and design paths to ensure that the robots work for the user. Yet, this is narrow reflexivity; it involves developers tweaking design based on user feedback, rather than conducting a fundamental analysis of the assumptions and values underlying the proposed solution or questioning if agricultural robotics is really the path we want to take as society. We rarely carry out a deeper form of reflexivity, possibly missing alternative solutions.</p>
        <p>The development of and engagement with best practice guidelines, codes of conduct and international standards is another form of reflexivity that can guide industry to conduct innovation in a responsible manner, although it is not always clear whether they continue to serve the purpose of reflexivity once adopted. In Australia, a code of practice for 'Agricultural Mobile Field Machinery with Autonomous Functions' is currently under development to help guide safe working procedures in the field; this code of practice is intended to hold some legal weight.</p>
        <p>International standards for the use of autonomous robots such as ISO 10218 provide norms for worker safety when collaborating with robots in a structured, industrial environment. In ISO 10218, safety aspects such as tactile and pressure sensors, safe maximum speed, proximity sensors, human detection cameras, and emergency stop are described to ensure the safety of human-robot collaboration. Other relevant international standards include: ISO 18497 (design principles for safety with highly automated agricultural machinesoperations of robots in-field are not covered)</p>
        <p>; ISO 17757 (for use of autonomous machinery in mining); and ISO/SAE DIS 21434, currently under development (for cybersecurity in road vehicles). The agricultural industry can glean insights from these standards, however there is a necessity to further develop agriculture specific standards and codes of practice that account for human-robot collaboration in flexible, unstructured environments such as in the field. Understanding how this might be done effectively, bringing together relevant stakeholders, is an important future area for research.</p>
        <p>Concepts of 'inclusion' are frequently limited to the 'consideration' of how stakeholders may be impacted or react to innovation by a limited group of experts 28 . Genuine inclusion should involve the participation of a full range of stakeholders through processes. If we do not pursue methods for the substantive inclusion of a full range of actors, not just the 'usual suspects', and do not give due attention to power inequalities between stakeholders throughout the participatory process, then we risk reinforcing unequal participation under the guise of inclusivity. It may appear that increased participation from the start is time-consuming and resource-intensive, but user-centred design can prevent problems further down the line.</p>
        <p>Within the development of autonomous robots in agriculture, inclusion has mostly taken the form of consultation and sometimes collaboration, involving feedback from farmers and farm workers on the technical side of robot development. Simulation experiments 29,30 and field-based workshops 23 have allowed farmers and farm workers to test the usability of a technology.</p>
        <p>Researchers have used task scenarios, observations, and participant feedback to feed into prototype development. The social sciences have developed a number of participatory methods that allow substantive inclusion, such as citizen juries and deliberative workshops, and a greater selection of these should be brought to bear for inclusion surrounding autonomous agriculture 31 .</p>
        <p>Stakeholders identified in the PAS 440 Responsible Innovation framework developed for InnovateUK 10 include co-developers; markets, customers, end-users; regulators and standards bodies; NGOs representing civil society stakeholders and individual citizens likely to be affected.</p>
        <p>Beyond the 'usual suspects', it is important to engage with 'harder to reach' stakeholders. Schillo and Robinson 28 discuss the importance of engaging with historically marginalized groups. In the case of autonomous agriculture, this could involve small farmers (who may be pushed out of the industry by larger farmers with more capacity to adopt and adapt), organic farmers (whose farming strategy may be more difficult to align with autonomous robots focussed on precision fertilisation 32 ), as well as farm workers (who could lose jobs as they are replaced by robots). Blok 33 argues that stakeholder inclusion and participation can typically become reductive as it focuses on the cognitive approach to understanding the perspectives of stakeholders in a self-serving 'immunization strategy', where the goal is to convince others, prevent criticism and portray the company as having good intentions. We should ultimately ensure that we are undertaking substantive, rather than tokenistic inclusion.</p>
        <p>The involvement of stakeholders should not be restricted to the exploration of consequences in terms of economic opportunity or technology acceptance, but include wider implications and society's 'grand challenges'. To date there are limited examples of this work; Pfeiffer et al. 14 explored public's opinions of digital farming technology through surveys and spontaneous associations; Kester et al. 13 surveyed farmer's views of the future of automation on topics such as perceived value, applications and expectations; and Baxter et al. 26 asked fruit pickers questions regarding the impact of autonomous robots on their job security.</p>
        <p>Identifying potential consequences, reflecting on underlying assumptions, values, and problemsolving processes, and including stakeholders in the innovation process can only lead to responsible innovation if newly gained insights are enacted upon. Actors should be reactive to new knowledge and ensure development is iterative. This could be in the form of adapting R&amp;D projects or early design prototypes based on information feedback from stakeholders. Other actions that result from new information could include adjusting business models, altering control or access to software, amending workers contracts and working conditions 3 , or refraining from developing a certain robot altogether if it is not desired by society.</p>
        <p>Responsiveness is also important within institutional structures, which should respond promptly to new information, in policy, law, and regulatory environment. Regulation can restrict innovation (e.g. GM crops in Europe), efficiency, and competitive advantage, however legal structures will be important to ensure protection for users of autonomous robots and for clarifying the liability framework. Hence, regulation can act as both a barrier to and an enabler of adoption. Basu et al. 5 describe the current legal frameworks, regulations and standards that are relevant to the development of autonomous robots in agriculture, as well as the gaps in areas such as data protection law, ethics of robot autonomy and artificial intelligence. Similarly to how the European Union embedded 'Privacy by Design' into its General Data Protection Regulation, others are calling for 'Equality by Design' in artificial intelligence (AI) regulation to safeguard against bias and discrimination that may inadvertently be engrained in technology and machine learning 34 .</p>
        <p>There are examples of "technological redlining" as well as technological limitations of measurement such as unequal object detection or lower quality heart rate measurement for those with darker skin 34 . A lack of transparency with algorithms, machine learning and AI -the "black box" problemcan lead to bias and discrimination issues within machine learning to become further entrenched and replicated. Regulatory oversight of "Equality by Design" 34 is key to ensure that programmers address any bias and discrimination that may be produced in algorithms, ultimately ensuring that technology treats users fairly.</p>
        <p>Addressing the social, legal, and ethical implications of autonomous robots is arguably a greater challenge than the development of the technology itself. More research is needed to ensure that anticipation, reflexivity, and inclusion efforts are turned into responsive action on the ground. As highlighted in this paper, most empirical work for the development of autonomous agriculture has been focused on the technical aspects of robot operation with some level of inclusion and reflexivity to ensure improvement of technical performance. Little published work has gone beyond this to use methods that allow for substantive inclusion and deeper reflexivity on the subject. Yet, if society decides that autonomous robotics for farming is the way to go, then practising responsible innovation in their development is vitally important to prevent future controversy, implementation delays, and negative consequences. Ultimately, the success or failure Figure 1: Overview of challenges, opportunities, and potential consequences of autonomous agriculture. The signs +, -and +-indicate positive, negative and uncertain consequences, respectively. Positive consequences denote opportunities to be harnessed, whereas negative consequences denote challenges to be overcome concerning the operationalization, adoption and/or deployment of innovations (see Sparrow and Howard 4 and Basu et al. 5 for more detail).</p>
        <p>This paper is was developed from the Robot Highways project funded by InnovateUK as part of the ISCF TFP Science and Technology into Practice: Demonstration call (Grant number 51367).</p>
        <p>Affiliations 1 School of Agriculture, Policy and Development, University of Reading, Earley, Reading, RG6 6EU, UK 2 Lincoln Institute for Agri-Food Technology, University of Lincoln, Riseholme Campus, Lincoln, LN2 2LG, UK</p>
        <p>David Christian Rose | d.c.rose@reading.ac.uk</p>
        <p>The authors declare no competing interests.</p>
    </text>
</tei>
