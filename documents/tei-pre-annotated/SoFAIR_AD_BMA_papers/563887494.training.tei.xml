<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-13T13:38+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>Management scholars and practitioners have highlighted the importance of ethical dimensions in the selection of strategies. However, to date, there has been little effort aimed at theoretically understanding the ethical positions of individuals/organizations concerning human resource management (HRM) decision-making processes, the selection of specific ethical positions and strategies, or the post-decision accounting for those decisions. To this end, we present a Throughput model framework that describes individuals' decision-making processes in an algorithmic HRM context. The model depicts how perceptions, judgments, and the use of information affect strategy selection, identifying how diverse strategies may be supported by the employment of certain ethical decision-making algorithmic pathways. In focusing on concerns relating to the impact and acceptance of artificial intelligence (AI) integration in HRM, this research draws insights from multidisciplinary theoretical lenses, such as AI-augmented (HRM (AI) ) and HRM (AI) assimilation processes, AI-mediated social exchange, and the judgment and choice literature. We highlight the use of algorithmic ethical positions in the adoption of AI for better HRM outcomes in terms of intelligibility and accountability of AI-generated HRM decision-making, which is often underexplored in existing research, and we propose their key role in HRM strategy selection.Management scholars and practitioners have highlighted the importance of ethical dimensions in the selection of strategies. However, to date, there has been little effort aimed at theoretically understanding the ethical positions of individuals/organizations concerning human resource management (HRM) decision-making processes, the selection of specific ethical positions and strategies, or the post-decision accounting for those decisions. To this end, we present a Throughput model framework that describes individuals' decision-making processes in an algorithmic HRM context. The model depicts how perceptions, judgments, and the use of information affect strategy selection, identifying how diverse strategies may be supported by the employment of certain ethical decision-making algorithmic pathways. In focusing on concerns relating to the impact and acceptance of artificial intelligence (AI) integration in HRM, this research draws insights from multidisciplinary theoretical lenses, such as AI-augmented (HRM (AI) ) and HRM (AI) assimilation processes, AI-mediated social exchange, and the judgment and choice literature. We highlight the use of algorithmic ethical positions in the adoption of AI for better HRM outcomes in terms of intelligibility and accountability of AI-generated HRM decision-making, which is often underexplored in existing research, and we propose their key role in HRM strategy selection.</p>
        <p>Artificial intelligence (AI) has the ability to make decisions in real time based on pre-installed algorithms and computing technologies constructed based on data analysis to learn and acclimate automatically to offer more refined responses to situations. Encompassing both the human element and the adoption of AI applications, human resource management (HRM) can offer an improved experience for an organization's employees (Pereira, Hadjielias, Christofi, &amp; Vrontis, 2021). As AI technology has advanced, concerns with human control of the inherently opaque nature of AI systems have driven increasing interest regarding the ethics-AI interface. A limited understanding of the theoretical basis for AI assimilation in HRM decision-making functions has not impeded the solving. As organizations increasingly depend on algorithm-based HRM decision-making to observe their employees, this movement is buttressed by the technology industry, maintaining that its decision-making apparatuses are efficient and objective, thereby downplaying their potential biases. Our study identifies six ethical theories that undergird the efficiency-driven logic of algorithm-based HRM decision-making and may assist HRM practitioners to more fully understand and support the balance between employees' personal integrity and workplace compliance (Leicht-Deobald et al., 2019).Artificial intelligence (AI) has the ability to make decisions in real time based on pre-installed algorithms and computing technologies constructed based on data analysis to learn and acclimate automatically to offer more refined responses to situations. Encompassing both the human element and the adoption of AI applications, human resource management (HRM) can offer an improved experience for an organization's employees (Pereira, Hadjielias, Christofi, &amp; Vrontis, 2021). As AI technology has advanced, concerns with human control of the inherently opaque nature of AI systems have driven increasing interest regarding the ethics-AI interface. A limited understanding of the theoretical basis for AI assimilation in HRM decision-making functions has not impeded the solving. As organizations increasingly depend on algorithm-based HRM decision-making to observe their employees, this movement is buttressed by the technology industry, maintaining that its decision-making apparatuses are efficient and objective, thereby downplaying their potential biases. Our study identifies six ethical theories that undergird the efficiency-driven logic of algorithm-based HRM decision-making and may assist HRM practitioners to more fully understand and support the balance between employees' personal integrity and workplace compliance (Leicht-Deobald et al., 2019).</p>
        <p>Following the six distinct ethical approaches to HRM, two objectives can be achieved. First, mainstream and critical approaches will be challenged to address ethical issues in HRM more critically (Leicht-Deobald et al., 2019). Second, a stalwart forward-looking research agenda for the ethical analysis of HRM will be advanced (Kandathil &amp; Joseph, 2019).Following the six distinct ethical approaches to HRM, two objectives can be achieved. First, mainstream and critical approaches will be challenged to address ethical issues in HRM more critically (Leicht-Deobald et al., 2019). Second, a stalwart forward-looking research agenda for the ethical analysis of HRM will be advanced (Kandathil &amp; Joseph, 2019).</p>
        <p>The intent of an organization is influenced by the "environment" within the organization (natural, social, and economic), and the adoption of AI technology incorporating an organization's "environmental variables" within HRM algorithms allows the opportunity for post-decision evaluation via RCA.The intent of an organization is influenced by the "environment" within the organization (natural, social, and economic), and the adoption of AI technology incorporating an organization's "environmental variables" within HRM algorithms allows the opportunity for post-decision evaluation via RCA.</p>
        <p>Nonetheless, Selbst, Boyd, Friedler, Venkatasubramanian, and Vertesi (2019) claimed that the elements of solutionism, the ripple effect, formalism, portability, and framing should be addressed when considering designing an AI-based machine-learning solution.Nonetheless, Selbst, Boyd, Friedler, Venkatasubramanian, and Vertesi (2019) claimed that the elements of solutionism, the ripple effect, formalism, portability, and framing should be addressed when considering designing an AI-based machine-learning solution.</p>
        <p>1. Solutionism is the failure to recognize the possibility that the best solution to a problem may not involve technology. 2. The ripple effect represents the failure to understand how technology incorporation into a prevailing social system changes the behaviors and embedded values of the former system. 3. Formalism indicates the breakdown to account for the overall connotation of social concepts, such as fairness, which can be procedural, contextual, and contestable, and cannot be reconciled through mathematical formalisms. 4. Portability implies the failure to comprehend how algorithmic solutions conceived for one social context may be misleading, erroneous, or otherwise cause impairment when harnessed to a dissimilar context. 5. Framing relates to the failure to model the complete system, whereby a social criterion, such as fairness, will be enforced (Selbst et al., 2019).1. Solutionism is the failure to recognize the possibility that the best solution to a problem may not involve technology. 2. The ripple effect represents the failure to understand how technology incorporation into a prevailing social system changes the behaviors and embedded values of the former system. 3. Formalism indicates the breakdown to account for the overall connotation of social concepts, such as fairness, which can be procedural, contextual, and contestable, and cannot be reconciled through mathematical formalisms. 4. Portability implies the failure to comprehend how algorithmic solutions conceived for one social context may be misleading, erroneous, or otherwise cause impairment when harnessed to a dissimilar context. 5. Framing relates to the failure to model the complete system, whereby a social criterion, such as fairness, will be enforced (Selbst et al., 2019).</p>
        <p>Moreover, ignorance of these issues may cause technical involvements to become ineffective, inaccurate, and perilously imprudent when they enter the societal context that surrounds decision-making systems. In this context, the current research focuses on three pillars. First, by identifying six distinct ethical approaches (solutionism) to HRM, the issue of framing in the AI algorithmic model that deduces formalism is addressed. Second, as social and technical approaches can be challenged to address ethical issues in HRM more critically, the issue of portability will be examined (Leicht-Deobald et al., 2019). Third, a stalwart and predictable forward-looking research agenda for the ethical analysis of HRM is offered (ripple effect) in view of the incorporation of AI technology (Kandathil &amp; Joseph, 2019).Moreover, ignorance of these issues may cause technical involvements to become ineffective, inaccurate, and perilously imprudent when they enter the societal context that surrounds decision-making systems. In this context, the current research focuses on three pillars. First, by identifying six distinct ethical approaches (solutionism) to HRM, the issue of framing in the AI algorithmic model that deduces formalism is addressed. Second, as social and technical approaches can be challenged to address ethical issues in HRM more critically, the issue of portability will be examined (Leicht-Deobald et al., 2019). Third, a stalwart and predictable forward-looking research agenda for the ethical analysis of HRM is offered (ripple effect) in view of the incorporation of AI technology (Kandathil &amp; Joseph, 2019).</p>
        <p>In addition, AI is a technology that attempts to simulate human reasoning in computers and other types of machines (Rodgers, 2019;Rodgers &amp; Al Fayi, 2019). Algorithms used in AI are unambiguous specifications for performing calculations, data processing, automated reasoning, and other tasks. This conceptual study employs AI algorithmic pathways derived from TP model theory (Rodgers, 1997;Rodgers, Alhendi, &amp; Xie, 2019), which highlights six dominant algorithmic pathways by employing the four major concepts of (1) perception (i.e., framing of the problem), (2) information, (3) judgment (analysis of perception and information), and (4) decision choice.In addition, AI is a technology that attempts to simulate human reasoning in computers and other types of machines (Rodgers, 2019;Rodgers &amp; Al Fayi, 2019). Algorithms used in AI are unambiguous specifications for performing calculations, data processing, automated reasoning, and other tasks. This conceptual study employs AI algorithmic pathways derived from TP model theory (Rodgers, 1997;Rodgers, Alhendi, &amp; Xie, 2019), which highlights six dominant algorithmic pathways by employing the four major concepts of (1) perception (i.e., framing of the problem), (2) information, (3) judgment (analysis of perception and information), and (4) decision choice.</p>
        <p>The TP model is engaged in this study because it embraces several vital issues in organizational behavior (Foss &amp; Rodgers, 2011), accounting and management (Rodgers &amp; Housel, 1992), education (Rodgers, Simon, &amp; Gabrielsson, 2017), ethics/corporate social responsibility (Rodgers et al., 2019;Rodgers, Söderbom, &amp; Guiral, 2014), consumer behavior (Rodgers &amp; Nguyen, 2022), and ethical dilemmas in auditing (Guiral, Rodgers, Ruiz, &amp; Gonzalo-Angulo, 2015;Rodgers, Guiral, &amp; Gonzalo, 2009). Moreover, the TP model provides a broad conceptual framework for examining the interrelated processes influencing the decision choices that affect organizations. This model's unique contribution is that it illuminates essential pathways in ethical decision-making (i.e., a parallel process instead of a serial process). Finally, the model integrates the concepts of perception (framing situational conditions), information, judgment (analysis of information/situational conditions), and decision choice as it applies to organizations.The TP model is engaged in this study because it embraces several vital issues in organizational behavior (Foss &amp; Rodgers, 2011), accounting and management (Rodgers &amp; Housel, 1992), education (Rodgers, Simon, &amp; Gabrielsson, 2017), ethics/corporate social responsibility (Rodgers et al., 2019;Rodgers, Söderbom, &amp; Guiral, 2014), consumer behavior (Rodgers &amp; Nguyen, 2022), and ethical dilemmas in auditing (Guiral, Rodgers, Ruiz, &amp; Gonzalo-Angulo, 2015;Rodgers, Guiral, &amp; Gonzalo, 2009). Moreover, the TP model provides a broad conceptual framework for examining the interrelated processes influencing the decision choices that affect organizations. This model's unique contribution is that it illuminates essential pathways in ethical decision-making (i.e., a parallel process instead of a serial process). Finally, the model integrates the concepts of perception (framing situational conditions), information, judgment (analysis of information/situational conditions), and decision choice as it applies to organizations.</p>
        <p>As Westerman, Edwards, Edwards, Luo, and Spence (2020) emphasize, with the rapid increase in the use of AI systems, interdisciplinary insights are required to understand interactions among people. In this context, the major contribution of our theoretical work is to enhance AI systems by highlighting ethical algorithms that can equip system designers, computer analysts, and HR practitioners with improved systems and accountability for their decisions.As Westerman, Edwards, Edwards, Luo, and Spence (2020) emphasize, with the rapid increase in the use of AI systems, interdisciplinary insights are required to understand interactions among people. In this context, the major contribution of our theoretical work is to enhance AI systems by highlighting ethical algorithms that can equip system designers, computer analysts, and HR practitioners with improved systems and accountability for their decisions.</p>
        <p>AI can be described as the theory and development of computer systems that can undertake assignments typically driven by algorithms (Rodgers, 2020). These algorithms are often supported by machine learning to add significant power to HRM concepts and practices. Since algorithmic bias can induce bias in the decision-making process, our research infuses an ethical decision-making platform into the process that can guide HR. AI algorithms can encompass ethics, decision-making, and managerial knowledge to identify appropriate HRM strategies.AI can be described as the theory and development of computer systems that can undertake assignments typically driven by algorithms (Rodgers, 2020). These algorithms are often supported by machine learning to add significant power to HRM concepts and practices. Since algorithmic bias can induce bias in the decision-making process, our research infuses an ethical decision-making platform into the process that can guide HR. AI algorithms can encompass ethics, decision-making, and managerial knowledge to identify appropriate HRM strategies.</p>
        <p>To address an evident gap in the literature, this study explores the impact of ethical dimensions on the selection of ethical strategies. Employing Rodgers' (1997) TP model, which highlights dominant algorithmic pathways for ethical decision-making processes (Rodgers &amp; Gago, 2001), we aspire to enhance past literature by incorporating an AI algorithmic ethical decision-making model into HRM concepts and practices. This AI approach can provide valuable insights into how different pathways may influence the strategies A TPM pathway roadmap for HRM decision integration with AI.To address an evident gap in the literature, this study explores the impact of ethical dimensions on the selection of ethical strategies. Employing Rodgers' (1997) TP model, which highlights dominant algorithmic pathways for ethical decision-making processes (Rodgers &amp; Gago, 2001), we aspire to enhance past literature by incorporating an AI algorithmic ethical decision-making model into HRM concepts and practices. This AI approach can provide valuable insights into how different pathways may influence the strategies A TPM pathway roadmap for HRM decision integration with AI.</p>
        <p>The Algorithmic governance of data driven-processing employment: Evidence-based management practices, artificial intelligence recruiting software, and automated hiring decisionsThe Algorithmic governance of data driven-processing employment: Evidence-based management practices, artificial intelligence recruiting software, and automated hiring decisions</p>
        <p>To better understand the relationship between evidencebased management practices, AI recruiting software, and automated hiring decisions.To better understand the relationship between evidencebased management practices, AI recruiting software, and automated hiring decisions.</p>
        <p>Convergence of computerbased data science with the investigation of human behavior has defined the sphere of people-analytics. HRM departments are instrumental in detecting relevant external data, transferring significant external input into the organization.Convergence of computerbased data science with the investigation of human behavior has defined the sphere of people-analytics. HRM departments are instrumental in detecting relevant external data, transferring significant external input into the organization.</p>
        <p>The TPM AI algorithm approach introduces a framework for accountability of decision-making process resulting from HRM input of external data.The TPM AI algorithm approach introduces a framework for accountability of decision-making process resulting from HRM input of external data.</p>
        <p>Article Purpose Findings Relationship to TPM AI Algorithmic Approach Buzko et al., 2016 Artificial intelligence technologies in human resource developmentArticle Purpose Findings Relationship to TPM AI Algorithmic Approach Buzko et al., 2016 Artificial intelligence technologies in human resource development</p>
        <p>To determine the effectiveness of training costs using cognitive-system AI analytics.To determine the effectiveness of training costs using cognitive-system AI analytics.</p>
        <p>Transition from information processing to AI is more relevant for decision-making.Transition from information processing to AI is more relevant for decision-making.</p>
        <p>Use of TPM is a foundation for interactions between AI and selfconsciousness.Use of TPM is a foundation for interactions between AI and selfconsciousness.</p>
        <p>(continued on next page) W. Rodgers et al. employed by HR decision makers.(continued on next page) W. Rodgers et al. employed by HR decision makers.</p>
        <p>The TP model offers insights from cognitive and social psychology into a descriptive model of how human constituents make decisions within organizations. It encompasses four components: perception (P), information (I), judgment (J), and decision choice (D). In the first stage, both perception and information influence judgment; then, in the second stage, perception and judgment influence decision choice (Foss &amp; Rodgers, 2011).The TP model offers insights from cognitive and social psychology into a descriptive model of how human constituents make decisions within organizations. It encompasses four components: perception (P), information (I), judgment (J), and decision choice (D). In the first stage, both perception and information influence judgment; then, in the second stage, perception and judgment influence decision choice (Foss &amp; Rodgers, 2011).</p>
        <p>The use of AI technologies by HRM practitioners raises questions regarding the acceptance and use of rules and policies that are imposed by programmers remotely from the HRM team. The TP model provides a framework for practitioners to frame and assess decisions, employing an audit trail and structure to frame the RCA of post-decision outcomes, including pay-gap analysis, the effectiveness of diversity and inclusion policies, and PMRS. The effective design and use of AI by HRM practitioners will help the PMRS to motivate employees to strive to attain an organization's goals, as ineffective systems can lead to a wide range of problems (Lillis, Malina, &amp; Mundy, 2015). The combination of AI technology and an ethical framework, such as the TP model, offers HRM practitioners the opportunity to account for both the objective and subjective components of performance measurement. In other words, the use of TP ethical pathways aims to explain the place of a particular AI algorithm in the overall decision-making process and how such algorithms work generally.The use of AI technologies by HRM practitioners raises questions regarding the acceptance and use of rules and policies that are imposed by programmers remotely from the HRM team. The TP model provides a framework for practitioners to frame and assess decisions, employing an audit trail and structure to frame the RCA of post-decision outcomes, including pay-gap analysis, the effectiveness of diversity and inclusion policies, and PMRS. The effective design and use of AI by HRM practitioners will help the PMRS to motivate employees to strive to attain an organization's goals, as ineffective systems can lead to a wide range of problems (Lillis, Malina, &amp; Mundy, 2015). The combination of AI technology and an ethical framework, such as the TP model, offers HRM practitioners the opportunity to account for both the objective and subjective components of performance measurement. In other words, the use of TP ethical pathways aims to explain the place of a particular AI algorithm in the overall decision-making process and how such algorithms work generally.</p>
        <p>The integration of AI into HRM can be depicted in four categories: (1) it is a system that thinks like a human, (2) it thinks rationally, (3) it acts like a human, and (4) it acts rationally (George &amp; Thomas, 2019). For example, the Turing test, formerly termed the imitation game by Alan Turing in 1950, is a test of an AI machine's capability to exhibit intelligent behavior comparable to or indistinguishable from that of a person. If the evaluator cannot certifiably indicate that the machine is different from the human, the machine is said to have passed the test (Moor, 2003).The integration of AI into HRM can be depicted in four categories: (1) it is a system that thinks like a human, (2) it thinks rationally, (3) it acts like a human, and (4) it acts rationally (George &amp; Thomas, 2019). For example, the Turing test, formerly termed the imitation game by Alan Turing in 1950, is a test of an AI machine's capability to exhibit intelligent behavior comparable to or indistinguishable from that of a person. If the evaluator cannot certifiably indicate that the machine is different from the human, the machine is said to have passed the test (Moor, 2003).</p>
        <p>The incorporation of computer-mediated communication (CMC) in lieu of human interaction in an organization's HRM practices may strategically be used to achieve an organization's objectives (Westerman et al., 2020). Smart chatbots, which are AI-based technologies that can support HRM decision-making (Rodgers, 2020), can assist the HRM team in relaying consistent organizationrelated information to employees, while simultaneously offering them a global view of the organization. This study proposes the adoption of an algorithmic pathway model to help determine the appropriate use and accountability of such technology. Westerman et al. (2020, p. 398) refer to human-machine communication (HMC) regarding the balance of privacy and disclosure, whereby people "balance their privacy concerns with the need to self-disclose in interpersonal relationships." As HMC is utilized, HRM practitioners will need to have a full understanding of any benefits of HMC over human-human contact. An example of HMC analysis is where data is obtained after human contact (e.g., post-phone call performance feedback via text), and although this is influenced by ethical positioning, feedback may be adjusted by perceptions of AI anonymity. Moreover, AI technology can benefit HRM in the following transaction areas:The incorporation of computer-mediated communication (CMC) in lieu of human interaction in an organization's HRM practices may strategically be used to achieve an organization's objectives (Westerman et al., 2020). Smart chatbots, which are AI-based technologies that can support HRM decision-making (Rodgers, 2020), can assist the HRM team in relaying consistent organizationrelated information to employees, while simultaneously offering them a global view of the organization. This study proposes the adoption of an algorithmic pathway model to help determine the appropriate use and accountability of such technology. Westerman et al. (2020, p. 398) refer to human-machine communication (HMC) regarding the balance of privacy and disclosure, whereby people "balance their privacy concerns with the need to self-disclose in interpersonal relationships." As HMC is utilized, HRM practitioners will need to have a full understanding of any benefits of HMC over human-human contact. An example of HMC analysis is where data is obtained after human contact (e.g., post-phone call performance feedback via text), and although this is influenced by ethical positioning, feedback may be adjusted by perceptions of AI anonymity. Moreover, AI technology can benefit HRM in the following transaction areas:</p>
        <p>1. Time pressure decisions: The cost of unhurried decisions is high (speed being essential). 2. Accuracy: The cost of wrong decision choices is minimized.1. Time pressure decisions: The cost of unhurried decisions is high (speed being essential). 2. Accuracy: The cost of wrong decision choices is minimized.</p>
        <p>The data size is too large for manual analysis or traditional algorithms. 4. Decisions where prediction accuracy is more important than explanation or clarification. 5. Provision of information where regulatory requirements are slight (Rodgers, 2020).The data size is too large for manual analysis or traditional algorithms. 4. Decisions where prediction accuracy is more important than explanation or clarification. 5. Provision of information where regulatory requirements are slight (Rodgers, 2020).</p>
        <p>According to their review of the state-of-the-art literature on the role of AI in business, Loureiro et al. (2021) observe that employment and decision-making constitute major areas in which AI's impact is prevalent. The adoption of AI is changing the strategic direction of the recruitment industry, impacting cost control and the volume of candidates for clients (Upadhyay &amp; Khandelwal, 2018), and automating repetitive administrative tasks. Scalability of HRM processes can be achieved using AI technology to increase the number of recruitment candidates, not only dramatically reducing the timescale and cost of recruitment but also increasing the socioeconomic diversity of new hires (Wilson &amp; Daugherty, 2018).According to their review of the state-of-the-art literature on the role of AI in business, Loureiro et al. (2021) observe that employment and decision-making constitute major areas in which AI's impact is prevalent. The adoption of AI is changing the strategic direction of the recruitment industry, impacting cost control and the volume of candidates for clients (Upadhyay &amp; Khandelwal, 2018), and automating repetitive administrative tasks. Scalability of HRM processes can be achieved using AI technology to increase the number of recruitment candidates, not only dramatically reducing the timescale and cost of recruitment but also increasing the socioeconomic diversity of new hires (Wilson &amp; Daugherty, 2018).</p>
        <p>Moreover, AI can play a role in HRM strategy and the analysis of organizational policies, such as by supporting organizational compliance (see Table 1). With the appropriate algorithms, AI-enabled systems can support management to recruit potential employees, to give prompt responses to candidates' queries and doubts, and to manage the submission and processing of applications. Furthermore, with the development of AI-enabled applications, HR-related cost savings and individualized employee experiences can be achieved (Malik, Budhwar, Patel, &amp; Srikanth, 2020), also promoting personalized talent management practices, which can increase job satisfaction and reduce turnover intentions (Malik, De Silva, Budhwar, &amp; Srikanth, 2021;Nguyen &amp; Malik, 2021a).Moreover, AI can play a role in HRM strategy and the analysis of organizational policies, such as by supporting organizational compliance (see Table 1). With the appropriate algorithms, AI-enabled systems can support management to recruit potential employees, to give prompt responses to candidates' queries and doubts, and to manage the submission and processing of applications. Furthermore, with the development of AI-enabled applications, HR-related cost savings and individualized employee experiences can be achieved (Malik, Budhwar, Patel, &amp; Srikanth, 2020), also promoting personalized talent management practices, which can increase job satisfaction and reduce turnover intentions (Malik, De Silva, Budhwar, &amp; Srikanth, 2021;Nguyen &amp; Malik, 2021a).</p>
        <p>The interdisciplinary literature highlighted in Table 1 illustrates an emerging pattern of concern with regard to the incorporation of AI into the workplace, which replicates human thought processes in a more efficient manner. Three themes emerge from the literature: employee detachment from decision-making, human understanding and perception of AI processes, and the impact of AI interpretation of datasets.The interdisciplinary literature highlighted in Table 1 illustrates an emerging pattern of concern with regard to the incorporation of AI into the workplace, which replicates human thought processes in a more efficient manner. Three themes emerge from the literature: employee detachment from decision-making, human understanding and perception of AI processes, and the impact of AI interpretation of datasets.</p>
        <p>As AI algorithms in the work environment are increasingly adopted in a convenient and accessible modality (e.g., smartphone apps), roles that traditionally belonged to HRM professionals are undertaken by AI algorithms (Duggan et al., 2020). This raises questions regarding the HRM function, and the pattern of concerns with AI adoption reinforcing the need for an HRM accountability framework for the implementation and use of AI in the workplace. App working in the gig economy has also challenged the conceptualization of work and employment status, with algorithms exercising control over app-workers' performance and scheduling based on real-time and predictive analytics, disrupting conventional workplace decisions and relationships (Duggan et al., 2020;Minbaeva, 2021).As AI algorithms in the work environment are increasingly adopted in a convenient and accessible modality (e.g., smartphone apps), roles that traditionally belonged to HRM professionals are undertaken by AI algorithms (Duggan et al., 2020). This raises questions regarding the HRM function, and the pattern of concerns with AI adoption reinforcing the need for an HRM accountability framework for the implementation and use of AI in the workplace. App working in the gig economy has also challenged the conceptualization of work and employment status, with algorithms exercising control over app-workers' performance and scheduling based on real-time and predictive analytics, disrupting conventional workplace decisions and relationships (Duggan et al., 2020;Minbaeva, 2021).</p>
        <p>Decision-making in a more traditional contract-worker environment using AI algorithms reflects similar patterns of cognitive detachment from the decision-making process. Upskilling in such an environment requires a level of understanding of the appropriate detachment from, and attachment to, AI decisions, dependent on the organization's strategies, hierarchy, and accountability. Ontological distance from decision-making (Bader &amp; Kaiser, 2019) suggests organizations should consider, in more detail, the role of epistemologies in algorithmic decision-making. Questions regarding employee integrity interfaced with AI decisions reinforce the importance of identification and an understanding of employees' perceptions of their ethical position in the decision-making process (Leicht-Deobald et al., 2019).Decision-making in a more traditional contract-worker environment using AI algorithms reflects similar patterns of cognitive detachment from the decision-making process. Upskilling in such an environment requires a level of understanding of the appropriate detachment from, and attachment to, AI decisions, dependent on the organization's strategies, hierarchy, and accountability. Ontological distance from decision-making (Bader &amp; Kaiser, 2019) suggests organizations should consider, in more detail, the role of epistemologies in algorithmic decision-making. Questions regarding employee integrity interfaced with AI decisions reinforce the importance of identification and an understanding of employees' perceptions of their ethical position in the decision-making process (Leicht-Deobald et al., 2019).</p>
        <p>Research on understanding why humans anthropomorphize technology illustrates that complex processes exist in employees' psychological contracts with the use of AI technologies in organizations (Bankins &amp; Formosa, 2020) and suggests that the positive impact of utilizing AI technology is undermined by a lack of attention given to the integration of AI and human capital (Barro &amp; Davenport, 2019). The interdependent relationships between employees and AI technology rely on an understanding of programmed decision algorithms. We add further to this area of research through the development of an accountability framework for organizations to more fully understand AI-generated decisions. Decision-making is dependent on relevant and applicable datasets, and this is an area where data literacy, the size of the data sets, and the incorporation of external data have an impact on HRM engagement and accountability in the investigation and development of employees' performance (Bekken, 2019;Tambe et al., 2019). Exponential increases in data generation require an AI solution to information processing, as employees have a limited capacity to process information (Nguyen &amp; Malik, 2021a). The acceptance of AI software in replacing the human role in repetitive and time-consuming tasks (Upadhyay &amp; Khandelwal, 2018) has now developed from being a component for increasing workplace productivity to a key factor in regional economic growth strategies toward upskilling the workforce for the AI-led transformation of the economy (European Commission, 2020). This research indicates the need for introducing a decision accountability framework whereby HRM practitioners have a pathway to consider and account for components of the organizational environment, employee engagement, and ethics when incorporating AI decision-making to assist in achieving organizational goals.Research on understanding why humans anthropomorphize technology illustrates that complex processes exist in employees' psychological contracts with the use of AI technologies in organizations (Bankins &amp; Formosa, 2020) and suggests that the positive impact of utilizing AI technology is undermined by a lack of attention given to the integration of AI and human capital (Barro &amp; Davenport, 2019). The interdependent relationships between employees and AI technology rely on an understanding of programmed decision algorithms. We add further to this area of research through the development of an accountability framework for organizations to more fully understand AI-generated decisions. Decision-making is dependent on relevant and applicable datasets, and this is an area where data literacy, the size of the data sets, and the incorporation of external data have an impact on HRM engagement and accountability in the investigation and development of employees' performance (Bekken, 2019;Tambe et al., 2019). Exponential increases in data generation require an AI solution to information processing, as employees have a limited capacity to process information (Nguyen &amp; Malik, 2021a). The acceptance of AI software in replacing the human role in repetitive and time-consuming tasks (Upadhyay &amp; Khandelwal, 2018) has now developed from being a component for increasing workplace productivity to a key factor in regional economic growth strategies toward upskilling the workforce for the AI-led transformation of the economy (European Commission, 2020). This research indicates the need for introducing a decision accountability framework whereby HRM practitioners have a pathway to consider and account for components of the organizational environment, employee engagement, and ethics when incorporating AI decision-making to assist in achieving organizational goals.</p>
        <p>The emerging and developing technologies increasingly utilized by HRM practitioners highlight the need to critically understand the processes involved, as the benefits for organizations and employees may be undermined without an understandable roadmap for future integration (Barro &amp; Davenport, 2019). The TP model offers a framework for both communicating and understanding AI-driven HRM decisions. Machine learning and deep learning are the key processes within the overall AI technology used in HRM. The roots of machine learning and deep learning are embedded in pattern recognition and in the concept that algorithms can learn from recorded data without being programmed to do so (Rodgers, 2020).The emerging and developing technologies increasingly utilized by HRM practitioners highlight the need to critically understand the processes involved, as the benefits for organizations and employees may be undermined without an understandable roadmap for future integration (Barro &amp; Davenport, 2019). The TP model offers a framework for both communicating and understanding AI-driven HRM decisions. Machine learning and deep learning are the key processes within the overall AI technology used in HRM. The roots of machine learning and deep learning are embedded in pattern recognition and in the concept that algorithms can learn from recorded data without being programmed to do so (Rodgers, 2020).</p>
        <p>Specifically, key cases of machine learning in an HRM context include the following:Specifically, key cases of machine learning in an HRM context include the following:</p>
        <p>1. Anomaly detection: Identify items, events, or observations that do not conform to an expected pattern or other items in a pool of job applicants. 2. Background verification: Machine learning-powered predictive models can extract meaning and highlight issues based on structured and unstructured data points from applicants' resumes. 3. Employee attrition: Find employees who are at high risk of attrition, enabling HR to proactively engage with and retain them. 4. Content personalization: Provide a more personalized employee experience by using predictive analytics to recommend career paths (Bekken, 2019), professional development programs, or optimize a workplace environment based on prior employee actions.1. Anomaly detection: Identify items, events, or observations that do not conform to an expected pattern or other items in a pool of job applicants. 2. Background verification: Machine learning-powered predictive models can extract meaning and highlight issues based on structured and unstructured data points from applicants' resumes. 3. Employee attrition: Find employees who are at high risk of attrition, enabling HR to proactively engage with and retain them. 4. Content personalization: Provide a more personalized employee experience by using predictive analytics to recommend career paths (Bekken, 2019), professional development programs, or optimize a workplace environment based on prior employee actions.</p>
        <p>Deep learning is a branch of machine learning that trains a computer to learn from large amounts of data through neural network architecture. It is a more advanced form of machine learning that breaks down data into layers of abstraction. Instead of organizing data to run through predefined equations, deep learning sets up basic parameters about the data and trains the computer to learn independently by recognizing patterns using multiple neural network layers for processing (similar to neurons in the brain) (Rodgers, 2020).Deep learning is a branch of machine learning that trains a computer to learn from large amounts of data through neural network architecture. It is a more advanced form of machine learning that breaks down data into layers of abstraction. Instead of organizing data to run through predefined equations, deep learning sets up basic parameters about the data and trains the computer to learn independently by recognizing patterns using multiple neural network layers for processing (similar to neurons in the brain) (Rodgers, 2020).</p>
        <p>The use of artificial neural networks (ANNs) is a machine-learning technique to form systems of elements of artificial "neurons" as numerically connected virtual "synapses" with numerical weights that are tuned based on experience and that are adaptive to inputs and capable of learning (Buzko et al., 2016). After sufficient training, deep-learning algorithms can begin to make predictions or interpretations of very complex data with minimal human oversight, such as financial trading (Barro &amp; Davenport, 2019).The use of artificial neural networks (ANNs) is a machine-learning technique to form systems of elements of artificial "neurons" as numerically connected virtual "synapses" with numerical weights that are tuned based on experience and that are adaptive to inputs and capable of learning (Buzko et al., 2016). After sufficient training, deep-learning algorithms can begin to make predictions or interpretations of very complex data with minimal human oversight, such as financial trading (Barro &amp; Davenport, 2019).</p>
        <p>Key use cases of deep learning in an HRM context include questions of ethics and data management for HRM practitioners, requiring a framework for decisions and accountability, including:Key use cases of deep learning in an HRM context include questions of ethics and data management for HRM practitioners, requiring a framework for decisions and accountability, including:</p>
        <p>1. Image and video recognition: Deep-learning algorithms outperform humans in object classification. Given videos and photos of thousands of applicants, deep-learning systems can identify and classify candidates based on objective data. Employing historical data, behavioral analytics is used by some organizations to predict how behavioral antecedents may result in fraudulent practice (Cockcroft &amp; Russell, 2018). Ethical positions of organizations and decision makers incorporated within a decision framework can be considered by HRM practitioners in organizations that utilize real-time AI psychological profiling systems that measure near real-time non-verbal behavior. 2. Speech recognition: While understanding the human voice and myriad accents is difficult for most machines, deep-learning algorithms can be designed to recognize and respond to human voice inputs. Virtual assistants use speech-recognition algorithms to process human voice characteristics and respond accordingly. Speech analytics software can help organizations ensure compliance with statutory regulations, identify potential fraud, and review previous communication to provide a pathway for future communication. However, these same data may include sensitive characteristics, identifying illnesses, and social, economic, or racial origin, requiring an ethical framework for HRM in the collection, processing, and storing of workforce analytics records. 3. Chatbots: Natural language processing (NLP) trains chatbots and similar systems to understand human language, tone, and context.1. Image and video recognition: Deep-learning algorithms outperform humans in object classification. Given videos and photos of thousands of applicants, deep-learning systems can identify and classify candidates based on objective data. Employing historical data, behavioral analytics is used by some organizations to predict how behavioral antecedents may result in fraudulent practice (Cockcroft &amp; Russell, 2018). Ethical positions of organizations and decision makers incorporated within a decision framework can be considered by HRM practitioners in organizations that utilize real-time AI psychological profiling systems that measure near real-time non-verbal behavior. 2. Speech recognition: While understanding the human voice and myriad accents is difficult for most machines, deep-learning algorithms can be designed to recognize and respond to human voice inputs. Virtual assistants use speech-recognition algorithms to process human voice characteristics and respond accordingly. Speech analytics software can help organizations ensure compliance with statutory regulations, identify potential fraud, and review previous communication to provide a pathway for future communication. However, these same data may include sensitive characteristics, identifying illnesses, and social, economic, or racial origin, requiring an ethical framework for HRM in the collection, processing, and storing of workforce analytics records. 3. Chatbots: Natural language processing (NLP) trains chatbots and similar systems to understand human language, tone, and context.</p>
        <p>NLP will emerge as a crucial capability for AI systems, as organizations continue to automate HRM service delivery with chatbots. 4. Recommendation engines: Digital learning experiences often involve personalized learning recommendations related to skill levels and professional interests. Using Big Data and deep learning, learning experience platforms can identify learning pathways that benefit both individual employees and their employer. Moreover, AI provides managers with a list of training exercises they can show to their employees (Matsa &amp; Gullamajji, 2019). Reliance on AI decision-making may lead HRM practitioners to replicate human-machine contact in PMRS human-human engagement (Bankins &amp; Formosa, 2020), deferring responsibility for HRM decisions to the AI HRM decision outcome when communicating to candidates or employees, resulting in a negative overall experience in engagement with the organization.NLP will emerge as a crucial capability for AI systems, as organizations continue to automate HRM service delivery with chatbots. 4. Recommendation engines: Digital learning experiences often involve personalized learning recommendations related to skill levels and professional interests. Using Big Data and deep learning, learning experience platforms can identify learning pathways that benefit both individual employees and their employer. Moreover, AI provides managers with a list of training exercises they can show to their employees (Matsa &amp; Gullamajji, 2019). Reliance on AI decision-making may lead HRM practitioners to replicate human-machine contact in PMRS human-human engagement (Bankins &amp; Formosa, 2020), deferring responsibility for HRM decisions to the AI HRM decision outcome when communicating to candidates or employees, resulting in a negative overall experience in engagement with the organization.</p>
        <p>The use of AI technology in HRM can improve organizational decision-making tasks, including HRM practitioners' everyday activities, such as scheduling vacation requests, team training, and recruitment (Matsa &amp; Gullamajji, 2019). The use of AI technology helps HRM teams by integrating recurring and low-value tasks, allowing the HRM team to focus on more strategic workforce tasks. An example would be when an organization traditionally hires a new employee, and it needs to provide the employee with an office, computer, etc. Instead of being tasked with these components, the organization uses algorithm-based apps, allowing for a more flexible work environment and granting the HRM team more time to focus on mentoring new employees.The use of AI technology in HRM can improve organizational decision-making tasks, including HRM practitioners' everyday activities, such as scheduling vacation requests, team training, and recruitment (Matsa &amp; Gullamajji, 2019). The use of AI technology helps HRM teams by integrating recurring and low-value tasks, allowing the HRM team to focus on more strategic workforce tasks. An example would be when an organization traditionally hires a new employee, and it needs to provide the employee with an office, computer, etc. Instead of being tasked with these components, the organization uses algorithm-based apps, allowing for a more flexible work environment and granting the HRM team more time to focus on mentoring new employees.</p>
        <p>AI technology can also be used to identify which employees are contemplating leaving an organization by analyzing their computer activities (e.g., emails and Internet browsing) (Matsa &amp; Gullamajji, 2019). The adoption of new AI software assists an organization in the automation of administrative tasks, such as reducing time on scheduling interviews or pre-screening candidates. In addition, algorithm-based email responses have helped HRM teams in their time management. By utilizing employees' surveys to enhance meaningful feedback pertaining to job satisfaction, organizations can better manage and evaluate employees' roles (O'Connor, 2020), and with AI-enhanced feedback mechanisms, organizations can encourage the retention of valuable employees using analytics to devise employee incentives.AI technology can also be used to identify which employees are contemplating leaving an organization by analyzing their computer activities (e.g., emails and Internet browsing) (Matsa &amp; Gullamajji, 2019). The adoption of new AI software assists an organization in the automation of administrative tasks, such as reducing time on scheduling interviews or pre-screening candidates. In addition, algorithm-based email responses have helped HRM teams in their time management. By utilizing employees' surveys to enhance meaningful feedback pertaining to job satisfaction, organizations can better manage and evaluate employees' roles (O'Connor, 2020), and with AI-enhanced feedback mechanisms, organizations can encourage the retention of valuable employees using analytics to devise employee incentives.</p>
        <p>HRM practitioners have increased their access to algorithm-based "apps" to monitor and address workforce accountability (Bekken, 2019). The deep-learning algorithms used in such AI technology are inherently opaque, and while HRM practitioners need a framework to account for decisions generated by AI systems, they also need to have a clear understanding of the quality of the data input and processes utilized by such systems (Haenlein &amp; Kaplan, 2019).HRM practitioners have increased their access to algorithm-based "apps" to monitor and address workforce accountability (Bekken, 2019). The deep-learning algorithms used in such AI technology are inherently opaque, and while HRM practitioners need a framework to account for decisions generated by AI systems, they also need to have a clear understanding of the quality of the data input and processes utilized by such systems (Haenlein &amp; Kaplan, 2019).</p>
        <p>Before machine learning and deep learning, HRM managed data in a manual and semi-automated manner. Nonetheless, HRM has been relatively slower to come to the table with machine learning and AI compared with other fields, such as marketing, communications, or healthcare (e.g., Hermann, 2021). The value of machine learning and deep learning in HRM can now be utilized, especially due to advances in algorithms that can forecast employee attrition. For example, deep-learning neural networks are edging toward more transparent reasoning in displaying why a particular result or conclusion was made (Bader &amp; Kaiser, 2019). In recruiting, machine learning and deep learning can be implemented to analyze blog/social media profiles and identify candidate attributes that may not appear on their resumes. Recruiters can also utilize machine learning and deep learning to proactively find the correct people for openings with software that searches the Internet to source prospects. Moreover, video-based interviewing analyzed by machine learning and deep learning can assist in determining an interviewee's mood, and whether the candidate is telling the truth or not. The preliminary stages of interviewing can become much simpler with the implementation of machine learning-and deep learning-driven chatbots on a firm's website to provide applicant onboarding (Matyunina, 2020).Before machine learning and deep learning, HRM managed data in a manual and semi-automated manner. Nonetheless, HRM has been relatively slower to come to the table with machine learning and AI compared with other fields, such as marketing, communications, or healthcare (e.g., Hermann, 2021). The value of machine learning and deep learning in HRM can now be utilized, especially due to advances in algorithms that can forecast employee attrition. For example, deep-learning neural networks are edging toward more transparent reasoning in displaying why a particular result or conclusion was made (Bader &amp; Kaiser, 2019). In recruiting, machine learning and deep learning can be implemented to analyze blog/social media profiles and identify candidate attributes that may not appear on their resumes. Recruiters can also utilize machine learning and deep learning to proactively find the correct people for openings with software that searches the Internet to source prospects. Moreover, video-based interviewing analyzed by machine learning and deep learning can assist in determining an interviewee's mood, and whether the candidate is telling the truth or not. The preliminary stages of interviewing can become much simpler with the implementation of machine learning-and deep learning-driven chatbots on a firm's website to provide applicant onboarding (Matyunina, 2020).</p>
        <p>Organizations and employees may have misunderstandings and contradictory perceptions regarding the intent and use of AI technology in HRM (Bankins &amp; Formosa, 2020). Ontological distance to AI-driven HRM decisions (Bader &amp; Kaiser, 2019) raises the role of epistemologies in algorithm-based decisions. Selbst et al. (2019) explore further how machine learning can incorporate notions of fairness, justice, and due process, and suggest a shift from a solution-oriented approach to a process-oriented one in helping decision makers understand the technology they use. It is in this process-oriented approach that the TP model allows HR decision makers to more fully understand ethical considerations incorporated in AI-based decision-making.Organizations and employees may have misunderstandings and contradictory perceptions regarding the intent and use of AI technology in HRM (Bankins &amp; Formosa, 2020). Ontological distance to AI-driven HRM decisions (Bader &amp; Kaiser, 2019) raises the role of epistemologies in algorithm-based decisions. Selbst et al. (2019) explore further how machine learning can incorporate notions of fairness, justice, and due process, and suggest a shift from a solution-oriented approach to a process-oriented one in helping decision makers understand the technology they use. It is in this process-oriented approach that the TP model allows HR decision makers to more fully understand ethical considerations incorporated in AI-based decision-making.</p>
        <p>The question of the accountability of organizations for errors in the algorithms they use is a real issue, resulting in ethical, legal, and philosophical challenges that need to be addressed (Haenlein &amp; Kaplan, 2019). Rodgers (1997Rodgers ( , 2006) ) developed a decision-making model that acknowledges that decision makers do not always act rationally. The model highlights discrepancies between how decision makers behave when compared with the intent and ethical position of their organization, and it portrays the importance of developing accurate descriptions of the algorithmic pathways used by decision makers. It thus identifies systematic pathways in which decision makers may depart from rationality, simultaneously allowing for an analysis of what can be expected if they follow a particular pathway (Foss &amp; Rodgers, 2011).The question of the accountability of organizations for errors in the algorithms they use is a real issue, resulting in ethical, legal, and philosophical challenges that need to be addressed (Haenlein &amp; Kaplan, 2019). Rodgers (1997Rodgers ( , 2006) ) developed a decision-making model that acknowledges that decision makers do not always act rationally. The model highlights discrepancies between how decision makers behave when compared with the intent and ethical position of their organization, and it portrays the importance of developing accurate descriptions of the algorithmic pathways used by decision makers. It thus identifies systematic pathways in which decision makers may depart from rationality, simultaneously allowing for an analysis of what can be expected if they follow a particular pathway (Foss &amp; Rodgers, 2011).</p>
        <p>The TP model is a cognitive model explaining the role played by perception, information, and judgment in human decision-making incorporated in machine learning (Rodgers, 1997(Rodgers, , 2006(Rodgers, , 2020)). Further, the model provides a broad conceptual framework for examining interrelated and parallel processes that impact decisions affecting individuals and organizations. Parallel processing depicts a knowledge representation displaying that perception and information can separately influence judgment, as well as perception and judgment independently influencing decision choice (Rumelhart &amp; McCelland, 1986;Rumelhart &amp; Ortony, 1977). Moreover, this model depicts a multi-stage, information-processing function in which cognitive, economic, and social processes are used to generate a set of outcomes via algorithmic pathways. Finally, the concept of a decision choice is a composite of mental or neural pathway activities that recognize and structure decision situations and then evaluate preferences to produce judgments and choices (Einhorn &amp; Hogarth, 1981;Kahneman &amp; Tversky, 1979).The TP model is a cognitive model explaining the role played by perception, information, and judgment in human decision-making incorporated in machine learning (Rodgers, 1997(Rodgers, , 2006(Rodgers, , 2020)). Further, the model provides a broad conceptual framework for examining interrelated and parallel processes that impact decisions affecting individuals and organizations. Parallel processing depicts a knowledge representation displaying that perception and information can separately influence judgment, as well as perception and judgment independently influencing decision choice (Rumelhart &amp; McCelland, 1986;Rumelhart &amp; Ortony, 1977). Moreover, this model depicts a multi-stage, information-processing function in which cognitive, economic, and social processes are used to generate a set of outcomes via algorithmic pathways. Finally, the concept of a decision choice is a composite of mental or neural pathway activities that recognize and structure decision situations and then evaluate preferences to produce judgments and choices (Einhorn &amp; Hogarth, 1981;Kahneman &amp; Tversky, 1979).</p>
        <p>The TP model, which is presented in Fig. 1, has four components: perception (P), information (I), judgment (J), and decision (D). According to the model, perception and information lead to judgment in the first stage, and then perception and judgment lead to a decision. The perception concept indicates that individuals frame situations according to their experience, training, and education. Further, based on the strengths or weaknesses of these elements, decision makers may employ heuristics and biases in the perception stage (Tversky &amp; Kahneman, 1981). This model proposes that information and perception are interrelated, as shown in Fig. 1 by the double-ended arrow, and that judgment is a joint product of information and perception. P = perception, I = information, J = judgment, and D = decision choice. The interdependent relationship between perception and information (i.e., P←→I) is comparable to a Bayesian statistic (Bolstad &amp; Curran, 2016), in that the "information" concept is continuously revising the decision maker's perception, that is, previous information is continually captured within the "information" construct. In addition, decision makers' previous decisions are immersed by information sources. Hence, the P←→I correlation functions in part as a framework that is similar to a neural network (Rodgers, 2020).The TP model, which is presented in Fig. 1, has four components: perception (P), information (I), judgment (J), and decision (D). According to the model, perception and information lead to judgment in the first stage, and then perception and judgment lead to a decision. The perception concept indicates that individuals frame situations according to their experience, training, and education. Further, based on the strengths or weaknesses of these elements, decision makers may employ heuristics and biases in the perception stage (Tversky &amp; Kahneman, 1981). This model proposes that information and perception are interrelated, as shown in Fig. 1 by the double-ended arrow, and that judgment is a joint product of information and perception. P = perception, I = information, J = judgment, and D = decision choice. The interdependent relationship between perception and information (i.e., P←→I) is comparable to a Bayesian statistic (Bolstad &amp; Curran, 2016), in that the "information" concept is continuously revising the decision maker's perception, that is, previous information is continually captured within the "information" construct. In addition, decision makers' previous decisions are immersed by information sources. Hence, the P←→I correlation functions in part as a framework that is similar to a neural network (Rodgers, 2020).</p>
        <p>A neural network is a class of computer software that simulates humans' biological neurons (Barnett &amp; Cerf, 2017). In addition, neural networks can buttress machine learning in that they can emulate pattern recognition or match similarities in the P←→I bond as they learn to decipher a problem (Rodgers, 2020). This methodology can provide a machine-learning apparatus (supervisory or nonsupervisory) for HRM. The AI machine-learning characteristic of the TP model provides the algorithmic pathways with the proficiency to robotically learn and improve from experience (i.e., P←→I) without being openly programmed.A neural network is a class of computer software that simulates humans' biological neurons (Barnett &amp; Cerf, 2017). In addition, neural networks can buttress machine learning in that they can emulate pattern recognition or match similarities in the P←→I bond as they learn to decipher a problem (Rodgers, 2020). This methodology can provide a machine-learning apparatus (supervisory or nonsupervisory) for HRM. The AI machine-learning characteristic of the TP model provides the algorithmic pathways with the proficiency to robotically learn and improve from experience (i.e., P←→I) without being openly programmed.</p>
        <p>Likewise, information is subjectively processed by humans through the five senses: vision, hearing, touch, taste, and smell. Nonetheless, through education, training, and experience (i.e., perception), we make sense of data and arrive at a consensus in society regarding the reliability and relevance of information as it pertains to our understanding. Therefore, the first part of the model (i.e., perception←→information) suggests that perception is updated by external information. This process is similar to Bayes' Theorem, which advocates that our perception is constantly updated by incoming information. Moreover, Bayes' Theorem is at the heart of neural networks that are utilized for AI applications of deep-learning tools (Cui &amp; Wong, 2006). Furthermore, there is "no need" for a pathway from decision choice to information, since exogenous "information" is continually updated, which influences "perception." From a statistical perspective, the loop from decision choice to information is problematic, since it will produce multiple solutions unless another variable is introduced influencing the decision-choice concept (see Rodgers &amp; Housel, 1992, for a presentation/analysis of a non-recursive model). In addition, from a cognitive perspective, the P←→I neural network also suggests that "perception" influences information and that information is stored in memory (i.e., judgment) for further processing and encoding to be acted upon by compensatory or non-compensatory routines.Likewise, information is subjectively processed by humans through the five senses: vision, hearing, touch, taste, and smell. Nonetheless, through education, training, and experience (i.e., perception), we make sense of data and arrive at a consensus in society regarding the reliability and relevance of information as it pertains to our understanding. Therefore, the first part of the model (i.e., perception←→information) suggests that perception is updated by external information. This process is similar to Bayes' Theorem, which advocates that our perception is constantly updated by incoming information. Moreover, Bayes' Theorem is at the heart of neural networks that are utilized for AI applications of deep-learning tools (Cui &amp; Wong, 2006). Furthermore, there is "no need" for a pathway from decision choice to information, since exogenous "information" is continually updated, which influences "perception." From a statistical perspective, the loop from decision choice to information is problematic, since it will produce multiple solutions unless another variable is introduced influencing the decision-choice concept (see Rodgers &amp; Housel, 1992, for a presentation/analysis of a non-recursive model). In addition, from a cognitive perspective, the P←→I neural network also suggests that "perception" influences information and that information is stored in memory (i.e., judgment) for further processing and encoding to be acted upon by compensatory or non-compensatory routines.</p>
        <p>Accordingly, we conceptualize the operationalization of perception (P), information (I), judgment (J), and decision choice (D) in an HRM context. These components are also summarized in Table 2. Depending upon an individual's perspective, certain pathways may be weighted heavier or dominate other pathways. HRM managers can considerably benefit from using this model by observing what other pathways may need to be explored in order to examine and modify their decisions to determine the best outcome for their organization and employees. This fresh approach enables us to complement several "ethical" positions with inimitable decisionmaking paths leading to a decision. Nevertheless, as pointed out by Selbst et al. (2019), the unethical application of AI technology risks embellishing existing biases and inequalities within organizations. Henceforth, it is imperative that HRM leaders have an ethical framework to assess the use of new AI technologies and to entrench ethical thinking in their evaluations.Accordingly, we conceptualize the operationalization of perception (P), information (I), judgment (J), and decision choice (D) in an HRM context. These components are also summarized in Table 2. Depending upon an individual's perspective, certain pathways may be weighted heavier or dominate other pathways. HRM managers can considerably benefit from using this model by observing what other pathways may need to be explored in order to examine and modify their decisions to determine the best outcome for their organization and employees. This fresh approach enables us to complement several "ethical" positions with inimitable decisionmaking paths leading to a decision. Nevertheless, as pointed out by Selbst et al. (2019), the unethical application of AI technology risks embellishing existing biases and inequalities within organizations. Henceforth, it is imperative that HRM leaders have an ethical framework to assess the use of new AI technologies and to entrench ethical thinking in their evaluations.</p>
        <p>Furthermore, ethical considerations as part of AI can benefit everyone in society and in organizations, not just those who control it. To circumvent unethical design problems, individuals from a wide range of disciplines can contribute to the social, societal, cultural, financial, and economic contexts in which AI operates and inject ethical thinking into every stage of the process, from design to implementation.Furthermore, ethical considerations as part of AI can benefit everyone in society and in organizations, not just those who control it. To circumvent unethical design problems, individuals from a wide range of disciplines can contribute to the social, societal, cultural, financial, and economic contexts in which AI operates and inject ethical thinking into every stage of the process, from design to implementation.</p>
        <p>The TP model portrays the most influential algorithmic pathways employed to arrive at a decision choice. That is, what we hold as constructive enters into our perception, and it can, in turn, influence our judgment and decision choice. Furthermore, judgments process information sources, analyze what is suitable as information, what evidence we frame (i.e., perception), and which information is relevant to answer questions influenced by what we hold as valuable (Rodgers &amp; Gago, 2001). Decision-making in the TP model is defined here as a multi-stage, information-processing function in which cognitive, economic, political, and social components influence data to generate a set of outcomes.The TP model portrays the most influential algorithmic pathways employed to arrive at a decision choice. That is, what we hold as constructive enters into our perception, and it can, in turn, influence our judgment and decision choice. Furthermore, judgments process information sources, analyze what is suitable as information, what evidence we frame (i.e., perception), and which information is relevant to answer questions influenced by what we hold as valuable (Rodgers &amp; Gago, 2001). Decision-making in the TP model is defined here as a multi-stage, information-processing function in which cognitive, economic, political, and social components influence data to generate a set of outcomes.</p>
        <p>Perception involves the process of individuals framing their problem-solving set or view of the world. Depending upon the task at hand, this framing involves individuals' expertise in using pre-formatted knowledge to direct and guide their search and assessment of incoming information necessary for problem-solving or decision-making. Rodgers (1997) argued that perception represents a person's expertise in classifying and categorizing information. This information is converted to knowledge once it is processed in the minds of individuals, and knowledge is consequently transferred as information once it is articulated and presented in the form of text, narratives, and graphics or other symbolic forms. Information includes the set of technical, managerial, economic, political, social, and environmental information available to a decision maker for problem-solving. The judgment stage contains the process by which individuals' implement and analyze incoming information and the influences from their perception. From both these sources, rules are implemented to weigh, sort, and classify the knowledge and information for decision-making. Finally, in the decision-choice stage, an action is taken or not taken.Perception involves the process of individuals framing their problem-solving set or view of the world. Depending upon the task at hand, this framing involves individuals' expertise in using pre-formatted knowledge to direct and guide their search and assessment of incoming information necessary for problem-solving or decision-making. Rodgers (1997) argued that perception represents a person's expertise in classifying and categorizing information. This information is converted to knowledge once it is processed in the minds of individuals, and knowledge is consequently transferred as information once it is articulated and presented in the form of text, narratives, and graphics or other symbolic forms. Information includes the set of technical, managerial, economic, political, social, and environmental information available to a decision maker for problem-solving. The judgment stage contains the process by which individuals' implement and analyze incoming information and the influences from their perception. From both these sources, rules are implemented to weigh, sort, and classify the knowledge and information for decision-making. Finally, in the decision-choice stage, an action is taken or not taken.</p>
        <p>The stages of perception, information, judgment, and choice are always present in decision-making; however, their predominanceThe stages of perception, information, judgment, and choice are always present in decision-making; however, their predominance</p>
        <p>The throughput model's algorithmic pathways.The throughput model's algorithmic pathways.</p>
        <p>Primary Ethical Pathways or ordering influences decision-making. There are differences of opinion about how many stages and subroutines within stages exist and the order in which the stages occur; however, the concepts in the model proposed here appear with certain consistency in the literature (Hogarth, 1987). This model represents a parsimonious way to capture major concepts about organizations, yet it provides a more interpretative cognitive schema, in that basic information-processing modeling normally involves serial processing, whereas we take this approach one step further by assuming parallel processing. That is, the complete TP model posits that there are many (oftentimes simultaneous) pathways leading to a decision. Furthermore, this decision-making model has been shown to be useful in conceptualizing, in tandem, a number of different issues that are important to organizations (Foss &amp; Rodgers, 2011;Rodgers, 1997). It is particularly relevant for clarifying critical pathways influenced by ethical positions (Rodgers &amp; Gago, 2001).Primary Ethical Pathways or ordering influences decision-making. There are differences of opinion about how many stages and subroutines within stages exist and the order in which the stages occur; however, the concepts in the model proposed here appear with certain consistency in the literature (Hogarth, 1987). This model represents a parsimonious way to capture major concepts about organizations, yet it provides a more interpretative cognitive schema, in that basic information-processing modeling normally involves serial processing, whereas we take this approach one step further by assuming parallel processing. That is, the complete TP model posits that there are many (oftentimes simultaneous) pathways leading to a decision. Furthermore, this decision-making model has been shown to be useful in conceptualizing, in tandem, a number of different issues that are important to organizations (Foss &amp; Rodgers, 2011;Rodgers, 1997). It is particularly relevant for clarifying critical pathways influenced by ethical positions (Rodgers &amp; Gago, 2001).</p>
        <p>There are six algorithmic pathways influenced by the ethical positions a decision maker can use. Table 2 illustrates the six algorithmic pathways, which are ethical egoism-preference based (P→D), deontology-rule based (P→J→D), utilitarianism-principle based (I→J→D), relativism (I→P→D), virtue ethics (P→I → J→D), and ethics of care (Stakeholder's perspective) I→P → J→D (Rodgers, 2009;Rodgers &amp; Gago, 2001). These algorithmic pathways can assist in machine learning by providing computer apparatuses with the ability to learn ethical foundations without specific programming.There are six algorithmic pathways influenced by the ethical positions a decision maker can use. Table 2 illustrates the six algorithmic pathways, which are ethical egoism-preference based (P→D), deontology-rule based (P→J→D), utilitarianism-principle based (I→J→D), relativism (I→P→D), virtue ethics (P→I → J→D), and ethics of care (Stakeholder's perspective) I→P → J→D (Rodgers, 2009;Rodgers &amp; Gago, 2001). These algorithmic pathways can assist in machine learning by providing computer apparatuses with the ability to learn ethical foundations without specific programming.</p>
        <p>The six dominant ethical algorithmic pathways that influence a decision choice (Rodgers, 2009) 1 reflect the problem statement in the introduction, whereby the modeling process may help arrest problems of transmitting and receiving HRM knowledge and information due to organizations seeking different and comparative ethical solutions to a problem.The six dominant ethical algorithmic pathways that influence a decision choice (Rodgers, 2009) 1 reflect the problem statement in the introduction, whereby the modeling process may help arrest problems of transmitting and receiving HRM knowledge and information due to organizations seeking different and comparative ethical solutions to a problem.</p>
        <p>The TP model offers insights from social psychology into a descriptive model of how HRM managers make decisions. More specifically, the TP model helps identify and explain the impact of perceptions of the HRM situation (e.g., environmental contextual features, employer organizational characteristics) on the HRM process. The multiple objectives of organizations can be incorporated into AI decision-making. An analysis of the decision intent and anticipated outcome will help HRM practitioners understand the pathways to an organizational decision. Understanding the ethical pathways will give HRM practitioners insight as to whether the organization's goals and objectives are reflected in evaluating or implementing AI decision-making systems. Between the four components outlined above (I, P, J, D), this model highlights six critical pathways in the decision-making process, eliminating rival alternative hypotheses. These pathways, which have been associated with six theories of ethical behavior (Rodgers et al., 2009;Rodgers &amp; Gago, 2001), are as follows.The TP model offers insights from social psychology into a descriptive model of how HRM managers make decisions. More specifically, the TP model helps identify and explain the impact of perceptions of the HRM situation (e.g., environmental contextual features, employer organizational characteristics) on the HRM process. The multiple objectives of organizations can be incorporated into AI decision-making. An analysis of the decision intent and anticipated outcome will help HRM practitioners understand the pathways to an organizational decision. Understanding the ethical pathways will give HRM practitioners insight as to whether the organization's goals and objectives are reflected in evaluating or implementing AI decision-making systems. Between the four components outlined above (I, P, J, D), this model highlights six critical pathways in the decision-making process, eliminating rival alternative hypotheses. These pathways, which have been associated with six theories of ethical behavior (Rodgers et al., 2009;Rodgers &amp; Gago, 2001), are as follows.</p>
        <p>(1) P→D algorithm encapsulates ethical egoism: In this algorithmic pathway, an action is considered ethically correct when it maximizes one's self-interest (Rodgers et al., 2009;Rodgers &amp; Gago, 2001). According to this reasoning, the decision is based on the perceived circumstance, downplaying any relevant information and judgment. Thus, the decision maker's perception directly influences the decision. Generally, ethical egoism (or psychological egoism in psychology or utility-based in economics/finance) suggests that P→D is the appropriate algorithmic pathway, since "perception" encapsulates one's wants, needs, and desires. These wants, needs, and desires are shaped by experience, training, and education. It is not that information does not exist, but it is downplayed due to the dominance of perception over information (see Rodgers &amp; Gago, 2001, 2003, 2004). For example, based on parental experiences, parents may tell their children that they cannot play after school until they have finished their homework. Here, the parent believes that s/he knows what is best for the children. There are many situations whereby information is either fragmented or incomplete, or where there is too much noise or disturbance in the information channel, hence one's perception dominates.(1) P→D algorithm encapsulates ethical egoism: In this algorithmic pathway, an action is considered ethically correct when it maximizes one's self-interest (Rodgers et al., 2009;Rodgers &amp; Gago, 2001). According to this reasoning, the decision is based on the perceived circumstance, downplaying any relevant information and judgment. Thus, the decision maker's perception directly influences the decision. Generally, ethical egoism (or psychological egoism in psychology or utility-based in economics/finance) suggests that P→D is the appropriate algorithmic pathway, since "perception" encapsulates one's wants, needs, and desires. These wants, needs, and desires are shaped by experience, training, and education. It is not that information does not exist, but it is downplayed due to the dominance of perception over information (see Rodgers &amp; Gago, 2001, 2003, 2004). For example, based on parental experiences, parents may tell their children that they cannot play after school until they have finished their homework. Here, the parent believes that s/he knows what is best for the children. There are many situations whereby information is either fragmented or incomplete, or where there is too much noise or disturbance in the information channel, hence one's perception dominates.</p>
        <p>(2) P→J→D algorithm portrays the deontology position: In this algorithmic pathway, the decision maker is committed to independent moral rules or duties and, thus, equal respect is devoted to all individuals. The focus is on taking the right actions, rather than on the consequences of the actions in this pathway, rules and laws are framed (P), and a judgment (J) is made before a decision is made (D). This position portrays the deontological perspective (see Guiral et al., 2015;Guiral, Rodgers, Ruiz, &amp; Gonzalo-Angulo, 2010;Rodgers &amp; Gago, 2001). In most cases, rules, procedures, guidelines, and laws are encapsulated in one's perception to be analyzed (i.e., judgment) before making a decision choice. For example, when people drive, they do not have a set of rules written down before them. That is, the duality of physically controlling the mechanics of a vehicle and processing the observation and compliance with traffic rules are embedded in people's perceptions whilst driving (and is not a single process of reading instructions and rules).(2) P→J→D algorithm portrays the deontology position: In this algorithmic pathway, the decision maker is committed to independent moral rules or duties and, thus, equal respect is devoted to all individuals. The focus is on taking the right actions, rather than on the consequences of the actions in this pathway, rules and laws are framed (P), and a judgment (J) is made before a decision is made (D). This position portrays the deontological perspective (see Guiral et al., 2015;Guiral, Rodgers, Ruiz, &amp; Gonzalo-Angulo, 2010;Rodgers &amp; Gago, 2001). In most cases, rules, procedures, guidelines, and laws are encapsulated in one's perception to be analyzed (i.e., judgment) before making a decision choice. For example, when people drive, they do not have a set of rules written down before them. That is, the duality of physically controlling the mechanics of a vehicle and processing the observation and compliance with traffic rules are embedded in people's perceptions whilst driving (and is not a single process of reading instructions and rules).</p>
        <p>(3) I→J→D algorithm denotes the utilitarian position: This algorithmic pathway emphasizes the maximization of the good and the minimization of harm to a society. Therefore, available information (I) is used in an objective manner throughout the analysis (J) before a decision is made (D). The decision maker's perception (P) is not considered. Guiral et al. (2010Guiral et al. ( , 2015) ) advocated that I → J → D reflects the utilitarian position, which is concerned with consequences, as well as the greatest good for the greatest number of people. Further, Rodgers and Gago (2001, p. 362) advocated that "utilitarianism is generally traced to Jeremy Bentham (1748-1832) who 1 For example, the preference-based ethical pathway (P→D) shows only the direct impact of perception on the decision. In addition, the rule-based ethical pathway (P→J→D) contains the direct impact of perception on judgment and the direct impact of the judgment on the decision. These two relationships represent the indirect impact of perception on the decision through judgment. The same is true with the principles-based ethical pathway (I→J→D), which represents the indirect impact of information on the decision through the judgment stage (Rodgers &amp; Al Fayi, 2019). The remaining three secondary algorithmic pathways build upon the preference-based algorithm (P→D), which advances to relativism-based (I→P→D). Next, the principles-based algorithm (I→J→D) forwards to virtue-based (P→I→J→D). Finally, the rule-based algorithm evolves into the ethics of care-based algorithm (I→P→J→D). sought an objective basis for making value judgments that would provide a common and publicly acceptable norm for determining social policy and social legislation" (see Bentham, 1962). This position is committed to the maximization of the good and the minimization of harm and evil. Furthermore, this theory advocates that society should always produce the greatest possible balance of positive value or the minimum balance of negative value for all individuals affected. Therefore, the utilitarian principle infers that quantities of benefits produced by an action can be measured and added, and the quantities of harm can be measured and subtracted. This will determine which action produces the greatest total benefits or the lowest total costs. Finally, this process is considered a backward-chain from a consequentialist viewpoint, as opposed to a forward-chain process indicated by a rule-based or nonconsequentialist perspective.(3) I→J→D algorithm denotes the utilitarian position: This algorithmic pathway emphasizes the maximization of the good and the minimization of harm to a society. Therefore, available information (I) is used in an objective manner throughout the analysis (J) before a decision is made (D). The decision maker's perception (P) is not considered. Guiral et al. (2010Guiral et al. ( , 2015) ) advocated that I → J → D reflects the utilitarian position, which is concerned with consequences, as well as the greatest good for the greatest number of people. Further, Rodgers and Gago (2001, p. 362) advocated that "utilitarianism is generally traced to Jeremy Bentham (1748-1832) who 1 For example, the preference-based ethical pathway (P→D) shows only the direct impact of perception on the decision. In addition, the rule-based ethical pathway (P→J→D) contains the direct impact of perception on judgment and the direct impact of the judgment on the decision. These two relationships represent the indirect impact of perception on the decision through judgment. The same is true with the principles-based ethical pathway (I→J→D), which represents the indirect impact of information on the decision through the judgment stage (Rodgers &amp; Al Fayi, 2019). The remaining three secondary algorithmic pathways build upon the preference-based algorithm (P→D), which advances to relativism-based (I→P→D). Next, the principles-based algorithm (I→J→D) forwards to virtue-based (P→I→J→D). Finally, the rule-based algorithm evolves into the ethics of care-based algorithm (I→P→J→D). sought an objective basis for making value judgments that would provide a common and publicly acceptable norm for determining social policy and social legislation" (see Bentham, 1962). This position is committed to the maximization of the good and the minimization of harm and evil. Furthermore, this theory advocates that society should always produce the greatest possible balance of positive value or the minimum balance of negative value for all individuals affected. Therefore, the utilitarian principle infers that quantities of benefits produced by an action can be measured and added, and the quantities of harm can be measured and subtracted. This will determine which action produces the greatest total benefits or the lowest total costs. Finally, this process is considered a backward-chain from a consequentialist viewpoint, as opposed to a forward-chain process indicated by a rule-based or nonconsequentialist perspective.</p>
        <p>(4) I→P→D algorithm indicates the relativism position: This algorithmic pathway considers ethical standards based on the decision makers themselves or the people around them. In this light, ethical beliefs are not absolute but depend on circumstances. Therefore, available information (I) influences individual perception (P) before a decision is reached (D). Rodgers and Gago (2001, p. 361) argued that "I→P→D highpoints the relativist perspective, which assumes that decision makers use themselves or the people surrounding them as their foundation for describing ethical standards. They observe the dealings of members of some applicable group and endeavor to ascertain the group consensus on a given behaviour. Relativism acknowledges that people live in a society in which they have different views and positions in order to validate decisions as right or wrong. Therefore, ethical relativists uphold that all ethical beliefs and values are relative to one's own culture, feelings, or religion."(4) I→P→D algorithm indicates the relativism position: This algorithmic pathway considers ethical standards based on the decision makers themselves or the people around them. In this light, ethical beliefs are not absolute but depend on circumstances. Therefore, available information (I) influences individual perception (P) before a decision is reached (D). Rodgers and Gago (2001, p. 361) argued that "I→P→D highpoints the relativist perspective, which assumes that decision makers use themselves or the people surrounding them as their foundation for describing ethical standards. They observe the dealings of members of some applicable group and endeavor to ascertain the group consensus on a given behaviour. Relativism acknowledges that people live in a society in which they have different views and positions in order to validate decisions as right or wrong. Therefore, ethical relativists uphold that all ethical beliefs and values are relative to one's own culture, feelings, or religion."</p>
        <p>(5) P→I→J→D algorithm describes the virtue ethics position: This algorithmic pathway does not consider what makes a good action, but instead focuses on how a good person makes a decision choice. Perception (P) thus influences the selection process of the information (I), ensuring that the selected information is consistent with being a good person. This leads to the judgment stage (J), en route to a decision (D). ( 6) I→P→J→D algorithm depicts the ethics of care position: This algorithmic pathway assumes that people are willing to listen to distinct and previously unacknowledged perspectives. Thus, all relevant information (I) is considered, and it influences perception (P). The resulting perceptions are analyzed in a judgment (J), en route to a decision (D). Rodgers and Gago (2001, p. 364) maintained that "I→P→J→D represents the ethics of care philosophy, which focuses on a set of character traits that are deeply valued in close personal relationships, such as sympathy, compassion, fidelity, love, friendship, and the like. This algorithm represents the last possible fragmented way for individuals' cognitive processes. In this sequence, an individual studies the given information, frames the problem, and then proceeds to analyze the problem before rendering a decision. Information guides an individual's perceptual perspective. That is, the ethics of care philosophy incorporates a willingness to listen to distinct and previously ignored or unaccustomed viewpoints."(5) P→I→J→D algorithm describes the virtue ethics position: This algorithmic pathway does not consider what makes a good action, but instead focuses on how a good person makes a decision choice. Perception (P) thus influences the selection process of the information (I), ensuring that the selected information is consistent with being a good person. This leads to the judgment stage (J), en route to a decision (D). ( 6) I→P→J→D algorithm depicts the ethics of care position: This algorithmic pathway assumes that people are willing to listen to distinct and previously unacknowledged perspectives. Thus, all relevant information (I) is considered, and it influences perception (P). The resulting perceptions are analyzed in a judgment (J), en route to a decision (D). Rodgers and Gago (2001, p. 364) maintained that "I→P→J→D represents the ethics of care philosophy, which focuses on a set of character traits that are deeply valued in close personal relationships, such as sympathy, compassion, fidelity, love, friendship, and the like. This algorithm represents the last possible fragmented way for individuals' cognitive processes. In this sequence, an individual studies the given information, frames the problem, and then proceeds to analyze the problem before rendering a decision. Information guides an individual's perceptual perspective. That is, the ethics of care philosophy incorporates a willingness to listen to distinct and previously ignored or unaccustomed viewpoints."</p>
        <p>The authors further stated on p. 364 that, "In the I→P→J→D pathway, information dominates the perception in an 'open-minded' individual. The judgments used to decide on will be the result of the perceptions that the individual produced as a result of the information. The 'altruism' is modeled in this model by the information available to decide on."The authors further stated on p. 364 that, "In the I→P→J→D pathway, information dominates the perception in an 'open-minded' individual. The judgments used to decide on will be the result of the perceptions that the individual produced as a result of the information. The 'altruism' is modeled in this model by the information available to decide on."</p>
        <p>In summary, HRM practitioners can be assisted by understanding the AI tools utilized in programming parameters that may incorporate biases, such as gender, age, race, school attended, etc. (Upadhyay &amp; Khandelwal, 2018). Therefore, biases can be depicted from two major progenies in establishing an HRM AI algorithmic system, which are type 1 and 2 errors (Rodgers, 2020). Type 1 and type 2 errors may occur due to the design and programming bias of the AI system (observer, instrument, recall, etc.). Hence, in practical terms, this research paper has identified applicable ethical algorithmic pathways to implement to address type 1 and type 2 errors. Type 1 errors may fuel inefficiencies and increase transaction costs, which can cause inadequate algorithms, as depicted by anIn summary, HRM practitioners can be assisted by understanding the AI tools utilized in programming parameters that may incorporate biases, such as gender, age, race, school attended, etc. (Upadhyay &amp; Khandelwal, 2018). Therefore, biases can be depicted from two major progenies in establishing an HRM AI algorithmic system, which are type 1 and 2 errors (Rodgers, 2020). Type 1 and type 2 errors may occur due to the design and programming bias of the AI system (observer, instrument, recall, etc.). Hence, in practical terms, this research paper has identified applicable ethical algorithmic pathways to implement to address type 1 and type 2 errors. Type 1 errors may fuel inefficiencies and increase transaction costs, which can cause inadequate algorithms, as depicted by an</p>
        <p>Appropriate people in the same social networks (i.e., sharing some common experience, tradition, education, customs, culture, religion, etc.). Others are NOT allowed to share benefits and opportunities, as suggested from the HRM AI algorithms.Appropriate people in the same social networks (i.e., sharing some common experience, tradition, education, customs, culture, religion, etc.). Others are NOT allowed to share benefits and opportunities, as suggested from the HRM AI algorithms.</p>
        <p>The wrong people in the same social networks (i.e., sharing some common experience, tradition, education, customs, culture, religion, etc.) are ALLOWED to share benefits and opportunities as suggested from the HRM AI algorithms.The wrong people in the same social networks (i.e., sharing some common experience, tradition, education, customs, culture, religion, etc.) are ALLOWED to share benefits and opportunities as suggested from the HRM AI algorithms.</p>
        <p>Employees DENIED promotion, hiring, etc. opportunities due to overly critical use of supporting information sources (e.g., social media) for reliability and relevance implemented in HRM AI algorithms.Employees DENIED promotion, hiring, etc. opportunities due to overly critical use of supporting information sources (e.g., social media) for reliability and relevance implemented in HRM AI algorithms.</p>
        <p>Employees ENDOWED with opportunities due to weak supporting and relevant information implemented in HRM AI algorithms.Employees ENDOWED with opportunities due to weak supporting and relevant information implemented in HRM AI algorithms.</p>
        <p>Personnel DENIED promotion, hiring, etc. opportunities due to overly critical formal structures, judging individual attributes executed in HRM AI algorithms.Personnel DENIED promotion, hiring, etc. opportunities due to overly critical formal structures, judging individual attributes executed in HRM AI algorithms.</p>
        <p>Personnel ENDOWED with opportunities due to weak formal structures, judging individual attributes executed in HRM AI algorithms.Personnel ENDOWED with opportunities due to weak formal structures, judging individual attributes executed in HRM AI algorithms.</p>
        <p>Workforce DENIED promotion, hiring, etc. opportunities due to the overly critical evaluation of relevant and reliable information about others to understand them and accurately predict their likely behavior via HRM AI algorithms.Workforce DENIED promotion, hiring, etc. opportunities due to the overly critical evaluation of relevant and reliable information about others to understand them and accurately predict their likely behavior via HRM AI algorithms.</p>
        <p>Workforce ENDOWED with opportunities due to a weak evaluation of relevant and reliable information about others to understand them and accurately predict their likely behavior via HRM AI algorithms.Workforce ENDOWED with opportunities due to a weak evaluation of relevant and reliable information about others to understand them and accurately predict their likely behavior via HRM AI algorithms.</p>
        <p>AI system. Likewise, the insertion of a type 2 error may engender inappropriate workforce individuals to receive opportunities (see Table 3). In selecting a particular HRM algorithmic pathway, organizations can utilize a cost-benefit analysis to control for type 1 and type 2 errors. Features, such as the size of the company, and budgetary and regulatory constraints, will factor into the decision-making processes in employing the appropriate AI algorithmic pathway for HRM design.AI system. Likewise, the insertion of a type 2 error may engender inappropriate workforce individuals to receive opportunities (see Table 3). In selecting a particular HRM algorithmic pathway, organizations can utilize a cost-benefit analysis to control for type 1 and type 2 errors. Features, such as the size of the company, and budgetary and regulatory constraints, will factor into the decision-making processes in employing the appropriate AI algorithmic pathway for HRM design.</p>
        <p>Forming decisions is the process of assessing how a particular action was initiated, with an evaluation of anticipated results versus measured results. Evaluating decision results is framed by the intent of the decision maker and is a measured variable that can be defined by the decision maker's priorities (e.g., profit or performance). Individuals have a "legitimate interest in knowing who to hold accountable" for AI-based decision-making (Hermann, 2021, p.10), which requires an understanding of the hierarchy levels of decision-making in organizations. The organizational culture may direct the ethical positionality of decision-making and influence accountability in the use of AI decision-making. Understanding the context and characteristics of the organization's decision makers (Prikshat et al., 2021) will help HRM practitioners to assess the interface of ethics in AI-generated HRM decisions. Incorporation of the TP model in AI system analysis with variables weighted in qualitative and quantitative data can provide an opportunity for HRM practitioners to account for decision outcomes.Forming decisions is the process of assessing how a particular action was initiated, with an evaluation of anticipated results versus measured results. Evaluating decision results is framed by the intent of the decision maker and is a measured variable that can be defined by the decision maker's priorities (e.g., profit or performance). Individuals have a "legitimate interest in knowing who to hold accountable" for AI-based decision-making (Hermann, 2021, p.10), which requires an understanding of the hierarchy levels of decision-making in organizations. The organizational culture may direct the ethical positionality of decision-making and influence accountability in the use of AI decision-making. Understanding the context and characteristics of the organization's decision makers (Prikshat et al., 2021) will help HRM practitioners to assess the interface of ethics in AI-generated HRM decisions. Incorporation of the TP model in AI system analysis with variables weighted in qualitative and quantitative data can provide an opportunity for HRM practitioners to account for decision outcomes.</p>
        <p>Due the opacity of algorithms in AI systems, HRM practitioners need to mediate between "both low and high levels of human involvement in decision-making" (Bader &amp; Kaiser, 2019, p. 656) to fully account for HRM decisions. Processes organizing the interactions between people and their organizations are integral when considering AI (Hermann, 2021), and we develop research to further address this by proposing the use of the TP model to look at the organizational level of AI decision-making and the organizational environment generating decision-making pathways. This level of human involvement is dependent on the decision maker's understanding of their objectives and anticipated outcomes, framed by the organizational decision hierarchy, and originating from the social, economic, and natural environment of the organization and the decision maker. The decision-making process in organizations can be split into a hierarchy of three layers:Due the opacity of algorithms in AI systems, HRM practitioners need to mediate between "both low and high levels of human involvement in decision-making" (Bader &amp; Kaiser, 2019, p. 656) to fully account for HRM decisions. Processes organizing the interactions between people and their organizations are integral when considering AI (Hermann, 2021), and we develop research to further address this by proposing the use of the TP model to look at the organizational level of AI decision-making and the organizational environment generating decision-making pathways. This level of human involvement is dependent on the decision maker's understanding of their objectives and anticipated outcomes, framed by the organizational decision hierarchy, and originating from the social, economic, and natural environment of the organization and the decision maker. The decision-making process in organizations can be split into a hierarchy of three layers:</p>
        <p>1. Strategic (to achieve an overall objective). 2. Tactical (to modify to align with changes in the environment).1. Strategic (to achieve an overall objective). 2. Tactical (to modify to align with changes in the environment).</p>
        <p>Within an AI deep neural network, decision outcomes are continually fed back to the organizational environment and decision pathway in a continuous loop of reinforcement learning, with the flexibility of decision processing being dependent on experience from previous decisions.Within an AI deep neural network, decision outcomes are continually fed back to the organizational environment and decision pathway in a continuous loop of reinforcement learning, with the flexibility of decision processing being dependent on experience from previous decisions.</p>
        <p>Adoption of the TP model ethical pathways in AI decision processing is represented by the neural network diagram illustrated in Fig. 2, with the "learning" component illustrated by the arrow direction.Adoption of the TP model ethical pathways in AI decision processing is represented by the neural network diagram illustrated in Fig. 2, with the "learning" component illustrated by the arrow direction.</p>
        <p>An AI algorithmic ethics framework must be the foundation on which any AI technology is fashioned and implemented. Nonetheless, even in its presence, it may be a while before bias can be entirely addressed in the execution of AI-powered solutions for HRM.An AI algorithmic ethics framework must be the foundation on which any AI technology is fashioned and implemented. Nonetheless, even in its presence, it may be a while before bias can be entirely addressed in the execution of AI-powered solutions for HRM.</p>
        <p>In addition, such a framework can assist organizations in creating AI technologies to minimize, if not eliminate, bias in their algorithms. Combined with human intervention, AI applications can spearhead unbiased recruitment, merits, promotions, and quality hiring. Table 4 provides an overlay of strengths and weaknesses when applying different AI ethical algorithmic pathways in an organization's HRM system.In addition, such a framework can assist organizations in creating AI technologies to minimize, if not eliminate, bias in their algorithms. Combined with human intervention, AI applications can spearhead unbiased recruitment, merits, promotions, and quality hiring. Table 4 provides an overlay of strengths and weaknesses when applying different AI ethical algorithmic pathways in an organization's HRM system.</p>
        <p>HRM practitioners can evaluate the extent of their attachment and detachment from AI-generated decisions (Bader &amp; Kaiser, 2019) by giving weight to the influencing variables to a decision. Mechanisms depicting the flow of data and the use of AI techniques (Prikshat et al., 2021) help HRM practitioners not only in terms of intelligibility, but also in terms of communicating accountability. The awareness and evaluation stage of the HRM (AI) framework proposed by Prikshat et al. (2021) can initiate an HRM analysis of intentions with anticipated outcomes utilizing AI systems prior to any commitment regarding adoption. Using the TP model, postdecision outcomes can be analyzed to determine which ethical pathways are to be taken, and whether these pathways support the delivery of the organization's goals.HRM practitioners can evaluate the extent of their attachment and detachment from AI-generated decisions (Bader &amp; Kaiser, 2019) by giving weight to the influencing variables to a decision. Mechanisms depicting the flow of data and the use of AI techniques (Prikshat et al., 2021) help HRM practitioners not only in terms of intelligibility, but also in terms of communicating accountability. The awareness and evaluation stage of the HRM (AI) framework proposed by Prikshat et al. (2021) can initiate an HRM analysis of intentions with anticipated outcomes utilizing AI systems prior to any commitment regarding adoption. Using the TP model, postdecision outcomes can be analyzed to determine which ethical pathways are to be taken, and whether these pathways support the delivery of the organization's goals.</p>
        <p>HRM practitioners can help in interpreting and contextualizing different HR activities (Prikshat et al., 2021). Evaluating decisionmaking by employees as a consequence of algorithm-driven decision-making and contextualizing the environmental antecedents (social, economic, physical) within the organizational decision hierarchy will help HRM practitioners assist management in interpreting decision outcomes. We propose that organizations should identify their ethical position on specific HRM activities first (with a focus on agility and scenario planning), and then analyze whether this is reflected in AI-driven HRM activities. Reflecting on accountability, the decision level within the organization, and the organization's goals and objectives will guide HRM practitioners as to whether a specific decision path is to be taken or not, raising questions as to the decision-making impact of AI-driven HRM decisions on the organization.HRM practitioners can help in interpreting and contextualizing different HR activities (Prikshat et al., 2021). Evaluating decisionmaking by employees as a consequence of algorithm-driven decision-making and contextualizing the environmental antecedents (social, economic, physical) within the organizational decision hierarchy will help HRM practitioners assist management in interpreting decision outcomes. We propose that organizations should identify their ethical position on specific HRM activities first (with a focus on agility and scenario planning), and then analyze whether this is reflected in AI-driven HRM activities. Reflecting on accountability, the decision level within the organization, and the organization's goals and objectives will guide HRM practitioners as to whether a specific decision path is to be taken or not, raising questions as to the decision-making impact of AI-driven HRM decisions on the organization.</p>
        <p>Recent research suggests that practical guidance on how to address incorporating principals into AI practice is required (Hermann, 2021). The development of the TP model within a framework to incorporate influencing components, such as the environment, time, or the organizational level impacting decision choice, will help HRM practitioners to more fully account for the incorporation of ethical principles into AI decision outcomes.Recent research suggests that practical guidance on how to address incorporating principals into AI practice is required (Hermann, 2021). The development of the TP model within a framework to incorporate influencing components, such as the environment, time, or the organizational level impacting decision choice, will help HRM practitioners to more fully account for the incorporation of ethical principles into AI decision outcomes.</p>
        <p>The positioning of the organization and the decision maker when determining the intention and anticipation of an HRM decision outcome is framed by components that are both static and fluid, requiring an understanding of relationships with other disciplines. Each of the economic, social, and physical environments of the organization or decision maker may be impacted by changes, impacting the quality or perception of the information available. Decision intent is framed by the anticipation of potential decision outcomes. In addition, the intent requiring a decision is influenced by the environment of the organization and the decision maker (social, economic, physical environment). The quality and weight given to the data of this environmental variable trigger the perception of, and information available to, the decision maker. As discussed earlier, the decision maker's decision pathway is a result of their priorities and ethical position; however, assessment by the decision maker of their decision pathway is also impacted by a time-based variable, that is, "time pressure" and "time restoration" impact decision choice. Deadlines for a decision may influence the decision maker to follow a particular ethical pathway; however, a restoration in time may allow the decision maker to reflect on and adopt an alternative pathway dependent on the decision to be made. Attributing weight to data in each variable in the journey to a decision can be compared to operating the dashboard controls of a car while reacting to constantly changing information. As each variable on the "dashboard" is adjusted, the journey to the decision outcome can be measured and assessed. The decision hierarchy frames the level of decision using the dashboard, responding to changes resulting from the environmental variable (information and perception). For instance:The positioning of the organization and the decision maker when determining the intention and anticipation of an HRM decision outcome is framed by components that are both static and fluid, requiring an understanding of relationships with other disciplines. Each of the economic, social, and physical environments of the organization or decision maker may be impacted by changes, impacting the quality or perception of the information available. Decision intent is framed by the anticipation of potential decision outcomes. In addition, the intent requiring a decision is influenced by the environment of the organization and the decision maker (social, economic, physical environment). The quality and weight given to the data of this environmental variable trigger the perception of, and information available to, the decision maker. As discussed earlier, the decision maker's decision pathway is a result of their priorities and ethical position; however, assessment by the decision maker of their decision pathway is also impacted by a time-based variable, that is, "time pressure" and "time restoration" impact decision choice. Deadlines for a decision may influence the decision maker to follow a particular ethical pathway; however, a restoration in time may allow the decision maker to reflect on and adopt an alternative pathway dependent on the decision to be made. Attributing weight to data in each variable in the journey to a decision can be compared to operating the dashboard controls of a car while reacting to constantly changing information. As each variable on the "dashboard" is adjusted, the journey to the decision outcome can be measured and assessed. The decision hierarchy frames the level of decision using the dashboard, responding to changes resulting from the environmental variable (information and perception). For instance:</p>
        <p>Strategic decision = travel from A to B. Tactical decision = truck. Operational decision = operating brakes/steering, etc. A simple HRM example is illustrated below: Strategic decision: senior HRM allocation of financial resources Tactical decision: HRM investment in appropriate communication software Operational decision: HRM engagement with workforce operation of software Each of these decisions is impacted by the environmental variable and time pressure or time restoration, and these will impact the information and perception catalysts for the ethical pathway to a decision choice. Specifically:Strategic decision = travel from A to B. Tactical decision = truck. Operational decision = operating brakes/steering, etc. A simple HRM example is illustrated below: Strategic decision: senior HRM allocation of financial resources Tactical decision: HRM investment in appropriate communication software Operational decision: HRM engagement with workforce operation of software Each of these decisions is impacted by the environmental variable and time pressure or time restoration, and these will impact the information and perception catalysts for the ethical pathway to a decision choice. Specifically:</p>
        <p>Physical environment (working in the office 'v' working from home) Social environment (group work 'v' individual processing) Economic environment (economic downturn 'v' niche service demand) As AI is incorporated into the decision process, the journey from the weighting of data through to the decision choice evolutionary algorithms, from machine learning through to deep learning in a deep neural network, requires a framework in order for HRM practitioners to more fully understand and account for the ethical pathway to a decision choice. The evolution of the TP model within a framework "
            <rs type="software">dashboard</rs>" to account for AI decision-making is illustrated in Fig. 3, with the sequential process explained in Table 5.
        </p>
        <p>Organizational leaders and HRM practitioners who are considering adopting AI or who are in the process of evaluating or implementing existing solutions can follow the sequential process in Table 5 and Fig. 3 as an analytical guideline for evaluating ethical incorporation into algorithmic decision-making. By giving weight to variables within the ethical framework of the TP model within the Decision Dashboard, each variable on the "dashboard" is adjusted on the journey to the decision outcome, which can be measured and assessed. These variables will have both static and fluid positions, impacting the decision process and accountability. However, by using RCA with the Decision Dashboard, HRM practitioners can assess the weight given to the sequence of components resulting in a particular AI decision outcome, and also evaluate the extent of their attachment and detachment from these decisions.Organizational leaders and HRM practitioners who are considering adopting AI or who are in the process of evaluating or implementing existing solutions can follow the sequential process in Table 5 and Fig. 3 as an analytical guideline for evaluating ethical incorporation into algorithmic decision-making. By giving weight to variables within the ethical framework of the TP model within the Decision Dashboard, each variable on the "dashboard" is adjusted on the journey to the decision outcome, which can be measured and assessed. These variables will have both static and fluid positions, impacting the decision process and accountability. However, by using RCA with the Decision Dashboard, HRM practitioners can assess the weight given to the sequence of components resulting in a particular AI decision outcome, and also evaluate the extent of their attachment and detachment from these decisions.</p>
        <p>The adoption of some AI technologies may challenge HRM in developing talent and career paths while achieving an organization's goals and objectives. It is reasonable for one of the organization's objectives to be to maintain cashflow and productivity by incorporating new AI technology; however, the use of the technology may reduce the workforce (World Economic Forum, 2018) and prohibit career development options (e.g., company accountant replaced with cloud-based accounting subscription service). Recent research by Nguyen and Malik (2021a, p. 21) reports how "reliability, flexibility and timeliness are the three dimensions of an AI system that frequently need to be checked to support the knowledge sharing process among employees." The time component affecting decision-making is reflected in the TP model's Decision Dashboard, allowing HRM practitioners to help determine if time is a factor affecting whether one decision pathway is chosen over another.The adoption of some AI technologies may challenge HRM in developing talent and career paths while achieving an organization's goals and objectives. It is reasonable for one of the organization's objectives to be to maintain cashflow and productivity by incorporating new AI technology; however, the use of the technology may reduce the workforce (World Economic Forum, 2018) and prohibit career development options (e.g., company accountant replaced with cloud-based accounting subscription service). Recent research by Nguyen and Malik (2021a, p. 21) reports how "reliability, flexibility and timeliness are the three dimensions of an AI system that frequently need to be checked to support the knowledge sharing process among employees." The time component affecting decision-making is reflected in the TP model's Decision Dashboard, allowing HRM practitioners to help determine if time is a factor affecting whether one decision pathway is chosen over another.</p>
        <p>An analysis of organizational decisions using the TP ethical algorithms within the Decision Dashboard provides the opportunity for HRM to analyze the ethical position and impact at each organizational level and whether time or environmental components affect the decision choice and outcome.An analysis of organizational decisions using the TP ethical algorithms within the Decision Dashboard provides the opportunity for HRM to analyze the ethical position and impact at each organizational level and whether time or environmental components affect the decision choice and outcome.</p>
        <p>An example of an HRM-based decision focused on staff training and development is that of an architectural firm required to use building information modeling (BIM) software in order for the firm to be retained on procurement consortiums. This investment, requiring staff development to operate it, may result in unanticipated outcomes due to a time pressure variable driven by a senior management-level decision for software adoption, raising questions about the awareness and skills at every level of the organization. Unanticipated outcomes may manifest only when the design project is on site (e.g., overly complex construction details relative to current market resources) as a result of the experience and knowledge of older management not being incorporated into the AI algorithms incorporated within the software operated by more junior staff.An example of an HRM-based decision focused on staff training and development is that of an architectural firm required to use building information modeling (BIM) software in order for the firm to be retained on procurement consortiums. This investment, requiring staff development to operate it, may result in unanticipated outcomes due to a time pressure variable driven by a senior management-level decision for software adoption, raising questions about the awareness and skills at every level of the organization. Unanticipated outcomes may manifest only when the design project is on site (e.g., overly complex construction details relative to current market resources) as a result of the experience and knowledge of older management not being incorporated into the AI algorithms incorporated within the software operated by more junior staff.</p>
        <p>The strategic decision intent in this scenario was driven by the economic environmental variable to retain contract opportunities,The strategic decision intent in this scenario was driven by the economic environmental variable to retain contract opportunities,</p>
        <p>The decision dashboard.The decision dashboard.</p>
        <p>Decision question process (follow the decision dashboard diagram arrows):Decision question process (follow the decision dashboard diagram arrows):</p>
        <p>1. What is the organizational intent? What are the strategic decisions to achieve the overall objectives? What are the tactical and operational decisions required to react to changes in environmental data? 2. What is the time pressure on the decision, and is there time restoration to revisit the decision analysis? 3. What is the status of the economic, social, and physical environments affecting each level of decision to achieve the anticipated decision outcomes? These may not be static and will have consequences on the quality of information and perception. 4. Which ethical pathway (preferences, rules, and principles) influences the decision-making organization and actors? 5. Decision is chosen and implemented. 6. Root-cause analysis of the decision outcome. 7. Repeat, incorporating changes in environmental data for incorporation into a deep neural network. and it was taken under time pressure, with management not fully aware of the time restoration required to develop staff training. The decision by management may be based on an anthropomorphized perception of AI processes (Bankins &amp; Formosa, 2020), as opposed to an information-based decision. Operational-based judgment may have followed an analytical utilitarianism pathway driven by a peerrestricted social environment within the office, with outcome decisions replicated with consequential damage to the organization's reputation. In this scenario, HRM's use of the TP model within the Decision Dashboard would positively help this organization to develop the office social environment demographics, analyze perceptions held by the organizational hierarchy and their sharing of information to develop junior career training, and coordinate time management to implement change.1. What is the organizational intent? What are the strategic decisions to achieve the overall objectives? What are the tactical and operational decisions required to react to changes in environmental data? 2. What is the time pressure on the decision, and is there time restoration to revisit the decision analysis? 3. What is the status of the economic, social, and physical environments affecting each level of decision to achieve the anticipated decision outcomes? These may not be static and will have consequences on the quality of information and perception. 4. Which ethical pathway (preferences, rules, and principles) influences the decision-making organization and actors? 5. Decision is chosen and implemented. 6. Root-cause analysis of the decision outcome. 7. Repeat, incorporating changes in environmental data for incorporation into a deep neural network. and it was taken under time pressure, with management not fully aware of the time restoration required to develop staff training. The decision by management may be based on an anthropomorphized perception of AI processes (Bankins &amp; Formosa, 2020), as opposed to an information-based decision. Operational-based judgment may have followed an analytical utilitarianism pathway driven by a peerrestricted social environment within the office, with outcome decisions replicated with consequential damage to the organization's reputation. In this scenario, HRM's use of the TP model within the Decision Dashboard would positively help this organization to develop the office social environment demographics, analyze perceptions held by the organizational hierarchy and their sharing of information to develop junior career training, and coordinate time management to implement change.</p>
        <p>AI has impacted and changed a variety of aspects of our everyday lives. Opportunities to address ethical, legal, and strategic challenges in HRM practice and research exist. AI software has influenced the HRM process by reducing the inefficiencies and time required to complete tasks, yet questions of trust from employees and management remain. If organizations' HRM teams do not keep up to speed with the forthcoming advances in AI technology, their organizations may not be able to compete effectively in attracting and recruiting employees in effective roles (Barro &amp; Davenport, 2019). To succeed, organizations will need to commit resources based on AI-impacted cost projections, rather than financing HRM development based purely on previous organizational income (Buzko et al., 2016). A framework for accountability in this investment decision will be required. To assist management to take full advantage of the power and potential that AI offers, this paper focuses on designing and developing ethical HRM systems to eliminate design bias. To this end, a TP model providing six dominant algorithmic pathways is offered to provide possible solutions to reduce AI system bias, which may lead to unethical actions.AI has impacted and changed a variety of aspects of our everyday lives. Opportunities to address ethical, legal, and strategic challenges in HRM practice and research exist. AI software has influenced the HRM process by reducing the inefficiencies and time required to complete tasks, yet questions of trust from employees and management remain. If organizations' HRM teams do not keep up to speed with the forthcoming advances in AI technology, their organizations may not be able to compete effectively in attracting and recruiting employees in effective roles (Barro &amp; Davenport, 2019). To succeed, organizations will need to commit resources based on AI-impacted cost projections, rather than financing HRM development based purely on previous organizational income (Buzko et al., 2016). A framework for accountability in this investment decision will be required. To assist management to take full advantage of the power and potential that AI offers, this paper focuses on designing and developing ethical HRM systems to eliminate design bias. To this end, a TP model providing six dominant algorithmic pathways is offered to provide possible solutions to reduce AI system bias, which may lead to unethical actions.</p>
        <p>The application of analytics and algorithmic decision-making has delivered practical and conceptual problems to HRM, raising questions about accountability, which proves critical when biases may be inputted at the data-generation stage (Tambe et al., 2019). Issues with accuracy, reliability, and bias within the data can also generate additional problems for HRM practitioners, where organizational priorities differ from the algorithm-based decision outcomes. Current research indicates that the integration of AI-driven HRM decisions may de-bias human recruiting (Loureiro et al., 2021). Though algorithms may de-bias human judgments, increasing privacy concerns for both companies and individuals regarding sharing data online may not only skew data and drive biases in algorithmic processing but may also raise privacy concerns with regards to transparency in communicating accountability (Hermann, 2021). While there have been few interdisciplinary exchanges in advances in AI research (Loureiro et al., 2021), a multidisciplinary perspective provides insights into the adoption of an ethical framework in decision analysis. Using the TP model is "useful in uncovering algorithmic pathways management accountants use before arriving at a decision" (Rodgers, 2020, p. 117). Multidisciplinary knowledge sharing and encouraging collaboration for effective AI-mediated knowledge sharing suggest that the insertion of ethical considerations (such as monitoring and privacy) into AI processes by HRM practitioners will have a positive impact on decisionmaking (Malik et al., 2020).The application of analytics and algorithmic decision-making has delivered practical and conceptual problems to HRM, raising questions about accountability, which proves critical when biases may be inputted at the data-generation stage (Tambe et al., 2019). Issues with accuracy, reliability, and bias within the data can also generate additional problems for HRM practitioners, where organizational priorities differ from the algorithm-based decision outcomes. Current research indicates that the integration of AI-driven HRM decisions may de-bias human recruiting (Loureiro et al., 2021). Though algorithms may de-bias human judgments, increasing privacy concerns for both companies and individuals regarding sharing data online may not only skew data and drive biases in algorithmic processing but may also raise privacy concerns with regards to transparency in communicating accountability (Hermann, 2021). While there have been few interdisciplinary exchanges in advances in AI research (Loureiro et al., 2021), a multidisciplinary perspective provides insights into the adoption of an ethical framework in decision analysis. Using the TP model is "useful in uncovering algorithmic pathways management accountants use before arriving at a decision" (Rodgers, 2020, p. 117). Multidisciplinary knowledge sharing and encouraging collaboration for effective AI-mediated knowledge sharing suggest that the insertion of ethical considerations (such as monitoring and privacy) into AI processes by HRM practitioners will have a positive impact on decisionmaking (Malik et al., 2020).</p>
        <p>As AI algorithms continue to evolve and grow, so do the associated risks. As data scientists, system designers, and programmers form an integral role within the core organizational strategy for HRM, responsibility for the design and development of HRM processes within the adoption of such inherently opaque AI technology needs to be clearly defined. Critical and legal questions arise when accountability for AI decisions is raised. A clear pathway for understanding the ethical position of organizations and their decision makers can help HRM practitioners interpret AI-generated HRM decisions. The traditional employment relationship based on reciprocity has eroded with the increasing reliance on AI algorithm-based technology (Duggan et al., 2020). An AI system fraught with unethical problems may emerge without employing a framework such as that of Selbst et al. (2019), which considers elements of solutionism, the ripple effect, formalism, portability, and the framing issues to be resolved.As AI algorithms continue to evolve and grow, so do the associated risks. As data scientists, system designers, and programmers form an integral role within the core organizational strategy for HRM, responsibility for the design and development of HRM processes within the adoption of such inherently opaque AI technology needs to be clearly defined. Critical and legal questions arise when accountability for AI decisions is raised. A clear pathway for understanding the ethical position of organizations and their decision makers can help HRM practitioners interpret AI-generated HRM decisions. The traditional employment relationship based on reciprocity has eroded with the increasing reliance on AI algorithm-based technology (Duggan et al., 2020). An AI system fraught with unethical problems may emerge without employing a framework such as that of Selbst et al. (2019), which considers elements of solutionism, the ripple effect, formalism, portability, and the framing issues to be resolved.</p>
        <p>The TP model's algorithms can assist HRM significantly by addressing accountability related to HRM decision-making in AI environments. Specifically, by embracing the six dominant algorithmic pathways offered by the TP model, HRM practitioners can considerably mitigate the risks associated with biases, which may be inherent in AI systems (Charlwood &amp; Guenole, 2022), thus reducing the occurrence of unethical actions. The analysis of which decision-making ethical pathway is chosen is made relative to each other (i.e., they are not to be analyzed in isolation). Depending on which stakeholder is concerned, each pathway can be considered in context, reflecting the organization's social, economic, and physical environments. These alternate pathways can act complementarily toward ensuring that ethics and fairness are actively promoted by HR professionals. Ethical egoism, for instance, can support the development of AI HRM algorithms based on decision-makers' existing experiences (e.g., regarding employee promotion procedures). Deontology can contribute toward transferring transparently ethical guidelines into mathematical codes that will support managers in distinguishing wrongdoing (e.g., in the recruitment and selection process). Utilitarianism would orientate HR decision makers toward the incorporation of moral standards that will favor sustainable welfare practices in the workplace (e.g., job satisfaction). Relativism can support HRM in making culturally conscious decisions that consider the specificities of international contexts (e.g., regarding ethical decision-making by international assignees). Virtue ethics can support the prevalence of HR leadership in initiating the coding of ethics that will override ethically problematic established practices (e.g., eradicate group thinking). Ethics of care may promote the creation of expert task forces that monitor the implementation of ethical AI-related HR processes, integrating the perspectives of multiple stakeholders within and beyond the boundaries of the organization.The TP model's algorithms can assist HRM significantly by addressing accountability related to HRM decision-making in AI environments. Specifically, by embracing the six dominant algorithmic pathways offered by the TP model, HRM practitioners can considerably mitigate the risks associated with biases, which may be inherent in AI systems (Charlwood &amp; Guenole, 2022), thus reducing the occurrence of unethical actions. The analysis of which decision-making ethical pathway is chosen is made relative to each other (i.e., they are not to be analyzed in isolation). Depending on which stakeholder is concerned, each pathway can be considered in context, reflecting the organization's social, economic, and physical environments. These alternate pathways can act complementarily toward ensuring that ethics and fairness are actively promoted by HR professionals. Ethical egoism, for instance, can support the development of AI HRM algorithms based on decision-makers' existing experiences (e.g., regarding employee promotion procedures). Deontology can contribute toward transferring transparently ethical guidelines into mathematical codes that will support managers in distinguishing wrongdoing (e.g., in the recruitment and selection process). Utilitarianism would orientate HR decision makers toward the incorporation of moral standards that will favor sustainable welfare practices in the workplace (e.g., job satisfaction). Relativism can support HRM in making culturally conscious decisions that consider the specificities of international contexts (e.g., regarding ethical decision-making by international assignees). Virtue ethics can support the prevalence of HR leadership in initiating the coding of ethics that will override ethically problematic established practices (e.g., eradicate group thinking). Ethics of care may promote the creation of expert task forces that monitor the implementation of ethical AI-related HR processes, integrating the perspectives of multiple stakeholders within and beyond the boundaries of the organization.</p>
        <p>Although an organization's agents may take a position on whether an employment contract exists in the various manifestations of app work in the gig economy, psychological contracts may exist from the workers' perspective (Duggan et al., 2020). In recent years, we have witnessed an increasingly wide range of workplace flexibility practices, such as part-time work, flextime, and telecommuting (Whyman, Baimbridge, Buraimo, &amp; Petrescu, 2015). This trend may become more challenging from an HRM perspective as more organizations have been compelled to change from a traditional workplace environment to adopting "working from home" due to the Covid-19 global pandemic, raising new questions and areas of research on the future role of HRM. The adoption of AI technology has enabled this trend, bringing additional challenges for HRM practitioners. As employee satisfaction is critical to the retention of talent and key staff (Degbey, Rodgers, Kromah, &amp; Weber, 2021), the impact of physical environmental factors has been seen to influence job satisfaction and productivity (Kwon &amp; Remøy, 2020). Since HRM practitioners may have no input into the newly imposed work environments of an organization's employees, questions are raised regarding the framework of accountability for decision outcomes resulting from the adoption of workplace AI technology in the home environment. HRM decisions based on AI data analyzing employee performance in home environments may challenge data patterns established from traditional work environments, raising questions around performance accountability, and new challenges regarding teamwork, employee satisfaction, and employee development. Increased use of algorithm-based decision-making through remote access raises questions regarding perceptions of monitoring and privacy, suggesting that future research on employee perceptions of HRM practitioners accessing AI technology within organizations may assist in the development of ethical guidelines in the HRM use of AI. A clearly accountable decision model supports organizations in terms of corporate disclosure and corporate social responsibility, and not only provides regulators and educators with a framework for evaluating decisions, but it also equips HRM leaders and practitioners with a framework to account for AI decisions in PMRS.Although an organization's agents may take a position on whether an employment contract exists in the various manifestations of app work in the gig economy, psychological contracts may exist from the workers' perspective (Duggan et al., 2020). In recent years, we have witnessed an increasingly wide range of workplace flexibility practices, such as part-time work, flextime, and telecommuting (Whyman, Baimbridge, Buraimo, &amp; Petrescu, 2015). This trend may become more challenging from an HRM perspective as more organizations have been compelled to change from a traditional workplace environment to adopting "working from home" due to the Covid-19 global pandemic, raising new questions and areas of research on the future role of HRM. The adoption of AI technology has enabled this trend, bringing additional challenges for HRM practitioners. As employee satisfaction is critical to the retention of talent and key staff (Degbey, Rodgers, Kromah, &amp; Weber, 2021), the impact of physical environmental factors has been seen to influence job satisfaction and productivity (Kwon &amp; Remøy, 2020). Since HRM practitioners may have no input into the newly imposed work environments of an organization's employees, questions are raised regarding the framework of accountability for decision outcomes resulting from the adoption of workplace AI technology in the home environment. HRM decisions based on AI data analyzing employee performance in home environments may challenge data patterns established from traditional work environments, raising questions around performance accountability, and new challenges regarding teamwork, employee satisfaction, and employee development. Increased use of algorithm-based decision-making through remote access raises questions regarding perceptions of monitoring and privacy, suggesting that future research on employee perceptions of HRM practitioners accessing AI technology within organizations may assist in the development of ethical guidelines in the HRM use of AI. A clearly accountable decision model supports organizations in terms of corporate disclosure and corporate social responsibility, and not only provides regulators and educators with a framework for evaluating decisions, but it also equips HRM leaders and practitioners with a framework to account for AI decisions in PMRS.</p>
        <p>As emerging evidence illustrates that various professionals' traditional roles are also challenged due to the widespread development of AI algorithm-based technology (Susskind &amp; Susskind, 2015), similar issues of automation and disintermediation faced by professionals, such as architects and lawyers, are faced by HRM practitioners. Without human oversight and intelligibility, HRM roles risk being de-skilled (Charlwood &amp; Guenole, 2022), raising research questions on how HRM practitioners can address a potential loss of control as a result of organizational perceptions of AI decision-making abilities, and questions on the long-term outcomes in terms of the professional expertise and commercial approach of HRM practitioners delegating HRM decisions to AI technologies.As emerging evidence illustrates that various professionals' traditional roles are also challenged due to the widespread development of AI algorithm-based technology (Susskind &amp; Susskind, 2015), similar issues of automation and disintermediation faced by professionals, such as architects and lawyers, are faced by HRM practitioners. Without human oversight and intelligibility, HRM roles risk being de-skilled (Charlwood &amp; Guenole, 2022), raising research questions on how HRM practitioners can address a potential loss of control as a result of organizational perceptions of AI decision-making abilities, and questions on the long-term outcomes in terms of the professional expertise and commercial approach of HRM practitioners delegating HRM decisions to AI technologies.</p>
        <p>There are risks in the acceptance of AI decisions without a clearly understandable decision audit trail that is legible for nonprogrammers. Applying HRM practitioner domain knowledge during the design, development, and deployment stages of AI technologies will help ensure that ethical considerations are addressed in AI-generated HRM decisions and that they will likely result in positive outcomes (Charlwood &amp; Guenole, 2022). Employee engagement with the testing and design of AI applications results in improvements in experience when interacting with technology (Malik et al., 2020). Future research on how HRM practitioners engage with AI developers, how organizations identify accountability internally and externally for AI-generated HRM decisions, and the impact on an organization's reputation due to AI-generated HRM decisions will inform HRM decision-making and professional development. Just as "explainers" are required in evidence-based industries to understand and communicate AI-generated recommendations (e.g., law, medicine) (Wilson &amp; Daugherty, 2018), the TP model supports HRM practitioners in understanding, managing, and communicating AI-generated HRM decisions. We hold that future studies that will collect data to operationalize the TP model can contribute to developing a deeper understanding of algorithm-based HR decisions. By implementing the TP model, as highlighted by the Dashboard, HR practitioners can help shed light on the technology interface between workplace ethics, employee compliance, and decision outcomes.There are risks in the acceptance of AI decisions without a clearly understandable decision audit trail that is legible for nonprogrammers. Applying HRM practitioner domain knowledge during the design, development, and deployment stages of AI technologies will help ensure that ethical considerations are addressed in AI-generated HRM decisions and that they will likely result in positive outcomes (Charlwood &amp; Guenole, 2022). Employee engagement with the testing and design of AI applications results in improvements in experience when interacting with technology (Malik et al., 2020). Future research on how HRM practitioners engage with AI developers, how organizations identify accountability internally and externally for AI-generated HRM decisions, and the impact on an organization's reputation due to AI-generated HRM decisions will inform HRM decision-making and professional development. Just as "explainers" are required in evidence-based industries to understand and communicate AI-generated recommendations (e.g., law, medicine) (Wilson &amp; Daugherty, 2018), the TP model supports HRM practitioners in understanding, managing, and communicating AI-generated HRM decisions. We hold that future studies that will collect data to operationalize the TP model can contribute to developing a deeper understanding of algorithm-based HR decisions. By implementing the TP model, as highlighted by the Dashboard, HR practitioners can help shed light on the technology interface between workplace ethics, employee compliance, and decision outcomes.</p>
        <p>William Degbey acknowledges the Kaute Foundation and Marcus Wallenberg Foundation in Finland for their support of this research.William Degbey acknowledges the Kaute Foundation and Marcus Wallenberg Foundation in Finland for their support of this research.</p>
    </text>
</tei>
