<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T09:57+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>In recent years, a new frame for innovation policy has emerged, namely "transformative innovation policy" (TIP), which aims at addressing transformative change or "Grand Challenges". Such a shift in policy theory should, ideally, be reflected in policy evaluation, but the literature has so far provided little advice on how to address TIP-related evaluation challenges such as directionality and system-level behavioural additionality. This paper discusses how the evaluation of policy interventions targeting system innovation can be designed to address these challenges. Combining the literature on sustainability transitions with policy evaluation, we propose an integrated evaluation framework composed of three main components: (i) programme theory (programme goals, systems boundaries and desired (or accepted) development paths); (ii) system analysis (transformative outcomes); and (iii) synthesis and overall assessment (including revision of programme theory). By integrating the two sets of literature, we provide a bridge between academic research on transitions and current evaluation practices. We briefly illustrate the applicability of the integrated framework in the BioInnovation Strategic Innovation Programme in Sweden.</p>
        <p>Since the mid-2000s, a new "frame" (or paradigm) for innovation policy has emerged, which some authors refer to as transformative innovation policy (TIP) (Diercks et al., 2019;Schot and Steinmueller, 2018). While this new frame partly builds on previous science, technology and innovation policy ideas, it implies a broader perspective on both the innovation policy agenda and the innovation process as such (Diercks et al., 2019). Current examples include the OECD S&amp;T Policy 2025, EU's Fit for 55 legislative packages, the Swedish Innovation Agency's Impact Innovation Programme, and the German High-Tech Strategy 2025.</p>
        <p>Although both policymakers and researchers are still trying to understand how to approach this new policy frame, some distinguishing characteristics compared with previous frames have been identified in the literature (Haddad et al., 2022). Most notably, TIP comes with a shift towards "purposive and directional innovation" (Diercks et al., 2019, p. 880; see also Weber and Rohracher, 2012), where innovation policy is mobilised to address broader societal goals, such as "Grand Challenges" or sustainability transitions in important societal sectors (Fagerberg, 2018;Steward, 2012). It involves multiple levels of governance (Amanatidou et al., 2014) as well as interactions with other (sectoral) policy domains (Diercks et al., 2019), resulting in an increasing need for policy coordination (Schot and Steinmueller, 2018;Weber and Rohracher, 2012). Drawing on literature on system innovation and sustainability transitions (Schot and Steinmueller, 2018), TIP also implies a broader view of the innovation process, in terms of both policy mixes (Diercks et al., 2019;Kivimaa and Kern, 2016) and stakeholder involvement (Steward, 2012). With regard to policy mixes, the TIP literature stresses the need for innovation policy to include not only both supply-and demand-side instruments for innovation (as in the previous innovation system frame) (Rogge and Reichardt, 2016) but also measures to support niche creation and regime destabilisation (Kivimaa and Kern, 2016). Regarding stakeholder involvement, the wider agenda implies that a more diverse set of stakeholders will be affected and, consequently, should be allowed to become engaged in policymaking processes (Diercks et al., 2019;Schot and Steinmueller, 2016). This might also require new governance modes (Kuhlmann and Rip, 2018). 1 Such a shift in policy approach should, ideally, be reflected in policy evaluation (Molas-Gallart and Davies, 2006). So far, researchers have tended to use existing analytical frameworks to analyse the influence of traditional policies and policy mixes (and other factors) on transition processes in different sectors (cf. Bergquist and Söderholm, 2016;Geels et al., 2016;Roberts and Geels, 2019;Skjølsvold and Ryghaug, 2019). However, the emergence of innovation programmes that have been designed for the explicit purpose of being transformative, such as those mentioned above, stresses the need for a new, more specific evaluation approach. Moreover, evaluation practices are still very much based on earlier innovation policy paradigms, and implementing TIP thinking into these practices can therefore be rather challenging (Amanatidou et al., 2014). Most notably, evaluating TIP would require evaluators to handle directionality and system-level behavioural additionality (Haddad, 2021b). With regard to directionality, there is a need to evaluate how policy mixes impact the direction of socio-technical change, for example in terms of assessing whether specific societal needs, demands, and challenges are addressed and acceptable development paths for different sub-systems identified (cf. Edler and Boon, 2018;Schlaile et al., 2017;Weber and Rohracher, 2012). Concerning behavioural additionality, TIP evaluation needs to go beyond traditional input-output analysis (Amanatidou et al., 2014;Janssen, 2019) to assess how policy generates transformative outcomes (Bergek and Haddad, 2022;Ghosh et al., 2021) andin the longer termcontributes to achieving sustainability transition and meeting targeted societal goals (Amanatidou et al., 2014). Accordingly, evaluations need to explain how specific interventions cause certain system-level impacts (Arnold et al., 2018;Gök, 2010;Kern and Rogge, 2018).</p>
        <p>We can, thus, conclude that TIP evaluation requires a framework that can handle directionality and is focused on behavioural additionality in terms of socio-technical outcomes and impacts. Some valuable attempts have been made towards developing such a framework, including efforts to analyse directionality and the influence of policy instruments/mixes on innovation systems or socio-technical niches and regimes (cf. Bugge et al., 2017;Bugge et al., 2018;Ghosh et al., 2021;Grillitsch et al., 2019;Janssen, 2019;Kern, 2012;Kivimaa et al., 2017;Kivimaa and Kern, 2016;Kivimaa and Virkamäki, 2014;Scordato et al., 2018). However, these frameworks rarely describe how to operationalise directionality for evaluation purposes, beyond studying the capacity of policy programmes to build shared visions (cf. Bugge et al., 2017;Bugge et al., 2018;Scordato et al., 2018), or how to move beyond traditional system analysis and evaluate behavioural additionality at the systems level (for an exception, see Janssen, 2019).</p>
        <p>In this paper, we argue that closer integration between the literature on TIP and the policy evaluation literature can be a useful approach to addressing these gaps. On the one hand, some evaluation theory streams include rather well-developed ideas that relate to directionality and additionality, which could be relevant for TIP evaluation. Most notably, the theory of change (ToC) literature is goal oriented and includes a structured way to consider both outcomes and impacts in relation to what a programme is meant to achieve (Blamey and Mackenzie, 2007;Reed et al., 2021), and the realist evaluation (RE) literature provides new perspectives on causality (Pawson, 2006;Pawson and Tilley, 1997) and presents a mechanism-based approach to addressing additionality (Hind, 2010). On the other hand, the evaluation literature does not consider the specific phenomenon at hand (White, 2010), which means that ToC and RE thinking needs to be adapted to the particular context of sustainability transitions to be useful for TIP evaluation. To achieve this, a theory-based approach which links general evaluation concepts and approaches with transition-specific conceptualisations of goals, outcomes, processes, and mechanismsas described in current innovation and transition studies literatureis key (Molas-Gallart and Davies, 2006;Sandin et al., 2019).</p>
        <p>Against this background, the purpose of this paper is to develop a framework for evaluating transformative innovation programmes, which integrates insights from literature on sustainability transitions and policy evaluation to address directionality and system-level behavioural additionality.</p>
        <p>As noted above, innovation policy evaluation practices already lag behind advances in innovation theory (Amanatidou et al., 2014;Molas-Gallart and Davies, 2006), and the advent of transformative innovation policy perspectives makes this gap even more accentuated (Haddad, 2021b). In this context, an additional benefit of integrating sustainability transitions literature and policy evaluation literature is that the latter (especially ToC) is well established among public policymakers and evaluators and, therefore, can serve as a bridge between the suggested TIP evaluation framework and current evaluation practices.</p>
        <p>Historically, three main theoretical perspectives have influenced our understanding of the innovation process and the rationale for public intervention in this process: the neoclassical perspective, the evolutionary-structural perspective, and the innovation system perspective (Chaminade and Edquist, 2010). 3 As mentioned in the introduction, these have recently been complemented by the emerging transformative innovation policy perspective, which is the focus of this paper. In the following, we will give a brief overview of the four perspectives and their respective approach to evaluation in terms of, for example, what type of effects should be measured, at what level of analysis, and how measured effects could be attributed to specific interventions (see Table 1 for a summary). This serves as a background to describing some attempts to develop an evaluation framework for transformative innovation policy.</p>
        <p>Innovation policy dates back to the 1950s and the advent of the linear "science-push" model (Martin, 2012). It was influenced mainly by neoclassical economics (Chaminade and Edquist, 2010), in which the main rationale for policy intervention is the failure of private actors to efficiently allocate resources to innovation compared with what would be socially and economically desirable, due to various forms of market failures (Fagerberg, 2017;Jacobsson et al., 2017;Smith, 2000). In this context, two main types of additionality are considered: input additionality, i.e. the extent to which public funding increases total R&amp;D investments instead of replacing or "crowding out" private R&amp;D activities (Georghiou, 1998), and output additionality, i.e. whether the same outputs, in terms of, for example, patents, publications, product introductions, sales, etc. would have been achieved without public support (Bach and Matt, 2005;Clarysse et al., 2009;Georghiou and Clarysse, 2006).</p>
        <p>The early 1980s saw the emergence of evolutionary economics and the notion of interactive innovation processes (Martin, 2012). This resulted in an increased focus on "opportunity enhancing" (Georghiou, 1998) innovation policies, such as policies directed at increasing collaboration between firms. In terms of evaluation, this new focus was translated into the concept of "behavioural additionality" (BA), which refers to the influence a policy intervention has on the actions of firms and other actors (Amanatidou et al., 2014;Bach and Matt, 2005;Georghiou and Clarysse, 2006). Initially, it was suggested that evaluations should assess changes in how firms organise and manage their R&amp;D and innovation processes (Bach and Matt, 2005;Clarysse et al., 2009;Georghiou, 1998;Georghiou and Clarysse, 2006). Later, the BA concept was expanded into an ambition to capture the indirect effects of policy, such as the learning that takes place in firms because of public support (Afcha Chávez, 2011;Clarysse et al., 2009;Georghiou and Clarysse, 2006).</p>
        <p>In the late 1980s, the evolutionary and interactive perspective on innovation converged with a revived discussion about the merits of industrial policy, which resulted in the development of various innovation system frameworks (Carlsson et al., 2010;Sharif, 2006). With these systemic approaches to innovation policy came a shift in rationales for government intervention from market failures to various system failures or weaknesses (Bergek et al., 2010;cf. Carlsson and Jacobsson, 1997;Chaminade and Edquist, 2010;Jacobsson and Johnson, 2000;Tödtling and Trippl, 2005;Wieczorek and Hekkert, 2012;Woolthuis et al., 2005). In order to handle such systemic problems, new and more complex policy initiatives, for example cluster and sectoral policies, were developed and implemented.</p>
        <p>From an evaluation perspective, this system orientation was and is challenging. The recognition that policies needed to be assessed at the level of systems rather than individual interventions led to the development of some systemic approaches (cf. Arnold, 2004;Edler et al., 2008), but still no standardised approach exists apart from the Oslo Manual's guidelines on how to collect and interpret innovation data (cf. OECD/Eurostat, 2005). Some scholars have suggested evaluating changes in network composition and interactions after an intervention (Bellandi and Caloffi, 2010;Rametsteiner and Weiss, 2006;Russo and Rossi, 2009), whereas others argue that evaluations should focus on the extent to which specific policy instruments address structural system failures (cf. Woolthuis et al., 2005) or influence key processes in targeted innovation systems (Bergek, 2004;Jacobsson and Perez Vico, 2010;Perez Vico and Jacobsson, 2012). However, the relationship between innovation policy and system-level changes is very complex (Bellandi and Caloffi, 2010;Brown et al., 2016;Gök, 2010;Magro and Wilson, 2013;Rametsteiner and Weiss, 2006;Russo and Rossi, 2009), which is perhaps why additionality is seldom explicitly addressed in these approaches. This has been highlighted further in the literature on policy mixes, which emphasises the need to understand the overall policy system and account for policy interactions and their impacts (Magro and Wilson, 2013). In relation to the former, the authors suggest that additionality should be approached in an integrated form (input, output and behavioural). Regarding the latter, meta-analysis (Arnold, 2004;Edler et al., 2008) can identify interactions across policy instruments and administrative levels.</p>
        <p>The emerging transformative innovation policy perspective builds on these previous innovation policy approaches and, thus, complements rather than replaces them (Diercks et al., 2019). As described in the introduction, it challenges the previous emphasis on innovation for the sake of economic growth and instead stresses the need to direct innovation to address broader societal goals, such as Grand Challenges and the Sustainable Development Goals (Diercks et al., 2019;Fagerberg, 2018;Schot and Steinmueller, 2018). Consequently, it has an even broader view of the innovation process, since reconfigurations of entire societal sectors of production and consumption are in focus. While TIP scholars tend to acknowledge the relevance of innovation system-based policy rationales, they also argue that there can be additional reasons for policy to intervene in transition processes. This is most clearly depicted in Weber and Rohracher's (2012) framework, which combines previously identified system failures with a set of "transformational" systems failures, i.e. directionality, demand articulation, policy coordination, and reflexivity failures. Addressing such transformative failures requires even more complicated policy mixes than in the system approach andin the context of innovation policyeven more complex innovation programmes, which combine and coordinate several types of policy instruments and activities with the overall aim of "jointly creating conditions conducive to achieving a so far unmet societal want or need" (Janssen et al., 2022, p. 1) and, thus, contributing to transitions in targeted societal sectors.</p>
        <p>From the point of view of evaluation, many of the same challenges exist as for innovation system-based innovation policy. However, the increased focus on directionality implies that there are new ends and goals against which policy programmes need to be evaluated, and there is also a need to consider how policy contributes to desired (or at least acceptable) pathway(s) in a particular sector (Schlaile et al., 2017;cf. also Magro and Wilson, 2019). Assessments of behavioural additionality need to include even longer-term changes in behaviour resulting in societal impacts (Amanatidou et al., 2014) and have to account for even more complex feedback loops between policy outputs, outcomes, and impacts when explaining how specific interventions influence targeted systems (Arnold et al., 2018;Kern and Rogge, 2018).</p>
        <p>The changing requirements on evaluation are to some extent reflected in recent academic literature that combines transition studies and innovation policy to incorporate new dimensions in the analysis and evaluation of transformative innovation policy. In this emerging field, approaches differ in terms of which aspect of policy they assess. Janssen et al. (2022) distinguish six main targets of evaluations: 1) intervention rationales, 2) governance processes and structures (including policy design features), 3) policy influence on systemic/transformational bottlenecks, 4) policy influence on innovation and transformation processes, 5) policy influence on structural system change, and 6) societal impact of policy. Since we are interested in impact evaluation rather than policy formulation or design, we focus on frameworks that aim at assessing to what extent policy has an effect on transformative change, i. e. categories 3-6 (see Table 2). 4 While policy is included in many, if not most, empirical system-level analyses of innovation and transition processes, this section, therefore, discusses frameworks developed specifically for analysing and assessing the influence of policy on such processes.</p>
        <p>The evaluation frameworks we have identified are for the most part based on analytical frameworks that are already well-established in the field of sustainability transitions, including the multi-level perspective (MLP) (Geels, 2002), strategic niche management (SNM) (cf. Kemp et al., 1998), technological innovation systems (TIS) (cf. Bergek et al., 2008;Hekkert et al., 2007), transition management (cf. Rotmans et al., 2001), and systemic and transformational failures (cf. Weber and 2). It should be noted that they differ in terms of their level of analysis, i.e. whether they aim at evaluating individual projects or initiatives, programmes, or entire policy/instrument mixes (cf. Molas-Gallart et al., 2021). The focus of this paper is on programme evaluation, but we nevertheless consider some of the policy mix-focused literature potentially useful also for this purpose. So far, few truly transformative innovation policy programmes (as defined in the TIP literature) have been implemented. Nevertheless, most of the suggested evaluation frameworks have been applied to innovation policies with at least some transformative ambition or to policy mixes consisting of goals, strategies, and instruments that ultimately aim at inducing sustainability transitions in, for example, the energy, transport, or health sectors. We would therefore argue that all these frameworks are relevant for TIP evaluation and advance our understanding of how TIP can be assessed and evaluated for both learning and accountability purposes. However, as will be discussed in the following sub-sections most of them have shortcomings when it comes to addressing the specific TIP-related evaluation challenges discussed above, i.e. behavioural additionality and directionality.</p>
        <p>As indicated by Table 2, all frameworks are potentially useful for analysing policy influences on aspects related to transitions and system change. However, some of them focus on policy influences on systemic or transformational failures rather than on system change as such (Bugge et al., 2018;Bugge et al., 2019;Grillitsch et al., 2019;van Mierlo et al., 2010), which makes them less useful from the point of view of behavioural additionality as this is a rather indirect way of assessing the influence of policy on system-level behaviour. Frameworks focusing on policy influence on innovation/transition processes and/or structural changes in targeted socio-technical configurations seem more useful in this regard (Bergek and Haddad, 2022;Ghosh et al., 2021;Janssen, 2019;Kern, 2012;Kivimaa et al., 2017;Kivimaa and Kern, 2016;Kivimaa and Virkamäki, 2014;Scordato et al., 2018). Indeed, the mesolevel change processes they describe (most notably innovation systembuilding, niche development and regime destabilisation) are directly associated with socio-technical transitions and can, therefore, be interpreted as system-level behavioural change.</p>
        <p>However, very few of these frameworks explicitly address additionality, i.e. whether the observed systemic changes can be attributed to (a particular) policy. Some authors mention that the change processes included in their frameworks can be influenced by other things than policy (Edmondson et al., 2019;Ghosh et al., 2021) or acknowledge the need to study the underlying mechanisms that lead to changes in the targeted systems (Bergek and Haddad, 2022;Kern, 2012;Scordato et al., 2018), which can be seen as a first step towards identifying how policy influence system-level change processes. But only Janssen's (2019) framework includes a direct assessment of additionality, through an analysis of how decisive the evaluated policy was for strengthening targeted, urgent functions.</p>
        <p>The lack of attention to additionality is also reflected in the empirical applications of the frameworks. In studies using process-oriented frameworks, causality is usually established through a narrative approach, in which the influence of a specific policy (or policy mix) on different system-level processes is described qualitatively. Some of them are focused primarily on the policy at hand and, therefore, largely fail to identify other potentially important influences on the processes or failures (see Edmondson et al., 2019;Kern, 2012). Other studies identify different types of influences on the processes, but without specifically highlighting the role of policy (see Ghosh et al., 2021). Yet other studies describe whether stakeholders perceive the influence of specific policies as positive or negative, without providing much information about the underlying reasons for this categorisation (see Kivimaa et al., 2017). Such weaknesses make it difficult to establish causality between policy and system-level changes and the relative importance of policy vis-à-vis other endogenous and exogenous influences. In contrast, van Mierlo et al. (2010) explicitly try to analyse how learning came about in the studied system and what circumstances influenced this process ▪ Influence on innovation and transformation processes ▪ Influence on structural system change a Firm-level learning processes rather than system-level change processes. b Match policy instruments and processes ex-ante.</p>
        <p>(including the role of the program under evaluation). Similarly, Janssen (2019, p. 93) highlights the importance of reconstructing the entire evolution of the focal system in order to identify the forces at play in different periods in order to "determine how much policy efforts have been leading the way."</p>
        <p>Almost all of the reviewed articles describe directionality as a key aspect of TIP and define the overarching goal of policy in terms of system innovation or (sustainability) transition, i.e. reconfiguration of sectoral socio-technical systems to improve their sustainability performance. 5 Nevertheless, directionality is seldom an explicit part of the frameworks. Indeed, only a few articles mention that policy evaluation should, ideally, be done in relation to the overarching goals (cf. Bergek and Haddad, 2022;Janssen, 2019), and even fewer try to make any form of (preliminary) assessment of whether a policy or policy mix seems to have contributed to the targeted transition (cf. Kivimaa et al., 2017;Kivimaa and Kern, 2016). Moreover, transition goals tend to be expressed at a rather general level, which makes them difficult to assess. This is also reflected in the empirical applications, where policy goals tend to be formulated in broad terms, for example as transitions of urban waste or water systems (Bugge et al., 2019;van Mierlo et al., 2010), lowcarbon transition (Kern, 2012), or low-energy innovation (Kivimaa and Kern, 2016). Only a few cases describe concrete goals or targets, which can be assessed more directly (Edmondson et al., 2019;Kivimaa et al., 2017;Kivimaa and Virkamäki, 2014). For the most part, this is not a weakness of the frameworks as such, but rather stem from the studied policies.</p>
        <p>The literature on directionality also points to the need to identify and support specific desirable (or at least acceptable) development paths. Consequently, TIP evaluation should include an assessment of which development paths the focal policy has supported and whether these are desirable/acceptable or not. This aspect of evaluation is, however, not dealt with directly in the received frameworks. Some see paths as more or less given by the focus of the policy under evaluation. For example, Bugge et al. (2018) describe how assisted living is seen as the main answer to challenges related to ageing societies and Janssen (2019) argues that transformative policies are meant to support specific paths that are defined from the start. Others acknowledge that there are choices to be made between different paths (Edmondson et al., 2019;Kivimaa and Kern, 2016) and that the inability to provide such direction could be considered a transformational failure (Bugge et al., 2018;Bugge et al., 2019;Grillitsch et al., 2019;Scordato et al., 2018), but do not provide any explicit means for assessing the achieved directionality. 6 Some frameworks nevertheless include elements that might be useful for assessing which direction a particular transition is taking and the role of policy in setting that direction (albeit that they are not necessarily introduced for that purpose). For example, Janssen (2019) suggests that an assessment should be made of whether industrial diversification resulting from policy interventions is done into related fields or genuinely novel fields. Bugge et al. (2019) instead distinguish between "system optimisation" (changes that improve the sustainability and cost-efficiency of an existing system) and "system change" (changes that radically transform the focal system), which might be interpreted as different development paths towards a sustainability transition. In a similar vein, but from a more empirical starting point, Kivimaa and Virkamäki (2014) distinguish four different low-carbon transition paths and demonstrate that the current policy mix supports some paths more than others. Finally, Bergek and Haddad's (2022) framework allows the evaluator to assess which existing and emerging socio-technical systems gains or loses innovation performance, which new and established actors are included and excluded from networks, and to what extent rule changes work in the favour of different socio-technical systems and actor groups.</p>
        <p>To sum up, several frameworks have been introduced that could be useful for TIP evaluation. While many of them can enable the identification of policy influences on system-level change processes (i.e. systemlevel behavioural change), they are weak in the areas of additionality and directionality. There is, thus, a need for an evaluation framework that more directly addresses the issue of attributing changes in systemlevel change processes to policy (additionality) and allows for an assessment of whether achieved changes seem to support desired (or at least acceptable) development paths. As argued in the introduction, the general policy evaluation literature can contribute important insights into these issues.</p>
        <p>Innovation policy evaluation has been dominated by evaluation approaches that try to measure the effects of policy intervention by relying on quantitative indicators to assess programme performance and effects, for example to determine accountability (Molas-Gallart and Davies, 2006). Such approaches, which are usually referred to as "black box evaluations" (Astbury and Leeuw, 2010), are experiment-focused and lack the power to explain how and why outcomes come about (Blamey and Mackenzie, 2007;Rolfe, 2019). Theory-based evaluation emerged as an alternative to such methods-based evaluation, focusing on unpacking the processes between policy intent and policy outcome by revealing causal mechanisms that generate the outcomes as well as the contextual factors that influence them (Rolfe, 2019). 7 The most influential theory-driven evaluation approaches are theories of change and realist evaluation (Blamey and Mackenzie, 2007), which are discussed in more detail below.</p>
        <p>The theories of change (ToC) approach (Connell et al., 1995;Fulbright-Anderson et al., 1998) aims at developing a visual and narrative model of the intervention under evaluation by analysing how central economic, psychological, social and physical processes generate change in individuals, organisations, communities, etc. (Funnell and Rogers, 2011). ToC proponents generally argue that the main source of "theory" in this context is stakeholders' (implicit) beliefs (Weiss, 1997), but others point out that this can be complemented by project documentation and existing evidence (Mason and Barnes, 2007).</p>
        <p>The ToC approach can essentially be summarised in four main stages, as suggested by Rolfe (2019). First, programme staff decides on the ultimate and long-term development impact, i.e. the programme's goal or mission, andvia a process of backwards mappingdiscusses what are the necessary outcomes, outputs, activities, and inputs to achieve that goal. This implies explicating the theories of change in terms of what is expected to be achieved as well as how and why this is supposed to 5 In two cases, it is difficult to understand in what sense there is a transition goal as the main driving force seems to be a need to increase economic competitiveness: Ghosh et al. (2021) (coffee production) and Janssen (2019) (industrial diversification). 6 It should be noted here that some authors have a bottom-up understanding of directionality. Most notably, Ghosh et al. (2021, p. 751) argue that a formative evaluation focusing on transformative outcomes can, in itself, be used as a tool to guide interventions as they "expect actors to deliberate which outcomes they want to prioritise and when." Similarly, Janssen (2019) sees directionality as a result of the alignment of actors and the adaptations in policy interventions in relation to the long-term target of TIP.</p>
        <p>deliver the desired outcome (Mason and Barnes, 2007). There is also an effort to understand the specific context in which the programme operates. Second, the programme staff reviews the assumptions underlying the resulting theories of change in order to assess if the programme's logic is realistic and if the resources that are available can be used as the model suggested (Blamey and Mackenzie, 2007). Third, the implementation of the programme is assessed by a range of indicators in order to establish causal attribution, in terms of showing what processes lead to the outcomes observed (Rogers and Weiss, 2007;Weiss, 1997). This can serve as an input to establishing the role of the programme in achieving the observed outcomes, i.e. the additionality of the programme. 8 Fourth and finally, the data is reviewed in a collaborative manner to assess inputs, activities, outputs, outcomes, and the impact of the programme.</p>
        <p>The main advantage of a ToC evaluation is the ability to unpack the complex processes involved in a policy intervention, by explicating the causal chain and shedding light on causal attribution (Rogers and Weiss, 2007). As such, it helps to provide a better idea of programme strategies and complexity (Blamey and Mackenzie, 2007). Among the challenges, the literature highlights that the ToC evaluation process can be very time and resource-consuming (Blamey and Mackenzie, 2007). ToC evaluations also tend to end up focusing on activities and intermediate outcomes rather than on the mechanisms of change (Rogers and Weiss, 2007;Rolfe, 2019), which makes it difficult to fully address additionality.</p>
        <p>Realist evaluation (RE) emerged as another alternative to the methods-based approach to evaluation. It was proposed by Pawson and Tilley (1997) and aims at identifying how causal mechanisms make a programme work, why, and under which circumstances. It follows the realist principle of generative causality which "holds that, to infer a causal outcome (O) between two events (X and Y), one needs to understand the underlying mechanism (M) that connects them and the context (C) in which the relationship occurs" (Pawson et al., 2005, p. 21-22).</p>
        <p>The realist evaluation cycle can be summarised in four steps (Rolfe, 2019). First, the evaluator tries to understand what the aim of the programme is, including its long-term goal, the targeted population, and in which context it will operate. This is done through discussions between programme stakeholders and the evaluator. Second, the evaluator formulates a set of middle-range theories that explain how (through which processes) an intervention is expected to lead to a particular outcome (Marchal et al., 2012). These can be supported, for example, by information provided by practitioners, previous evaluations, and theories from other studies. Third, the evaluator collects both qualitative and quantitative data to analyse and test these middle-range theories. Fourth, following the data analysis, the theories are refined into the form of Context-Mechanism-Outcome configuration (CMOc) hypotheses. In other words, CMOc work as theories of how the programme works, for whom, and in what contexts (Blamey and Mackenzie, 2007).</p>
        <p>The main advantage of the realist approach is its potential to explain and understand how programmes work (Astbury, 2013) and, more specifically, that it allows for a better understanding of the social and behavioural mechanisms that underly program theory (van der Knaap et al., 2008). This is useful for establishing causality and, thus, additionality. It should be noted that, in comparison with the ToC approach, the role of the evaluator is more explicit in uncovering the programme's underlying theories (Blamey and Mackenzie, 2007).</p>
        <p>Some authors have explored the possibility and feasibility of combining ToC and RE in order to improve learning (Blamey and Mackenzie, 2007;Rolfe, 2016Rolfe, , 2019)). One of the main advantages of such a combination is the potential to better address complex programmes by using ToC to get a broader overview of how the programme is being addressed and realist evaluation to examine the causal processes generating change (Blamey and Mackenzie, 2007;Rolfe, 2019). Accordingly, theories of change can be used as a means for detailing implementation theory, while realist evaluation focuses on testing promising programme theories.</p>
        <p>More specifically, Rolfe (2019) proposes using RE to investigate the underlying causal mechanisms acting within the broader ToC framework. A first step would then be to develop a generic ToC model, based on a literature review of the history and impacts of policies at different levels, e.g. national and local. The evaluator would then identify potential realist middle-range theories within the generic ToC model by looking for relevant mechanisms and contextual factors (in the form of hypotheses). By analysing the evidence from empirical cases and studies, the theories would then be refined in the form of CMOc. Finally, the findings from theory refinement could result in improvements in the generic ToC model.</p>
        <p>In the next Section, we use the insights from the combined ToC-RE approach as an evaluation framework and we complement it with the transformative innovation policy literature. We argue that the latter strengthens the theoretical basis for identifying CMOc in programmes targeting socio-technical system change.</p>
        <p>In this section, we exploit the complementarities between the innovation policy and sustainability transitions literature (Section 2) and the literature on theory-based evaluation (Section 3) by integrating them into a framework for evaluating transformative innovation policy programmes. Fig. 1 summarises this integrated framework, divided into three main components (Programme theory, System analysis, and Synthesis and overall assessment) and seven steps. The figure also illustrates in which steps approaches from each literature are used (see the "bubbles" with arrows pointing at each step) and where behavioural additionality and directionality are addressed (see the coloured boxes inside the circle). While presented in the form of linear steps, the framework should be seen as an iterative process, in which each step informs and is informed by the others. As such, the evaluator might need to consider feedback loops emerging from previous steps when operationalising the framework, and policymakers should use insights from previous evaluations when formulating programme theories of new or revised programmes.</p>
        <p>While the proposed steps focus on the level of programmes, we fully acknowledge that some TIP initiatives involve more complex settings, for example a portfolio of interventions targeting different sociotechnical systems. In those cases, the evaluator can break these interventions down into separate programmes and look for interactions across the portfolio of interventions. This is closely related to the idea of meta-evaluations or secondary analysis, as discussed in Section 2.1, where the evaluator moves "from isolated, individual evaluations to meta-evaluations or secondary analysis that build on individual evaluations in trying to capture the systemic nature of policies" (Magro andWilson, 2013, p. 1649). We discuss this further below in relation to system delineation.</p>
        <p>The first component aims to describe and understand the initiative's programme theory. This involves reconstructing the (implicit) programme theory underlying a policy intervention, which should be 8 As described in Section 2.1, additionality refers to the influence a policy intervention has on input, output and behaviour of firms and other actors. In order to assess additionality, we, therefore, need to attribute the effects of the programme to the policy intervention.</p>
        <p>supported by a policy theory (in this case, theory about transformative innovation policy). This helps the evaluator to understand "the logical links between policy practice and their expected effects and to turn them into the theoretical support for a detailed evaluation study" (Molas-Gallart and Davies, 2006, p. 2). Component 1 includes three main steps: (i) define the transition focus, (ii) explicate the programme's theory of change, and (iii) identify potential causal mechanisms.</p>
        <p>The first step in the integrated framework is to define the transition focus of the programme. This includes three key features. The first feature is to identify the nature of the problem that the program is addressingwhich in the context of transformative innovation policy would be a specific Grand Challenge or mission (or a sub-problem related to such a challenge/mission) -as well as to understand its overall causes and consequences. This is similar to what Funnell and Rogers (2011) call situation analysis when developing theories of change, i.e. the identification of problems and causes. In recent conceptualisations of mission-oriented innovation systems (MIS), this would be analogous to "problem directionality", which corresponds to "the way the different societal problems are included and prioritized in the mission formulation" (Wesseling and Meijerhof, 2021, p. 6).</p>
        <p>The second feature is system delineation, i.e. the identification of the targeted system's boundaries. Funnell and Rogers (2011) argue that it is especially important to systematically scope and focus the programme theory for programmes that target complex and wicked problems (as is the case with Grand Challenges) since such problems otherwise "can lead to an ever-expanding boundary of what a program might usefully address" (p. 163). In transition terms, that would mean identifying and defining the targeted socio-technical configuration, i.e. the sociotechnical system(s), actors, and institutions (cf. Geels, 2004) in which a transition is needed to solve the identified problem. Additional dimensions could also be considered, such as spatial and temporal boundaries (Andersson et al., 2021).</p>
        <p>It should be noted that transformative change usually goes beyond individual socio-technical systems and might cut across multiple sectors (Rosenbloom, 2020). For evaluation, this brings additional challenges for boundary setting and scoping. Within given resource constraints, the evaluator would have to choose between a broader approach to account for multi-system interaction, resulting in a higher level of abstraction, or limit the scope of the evaluation to be able to go into more detail.foot_3 Due to our focus on behavioural additionality, which requires in-depth system analysis, we recommend the latter approach. However, this increases the need to consider interactions between more narrowly defined systems, such as the electricity and transport systems in relation to electric vehicles (Rosenbloom, 2020). When building the programme theory, it could therefore be useful to distinguish between outcomes that are infocus of the programme (i.e. the direct effects of the strategies and policy tools that the programme will use), outcomes that are out-offocus but within scope, i.e. indirect effects that are still the responsibility of the programme, and outcomes that are out-of-scope, i.e. intermediate and ultimate outcomes that go beyond the influence of the programme itself but are important for its success (Funnell and Rogers, 2011). Interactions across system boundaries can then be included in the evaluation as out-of-scope outcomes. To continue with the same example as above, the power regime related to the electricity system would probably be out-of-scope of a programme targeting the development of the electric vehicle niche, but it would still exert influence on it. This influence would have to be considered in an evaluation to assess whether the programme has been successful or not. This could potentially be followed up in meta-evaluations (see Section 2.2).</p>
        <p>The third feature refers to the more specific development path(s) the programme intends to stimulate. This relates to the need to make directionality more explicit when it comes to steering transition and innovations (Andersson et al., 2021;Pel et al., 2020). While there is no common understanding in the transitions literature on how to translate overarching challenges or missions to a more detailed level (Bergek et al., 2022), there are some frameworks that can potentially be useful here. For example, directionality can be described in terms of the intended transition pathway the programme aims to pursue. This would involve identifying the kinds of changes policymakers foresee in terms of multi-level interactions, actors and social groups, technologies and socio-technical systems, and rules and institutions (Geels and Schot, 2007). These can be described in four main archetypes: transformation (or reorientation), de-alignment and re-alignment, technological substitution, and reconfiguration (cf. Geels et al., 2016). Alternatively, MIS proponents refer to "solution directionality", which relates to the direction given to the search for solutions that can potentially fulfil a mission (Wesseling and Meijerhof, 2021). The authors propose a set of diagnostic questions the analyst could ask in order to explicate the solution directionality (cf. Wesseling and Meijerhof, 2021). Yet, another approach could be the analytical framework proposed by Pel et al. (2020), in which three angles of directionality are combined for analysing the governance in socio-technical transitions: socio-technical multiplicity (how actors envision the range of possible socio-technical configurations); appraisal diversity (how alternative configurations are valued and evaluated); and process dynamics and junctures (the analysis of system reproduction and transition pathways).</p>
        <p>While most of these approaches acknowledge that there can be multiple possible development paths for a particular targeted sociotechnical configuration, they do not provide much guidance when it comes to selecting a preferred path or assessing whether the paths that develop are acceptable or desirable from a societal point of view. Evaluation methods would then need to be supplemented by additional tools, such as technology assessment or technology foresight (OECD, 2021; Smits and Kuhlmann, 2004). Moreover, formative evaluation can enable the gradual adaptation of programmes, where alternative paths can be considered if the programme seems to be approaching a "tipping point", i.e. a "point at which a particular action is no longer adequate for meeting the plan's objective" (Haasnoot et al., 2013, p. 486).</p>
        <p>The second step is to explicate the programme's theory of change, as conceptualised in ToC evaluation, by developing an overview of the programme. The goal of this step is, thus, to reflect, via backwards mappingand in a collaborative manner with relevant stakeholdersthe ultimate aim of the programme, the types of outputs and outcomes that will help achieve the aim, and the activities and inputs required to bring about change (Blamey and Mackenzie, 2007;Rolfe, 2019). From a TIP perspective, this would mean capturing how the policymakers originally theorised socio-technical change processes (outcomes), their intended effects on the socio-technical transitions (impacts), and the contribution of policy to both outcomes and impacts (additionality).</p>
        <p>It should be noted, however, that it can be challenging to identify links between innovation theory and policy evaluation practice, as the complex nature of transformative policy makes it difficult to demonstrate all the consequences of a policy or policy mix (Janssen, 2019). The literature does not provide much guidance on how to deal with such complexities, except for suggesting the inclusion of both researchers and practitioners in the process while also using different sources of "theory", such as workshops with stakeholders, project documentation, theoretical literature, and other research evidence (Mason and Barnes, 2007;Reed et al., 2021). Nonetheless, while most traditional ToC approaches build on theory in terms of stakeholders' beliefs (Rogers and Weiss, 2007), we would argue that when it comes to TIP, the role of the evaluator should also be that of a translator between theory about transformative change and policy practice.</p>
        <p>Regarding the representation of complex programme interventions, Funnell and Rogers (2011) suggest using diagrams and concepts from systems thinking, e.g. network theory and system dynamics. These approaches seem more appropriate for TIP programme theory representation than the traditional, linear pipeline logic model (describing inputs, activities, outputs, and outcomes) since they make it possible to account for relationships between different actors (network theory) and feedback loops (system dynamics).</p>
        <p>Step 3 is about developing middle-range theories in the form of CMOc, by identifying causal mechanisms and relevant contextual factors within the generic ToC (Blamey and Mackenzie, 2007;Rolfe, 2019). More specifically, the evaluator identifies how causal mechanisms are expected to generate change in the targeted population. Rather than capturing all the possible causal pathways, the evaluator selects core points within the generic ToC where a range of causal mechanisms play out and lists them in the form of CMOc. These CMOc will be later tested and "populated" with evidence (Pawson et al., 2005) to identify how policy influences processes of change within the targeted socio-technical configuration and determine which changes are due to the programme, i.e. additionality.</p>
        <p>While there are many variations in the literature on how to use realist principles in practice (Pawson and Manzano-Santaella, 2012), CMOc can be presented in the form of a matrix, in which the evaluator placesin separate columnscontext, mechanism and outcomes so that each row corresponds to a hypothesis in the form of C1 + M1 = O1. This formula can be replaced by C&amp;Ms. → Oc to represent the large multilayered and multi-faceted complex social systems, as suggested by Byrne (2018). 10 While there is a lack of applications of these principles in relation to innovation policy, Step 5 of the integrated framework describes how CMOc can be refined for TIP interventions.</p>
        <p>The goal of the second component is to understand the outcomes in transformative terms, i.e. assess how the programme is promoting change in the targeted socio-technical configuration. It follows from the programme theory and includes two steps: (iv) analyse socio-technical change processes and (v) test and revise causal mechanisms. Together, these two steps form a framework for assessing behavioural additionality in terms of how a specific policy has influenced or contributed to intermediate transformative processes at the system level. Additionally, they later provide information about the directionality of the 10 Byrne (2018) modifies the original C + M = Oc formula to C&amp;Ms → Oc, in which (i) &amp; represents interaction rather than addition; (ii) the "s" in M refers to the plurality of mechanisms that might be operating; and (iii) the → indicates the directional path of causation rather than the = sign, which he argues is nondirectional. programme.</p>
        <p>Given the programme theory defined in component 1, the evaluator proceeds in this step with an analysis of socio-technical change processes. While the theory-based approach serves as a framework for evaluation, it still needs an analytical approach for determining the outcomes of the intervention (White, 2010), and in a TIP context the system analysis works as an analytical basis for this. The analysis also provides a basis for testing and refining CMOc in order to assess the additionality of the programme (Step 5) and for identifying the unfolding development path (Step 6).</p>
        <p>At this point, the evaluator should reflect on the depth of the system analysis, i.e. whether it is more appropriate to make a full analysis of the programme or choose key aspects to focus on, for example certain nicheinnovations, actor networks, institutional aspects, functionality, etc. This should be done in accordance with the goal of the programme and the purpose of the evaluation, as well as the pre-defined CMOc. While a full system analysis can provide a better overview of the performance and dynamics of the socio-technical system, which can also help to refine the CMOc in Step 5, time and resource constraints might make such an approach unfeasible.</p>
        <p>As discussed in Section 2.2, there are many frameworks useful for analysing policy and/or system-level processes and shedding light on potential programme outcomes. Most notably, these include frameworks drawing on the literature on niche building and regime destabilisation (Ghosh et al., 2021;Kern, 2012), structural or functional dynamics of (technological) innovation systems (Janssen, 2019;Kivimaa and Virkamäki, 2014), systemic failures (van Mierlo et al., 2010), or combinations of these (Bergek and Haddad, 2022;Kivimaa et al., 2017;Kivimaa and Kern, 2016;Scordato et al., 2018). Table 3 summarises some frameworks that can potentially be used for assessing sociotechnical system outcomes. Which of these is most useful for a particular evaluation will differ depending on, most notably, the transition goals and system boundaries of the program, as defined in Step 1 of the evaluation framework. In turn, the choice of system analysis framework should inform the evaluator's work with explicating the programme's theory of change (Step 2) and identifying potential causal mechanisms (Step 3).</p>
        <p>Methodology-wise, each of these frameworks comes with its own set of more detailed sub-processes, (soft) indicators, and guiding questions, which can be used in the analysis (see Appendix A). These can be studied using different qualitative and quantitative system analysis methods that have been developed for other purposes (most often research). 11 For example, process analysis, event analysis, expert ratings, and system dynamics modelling could inform evaluators about changes and mechanisms related to system functions and niche development processes; social network analysis could be used to trace different types of qualitative and quantitative changes in actor networks; and discourse analysis and discourse network analysis could identify various aspects of institutional change related to, for example, niche development and regime destabilisation (see Table 4). So far, all of the empirical applications have been qualitative (see Table 3), and most TIP evaluation researchers also seem to advocate qualitative approaches before quantitative ones since they allow for identifying underlying mechanisms and distinguishing policy influences from other factors driving and blocking transformative change, i.e. to establish causality (see next section).</p>
        <p>While the socio-technical analysis provides a suitable starting point for assessing socio-technical outcomes (Step 4), Step 5 is about using the evidence from that analysis to test and refine the CMOc hypotheses in order to seek a plausible explanation of how, for whom and why a programme works. In other words, the evaluator should both look for pieces of evidence that confirm (or reject) the hypothesised CMOc and refine the CMOc based on the findings from the socio-technical system analysis. In the following, we first discuss causality and how the TIP literature can inform the identification of causal mechanisms and context in relation to transformative change. We then reflect on how to establish behavioural additionality, i.e. provide evidence of the contribution of the programme to the observed transformative outcomes.</p>
        <p>As discussed in Section 3.2, realist evaluation follows the notion of generative causality, which is about understanding the relationship between mechanisms and the context to infer a causal outcome. The associated perspective of critical realism allows for a pluralistic approach to causal inference, i.e. complex causality (George and Bennett, 2004). Geels (2022) distinguishes three types of complex causality that can be used to explain sustainability transitions: (i) conjunctural (relatively independent events converge at some point in time to produce an outcome); (ii) configurational (components of a heterogeneous entity combine in different ways to produce an outcome); and (iii) eventchain (sequential interactions of events over time contribute to the generation of the outcome). As such, we believe that the idea of using complex causality can also be used when testing causal mechanisms and, thus, CMOc.</p>
        <p>The evaluation literature also provides some general insights into the types of causal mechanisms the evaluator could look for in realist evaluation. In addition to the two classic realist mechanisms of "power and liabilities of things" and "resources and reasoning" (cf. Pawson and Tilley, 1997), Westhorp (2018) proposes three ways mechanisms can be conceptualised for open systems, namely "forces", "interactions", and "feedback or feedforward processes". How could such general mechanisms be interpreted in the specific context of TIP? In fact, a great deal of criticism has been raised in the sustainability transitions literature regarding the limited capacity of systemic frameworks to explain causal mechanisms (cf. Papachristos, 2018;Sorrell, 2018;Svensson and Nikoleris, 2018). However, a few recent works have provided useful insights. Geels (2022) suggests that TIS has the potential to explain how mechanisms unfold over time in relation to different system functions (Bergek et al., 2008;Hekkert et al., 2007). This potential is discussed further by de Oliveira et al. (2020), who use a mechanism-based approach to improve the analytical capacity of the TIS framework to explain systemic malfunctioning and its implications. They describe causal mechanisms in terms of how systemic problemsor blocking mechanismshinder the fulfilment of TIS functions, 12 which allows policy analysts to better answer questions such as "how" and "why" blocking mechanisms impact an innovation system. In the same vein, inducement mechanisms that have a positive impact on functions can be identified (Johnson and Jacobsson, 2001). Geels (2022) also argues that SNM (Kemp et al., 1998;Smith and Raven, 2012) can explain the mechanisms underlying nicheinnovations, and that the MLP can explain "enacted processes and mechanisms that drive niche-innovations and disrupt socio-technical systems in the context of structural 'landscape' developments" (Geels, 2022, p. 10). 13 In addition to causal mechanisms, the evaluator should also look for contextual conditions. This will serve as starting point to understand how the context (C) influences mechanisms and the emergence of outcomes in the particular setting of the programme. In complex interventions, there can be a set of interrelated layers of contextual 11 For a general overview of methodological approaches related to transition studies, see Zolfagharian et al. (2019).</p>
        <p>12 This is similar to the definition of blocking mechanisms provided by the early TIS literature (Bergek et al., 2008;Johnson and Jacobsson, 2001;Wieczorek and Hekkert, 2012). 13 For example, Geels (2005) lists sixteen mechanisms for system innovation, organised into four main transition phases. These include, among others, the emergence of new social groups, the influence of outsiders on the development of radical innovations, and innovation races (cf. Geels, 2005). influences (Astbury, 2013). These include, for example, individual characteristics and capacity, programme staff and organisational setting, interpersonal relationships, as well as the overall political and institutional environment. As such, mechanisms and outcomes are influenced by factors internal or external to the programme and, we would add, the focal socio-technical system. Regarding the latter, the boundaries defined in Step 1 will determine what separates the focal system from its external context (de Oliveira et al., 2020). Accordingly, contextual factors can be related to various context structures, such as relevant sectors, geographical structures and political contexts (Bergek et al., 2015). They can also be landscape forces (cf. Geels and Schot, 2007), i.e. macro-level developments.</p>
        <p>In order to proceed from testing and refining CMOc to assessing behavioural additionality, we need to discuss the counterfactual. According to traditional impact evaluation approaches, attributing an observed change to a specific policy intervention requires a counterfactual, i.e. "what would have happened in the absence of the intervention" (Cummings, 2006, p. 6). In relation to innovation policy evaluation, this is typically achieved through before-after comparisons or control groups consisting of non-supported firms (cf. Afcha Chávez, 2011; Clarysse et al., 2009;Georghiou, 1998). Unfortunately, the TIP literature provides little guidance on how to address this in the context of transformative change. Janssen (2019) simply states that when it comes to transformative policy interventions, we might lack a good counterfactual and, similarly, Sorrell (2018Sorrell ( , p. 1279) ) points out that the problem with defining a counterfactual in MLP studies is due to the fact that causality "is assumed to result from multiple mechanisms and events that combine in different ways over very long periods of time" (i. e. complex causality).</p>
        <p>However, we would argue that even if it is difficult (or even impossible) to define a control group and establish cause-effect relationships by measuring the counterfactual through statistical analysis, this does not mean that there is no (implicit) counterfactual (cf. White, 2010). Indeed, some writings on theory-based evaluation have provided alternative ways to look for the counterfactual, in which the evaluator uses theory itself as the counterfactual (Cummings, 2006;Hind, 2010). This approach has been used in policy practice in different ways (American Evaluation Association, 2009;Hind, 2010). Most notably, Falleti (2016, p. 457) argues that "the process tracing method, applied in a deductive manner and through a series of evidence tests, can rule out or corroborate the existence of necessary and/or sufficient conditions that mediate between a hypothesised cause and the effect". This is also in line with Rogers and Weiss (2007), who argue that "if the evaluation can show the series of micro-steps that lead from inputs to outcomes, then causal attribution for all practical purposes seems to be within reach" (p. 70). This means that the evaluator can use different approaches to establish whether the collected evidence was due to the programme or not. The idea is, then, not to prove attribution definitively, but rather collect pieces of evidenceby means of mixed methods and complex causalityof the effect of a programme in order to establish behavioural additionality.</p>
        <p>Finally, the third component is aimed at analysing the overall directionality of the programme in relation to the intended (desired or acceptable) pathways of development (cf. Step 1 of the integrated framework). This can be further divided into two steps: (vi) assess the trajectory of change in relation to the intended direction (based on the findings from previous steps) and (vii) revisit (and revise) programme theory.</p>
        <p>In Step 1, the targeted transition of the programme was defined. In Step 6, the task is to assess the actual trajectory of change in order to indicate which development path the programme is, in fact, following, based on the findings from Steps 4 and 5. For example, if the evaluator chooses to analyse transition pathways, the findings from the sociotechnical system analysis (Step 4) and the hypothesis testing (Step 5) should be compared with the four elements of the pathways typology to "diagnose" the unfolding transition. This would provide evidence on whether the system is developing according to the chosen transition focus and if not why. The literature highlights two other ways to analyse transition pathways, including quantitative system modelling and practice-based action research (cf. Hof et al., 2020;Turnheim et al., 2015). Each approach contains strengths and weaknesses, and they can be used separately or in combination to complement the system analysis and provide a better picture of how the sustainability transition is unfolding (cf. Turnheim et al., 2015).</p>
        <p>If the evaluator instead opts to follow a MIS approach, the overall system analysis and evidence found in Steps 4 and 5 can indicate if the programme is contributing to achieving the mission, according to the solution directionality defined in Step 1. Another way is to assess how the transition directionality is manifesting itself by using a complementarity analysis of the three analytical angles proposed by Pel et al. (2020), i.e. the socio-technical multiplicity, appraisal diversity, and process dynamics and junctures.</p>
        <p>This last step aims at updating programme theory informed by the findings from the previous steps and, hence, works as a learning tool for policymakers to generate lessons for further policy practices and formative evaluation. While realist evaluation analysis can contribute to a process of learning and generate more robust ToCs (Rolfe, 2019), adding an analysis of the direction of change means that the evaluator can understand better if the programme theory achieved its purpose, as defined in Step 1. As such, in Step 7, the evaluator can "present conclusions as a series of contextualised decision points of the general format 'if A, then B' or 'In the case of C, D is unlikely of work'", as suggested by Pawson et al. (2005, p. 24). Therefore, the evaluator can conclude what has worked and not, and cooperate with programme managers and policymakers in developing recommendations for further improvements.</p>
        <p>Such an approach can serve as basis for a process of adaptation and reflexivity, given that the long-term aspect of transformative change calls for monitoring and adaptation strategies (Weber and Rohracher, 2012). Howlett (2009) highlights that evidence-based policymaking contributes to policy learning and can prevent the occurrence of policy failures and enhance the successful implementation of policies. Similarly, as suggested by Magro andWilson (2013, p. 1649), policy evaluation should also contribute to an "understanding of how complex innovation policy systems operate, fostering what is known as policy learning". Therefore, improved programme theory can inform future policy interventions (Mason and Barnes, 2007). A note of caution is that the context should always be taken into consideration.</p>
        <p>In the previous section, we pointed out how an integrated framework for evaluating TIP could be designed to tackle evaluation challenges such as behavioural additionality and directionality. We also highlighted, when relevant, how different approaches proposed in the TIP literature could be used for operationalising each step of the framework. In order to make the integrated framework more tangible, we use the BioInnovation Strategic Innovation Programme (SIP), funded by the Swedish Innovation Agency (Vinnova), as an illustrative example. Rather than trying to make a full evaluation of the BioInnovation SIP, we use this illustrative example as a "proof of principle" to demonstrate the feasibility of the framework (Edmondson et al., 2019;Fuenfschilling and Binz, 2018;Kanger et al., 2020).</p>
        <p>For this illustrative example, we rely on an analysis of different programme documents and reports describing the design and implementation of BioInnovation SIP, obtained from both BioInnovation's and Vinnova's project database in March 2021 (BioInnovation, 2021;Vinnova, 2021). We use the transition pathways proposed by Geels et al. (2016) to analyse the programme's directionality and the functions of innovation systems (Bergek et al., 2008;Hekkert et al., 2007) to analyse outcomes. Instead of illustrating the evaluation in full, which would require the analysis of all the processes described by the authors, we focus on resource mobilisation. 14</p>
        <p>Regarding the nature of the problem, the BioInnovation SIP started in 2015 inspired by current Grand Challenges, such as climate change, population growth and increased consumption of natural resources. In this context, it sees a circular bioeconomy as the way forward towards achieving sustainable development and contributing to the SDGs (Bio-Innovation, 2020c), and has a clear vision that Sweden will have transformed into a bioeconomy by 2050. This involves an increased use of bio-based raw materials, as well more resource-efficient processes.</p>
        <p>In terms of system delineation, the programme has not defined a focal socio-technical system but focuses on three main areas: Chemicals and Energy, Construction and Design, and Materials. This implies that the SIP involves a range of different actors from different industries, including forestry, chemicals, and pulp and paper.</p>
        <p>In terms of transition pathways, the programme does not clearly specify any desired pathways. Regarding actor networks, the programme description indicates that the aim is to create new business</p>
        <p>a Examples are for the most part not related specifically to policy evaluation but illustrate how a system analysis using a particular approach could be done more generally.</p>
        <p>14 A more complete analysis has been performed and is available elsewhere (see Haddad, 2021a).</p>
        <p>models by encouraging new entrants and reorienting established actors. At the technological level, it envisages the replacement of nonsustainable materials and chemicals with bio-based alternatives, in a so-called substitution process (BioInnovation, 2020c). This indicates that the current programme design presents characteristics of both the substitution pathway (at the technological level) and the reconfiguration pathway (at the actor and social groups level). Little is said, however, about the intended changes at the institutional level, apart from the need to change consumer behaviour and develop circular systems.</p>
        <p>Step 2 (explicate the programme's theory of change) BioInnovation focuses on different types of efforts and activities, by providing funding for different types of projects, including those focused on testing new ideas, developing areas that need special stimulus, demonstrating the feasibility of bio-based materials, products and services, promoting cooperation, and enhancing knowledge. The programme also has its own effect logic. Below, we provide a translation of this (espoused) effect logic using a transformative innovation policy lens, with a focus on the resource mobilisation function.</p>
        <p>Fig. 2 illustrates both a "slice" of the espoused effect logic and the adapted effect logic related to resource mobilisation. One example of what the programme is trying to achieve is that it foresees that the efforts towards setting up the Treesearch platform will enable the provision of infrastructure, which in turn will lead to a provision of expertise and research collaboration for the bioeconomy (Treesearch, 2020). In addition, BioInnovation envisages supporting the development of capacity in SMEs to work with bio-based solutions (BioInnovation, 2020a, 2020c).</p>
        <p>Due to the limitations of the current effect logic, some mechanisms and contextual aspects are left unexplained. When developing a realist matrix for the resource mobilisation example (see Table 5), some explanatory factors are, consequently, missing (see text in red). In a real programme evaluation using our framework, this would have been coveredor at least reflected uponin the previous steps but in this case, we are left with some gaps. For the Treesearch platform, we could, however, formulate the CMOc Efforts towards setting up 
            <rs type="software">Treesearch</rs> platform &amp; 
            <rs type="software">Treesearch</rs> platform provides infrastructure → Provision of expertise and research collaboration.
        </p>
        <p>Within BioInnovation, a variety of resources are being mobilised. 15 In terms of financial resources, the programme has been providing funding for RD&amp;D through different project types, such as cooperation projects and projects related to enhancing knowledge. Funds are being mobilised to, among other things, produce fuels and chemicals from lignin and other forest raw materials, improve resource use in construction by adopting the use of wood-based materials, and develop textile fibres made from forest raw materials. Bio-based innovations in healthcare have also received a good portion of the funding. Other technologies that were targeted include chemicals from forest raw materials, as well as packaging and new bio-based composites. Some projects also signal that they would like to continue developing their solutions after participating in the programme. This can indicate behavioural additionality in terms of an influence of public funding on company strategies.</p>
        <p>Regarding human resources, 
            <rs type="software">Treesearch</rs> has been training and supporting doctoral and postdoctoral projects on new materials and chemicals from forest raw materials (
            <rs type="software">Treesearch</rs>, 2020). It has also been responsible for advancing an open research infrastructure on materials and chemicals (Treesearch, 2020), indicating that resources are being mobilised in the form of complementary assets and infrastructure. Additionally, another project (namely BioLyftet) has been set up and is providing education and training for SMEs to work with bio-based solutions. For example, SMEs are being trained on how to replace fossilbased materials with bio-based ones in their products (BioInnovation, 2020b).
        </p>
        <p>Table 6 shows the list of tested and refined CMOc.</p>
        <p>Given that the illustrative example has focused on one specific system process, i.e. resource mobilisation, it is hard to assess the trajectory of change that is unfolding in terms of transition pathways (Step 6: Assess the trajectory of change). Identifying transition pathways would require a full system analysis, including changes in technology, actor networks and institutions (cf. Geels et al., 2016), which goes beyond this proof of principle. However, previous work showed early signs of the reconfiguration pathway at the actor level, as many incumbents have been participating in various projects, while new entrants have been rare (Haddad, 2021a). This needs to be investigated further, given that little is known about the effect on the behaviour of incumbents. At the technological level, solutions are being developed to either be combined with existing technologies or replace established ones, also indicating signs towards reconfiguration. There has not been much effort to achieve regime destabilisation and institutional change, which is a sign of the reproduction pathway at the institutional level.</p>
        <p>Revisiting and revising programme theory (Step 7) would be the next step, allowing for formative evaluation and adaption of what is not working and course correcting for unintended outcomes.</p>
        <p>The purpose of this paper was to develop a framework for evaluating transformative innovation programmes, which integrates insights from literature on sustainability transitions and policy evaluation to address 15 Resource mobilisation can be analysed in terms of rising volumes of capital, financial resources, changes in complementary assets and infrastructure, public and private funding, education and training, and development of complementary infrastructure (Bergek, 2019;Bergek et al., 2008).</p>
        <p>directionality and system-level behavioural additionality. We argued that closer integration between the TIP and policy evaluation literatures could be a useful approach to addressing these gaps. Drawing on recent frameworks for TIP evaluation and theory-based evaluation, the contribution of this paper is an integrated framework for evaluating transformative innovation policy. In this framework, insights on theorybased evaluation, which examines causal mechanisms and contextual factors, are key to understanding complex processes between, on the one hand, policy design and implementation and, on the other hand, policy outcomes. Additionally, insights from different perspectives on sociotechnical systems provide a basis for identifying transformative outcomes that can potentially unleash a transition and determining whether these outcomes are due to the policy intervention.</p>
        <p>The resulting integrated evaluation framework is composed of three main components, which form the building blocks to develop a theorybased evaluation of transformative innovation policy. The first component addresses the need for a more structured programme theory and describes the links between the policy intervention and its expected effects. Its purpose is to serve as theoretical support for the evaluation.</p>
        <p>For TIP, this programme theory is based on a transformative perspective that includes directionality in terms of desired (or accepted) development path(s), for example in terms of transition pathways (Geels et al., 2016;Geels and Schot, 2007), solution directionality (Wesseling and Meijerhof, 2021), or angles of directionality (Pel et al., 2020). This allows for a later assessment of which direction(s) of change the program has enabled. The second component comprises a socio-technical system analysis to assess transformative outcomes, which can be based on existing socio-technical system frameworks based on, for example, MLP, SNM or TIS (cf. Bergek and Haddad, 2022;Ghosh et al., 2021;Janssen, 2019;Kern, 2012;Kivimaa and Kern, 2016;Kivimaa and Virkamäki, 2014;Scordato et al., 2018;van Mierlo et al., 2010). The TIP literature also provides ways to identify causal mechanisms and contextual factors to generate such outcomes. We argue that even if a traditional counterfactual in the form of a control group cannot be established, additionality can be assessed by following the notions of generative and complex causality (cf. Geels, 2022), i.e. by identifying causal mechanisms and the contexts within which they operate to generate outcomes. The third component consists of synthesising the evidence of the</p>
        <p>Realist matrix related to resource mobilisation process. In order to allow for formative evaluation and learning, we suggest that the evaluator revisits and revises the programme theory based on the findings from the evaluation. Some limitations related to the integrated framework should be highlighted. First, the proposed integrated framework was developed through a deductive approach and, hence, the practical side of the policymaking process related to evaluation still needs to be reflected upon. Therefore, future adjustments might be needed according to findings from empirical applications and feedback from policymakers. While we included an empirical illustration of how the framework can be applied, this does not show the full capacity of the framework in identifying mechanisms and evidence of transformative change. Second, dealing with entire socio-technical systems involves new challenges to setting system boundaries, which influence the depth and breadth of the evaluation. This can have a direct impact on the practical application of the framework in terms of costs, resources needed, human capacity, and time. Additionally, the framework is intended for the evaluation of programmes rather than very complex policy mixes, which can bring additional challenges for the evaluator. On top of that, there is an extra layer of complexity if the evaluator needs to account for interactions across multiple systems or consider alternative development paths when designing programme theory. Third, although the focus is on policy programmes aiming at handling societal challenges and achieving sustainability transitions, the framework does not include the environmental or social consequences of the transition itself. While we do not see this as being part of the scope of a TIP-integrated framework, policymakers still need to consider such consequences when setting goals and designing and adapting programmes targeting system innovation. This can, for example, be explored in summative evaluations, where measurable goals, such as the reduction of CO 2 emissions can be included as part of societal impact, as suggested by Janssen et al. (2022). Alternative strategic intelligence tools, such as technology assessment and technology foresight (cf. OECD, 2021; Robinson et al., 2021), could also be used for this purpose.</p>
        <p>Opportunities for further research include the application and operationalisation of the framework to multiple empirical situations and using different methods. Additionally, the discussions about how to define the counterfactual in the context of transformative innovation policy need to be explored further. While some scholars have pointed out that there is a lack of a clear counterfactual regarding transformative policy (Janssen, 2019), we have argued in this paper that there is a possibility to use theory as a way to construct the counterfactual, following a generative view of causality. This view allows the exploration, in context, of the patterns between interventions and outcomes, and has already been applied in past innovation programmes (American Evaluation Association, 2009;Hind, 2010). However, questions such as how to approach this in practice in order to establish causal links between policy intervention and outcomes in TIP interventions need to be explored further. Moreover, this approach might require a complete analysis of the entire system, but can evaluators be expected to do that within their usually limited timeframe and budget? As mentioned previously, this becomes even more challenging if the evaluator needs to consider multi-system interactions. In such cases, the application of meta-evaluations or secondary analysis (as suggested by Arnold, 2004;Edler et al., 2008) can be helpful. However, this has rarely been done in the specific context of TIP interventions, apart from recent evaluations of the Swedish SIPs (cf. Technopolis, 2020). Furthermore, the integrated framework highlights that the kind of system-level effects evaluators should be looking for go beyond current understandings of behavioural additionality. This concept has already been broadened in relation to its initial conceptualisationfrom the firm level to a population of firms (cf. Gök, 2010) -but we would thus argue that there is a need to consider a new type of "transformative additionality" that can capture the effect of transformative change in socio-technical configurations.</p>
        <p>Carolina R. Haddad: Conceptualization, Writingoriginal draft. Anna Bergek: Conceptualization, Writingoriginal draft, Supervision, Funding acquisition.</p>
        <p>The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. All of the sources of funding for the work described in this publication are acknowledged below.</p>
        <p>List of refined CMOc for resource mobilisation.</p>
        <p>▪ Influence on structural system change (indirect)</p>
        <p>Ghosh et al. (2021)</p>
        <p>Programme ▪ MLP (niche and regime processes) ▪ SNM (niche processes)</p>
        <p>▪ Influence on innovation and transformation processes</p>
        <p>Bergek and Haddad (2022)</p>
        <p>Programme ▪ TIS (functions) ▪ SNM (niche processes) ▪ MLP (niche and regime processes, transition pathways)</p>
        <p>This section draws onHaddad (2021b), which in turn draws on previous versions of this paper.</p>
        <p>Some of these perspectives refer to science and technology policy rather than innovation policy in the modern sense of the word. For the purpose of this paper, we nevertheless consider them innovation policy perspectives as they are important predecessors to today's innovation policy and the evaluation practices connected to them are still used in innovation policy evaluations. This is also in line with previous descriptions of the history of the field (seeMartin, 2012).</p>
        <p>Theory-based is also referred to in the literature as theory-led, theory-oriented, or theory-driven evaluation.C.R.Haddad and A. Bergek</p>
        <p>This has also been suggested byHoltz et al. (2015) for defining the boundaries of transition models.</p>
        <p>Funding from the Swedish Innovation Agency Vinnova through the Swedish Transformative Innovation Policy Platform (STIPP) [grant number: 2017-01600] is gratefully acknowledged. The funder has not been involved in study design; data collection, analysis, or interpretation; the writing of the article; or the decision to submit the article for publication.</p>
        <p>No data was used for the research described in the article.</p>
        <p>Supplementary data to this article can be found online at https://doi. org/10.1016/j.respol.2022.104676.</p>
    </text>
</tei>
