<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-13T13:34+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>Die Deutsche Nationalbibliothek verzeichnet diese Publikation in der Deutschen Nationalbibliografie; detaillierte bibliografische Daten sind im Internet über http://dnb.d-nb.de abrufbar.Die Deutsche Nationalbibliothek verzeichnet diese Publikation in der Deutschen Nationalbibliografie; detaillierte bibliografische Daten sind im Internet über http://dnb.d-nb.de abrufbar.</p>
        <p>. Die Gesellschaft weiß um die vermeintlich elementare Bedeutung der digitalen Computertechnik und informationsverarbeitender Systeme für die Welt. Sie beschreibt sich selbst mitunter bereits als eine digitale Gesellschaft.. Die Gesellschaft weiß um die vermeintlich elementare Bedeutung der digitalen Computertechnik und informationsverarbeitender Systeme für die Welt. Sie beschreibt sich selbst mitunter bereits als eine digitale Gesellschaft.</p>
        <p>Ein Abschalten der Digitaltechnik ist also mittlerweile undenkbar geworden und es gibt vermeintlich kein Zurück hinter den Status quo. Vielmehr hat man sich mit dem gesellschaftlichen Vordringen von Phänomenen und Artefakten der Digitalisierung und mit der mit ihnen einhergehenden digitalen Datensammlung und -verwertung anscheinend abgefunden, trotz substantieller nachteiliger und risikobehafteter Entwicklungen wie bspw. Privatheitsrisiken und der Nicht-Nachvollziehbarkeit automatisiert im Hintergrund getroffener Entscheidungen durch vernetzte Computersysteme. Sei es unverzichtbare Steuerungstechnik in Industrie, Handel und Verkehr oder lediglich das Smartphone, auf das bereits die Mehrheit aller Jugendlichen im Leben nicht mehr verzichten will (Bitkom, 2019).Ein Abschalten der Digitaltechnik ist also mittlerweile undenkbar geworden und es gibt vermeintlich kein Zurück hinter den Status quo. Vielmehr hat man sich mit dem gesellschaftlichen Vordringen von Phänomenen und Artefakten der Digitalisierung und mit der mit ihnen einhergehenden digitalen Datensammlung und -verwertung anscheinend abgefunden, trotz substantieller nachteiliger und risikobehafteter Entwicklungen wie bspw. Privatheitsrisiken und der Nicht-Nachvollziehbarkeit automatisiert im Hintergrund getroffener Entscheidungen durch vernetzte Computersysteme. Sei es unverzichtbare Steuerungstechnik in Industrie, Handel und Verkehr oder lediglich das Smartphone, auf das bereits die Mehrheit aller Jugendlichen im Leben nicht mehr verzichten will (Bitkom, 2019).</p>
        <p>Vielerorts wird mithin noch mehr Digitalisierung gefordert, selbst wenn zunächst oft ungeklärt bleibt, was eigentlich konkret gemeint ist, wenn mit Bezug auf die Verbreitung von Computertechnik und den damit einhergehenden gesellschaftlichen Veränderungen derzeit ganz allgemein von der Digitalisierung gesprochen wird. Dieser Umgang der Gesellschaft mit der Digitalisierung wirft Fragen auf: Woher rühren die weit verbreiteten Überzeugungen von der positiven Wirkmächtigkeit der Digitalisierung? Worauf genau beziehen sich überhaupt die gesellschaftlichen Erwartungen, wenn es um den positiven Einfluss der Digitaltechnik geht? Und welche Konsequenzen haben diese Erwartungen für Legitimation und Delegitimation von Handeln und Entscheiden in der digitalen Gesellschaft? Analog zum politischen Handeln bezieht auch das Handeln in der sich digitalisierenden Gesellschaft "seine Rationalität wie auch seine Legitimität aus bestimmten Annahmen oder Vorstellungen über die Wirklichkeit. Argumente, Programme und Begriffe (…) spiegeln nicht die reale Welt, sondern spezifische Interpretationen derselben wider" (J. Hofmann, 1993, S. 13). Diesen mittelbaren wirklichkeitskonstruierenden Zugang und Umgang mit der Digitalisierung untersucht die vorliegende Arbeit an einem ihrer zentralen Elemente: den digitalen Daten, die im Zuge der Digitalisierung und der Verbreitung von Informationsund Kommunikationstechnologie (IuK) laufend weltweit entstehen, gespeichert, zusammengeführt und ausgewertet werden. Die hierbei entstehenden großen digitalen Datenbestände werden auch als Big Data bezeichnet: ein Begriff, der eine besondere Wahrnehmung von digitalen Daten und Erwartungen an diese formuliert.Vielerorts wird mithin noch mehr Digitalisierung gefordert, selbst wenn zunächst oft ungeklärt bleibt, was eigentlich konkret gemeint ist, wenn mit Bezug auf die Verbreitung von Computertechnik und den damit einhergehenden gesellschaftlichen Veränderungen derzeit ganz allgemein von der Digitalisierung gesprochen wird. Dieser Umgang der Gesellschaft mit der Digitalisierung wirft Fragen auf: Woher rühren die weit verbreiteten Überzeugungen von der positiven Wirkmächtigkeit der Digitalisierung? Worauf genau beziehen sich überhaupt die gesellschaftlichen Erwartungen, wenn es um den positiven Einfluss der Digitaltechnik geht? Und welche Konsequenzen haben diese Erwartungen für Legitimation und Delegitimation von Handeln und Entscheiden in der digitalen Gesellschaft? Analog zum politischen Handeln bezieht auch das Handeln in der sich digitalisierenden Gesellschaft "seine Rationalität wie auch seine Legitimität aus bestimmten Annahmen oder Vorstellungen über die Wirklichkeit. Argumente, Programme und Begriffe (…) spiegeln nicht die reale Welt, sondern spezifische Interpretationen derselben wider" (J. Hofmann, 1993, S. 13). Diesen mittelbaren wirklichkeitskonstruierenden Zugang und Umgang mit der Digitalisierung untersucht die vorliegende Arbeit an einem ihrer zentralen Elemente: den digitalen Daten, die im Zuge der Digitalisierung und der Verbreitung von Informationsund Kommunikationstechnologie (IuK) laufend weltweit entstehen, gespeichert, zusammengeführt und ausgewertet werden. Die hierbei entstehenden großen digitalen Datenbestände werden auch als Big Data bezeichnet: ein Begriff, der eine besondere Wahrnehmung von digitalen Daten und Erwartungen an diese formuliert.</p>
        <p>Die Funktion digitaler Daten im Rahmen der Digitalisierung ist dabei ihrem Wesen nach zu allererst eine mathematische, betrifft hier Zahlen, Symbole und Formeln. Kurzum ist Information gemeint; ausgedrückt in einer binär codierten Sequenz von Zustandsbeschreibungen, die elementar für das Funktionieren der Digitaltechnik sind. Digitale Daten zeitigen dann allerdings insbesondere immer dort soziale Konsequenzen, wo sie menschliche Entscheidungen beeinflussen (Mau, 2017;Mayer-Schönberger &amp; Cukier, 2013;Nassehi, 2019;Reckwitz, 2017). Doch wie nähert man sich einem nicht direkt und unmittelbar zu beobachtenden Untersuchungsgegenstand? Wie Hofmann (1993) betont, hat es sozialwissenschaftliche Forschung ja gerade "nicht mit eindeutigen Tatbeständen (…) zu tun, sondern mit theoriegeladenen Konstrukten, bestehend aus einem Amalgam sozialwissenschaftlicher und alltagsweltlicher Definitionen, Konventionen und Abstraktionen" (S. 14). Als solch ein theoriegeladenes Konstrukt müssen mit Blick auf die notwendige Analyse ihrer sozialen Wirkmächtigkeit auch digitale Daten verstanden werden.Die Funktion digitaler Daten im Rahmen der Digitalisierung ist dabei ihrem Wesen nach zu allererst eine mathematische, betrifft hier Zahlen, Symbole und Formeln. Kurzum ist Information gemeint; ausgedrückt in einer binär codierten Sequenz von Zustandsbeschreibungen, die elementar für das Funktionieren der Digitaltechnik sind. Digitale Daten zeitigen dann allerdings insbesondere immer dort soziale Konsequenzen, wo sie menschliche Entscheidungen beeinflussen (Mau, 2017;Mayer-Schönberger &amp; Cukier, 2013;Nassehi, 2019;Reckwitz, 2017). Doch wie nähert man sich einem nicht direkt und unmittelbar zu beobachtenden Untersuchungsgegenstand? Wie Hofmann (1993) betont, hat es sozialwissenschaftliche Forschung ja gerade "nicht mit eindeutigen Tatbeständen (…) zu tun, sondern mit theoriegeladenen Konstrukten, bestehend aus einem Amalgam sozialwissenschaftlicher und alltagsweltlicher Definitionen, Konventionen und Abstraktionen" (S. 14). Als solch ein theoriegeladenes Konstrukt müssen mit Blick auf die notwendige Analyse ihrer sozialen Wirkmächtigkeit auch digitale Daten verstanden werden.</p>
        <p>Die vorliegende Arbeit versucht dabei mittels einer umfassenden sozialwissenschaftlichen Analyse Antworten auf die zuvor aufgeworfenen Fragen zur Wahrnehmung der Digitalisierung in der Gesellschaft zu geben. Dabei ermöglicht das nachfolgend beschriebene Vorgehen eine empirisch geleitete Reflexion über die menschliche Perspektive auf eine der zentralen Erzählungen der digitalisierten Gesellschaft: den Mythos Big Data und seine Rolle für die gesellschaftliche Wahrnehmung der Entwicklungen der Digitalisierung. Die folgenden Ausführungen lassen sich dabei in zwei Teile aufteilen und geben die übergeordnete Strukturierung der Arbeit vor. Gesellschaftliche Diskurse zur datengetriebenen Digitalisierung und Wissensgesellschaft führen zu einem Wahrnehmungsmuster von digitalen Daten, das -so das Argument des ersten Teils der vorliegenden Arbeit -in einem weit verbreiteten Glauben in Bezug auf digitale Daten münden könnte. Wie gezeigt werden wird, vereint dieses sogenannte ‚Big-Data-Glaubenssystem' (BDGS) für das Individuum nur mittelbar zu erfahrende und somit weitgehend unnachprüfbare Eindrücke, die mit digitalen Daten im Rahmen der Digitalisierung verbunden sind. Diese Wahrnehmungen können vor dem Hintergrund der gesellschaftlichen Erzählung einer Wissensgesellschaft und deren Resonanz in den persönlichen Überzeugungen von Erkenntnis-und Nutzengewinnen integriert werden.Die vorliegende Arbeit versucht dabei mittels einer umfassenden sozialwissenschaftlichen Analyse Antworten auf die zuvor aufgeworfenen Fragen zur Wahrnehmung der Digitalisierung in der Gesellschaft zu geben. Dabei ermöglicht das nachfolgend beschriebene Vorgehen eine empirisch geleitete Reflexion über die menschliche Perspektive auf eine der zentralen Erzählungen der digitalisierten Gesellschaft: den Mythos Big Data und seine Rolle für die gesellschaftliche Wahrnehmung der Entwicklungen der Digitalisierung. Die folgenden Ausführungen lassen sich dabei in zwei Teile aufteilen und geben die übergeordnete Strukturierung der Arbeit vor. Gesellschaftliche Diskurse zur datengetriebenen Digitalisierung und Wissensgesellschaft führen zu einem Wahrnehmungsmuster von digitalen Daten, das -so das Argument des ersten Teils der vorliegenden Arbeit -in einem weit verbreiteten Glauben in Bezug auf digitale Daten münden könnte. Wie gezeigt werden wird, vereint dieses sogenannte ‚Big-Data-Glaubenssystem' (BDGS) für das Individuum nur mittelbar zu erfahrende und somit weitgehend unnachprüfbare Eindrücke, die mit digitalen Daten im Rahmen der Digitalisierung verbunden sind. Diese Wahrnehmungen können vor dem Hintergrund der gesellschaftlichen Erzählung einer Wissensgesellschaft und deren Resonanz in den persönlichen Überzeugungen von Erkenntnis-und Nutzengewinnen integriert werden.</p>
        <p>Dabei wird in Kapitel 2 zunächst allgemein auf die Digitalisierung als übergeordnetes Phänomen sowie auf die an sie unter den Vorzeichen sozialen Wandels gerichteten Erwartungen abgestellt. Es ist dann auf die digitalen Daten einzugehen, die bezüglich des (Selbst-)Verständnisses der digitalisierten Gesellschaft eine zentrale Rolle einnehmen. Abgeleitet von den geläufigen Definitionen des Begriffs Big Data wird in Kapitel 3 gezeigt, welche konkreten epistemischen Vorstellungen in Bezug auf die digitalen Datenbestände im Glaubenssystem bestehen können und mithin beobachtbar sein sollten. Dafür wird, ausgehend von den Beschreibungsdimensionen von Big Data, die ihren Ursprung in einer primär wissenschaftlich-industriellen Perspektive auf die großen digitalen Datenbestände nehmen, zum einen ein allgemeines Verständnis für die Beschaffenheit der digitalen Daten hergestellt. Zum anderen wird in Kapitel 4 der Verwertungs-und Wirkungszusammenhang digitaler Daten adressiert, der zu einem sogenannten Mythos Big Data beiträgt (boyd &amp; Crawford, 2012). Die an diesen geknüpften Erwartungen an die Richtigkeit der Daten und aus ihnen gewonnenen Erkenntnis bilden zentrale Elemente des Glaubenssystems. Diese besondere Qualität der digitalen Daten für Erkenntnis und Wissen fallen hier auf einen fruchtbaren Boden, der in den letzten Jahrzehnten durch die öffentlichen Diskurse über die angesprochene Wissensgesellschaft bestellt wurde. In deren Rahmen hat eine Bewertungs-und Vergleichslogik Ausbreitung gefunden, die in Kapitel 5 besprochen wird und in deren Rahmen sich der vermeintliche Nutzen der Digitalisierung für Individuum und Gesellschaft durch die Quantifizierung des Sozialen verdeutlichen lässt. Eine Erwartungshaltung, die sich aus der Wahrnehmung der dokumentierten Potentiale digitaler Daten ergibt, lässt sich unter den Vorzeichen der Nicht-Nachprüfbarkeit der tatsächlichen Voraussetzungen, Qualitäten und Konsequenzen digitaler Daten dann in Kapitel 6 als Glaubenssystem skizzieren.Dabei wird in Kapitel 2 zunächst allgemein auf die Digitalisierung als übergeordnetes Phänomen sowie auf die an sie unter den Vorzeichen sozialen Wandels gerichteten Erwartungen abgestellt. Es ist dann auf die digitalen Daten einzugehen, die bezüglich des (Selbst-)Verständnisses der digitalisierten Gesellschaft eine zentrale Rolle einnehmen. Abgeleitet von den geläufigen Definitionen des Begriffs Big Data wird in Kapitel 3 gezeigt, welche konkreten epistemischen Vorstellungen in Bezug auf die digitalen Datenbestände im Glaubenssystem bestehen können und mithin beobachtbar sein sollten. Dafür wird, ausgehend von den Beschreibungsdimensionen von Big Data, die ihren Ursprung in einer primär wissenschaftlich-industriellen Perspektive auf die großen digitalen Datenbestände nehmen, zum einen ein allgemeines Verständnis für die Beschaffenheit der digitalen Daten hergestellt. Zum anderen wird in Kapitel 4 der Verwertungs-und Wirkungszusammenhang digitaler Daten adressiert, der zu einem sogenannten Mythos Big Data beiträgt (boyd &amp; Crawford, 2012). Die an diesen geknüpften Erwartungen an die Richtigkeit der Daten und aus ihnen gewonnenen Erkenntnis bilden zentrale Elemente des Glaubenssystems. Diese besondere Qualität der digitalen Daten für Erkenntnis und Wissen fallen hier auf einen fruchtbaren Boden, der in den letzten Jahrzehnten durch die öffentlichen Diskurse über die angesprochene Wissensgesellschaft bestellt wurde. In deren Rahmen hat eine Bewertungs-und Vergleichslogik Ausbreitung gefunden, die in Kapitel 5 besprochen wird und in deren Rahmen sich der vermeintliche Nutzen der Digitalisierung für Individuum und Gesellschaft durch die Quantifizierung des Sozialen verdeutlichen lässt. Eine Erwartungshaltung, die sich aus der Wahrnehmung der dokumentierten Potentiale digitaler Daten ergibt, lässt sich unter den Vorzeichen der Nicht-Nachprüfbarkeit der tatsächlichen Voraussetzungen, Qualitäten und Konsequenzen digitaler Daten dann in Kapitel 6 als Glaubenssystem skizzieren.</p>
        <p>Es schließen folglich in Kapitel 7 Fragen nach der Prävalenz und Konsequenz dieses Big-Data-Glaubenssystems an, die im zweiten Teil der Arbeit empirisch beantwortet werden. Es wird dabei zunächst in einer ersten Studie eine standardisierte kognitionspsychologische Messung dieses Glaubenssystems vorgeschlagen, für die aufbauend auf den Beschreibungsdimensionen von Big Data eine Itembatterie für die Anwendung in Befragungsstudien entwickelt wurde. Wie in Kapitel 8 dokumentiert, kam diese Itembatterie in einer Erhebung zur Skalenkonstruktion zum Einsatz. Diese führt zu einer vierdimensionalen Befragungsskala, die auf Einschätzungen der Genauigkeit, des Wissensgewinns sowie des individuellen und gesellschaftlichen Nutzens der großen digitalen Datenbestände Bezug nimmt. Die Skalenentwicklung wurde dann nachfolgend in zwei weiteren Erhebungen validiert und Ergebnisse aus der Anwendung im Feld werden in Kapitel 9 berichtet. Es zeigt sich hierbei eine ausgeprägte Überzeugung von einem Wissensgewinn aus Big Data, der mit Erwartungen an zu realisierenden individuellen sowie gesellschaftlichen Nutzen durch die Sammlung und Auswertung großer digitaler Datenbestände einhergeht.Es schließen folglich in Kapitel 7 Fragen nach der Prävalenz und Konsequenz dieses Big-Data-Glaubenssystems an, die im zweiten Teil der Arbeit empirisch beantwortet werden. Es wird dabei zunächst in einer ersten Studie eine standardisierte kognitionspsychologische Messung dieses Glaubenssystems vorgeschlagen, für die aufbauend auf den Beschreibungsdimensionen von Big Data eine Itembatterie für die Anwendung in Befragungsstudien entwickelt wurde. Wie in Kapitel 8 dokumentiert, kam diese Itembatterie in einer Erhebung zur Skalenkonstruktion zum Einsatz. Diese führt zu einer vierdimensionalen Befragungsskala, die auf Einschätzungen der Genauigkeit, des Wissensgewinns sowie des individuellen und gesellschaftlichen Nutzens der großen digitalen Datenbestände Bezug nimmt. Die Skalenentwicklung wurde dann nachfolgend in zwei weiteren Erhebungen validiert und Ergebnisse aus der Anwendung im Feld werden in Kapitel 9 berichtet. Es zeigt sich hierbei eine ausgeprägte Überzeugung von einem Wissensgewinn aus Big Data, der mit Erwartungen an zu realisierenden individuellen sowie gesellschaftlichen Nutzen durch die Sammlung und Auswertung großer digitaler Datenbestände einhergeht.</p>
        <p>Analyse der an sie gerichteten Erwartungen von Bedeutung sein? Dem Grundverständnis nach ist die Digitalisierung vordergründig nichts weiter als ein technischer Prozess, bei dem analoge Entitäten in ein digitales, meist binäres Format übertragen werden, mit dem Ziel, dieses mit Hilfe informationstechnischer Infrastrukturen wie bspw. dem Computer zu speichern und zu verarbeiten (Brennen &amp; Kreiss, 2016;Chun &amp; Soderman, 2008;Storsul &amp; Fagerjord, 2008). Schon hier zeigt sich, dass Digitalisierung im ursprünglichen Sinne lediglich auf binär codierte Information abstellt, ein dann digitales Datum. Jedoch verbirgt sich hinter jenem Phänomen, das wir insbesondere in Deutschland mit jenem Oberbegriff Digitalisierung bezeichnen, eine Vielzahl an unterschiedlichen Begriffen, Phänomenen, Erzählungen und Vorstellungen. 1 Die Erzählungen beginnen hierbei meist mit einer einfachen Betrachtung von elektronischen Artefakten wie dem Computer im Zusammenspiel mit seinem menschlichen Nutzer und enden nicht selten in einer durch eben jene elektronischen Datenverarbeitungsanlagen ausgelösten Transformation menschlicher Gesellschaften oder gar gleich in einer vollständigen digitalen Transzendenz menschlicher Biologie und Erfahrungetwa, wenn es um Vorstellungen davon geht, die menschliche Seele in einen Computer ‚hochzuladen' (Barrat, 2013;Bostrom, 2016;Callaghan et al., 2017;Kurzweil, 2005;Tegmark, 2018). Etwas nüchterner betrachtet begründet sich der vermeintliche Siegeszug auf der vielfältigen, beinahe alle menschlichen Lebensbereiche durchdringenden Verwendung von Computern und den vordergründig positiven Veränderungen, die diese Entwicklung mit sich bringt. Der vermeintliche Gewinn besteht für das menschliche Individuum und seine Gesellschaft darin, einen Nutzen aus dieser fortschreitenden Digitalisierung zu ziehen, also Vorteile mit Blick auf Wirtschaft, Politik, Gesundheit, Kommunikation etc. zu erfahren, die ohne Digitalisierung so nicht möglich sind. Dabei kommt es mitunter auch zu überzogenen Zukunftserwartungen, was Digitalisierung leisten kann und soll. So formuliert der Journalist Jürgen Kaube mit Blick auf die Digitalisierung der Schule folgende Beobachtung (Kaube, 2019): "Man muss heute in jedem Lebensbereich nur noch ‚Digitalisierung' sagen, und schon meldet sich der Verstand zugunsten von Visionen ab" ( § 3). Was ist dran an dieser Aussage? Dient der Begriff Digitalisierung womöglich als eine ‚Applaus!'-Anzeige, bei deren Aufleuchten das Publikum angehalten ist unreflektiert und ohne tatsächlichen Anlass mitzuklatschen (Yudkowsky, 2018)? Ist der Begriff bloß ein Feigenblatt, das vor einer tiefergehenden Betrachtung und kritischen Nachfragen schützt, was und warum da nun wie durch Hard-und Software ergänzt, verändert, oder gar verbessert werden soll? Glauben Bürger*innen in Deutschland vielleicht tatsächlich, dass jede Maßnahme, die nur das Label Digitalisierung trägt, zum Selbstläufer wird, bei dem sich der Erfolg von selbst einstellt? Der gesellschaftliche Umgang mit der Digitalisierung erscheint vielschichtiger und uneindeutiger, als es das digitale Kodierschema von 1 und 0 für Erfolg oder Misserfolg der Digitalisierung suggeriert.Analyse der an sie gerichteten Erwartungen von Bedeutung sein? Dem Grundverständnis nach ist die Digitalisierung vordergründig nichts weiter als ein technischer Prozess, bei dem analoge Entitäten in ein digitales, meist binäres Format übertragen werden, mit dem Ziel, dieses mit Hilfe informationstechnischer Infrastrukturen wie bspw. dem Computer zu speichern und zu verarbeiten (Brennen &amp; Kreiss, 2016;Chun &amp; Soderman, 2008;Storsul &amp; Fagerjord, 2008). Schon hier zeigt sich, dass Digitalisierung im ursprünglichen Sinne lediglich auf binär codierte Information abstellt, ein dann digitales Datum. Jedoch verbirgt sich hinter jenem Phänomen, das wir insbesondere in Deutschland mit jenem Oberbegriff Digitalisierung bezeichnen, eine Vielzahl an unterschiedlichen Begriffen, Phänomenen, Erzählungen und Vorstellungen. 1 Die Erzählungen beginnen hierbei meist mit einer einfachen Betrachtung von elektronischen Artefakten wie dem Computer im Zusammenspiel mit seinem menschlichen Nutzer und enden nicht selten in einer durch eben jene elektronischen Datenverarbeitungsanlagen ausgelösten Transformation menschlicher Gesellschaften oder gar gleich in einer vollständigen digitalen Transzendenz menschlicher Biologie und Erfahrungetwa, wenn es um Vorstellungen davon geht, die menschliche Seele in einen Computer ‚hochzuladen' (Barrat, 2013;Bostrom, 2016;Callaghan et al., 2017;Kurzweil, 2005;Tegmark, 2018). Etwas nüchterner betrachtet begründet sich der vermeintliche Siegeszug auf der vielfältigen, beinahe alle menschlichen Lebensbereiche durchdringenden Verwendung von Computern und den vordergründig positiven Veränderungen, die diese Entwicklung mit sich bringt. Der vermeintliche Gewinn besteht für das menschliche Individuum und seine Gesellschaft darin, einen Nutzen aus dieser fortschreitenden Digitalisierung zu ziehen, also Vorteile mit Blick auf Wirtschaft, Politik, Gesundheit, Kommunikation etc. zu erfahren, die ohne Digitalisierung so nicht möglich sind. Dabei kommt es mitunter auch zu überzogenen Zukunftserwartungen, was Digitalisierung leisten kann und soll. So formuliert der Journalist Jürgen Kaube mit Blick auf die Digitalisierung der Schule folgende Beobachtung (Kaube, 2019): "Man muss heute in jedem Lebensbereich nur noch ‚Digitalisierung' sagen, und schon meldet sich der Verstand zugunsten von Visionen ab" ( § 3). Was ist dran an dieser Aussage? Dient der Begriff Digitalisierung womöglich als eine ‚Applaus!'-Anzeige, bei deren Aufleuchten das Publikum angehalten ist unreflektiert und ohne tatsächlichen Anlass mitzuklatschen (Yudkowsky, 2018)? Ist der Begriff bloß ein Feigenblatt, das vor einer tiefergehenden Betrachtung und kritischen Nachfragen schützt, was und warum da nun wie durch Hard-und Software ergänzt, verändert, oder gar verbessert werden soll? Glauben Bürger*innen in Deutschland vielleicht tatsächlich, dass jede Maßnahme, die nur das Label Digitalisierung trägt, zum Selbstläufer wird, bei dem sich der Erfolg von selbst einstellt? Der gesellschaftliche Umgang mit der Digitalisierung erscheint vielschichtiger und uneindeutiger, als es das digitale Kodierschema von 1 und 0 für Erfolg oder Misserfolg der Digitalisierung suggeriert.</p>
        <p>Schnell stehen wirkmächtige Begriffe im Raum wie bspw. die digitale Revolution, von der erwartet wird, dass sie nach und nach alle Gesellschaftsbereiche erfasst, durchdringt und nachhaltig verändert (Brown, 2019;Helbing, 2019;Isaacson, 2014;Kelly, 2009;Schirrmacher, 2015;Zysman &amp; Newman, 2006). Dass Revolutionen -und nun eben auch die digitale -für gewöhnlich nicht zwangsläufig zum Vorteil aller Beteiligten verlaufen und naturgemäß auch mit sozialen Kosten und Nachteilen verbunden sind, darf mit Blick auf den durch Digitalisierung ausgelösten sozialen Wandel, der den Menschen direkt und unmittelbar betrifft, an dieser Stelle nicht vernachlässigt werden. Ein Beispiel: Nach anfänglicher Euphorie über die vermeintlich demokratisierende und befreiende Kraft des Internets (Ghonim, 2012;Shirky, 2008) -einer dezentralen Infrastruktur der Digitalisierung mit zeitgleich zentraler gesellschaftlicher Bedeutung -melden sich auch immer wieder Stimmen, die hieran berechtigte Zweifel anmeldeten, wenn bspw. auf den gesellschaftlich nachteiligen Missbrauch der Technik durch autokratische Herrschaft oder Unternehmen verwiesen wird (Eubanks, 2018;Morozov, 2012Morozov, , 2014;;Mosco, 2014;Pariser, 2011;Sunstein, 2002).Schnell stehen wirkmächtige Begriffe im Raum wie bspw. die digitale Revolution, von der erwartet wird, dass sie nach und nach alle Gesellschaftsbereiche erfasst, durchdringt und nachhaltig verändert (Brown, 2019;Helbing, 2019;Isaacson, 2014;Kelly, 2009;Schirrmacher, 2015;Zysman &amp; Newman, 2006). Dass Revolutionen -und nun eben auch die digitale -für gewöhnlich nicht zwangsläufig zum Vorteil aller Beteiligten verlaufen und naturgemäß auch mit sozialen Kosten und Nachteilen verbunden sind, darf mit Blick auf den durch Digitalisierung ausgelösten sozialen Wandel, der den Menschen direkt und unmittelbar betrifft, an dieser Stelle nicht vernachlässigt werden. Ein Beispiel: Nach anfänglicher Euphorie über die vermeintlich demokratisierende und befreiende Kraft des Internets (Ghonim, 2012;Shirky, 2008) -einer dezentralen Infrastruktur der Digitalisierung mit zeitgleich zentraler gesellschaftlicher Bedeutung -melden sich auch immer wieder Stimmen, die hieran berechtigte Zweifel anmeldeten, wenn bspw. auf den gesellschaftlich nachteiligen Missbrauch der Technik durch autokratische Herrschaft oder Unternehmen verwiesen wird (Eubanks, 2018;Morozov, 2012Morozov, , 2014;;Mosco, 2014;Pariser, 2011;Sunstein, 2002).</p>
        <p>Unter der Annahme, Digitalisierung sei für Individuum und Gesellschaft zumindest mit weitreichenden Konsequenzen behaftet und bedeutungsvoll, gebieten die diesbezüglich ablaufenden gesellschaftlichen Kommunikations-und Aushandlungsprozesse eine sozialwissenschaftliche Analyse. Die zuvor angesprochenen latenten, also nicht-beobachtbaren sozialen Konsequenzen der Digitalisierung können sozialwissenschaftlich analysiert werden, um sie trotz oder genau wegen ihrer Nicht-Einsehbarkeit sichtbar und verständlich zu machen.Unter der Annahme, Digitalisierung sei für Individuum und Gesellschaft zumindest mit weitreichenden Konsequenzen behaftet und bedeutungsvoll, gebieten die diesbezüglich ablaufenden gesellschaftlichen Kommunikations-und Aushandlungsprozesse eine sozialwissenschaftliche Analyse. Die zuvor angesprochenen latenten, also nicht-beobachtbaren sozialen Konsequenzen der Digitalisierung können sozialwissenschaftlich analysiert werden, um sie trotz oder genau wegen ihrer Nicht-Einsehbarkeit sichtbar und verständlich zu machen.</p>
        <p>Dabei scheinen insbesondere die an die Konsequenzen der Digitalisierung geknüpften Vorstellungen und Erwartungen für das soziale Miteinander in menschlichen Gesellschaften ein lohnenswertes Unterfangen auf dem Weg, die forschungsleitende Frage zu beantworten: Was und wie denken Menschen über die Digitalisierung und wozu führt dieses Denken? Es gibt hier viele spezifische Erzählungen zur Digitalisierung, die ihre gesellschaftliche Wahrnehmung prägen und die spezifische Vorstellungen auszulösen vermögen, was Digitalisierung für den Menschen und das menschliche Miteinander im Rahmen sozialer Ordnung bedeutet. Bezugnehmend auf den insbesondere im anglophonen Raum eng mit der Digitalisierung verbundenen Begriff ‚Cyber' adressiert Rid (2017) dessen vielschichtige gesellschaftliche Bedeutung folgendermaßen:Dabei scheinen insbesondere die an die Konsequenzen der Digitalisierung geknüpften Vorstellungen und Erwartungen für das soziale Miteinander in menschlichen Gesellschaften ein lohnenswertes Unterfangen auf dem Weg, die forschungsleitende Frage zu beantworten: Was und wie denken Menschen über die Digitalisierung und wozu führt dieses Denken? Es gibt hier viele spezifische Erzählungen zur Digitalisierung, die ihre gesellschaftliche Wahrnehmung prägen und die spezifische Vorstellungen auszulösen vermögen, was Digitalisierung für den Menschen und das menschliche Miteinander im Rahmen sozialer Ordnung bedeutet. Bezugnehmend auf den insbesondere im anglophonen Raum eng mit der Digitalisierung verbundenen Begriff ‚Cyber' adressiert Rid (2017) dessen vielschichtige gesellschaftliche Bedeutung folgendermaßen:</p>
        <p>For politicians in Washington, the word stands for power outages that could plunge entire cities into chaos at any moment. For spies in Maryland, it stands for conflict and war, and for data being stolen by Russian criminals and Chinese spies. For executives in the City of London, it stands for major security breaches, for banks bleeding money, and for ruined corporate reputations. For inventors in Tel Aviv, it triggers visions of humans merging with machines, of wired-up prostheses with sensitive fingertips, and of silicon chips implanted under tender human skin. For science fiction fans in Tokyo, it stands for an escapist yet retro punk aesthetic, for mirrored shades, leather jackets, and worn-down, dusty gadgets. For romantic internet activists in Boston, it stands for a new realm of freedom, a space beyond the control of oppressive governments and law enforcement agencies. For engineers in Munich, it stands for steely control, and for running chemical plants by computer console. Ageing hippies in San Francisco nostalgically think back to wholeness and psychedelics and 'turning on' the brain. And for screen-addicted youth in between, 'cyber' means simply sex-by-video-chat. (S. XIII) Die Vielschichtigkeit der Digitalisierung als soziales Phänomen bedeutet letztlich auch, dass es nicht die sozialwissenschaftliche Digitalisierungsforschung geben kann, sondern sich einzelne wissenschaftliche Disziplinen mit der sozialen Dimension bestimmter Phänomene und Kontexte der Digitalisierung befassen. Es ist daher notwendig, zunächst ein paar einführende Worte zur Einordnung der vorliegenden Arbeit in den sozialwissenschaftlichen Forschungskontext zur Digitalisierung zu verlieren, um deutlich zu machen, auf welche Fragen die Leser*innen Antworten erwarten können und auf welche nicht.For politicians in Washington, the word stands for power outages that could plunge entire cities into chaos at any moment. For spies in Maryland, it stands for conflict and war, and for data being stolen by Russian criminals and Chinese spies. For executives in the City of London, it stands for major security breaches, for banks bleeding money, and for ruined corporate reputations. For inventors in Tel Aviv, it triggers visions of humans merging with machines, of wired-up prostheses with sensitive fingertips, and of silicon chips implanted under tender human skin. For science fiction fans in Tokyo, it stands for an escapist yet retro punk aesthetic, for mirrored shades, leather jackets, and worn-down, dusty gadgets. For romantic internet activists in Boston, it stands for a new realm of freedom, a space beyond the control of oppressive governments and law enforcement agencies. For engineers in Munich, it stands for steely control, and for running chemical plants by computer console. Ageing hippies in San Francisco nostalgically think back to wholeness and psychedelics and 'turning on' the brain. And for screen-addicted youth in between, 'cyber' means simply sex-by-video-chat. (S. XIII) Die Vielschichtigkeit der Digitalisierung als soziales Phänomen bedeutet letztlich auch, dass es nicht die sozialwissenschaftliche Digitalisierungsforschung geben kann, sondern sich einzelne wissenschaftliche Disziplinen mit der sozialen Dimension bestimmter Phänomene und Kontexte der Digitalisierung befassen. Es ist daher notwendig, zunächst ein paar einführende Worte zur Einordnung der vorliegenden Arbeit in den sozialwissenschaftlichen Forschungskontext zur Digitalisierung zu verlieren, um deutlich zu machen, auf welche Fragen die Leser*innen Antworten erwarten können und auf welche nicht.</p>
        <p>Sozialwissenschaftliche Digitalisierungsforschung lässt sich nur schwer umfassend beschreiben und klar von anderen, nicht digitalisierungsbezogenen Forschungsbemühungen abgrenzen. Hierfür gibt es diverse Gründe: Zum einen ist das verbindende Element aller Digitalisierungsforschung lediglich das Materialobjekt, also die materiellen Artefakte der Digitalisierung selbst, auch wenn diese das zu untersuchende Phänomen nur mittelbar ermöglichen. Hier seien vor allem digitale ‚Dinge' wie zuallererst der Computer oder verwandte technologische Innovationen wie bspw. Smartphones genannt (Dogruel, 2013;Neuberger, 2008;Wagner, 1997). Das, was in engerem Sinne durch diese Computer-Artefakte beeinflusst und folglich untersucht wird, unterscheidet sich dann je nach dem sogenannten Formalobjekt der unterschiedlichen wissenschaftlichen Disziplinen. Hierzu gehört dann bspw. die Forschung im Bereich Social Robotics, mit einem eher materiellen Fokus auf technische digitalisierte Artefakte an der Schnittstelle der Human-Computer-Interaction (Goodrich &amp; Schultz, 2007). So findet sich Forschung, die die menschliche Wahrnehmung in der Interaktion mit computerisierten Maschinen wie Pflegerobotern untersucht und bspw. Fragen nach deren Akzeptanz stellt (Heerink et al., 2010;Hudson et al., 2017), neben Untersuchungen zu den durch Digitalisierung und Automatisierung ausgelösten Veränderungen auf dem Arbeitsmarkt (Savela et al., 2017), die zeigen, dass Menschen durchaus mit Emotionen wie etwa durch Bedrohungswahrnehmungen ausgelöste Angst auf vermeintlich autonome Maschinen reagieren (Liang &amp; Lee, 2017).Sozialwissenschaftliche Digitalisierungsforschung lässt sich nur schwer umfassend beschreiben und klar von anderen, nicht digitalisierungsbezogenen Forschungsbemühungen abgrenzen. Hierfür gibt es diverse Gründe: Zum einen ist das verbindende Element aller Digitalisierungsforschung lediglich das Materialobjekt, also die materiellen Artefakte der Digitalisierung selbst, auch wenn diese das zu untersuchende Phänomen nur mittelbar ermöglichen. Hier seien vor allem digitale ‚Dinge' wie zuallererst der Computer oder verwandte technologische Innovationen wie bspw. Smartphones genannt (Dogruel, 2013;Neuberger, 2008;Wagner, 1997). Das, was in engerem Sinne durch diese Computer-Artefakte beeinflusst und folglich untersucht wird, unterscheidet sich dann je nach dem sogenannten Formalobjekt der unterschiedlichen wissenschaftlichen Disziplinen. Hierzu gehört dann bspw. die Forschung im Bereich Social Robotics, mit einem eher materiellen Fokus auf technische digitalisierte Artefakte an der Schnittstelle der Human-Computer-Interaction (Goodrich &amp; Schultz, 2007). So findet sich Forschung, die die menschliche Wahrnehmung in der Interaktion mit computerisierten Maschinen wie Pflegerobotern untersucht und bspw. Fragen nach deren Akzeptanz stellt (Heerink et al., 2010;Hudson et al., 2017), neben Untersuchungen zu den durch Digitalisierung und Automatisierung ausgelösten Veränderungen auf dem Arbeitsmarkt (Savela et al., 2017), die zeigen, dass Menschen durchaus mit Emotionen wie etwa durch Bedrohungswahrnehmungen ausgelöste Angst auf vermeintlich autonome Maschinen reagieren (Liang &amp; Lee, 2017).</p>
        <p>Wenn man einmal auf die Kommunikationswissenschaft abstellt, ist das Formalobjekt die ‚(soziale) Kommunikation' (K. Beck, 2017), die mithin auch im Blickpunkt der vorliegenden Arbeit steht. Es interessiert also nicht die Digitalisierung an sich, sondern von Interesse sind die Bedingungen und Konsequenzen ihrer kommunikativen Verhandlung innerhalb der Gesellschaft. Doch auch die Betrachtung der Digitalisierung im Rahmen dieser sozialen Kommunikation ist vielfältig. So gibt es kommunikationswissenschaftliche Forschung, die einerseits die Bedingungen und Auswirkungen computervermittelter interpersonaler Kommunikation betrifft und andererseits digitalisierte öffentliche massenmediale Kommunikation in den Blick nimmt (K. Beck, 2006;Kimpeler et al., 2007;Schweiger &amp; Beck, 2010). Zu nennen sind hier allen voran die sogenannten ‚Sozialen' Medien mit einem Fokus auf Kommunikation in den Onlineangeboten sozialer Netzwerke (Hautzer et al., 2012;J.-H. Schmidt, 2018). Dazu gehört auch die Forschung zu digitalisierten Öffentlichkeiten, die mögliche Konsequenzen wie deren Zerfall (Jarren et al., 2000) und eine durch das Internet ausgelöste gesellschaftliche Fragmentierung untersucht (Mahrt, 2019;Webster &amp; Ksiazek, 2012;Zuiderveen Borgesius et al., 2016) und dabei u. a. Kommunikationsphänomene wie Echokammern auf vermeintliche Filterblasen in den virtuellen Räumen übertragen hat (Pariser, 2011;Sunstein, 2002).Wenn man einmal auf die Kommunikationswissenschaft abstellt, ist das Formalobjekt die ‚(soziale) Kommunikation' (K. Beck, 2017), die mithin auch im Blickpunkt der vorliegenden Arbeit steht. Es interessiert also nicht die Digitalisierung an sich, sondern von Interesse sind die Bedingungen und Konsequenzen ihrer kommunikativen Verhandlung innerhalb der Gesellschaft. Doch auch die Betrachtung der Digitalisierung im Rahmen dieser sozialen Kommunikation ist vielfältig. So gibt es kommunikationswissenschaftliche Forschung, die einerseits die Bedingungen und Auswirkungen computervermittelter interpersonaler Kommunikation betrifft und andererseits digitalisierte öffentliche massenmediale Kommunikation in den Blick nimmt (K. Beck, 2006;Kimpeler et al., 2007;Schweiger &amp; Beck, 2010). Zu nennen sind hier allen voran die sogenannten ‚Sozialen' Medien mit einem Fokus auf Kommunikation in den Onlineangeboten sozialer Netzwerke (Hautzer et al., 2012;J.-H. Schmidt, 2018). Dazu gehört auch die Forschung zu digitalisierten Öffentlichkeiten, die mögliche Konsequenzen wie deren Zerfall (Jarren et al., 2000) und eine durch das Internet ausgelöste gesellschaftliche Fragmentierung untersucht (Mahrt, 2019;Webster &amp; Ksiazek, 2012;Zuiderveen Borgesius et al., 2016) und dabei u. a. Kommunikationsphänomene wie Echokammern auf vermeintliche Filterblasen in den virtuellen Räumen übertragen hat (Pariser, 2011;Sunstein, 2002).</p>
        <p>Die vorhergehenden Ausführungen dienen an dieser Stelle lediglich der Illustration der Vielseitigkeit sozial-und kommunikationswissenschaftlicher Forschung zur Digitalisierung. Sie dokumentieren jedoch, dass unter der Annahme einer fortschreitenden Digitalisierung eine tiefgreifende Beeinflussung der sozialen Situation durch die Präsenz von Phänomenen der Digitalisierung in Gegenwart und Zukunft und diesbezüglicher sozialer Kommunikation erwartet wird, die ein Verständnis und Erklären dieser Veränderungen für das soziale Handeln in seinem jeweiligen Alltagskosmos dringend notwendig machen. Dabei bedeutet die Präsenz von Phänomenen der Digitalisierung, dass nicht zwingend materielle Artefakte der Digitalisierung in einer Situation präsent sein müssen, sondern lediglich, dass die Auswirkungen einzelner Phänomene, die auf Digitalisierung zurückzuführen sind, in der sozialen Situation zu beobachten und mithin zu analysieren sind.Die vorhergehenden Ausführungen dienen an dieser Stelle lediglich der Illustration der Vielseitigkeit sozial-und kommunikationswissenschaftlicher Forschung zur Digitalisierung. Sie dokumentieren jedoch, dass unter der Annahme einer fortschreitenden Digitalisierung eine tiefgreifende Beeinflussung der sozialen Situation durch die Präsenz von Phänomenen der Digitalisierung in Gegenwart und Zukunft und diesbezüglicher sozialer Kommunikation erwartet wird, die ein Verständnis und Erklären dieser Veränderungen für das soziale Handeln in seinem jeweiligen Alltagskosmos dringend notwendig machen. Dabei bedeutet die Präsenz von Phänomenen der Digitalisierung, dass nicht zwingend materielle Artefakte der Digitalisierung in einer Situation präsent sein müssen, sondern lediglich, dass die Auswirkungen einzelner Phänomene, die auf Digitalisierung zurückzuführen sind, in der sozialen Situation zu beobachten und mithin zu analysieren sind.</p>
        <p>Dabei ist Digitalisierung kein Selbstläufer. Wem blühende Landschaften versprochen werden und wer im Nachhinein merkt, dass man ihm oder ihr potemkinsche Dörfer präsentiert, bei dem oder der sollten auch hier Zweifel kommen, wie zuverlässig gemachte Prognosen für die Zukunft tatsächlich sind, insbesondere mit Blick auf die gesellschaftlichen Auswirkungen von Großtechnologien. Dass etwaige Versprechungen und Erwartungen nicht eingelöst werden, lässt sich mit Blick auf die Entwicklung bspw. der Biotechnologie (Joppi et al., 2005) oder der Atomkraft (U. Beck, 1987;Hasegawa, 2012Hasegawa, , 2014) ) beobachten. Es besteht die Einsicht, dass technologische Entwicklung ohne eine gleichzeitige Berücksichtigung der potentiellen Risiken für die menschliche Gesellschaft undenkbar ist (U. Beck, 1986). So wäre zumindest zu erwarten, dass eine Person, die regelmäßig beobachtet, dass Voraussagen zu gesellschaftlichen Entwicklungen nicht wie versprochen und erwartet eintreten, die Eintrittswahrscheinlichkeit P(Siegeszug der Digitalisier ung) mit kleiner als 1 belegt. Zumal an dieser Stelle noch vollkommen unreflektiert ist, wie konkret sich dieser Siegeszug in unterschiedlichen Sphären des öffentlichen und privaten Lebens manifestiert.Dabei ist Digitalisierung kein Selbstläufer. Wem blühende Landschaften versprochen werden und wer im Nachhinein merkt, dass man ihm oder ihr potemkinsche Dörfer präsentiert, bei dem oder der sollten auch hier Zweifel kommen, wie zuverlässig gemachte Prognosen für die Zukunft tatsächlich sind, insbesondere mit Blick auf die gesellschaftlichen Auswirkungen von Großtechnologien. Dass etwaige Versprechungen und Erwartungen nicht eingelöst werden, lässt sich mit Blick auf die Entwicklung bspw. der Biotechnologie (Joppi et al., 2005) oder der Atomkraft (U. Beck, 1987;Hasegawa, 2012Hasegawa, , 2014) ) beobachten. Es besteht die Einsicht, dass technologische Entwicklung ohne eine gleichzeitige Berücksichtigung der potentiellen Risiken für die menschliche Gesellschaft undenkbar ist (U. Beck, 1986). So wäre zumindest zu erwarten, dass eine Person, die regelmäßig beobachtet, dass Voraussagen zu gesellschaftlichen Entwicklungen nicht wie versprochen und erwartet eintreten, die Eintrittswahrscheinlichkeit P(Siegeszug der Digitalisier ung) mit kleiner als 1 belegt. Zumal an dieser Stelle noch vollkommen unreflektiert ist, wie konkret sich dieser Siegeszug in unterschiedlichen Sphären des öffentlichen und privaten Lebens manifestiert.</p>
        <p>Ohne hier schon zu viel vorwegzunehmen: Der vermeintliche Siegeszug -so es denn einer sein sollte -ist auch immer wieder gespickt mit vielen kleinen negativen Auswirkungen für die Menschen in ihren Rollen als Bürger*innen, Arbeitnehmer*innen und Konsument*innen, wie nachfolgend an etlichen Stellen diskutiert wird. Das letzte Wort der zukünftigen Entwicklung von Digitalisierung in der digitalen Gesellschaft ist noch nicht gesprochen und Erfolgsverkündungen sind zu früh. Nun zeigt der Blick auf die Forschung auch, dass selbst das Nicht-Eintreten von Vorhersagen nicht automatisch zu erdrückenden Zweifeln an einer Idee führen muss, sondern häufig das Gegenteil bewirkt (Festinger et al., 1964). Mit anderen Worten: Auch wenn objektiv nicht von einem umfassenden Erfolg der Digitalisierung gesprochen werden kann, so sagt das noch lange nichts über den subjektiven Eindruck und dessen Bewertung aus.Ohne hier schon zu viel vorwegzunehmen: Der vermeintliche Siegeszug -so es denn einer sein sollte -ist auch immer wieder gespickt mit vielen kleinen negativen Auswirkungen für die Menschen in ihren Rollen als Bürger*innen, Arbeitnehmer*innen und Konsument*innen, wie nachfolgend an etlichen Stellen diskutiert wird. Das letzte Wort der zukünftigen Entwicklung von Digitalisierung in der digitalen Gesellschaft ist noch nicht gesprochen und Erfolgsverkündungen sind zu früh. Nun zeigt der Blick auf die Forschung auch, dass selbst das Nicht-Eintreten von Vorhersagen nicht automatisch zu erdrückenden Zweifeln an einer Idee führen muss, sondern häufig das Gegenteil bewirkt (Festinger et al., 1964). Mit anderen Worten: Auch wenn objektiv nicht von einem umfassenden Erfolg der Digitalisierung gesprochen werden kann, so sagt das noch lange nichts über den subjektiven Eindruck und dessen Bewertung aus.</p>
        <p>Ohne jedoch hier schon auf eine mögliche Beantwortung der Fragen hinzuwirken, welche konkreten gesellschaftlichen Auswirkungen Digitalisierung zeitigt und ob und warum sie von der Bevölkerung als eine positive oder negative Entwicklung bewertet wird sowie welche Hoffnungen sich mit ihr für die Zukunft verbinden (siehe hierzu die Kapitel 4 und 5), soll zunächst folgende These aufgestellt werden: Digitalisierung ist mit Blick auf die mannigfaltige Verwendung des Begriffs im Alltag, in den Medien, in Wahlkämpfen und in der Wirtschaft eine derzeit wirkmächtige Idee. Sie nährt sich aus vielfach formulierten Erwartungen bezüglich der Konsequenzen bspw. der digitalen Schule, Verwaltung oder Gesundheitsversorgung, neuer Wirtschaftszweige und gänzlich veränderter Medien-und Informationsnutzung.Ohne jedoch hier schon auf eine mögliche Beantwortung der Fragen hinzuwirken, welche konkreten gesellschaftlichen Auswirkungen Digitalisierung zeitigt und ob und warum sie von der Bevölkerung als eine positive oder negative Entwicklung bewertet wird sowie welche Hoffnungen sich mit ihr für die Zukunft verbinden (siehe hierzu die Kapitel 4 und 5), soll zunächst folgende These aufgestellt werden: Digitalisierung ist mit Blick auf die mannigfaltige Verwendung des Begriffs im Alltag, in den Medien, in Wahlkämpfen und in der Wirtschaft eine derzeit wirkmächtige Idee. Sie nährt sich aus vielfach formulierten Erwartungen bezüglich der Konsequenzen bspw. der digitalen Schule, Verwaltung oder Gesundheitsversorgung, neuer Wirtschaftszweige und gänzlich veränderter Medien-und Informationsnutzung.</p>
        <p>Der öffentliche Diskurs über die Digitalisierung und ihre spezifische Ausgestaltung, bspw. in Form des Phänomens Big Data, hat einen Einfluss darauf, was Menschen bei Fragen der Digitalisierung denken und wie sie sich zu diesen verhalten (Knorre et al., 2020). Analog zu theoretischen Überlegungen der Kultivierungsanalyse (Gerbner, 1973;Gerbner et al., 1980;Gerbner, 1998;Morgan, 2008) erfolgt hier eine in dieser Arbeit nachfolgend zu skizzierende Realitätsbeschreibung des Wesens und der Konsequenzen von Digitalisierung. Individuum und Gesellschaft evaluieren und lernen im Rahmen dieser öffentlichen kommunikativen Verhandlung laufend und langfristig, welchen vermeintlichen Entwicklungsstatus die digitale Gesellschaft hat und welchen mutmaßlichen Entwicklungsverlauf sie nimmt. Dabei formen sich in einem Prozess aufeinander aufbauender und miteinander verwobener Rezeptions-und Wirkungsereignisse insbesondere massenmedial geprägte Realitätskonzeptionen (Fahr &amp; Früh, 2011;Früh, 1991;Früh &amp; Schönbach, 1982;Gerbner, 1973;McQuail &amp; Windahl, 1993). Diese Realitätskonzeptionen sind also vor dem Hintergrund eines vielschichtigen öffentlichen Diskurses zu bewerten, aus dem sie sich speisen, in den sie jedoch auch wieder zurückwirken, wobei sich wechselseitige Transformationsprozesse einstellen.Der öffentliche Diskurs über die Digitalisierung und ihre spezifische Ausgestaltung, bspw. in Form des Phänomens Big Data, hat einen Einfluss darauf, was Menschen bei Fragen der Digitalisierung denken und wie sie sich zu diesen verhalten (Knorre et al., 2020). Analog zu theoretischen Überlegungen der Kultivierungsanalyse (Gerbner, 1973;Gerbner et al., 1980;Gerbner, 1998;Morgan, 2008) erfolgt hier eine in dieser Arbeit nachfolgend zu skizzierende Realitätsbeschreibung des Wesens und der Konsequenzen von Digitalisierung. Individuum und Gesellschaft evaluieren und lernen im Rahmen dieser öffentlichen kommunikativen Verhandlung laufend und langfristig, welchen vermeintlichen Entwicklungsstatus die digitale Gesellschaft hat und welchen mutmaßlichen Entwicklungsverlauf sie nimmt. Dabei formen sich in einem Prozess aufeinander aufbauender und miteinander verwobener Rezeptions-und Wirkungsereignisse insbesondere massenmedial geprägte Realitätskonzeptionen (Fahr &amp; Früh, 2011;Früh, 1991;Früh &amp; Schönbach, 1982;Gerbner, 1973;McQuail &amp; Windahl, 1993). Diese Realitätskonzeptionen sind also vor dem Hintergrund eines vielschichtigen öffentlichen Diskurses zu bewerten, aus dem sie sich speisen, in den sie jedoch auch wieder zurückwirken, wobei sich wechselseitige Transformationsprozesse einstellen.</p>
        <p>In diesem Diskurs spielen -weit oberhalb des täglichen Klein-Kleins aktueller Geschehnisse -übergeordnete Gegenwartsdiagnosen eine zentrale und gewichtige Rolle für das Selbstverständnis einer Gesellschaft. Sie prägen als ausformulierte Erzählung einer gesamtgesellschaftlichen Selbstreflexion eine zeitgenössische Haltung, die sich im alltäglichen Handeln in den Sphären des öffentlichen und privaten Lebens niederschlägt. Die bereits angesprochene digitale Gesellschaft ist eine solche verhältnismäßig junge Gesellschaftsdiagnose. Sie erwächst jedoch einer weitaus allgemeineren Konzeption gesellschaftlicher Verfasstheit, die einen konkreten Bezug auf das epistemische Selbstverständnis des Menschen hat, in dessen Rahmen Digitallogik und Digitaltechnik eine maßgebliche und unverzichtbare Bedeutung für das Entstehen von Erkenntnis besitzen, jedoch auf den ersten Blick lediglich einen funktionalen Charakter innehaben (Nassehi, 2019). Gemeint ist die Zeitdiagnose der Wissensgesellschaft (Kübler, 2009;Stehr, 2012Stehr, , 2017)), auf die nachfolgend einzugehen ist (siehe Abschnitt 4.2). In ihrem Rahmen wird Wissen in einen Stand erhoben, der die faktische jedoch auch imaginierte besondere Bedeutung von Wissen für die Gesellschaft hervorhebt. Wissen ist dann zentrale Kategorie, doch gleichzeitig auch ein abstrahiertes und theoriegeladenes Konstrukt, über das gelernt und gewusst, diesbezüglich jedoch auch erwartet, gehofft und geglaubt werden kann (siehe Abschnitt 4.1). Es ergibt sich mithin abseits jeglicher tatsächlich manifestierter Konsequenz eine Erwartungshaltung, die auf die Wissensgesellschaft und das in ihr generierte Wissen gerichtet ist. Diese allgemeine Erwartungshaltung zielt dann auf die Idee der Wissensgesellschaft ab, die zwar vielfach und immer anders nuanciert diskutiert wird, zu deren Kernbestand jedoch meist alle Innovationen und Artefakte aus dem Bereich der IuK zählen (Gerbner et al., 1973;Kübler, 2009).In diesem Diskurs spielen -weit oberhalb des täglichen Klein-Kleins aktueller Geschehnisse -übergeordnete Gegenwartsdiagnosen eine zentrale und gewichtige Rolle für das Selbstverständnis einer Gesellschaft. Sie prägen als ausformulierte Erzählung einer gesamtgesellschaftlichen Selbstreflexion eine zeitgenössische Haltung, die sich im alltäglichen Handeln in den Sphären des öffentlichen und privaten Lebens niederschlägt. Die bereits angesprochene digitale Gesellschaft ist eine solche verhältnismäßig junge Gesellschaftsdiagnose. Sie erwächst jedoch einer weitaus allgemeineren Konzeption gesellschaftlicher Verfasstheit, die einen konkreten Bezug auf das epistemische Selbstverständnis des Menschen hat, in dessen Rahmen Digitallogik und Digitaltechnik eine maßgebliche und unverzichtbare Bedeutung für das Entstehen von Erkenntnis besitzen, jedoch auf den ersten Blick lediglich einen funktionalen Charakter innehaben (Nassehi, 2019). Gemeint ist die Zeitdiagnose der Wissensgesellschaft (Kübler, 2009;Stehr, 2012Stehr, , 2017)), auf die nachfolgend einzugehen ist (siehe Abschnitt 4.2). In ihrem Rahmen wird Wissen in einen Stand erhoben, der die faktische jedoch auch imaginierte besondere Bedeutung von Wissen für die Gesellschaft hervorhebt. Wissen ist dann zentrale Kategorie, doch gleichzeitig auch ein abstrahiertes und theoriegeladenes Konstrukt, über das gelernt und gewusst, diesbezüglich jedoch auch erwartet, gehofft und geglaubt werden kann (siehe Abschnitt 4.1). Es ergibt sich mithin abseits jeglicher tatsächlich manifestierter Konsequenz eine Erwartungshaltung, die auf die Wissensgesellschaft und das in ihr generierte Wissen gerichtet ist. Diese allgemeine Erwartungshaltung zielt dann auf die Idee der Wissensgesellschaft ab, die zwar vielfach und immer anders nuanciert diskutiert wird, zu deren Kernbestand jedoch meist alle Innovationen und Artefakte aus dem Bereich der IuK zählen (Gerbner et al., 1973;Kübler, 2009).</p>
        <p>Die vorliegende Arbeit nimmt dabei nun den Verwertungszusammenhang digitaler Daten in den Blick, die im Rahmen der fortschreitenden Digitalisierung bei der Verwendung eben jener IuK entstehen, und die gesellschaftliche Bedeutung dieser Daten sowie öffentliche Erwartungen hinsichtlich Erkenntnis-und Nutzengewinnen (Houben &amp; Prietl, 2018;Knorre et al., 2020;Kolany-Raiser et al., 2018). Denn aus der Digitalisierung, die in ihrem Wesen aus einer Unterscheidung in Nullen und Einsen besteht, ergibt sich eine konstante und gewichtige Konsequenz: Digitalisierung ist datengetrieben. Grund hierfür ist vor allem, dass die technische Möglichkeit der Feststellung und Übertragung realweltlicher Zustände in ein binäres digitales Format und dessen langfristige Speicherung Wissen über Zustände jenseits der Technik bereitstellt. Hieraus abgeleitete Erkenntnisse über die Welt können in vielfältigen sozialen Kontexten aufgegriffen, verwertet und genutzt werden und regen somit Anschlusshandlungen an. Daher sind digitale Daten, so eine weitere Prämisse der vorliegenden Arbeit, Ergebnis und gleichzeitig Treiber der Digitalisierung der Gesellschaft in einem rekursiven Prozess. Dieser dehnt sich -nicht nur, weil es technisch möglich ist, sondern weil es gesellschaftlich befürwortet wird -auf immer mehr Lebensbereiche aus und führt zu sozialen Konsequenzen für Individuum und Gesellschaft. Die digitalen Daten sowie vor allem das auf ihnen aufbauende Wissen erfahren hierbei unter Stichworten wie Big Data, Datafizierung oder das auf Daten basierende Machine Learning (ML) und hiermit verbundener Erwartungen an Künstliche Intelligenz (KI) derzeit eine hohe Aufmerksamkeit in öffentlichen Diskussionen der Sphären der Wissenschaft, der Wirtschaft und Politik sowie der Zivilgesellschaft (Finlay, 2017;J. Kaplan, 2016;Katz, 2017;Knorre et al., 2020;Mayer-Schönberger &amp; Cukier, 2013;O'Neil, 2017;Orwat &amp; Schankin, 2018).Die vorliegende Arbeit nimmt dabei nun den Verwertungszusammenhang digitaler Daten in den Blick, die im Rahmen der fortschreitenden Digitalisierung bei der Verwendung eben jener IuK entstehen, und die gesellschaftliche Bedeutung dieser Daten sowie öffentliche Erwartungen hinsichtlich Erkenntnis-und Nutzengewinnen (Houben &amp; Prietl, 2018;Knorre et al., 2020;Kolany-Raiser et al., 2018). Denn aus der Digitalisierung, die in ihrem Wesen aus einer Unterscheidung in Nullen und Einsen besteht, ergibt sich eine konstante und gewichtige Konsequenz: Digitalisierung ist datengetrieben. Grund hierfür ist vor allem, dass die technische Möglichkeit der Feststellung und Übertragung realweltlicher Zustände in ein binäres digitales Format und dessen langfristige Speicherung Wissen über Zustände jenseits der Technik bereitstellt. Hieraus abgeleitete Erkenntnisse über die Welt können in vielfältigen sozialen Kontexten aufgegriffen, verwertet und genutzt werden und regen somit Anschlusshandlungen an. Daher sind digitale Daten, so eine weitere Prämisse der vorliegenden Arbeit, Ergebnis und gleichzeitig Treiber der Digitalisierung der Gesellschaft in einem rekursiven Prozess. Dieser dehnt sich -nicht nur, weil es technisch möglich ist, sondern weil es gesellschaftlich befürwortet wird -auf immer mehr Lebensbereiche aus und führt zu sozialen Konsequenzen für Individuum und Gesellschaft. Die digitalen Daten sowie vor allem das auf ihnen aufbauende Wissen erfahren hierbei unter Stichworten wie Big Data, Datafizierung oder das auf Daten basierende Machine Learning (ML) und hiermit verbundener Erwartungen an Künstliche Intelligenz (KI) derzeit eine hohe Aufmerksamkeit in öffentlichen Diskussionen der Sphären der Wissenschaft, der Wirtschaft und Politik sowie der Zivilgesellschaft (Finlay, 2017;J. Kaplan, 2016;Katz, 2017;Knorre et al., 2020;Mayer-Schönberger &amp; Cukier, 2013;O'Neil, 2017;Orwat &amp; Schankin, 2018).</p>
        <p>Bevor jedoch auf die gesellschaftlichen Bedingungen und Erwartungen bezüglich der digitalen Datensammlung und -verwertung vor dem Hintergrund eines Erkenntnis-und Nutzengewinns eingegangen werden kann, ist zunächst Folgendes zu klären: Was genau hat es mit digitalen Daten auf sich und in welchem Zusammenhang stehen sie zum Wissen? Was bedeutet hierbei überhaupt Wissen und welche Bedeutung hat es für Gesellschaft und Digitalisierung? Es wird daher im nachfolgenden Kapitel 3 zunächst einmal abgegrenzt, was unter digitalen Daten verstanden wird und welche Voraussetzungen und Konsequenzen mit ihrer Entstehung, Sammlung und Auswertung in technischer wie in sozialer Hinsicht verbunden sind. Nach der Diskussion dieser vor allem sozio-technischen Voraussetzungen von digitalen Daten werden dann in Kapitel 4 das Wesen und die Bedeutung des Wissens in den Blick genommen, das auf Grundlage digitaler Daten gewonnen werden kann. Erst im Anschluss kann sich der Analyse der sozialen Bedeutung von Big Data und Wissen für die digitalisierte Gesellschaft vor dem Hintergrund aktueller gesellschaftlicher Entwicklungen gewidmet werden.Bevor jedoch auf die gesellschaftlichen Bedingungen und Erwartungen bezüglich der digitalen Datensammlung und -verwertung vor dem Hintergrund eines Erkenntnis-und Nutzengewinns eingegangen werden kann, ist zunächst Folgendes zu klären: Was genau hat es mit digitalen Daten auf sich und in welchem Zusammenhang stehen sie zum Wissen? Was bedeutet hierbei überhaupt Wissen und welche Bedeutung hat es für Gesellschaft und Digitalisierung? Es wird daher im nachfolgenden Kapitel 3 zunächst einmal abgegrenzt, was unter digitalen Daten verstanden wird und welche Voraussetzungen und Konsequenzen mit ihrer Entstehung, Sammlung und Auswertung in technischer wie in sozialer Hinsicht verbunden sind. Nach der Diskussion dieser vor allem sozio-technischen Voraussetzungen von digitalen Daten werden dann in Kapitel 4 das Wesen und die Bedeutung des Wissens in den Blick genommen, das auf Grundlage digitaler Daten gewonnen werden kann. Erst im Anschluss kann sich der Analyse der sozialen Bedeutung von Big Data und Wissen für die digitalisierte Gesellschaft vor dem Hintergrund aktueller gesellschaftlicher Entwicklungen gewidmet werden.</p>
        <p>Open Access Dieses Kapitel wird unter der Creative Commons Namensnennung 4.0 International Lizenz (http://creativecommons.org/licenses/by/4.0/deed.de) veröffentlicht, welche die Nutzung, Vervielfältigung, Bearbeitung, Verbreitung und Wiedergabe in jeglichem Medium und Format erlaubt, sofern Sie den/die ursprünglichen Autor(en) und die Quelle ordnungsgemäß nennen, einen Link zur Creative Commons Lizenz beifügen und angeben, ob Änderungen vorgenommen wurden.Open Access Dieses Kapitel wird unter der Creative Commons Namensnennung 4.0 International Lizenz (http://creativecommons.org/licenses/by/4.0/deed.de) veröffentlicht, welche die Nutzung, Vervielfältigung, Bearbeitung, Verbreitung und Wiedergabe in jeglichem Medium und Format erlaubt, sofern Sie den/die ursprünglichen Autor(en) und die Quelle ordnungsgemäß nennen, einen Link zur Creative Commons Lizenz beifügen und angeben, ob Änderungen vorgenommen wurden.</p>
        <p>Die in diesem Kapitel enthaltenen Bilder und sonstiges Drittmaterial unterliegen ebenfalls der genannten Creative Commons Lizenz, sofern sich aus der Abbildungslegende nichts anderes ergibt. Sofern das betreffende Material nicht unter der genannten Creative Commons Lizenz steht und die betreffende Handlung nicht nach gesetzlichen Vorschriften erlaubt ist, ist für die oben aufgeführten Weiterverwendungen des Materials die Einwilligung des jeweiligen Rechteinhabers einzuholen.Die in diesem Kapitel enthaltenen Bilder und sonstiges Drittmaterial unterliegen ebenfalls der genannten Creative Commons Lizenz, sofern sich aus der Abbildungslegende nichts anderes ergibt. Sofern das betreffende Material nicht unter der genannten Creative Commons Lizenz steht und die betreffende Handlung nicht nach gesetzlichen Vorschriften erlaubt ist, ist für die oben aufgeführten Weiterverwendungen des Materials die Einwilligung des jeweiligen Rechteinhabers einzuholen.</p>
        <p>Um die Bedeutung digitaler Daten im sozialen Kontext der Digitalisierung nachvollziehen zu können, muss nun zunächst ein grundlegendes Verständnis dafür hergestellt werden, was Daten und insbesondere digitale Daten ausmacht sowie warum im Kontext digitaler Daten oft von Big Data die Rede ist. 1 Dabei steht zunächst erst einmal die eher technische Definition von Daten im Vordergrund. Doch bereits bei Betrachtung dessen, was gemeinhin unter Big Data verstanden wird, wird in der Literatur die rein technische Abgrenzung aufgeweicht und auch um sozio-technologische Aspekte der großen digitalen Datenbestände erweitert. Diese Erweiterung der Perspektive auf digitale Daten bringt, wie zu zeigen sein wird, eine Einbettung in den sozialen Kontext also zwingend mit sich, in dem Big Data mithin immer auch als ein sozio-technisches Phänomen verstanden werden müssen. Das liegt auch daran, dass die gängigen Definitionen von Big Data immer auch mit Blick auf ihren Ursprung im Verwertungskontext in Wissenschaft und Wirtschaft zu verstehen sind; zwei Bereiche menschlichen Lebens, die fest im zivilisatorischen Fundament verankert sind und ohne Mensch und Gesellschaft nicht denkbar wären. Die nachfolgenden Abschnitte legen somit den Grundstein für ein umfassendes Verständnis des Phänomens Big Data, das 1 Dabei sind die Bedeutung und insbesondere das Verhältnis der drei nachfolgend behandelten Konstrukte der Daten, der Informationen und des Wissens sehr vielfältig gelagert und je nach eingenommener Perspektive nicht trennscharf zu unterscheiden. Daher wird an den entsprechenden Stellen auf weiterführende Literatur zur ideengeschichtlichen Auseinandersetzung mit den jeweiligen Begrifflichkeiten verwiesen. Bezüglich der vorliegenden Ausführungen kann es daher jedoch immer nur um ein Arbeitsverständnis der Definitionen gehen, das primär auf die wesentlichen Charakteristika von Informationen, Daten und Wissen vor dem Hintergrund ihrer Bedeutung für den vorliegenden Forschungszusammenhang abstellt.Um die Bedeutung digitaler Daten im sozialen Kontext der Digitalisierung nachvollziehen zu können, muss nun zunächst ein grundlegendes Verständnis dafür hergestellt werden, was Daten und insbesondere digitale Daten ausmacht sowie warum im Kontext digitaler Daten oft von Big Data die Rede ist. 1 Dabei steht zunächst erst einmal die eher technische Definition von Daten im Vordergrund. Doch bereits bei Betrachtung dessen, was gemeinhin unter Big Data verstanden wird, wird in der Literatur die rein technische Abgrenzung aufgeweicht und auch um sozio-technologische Aspekte der großen digitalen Datenbestände erweitert. Diese Erweiterung der Perspektive auf digitale Daten bringt, wie zu zeigen sein wird, eine Einbettung in den sozialen Kontext also zwingend mit sich, in dem Big Data mithin immer auch als ein sozio-technisches Phänomen verstanden werden müssen. Das liegt auch daran, dass die gängigen Definitionen von Big Data immer auch mit Blick auf ihren Ursprung im Verwertungskontext in Wissenschaft und Wirtschaft zu verstehen sind; zwei Bereiche menschlichen Lebens, die fest im zivilisatorischen Fundament verankert sind und ohne Mensch und Gesellschaft nicht denkbar wären. Die nachfolgenden Abschnitte legen somit den Grundstein für ein umfassendes Verständnis des Phänomens Big Data, das 1 Dabei sind die Bedeutung und insbesondere das Verhältnis der drei nachfolgend behandelten Konstrukte der Daten, der Informationen und des Wissens sehr vielfältig gelagert und je nach eingenommener Perspektive nicht trennscharf zu unterscheiden. Daher wird an den entsprechenden Stellen auf weiterführende Literatur zur ideengeschichtlichen Auseinandersetzung mit den jeweiligen Begrifflichkeiten verwiesen. Bezüglich der vorliegenden Ausführungen kann es daher jedoch immer nur um ein Arbeitsverständnis der Definitionen gehen, das primär auf die wesentlichen Charakteristika von Informationen, Daten und Wissen vor dem Hintergrund ihrer Bedeutung für den vorliegenden Forschungszusammenhang abstellt.</p>
        <p>nötig ist, um anschließend den Blick auf die soziale Logik der Datensammlung und -auswertung zu richten. Folglich wird in Abschnitt 3.1 zunächst einmal ein allgemeines Verständnis von (digitalen) Daten im Sinne dieser Arbeit hergestellt. In Abschnitt 3.2 wird anschließend der Zusammenhang zwischen der Entstehung, Speicherung und Auswertung der Daten unter den Vorzeichen digitaler Umwandlung und Dokumentation auf Speichermedien erläutert, die dann mit Hilfe von IuK eingesehen und bearbeitet werden können. Diese Voraussetzung digitaler Datenerzeugung und -speicherung ist der Ausgangspunkt für eine tiefergehende Betrachtung des Ausmaßes und der Besonderheiten der Datenakkumulation, die unter Big Data verstanden wird und deren Einbettung in einen sozialen Zusammenhang dann Gegenstand der Abschnitte 3.4 bis 3.6 ist.nötig ist, um anschließend den Blick auf die soziale Logik der Datensammlung und -auswertung zu richten. Folglich wird in Abschnitt 3.1 zunächst einmal ein allgemeines Verständnis von (digitalen) Daten im Sinne dieser Arbeit hergestellt. In Abschnitt 3.2 wird anschließend der Zusammenhang zwischen der Entstehung, Speicherung und Auswertung der Daten unter den Vorzeichen digitaler Umwandlung und Dokumentation auf Speichermedien erläutert, die dann mit Hilfe von IuK eingesehen und bearbeitet werden können. Diese Voraussetzung digitaler Datenerzeugung und -speicherung ist der Ausgangspunkt für eine tiefergehende Betrachtung des Ausmaßes und der Besonderheiten der Datenakkumulation, die unter Big Data verstanden wird und deren Einbettung in einen sozialen Zusammenhang dann Gegenstand der Abschnitte 3.4 bis 3.6 ist.</p>
        <p>Wenn man Big Data beim Wort nimmt, dann geht es vordergründig anscheinend einfach nur um große Mengen an Daten. Kein direkter Hinweis findet sich zunächst zum Informationscharakter, zur Digitalität oder gar zu Techniken der Informationsverarbeitung mit Hilfe von Computern; keine Antworten darauf, wessen Daten gemeint sind, wie diese entstehen und wo und wie diese gespeichert werden sowie ob und wie sie einer wie auch immer gearteten Weiterverarbeitung zugeführt werden. Bevor diese Fragen adressiert werden können, ist an dieser Stelle daher zunächst zu erörtern, was genau eigentlich unter Daten zu verstehen ist, wobei die beiden zentralen Kriterien des Bedeutungsgehalts und des Bedeutungsbezugs des Datenbegriffs in dieser Arbeit im Mittelpunkt stehen und nachfolgend anschaulich einführt werden sollen.Wenn man Big Data beim Wort nimmt, dann geht es vordergründig anscheinend einfach nur um große Mengen an Daten. Kein direkter Hinweis findet sich zunächst zum Informationscharakter, zur Digitalität oder gar zu Techniken der Informationsverarbeitung mit Hilfe von Computern; keine Antworten darauf, wessen Daten gemeint sind, wie diese entstehen und wo und wie diese gespeichert werden sowie ob und wie sie einer wie auch immer gearteten Weiterverarbeitung zugeführt werden. Bevor diese Fragen adressiert werden können, ist an dieser Stelle daher zunächst zu erörtern, was genau eigentlich unter Daten zu verstehen ist, wobei die beiden zentralen Kriterien des Bedeutungsgehalts und des Bedeutungsbezugs des Datenbegriffs in dieser Arbeit im Mittelpunkt stehen und nachfolgend anschaulich einführt werden sollen.</p>
        <p>Man könnte sich für ein erstes, recht basales -und wie gleich auch deutlich werden wird -verkürztes Verständnis von Daten zunächst einfach vorstellen, dass man sich in einem großen Raum befindet, mit vielen Schränken ähnlich einer Bibliothek, in denen Ordner stehen, worin sich wiederum viele Blätter Papier befinden, die jeweils mit Text oder auch einfach nur Buchstaben, Zahlen oder unbekannten Symbolen bedruckt sind. Wichtig ist dabei jedoch folgendes erstes Charakteristikum, das diese Zeichen zu Daten im Sinne dieser Arbeit macht: Den Angaben, die als Buchstaben, Zahlen oder anderweitigen Symbolen auf dem Speichermedium Papier festgehalten sind und hierbei zunächst lediglich jenen Symbolcharakter haben, kann eine Bedeutung zugewiesen werden, auf deren Grundlage Unterscheidungen getroffen werden können. Sie stellen für Mensch (und auch für Maschine) daher mit Sinn behaftete, bedeutungsvolle Informationen über einen Zustand bereit (Gleick, 2012). 2 Es kann dann dahingehend davon ausgegangen werden, dass man die dokumentierten Symbole versteht (bzw. prinzipiell verstehen könnte), also um die Bedeutung der Zeichen wissen kann und diese nun nutzen kann, indem man sie einer kognitiven oder bei einem Computer eben maschinellen Verarbeitung zuführt, die auf Grundlage einer durch diese Daten getroffenen Unterscheidung operiert. Daten haben mithin zunächst ein Bedeutungspotential.Man könnte sich für ein erstes, recht basales -und wie gleich auch deutlich werden wird -verkürztes Verständnis von Daten zunächst einfach vorstellen, dass man sich in einem großen Raum befindet, mit vielen Schränken ähnlich einer Bibliothek, in denen Ordner stehen, worin sich wiederum viele Blätter Papier befinden, die jeweils mit Text oder auch einfach nur Buchstaben, Zahlen oder unbekannten Symbolen bedruckt sind. Wichtig ist dabei jedoch folgendes erstes Charakteristikum, das diese Zeichen zu Daten im Sinne dieser Arbeit macht: Den Angaben, die als Buchstaben, Zahlen oder anderweitigen Symbolen auf dem Speichermedium Papier festgehalten sind und hierbei zunächst lediglich jenen Symbolcharakter haben, kann eine Bedeutung zugewiesen werden, auf deren Grundlage Unterscheidungen getroffen werden können. Sie stellen für Mensch (und auch für Maschine) daher mit Sinn behaftete, bedeutungsvolle Informationen über einen Zustand bereit (Gleick, 2012). 2 Es kann dann dahingehend davon ausgegangen werden, dass man die dokumentierten Symbole versteht (bzw. prinzipiell verstehen könnte), also um die Bedeutung der Zeichen wissen kann und diese nun nutzen kann, indem man sie einer kognitiven oder bei einem Computer eben maschinellen Verarbeitung zuführt, die auf Grundlage einer durch diese Daten getroffenen Unterscheidung operiert. Daten haben mithin zunächst ein Bedeutungspotential.</p>
        <p>Wenn eine Ärztin stündlich festhält, wie sich die Fiebertemperatur eines Patienten entwickelt, beobachtet und dokumentiert sie von einem Thermometer abgelesene Daten über dessen Zustand. Mit Blick auf die informative Bedeutung dieser Daten besitzt die Ärztin nun Anhaltspunkte über den Status und die Entwicklung des Gesundheitszustands eines Patienten und kann zwischen gesund oder krank unterscheiden sowie im Zeitverlauf zwischen einer gesundheitlichen Verbesserung oder Verschlechterung und weiß so um die spezifische Bedeutung der so getroffenen Unterscheidungen. In Rahmen dieses Beispiels wird neben dem Potential der Bedeutung von Daten dabei ein weiteres essentielles Charakteristikum für den Datenbegriff eingeführt, das weithin als konstitutiv angenommen wird: Daten sind diesem Beispiel folgend dokumentierte Beobachtungen von Tatsachen über die Welt und weisen somit auf den spezifischen Bezug des Bedeutungsgehalts festgehaltener Symbole hin.Wenn eine Ärztin stündlich festhält, wie sich die Fiebertemperatur eines Patienten entwickelt, beobachtet und dokumentiert sie von einem Thermometer abgelesene Daten über dessen Zustand. Mit Blick auf die informative Bedeutung dieser Daten besitzt die Ärztin nun Anhaltspunkte über den Status und die Entwicklung des Gesundheitszustands eines Patienten und kann zwischen gesund oder krank unterscheiden sowie im Zeitverlauf zwischen einer gesundheitlichen Verbesserung oder Verschlechterung und weiß so um die spezifische Bedeutung der so getroffenen Unterscheidungen. In Rahmen dieses Beispiels wird neben dem Potential der Bedeutung von Daten dabei ein weiteres essentielles Charakteristikum für den Datenbegriff eingeführt, das weithin als konstitutiv angenommen wird: Daten sind diesem Beispiel folgend dokumentierte Beobachtungen von Tatsachen über die Welt und weisen somit auf den spezifischen Bezug des Bedeutungsgehalts festgehaltener Symbole hin.</p>
        <p>Unter dem Begriff Daten werden laut Duden auch ganz allgemein "Beobachtungen, Messungen, statistischen Erhebungen" (Kunkel-Razum et al., 2017) subsumiert. Wenn nachfolgend nun von Daten und insbesondere digitalen Daten gesprochen wird, dann wird der Datenbegriff in eben diesem Sinne der manifest dokumentierten Beobachtung von Tatsachen verstanden. Da jedoch auch ein Musikstück oder ein Video in digitaler Datenform vorliegen kann, wird bereits an dieser Stelle deutlich, dass es unterschiedlich weit gefasste Datenbegriffe geben kann: Einen weitreichenden Datenbegriff , der allein auf die technisch-materielle Dokumentationsform abstellt und mithin bspw. auch kulturelle Produkte umschließt, die in Datenform vorliegen, sowie einen engeren Datenbegriff , der empirisch zu verstehen ist und speziell auf Beobachtungsdaten rekurriert. Wenn nicht anders genannt oder hervorgehoben, wird dabei meistens diesem engen Datenbegriff gefolgt, wenn nachfolgend von Daten in diesem forschungsempirischen Sinne die Rede ist. Doch auch ein weitreichenderer sozio-technischer und kultureller Datenbegriff wird in den folgenden Ausführungen immer dort relevant, wo es um die soziale Bedeutung von Digitaldaten geht. Dabei ist der Datenbegriff dann nicht beliebig gewählt, sondern in seiner vielschichtigen Bedeutung der Bezugspunkt eines besseren und umfassenden Verständnisses des Phänomens Big Data, das sowohl die Gesellschaft betreffen kann (Kolany-Raiser et al., 2018) als auch die eigentliche Forschungsbeschäftigung und ein empirisches Wissenschaftsverständnis umfasst (boyd &amp; Crawford, 2012;Mahrt &amp; Scharkow, 2013).Unter dem Begriff Daten werden laut Duden auch ganz allgemein "Beobachtungen, Messungen, statistischen Erhebungen" (Kunkel-Razum et al., 2017) subsumiert. Wenn nachfolgend nun von Daten und insbesondere digitalen Daten gesprochen wird, dann wird der Datenbegriff in eben diesem Sinne der manifest dokumentierten Beobachtung von Tatsachen verstanden. Da jedoch auch ein Musikstück oder ein Video in digitaler Datenform vorliegen kann, wird bereits an dieser Stelle deutlich, dass es unterschiedlich weit gefasste Datenbegriffe geben kann: Einen weitreichenden Datenbegriff , der allein auf die technisch-materielle Dokumentationsform abstellt und mithin bspw. auch kulturelle Produkte umschließt, die in Datenform vorliegen, sowie einen engeren Datenbegriff , der empirisch zu verstehen ist und speziell auf Beobachtungsdaten rekurriert. Wenn nicht anders genannt oder hervorgehoben, wird dabei meistens diesem engen Datenbegriff gefolgt, wenn nachfolgend von Daten in diesem forschungsempirischen Sinne die Rede ist. Doch auch ein weitreichenderer sozio-technischer und kultureller Datenbegriff wird in den folgenden Ausführungen immer dort relevant, wo es um die soziale Bedeutung von Digitaldaten geht. Dabei ist der Datenbegriff dann nicht beliebig gewählt, sondern in seiner vielschichtigen Bedeutung der Bezugspunkt eines besseren und umfassenden Verständnisses des Phänomens Big Data, das sowohl die Gesellschaft betreffen kann (Kolany-Raiser et al., 2018) als auch die eigentliche Forschungsbeschäftigung und ein empirisches Wissenschaftsverständnis umfasst (boyd &amp; Crawford, 2012;Mahrt &amp; Scharkow, 2013).</p>
        <p>Es gibt viele Lebensbereiche, in denen vor allem jene Beobachtungsdaten eine immense Bedeutung innehaben, so etwa in der Medizin, im Staatswesen, selbstverständlich in der Wirtschaft und insbesondere auch in der Wissenschaft (Cohen, 2006;Crook &amp; O'Hara, 2011;Hacking, 1990;MacKenzie, 1981; T. M. Porter, 2011). Man erhält so bspw. durch Daten über die wirtschaftliche Güter-und Dienstleistungsproduktion eines Landes einen Einblick in die Verfassung seiner Ökonomie. Ganz gleich, ob die Speicherung bereits für einen gezielten Verwertungszweck geschieht oder die Daten als Nebenprodukt anfallen: Die andauernde Dokumentation, das Festhalten dieser Daten auf einem Speichermedium meint Datenspeicherung und ist somit das Ergebnis fortlaufend festgehaltener Beobachtungen. An diese Speicherung kann dann eine Weiterverarbeitung anschließen, diese muss jedoch nicht zwingend stattfinden. Erfolgt bspw. eine Auswertung der Daten, meint dies oft, jedoch nicht zwangsläufig, dass statistische Zusammenhänge in den Daten aufgezeigt werden und unterschiedliche Daten miteinander in Beziehung gebracht werden. Viel wichtiger ist zunächst jedoch das zuvor erwähnte Moment der Bedeutungsfeststellung auf Grundlage der Beobachtungsdaten, denn diese Bedeutungszuschreibung stößt wiederum weitergehende Handlungsentscheidungen an (Cohen, 2006; T. M. Porter, 2011;Rieder &amp; Simon, 2016). Mit Bezug auf das eingangs eingeführte Beispiel diagnostiziert die Ärztin aus dem Ansteigen der Fieberkurve des Patienten eine Verschlimmerung des Krankheitsverlaufs und sieht sich zu einer Maßnahme wie der Gabe eines fiebersenkenden Medikaments veranlasst.Es gibt viele Lebensbereiche, in denen vor allem jene Beobachtungsdaten eine immense Bedeutung innehaben, so etwa in der Medizin, im Staatswesen, selbstverständlich in der Wirtschaft und insbesondere auch in der Wissenschaft (Cohen, 2006;Crook &amp; O'Hara, 2011;Hacking, 1990;MacKenzie, 1981; T. M. Porter, 2011). Man erhält so bspw. durch Daten über die wirtschaftliche Güter-und Dienstleistungsproduktion eines Landes einen Einblick in die Verfassung seiner Ökonomie. Ganz gleich, ob die Speicherung bereits für einen gezielten Verwertungszweck geschieht oder die Daten als Nebenprodukt anfallen: Die andauernde Dokumentation, das Festhalten dieser Daten auf einem Speichermedium meint Datenspeicherung und ist somit das Ergebnis fortlaufend festgehaltener Beobachtungen. An diese Speicherung kann dann eine Weiterverarbeitung anschließen, diese muss jedoch nicht zwingend stattfinden. Erfolgt bspw. eine Auswertung der Daten, meint dies oft, jedoch nicht zwangsläufig, dass statistische Zusammenhänge in den Daten aufgezeigt werden und unterschiedliche Daten miteinander in Beziehung gebracht werden. Viel wichtiger ist zunächst jedoch das zuvor erwähnte Moment der Bedeutungsfeststellung auf Grundlage der Beobachtungsdaten, denn diese Bedeutungszuschreibung stößt wiederum weitergehende Handlungsentscheidungen an (Cohen, 2006; T. M. Porter, 2011;Rieder &amp; Simon, 2016). Mit Bezug auf das eingangs eingeführte Beispiel diagnostiziert die Ärztin aus dem Ansteigen der Fieberkurve des Patienten eine Verschlimmerung des Krankheitsverlaufs und sieht sich zu einer Maßnahme wie der Gabe eines fiebersenkenden Medikaments veranlasst.</p>
        <p>Die Speicherung von Daten funktioniert wie im Falle aller menschlich geschaffenen Symbole mit Blick auf die Menschheitsgeschichte zunächst vor allem durch Festhalten von Informationen auf Papier oder anderen ‚analogen' Speichermedien (Faulstich, 2006). So wurden in der Schifffahrt Logbücher geführt (Cohen, 2006), in denen allerlei wichtige und nebensächliche Informationen zu Beschaffenheit von See und Schiff dokumentiert sind. Die analoge Speicherung der Daten auf in Aktenordnern gesammelten und verwahrten Unmengen von Papier ist dabei auch weiterhin recht gebräuchlich, wird jedoch nunmehr ergänzt um die digitale Speicherung von Daten.Die Speicherung von Daten funktioniert wie im Falle aller menschlich geschaffenen Symbole mit Blick auf die Menschheitsgeschichte zunächst vor allem durch Festhalten von Informationen auf Papier oder anderen ‚analogen' Speichermedien (Faulstich, 2006). So wurden in der Schifffahrt Logbücher geführt (Cohen, 2006), in denen allerlei wichtige und nebensächliche Informationen zu Beschaffenheit von See und Schiff dokumentiert sind. Die analoge Speicherung der Daten auf in Aktenordnern gesammelten und verwahrten Unmengen von Papier ist dabei auch weiterhin recht gebräuchlich, wird jedoch nunmehr ergänzt um die digitale Speicherung von Daten.</p>
        <p>Ausgehend von Claude Shannons Arbeiten zu einer mathematischen Theorie von Kommunikation (Shannon, 1948) bekam der bis dato unscharfe Begriff der Information eine zählbare Form und wurde forthin quantifizierbar (Shannon &amp; Weaver, 1949). Shannon war somit der Wegbereiter einer neuen Sicht auf Information (Gleick, 2012), prägte hierbei den Begriff Bit und ebnete damit der bis heute gebräuchlichsten Ausdrucksweise von Daten den Weg: binär codierte Sequenzen von Zustandsbeschreibungen, ausgedrückt in 1 oder 0. Er legte den konzeptuellen Grundstein für das, was heutzutage weithin unter digitaler IuK verstanden wird (Guizzo, 2003). Denn gegen Mitte des 20. Jahrhundert bestand nunmehr auch die Möglichkeit, Informationen auf digitalen Speichermedien festzuhalten (Ceruzzi, 2003). Dies führt in Kombination mit Computern, die jegliche Informationen als binär codierte Sequenzen in den digitalen Speicher schreiben und weiterverarbeiten, durch industrielle Massenfertigung zu einem explosionsartigen Anstieg von verfügbaren Datenträgern und Datenverarbeitungsanlagen (Berkeley, 1949;Ifrah, 2001). Daten können nun maschinell und fortlaufend ohne menschliches Zutun automatisiert erhoben und darüber hinaus schnell vervielfältigt werden (Chun &amp; Soderman, 2008;Storsul &amp; Fagerjord, 2008). Informationsverarbeitende IuK, allen voran ebenjener Computer, werden innerhalb weniger Jahrzehnte zentraler Bestandteil menschlicher Gesellschaften. Die zunehmende Nutzung von IuK in unterschiedlichen Lebensbereichen bringt immer auch die Möglichkeit der begleitenden Speicherung und Dokumentation dieser Nutzung mit sich. Wo immer Computertechnik zum Einsatz kommt, fallen nun Digitaldaten an. Aufgrund der fortschreitenden Verbreitung digitaler Medientechnologien wie Laptops, Computer und Smartwatches bezeichnen McAfee und Brynjolfsson (2012) den Menschen, der diese Technologien nutzt, auch als "Walking Data Generator". Zudem entstehen beim computerisierten Zugriff auf digitale Daten erster Ordnung zusätzlich neue digitale Daten zweiter Ordnung, sogenannte Meta-Daten (Pomerantz, 2015). Neben der Speicherung großer Datenmengen erlauben Computer zudem auch die regelgeleitete Weiterverarbeitung und Analyse der Daten. Moderne Prozessoren, bezeichnenderweise auch Rechner genannt, erlauben mannigfaltige statistische Auswertungen und Datenverarbeitung, wobei die Daten erster und zweiter Ordnung immer wieder zusammengefasst und transformiert werden können. Die Möglichkeit, die Vielzahl an Daten auf digitalen Speichermedien festzuhalten und von hier Techniken der Informationsverarbeitung zuzuführen, legen den Grundstein für das, was mittlerweile gemeinhin unter dem Begriff Big Data verstanden wird, einem Phänomen, bei dem also Daten unter dem Vorzeichen der Digitalisierung in großen Mengen anfallen und produziert werden können. An der Schwelle zum 21. Jahrhundert verdoppeln sich jedes Jahr allein die weltweit verfügbaren wissenschaftlichen Daten (Szalay &amp; Gray, 2006), so dass sinnbildlich von einer Datenflut (engl. ‚Data Deluge') gesprochen wird (C. Anderson, 2008;G. Bell et al., 2009).Ausgehend von Claude Shannons Arbeiten zu einer mathematischen Theorie von Kommunikation (Shannon, 1948) bekam der bis dato unscharfe Begriff der Information eine zählbare Form und wurde forthin quantifizierbar (Shannon &amp; Weaver, 1949). Shannon war somit der Wegbereiter einer neuen Sicht auf Information (Gleick, 2012), prägte hierbei den Begriff Bit und ebnete damit der bis heute gebräuchlichsten Ausdrucksweise von Daten den Weg: binär codierte Sequenzen von Zustandsbeschreibungen, ausgedrückt in 1 oder 0. Er legte den konzeptuellen Grundstein für das, was heutzutage weithin unter digitaler IuK verstanden wird (Guizzo, 2003). Denn gegen Mitte des 20. Jahrhundert bestand nunmehr auch die Möglichkeit, Informationen auf digitalen Speichermedien festzuhalten (Ceruzzi, 2003). Dies führt in Kombination mit Computern, die jegliche Informationen als binär codierte Sequenzen in den digitalen Speicher schreiben und weiterverarbeiten, durch industrielle Massenfertigung zu einem explosionsartigen Anstieg von verfügbaren Datenträgern und Datenverarbeitungsanlagen (Berkeley, 1949;Ifrah, 2001). Daten können nun maschinell und fortlaufend ohne menschliches Zutun automatisiert erhoben und darüber hinaus schnell vervielfältigt werden (Chun &amp; Soderman, 2008;Storsul &amp; Fagerjord, 2008). Informationsverarbeitende IuK, allen voran ebenjener Computer, werden innerhalb weniger Jahrzehnte zentraler Bestandteil menschlicher Gesellschaften. Die zunehmende Nutzung von IuK in unterschiedlichen Lebensbereichen bringt immer auch die Möglichkeit der begleitenden Speicherung und Dokumentation dieser Nutzung mit sich. Wo immer Computertechnik zum Einsatz kommt, fallen nun Digitaldaten an. Aufgrund der fortschreitenden Verbreitung digitaler Medientechnologien wie Laptops, Computer und Smartwatches bezeichnen McAfee und Brynjolfsson (2012) den Menschen, der diese Technologien nutzt, auch als "Walking Data Generator". Zudem entstehen beim computerisierten Zugriff auf digitale Daten erster Ordnung zusätzlich neue digitale Daten zweiter Ordnung, sogenannte Meta-Daten (Pomerantz, 2015). Neben der Speicherung großer Datenmengen erlauben Computer zudem auch die regelgeleitete Weiterverarbeitung und Analyse der Daten. Moderne Prozessoren, bezeichnenderweise auch Rechner genannt, erlauben mannigfaltige statistische Auswertungen und Datenverarbeitung, wobei die Daten erster und zweiter Ordnung immer wieder zusammengefasst und transformiert werden können. Die Möglichkeit, die Vielzahl an Daten auf digitalen Speichermedien festzuhalten und von hier Techniken der Informationsverarbeitung zuzuführen, legen den Grundstein für das, was mittlerweile gemeinhin unter dem Begriff Big Data verstanden wird, einem Phänomen, bei dem also Daten unter dem Vorzeichen der Digitalisierung in großen Mengen anfallen und produziert werden können. An der Schwelle zum 21. Jahrhundert verdoppeln sich jedes Jahr allein die weltweit verfügbaren wissenschaftlichen Daten (Szalay &amp; Gray, 2006), so dass sinnbildlich von einer Datenflut (engl. ‚Data Deluge') gesprochen wird (C. Anderson, 2008;G. Bell et al., 2009).</p>
        <p>Die vorhergehenden Ausführungen dienen zunächst einmal einem Grundverständnis für das, was gemeinhin unter Daten zu verstehen ist und wieso insbesondere die Digitalisierung die Entstehung, Speicherung und Auswertung der Daten begünstigt und zu immer größer werdenden Datenbeständen führt. Hieraus lässt sich jedoch noch nicht ableiten, warum genau diese Daten nun gerade eine so große gesellschaftliche Beachtung erfahren und ihnen eine immense Bedeutung zugeschrieben wird, sie gar zu einer neuen Leitwährung stilisiert werden. Hierzu bedarf es einer weitergehenden Betrachtung der Charakteristika und hieraus abgeleiteter Potentiale der Sammlung und Verwertung großer digitaler Datenbestände, die auch als Big Data bezeichnet werden.Die vorhergehenden Ausführungen dienen zunächst einmal einem Grundverständnis für das, was gemeinhin unter Daten zu verstehen ist und wieso insbesondere die Digitalisierung die Entstehung, Speicherung und Auswertung der Daten begünstigt und zu immer größer werdenden Datenbeständen führt. Hieraus lässt sich jedoch noch nicht ableiten, warum genau diese Daten nun gerade eine so große gesellschaftliche Beachtung erfahren und ihnen eine immense Bedeutung zugeschrieben wird, sie gar zu einer neuen Leitwährung stilisiert werden. Hierzu bedarf es einer weitergehenden Betrachtung der Charakteristika und hieraus abgeleiteter Potentiale der Sammlung und Verwertung großer digitaler Datenbestände, die auch als Big Data bezeichnet werden.</p>
        <p>Die Erläuterung des Wesens von Daten im vorigen Abschnitt, vor allem mit Blick auf die Besonderheiten digitaler Daten und den Voraussetzungen und Möglichkeiten ihrer informationstechnischen Verarbeitung, erlaubt nun den Blick auf das Phänomen Big Data zu richten. Big Data nimmt seinen Ausgangspunkt in der vorrangigen Digitalität von Daten im Zuge der Mitte des 20. Jahrhunderts beginnenden, eingangs beschriebenen Digitalisierung und der hiermit einhergehenden Verbreitung von Computertechnologie (Ceruzzi, 2003;Rid, 2017;Wittpahl, 2017).Die Erläuterung des Wesens von Daten im vorigen Abschnitt, vor allem mit Blick auf die Besonderheiten digitaler Daten und den Voraussetzungen und Möglichkeiten ihrer informationstechnischen Verarbeitung, erlaubt nun den Blick auf das Phänomen Big Data zu richten. Big Data nimmt seinen Ausgangspunkt in der vorrangigen Digitalität von Daten im Zuge der Mitte des 20. Jahrhunderts beginnenden, eingangs beschriebenen Digitalisierung und der hiermit einhergehenden Verbreitung von Computertechnologie (Ceruzzi, 2003;Rid, 2017;Wittpahl, 2017).</p>
        <p>Eine der wichtigsten Vorbedingungen für die vermeintliche Explosion an Daten ist jedoch insbesondere das Internet, das eine Vernetzung zwischen Schnittstellen der IuK und den dezentralen Austausch digital codierter Information ermöglicht. Entsprechend definieren B. M. Leiner et al. (2009) auch wie folgt: "The Internet is at once a world-wide broadcasting capability, a mechanism for information dissemination, and a medium for collaboration and interaction between individuals and their computers without regard for geographic location" (S. 23). Als technische Infrastruktur, die aus dem militärischen und wissenschaftlichen Kontext entstammt und von der Advanced Research Projects Agency (ARPA) des US-amerikanischen Verteidigungsministeriums vorangetrieben wurde (Belfiore, 2009), hat sich das Internet ab Ende des vergangenen Jahrtausends weltweit in immer mehr Lebensbereichen fest etabliert. Bedingt durch die technische Infrastruktur des Internets in Kombination mit anderen IuK werden laufend und global Unmengen von digitalen Daten erzeugt, verteilt und weiterverarbeitet (Pentland, 2014;Stephens-Davidowitz, 2017). Zum Beispiel werden heutzutage in so gut wie allen Bereichen des privaten und beruflichen Alltags IuK genutzt, die stetig mit dem Internet verbunden, also online sind. Was mit stationären Computern mit Online-Zugang begann, setzt sich mit dem weitreichenden Gebrauch von Smartphones fort. Im Jahr 2018 nutzen 57 Millionen Menschen in Deutschland solch ein Gerät, das man fast überall hin mitnehmen kann und das jederzeit mit dem Internet verbunden ist (Statista, 2018c). Mit diesem kann man mittlerweile nicht mehr nur telefonieren und Nachrichten austauschen (Gebhardt, 2008), sondern auch Musik hören, Fotos machen und auf einen globalen Informationsspeicher zugreifen.Eine der wichtigsten Vorbedingungen für die vermeintliche Explosion an Daten ist jedoch insbesondere das Internet, das eine Vernetzung zwischen Schnittstellen der IuK und den dezentralen Austausch digital codierter Information ermöglicht. Entsprechend definieren B. M. Leiner et al. (2009) auch wie folgt: "The Internet is at once a world-wide broadcasting capability, a mechanism for information dissemination, and a medium for collaboration and interaction between individuals and their computers without regard for geographic location" (S. 23). Als technische Infrastruktur, die aus dem militärischen und wissenschaftlichen Kontext entstammt und von der Advanced Research Projects Agency (ARPA) des US-amerikanischen Verteidigungsministeriums vorangetrieben wurde (Belfiore, 2009), hat sich das Internet ab Ende des vergangenen Jahrtausends weltweit in immer mehr Lebensbereichen fest etabliert. Bedingt durch die technische Infrastruktur des Internets in Kombination mit anderen IuK werden laufend und global Unmengen von digitalen Daten erzeugt, verteilt und weiterverarbeitet (Pentland, 2014;Stephens-Davidowitz, 2017). Zum Beispiel werden heutzutage in so gut wie allen Bereichen des privaten und beruflichen Alltags IuK genutzt, die stetig mit dem Internet verbunden, also online sind. Was mit stationären Computern mit Online-Zugang begann, setzt sich mit dem weitreichenden Gebrauch von Smartphones fort. Im Jahr 2018 nutzen 57 Millionen Menschen in Deutschland solch ein Gerät, das man fast überall hin mitnehmen kann und das jederzeit mit dem Internet verbunden ist (Statista, 2018c). Mit diesem kann man mittlerweile nicht mehr nur telefonieren und Nachrichten austauschen (Gebhardt, 2008), sondern auch Musik hören, Fotos machen und auf einen globalen Informationsspeicher zugreifen.</p>
        <p>Nach und nach werden in einem Zusammenspiel kabelloser und miteinander vernetzter Sensorik immer mehr Alltagsgegenstände wie bspw. Haushaltsgeräte ‚online' sein und zusätzliche Funktionen und Informationen bereitstellen, für die eine stetige Verbindung zur zuvor beschriebenen technischen Infrastruktur des Internets gegeben sein muss. Diese Entwicklung aus der IuK, bei der Computertechnik allzeit online ist, wird auch als Internet der Dinge (engl. Internet of Things -IOT) bezeichnet (Ashton, 2009;Gubbi et al., 2013). Hierunter fallen Kühlschränke und Heizungssysteme, die mit dem Internet verbunden sind und über dieses, insbesondere via Smartphone, aus der Ferne gesteuert werden können, Befehle empfangen oder versenden können. Die vermeintlichen Vorzüge dieser Vernetzung und den sich hieraus ergebenden Steuerungs-und Optimierungsmöglichkeiten werden unter dem Stichwort 
            <rs type="software">Smart Home</rs> angepriesen (Harper, 2003). Es wird alleine hierdurch deutlich, dass die stetige Online-Konnektivität technischer Endgeräte und ihrer Sensorik sowie der laufende Kommunikationsaustausch dieser Geräte untereinander und mit den Nutzer*innen das Ausmaß der digitalen Datenentstehung weiter befeuern wird. Folglich gibt es etliche weitere Anwendungsfelder und Verwendungsmöglichkeiten des IOT und laufend kommen neuen Online-Innovationen hinzu (Li et al., 2015). Dies sind nur einige von vielen Beispielen, um zu demonstrieren, in welchem Umfang digitalisiert wird und bei der Nutzung digitaler Medien automatisiert Daten entstehen (Kolany-Raiser et al., 2018;Wittpahl, 2017). Die Automatisierung der Datenerhebung wird dabei bspw. direkt handlungsrelevant beim Aufzeichnen, Analysieren und Reflektieren von und über Daten, die man im Rahmen des Self-Tracking, zur Selbstbeobachtung und -vermessung des eigenen Gesundheitszustands über sich selbst gesammelt hat (Gilmore, 2016;Nafus &amp; Sherman, 2014;Neff &amp; Nafus, 2016). Sie kann sich jedoch auch indirekt bemerkbar machen, etwa, wenn datenbasiert Empfehlungen ausgesprochen werden und Entscheidungen abgenommen werden, z. B. bei personalisierten Angeboten und zielgerichteter Werbung, die durch Algorithmen des maschinellen Lernens möglich werden (Beer, 2017;Mohabbat Kar et al., 2018).
        </p>
        <p>Eine ausführliche Betrachtung des Phänomens Big Data und der Beschreibungsdimensionen, die in der Literatur verwendet werden, legt somit den Grundstein für ein umfassendes Verständnis für die technischen Grundlagen eines zu beschreibenden Mythos Big Data und des sich hieraus gespeisten Glaubenssystems in Bezug auf Big Data, die insbesondere auf die Erwartungen an Erkenntnis-und Nutzengewinn von Big Data abstellen. Hierbei ist trotz der weit zurück zu verfolgenden historischen Entwicklungslinie bereits an dieser Stelle anzumerken, dass Begriff, Verständnis und Bedeutung von Big Data selbst noch recht jung sind, es zwar keine etablierte Definition, jedoch durchaus definitorische Übereinstimmungen gibt. Erste Definitionsansätze sind durch die Entwicklungsdynamiken im Zuge der Digitalisierung folglich noch flexibel und dehnbar. Der folgende Abschnitt nähert sich einer Arbeitsdefinition der essentiellen Wesensmerkmale von Big Data, die Grundlage für die auszuarbeitende Betrachtung von durch Digitalisierung begünstigter Quantifizierung der Gesellschaft und insbesondere hiermit verbundenem Wissenszugewinn und individuellem und gesellschaftlichem Nutzen sein soll. Mit Bezug auf akademische Literatursynthesen und Überblicksartikel wird für diesen Abschnitt eine Aufteilung der Literatur nach Beschreibungsschwerpunkten vorgenommen (Mauro et al., 2016). Abschnitt 3.4 beschäftigt sich daher zunächst mit den technischen Beschreibungsdimensionen von Big Data. Hierauf folgend wird auf die soziotechnischen Konsequenzen eingegangen und insbesondere das Neuartige an Big Data in den Vordergrund gestellt (Abschnitt 3.5). Da Big Data eines von etlichen Schlagworten ist, welches sich derzeit in der öffentlichen Debatte wiederfindet, soll abschließend in Abschnitt 3.6 auf verwandte Phänomene und Entwicklungen eingegangen werden, in deren Rahmen Big Data eine gewichtige Einflussgröße oder wie beim maschinellen Lernen gar eine Grundbedingung darstellen. Ausgehend von dem dann gelegten sozio-technischen Verständnis von Big Data kann schließlich deren soziale Bedeutung für einen Erkenntnis-und Nutzengewinn näher erläutert werden.Eine ausführliche Betrachtung des Phänomens Big Data und der Beschreibungsdimensionen, die in der Literatur verwendet werden, legt somit den Grundstein für ein umfassendes Verständnis für die technischen Grundlagen eines zu beschreibenden Mythos Big Data und des sich hieraus gespeisten Glaubenssystems in Bezug auf Big Data, die insbesondere auf die Erwartungen an Erkenntnis-und Nutzengewinn von Big Data abstellen. Hierbei ist trotz der weit zurück zu verfolgenden historischen Entwicklungslinie bereits an dieser Stelle anzumerken, dass Begriff, Verständnis und Bedeutung von Big Data selbst noch recht jung sind, es zwar keine etablierte Definition, jedoch durchaus definitorische Übereinstimmungen gibt. Erste Definitionsansätze sind durch die Entwicklungsdynamiken im Zuge der Digitalisierung folglich noch flexibel und dehnbar. Der folgende Abschnitt nähert sich einer Arbeitsdefinition der essentiellen Wesensmerkmale von Big Data, die Grundlage für die auszuarbeitende Betrachtung von durch Digitalisierung begünstigter Quantifizierung der Gesellschaft und insbesondere hiermit verbundenem Wissenszugewinn und individuellem und gesellschaftlichem Nutzen sein soll. Mit Bezug auf akademische Literatursynthesen und Überblicksartikel wird für diesen Abschnitt eine Aufteilung der Literatur nach Beschreibungsschwerpunkten vorgenommen (Mauro et al., 2016). Abschnitt 3.4 beschäftigt sich daher zunächst mit den technischen Beschreibungsdimensionen von Big Data. Hierauf folgend wird auf die soziotechnischen Konsequenzen eingegangen und insbesondere das Neuartige an Big Data in den Vordergrund gestellt (Abschnitt 3.5). Da Big Data eines von etlichen Schlagworten ist, welches sich derzeit in der öffentlichen Debatte wiederfindet, soll abschließend in Abschnitt 3.6 auf verwandte Phänomene und Entwicklungen eingegangen werden, in deren Rahmen Big Data eine gewichtige Einflussgröße oder wie beim maschinellen Lernen gar eine Grundbedingung darstellen. Ausgehend von dem dann gelegten sozio-technischen Verständnis von Big Data kann schließlich deren soziale Bedeutung für einen Erkenntnis-und Nutzengewinn näher erläutert werden.</p>
        <p>Eine der ersten Definitionen, ohne dass diese bereits von Big Data gesprochen hat, geht auf einen Gartner-Report von Laney (2001) zurück, in dem dieser drei mit V beginnende Beschreibungsdimensionen, namentlich Volume, Velocity und Variety (übersetzt als: Volumen, Geschwindigkeit und Vielfalt) 3 einführt, die die großen Datenmengen charakterisieren, die im Zuge der Digitalisierung fortlaufend entstehen. In der Tradition dieser Alliteration kamen über die Zeit viele weitere mit dem Buchstaben V beginnende Beschreibungsdimensionen hinzu, die auf unterschiedliche Charakteristika der Datenmengen abstellen (Diebold, 2012). Allerdings lässt sich eine weitläufige Verbreitung des Begriffs erst ab 2010 feststellen (Gandomi &amp; Haider, 2015). Während es je nach Betrachtung also etliche zu unterscheidende Beschreibungsdimensionen gibt und mitunter über die exakte Definition von Big Data gestritten wird (Kitchin &amp; McArdle, 2016), beschränken sich die nachfolgenden Ausführungen auf die eingangs erwähnten eher deskriptiven Dimensionen Volumen, Geschwindigkeit und Vielfalt sowie insbesondere auf die in der Literatur für den Verwertungszusammenhang der Daten hervorgehobenen zentralen Dimensionen Veracity und Value. Während die deskriptiven Dimensionen die Daten an sich beschreiben, haben die beiden letztgenannten Dimensionen einen eher sozio-technisch bedeutsamen Charakter, der insofern auf die Qualität von großen digitalen Datenbeständen abstellt, indem deren erwarteten Konsequenzen für Erkenntnis-und Nutzengewinn evaluiert werden (H. Chen &amp; Yan, 2016;Gandomi &amp; Haider, 2015;Wiencierz, 2016). Letztere werden nachfolgend auch als Richtigkeit und Nutzen bezeichnet (siehe Abschnitt 3.5.1 und Abschnitt 3.5.2). Es bedarf dabei in den folgenden Kapiteln zunächst der Definition der einzelnen Charakteristika von Big Data, um hiervon ausgehend deren jeweilige 3 Für eine bessere Verständlichkeit der folgenden Ausführungen werden die jeweiligen V-Dimensionen übersetzt und es werden im weiteren Verlauf der Arbeit die deutschen Begriffsverwendungen verwendet.Eine der ersten Definitionen, ohne dass diese bereits von Big Data gesprochen hat, geht auf einen Gartner-Report von Laney (2001) zurück, in dem dieser drei mit V beginnende Beschreibungsdimensionen, namentlich Volume, Velocity und Variety (übersetzt als: Volumen, Geschwindigkeit und Vielfalt) 3 einführt, die die großen Datenmengen charakterisieren, die im Zuge der Digitalisierung fortlaufend entstehen. In der Tradition dieser Alliteration kamen über die Zeit viele weitere mit dem Buchstaben V beginnende Beschreibungsdimensionen hinzu, die auf unterschiedliche Charakteristika der Datenmengen abstellen (Diebold, 2012). Allerdings lässt sich eine weitläufige Verbreitung des Begriffs erst ab 2010 feststellen (Gandomi &amp; Haider, 2015). Während es je nach Betrachtung also etliche zu unterscheidende Beschreibungsdimensionen gibt und mitunter über die exakte Definition von Big Data gestritten wird (Kitchin &amp; McArdle, 2016), beschränken sich die nachfolgenden Ausführungen auf die eingangs erwähnten eher deskriptiven Dimensionen Volumen, Geschwindigkeit und Vielfalt sowie insbesondere auf die in der Literatur für den Verwertungszusammenhang der Daten hervorgehobenen zentralen Dimensionen Veracity und Value. Während die deskriptiven Dimensionen die Daten an sich beschreiben, haben die beiden letztgenannten Dimensionen einen eher sozio-technisch bedeutsamen Charakter, der insofern auf die Qualität von großen digitalen Datenbeständen abstellt, indem deren erwarteten Konsequenzen für Erkenntnis-und Nutzengewinn evaluiert werden (H. Chen &amp; Yan, 2016;Gandomi &amp; Haider, 2015;Wiencierz, 2016). Letztere werden nachfolgend auch als Richtigkeit und Nutzen bezeichnet (siehe Abschnitt 3.5.1 und Abschnitt 3.5.2). Es bedarf dabei in den folgenden Kapiteln zunächst der Definition der einzelnen Charakteristika von Big Data, um hiervon ausgehend deren jeweilige 3 Für eine bessere Verständlichkeit der folgenden Ausführungen werden die jeweiligen V-Dimensionen übersetzt und es werden im weiteren Verlauf der Arbeit die deutschen Begriffsverwendungen verwendet.</p>
        <p>Bedeutung für eine Betrachtung der sozialen Dimension des Phänomens zu erläutern. Dabei werden zu Illustrationszwecken und für ein besseres Verständnis auch einige prominente Beispiele zum Anwendungskontext von Big Data eingebracht. Für weitere Beispiele zu Anwendungen und Einsatzpotential von Big Data sei an dieser Stelle stellvertretend auf die Ausführungen von Mayer-Schönberger und Cukier (2013), O'Neil (2017), Rudder (2014) und Stephens-Davidowitz (2017) verwiesen.Bedeutung für eine Betrachtung der sozialen Dimension des Phänomens zu erläutern. Dabei werden zu Illustrationszwecken und für ein besseres Verständnis auch einige prominente Beispiele zum Anwendungskontext von Big Data eingebracht. Für weitere Beispiele zu Anwendungen und Einsatzpotential von Big Data sei an dieser Stelle stellvertretend auf die Ausführungen von Mayer-Schönberger und Cukier (2013), O'Neil (2017), Rudder (2014) und Stephens-Davidowitz (2017) verwiesen.</p>
        <p>Das Volumen (Volume) digitaler Datenentstehung und -verwertung betrifft das Ausmaß oder die Größenordnung der Datenmengen, die sich nicht nur einfacher Datenspeicherung und -analyse, sondern oft auch der menschlichen Vorstellungskraft entziehen. "The term 'Big Data' suggests that size is its key feature" (Lyon, 2014, S. 5). Wie zuvor beschrieben wurde, fallen in nahezu allen Lebensbereichen und insbesondere immer dort digitale Daten an, wo Technologien der digitalen Informationsverarbeitung Anwendung finden. So werden bspw. am European Bioinformatics Institute und auch dem CERN, einer europäischen Forschungseinrichtung im Bereich der Teilchenphysik, mittlerweile Petabyte 4 an Daten gespeichert -das Tausendfache einer handelsüblichen Festplatte (Marx, 2013).Das Volumen (Volume) digitaler Datenentstehung und -verwertung betrifft das Ausmaß oder die Größenordnung der Datenmengen, die sich nicht nur einfacher Datenspeicherung und -analyse, sondern oft auch der menschlichen Vorstellungskraft entziehen. "The term 'Big Data' suggests that size is its key feature" (Lyon, 2014, S. 5). Wie zuvor beschrieben wurde, fallen in nahezu allen Lebensbereichen und insbesondere immer dort digitale Daten an, wo Technologien der digitalen Informationsverarbeitung Anwendung finden. So werden bspw. am European Bioinformatics Institute und auch dem CERN, einer europäischen Forschungseinrichtung im Bereich der Teilchenphysik, mittlerweile Petabyte 4 an Daten gespeichert -das Tausendfache einer handelsüblichen Festplatte (Marx, 2013).</p>
        <p>Basierend auf einer Analyse von Suchmaschinen wird die derzeitige Größe der im indizierten Internet erreichbaren Webseiten mit 4,47 Milliarden Einträgen angegeben (van den Bosch et al., 2016;WorldWideWebSize, o. D.). Doch auch bereits vorhandene analoge Daten, die in den Jahrhunderten vor der Digitalisierung entstanden, werden zunehmend in digitale Daten überführt. Das Projekt Google Books hat seit seiner Entstehung 2004 bis zum Jahr 2015 rund mehr als 25 Millionen der weltweit geschätzt 130 Millionen verfügbaren Bücher digitalisiert (Heyman, 2015;Taycher, 2010). Diese Zahlen stehen hier illustrativ für die große Menge an Daten, die die Menschheit fortlaufend erzeugt. Die Beschreibungsdimension Volumen -die im Folgenden auch als Ausmaß der Datenerzeugung und -speicherung umschrieben wird -ist folglich jene Eigenschaft, die wohl den meisten Menschen in den Sinn kommt, wenn es um Big Data geht. Es gibt keinen Zweifel daran, dass man es im Rahmen von Big Data mit einer Unmenge an Daten zu tun hat, auch wenn in der Literatur vereinzelt angezweifelt wird, dass nur große Datensätze Big Data 4 Ein Petabyte sind 10 15 Bytes oder auch eine Million Gigabyte. sein können und es keine verbindliche Grenze gibt, ab wann ‚kleine' oder vermeintlich ‚normal große' Datensätze zu Big Data werden (Kitchin, 2014). Dass mit Blick auf eine konkrete Zahl an erhobenen Variablen oder Fällen kein Wert benannt werden kann, führt auch dazu, dass insbesondere auf die technischen Herausforderungen bei der Verarbeitung von Big Data als zentrale Konsequenz hingewiesen wird:Basierend auf einer Analyse von Suchmaschinen wird die derzeitige Größe der im indizierten Internet erreichbaren Webseiten mit 4,47 Milliarden Einträgen angegeben (van den Bosch et al., 2016;WorldWideWebSize, o. D.). Doch auch bereits vorhandene analoge Daten, die in den Jahrhunderten vor der Digitalisierung entstanden, werden zunehmend in digitale Daten überführt. Das Projekt Google Books hat seit seiner Entstehung 2004 bis zum Jahr 2015 rund mehr als 25 Millionen der weltweit geschätzt 130 Millionen verfügbaren Bücher digitalisiert (Heyman, 2015;Taycher, 2010). Diese Zahlen stehen hier illustrativ für die große Menge an Daten, die die Menschheit fortlaufend erzeugt. Die Beschreibungsdimension Volumen -die im Folgenden auch als Ausmaß der Datenerzeugung und -speicherung umschrieben wird -ist folglich jene Eigenschaft, die wohl den meisten Menschen in den Sinn kommt, wenn es um Big Data geht. Es gibt keinen Zweifel daran, dass man es im Rahmen von Big Data mit einer Unmenge an Daten zu tun hat, auch wenn in der Literatur vereinzelt angezweifelt wird, dass nur große Datensätze Big Data 4 Ein Petabyte sind 10 15 Bytes oder auch eine Million Gigabyte. sein können und es keine verbindliche Grenze gibt, ab wann ‚kleine' oder vermeintlich ‚normal große' Datensätze zu Big Data werden (Kitchin, 2014). Dass mit Blick auf eine konkrete Zahl an erhobenen Variablen oder Fällen kein Wert benannt werden kann, führt auch dazu, dass insbesondere auf die technischen Herausforderungen bei der Verarbeitung von Big Data als zentrale Konsequenz hingewiesen wird:</p>
        <p>The term Big Data has a relative meaning and tends to denote bigger and bigger data sets over time. In computer science, it refers to data sets that are too big to be handled by regular storage and processing infrastructures. (Mahrt &amp; Scharkow, 2013, S. 22) Gleichzeitig bedeutet das auch, dass die Datenmengen so groß sind, dass kein Mensch sie selbst und unmittelbar verarbeiten kann, er also ohne technische Hilfsmittel nicht in der Lage ist, eine unmittelbare Bedeutung aus ihnen abzuleiten. Schon hier wird deutlich, dass lediglich ein indirekter vermittelter Zugang zu den Daten bestehen kann, aus dem sich ein Verständnis dessen speist, was man in den Daten zu erkennen glaubt. Ein Datenleck, bei dem Millionen von vertraulichen Daten in die falschen Hände geraten, wird erst dann zu einer großen Gefahr, wenn diese Daten mit Computertechnik ausgewertet werden und ihnen so eine entsprechende Bedeutung zugeschrieben wird.The term Big Data has a relative meaning and tends to denote bigger and bigger data sets over time. In computer science, it refers to data sets that are too big to be handled by regular storage and processing infrastructures. (Mahrt &amp; Scharkow, 2013, S. 22) Gleichzeitig bedeutet das auch, dass die Datenmengen so groß sind, dass kein Mensch sie selbst und unmittelbar verarbeiten kann, er also ohne technische Hilfsmittel nicht in der Lage ist, eine unmittelbare Bedeutung aus ihnen abzuleiten. Schon hier wird deutlich, dass lediglich ein indirekter vermittelter Zugang zu den Daten bestehen kann, aus dem sich ein Verständnis dessen speist, was man in den Daten zu erkennen glaubt. Ein Datenleck, bei dem Millionen von vertraulichen Daten in die falschen Hände geraten, wird erst dann zu einer großen Gefahr, wenn diese Daten mit Computertechnik ausgewertet werden und ihnen so eine entsprechende Bedeutung zugeschrieben wird.</p>
        <p>Volumen als Charakteristikum von Big Data ist somit eine zentrale, jedoch eher deskriptive Dimension, die in so gut wie jeder Definition zu Big Data Erwähnung findet (Ylijoki &amp; Porras, 2016). 5 Zu den weiteren überwiegend deskriptiven Beschreibungsdimensionen zählen Velocity (Geschwindigkeit) und Variety (Vielfalt), die nachfolgend erörtert werden. Diese beiden Dimensionen werden dann von den eher konsequentiell-evaluativen Dimensionen Veracity (Richtigkeit) und Value (Nutzen) abgegrenzt.Volumen als Charakteristikum von Big Data ist somit eine zentrale, jedoch eher deskriptive Dimension, die in so gut wie jeder Definition zu Big Data Erwähnung findet (Ylijoki &amp; Porras, 2016). 5 Zu den weiteren überwiegend deskriptiven Beschreibungsdimensionen zählen Velocity (Geschwindigkeit) und Variety (Vielfalt), die nachfolgend erörtert werden. Diese beiden Dimensionen werden dann von den eher konsequentiell-evaluativen Dimensionen Veracity (Richtigkeit) und Value (Nutzen) abgegrenzt.</p>
        <p>Velocity ist gemeinhin als Geschwindigkeit zu übersetzen. Neben dieser räumlichen Dispersität der Daten sind die Datensätze, die unter Big Data verstanden werden, anders als es der Begriff andeutet, auch aus zeitlicher Sicht keine fertigen und abgeschlossenen Einheiten. Sie können sich stetig vergrößern oder aber bei versehentlichem Datenverlust oder aktiver Löschung7 verkleinern -was bei fortlaufender Analyse und der Interpretation ihrer Ergebnisse ebenfalls berücksichtigt werden muss.Velocity ist gemeinhin als Geschwindigkeit zu übersetzen. Neben dieser räumlichen Dispersität der Daten sind die Datensätze, die unter Big Data verstanden werden, anders als es der Begriff andeutet, auch aus zeitlicher Sicht keine fertigen und abgeschlossenen Einheiten. Sie können sich stetig vergrößern oder aber bei versehentlichem Datenverlust oder aktiver Löschung7 verkleinern -was bei fortlaufender Analyse und der Interpretation ihrer Ergebnisse ebenfalls berücksichtigt werden muss.</p>
        <p>Wenn die Entstehung großer Datenmengen in Echtzeit zu verfolgen ist, dann hat das nicht nur Auswirkungen auf die Speicherung von Big Data, sondern weckt auch menschliche Begehrlichkeit, Erkenntnisse über diese Daten und aus diesen Daten in Echtzeit zu gewinnen (Kitchin, 2014;Mayer-Schönberger &amp; Cukier, 2013). Big-Data-Analysewerkzeuge müssen daher nicht nur in der Lage sein, digitale Daten zeitlich synchron einzulesen und zu speichern, sondern auch synchron und unmittelbar Erkenntnisse bezüglich eben jener Daten zu liefern, so dass aktuelle Trends und statistische Zusammenhänge in Echtzeit verfolgt werden können (Barlow, 2013;Vera-Baquero et al., 2016). Das sind zumindest die Erwartungen, die an Big Data gerichtet sind und die der Beschreibungsdimension Geschwindigkeit für den letztendlichen Nutzungskontext besondere Bedeutung verleihen. Es reicht nicht nur zu beobachten, dass sekündlich weltweit Menschen tausende Fotos auf Facebook und Instagram hochladen. Es ist mit Blick auf das Versprechen von Big Data auch von Bedeutung, hieraus jetzt und sofort Erkenntnisse zu ziehen. Für den sozialen Kontext sollen u. a. folgende Fragen mit Hilfe von Sentiment-Analysen zur Stimmungserkennung von Personen beantwortet werden, die auf Big Data zugreifen (Bravo-Marquez et al., 2014;Liu et al., 2013;H. Wang et al., 2012): Was bewegt die Nutzer*innen bspw. gerade in ihrer Rolle als Bürger*innen? Welche Themen treiben die Öffentlichkeit um, wie sieht die öffentliche Meinung und ihre Verteilung aus? Welche Politiktreibenden fallen oder steigen gerade aus welchen Gründen in der öffentlichen Gunst? Die Möglichkeit solcher Analysen befeuern den Wunsch nach Big-Data-Kompetenzen und Auswertungskapazitäten, die in Echtzeit abgerufen werden können, da die Erwartung besteht, aus der unmittelbaren Vergangenheit und Gegenwart Erkenntnisse über Weltzustände in der Zukunft zu gewinnen (Mayer-Schönberger, 2015;Obermeyer &amp; Emanuel, 2016).Wenn die Entstehung großer Datenmengen in Echtzeit zu verfolgen ist, dann hat das nicht nur Auswirkungen auf die Speicherung von Big Data, sondern weckt auch menschliche Begehrlichkeit, Erkenntnisse über diese Daten und aus diesen Daten in Echtzeit zu gewinnen (Kitchin, 2014;Mayer-Schönberger &amp; Cukier, 2013). Big-Data-Analysewerkzeuge müssen daher nicht nur in der Lage sein, digitale Daten zeitlich synchron einzulesen und zu speichern, sondern auch synchron und unmittelbar Erkenntnisse bezüglich eben jener Daten zu liefern, so dass aktuelle Trends und statistische Zusammenhänge in Echtzeit verfolgt werden können (Barlow, 2013;Vera-Baquero et al., 2016). Das sind zumindest die Erwartungen, die an Big Data gerichtet sind und die der Beschreibungsdimension Geschwindigkeit für den letztendlichen Nutzungskontext besondere Bedeutung verleihen. Es reicht nicht nur zu beobachten, dass sekündlich weltweit Menschen tausende Fotos auf Facebook und Instagram hochladen. Es ist mit Blick auf das Versprechen von Big Data auch von Bedeutung, hieraus jetzt und sofort Erkenntnisse zu ziehen. Für den sozialen Kontext sollen u. a. folgende Fragen mit Hilfe von Sentiment-Analysen zur Stimmungserkennung von Personen beantwortet werden, die auf Big Data zugreifen (Bravo-Marquez et al., 2014;Liu et al., 2013;H. Wang et al., 2012): Was bewegt die Nutzer*innen bspw. gerade in ihrer Rolle als Bürger*innen? Welche Themen treiben die Öffentlichkeit um, wie sieht die öffentliche Meinung und ihre Verteilung aus? Welche Politiktreibenden fallen oder steigen gerade aus welchen Gründen in der öffentlichen Gunst? Die Möglichkeit solcher Analysen befeuern den Wunsch nach Big-Data-Kompetenzen und Auswertungskapazitäten, die in Echtzeit abgerufen werden können, da die Erwartung besteht, aus der unmittelbaren Vergangenheit und Gegenwart Erkenntnisse über Weltzustände in der Zukunft zu gewinnen (Mayer-Schönberger, 2015;Obermeyer &amp; Emanuel, 2016).</p>
        <p>Ein weiteres Versprechen von Big Data ist, dass man mannigfaltige Erkenntnisse für alle vorstellbaren Lebensbereiche gewinnt, solange nicht nur punktuell viel, sondern am besten auch überall und für alles Mögliche entsprechend vielfältige Daten gesammelt werden. Die Vielfalt (Variety) digitaler Datenentstehung und -verwertung rückt an späterer Stelle insbesondere im Kapitel 5 bei der fortschreitenden Quantifizierung des Sozialen in den Blick. Hier wird deutlich werden, dass mit Big Data die Hoffnung verbunden ist, für jeglichen Bereich des sozialen Miteinanders Erkenntnisse zu gewinnen, und daher in der Konsequenz überall auch Daten gesammelt werden (Mau, 2017). Der Anspruch der Digitalisierung und ihrer digitalen Daten ist mithin auch, alles messen zu können (Hubbard, 2010). Die ubiquitäre Datensammlung geschieht daher nicht nur in Form der unterschiedlichen Kommunikationsmodi wie allen voran Text sowie Bild-und Audio-Dateien, die entstehen und bspw. über die Kommunikationsarchitektur des Internets zwischen den Nutzenden ausgetauscht werden. Sondern diese unterschiedlichen Arten von Daten entstehen auch in immer neuen Kontexten. Sensoren, die von Temperatur hin zu Bewegungen etc. alles Mögliche messen, befeuern die Vielfalt der entstehenden Daten und werden nicht nur in Automotoren und Flugzeugtriebwerken verbaut, sondern auch in Uhren, mit denen Menschen jederzeit ihre Schrittzahl oder den eigenen Puls nachverfolgen können. Letzteres Beispiel nimmt Bezug auf das sogenannte Self-Tracking, bei dem laufend individuelle Körperdaten für die unterschiedlichsten Vitalparameter erhoben werden (Aktypi et al., 2017;Neff &amp; Nafus, 2016;Sharon &amp; Zandbergen, 2016). Mittlerweile nutzen 14 % der deutschen Bevölkerung sogenannte Digital-Health-Applikationen, also Hard-oder Software, mit deren Hilfe sie ihre Kalorienaufnahme, Sportaktivitäten und ihren Schlaf in digitalen Daten dokumentieren (Statista, 2018a). Die Liste an Beispielen zu der Vielseitigkeit von Datenerhebung und der Vielfalt der entstehenden digitalen Datenbestände ist lang und wächst täglich. Sie kann daher an dieser Stelle nur angedeutet werden, zumal sie ebenfalls lediglich eine deskriptive Dimension des Phänomens Big Data betrifft und erst dann tatsächlich relevant wird, wenn der Digitalisierungskontext eine nähere Betrachtung der spezifischen Charakteristika der Datenvielfalt notwendig macht. 8 Es ist an dieser Stelle jedoch auch darauf hinzuweisen, dass die Vielfalt der Daten und die Ubiquität der Datensammlung dazu führen, dass je nach Schätzung rund 85 bis 95 % der Datensätze aus unstrukturierten Daten bestehen (Gandomi &amp; Haider, 2015;Taylor, 2017). Strukturierte Daten sind meist in sogenannten relationalen Datenbank-Managementsystemen (RDBMS) aufbereitet und folgen in ihrem Aufbau vorher definierten Dateneingaben für bestimmte Kennwerte wie Geburtsdaten, Sozialversicherungsnummern und Geldwerten (Meier, 2010). Unstrukturierte Daten hingegen bestehen u. a. aus Text, Bildern, Audio-und Video-Dateien (Isson, 2018), reichen also von E-Mails hin zu Online-Nachrichtenartikeln, von Smartphone-Fotos hin zu Sport-Live-Streams und Videos von Überwachungskameras. Das führt nicht nur zu Herausforderungen mit Blick auf die Auswertungsmöglichkeiten, sondern häufig auch dazu, dass man zwar viele und immer neue Daten hat, abhängig vom Verwertungskontext oft jedoch erst einmal reflektieren muss, worüber diese Daten denn nun genau Auskunft geben können. Es muss daher auch die soziale Bedeutung von Big Data in ihrem soziotechnischen Kontext angesprochen werden, wobei sogleich auf zwei entsprechende Dimensionen einzugehen ist, die das Verständnis vom Sinn und Zweck der Sammlung von Big Data anleiten.Ein weiteres Versprechen von Big Data ist, dass man mannigfaltige Erkenntnisse für alle vorstellbaren Lebensbereiche gewinnt, solange nicht nur punktuell viel, sondern am besten auch überall und für alles Mögliche entsprechend vielfältige Daten gesammelt werden. Die Vielfalt (Variety) digitaler Datenentstehung und -verwertung rückt an späterer Stelle insbesondere im Kapitel 5 bei der fortschreitenden Quantifizierung des Sozialen in den Blick. Hier wird deutlich werden, dass mit Big Data die Hoffnung verbunden ist, für jeglichen Bereich des sozialen Miteinanders Erkenntnisse zu gewinnen, und daher in der Konsequenz überall auch Daten gesammelt werden (Mau, 2017). Der Anspruch der Digitalisierung und ihrer digitalen Daten ist mithin auch, alles messen zu können (Hubbard, 2010). Die ubiquitäre Datensammlung geschieht daher nicht nur in Form der unterschiedlichen Kommunikationsmodi wie allen voran Text sowie Bild-und Audio-Dateien, die entstehen und bspw. über die Kommunikationsarchitektur des Internets zwischen den Nutzenden ausgetauscht werden. Sondern diese unterschiedlichen Arten von Daten entstehen auch in immer neuen Kontexten. Sensoren, die von Temperatur hin zu Bewegungen etc. alles Mögliche messen, befeuern die Vielfalt der entstehenden Daten und werden nicht nur in Automotoren und Flugzeugtriebwerken verbaut, sondern auch in Uhren, mit denen Menschen jederzeit ihre Schrittzahl oder den eigenen Puls nachverfolgen können. Letzteres Beispiel nimmt Bezug auf das sogenannte Self-Tracking, bei dem laufend individuelle Körperdaten für die unterschiedlichsten Vitalparameter erhoben werden (Aktypi et al., 2017;Neff &amp; Nafus, 2016;Sharon &amp; Zandbergen, 2016). Mittlerweile nutzen 14 % der deutschen Bevölkerung sogenannte Digital-Health-Applikationen, also Hard-oder Software, mit deren Hilfe sie ihre Kalorienaufnahme, Sportaktivitäten und ihren Schlaf in digitalen Daten dokumentieren (Statista, 2018a). Die Liste an Beispielen zu der Vielseitigkeit von Datenerhebung und der Vielfalt der entstehenden digitalen Datenbestände ist lang und wächst täglich. Sie kann daher an dieser Stelle nur angedeutet werden, zumal sie ebenfalls lediglich eine deskriptive Dimension des Phänomens Big Data betrifft und erst dann tatsächlich relevant wird, wenn der Digitalisierungskontext eine nähere Betrachtung der spezifischen Charakteristika der Datenvielfalt notwendig macht. 8 Es ist an dieser Stelle jedoch auch darauf hinzuweisen, dass die Vielfalt der Daten und die Ubiquität der Datensammlung dazu führen, dass je nach Schätzung rund 85 bis 95 % der Datensätze aus unstrukturierten Daten bestehen (Gandomi &amp; Haider, 2015;Taylor, 2017). Strukturierte Daten sind meist in sogenannten relationalen Datenbank-Managementsystemen (RDBMS) aufbereitet und folgen in ihrem Aufbau vorher definierten Dateneingaben für bestimmte Kennwerte wie Geburtsdaten, Sozialversicherungsnummern und Geldwerten (Meier, 2010). Unstrukturierte Daten hingegen bestehen u. a. aus Text, Bildern, Audio-und Video-Dateien (Isson, 2018), reichen also von E-Mails hin zu Online-Nachrichtenartikeln, von Smartphone-Fotos hin zu Sport-Live-Streams und Videos von Überwachungskameras. Das führt nicht nur zu Herausforderungen mit Blick auf die Auswertungsmöglichkeiten, sondern häufig auch dazu, dass man zwar viele und immer neue Daten hat, abhängig vom Verwertungskontext oft jedoch erst einmal reflektieren muss, worüber diese Daten denn nun genau Auskunft geben können. Es muss daher auch die soziale Bedeutung von Big Data in ihrem soziotechnischen Kontext angesprochen werden, wobei sogleich auf zwei entsprechende Dimensionen einzugehen ist, die das Verständnis vom Sinn und Zweck der Sammlung von Big Data anleiten.</p>
        <p>Die sozio-technischen Dimensionen von Big Data Mayer-Schönberger und Cukier (2013) insbesondere auf diesen Zusammenhang ab: "Big data refers to things one can do at a large scale that cannot be done at a smaller one, to extract new insights or create new forms of value, in ways that change markets, organizations, the relationship between citizens and governments, and more" (S. 6, Hervorh. d. Verf.). Jegliche Beiträge, die den Schwerpunkt aus einer sozio-technischen Anwendersicht auf Big Data legen, gehen also meist davon aus, dass die Daten im Rahmen von Big Data über die zuvor beschriebenen Eigenschaften verfügen. Sie halten sich mithin selten mit definitorischen Grenzziehungen auf oder streifen diese nur kurz, um dann zu thematisieren, wie der menschliche Umgang mit den Daten charakterisiert werden kann; insbesondere welche epistemische Qualität und welchen Nutzen die Daten für ihn haben und welche Konsequenzen hieraus für Individuum und Gesellschaft erwachsen (Doll, 2014). Diese sozio-technischen Fragen lassen sich daher in den als konsequentiell-evaluativen Dimensionen Veracity und Value von Big Data verorten, die laut Ylijoki und Porras (2016) in 23 % bzw. 27 % aller von ihnen untersuchten Definitionen adressiert werden und nachfolgend besprochen werden. Dabei muss insbesondere auch die Charakterisierung der beiden Dimensionen als konsequentiell-evaluativ herausgearbeitet werden. Diese bezieht sich auf die Variabilität der Einschätzung der Ausprägung der zugrunde liegenden Dimensionen. Das bedeutet, dass es Big Data gibt, die diese Charakteristika und erwarteten Potentiale besitzen, dies jedoch nicht zwingend für alle großen digitalen Datenbestände der Fall sein muss.Die sozio-technischen Dimensionen von Big Data Mayer-Schönberger und Cukier (2013) insbesondere auf diesen Zusammenhang ab: "Big data refers to things one can do at a large scale that cannot be done at a smaller one, to extract new insights or create new forms of value, in ways that change markets, organizations, the relationship between citizens and governments, and more" (S. 6, Hervorh. d. Verf.). Jegliche Beiträge, die den Schwerpunkt aus einer sozio-technischen Anwendersicht auf Big Data legen, gehen also meist davon aus, dass die Daten im Rahmen von Big Data über die zuvor beschriebenen Eigenschaften verfügen. Sie halten sich mithin selten mit definitorischen Grenzziehungen auf oder streifen diese nur kurz, um dann zu thematisieren, wie der menschliche Umgang mit den Daten charakterisiert werden kann; insbesondere welche epistemische Qualität und welchen Nutzen die Daten für ihn haben und welche Konsequenzen hieraus für Individuum und Gesellschaft erwachsen (Doll, 2014). Diese sozio-technischen Fragen lassen sich daher in den als konsequentiell-evaluativen Dimensionen Veracity und Value von Big Data verorten, die laut Ylijoki und Porras (2016) in 23 % bzw. 27 % aller von ihnen untersuchten Definitionen adressiert werden und nachfolgend besprochen werden. Dabei muss insbesondere auch die Charakterisierung der beiden Dimensionen als konsequentiell-evaluativ herausgearbeitet werden. Diese bezieht sich auf die Variabilität der Einschätzung der Ausprägung der zugrunde liegenden Dimensionen. Das bedeutet, dass es Big Data gibt, die diese Charakteristika und erwarteten Potentiale besitzen, dies jedoch nicht zwingend für alle großen digitalen Datenbestände der Fall sein muss.</p>
        <p>Die Richtigkeit (Veracity) digitaler Daten betrifft die epistemische Qualität der Daten, bezieht sich also auf Erkenntnis und Wissen. Man kann Veracity auch mit Wahrhaftigkeit übersetzen, da jedoch nachfolgend gesondert auf die speziellen Wesensmerkmale Wahrhaftigkeit und Objektivität eingegangen wird, ist hier zunächst der Oberbegriff der Richtigkeit vorzuziehen. Dieser zielt nicht auf eine moralische Qualität ab, sondern auf den qualitativen Wirklichkeitsbezug der Daten. Die Richtigkeit betrifft mithin sowohl (1) die Informationsqualität realitätstreuer Abbildung der Daten sowie (2) das Wissen, das in den Daten steckt bzw. aus ihnen gezogen wird (Cai &amp; Zhu, 2015). Bevor also gesichertes Wissen auf Grundlage von Big Data entsteht, müssen weitere Voraussetzungen und notwendige Bedingungen bezüglich der Datenqualität erfüllt sein, die nachfolgend diskutiert werden. Für boyd und Crawford (2012) ist es nämlich insbesondere die zugesprochene Richtigkeit der digitalen Daten, die einen Mythos von Big Data nährt: "The widespread belief that large data sets offer a higher form of intelligence and knowledge that can generate insights that were previously impossible, with the aura of truth, objectivity, and accuracy" (S. 663). Hier werden bereits die zentralen Aspekte genannt, die zur Richtigkeit der Daten zählen und nachfolgend erörtert werden. Hierzu gehören die Genauigkeit sowie die Wahrhaftigkeit und Objektivität der digitalen Daten, die einen vermeintlichen Wissensgewinn erst möglich machen.Die Richtigkeit (Veracity) digitaler Daten betrifft die epistemische Qualität der Daten, bezieht sich also auf Erkenntnis und Wissen. Man kann Veracity auch mit Wahrhaftigkeit übersetzen, da jedoch nachfolgend gesondert auf die speziellen Wesensmerkmale Wahrhaftigkeit und Objektivität eingegangen wird, ist hier zunächst der Oberbegriff der Richtigkeit vorzuziehen. Dieser zielt nicht auf eine moralische Qualität ab, sondern auf den qualitativen Wirklichkeitsbezug der Daten. Die Richtigkeit betrifft mithin sowohl (1) die Informationsqualität realitätstreuer Abbildung der Daten sowie (2) das Wissen, das in den Daten steckt bzw. aus ihnen gezogen wird (Cai &amp; Zhu, 2015). Bevor also gesichertes Wissen auf Grundlage von Big Data entsteht, müssen weitere Voraussetzungen und notwendige Bedingungen bezüglich der Datenqualität erfüllt sein, die nachfolgend diskutiert werden. Für boyd und Crawford (2012) ist es nämlich insbesondere die zugesprochene Richtigkeit der digitalen Daten, die einen Mythos von Big Data nährt: "The widespread belief that large data sets offer a higher form of intelligence and knowledge that can generate insights that were previously impossible, with the aura of truth, objectivity, and accuracy" (S. 663). Hier werden bereits die zentralen Aspekte genannt, die zur Richtigkeit der Daten zählen und nachfolgend erörtert werden. Hierzu gehören die Genauigkeit sowie die Wahrhaftigkeit und Objektivität der digitalen Daten, die einen vermeintlichen Wissensgewinn erst möglich machen.</p>
        <p>Die Genauigkeit von digitalen Daten wird oft als eines ihrer zentralen Charakteristika hervorgehoben. Genauigkeit meint die Wiedergabequalität der Beschreibung von Zuständen durch Daten oder wie Cai und Zhu (2015) definieren: "Data representation (or value) well reflects the true state of the source information" (S. 5). Auch wenn in dieser Definition von Genauigkeit bereits der Wahrheitsbegriff enthalten ist und somit anscheinend vorweggenommen wird, ist er hier lediglich als Bedingung im Sinne einer Reliabilität der Daten zu verstehen. Wie mit Blick auf die nachfolgend besprochene Dimension der Wahrhaftigkeit und Objektivität zu diskutieren ist, können jedoch auch subjektive und unwahre Zustandsbeschreibungen reliabel in ein konsistentes Datenformat überführt werden. Deshalb ist zu ergänzen, dass die codierte Information dahingehend ambiguitätsfrei sein muss, als dass der Übersetzungsvorgang in das digitale Format störungsfrei vonstattengeht und zu vollständigen mangelfreien Daten führt. Eine einmal programmierte Maschine führt Befehle prinzipiell immer auf die gleiche Art und Weise aus und produziert somit zumindest in der Theorie Ergebnisse gleichbleibender Qualität. Dennoch können Datensätze trotz weitreichender Automatisierung ihrer Generierung zufällige sowie systematische Integritätsverletzungen beinhalten, unvollständig sein sowie Daten ganz unterschiedlicher Codierungsqualität und Güte beinhalten. Die Gründe für diese Fehlerhaftigkeit und hieraus resultierende Dirty Data (O'Leary, 2013) sind dabei mannigfaltig und können nicht nur technischen Ursprungs sein, sondern haben vor allem auch menschliche Ursachen, auf die sogleich eingegangen wird.Die Genauigkeit von digitalen Daten wird oft als eines ihrer zentralen Charakteristika hervorgehoben. Genauigkeit meint die Wiedergabequalität der Beschreibung von Zuständen durch Daten oder wie Cai und Zhu (2015) definieren: "Data representation (or value) well reflects the true state of the source information" (S. 5). Auch wenn in dieser Definition von Genauigkeit bereits der Wahrheitsbegriff enthalten ist und somit anscheinend vorweggenommen wird, ist er hier lediglich als Bedingung im Sinne einer Reliabilität der Daten zu verstehen. Wie mit Blick auf die nachfolgend besprochene Dimension der Wahrhaftigkeit und Objektivität zu diskutieren ist, können jedoch auch subjektive und unwahre Zustandsbeschreibungen reliabel in ein konsistentes Datenformat überführt werden. Deshalb ist zu ergänzen, dass die codierte Information dahingehend ambiguitätsfrei sein muss, als dass der Übersetzungsvorgang in das digitale Format störungsfrei vonstattengeht und zu vollständigen mangelfreien Daten führt. Eine einmal programmierte Maschine führt Befehle prinzipiell immer auf die gleiche Art und Weise aus und produziert somit zumindest in der Theorie Ergebnisse gleichbleibender Qualität. Dennoch können Datensätze trotz weitreichender Automatisierung ihrer Generierung zufällige sowie systematische Integritätsverletzungen beinhalten, unvollständig sein sowie Daten ganz unterschiedlicher Codierungsqualität und Güte beinhalten. Die Gründe für diese Fehlerhaftigkeit und hieraus resultierende Dirty Data (O'Leary, 2013) sind dabei mannigfaltig und können nicht nur technischen Ursprungs sein, sondern haben vor allem auch menschliche Ursachen, auf die sogleich eingegangen wird.</p>
        <p>Aufbauend auf der Genauigkeit der Daten, die insbesondere auf Reliabilität und hierauf fußender Belastbarkeit des technischen Übersetzungsvorgangs als Prozess abstellt, wird der Anspruch formuliert, dass die Daten als Produkt dieses Prozesses vor allem auch objektiv und wahrhaftig sind (T. M. Porter, 1996). Ihr Anspruch ist es, Merkmale und Eigenschaften von Wirklichkeit transparent zu machen (Hansen, 2015). Dabei zielen beide Begriffe auf dasselbe ab und bauen untrennbar aufeinander auf: Digitale Daten sollen in ihrer Qualität repräsentativ für eine vermeintlich tatsächliche Realität und in ihrem wahrheitsgetreuen Wirklichkeitsabbild nicht durch äußere Einflüsse verzerrt sein. Es stellt sich mithin die Frage nach der Validität der Daten; also ob diese auch tatsächlich dasjenige repräsentieren, was sie mit Blick auf ihre Bedeutungszuschreibung repräsentieren sollen (Bandalos, 2017;Sireci, 2009).Aufbauend auf der Genauigkeit der Daten, die insbesondere auf Reliabilität und hierauf fußender Belastbarkeit des technischen Übersetzungsvorgangs als Prozess abstellt, wird der Anspruch formuliert, dass die Daten als Produkt dieses Prozesses vor allem auch objektiv und wahrhaftig sind (T. M. Porter, 1996). Ihr Anspruch ist es, Merkmale und Eigenschaften von Wirklichkeit transparent zu machen (Hansen, 2015). Dabei zielen beide Begriffe auf dasselbe ab und bauen untrennbar aufeinander auf: Digitale Daten sollen in ihrer Qualität repräsentativ für eine vermeintlich tatsächliche Realität und in ihrem wahrheitsgetreuen Wirklichkeitsabbild nicht durch äußere Einflüsse verzerrt sein. Es stellt sich mithin die Frage nach der Validität der Daten; also ob diese auch tatsächlich dasjenige repräsentieren, was sie mit Blick auf ihre Bedeutungszuschreibung repräsentieren sollen (Bandalos, 2017;Sireci, 2009).</p>
        <p>Dabei werden entsprechende Verzerrungen auch als Bias bezeichnet und können vielfältiger Natur sein (R. M. Kaplan et al., 2014). Am Ende veranlasst und beeinflusst immer menschliche Entscheidung den Übersetzungs-und Produktionsprozess von digitalen Daten, weshalb die Daten womöglich nicht das wiedergeben, was sie wiedergeben sollen. So können Daten auf der einen Seite bereits mit einem Bias produziert werden, bspw. wenn Klassifikationen fehlerhaft sind, da Codierentscheidungen subjektiv geprägt sind (Bollen &amp; Paxton, 1998). Richardson, Schultz und Crawford (2019) greifen diesbezüglich auch den zuvor angesprochenen Begriff Dirty Data auf, wenn sie die in den USA verbreitete Praxis des Predictive Policing (Vorhersagende Polizeiarbeit, Pollich &amp; Bode, 2017) kritisieren. Im Rahmen dieses Beispiels wird die Problematik subjektiv verzerrter Daten deutlich, die Ansprüche an Objektivität und Wahrhaftigkeit verletzen:Dabei werden entsprechende Verzerrungen auch als Bias bezeichnet und können vielfältiger Natur sein (R. M. Kaplan et al., 2014). Am Ende veranlasst und beeinflusst immer menschliche Entscheidung den Übersetzungs-und Produktionsprozess von digitalen Daten, weshalb die Daten womöglich nicht das wiedergeben, was sie wiedergeben sollen. So können Daten auf der einen Seite bereits mit einem Bias produziert werden, bspw. wenn Klassifikationen fehlerhaft sind, da Codierentscheidungen subjektiv geprägt sind (Bollen &amp; Paxton, 1998). Richardson, Schultz und Crawford (2019) greifen diesbezüglich auch den zuvor angesprochenen Begriff Dirty Data auf, wenn sie die in den USA verbreitete Praxis des Predictive Policing (Vorhersagende Polizeiarbeit, Pollich &amp; Bode, 2017) kritisieren. Im Rahmen dieses Beispiels wird die Problematik subjektiv verzerrter Daten deutlich, die Ansprüche an Objektivität und Wahrhaftigkeit verletzen:</p>
        <p>These policing practices and policies shape the environment and the methodology by which data is created, which raises the risk of creating inaccurate, skewed, or systemically biased data ('dirty data'). If predictive policing systems are informed by such data, they cannot escape the legacies of the unlawful or biased policing practices that they are built on. (Richardson, Schultz &amp; Crawford, 2019, S. 1) Auf der anderen Seite können Daten nicht geeignet sein, die spezifischen Fragen zu klären, für deren Beantwortung sie herangezogen werden. So sind Bevölkerungsstichproben auf Grundlage sogenannter Sozialer Online-Netzwerke biased, da sie nicht repräsentativ für die Gesamtbevölkerung sind (Hargittai, 2015).These policing practices and policies shape the environment and the methodology by which data is created, which raises the risk of creating inaccurate, skewed, or systemically biased data ('dirty data'). If predictive policing systems are informed by such data, they cannot escape the legacies of the unlawful or biased policing practices that they are built on. (Richardson, Schultz &amp; Crawford, 2019, S. 1) Auf der anderen Seite können Daten nicht geeignet sein, die spezifischen Fragen zu klären, für deren Beantwortung sie herangezogen werden. So sind Bevölkerungsstichproben auf Grundlage sogenannter Sozialer Online-Netzwerke biased, da sie nicht repräsentativ für die Gesamtbevölkerung sind (Hargittai, 2015).</p>
        <p>Unabhängig davon, wie der Bias zustande gekommen ist, führen entsprechende Validitätsverletzungen und Verzerrungen der Daten dazu, dass Objektivitäts-und Wahrheitsannahmen häufig nicht haltbar sind. Objektivität und Wahrhaftigkeit sowie auch die Genauigkeit der Daten sind im Rahmen von Big Data also zunächst einmal in vielen Definitionen als Ansprüche formuliert, die jedoch wie dokumentiert nicht immer eingelöst werden bzw. einfach einzulösen sind. Es ist eben wie von boyd und Crawford (2012) angesprochen nur der Anspruch der genannten epistemischen Bedingungen, die Big Data anhaftet. Es zeigt sich allerdings, dass eine qualitative Varianz auf einem Kontinuum zwischen genau und ungenau, objektiv und nicht objektiv sowie wahr und unwahr bestehen kann. Dabei kann die Verletzung der Validität von Daten bzw. das beobachtete Ausmaß der Verzerrung nicht immer zweifelsfrei erkannt und festgestellt werden und ist mithin diskussionswürdig (Messick, 1989). Entsprechend kommt Messick (1995) auch zu dem Schluss: "Validity judgments are value judgments" (S. 748, Hervorh. im Orig.).9 Es bleibt an dieser Stelle jedoch zunächst einmal festzustellen, dass Validitätseinschätzungen bezüglich Genauigkeit, Objektivität und Wahrhaftigkeit digitaler Daten variabel sind.Unabhängig davon, wie der Bias zustande gekommen ist, führen entsprechende Validitätsverletzungen und Verzerrungen der Daten dazu, dass Objektivitäts-und Wahrheitsannahmen häufig nicht haltbar sind. Objektivität und Wahrhaftigkeit sowie auch die Genauigkeit der Daten sind im Rahmen von Big Data also zunächst einmal in vielen Definitionen als Ansprüche formuliert, die jedoch wie dokumentiert nicht immer eingelöst werden bzw. einfach einzulösen sind. Es ist eben wie von boyd und Crawford (2012) angesprochen nur der Anspruch der genannten epistemischen Bedingungen, die Big Data anhaftet. Es zeigt sich allerdings, dass eine qualitative Varianz auf einem Kontinuum zwischen genau und ungenau, objektiv und nicht objektiv sowie wahr und unwahr bestehen kann. Dabei kann die Verletzung der Validität von Daten bzw. das beobachtete Ausmaß der Verzerrung nicht immer zweifelsfrei erkannt und festgestellt werden und ist mithin diskussionswürdig (Messick, 1989). Entsprechend kommt Messick (1995) auch zu dem Schluss: "Validity judgments are value judgments" (S. 748, Hervorh. im Orig.).9 Es bleibt an dieser Stelle jedoch zunächst einmal festzustellen, dass Validitätseinschätzungen bezüglich Genauigkeit, Objektivität und Wahrhaftigkeit digitaler Daten variabel sind.</p>
        <p>Unter der Voraussetzung, dass die Bedingungen der Genauigkeit sowie Wahrhaftigkeit und Objektivität digitaler Daten zu einem hohen Grad gewährleistet sind, können digitale Daten als Abbild beobachteter Tatsachen Fakten bereitstellen, die zu neuen Erkenntnissen und einem Wissensgewinn führen (Hansen, 2015). Nachfolgend beschäftigt sich Abschnitt 4.1 daher ausführlich mit dem Wissensbegriff und der Wahrheit als zentralem Kriterium dieses Wissens. An dieser Stelle soll zunächst lediglich die Bedeutung des Wissensbegriffs im Rahmen der sozio-technischen Beschreibung von Big Data erörtert werden.Unter der Voraussetzung, dass die Bedingungen der Genauigkeit sowie Wahrhaftigkeit und Objektivität digitaler Daten zu einem hohen Grad gewährleistet sind, können digitale Daten als Abbild beobachteter Tatsachen Fakten bereitstellen, die zu neuen Erkenntnissen und einem Wissensgewinn führen (Hansen, 2015). Nachfolgend beschäftigt sich Abschnitt 4.1 daher ausführlich mit dem Wissensbegriff und der Wahrheit als zentralem Kriterium dieses Wissens. An dieser Stelle soll zunächst lediglich die Bedeutung des Wissensbegriffs im Rahmen der sozio-technischen Beschreibung von Big Data erörtert werden.</p>
        <p>Wissen auf Grundlage von Big Data ist die elementare Voraussetzung einer weitergehenden Verwertung und Nutzung dieser. Dabei soll die Datensammlung und -auswertung nicht nur neues Wissen produzieren, sie kann natürlich auch bereits bestehendes Wissen in Form digitaler Daten speichern. Die Erwartung ist jedoch darauf ausgerichtet, dass durch die binär codierten Sequenzen von Zustandsbeschreibungen Unterscheidungen getroffen werden können, aus denen Menschen (und eben auch Maschinen) Einsichten generieren und etwas lernen können (Leonelli, 2014;Mayer-Schönberger &amp; Cukier, 2013;Pentland, 2014). Gewonnene Erkenntnis über Zustände und Mechanismen beeinflusst in der Folge Anschlusshandlungen, bspw., wenn Wissen zu treffende Entscheidungen anleitet.Wissen auf Grundlage von Big Data ist die elementare Voraussetzung einer weitergehenden Verwertung und Nutzung dieser. Dabei soll die Datensammlung und -auswertung nicht nur neues Wissen produzieren, sie kann natürlich auch bereits bestehendes Wissen in Form digitaler Daten speichern. Die Erwartung ist jedoch darauf ausgerichtet, dass durch die binär codierten Sequenzen von Zustandsbeschreibungen Unterscheidungen getroffen werden können, aus denen Menschen (und eben auch Maschinen) Einsichten generieren und etwas lernen können (Leonelli, 2014;Mayer-Schönberger &amp; Cukier, 2013;Pentland, 2014). Gewonnene Erkenntnis über Zustände und Mechanismen beeinflusst in der Folge Anschlusshandlungen, bspw., wenn Wissen zu treffende Entscheidungen anleitet.</p>
        <p>Es ist zu diskutieren, inwieweit eine Verletzung der Bedingungen der Genauigkeit und Objektivität der Daten zwingend dazu führt, dass keine oder geminderte Erkenntnis aus digitalen Daten gezogen werden kann. Ausschlaggebend hierfür sind dann jedoch primär der jeweilige Grad der Verletzung und der Kontext, in dem das Wissen konkrete Konsequenzen zeitigt. Im Vergleich mit den Ergebnissen eines Temperatursensors, der auf wenige Grad Celsius die ungefähre tatsächliche Temperatur wiedergibt, sind die Daten einer stehen gebliebenen Uhr nutzlos, selbst wenn sie zweimal am Tag richtig geht. Ist die Genauigkeit des Temperatursensors jedoch entscheidend, bspw. bei der Herstellung von temperatursensiblen Produkten, dann ist eine hohe Genauigkeit dennoch zentral. Eine finale Diskussion dieser Problematik ist also nur mit Blick auf die Erfordernisse des Verwertungszusammenhangs digitaler Daten zu entscheiden und kann hier nicht abschließend getroffen werden. Wichtig ist jedoch, dass die Genauigkeit der Daten prinzipiell technisch möglich ist bzw. sein sollte und mit Blick auf die Richtigkeit der digitalen Daten definitorisch vorausgesetzt wird. Wie deutlich geworden ist, hängen die Wahrhaftigkeit sowie die Objektivität jedoch vor allem von der zu messenden Entität ab, ihrer konstruierten mentalen Konzeptionierung auf Seiten der Messenden sowie den getroffenen Operationalisierungsund Messentscheidungen im Rahmen der Überführung realweltlicher Phänomene in Daten.Es ist zu diskutieren, inwieweit eine Verletzung der Bedingungen der Genauigkeit und Objektivität der Daten zwingend dazu führt, dass keine oder geminderte Erkenntnis aus digitalen Daten gezogen werden kann. Ausschlaggebend hierfür sind dann jedoch primär der jeweilige Grad der Verletzung und der Kontext, in dem das Wissen konkrete Konsequenzen zeitigt. Im Vergleich mit den Ergebnissen eines Temperatursensors, der auf wenige Grad Celsius die ungefähre tatsächliche Temperatur wiedergibt, sind die Daten einer stehen gebliebenen Uhr nutzlos, selbst wenn sie zweimal am Tag richtig geht. Ist die Genauigkeit des Temperatursensors jedoch entscheidend, bspw. bei der Herstellung von temperatursensiblen Produkten, dann ist eine hohe Genauigkeit dennoch zentral. Eine finale Diskussion dieser Problematik ist also nur mit Blick auf die Erfordernisse des Verwertungszusammenhangs digitaler Daten zu entscheiden und kann hier nicht abschließend getroffen werden. Wichtig ist jedoch, dass die Genauigkeit der Daten prinzipiell technisch möglich ist bzw. sein sollte und mit Blick auf die Richtigkeit der digitalen Daten definitorisch vorausgesetzt wird. Wie deutlich geworden ist, hängen die Wahrhaftigkeit sowie die Objektivität jedoch vor allem von der zu messenden Entität ab, ihrer konstruierten mentalen Konzeptionierung auf Seiten der Messenden sowie den getroffenen Operationalisierungsund Messentscheidungen im Rahmen der Überführung realweltlicher Phänomene in Daten.</p>
        <p>Gerade mit Blick auf die Ubiquität digitaler Datenerzeugung und die Möglichkeiten ihrer Auswertung ist nun also diejenige Erkenntnis von Interesse, die erst aus den digitalen Daten gewonnen werden kann. Dabei ist es zunächst unerheblich, ob die Daten gezielt erzeugt werden oder ganz nebenbei anfallen. 10 Während die Qualität der Daten und der hieraus gewonnenen Erkenntnisse also durchaus auf einem Kontinuum eingeordnet werden können, soll an dieser Stelle zunächst die zentrale Bedeutung der Dimension des Wissensgewinns im Rahmen der Definition großer digitaler Datenbestände hervorgehoben werden. Eine detaillierte Diskussion der Qualität und sozialen Bedeutung dieses Wissens, insbesondere auf Grundlage von Big Data, wird nachfolgend in Kapitel 4 geleistet.Gerade mit Blick auf die Ubiquität digitaler Datenerzeugung und die Möglichkeiten ihrer Auswertung ist nun also diejenige Erkenntnis von Interesse, die erst aus den digitalen Daten gewonnen werden kann. Dabei ist es zunächst unerheblich, ob die Daten gezielt erzeugt werden oder ganz nebenbei anfallen. 10 Während die Qualität der Daten und der hieraus gewonnenen Erkenntnisse also durchaus auf einem Kontinuum eingeordnet werden können, soll an dieser Stelle zunächst die zentrale Bedeutung der Dimension des Wissensgewinns im Rahmen der Definition großer digitaler Datenbestände hervorgehoben werden. Eine detaillierte Diskussion der Qualität und sozialen Bedeutung dieses Wissens, insbesondere auf Grundlage von Big Data, wird nachfolgend in Kapitel 4 geleistet.</p>
        <p>Die Qualität der Daten aus epistemischer Perspektive, sprich ihre Erforderlichkeiten und Konsequenzen mit Blick auf mögliche Erkenntnis, hat eine zentrale Bedeutung im Entstehungs-und Verwertungskontext von Big Data (Frické, 2015;Kitchin, 2014). Während die zuvor thematisierten Wesensmerkmale eine 10 Wobei selbstredend auch eine beiläufige Datenspeicherung bewusst geschieht und die Erzeugung aktiv veranlasst werden muss. Gemeint ist hier vor allem, dass bei der Erzeugung und Speicherung noch nicht auf eine bestimmte Auswertung, die eine spezielle Frage beantworten soll, abgestellt wurde.Die Qualität der Daten aus epistemischer Perspektive, sprich ihre Erforderlichkeiten und Konsequenzen mit Blick auf mögliche Erkenntnis, hat eine zentrale Bedeutung im Entstehungs-und Verwertungskontext von Big Data (Frické, 2015;Kitchin, 2014). Während die zuvor thematisierten Wesensmerkmale eine 10 Wobei selbstredend auch eine beiläufige Datenspeicherung bewusst geschieht und die Erzeugung aktiv veranlasst werden muss. Gemeint ist hier vor allem, dass bei der Erzeugung und Speicherung noch nicht auf eine bestimmte Auswertung, die eine spezielle Frage beantworten soll, abgestellt wurde.</p>
        <p>vermeintliche Grundvoraussetzung für den Wissensgewinn sind, ist der Wissensgewinn wiederum die Vorbedingung für den aus den Daten gezogenen Nutzen und somit ein notwendiges Bindeglied zwischen Ausmaß der Datensammlung und -verwertung und den hiermit verbundenen positiven Konsequenzen für Individuum oder Gesellschaft. Der nun nachfolgend besprochene Nutzen digitaler Daten hängt maßgeblich von der Qualität und der Reichweite dieses generierten Wissens ab.vermeintliche Grundvoraussetzung für den Wissensgewinn sind, ist der Wissensgewinn wiederum die Vorbedingung für den aus den Daten gezogenen Nutzen und somit ein notwendiges Bindeglied zwischen Ausmaß der Datensammlung und -verwertung und den hiermit verbundenen positiven Konsequenzen für Individuum oder Gesellschaft. Der nun nachfolgend besprochene Nutzen digitaler Daten hängt maßgeblich von der Qualität und der Reichweite dieses generierten Wissens ab.</p>
        <p>Die Unmengen von digitalen Daten werden selbstverständlich nicht zum Selbstzweck erzeugt und gespeichert. Zwar fallen wie gezeigt viele Daten ganz nebenbei beim Betrieb von Computertechnik und Sensoren an. Die Entscheidung über Speicherung und Verarbeitung wird jedoch bewusst getroffen. Denn auch wenn Rechenkapazität und Speicherplatz über die Zeit immer preisgünstiger werden, verursachen Entstehung, Speicherung und Verarbeitung von Daten hohe Kosten mit Blick auf Speichermedien, Prozessoren, Serverinfrastruktur und den beim Betrieb anfallenden Stromverbrauch (Greenberg et al., 2008;Le et al., 2010). Diese Kosten werden nur in Kauf genommen, wenn ihnen gegenüber auch ein erwarteter Nutzen (Value) steht.Die Unmengen von digitalen Daten werden selbstverständlich nicht zum Selbstzweck erzeugt und gespeichert. Zwar fallen wie gezeigt viele Daten ganz nebenbei beim Betrieb von Computertechnik und Sensoren an. Die Entscheidung über Speicherung und Verarbeitung wird jedoch bewusst getroffen. Denn auch wenn Rechenkapazität und Speicherplatz über die Zeit immer preisgünstiger werden, verursachen Entstehung, Speicherung und Verarbeitung von Daten hohe Kosten mit Blick auf Speichermedien, Prozessoren, Serverinfrastruktur und den beim Betrieb anfallenden Stromverbrauch (Greenberg et al., 2008;Le et al., 2010). Diese Kosten werden nur in Kauf genommen, wenn ihnen gegenüber auch ein erwarteter Nutzen (Value) steht.</p>
        <p>Die Dimension des Nutzens ist nun eng mit der Wahrhaftigkeit und dem in den Daten enthaltenen Wissen verknüpft und baut unmittelbar auf ihr auf (Lupton, 2013;Sharon &amp; Zandbergen, 2016). Der aus den Daten gewonnene Nutzen stellt auf einen generierten Mehrwert ab, der auf Grundlage der Daten geschaffen wird (Mahrt &amp; Scharkow, 2013). Diese Nutzenerwartung ist dabei immer mit Bezug auf das menschliche Individuum oder die Gesellschaft und somit als explizit sozio-technische Dimension zu verstehen. Die Zweckgebundenheit von Datensammlung und -verarbeitung ist dabei an vielen Stellen in den vorhergehenden Abschnitten bereits durchgeklungen, soll an dieser Stelle jedoch noch einmal differenziert betrachtet werden. Denn Nutzen kann hier durchaus in seinem doppeldeutigen Gebrauch verstanden werden.Die Dimension des Nutzens ist nun eng mit der Wahrhaftigkeit und dem in den Daten enthaltenen Wissen verknüpft und baut unmittelbar auf ihr auf (Lupton, 2013;Sharon &amp; Zandbergen, 2016). Der aus den Daten gewonnene Nutzen stellt auf einen generierten Mehrwert ab, der auf Grundlage der Daten geschaffen wird (Mahrt &amp; Scharkow, 2013). Diese Nutzenerwartung ist dabei immer mit Bezug auf das menschliche Individuum oder die Gesellschaft und somit als explizit sozio-technische Dimension zu verstehen. Die Zweckgebundenheit von Datensammlung und -verarbeitung ist dabei an vielen Stellen in den vorhergehenden Abschnitten bereits durchgeklungen, soll an dieser Stelle jedoch noch einmal differenziert betrachtet werden. Denn Nutzen kann hier durchaus in seinem doppeldeutigen Gebrauch verstanden werden.</p>
        <p>Zum einen können Daten verwendet werden: Sie sind dann mit Blick auf ihren oft als ‚Öl des 21. Jahrhunderts' beschriebenen Charakter ein nicht-dinglicher Energieträger, der ‚genutzt' oder ‚einer Nutzung oder Verwertung zugeführt' werden kann; gleich eines Schmierstoffes, der datenverarbeitende Anwendungen am Laufen hält. Gleichzeitig entspringt mit Blick auf den Erkenntnisgewinn aus dieser Nutzung ein Nutzen im Sinne von Gewinn oder Profit, so wie auch Öl einen Marktpreis hat und als Produktionsmittel für mit Gewinnabsicht produzierte Güter und Dienstleistungen verwendet wird. Dieser Nutzen ist dann vor allem, jedoch nicht allein als Nutzen im Rahmen einer ökonomischen Verwertungslogik zu sehen (Chen et al., 2012;Mayer-Schönberger &amp; Cukier, 2013).Zum einen können Daten verwendet werden: Sie sind dann mit Blick auf ihren oft als ‚Öl des 21. Jahrhunderts' beschriebenen Charakter ein nicht-dinglicher Energieträger, der ‚genutzt' oder ‚einer Nutzung oder Verwertung zugeführt' werden kann; gleich eines Schmierstoffes, der datenverarbeitende Anwendungen am Laufen hält. Gleichzeitig entspringt mit Blick auf den Erkenntnisgewinn aus dieser Nutzung ein Nutzen im Sinne von Gewinn oder Profit, so wie auch Öl einen Marktpreis hat und als Produktionsmittel für mit Gewinnabsicht produzierte Güter und Dienstleistungen verwendet wird. Dieser Nutzen ist dann vor allem, jedoch nicht allein als Nutzen im Rahmen einer ökonomischen Verwertungslogik zu sehen (Chen et al., 2012;Mayer-Schönberger &amp; Cukier, 2013).</p>
        <p>Der Zuschnitt nur auf ökonomischen Nutzen ist hier also zu eng gefasst. Ein Nutzen kann sich ferner auch in anderen sozialen Kontexten wie Politik, Wissenschaft und Zivilgesellschaft manifestieren und ist hier vor allem mit Begriffen wie bspw. Open Data verbunden, womit kostenfreie öffentlich zugängliche Datensätze, auf die jeder frei zugreifen kann, gemeint sind und deren Nutzen vielfältigerer Natur sein kann (Mayernik, 2017;World Wide Web Foundation, 2018). Gleichwohl der konkrete Nutzen vor allem im jeweiligen Entstehungs-und Verwertungskontext betrachtet werden muss, lässt sich mit Blick auf die allgemeine gesellschaftliche Durchdringung von informationstechnischen Anwendungen der Datenverwertung insbesondere mit Blick auf deren öffentliche Thematisierung zwischen einem Nutzen unterscheiden, der sich auf einer gesellschaftlich höher-gelagerten Ebene realisiert (Weyer et al., 2018), und einem Nutzen, der sich für das Individuum ergibt (Knorre et al., 2020).Der Zuschnitt nur auf ökonomischen Nutzen ist hier also zu eng gefasst. Ein Nutzen kann sich ferner auch in anderen sozialen Kontexten wie Politik, Wissenschaft und Zivilgesellschaft manifestieren und ist hier vor allem mit Begriffen wie bspw. Open Data verbunden, womit kostenfreie öffentlich zugängliche Datensätze, auf die jeder frei zugreifen kann, gemeint sind und deren Nutzen vielfältigerer Natur sein kann (Mayernik, 2017;World Wide Web Foundation, 2018). Gleichwohl der konkrete Nutzen vor allem im jeweiligen Entstehungs-und Verwertungskontext betrachtet werden muss, lässt sich mit Blick auf die allgemeine gesellschaftliche Durchdringung von informationstechnischen Anwendungen der Datenverwertung insbesondere mit Blick auf deren öffentliche Thematisierung zwischen einem Nutzen unterscheiden, der sich auf einer gesellschaftlich höher-gelagerten Ebene realisiert (Weyer et al., 2018), und einem Nutzen, der sich für das Individuum ergibt (Knorre et al., 2020).</p>
        <p>Aus der Sicht des Individuums in der digitalen Gesellschaft sind mit Blick auf die Bewertung des großen Ausmaßes digitaler Datensammlung und -verwertung zunächst insbesondere Konsequenzen für die eigene Person relevant, da Big Data auch seine unmittelbare Lebenswelt betrifft (Knorre et al., 2020). Geht es um eine generelle Bewertung von Big Data, haben bedingt durch die Zweckgebundenheit digitaler Datensammlung und -verwertung mithin Einschätzungen zum persönlichen Nutzen einen zentralen Einfluss: Jedes Individuum trifft hier für sich im Rahmen einer laufenden Kosten-Nutzen-Kalkulation eine Abwägung (Diekmann &amp; Voß, 2004a;Kunz, 2004), ob und inwieweit es von Big Data profitiert. Das gilt zwar ganz allgemein für die weitreichende Datensammlung, wird jedoch vor allem in Situationen relevant, in denen eine Entscheidung getroffen werden muss, eigene persönliche Daten preiszugeben. Insbesondere hier stellt sich die Frage, warum Daten gesammelt und ausgewertet werden sollten: Was habe ich davon, wenn Online-Angebote umfassende Daten erheben und speichern und ich im Internet laufend der Aufzeichnung und Auswertung meiner Nutzungsdaten zustimmen muss? Warum sollte ich der Uhr an meinem Handgelenk erlauben, laufend meinen Puls zu messen? Entscheidend für diesbezüglich getroffene Entscheidungen ist, dass man sich etwas hiervon verspricht. Etwa, wenn man bei Online-Angeboten auf die eigenen Präferenzen abgestimmte Produktangebote und Vorschläge für Videos oder Musikstücke erhält, die einem gefallen könnten. Oder wenn man aus der Erhebung der eigenen Vitalparameter etwas über den eigenen Gesundheitszustand erfährt und man bspw. sieht, dass das Ausdauertraining auch tatsächlich zu einer Leistungssteigerung führt. Dabei knüpft der vermeintliche Nutzen auch und insbesondere an die zuvor beschriebene Leistungsfähigkeit der Daten hinsichtlich eines Erkenntnisgewinns an (Sharon &amp; Zandbergen, 2016):Aus der Sicht des Individuums in der digitalen Gesellschaft sind mit Blick auf die Bewertung des großen Ausmaßes digitaler Datensammlung und -verwertung zunächst insbesondere Konsequenzen für die eigene Person relevant, da Big Data auch seine unmittelbare Lebenswelt betrifft (Knorre et al., 2020). Geht es um eine generelle Bewertung von Big Data, haben bedingt durch die Zweckgebundenheit digitaler Datensammlung und -verwertung mithin Einschätzungen zum persönlichen Nutzen einen zentralen Einfluss: Jedes Individuum trifft hier für sich im Rahmen einer laufenden Kosten-Nutzen-Kalkulation eine Abwägung (Diekmann &amp; Voß, 2004a;Kunz, 2004), ob und inwieweit es von Big Data profitiert. Das gilt zwar ganz allgemein für die weitreichende Datensammlung, wird jedoch vor allem in Situationen relevant, in denen eine Entscheidung getroffen werden muss, eigene persönliche Daten preiszugeben. Insbesondere hier stellt sich die Frage, warum Daten gesammelt und ausgewertet werden sollten: Was habe ich davon, wenn Online-Angebote umfassende Daten erheben und speichern und ich im Internet laufend der Aufzeichnung und Auswertung meiner Nutzungsdaten zustimmen muss? Warum sollte ich der Uhr an meinem Handgelenk erlauben, laufend meinen Puls zu messen? Entscheidend für diesbezüglich getroffene Entscheidungen ist, dass man sich etwas hiervon verspricht. Etwa, wenn man bei Online-Angeboten auf die eigenen Präferenzen abgestimmte Produktangebote und Vorschläge für Videos oder Musikstücke erhält, die einem gefallen könnten. Oder wenn man aus der Erhebung der eigenen Vitalparameter etwas über den eigenen Gesundheitszustand erfährt und man bspw. sieht, dass das Ausdauertraining auch tatsächlich zu einer Leistungssteigerung führt. Dabei knüpft der vermeintliche Nutzen auch und insbesondere an die zuvor beschriebene Leistungsfähigkeit der Daten hinsichtlich eines Erkenntnisgewinns an (Sharon &amp; Zandbergen, 2016):</p>
        <p>Where the question of the value of data for those who generate it is addressed, this value is typically understood as residing in the aura of neutrality and objectivity that numbers convey, and their role in a will to (quantified) truth. (S. 1696, Hervorh. im Orig.)Where the question of the value of data for those who generate it is addressed, this value is typically understood as residing in the aura of neutrality and objectivity that numbers convey, and their role in a will to (quantified) truth. (S. 1696, Hervorh. im Orig.)</p>
        <p>Der Abwägungsprozess bezüglich des Ausmaßes individuellen Nutzens speist sich dabei im Rahmen der Kosten-Nutzen-Kalkulation aus diversen Nutzenerfahrungen und -erwartungen, die sich aus den unterschiedlich gelagerten Verwertungskontexten digitaler Daten ergeben können. Dies ist etwa der Fall, wenn es Sicherheitsbedenken bei der Preisgabe persönlicher Daten im Rahmen von digitaler Mediennutzung gibt, deren Zusammenhang in der Privacy-Forschung untersucht wird (Dienlin &amp; Metzger, 2016;Dinev &amp; Hart, 2006).Der Abwägungsprozess bezüglich des Ausmaßes individuellen Nutzens speist sich dabei im Rahmen der Kosten-Nutzen-Kalkulation aus diversen Nutzenerfahrungen und -erwartungen, die sich aus den unterschiedlich gelagerten Verwertungskontexten digitaler Daten ergeben können. Dies ist etwa der Fall, wenn es Sicherheitsbedenken bei der Preisgabe persönlicher Daten im Rahmen von digitaler Mediennutzung gibt, deren Zusammenhang in der Privacy-Forschung untersucht wird (Dienlin &amp; Metzger, 2016;Dinev &amp; Hart, 2006).</p>
        <p>Jenseits eines individuell realisierten Nutzens durch Big Data werden durchaus auch Erwartungen formuliert, die darauf abzielen, wie Big Data für die Gesellschaft von Nutzen sein können und sollen (Houben &amp; Prietl, 2018;Kolany-Raiser et al., 2018;Mayer-Schönberger &amp; Cukier, 2013). Big Data müssen hierbei fernab jedes Technikoptimismus oder -pessimismus zunächst einmal als ein Werkzeug betrachtet werden, das sowohl Schäden verursachen oder Nutzen bringen kann. So können Schäden, die aus einer weitreichenden Datensammlung von Gesundheitsdaten entstehen, etwa wenn diese Daten in falsche Hände geraten, den individuellen und vor allem auch gesellschaftlichen Vorteilen gegenübergestellt werden. Es ist positiv zu bewerten, sollten aus der zentralen Speicherung und Auswertung von Daten zu Krankheiten und deren Behandlung neue Therapiemöglichkeiten entstehen, von denen ich und viele andere profitieren, weil sich Gesundheit verbessert und sich Kosten vermeiden lassen.Jenseits eines individuell realisierten Nutzens durch Big Data werden durchaus auch Erwartungen formuliert, die darauf abzielen, wie Big Data für die Gesellschaft von Nutzen sein können und sollen (Houben &amp; Prietl, 2018;Kolany-Raiser et al., 2018;Mayer-Schönberger &amp; Cukier, 2013). Big Data müssen hierbei fernab jedes Technikoptimismus oder -pessimismus zunächst einmal als ein Werkzeug betrachtet werden, das sowohl Schäden verursachen oder Nutzen bringen kann. So können Schäden, die aus einer weitreichenden Datensammlung von Gesundheitsdaten entstehen, etwa wenn diese Daten in falsche Hände geraten, den individuellen und vor allem auch gesellschaftlichen Vorteilen gegenübergestellt werden. Es ist positiv zu bewerten, sollten aus der zentralen Speicherung und Auswertung von Daten zu Krankheiten und deren Behandlung neue Therapiemöglichkeiten entstehen, von denen ich und viele andere profitieren, weil sich Gesundheit verbessert und sich Kosten vermeiden lassen.</p>
        <p>Natürlich muss ein Nutzen, der nicht vom Individuum realisiert wird, nicht auch automatisch auf gesamtgesellschaftlicher Ebene eintreten. Zwischen der Mikro-und der Makro-Ebene gibt es unzählige weitere mögliche Profiteure mit individuellen Sonderinteressen, die sich auf der Meso-Ebene ansiedeln lassen. Die Nutzenerwartung an die großen digitalen Datenbestände kann hier wie folgt beschrieben werden:Natürlich muss ein Nutzen, der nicht vom Individuum realisiert wird, nicht auch automatisch auf gesamtgesellschaftlicher Ebene eintreten. Zwischen der Mikro-und der Makro-Ebene gibt es unzählige weitere mögliche Profiteure mit individuellen Sonderinteressen, die sich auf der Meso-Ebene ansiedeln lassen. Die Nutzenerwartung an die großen digitalen Datenbestände kann hier wie folgt beschrieben werden:</p>
        <p>Right now big data is enabling organizations to move away from intuitive-to databased decision making. Ultimately, enterprises will use big data because it creates value by solving new problems, as well as solving existing problems faster or cheaper, or providing a better and richer understanding of those problems. (O'Leary, 2013, S. 99) Zu den angesprochenen Organisationen gehören bspw. Hacker sowie Datenaktivist*innen (Cardullo, 2015;Schrock, 2016) oder gleich ganze gesellschaftliche Felder wie die Forschung (Aitken et al., 2018;Mahrt &amp; Scharkow, 2013), der Journalismus (C. W. Anderson, 2013;Coddington, 2015;Lewis, 2015), die Wirtschaft sowie staatliche Institutionen (Andrejevic &amp; Gates, 2014;Lyon, 2014). Doch selbst wenn diese einzelnen Gruppen und Einheiten partikulare Interessen verfolgen, so sind sie gesellschaftlichen (Teil-)Systemen zuzuordnen, die innerhalb der Gesellschaft wichtige Funktionen übernehmen und gesellschaftlichen Wandel bewirken und hier etwaigen Nutzen für die Gesellschaft erbringen oder auch nicht. 11Für eine übergeordnete gesellschaftliche Wahrnehmung von digitalen Daten kann an dieser Stelle daher mit Blick auf Nutzenerwartungen nicht kleinteilig unterschieden werden. Es mag je nach individueller Bewertung und eigenem Vorwissen und Erfahrung auf unzählige einzelne Bereiche abgestellt werden, in denen Nutzen durch Big Data gesehen wird oder eben auch nicht. Darüber hinaus sollte es jedoch zu einer allgemeinen Gesamtbewertung beim beobachtenden Individuum kommen, die auf einer Einschätzung zum Nutzen von Big Data für die Gesamtgesellschaft beruht, deren Teil man ist. In Abhängigkeit von vielen individuell zu treffenden Einschätzungen wird der generelle Nutzen von Big Data sowohl für das Selbst als auch für die Gesellschaft bewertet. Unbenommen möglicher noch feinteilig differenzierter Zwischenstufen der Nutzeneinschätzung, die jedoch theoretisch und empirisch erst einmal zu beschreiben wären. Es ist zunächst zu prüfen, inwieweit sich individuelle und gesellschaftliche Nutzenüberzeugungen analysieren lassen. Dies lässt dann immerhin auch die Möglichkeit zu, zu untersuchen, ob beide Einschätzungen zusammen-oder auseinanderfallen, was mit Blick auf die Abwägung von Schadens-und Nutzenbewertung eine relevante Frage ist.Right now big data is enabling organizations to move away from intuitive-to databased decision making. Ultimately, enterprises will use big data because it creates value by solving new problems, as well as solving existing problems faster or cheaper, or providing a better and richer understanding of those problems. (O'Leary, 2013, S. 99) Zu den angesprochenen Organisationen gehören bspw. Hacker sowie Datenaktivist*innen (Cardullo, 2015;Schrock, 2016) oder gleich ganze gesellschaftliche Felder wie die Forschung (Aitken et al., 2018;Mahrt &amp; Scharkow, 2013), der Journalismus (C. W. Anderson, 2013;Coddington, 2015;Lewis, 2015), die Wirtschaft sowie staatliche Institutionen (Andrejevic &amp; Gates, 2014;Lyon, 2014). Doch selbst wenn diese einzelnen Gruppen und Einheiten partikulare Interessen verfolgen, so sind sie gesellschaftlichen (Teil-)Systemen zuzuordnen, die innerhalb der Gesellschaft wichtige Funktionen übernehmen und gesellschaftlichen Wandel bewirken und hier etwaigen Nutzen für die Gesellschaft erbringen oder auch nicht. 11Für eine übergeordnete gesellschaftliche Wahrnehmung von digitalen Daten kann an dieser Stelle daher mit Blick auf Nutzenerwartungen nicht kleinteilig unterschieden werden. Es mag je nach individueller Bewertung und eigenem Vorwissen und Erfahrung auf unzählige einzelne Bereiche abgestellt werden, in denen Nutzen durch Big Data gesehen wird oder eben auch nicht. Darüber hinaus sollte es jedoch zu einer allgemeinen Gesamtbewertung beim beobachtenden Individuum kommen, die auf einer Einschätzung zum Nutzen von Big Data für die Gesamtgesellschaft beruht, deren Teil man ist. In Abhängigkeit von vielen individuell zu treffenden Einschätzungen wird der generelle Nutzen von Big Data sowohl für das Selbst als auch für die Gesellschaft bewertet. Unbenommen möglicher noch feinteilig differenzierter Zwischenstufen der Nutzeneinschätzung, die jedoch theoretisch und empirisch erst einmal zu beschreiben wären. Es ist zunächst zu prüfen, inwieweit sich individuelle und gesellschaftliche Nutzenüberzeugungen analysieren lassen. Dies lässt dann immerhin auch die Möglichkeit zu, zu untersuchen, ob beide Einschätzungen zusammen-oder auseinanderfallen, was mit Blick auf die Abwägung von Schadens-und Nutzenbewertung eine relevante Frage ist.</p>
        <p>An dieser Stelle muss nun zudem kurz auf technische Anwendungskontexte im Zusammenhang mit den großen digitalen Datenmengen abgestellt werden, um deutlich zu machen, wie Big Data sich zu unmittelbar angrenzenden Techniken wie Algorithmen oder Anwendungen Künstlicher Intelligenz (KI) verhalten, die Datenverarbeitung und -auswertung in den vorliegenden Ausmaßen erst ermöglichen.An dieser Stelle muss nun zudem kurz auf technische Anwendungskontexte im Zusammenhang mit den großen digitalen Datenmengen abgestellt werden, um deutlich zu machen, wie Big Data sich zu unmittelbar angrenzenden Techniken wie Algorithmen oder Anwendungen Künstlicher Intelligenz (KI) verhalten, die Datenverarbeitung und -auswertung in den vorliegenden Ausmaßen erst ermöglichen.</p>
        <p>Algorithmen sind hier das Bindeglied zwischen der Hardware und den digitalen Daten, denn "elektronische Datenverarbeitung beruht auf Algorithmen" (Cormen et al., 2017, S. XIII). Ein Algorithmus definiert sich nach Kraemer et al. (2011) wie folgt: "An algorithm is, roughly speaking, a finite sequence of well-defined instructions that describe in sufficiently great detail how to solve a problem" (S. 251). Die Computerhardware wird nicht zuletzt auch Rechner genannt, aufgrund der programmiersprachlichen Formulierung von Algorithmen als Entscheidungsregeln, die häufig in Gestalt von mathematischen Formeln festgelegt sind. Die digitalen Daten werden den Algorithmen als Eingabe zugeführt oder entstehen als Ausgabe algorithmischer Verarbeitung (Cormen et al., 2017). Dabei ist das besondere an den Algorithmen, dass sie wie die IuK fortlaufend eingesetzt werden können. Als einprogrammiertes System von Rechenvorschriften können Rechenprobleme nun mit Hilfe von IuK automatisiert gelöst werden. Dabei stehen die Algorithmen nicht nur in einem Verwertungszusammenhang mit digitalen Daten, auch mit ihnen verbundene Problematiken erinnern an die zuvor aufgeworfenen Schwierigkeiten menschlicher Fehlbarkeit und subjektiver Einflüsse im Rahmen ihres Einsatzes:Algorithmen sind hier das Bindeglied zwischen der Hardware und den digitalen Daten, denn "elektronische Datenverarbeitung beruht auf Algorithmen" (Cormen et al., 2017, S. XIII). Ein Algorithmus definiert sich nach Kraemer et al. (2011) wie folgt: "An algorithm is, roughly speaking, a finite sequence of well-defined instructions that describe in sufficiently great detail how to solve a problem" (S. 251). Die Computerhardware wird nicht zuletzt auch Rechner genannt, aufgrund der programmiersprachlichen Formulierung von Algorithmen als Entscheidungsregeln, die häufig in Gestalt von mathematischen Formeln festgelegt sind. Die digitalen Daten werden den Algorithmen als Eingabe zugeführt oder entstehen als Ausgabe algorithmischer Verarbeitung (Cormen et al., 2017). Dabei ist das besondere an den Algorithmen, dass sie wie die IuK fortlaufend eingesetzt werden können. Als einprogrammiertes System von Rechenvorschriften können Rechenprobleme nun mit Hilfe von IuK automatisiert gelöst werden. Dabei stehen die Algorithmen nicht nur in einem Verwertungszusammenhang mit digitalen Daten, auch mit ihnen verbundene Problematiken erinnern an die zuvor aufgeworfenen Schwierigkeiten menschlicher Fehlbarkeit und subjektiver Einflüsse im Rahmen ihres Einsatzes:</p>
        <p>Zwar genießen Algorithmen oftmals den Nimbus der Objektivität, weil sie unpersönlich sind und quantitative Daten verarbeiten, doch diese kalkulativen Praktiken selbst sind keineswegs neutrale Verdatungsformen des Sozialen. Algorithmen stehen in einem unauflöslichen Zusammenhang mit sozialen Formen der Zuschreibung von Wertigkeit, und in diesem Sinne produzieren und repräsentieren sie das, was für relevant oder wertvoll gehalten werden soll. (Mau, 2017, S. 204-205) Algorithmen werden folglich dort für das Wahrnehmungsmuster digitaler Daten relevant, wo sie die in den Daten verbundenen Problemlagen noch verschärfen oder gar dazu eingesetzt werden sollen, einmal identifizierte Probleme abzumildern oder gar zu beseitigen. Wenn in den Daten Verzerrungen oder Ungenauigkeiten vorliegen, ihr Wirklichkeitsabbild fraglich ist oder aber, wenn eine andere Gewichtung der Daten gewünscht ist, dann sollen die Rechenvorschriften der Algorithmen zur Datenverarbeitung eben angepasst werden. Ihr Verhältnis zu den digitalen Datenbeständen ist somit an dieser Stelle verdeutlicht. Es wird jedoch im vorliegenden Forschungszusammenhang zwecks begrifflicher Klarheit und der vorrangigen Fokussierung auf ganz allgemeine Datensammlung undverwertung nicht weiter ausgeführt und explizit unter dem Label Algorithmus angesprochen. Weiterhin sind Algorithmen jedoch auch unverzichtbarer Teil des Entstehungs-und Verwertungszusammenhangs digitaler Daten, wenn es um den Fall von Anwendungen der KI geht, bei denen die Folgen von Rechenvorschriften eine elementare Rolle spielen. Auch hier soll nicht mit dem eher allgemeinen Begriff Algorithmus operiert werden, sondern auf die wesentlichen Charakteristika der KI abgestellt werden, die nachfolgend erläutert und zu Big Data in Beziehung gesetzt werden.Zwar genießen Algorithmen oftmals den Nimbus der Objektivität, weil sie unpersönlich sind und quantitative Daten verarbeiten, doch diese kalkulativen Praktiken selbst sind keineswegs neutrale Verdatungsformen des Sozialen. Algorithmen stehen in einem unauflöslichen Zusammenhang mit sozialen Formen der Zuschreibung von Wertigkeit, und in diesem Sinne produzieren und repräsentieren sie das, was für relevant oder wertvoll gehalten werden soll. (Mau, 2017, S. 204-205) Algorithmen werden folglich dort für das Wahrnehmungsmuster digitaler Daten relevant, wo sie die in den Daten verbundenen Problemlagen noch verschärfen oder gar dazu eingesetzt werden sollen, einmal identifizierte Probleme abzumildern oder gar zu beseitigen. Wenn in den Daten Verzerrungen oder Ungenauigkeiten vorliegen, ihr Wirklichkeitsabbild fraglich ist oder aber, wenn eine andere Gewichtung der Daten gewünscht ist, dann sollen die Rechenvorschriften der Algorithmen zur Datenverarbeitung eben angepasst werden. Ihr Verhältnis zu den digitalen Datenbeständen ist somit an dieser Stelle verdeutlicht. Es wird jedoch im vorliegenden Forschungszusammenhang zwecks begrifflicher Klarheit und der vorrangigen Fokussierung auf ganz allgemeine Datensammlung undverwertung nicht weiter ausgeführt und explizit unter dem Label Algorithmus angesprochen. Weiterhin sind Algorithmen jedoch auch unverzichtbarer Teil des Entstehungs-und Verwertungszusammenhangs digitaler Daten, wenn es um den Fall von Anwendungen der KI geht, bei denen die Folgen von Rechenvorschriften eine elementare Rolle spielen. Auch hier soll nicht mit dem eher allgemeinen Begriff Algorithmus operiert werden, sondern auf die wesentlichen Charakteristika der KI abgestellt werden, die nachfolgend erläutert und zu Big Data in Beziehung gesetzt werden.</p>
        <p>Im Rahmen der Diskussion um die Digitalisierung der Gesellschaft erfährt derzeit auch der Begriff der KI wieder eine Renaissance (Bostrom, 2016;Cath et al., 2018;Wittpahl, 2019). Ein Phänomen, das nach heutigem Stand in seinen zentralen Anwendungen wie Machine Learning (ML) vor allem auf die Verfügbarkeit der großen digitalen Datenbestände angewiesen und daher unmittelbar mit Big Data verbunden ist (Mayer-Schönberger &amp; Cukier, 2013). Beginnend mit der Darthmouth Conference im Jahr 1956 wurde an der Entwicklung von Computersystemen gearbeitet, die intelligente Eigenschaften besitzen (Rid, 2017). Obwohl es keine allgemeingültige Begriffsbestimmung, sondern viele unterschiedliche Definitionen von ‚natürlicher' Intelligenz gibt, wie sie bei Mensch und Tier zu beobachten ist (Legg &amp; Hutter, 2007), entstehen derzeit weltweit Forschungsprogramme, die besagte KI entwickeln und ihren gesellschaftlichen Einsatz vorantreiben. So stellte auch die Bundesregierung Deutschlands im Sommer 2018 Eckpunkte für eine zu entwickelnde nationale KI-Strategie vor (Bundesregierung Deutschland, 2018b), die im November 2018 verabschiedet und der Öffentlichkeit präsentiert wurde (Bundesregierung Deutschland, 2018a).Im Rahmen der Diskussion um die Digitalisierung der Gesellschaft erfährt derzeit auch der Begriff der KI wieder eine Renaissance (Bostrom, 2016;Cath et al., 2018;Wittpahl, 2019). Ein Phänomen, das nach heutigem Stand in seinen zentralen Anwendungen wie Machine Learning (ML) vor allem auf die Verfügbarkeit der großen digitalen Datenbestände angewiesen und daher unmittelbar mit Big Data verbunden ist (Mayer-Schönberger &amp; Cukier, 2013). Beginnend mit der Darthmouth Conference im Jahr 1956 wurde an der Entwicklung von Computersystemen gearbeitet, die intelligente Eigenschaften besitzen (Rid, 2017). Obwohl es keine allgemeingültige Begriffsbestimmung, sondern viele unterschiedliche Definitionen von ‚natürlicher' Intelligenz gibt, wie sie bei Mensch und Tier zu beobachten ist (Legg &amp; Hutter, 2007), entstehen derzeit weltweit Forschungsprogramme, die besagte KI entwickeln und ihren gesellschaftlichen Einsatz vorantreiben. So stellte auch die Bundesregierung Deutschlands im Sommer 2018 Eckpunkte für eine zu entwickelnde nationale KI-Strategie vor (Bundesregierung Deutschland, 2018b), die im November 2018 verabschiedet und der Öffentlichkeit präsentiert wurde (Bundesregierung Deutschland, 2018a).</p>
        <p>Ganz allgemein stellt KI darauf ab, dass Maschinen intelligente Fähigkeiten demonstrieren, die man sonst nur im Rahmen natürlicher Intelligenz bei Menschen beobachtet und die sich u. a. in mathematischem, sprachlichem oder räumlichem Denken, Merkfähigkeit, Wahrnehmung, Auffassungsgabe und Verarbeitungsgeschwindigkeit äußern (Bostrom, 2016;Finlay, 2017;J. Kaplan, 2016). Dabei ist der Begriff KI dahingehend zunächst einmal irreführend, da er falsche Vorstellungen davon vermittelt, welche konkreten Anwendungen sich unter dem allgemein gehaltenen Label derzeit versammeln. Häufig geht es bei KI um Computerprogramme des maschinellen Lernens, die mit Hilfe von Algorithmen Muster in den großen digitalen Datenbeständen erkennen sowie Objekte und Personen identifizieren und zuordnen (Alpaydin, 2016).Ganz allgemein stellt KI darauf ab, dass Maschinen intelligente Fähigkeiten demonstrieren, die man sonst nur im Rahmen natürlicher Intelligenz bei Menschen beobachtet und die sich u. a. in mathematischem, sprachlichem oder räumlichem Denken, Merkfähigkeit, Wahrnehmung, Auffassungsgabe und Verarbeitungsgeschwindigkeit äußern (Bostrom, 2016;Finlay, 2017;J. Kaplan, 2016). Dabei ist der Begriff KI dahingehend zunächst einmal irreführend, da er falsche Vorstellungen davon vermittelt, welche konkreten Anwendungen sich unter dem allgemein gehaltenen Label derzeit versammeln. Häufig geht es bei KI um Computerprogramme des maschinellen Lernens, die mit Hilfe von Algorithmen Muster in den großen digitalen Datenbeständen erkennen sowie Objekte und Personen identifizieren und zuordnen (Alpaydin, 2016).</p>
        <p>Nicht nur, dass viele KI-Systeme und insbesondere ML-Anwendungen auf Big Data angewiesen sind, um zu lernen, die Mustererkennung und Vorhersagen zu verbessern. KI kann potentiell auch dafür eingesetzt werden, die anfallenden Datenbestände zu be-und verarbeiten. So führt O'Leary (2013) aus, dass KI mit Blick auf die Entstehungsgeschwindigkeit der digitalen Daten schnellere und umfassendere Entscheidungen treffen kann als der Mensch, und führt als Beispiel den Einsatz von High-Frequency-Tradingsystemen an der Börse an. Hier werden unzählige laufend eingehende Informationen in Sekundenbruchteilen von Computerprogrammen gesichtet und bewertet, um Kauf-oder Verkaufsentscheidungen zu treffen. Laut Glantz und Kissell (2014, S. 258) entfällt mittlerweile der Großteil der börslichen Handelsaktivität (85 % im Jahr 2012) auf die unter dem Stichwort Algorithmic Trading zusammengefassten Computersysteme, von denen etliche KI-basiert sind (Martinsky, 2010;Slade, 2018). 12Insbesondere aufgrund der angeführten Unstrukturiertheit vieler großer Datenbestände verbinden sich mit KI Hoffnungen auf einen vereinfachten Umgang mit den angesprochenen Herausforderungen bei der Verarbeitung und Auswertung von Big Data. Da maschinelles Lernen in der Lage ist, große Datenmengen verhältnismäßig schnell und zuverlässig zu verarbeiten und hierin Muster zu erkennen, erlauben diese Programme einen vermeintlich einfacheren Zugang zu großen unstrukturierten Datensätzen (O'Leary, 2013).Nicht nur, dass viele KI-Systeme und insbesondere ML-Anwendungen auf Big Data angewiesen sind, um zu lernen, die Mustererkennung und Vorhersagen zu verbessern. KI kann potentiell auch dafür eingesetzt werden, die anfallenden Datenbestände zu be-und verarbeiten. So führt O'Leary (2013) aus, dass KI mit Blick auf die Entstehungsgeschwindigkeit der digitalen Daten schnellere und umfassendere Entscheidungen treffen kann als der Mensch, und führt als Beispiel den Einsatz von High-Frequency-Tradingsystemen an der Börse an. Hier werden unzählige laufend eingehende Informationen in Sekundenbruchteilen von Computerprogrammen gesichtet und bewertet, um Kauf-oder Verkaufsentscheidungen zu treffen. Laut Glantz und Kissell (2014, S. 258) entfällt mittlerweile der Großteil der börslichen Handelsaktivität (85 % im Jahr 2012) auf die unter dem Stichwort Algorithmic Trading zusammengefassten Computersysteme, von denen etliche KI-basiert sind (Martinsky, 2010;Slade, 2018). 12Insbesondere aufgrund der angeführten Unstrukturiertheit vieler großer Datenbestände verbinden sich mit KI Hoffnungen auf einen vereinfachten Umgang mit den angesprochenen Herausforderungen bei der Verarbeitung und Auswertung von Big Data. Da maschinelles Lernen in der Lage ist, große Datenmengen verhältnismäßig schnell und zuverlässig zu verarbeiten und hierin Muster zu erkennen, erlauben diese Programme einen vermeintlich einfacheren Zugang zu großen unstrukturierten Datensätzen (O'Leary, 2013).</p>
        <p>Die Mustererkennung ist hier vor allem im Zusammenhang mit dem nachfolgend zu besprechenden Wissen zu bewerten. Erst durch Big-Data-Analytics ergibt sich ein Erkenntnisgewinn aus den zunächst einmal unzugänglichen und somit wertlosen Daten (Barlow, 2013). Denn ohne diese maschinelle Hilfe könnte kein Mensch die großen digitalen Datenbestände bearbeiten und ein Verständnis hieraus gewinnen, weshalb sich insbesondere Fragen nach dem vermeintlichen Erkenntnisgewinn und einem hieraus gezogenen Nutzen der Analyse von Big Data durch KI ergeben.Die Mustererkennung ist hier vor allem im Zusammenhang mit dem nachfolgend zu besprechenden Wissen zu bewerten. Erst durch Big-Data-Analytics ergibt sich ein Erkenntnisgewinn aus den zunächst einmal unzugänglichen und somit wertlosen Daten (Barlow, 2013). Denn ohne diese maschinelle Hilfe könnte kein Mensch die großen digitalen Datenbestände bearbeiten und ein Verständnis hieraus gewinnen, weshalb sich insbesondere Fragen nach dem vermeintlichen Erkenntnisgewinn und einem hieraus gezogenen Nutzen der Analyse von Big Data durch KI ergeben.</p>
        <p>Aus den beispielhaften Ausführungen wird deutlich, dass öffentliche Erwartungen bestehen, in deren Rahmen sich Big Data und Musterkennung gegenseitig befruchten und gemeinsam gewinnbringend genutzt werden können. So ist es für Katz (2017) nicht überraschend, dass das erneute Aufblühen der an KI gerichteten Erwartungen eng mit dem Aufkommen von Big Data im Rahmen einer ökonomischen Verwertungslogik verbunden ist und von den Unternehmen aktiv befördert wird:Aus den beispielhaften Ausführungen wird deutlich, dass öffentliche Erwartungen bestehen, in deren Rahmen sich Big Data und Musterkennung gegenseitig befruchten und gemeinsam gewinnbringend genutzt werden können. So ist es für Katz (2017) nicht überraschend, dass das erneute Aufblühen der an KI gerichteten Erwartungen eng mit dem Aufkommen von Big Data im Rahmen einer ökonomischen Verwertungslogik verbunden ist und von den Unternehmen aktiv befördert wird:</p>
        <p>Corporations have helped manufacture an 'AI revolution' in which AI stands for a confused mix of terms-such as 'big data,' 'machine learning,' or 'deep learning'whose common denominator is the use of expensive computing power to analyze massive centralized data. (S. 2) Eine Befragung von Kersting und Meyer (2018) unter KI-Forschern aus Wissenschaft und Industrie kommt zwar zu dem Ergebnis, dass KI und Big Data miteinander in Bezug stehen, dass sie jedoch zumindest von Expertenseite auf keinen Falls als deckungsgleich oder miteinander konvergierend erachtet werden. Ihre Verbindung wird jedoch auch hier dadurch deutlich, dass die KI und hier genauer die angesprochenen ML-Anwendungen als eine Zugangsmöglichkeit zu den Daten, vor dem Hintergrund der technischen Herausforderungen ihres Entstehungs-, insbesondere jedoch ihres Verwertungskontextes, gesehen werden. KI ist weithin auch als eine "Methode der Erkenntnisgewinnung" (Mohabbat Kar &amp; Parycek, 2018, S. 9) zu betrachten, die auf digitale Daten zurückgreift, Muster in ihnen erkennt und so das aus ihnen destillierbare Wissen zugänglich macht. Folglich werden unlängst immer mehr Innovationen aus dem Feld der KI für die Verwendung in den unterschiedlichsten Gesellschaftsbereichen angedacht oder bereits eingeführt. Daher stellt auch der letztendliche Forschungszusammenhang zu einem Glauben an Big Data nachfolgend vor allem auf den Einsatz von datenverarbeitenden KI-Anwendungen ab (siehe Kapitel 7). Insbesondere mit Blick auf die zuvor angesprochenen Verheißungen von Erkenntnis-und Nutzengewinnen erfährt Big Data in Verbindung mit KI-Anwendungen derzeit also eine hohe gesellschaftliche Aufmerksamkeit. Wichtig ist hier also der Bezug zwischen digitalen Daten und Wissen sowie dessen Bedeutung im Zusammenhang mit der gesellschaftlichen Ordnung und Verwertung von Wissen, der nun nachfolgend genauer herausgearbeitet wird. Wie erörtert, sollen Daten die Wirklichkeit nicht nur vermeintlich objektiv, realitätsgetreu und folglich wahrheitsgemäß abbilden, sondern auf den Daten basierende Einsichten sollen und werden im Rahmen einer vorrangig ökonomischen Verwertungslogik in der postindustriellen Gesellschaft genutzt.1 Die besondere Bedeutung der Erzeugung, Verteilung und Verwertung von Wissen auf Datengrundlage spielt dabei auch direkt auf Vorstellungen an, die mit dem Konzept der Wissensgesellschaft verbunden sind und in den vergangenen Jahrzehnten vielfach in der Öffentlichkeit diskutiert wurden (Kübler, 2009).Corporations have helped manufacture an 'AI revolution' in which AI stands for a confused mix of terms-such as 'big data,' 'machine learning,' or 'deep learning'whose common denominator is the use of expensive computing power to analyze massive centralized data. (S. 2) Eine Befragung von Kersting und Meyer (2018) unter KI-Forschern aus Wissenschaft und Industrie kommt zwar zu dem Ergebnis, dass KI und Big Data miteinander in Bezug stehen, dass sie jedoch zumindest von Expertenseite auf keinen Falls als deckungsgleich oder miteinander konvergierend erachtet werden. Ihre Verbindung wird jedoch auch hier dadurch deutlich, dass die KI und hier genauer die angesprochenen ML-Anwendungen als eine Zugangsmöglichkeit zu den Daten, vor dem Hintergrund der technischen Herausforderungen ihres Entstehungs-, insbesondere jedoch ihres Verwertungskontextes, gesehen werden. KI ist weithin auch als eine "Methode der Erkenntnisgewinnung" (Mohabbat Kar &amp; Parycek, 2018, S. 9) zu betrachten, die auf digitale Daten zurückgreift, Muster in ihnen erkennt und so das aus ihnen destillierbare Wissen zugänglich macht. Folglich werden unlängst immer mehr Innovationen aus dem Feld der KI für die Verwendung in den unterschiedlichsten Gesellschaftsbereichen angedacht oder bereits eingeführt. Daher stellt auch der letztendliche Forschungszusammenhang zu einem Glauben an Big Data nachfolgend vor allem auf den Einsatz von datenverarbeitenden KI-Anwendungen ab (siehe Kapitel 7). Insbesondere mit Blick auf die zuvor angesprochenen Verheißungen von Erkenntnis-und Nutzengewinnen erfährt Big Data in Verbindung mit KI-Anwendungen derzeit also eine hohe gesellschaftliche Aufmerksamkeit. Wichtig ist hier also der Bezug zwischen digitalen Daten und Wissen sowie dessen Bedeutung im Zusammenhang mit der gesellschaftlichen Ordnung und Verwertung von Wissen, der nun nachfolgend genauer herausgearbeitet wird. Wie erörtert, sollen Daten die Wirklichkeit nicht nur vermeintlich objektiv, realitätsgetreu und folglich wahrheitsgemäß abbilden, sondern auf den Daten basierende Einsichten sollen und werden im Rahmen einer vorrangig ökonomischen Verwertungslogik in der postindustriellen Gesellschaft genutzt.1 Die besondere Bedeutung der Erzeugung, Verteilung und Verwertung von Wissen auf Datengrundlage spielt dabei auch direkt auf Vorstellungen an, die mit dem Konzept der Wissensgesellschaft verbunden sind und in den vergangenen Jahrzehnten vielfach in der Öffentlichkeit diskutiert wurden (Kübler, 2009).</p>
        <p>Im Zuge des technischen Fortschritts entstand ein neues Verständnis der Wesensmerkmale von Gesellschaften unter dem Einfluss neuer IuK, das auf deren spezifische Auswirkungen auf Wissensordnungen und deren gesellschaftliche Bedeutung abstellt. Innovationen wie das Internet und Smartphone diffundieren dabei nach und nach über den ganzen Erdball, so dass digitale Technologien mittlerweile auch in den Schwellen-und Entwicklungsländern weite Verbreitung finden (Etzo &amp; Collender, 2010;UNCTAD, 2017). Stand 2018 gibt es allein in Afrika mehr als 419 Millionen Nutzer*innen mobiler Breitbandverbindungen (Reed, 2017). Das einst von McLuhan (1962) vorgestellte globale Dorf nimmt damit in den Augen vieler Beobachter*innen nach und nach Gestalt an und lässt die Welt durch schnellen entgrenzten Wissensaustausch vor allem wirtschaftlich zusammenwachsen (Friedman, 2005).Im Zuge des technischen Fortschritts entstand ein neues Verständnis der Wesensmerkmale von Gesellschaften unter dem Einfluss neuer IuK, das auf deren spezifische Auswirkungen auf Wissensordnungen und deren gesellschaftliche Bedeutung abstellt. Innovationen wie das Internet und Smartphone diffundieren dabei nach und nach über den ganzen Erdball, so dass digitale Technologien mittlerweile auch in den Schwellen-und Entwicklungsländern weite Verbreitung finden (Etzo &amp; Collender, 2010;UNCTAD, 2017). Stand 2018 gibt es allein in Afrika mehr als 419 Millionen Nutzer*innen mobiler Breitbandverbindungen (Reed, 2017). Das einst von McLuhan (1962) vorgestellte globale Dorf nimmt damit in den Augen vieler Beobachter*innen nach und nach Gestalt an und lässt die Welt durch schnellen entgrenzten Wissensaustausch vor allem wirtschaftlich zusammenwachsen (Friedman, 2005).</p>
        <p>Die gestiegene quantitative und qualitative Bedeutung von Informationen und Wissen wurde in diesem Zusammenhang auch von der Wissenschaft kommentiert und als Anlass genommen, Gesellschaftsentwürfe und Epochen wie das Informationszeitalter (Castells, 1996(Castells, , 1997(Castells, , 1998) ) oder die Wissensgesellschaft auszurufen (Böhme &amp; Stehr, 1986;Kübler, 2009;Stehr, 2012). Bevor jedoch auf entsprechende globale Gesellschaftsdiagnosen eingegangen werden kann, soll nachfolgend zunächst dargelegt werden, was es mit dem Begriff des Wissens auf sich hat (siehe Abschnitt 4.1). Dabei soll Wissen immer in seiner besonderen Beziehung zu den Eigenschaften der großen digitalen Datenbestände betrachtet werden. Anschließend muss dann erörtert werden, wieso nun Wissen eine zentrale Kategorie der Gesellschaftsdiagnose der Wissensgesellschaft ist, warum diese im Zusammenhang mit den digitalen Daten eine positive Konnotation erfährt und welche kommunikative Bedeutung ein entsprechender Mythos in diesem Zusammenhang hat (siehe Abschnitt 4.2). Erst vor diesem Hintergrund kann die soziale Bedeutung des Wissens aus Quantifizierung und hierauf basierender Vergleiche in einer digitalisierten Welt demonstriert werden (siehe Kapitel 5). Auch kann erst dann die Konsequenz für die Erwartungen an digitale Daten herausgearbeitet werden, um eine Analyse der Konsequenzen gesellschaftlicher Perzeptionen von datenverarbeitender IuK vorzubereiten (siehe Kapitel 6).Die gestiegene quantitative und qualitative Bedeutung von Informationen und Wissen wurde in diesem Zusammenhang auch von der Wissenschaft kommentiert und als Anlass genommen, Gesellschaftsentwürfe und Epochen wie das Informationszeitalter (Castells, 1996(Castells, , 1997(Castells, , 1998) ) oder die Wissensgesellschaft auszurufen (Böhme &amp; Stehr, 1986;Kübler, 2009;Stehr, 2012). Bevor jedoch auf entsprechende globale Gesellschaftsdiagnosen eingegangen werden kann, soll nachfolgend zunächst dargelegt werden, was es mit dem Begriff des Wissens auf sich hat (siehe Abschnitt 4.1). Dabei soll Wissen immer in seiner besonderen Beziehung zu den Eigenschaften der großen digitalen Datenbestände betrachtet werden. Anschließend muss dann erörtert werden, wieso nun Wissen eine zentrale Kategorie der Gesellschaftsdiagnose der Wissensgesellschaft ist, warum diese im Zusammenhang mit den digitalen Daten eine positive Konnotation erfährt und welche kommunikative Bedeutung ein entsprechender Mythos in diesem Zusammenhang hat (siehe Abschnitt 4.2). Erst vor diesem Hintergrund kann die soziale Bedeutung des Wissens aus Quantifizierung und hierauf basierender Vergleiche in einer digitalisierten Welt demonstriert werden (siehe Kapitel 5). Auch kann erst dann die Konsequenz für die Erwartungen an digitale Daten herausgearbeitet werden, um eine Analyse der Konsequenzen gesellschaftlicher Perzeptionen von datenverarbeitender IuK vorzubereiten (siehe Kapitel 6).</p>
        <p>Wissen ist ein zentraler Begriff für die vorliegende Arbeit. Es wäre zu kurz gegriffen, sich damit zu begnügen, auf den vordergründig allgemein-und somit vermeintlich selbstverständlichen Zusammenhang von Wissen abzustellen und über diese Verkürzung direkt mit der Bedeutung des Wissensbegriffes im Rahmen der Wissensgesellschaft sowie der eigentlichen Unterscheidung von Wissens-und Glaubenssystemen fortzufahren. Es müssen zunächst die Bedingungen des Wissens erörtert werden, um nachfolgend zu zeigen, wie sich Wissen zu den digitalen Datenbeständen und auch den Bürger*innen verhält. Welches Wissen steckt in den Daten bzw. kann in ihnen stecken? Welchen Zugang haben Bürger*innen zu diesem Wissen? Dabei wird deutlich werden, dass Wissen unterschiedliche Qualitäten und somit Affordanzen besitzt. Es ist dann herauszuarbeiten, über welches Wissen denn konkret gesprochen wird, wenn über aus digitalen Daten gewonnenes Wissen gesprochen wird, und wie die oder der durchschnittliche Bürger*in auf dieses Wissen zugreift, es internalisieren und nutzen kann oder zumindest an einem solchen Prozess teilhaben kann, wenn Dritte das Wissen aus den Daten verarbeiten.Wissen ist ein zentraler Begriff für die vorliegende Arbeit. Es wäre zu kurz gegriffen, sich damit zu begnügen, auf den vordergründig allgemein-und somit vermeintlich selbstverständlichen Zusammenhang von Wissen abzustellen und über diese Verkürzung direkt mit der Bedeutung des Wissensbegriffes im Rahmen der Wissensgesellschaft sowie der eigentlichen Unterscheidung von Wissens-und Glaubenssystemen fortzufahren. Es müssen zunächst die Bedingungen des Wissens erörtert werden, um nachfolgend zu zeigen, wie sich Wissen zu den digitalen Datenbeständen und auch den Bürger*innen verhält. Welches Wissen steckt in den Daten bzw. kann in ihnen stecken? Welchen Zugang haben Bürger*innen zu diesem Wissen? Dabei wird deutlich werden, dass Wissen unterschiedliche Qualitäten und somit Affordanzen besitzt. Es ist dann herauszuarbeiten, über welches Wissen denn konkret gesprochen wird, wenn über aus digitalen Daten gewonnenes Wissen gesprochen wird, und wie die oder der durchschnittliche Bürger*in auf dieses Wissen zugreift, es internalisieren und nutzen kann oder zumindest an einem solchen Prozess teilhaben kann, wenn Dritte das Wissen aus den Daten verarbeiten.</p>
        <p>Wo fängt eine Beschäftigung mit Wissen an? Die Literatur zum Begriff des Wissens (und auch des Glaubens sowie ihrer Abgrenzung) ist nicht zu überschauen. Abhandlungen darüber, ob und wie der Mensch wissen und erkennen kann, füllen Bibliotheken und führen ideengeschichtlich zurück bis in die Antike zu Platon (2017). Die Erkenntnistheorie, auch Epistemologie genannt, ist ein Hauptgebiet der Philosophie und eine eigene Wissenschaftsdisziplin (Baumann, 2015). Da Wissen das Wesen von Wissenschaft im Kern betrifft und diese Arbeit insbesondere auf die Wissensdimension von Big Data abstellt und einer sozialwissenschaftlichen Analyse zuführt, kann und soll zwar keine ausführliche philosophische Aufarbeitung geleistet werden. Jedoch sind an dieser Stelle ein paar Setzungen sinnvoll und nötig, die deutlich machen, wie sich Wissen zur besonderen Qualität digitaler Daten verhält. Sie beschränken sich dabei auf ein Grundverständnis und stehen nachfolgend immer in konkretem Bezug zu Big Data und dem Erkenntnisinteresse der vorliegenden Arbeit. 2Wenden wir uns zunächst einer Definition von Wissen zu und erörtern, was gemeinhin gemeint ist, wenn von Wissen gesprochen wird. Ähnlich wie bei den zuvor thematisierten theoriegeladenen Konstrukten Digitalisierung oder Big Data gibt es auch für Wissen keine allgemeingültige Definition. Mal wird Wissen als eine Handlungskompetenz (von Subjekten) verstanden, mal als "auf wahre Aussagen zielende Größe" (J. Hofmann, 2001, S. 3) The project of analysing knowledge is to state conditions that are individually necessary and jointly sufficient for propositional knowledge, thoroughly answering the question, what does it take to know something? By 'propositional knowledge', we mean knowledge of a proposition-for example, if Susan knows that Alyssa is a musician, she has knowledge of the proposition that Alyssa is a musician. ( § 2) Dieses Verständnis propositionalen Wissens, bei dem gefragt wird, welche Bedingungen erfüllt sein müssen, damit man wissen kann, ist aufgrund seiner subjektbezogenen Perspektive auch für die vorliegende Arbeit zielführend. Wissen wird dabei in der klassischen Analyse von Wissen (KAW) auch als ein 'justified true belief ' verstanden, den eine Person haben kann (Ichikawa &amp; Steup, 2018). Wie nun zu erörtern sein wird, ist das im vorliegenden Forschungszusammenhang thematisierte Wissen auf Grundlage digitaler Daten an dieses Wissensverständnis anschlussfähig.Wo fängt eine Beschäftigung mit Wissen an? Die Literatur zum Begriff des Wissens (und auch des Glaubens sowie ihrer Abgrenzung) ist nicht zu überschauen. Abhandlungen darüber, ob und wie der Mensch wissen und erkennen kann, füllen Bibliotheken und führen ideengeschichtlich zurück bis in die Antike zu Platon (2017). Die Erkenntnistheorie, auch Epistemologie genannt, ist ein Hauptgebiet der Philosophie und eine eigene Wissenschaftsdisziplin (Baumann, 2015). Da Wissen das Wesen von Wissenschaft im Kern betrifft und diese Arbeit insbesondere auf die Wissensdimension von Big Data abstellt und einer sozialwissenschaftlichen Analyse zuführt, kann und soll zwar keine ausführliche philosophische Aufarbeitung geleistet werden. Jedoch sind an dieser Stelle ein paar Setzungen sinnvoll und nötig, die deutlich machen, wie sich Wissen zur besonderen Qualität digitaler Daten verhält. Sie beschränken sich dabei auf ein Grundverständnis und stehen nachfolgend immer in konkretem Bezug zu Big Data und dem Erkenntnisinteresse der vorliegenden Arbeit. 2Wenden wir uns zunächst einer Definition von Wissen zu und erörtern, was gemeinhin gemeint ist, wenn von Wissen gesprochen wird. Ähnlich wie bei den zuvor thematisierten theoriegeladenen Konstrukten Digitalisierung oder Big Data gibt es auch für Wissen keine allgemeingültige Definition. Mal wird Wissen als eine Handlungskompetenz (von Subjekten) verstanden, mal als "auf wahre Aussagen zielende Größe" (J. Hofmann, 2001, S. 3) The project of analysing knowledge is to state conditions that are individually necessary and jointly sufficient for propositional knowledge, thoroughly answering the question, what does it take to know something? By 'propositional knowledge', we mean knowledge of a proposition-for example, if Susan knows that Alyssa is a musician, she has knowledge of the proposition that Alyssa is a musician. ( § 2) Dieses Verständnis propositionalen Wissens, bei dem gefragt wird, welche Bedingungen erfüllt sein müssen, damit man wissen kann, ist aufgrund seiner subjektbezogenen Perspektive auch für die vorliegende Arbeit zielführend. Wissen wird dabei in der klassischen Analyse von Wissen (KAW) auch als ein 'justified true belief ' verstanden, den eine Person haben kann (Ichikawa &amp; Steup, 2018). Wie nun zu erörtern sein wird, ist das im vorliegenden Forschungszusammenhang thematisierte Wissen auf Grundlage digitaler Daten an dieses Wissensverständnis anschlussfähig.</p>
        <p>Den Ausführungen von Ichikawa und Steup zu dieser traditionellen Dreiteilung folgend, muss Wissen mithin drei notwendige und zusammenwirkend hinreichende Bedingungen erfüllen, die nachfolgend erläutert werden: (1) die Bedingungen der Wahrheit, (2) der Überzeugung und (3) der Rechtfertigung (auch: Nicht-Zufälligkeit, vgl. Baumann, 2015, S. 37-40).Den Ausführungen von Ichikawa und Steup zu dieser traditionellen Dreiteilung folgend, muss Wissen mithin drei notwendige und zusammenwirkend hinreichende Bedingungen erfüllen, die nachfolgend erläutert werden: (1) die Bedingungen der Wahrheit, (2) der Überzeugung und (3) der Rechtfertigung (auch: Nicht-Zufälligkeit, vgl. Baumann, 2015, S. 37-40).</p>
        <p>Ichikawa und Steup (2018, § 10) folgend kann man nur Dinge (nachfolgend auch als Entitäten bezeichnet)3 wissen, die wahr sind. Aussagen, die falsch oder unwahr sind, können somit nicht gewusst werden. Dabei ist für die Wahrheit einer Entität jedoch nicht notwendig, dass überhaupt jemand etwas über sie wissen kann oder in der Lage ist, zu beweisen, dass sie wahr ist. Eine Wahrheit muss mithin nicht bekannt sein, aber Wissen, das bekannt ist -im Sinne einer getroffenen Feststellung von etwas vermeintlich Gewusstem -muss wahr sein.Ichikawa und Steup (2018, § 10) folgend kann man nur Dinge (nachfolgend auch als Entitäten bezeichnet)3 wissen, die wahr sind. Aussagen, die falsch oder unwahr sind, können somit nicht gewusst werden. Dabei ist für die Wahrheit einer Entität jedoch nicht notwendig, dass überhaupt jemand etwas über sie wissen kann oder in der Lage ist, zu beweisen, dass sie wahr ist. Eine Wahrheit muss mithin nicht bekannt sein, aber Wissen, das bekannt ist -im Sinne einer getroffenen Feststellung von etwas vermeintlich Gewusstem -muss wahr sein.</p>
        <p>Truth is a metaphysical, as opposed to epistemological, notion: truth is a matter of how things are, not how they can be shown to be. So when we say that only true things can be known, we're not (yet) saying anything about how anyone can access the truth. (…) Knowledge is a kind of relationship with the truth-to know something is to have a certain kind of access to a fact. (Ichikawa &amp; Steup, 2018, § 12, Hervorh. im Orig.) Die Bedeutung dieser Bedingung wird also insbesondere in solchen Momenten deutlich, in denen die Voraussetzung der Wahrheit verletzt ist, also bspw. mit Bezug auf unwahre Tatsachen, wie etwa der um Mitternacht getroffenen Aussage, es sei gerade Mittagszeit. Mithin bezeichnet Baumann (2015) die Bedingung des Wissens auch als die "Unproblematischste" (S. 36) und ihre spezifischen Rahmenbedingungen sollen an dieser Stelle nicht weiter vertieft werden.Truth is a metaphysical, as opposed to epistemological, notion: truth is a matter of how things are, not how they can be shown to be. So when we say that only true things can be known, we're not (yet) saying anything about how anyone can access the truth. (…) Knowledge is a kind of relationship with the truth-to know something is to have a certain kind of access to a fact. (Ichikawa &amp; Steup, 2018, § 12, Hervorh. im Orig.) Die Bedeutung dieser Bedingung wird also insbesondere in solchen Momenten deutlich, in denen die Voraussetzung der Wahrheit verletzt ist, also bspw. mit Bezug auf unwahre Tatsachen, wie etwa der um Mitternacht getroffenen Aussage, es sei gerade Mittagszeit. Mithin bezeichnet Baumann (2015) die Bedingung des Wissens auch als die "Unproblematischste" (S. 36) und ihre spezifischen Rahmenbedingungen sollen an dieser Stelle nicht weiter vertieft werden.</p>
        <p>Dass Wahrheit und Wahrhaftigkeit bezüglich digitaler Daten jedoch ebenfalls eine bedeutende Rolle spielen, wurde bereits mit Blick auf die zuvor besprochene Dimension der Richtigkeit der digitalen Daten deutlich (siehe Abschnitt 3.5.1).Dass Wahrheit und Wahrhaftigkeit bezüglich digitaler Daten jedoch ebenfalls eine bedeutende Rolle spielen, wurde bereits mit Blick auf die zuvor besprochene Dimension der Richtigkeit der digitalen Daten deutlich (siehe Abschnitt 3.5.1).</p>
        <p>Hier besteht der Anspruch, dass, unter Annahme einer objektiven Beobachtung und eines präzisen Übersetzungsprozesses realweltlicher Tatsachen in Daten, prinzipiell Wahrheiten in diesen Daten dokumentiert sind und sich erkennen lassen. Die digitalen Daten sind somit wichtiger Bezugspunkt von Wissen, auch wenn die tatsächliche Wahrheit vermeintlicher Tatsachen in ihrer Bedingung für Wissen zwar (noch) nicht zweifelsfrei bewiesen sein muss, so doch aber zumindest mit gewisser empirischer Evidenz unterfüttert ist: "Something's truth does not require that anyone can know or prove that it is true. Not all truths are established truths" (Ichikawa &amp; Steup, 2018, § 12, Hervorh. im Orig.). Es kann trotz möglicher angesprochener Einschränkungen zumindest generell davon ausgegangen werden, dass sich auf Grundlage digitaler Daten Wahrheiten erkennen und wahrhaftige Aussagen tätigen lassen.Hier besteht der Anspruch, dass, unter Annahme einer objektiven Beobachtung und eines präzisen Übersetzungsprozesses realweltlicher Tatsachen in Daten, prinzipiell Wahrheiten in diesen Daten dokumentiert sind und sich erkennen lassen. Die digitalen Daten sind somit wichtiger Bezugspunkt von Wissen, auch wenn die tatsächliche Wahrheit vermeintlicher Tatsachen in ihrer Bedingung für Wissen zwar (noch) nicht zweifelsfrei bewiesen sein muss, so doch aber zumindest mit gewisser empirischer Evidenz unterfüttert ist: "Something's truth does not require that anyone can know or prove that it is true. Not all truths are established truths" (Ichikawa &amp; Steup, 2018, § 12, Hervorh. im Orig.). Es kann trotz möglicher angesprochener Einschränkungen zumindest generell davon ausgegangen werden, dass sich auf Grundlage digitaler Daten Wahrheiten erkennen und wahrhaftige Aussagen tätigen lassen.</p>
        <p>Noch wichtiger, insbesondere mit Blick auf den vermeintlichen Erkenntnisgewinn aus digitalen Daten, ist die Bedingung der Überzeugung, die auch einen zentralen Bestandteil des in dieser Arbeit analysierten Glaubenssystems zu Big Data darstellt (Arisov et al., 2019). Nur wenn man von etwas überzeugt ist, dann kann man es auch wissen. Die Bedingung wird bei Ichikawa und Steup (2018) auch wie folgt beschrieben: "The general idea behind the belief condition is that you can only know what you believe. Failing to believe something precludes knowing it" (Ichikawa &amp; Steup, 2018, § 13). Dabei ist Überzeugung im Rahmen des Wissens trotz der vorliegenden Umschreibung gerade nicht mit einem Glauben zu verwechseln, wie er nachfolgend im Rahmen von Glaubenssystemen thematisiert wird. Während Glaube mit Unsicherheit behaftet sein kann und somit mehr oder weniger stark ausgeprägt ist, geht es hier eher um ein starkes Für-wahr-Halten. Gemeint ist dahingehend also eine Überzeugung, die möglichst absolut ist, also keinerlei Zweifel zulässt: Eine Überzeugung zu haben bedeutet, dass eine Person annimmt, dass etwas auch tatsächlich der Fall ist (Baumann, 2015). Das heißt, dass mit der Überzeugung i. S. v. Wissen nicht lediglich eine hohe Zuversicht verbunden sein sollte, sondern eine möglichst absolute Verbindlichkeit. Es wird mit Blick auf Wissen auch von einem Full Belief oder Outright Belief gesprochen, der von unterschiedlichen abzugrenzenden Konfidenzebenen unterschieden wird: "(…) Having an outright belief is a state of being stably disposed to treat p as though it were practically certain" (Wedgwood, 2012, S. 321, Hervorh. im Orig.).Noch wichtiger, insbesondere mit Blick auf den vermeintlichen Erkenntnisgewinn aus digitalen Daten, ist die Bedingung der Überzeugung, die auch einen zentralen Bestandteil des in dieser Arbeit analysierten Glaubenssystems zu Big Data darstellt (Arisov et al., 2019). Nur wenn man von etwas überzeugt ist, dann kann man es auch wissen. Die Bedingung wird bei Ichikawa und Steup (2018) auch wie folgt beschrieben: "The general idea behind the belief condition is that you can only know what you believe. Failing to believe something precludes knowing it" (Ichikawa &amp; Steup, 2018, § 13). Dabei ist Überzeugung im Rahmen des Wissens trotz der vorliegenden Umschreibung gerade nicht mit einem Glauben zu verwechseln, wie er nachfolgend im Rahmen von Glaubenssystemen thematisiert wird. Während Glaube mit Unsicherheit behaftet sein kann und somit mehr oder weniger stark ausgeprägt ist, geht es hier eher um ein starkes Für-wahr-Halten. Gemeint ist dahingehend also eine Überzeugung, die möglichst absolut ist, also keinerlei Zweifel zulässt: Eine Überzeugung zu haben bedeutet, dass eine Person annimmt, dass etwas auch tatsächlich der Fall ist (Baumann, 2015). Das heißt, dass mit der Überzeugung i. S. v. Wissen nicht lediglich eine hohe Zuversicht verbunden sein sollte, sondern eine möglichst absolute Verbindlichkeit. Es wird mit Blick auf Wissen auch von einem Full Belief oder Outright Belief gesprochen, der von unterschiedlichen abzugrenzenden Konfidenzebenen unterschieden wird: "(…) Having an outright belief is a state of being stably disposed to treat p as though it were practically certain" (Wedgwood, 2012, S. 321, Hervorh. im Orig.).</p>
        <p>Es ergibt sich wie gezeigt eine besondere Qualität der Überzeugungsleistung von Wissensinhalten auf Grundlage digitaler Daten für das Wissen, da sie zumindest ihrer Beschreibung nach als Beobachtungen von Tatsachen wahre Begebenheiten realitätsgetreu abbilden können und somit in der Lage sind, Überzeugungen zu nähren, wie etwas wirklich ist. Aus der Sicht eines empirisch lernenden Subjekts können also digitale Beobachtungsdaten die Bedingung der Überzeugung von Aussagen fördern, wenn sie diese faktisch stützen. Dabei ist die Tragweite datenbasierter Überzeugung selbstredend in Abhängigkeit situativer Einflüsse zu bewerten und wird mithin immer subjektiv evaluiert. Es geht hier jedoch um das Potential der digitalen Daten für die Überzeugung von Wissenspropositionen. Dieses ist im Sinne von Wissenschaft, die ihr Wissen empirisch auf Grundlage gesammelter Daten schafft, durchaus gegeben (Chalmers, 1976).Es ergibt sich wie gezeigt eine besondere Qualität der Überzeugungsleistung von Wissensinhalten auf Grundlage digitaler Daten für das Wissen, da sie zumindest ihrer Beschreibung nach als Beobachtungen von Tatsachen wahre Begebenheiten realitätsgetreu abbilden können und somit in der Lage sind, Überzeugungen zu nähren, wie etwas wirklich ist. Aus der Sicht eines empirisch lernenden Subjekts können also digitale Beobachtungsdaten die Bedingung der Überzeugung von Aussagen fördern, wenn sie diese faktisch stützen. Dabei ist die Tragweite datenbasierter Überzeugung selbstredend in Abhängigkeit situativer Einflüsse zu bewerten und wird mithin immer subjektiv evaluiert. Es geht hier jedoch um das Potential der digitalen Daten für die Überzeugung von Wissenspropositionen. Dieses ist im Sinne von Wissenschaft, die ihr Wissen empirisch auf Grundlage gesammelter Daten schafft, durchaus gegeben (Chalmers, 1976).</p>
        <p>Als dritte Bedingung wird in der klassischen Analyse des Wissens die Rechtfertigung propositionalen Wissens in den Blick genommen. Die Bedingung betrifft die Herleitung und Begründung eines Wissensinhalts:Als dritte Bedingung wird in der klassischen Analyse des Wissens die Rechtfertigung propositionalen Wissens in den Blick genommen. Die Bedingung betrifft die Herleitung und Begründung eines Wissensinhalts:</p>
        <p>Why not say that knowledge is true belief? The standard answer is that to identify knowledge with true belief would be implausible because a belief might be true even though it is formed improperly. Suppose that William flips a coin, and confidently believes-on no particular basis-that it will land tails. If by chance the coin does land tails, then William's belief was true; but a lucky guess such as this one is no knowledge. For William to know, his belief must in some epistemic sense be proper or appropriate: it must be justified. (Ichikawa &amp; Steup, 2018, § 19, Hervorh. im Orig.) Die Bedingung der Rechtfertigung wird von Baumann (2015) folglich auch als "Nicht-Zufälligkeit" (S. 37) beschrieben: Dabei geht es nicht um die Zufälligkeit des Zustandekommens der Tatsachen, die eine Überzeugung ‚wahr machen', sondern die Abwesenheit von Anhaltspunkten, auf die eine Person Überzeugungen begründet. Diese Zufälligkeit von Überzeugungen kann nicht als Wissen gelten.Why not say that knowledge is true belief? The standard answer is that to identify knowledge with true belief would be implausible because a belief might be true even though it is formed improperly. Suppose that William flips a coin, and confidently believes-on no particular basis-that it will land tails. If by chance the coin does land tails, then William's belief was true; but a lucky guess such as this one is no knowledge. For William to know, his belief must in some epistemic sense be proper or appropriate: it must be justified. (Ichikawa &amp; Steup, 2018, § 19, Hervorh. im Orig.) Die Bedingung der Rechtfertigung wird von Baumann (2015) folglich auch als "Nicht-Zufälligkeit" (S. 37) beschrieben: Dabei geht es nicht um die Zufälligkeit des Zustandekommens der Tatsachen, die eine Überzeugung ‚wahr machen', sondern die Abwesenheit von Anhaltspunkten, auf die eine Person Überzeugungen begründet. Diese Zufälligkeit von Überzeugungen kann nicht als Wissen gelten.</p>
        <p>Wenn zum Wesen von (digitalen) Daten gehört, dass sie Überzeugungen nähren, dann müssen sie wiederum auch ebenso dazu dienen können, als Rechtfertigung von propositionalen Wissenssätzen herangezogen werden. Wie in Kapitel 3 erörtert, sind die digitalen Daten, die unter den in dieser Arbeit verwendeten Begriff von Big Data fallen, als Beobachtungsdaten zu verstehen. Sie dienen somit als die zuvor angesprochenen Anhaltspunkte von Beobachtenden, auf die sich Wissen über etwas stützen muss, und können mithin als besondere Form von Evidenz gelten, die Wissen rechtfertigt. Sie sind, unter der Voraussetzung ihrer Richtigkeit, (binär) codiert festgehaltene Beobachtungen von Tatsachen der Welt.Wenn zum Wesen von (digitalen) Daten gehört, dass sie Überzeugungen nähren, dann müssen sie wiederum auch ebenso dazu dienen können, als Rechtfertigung von propositionalen Wissenssätzen herangezogen werden. Wie in Kapitel 3 erörtert, sind die digitalen Daten, die unter den in dieser Arbeit verwendeten Begriff von Big Data fallen, als Beobachtungsdaten zu verstehen. Sie dienen somit als die zuvor angesprochenen Anhaltspunkte von Beobachtenden, auf die sich Wissen über etwas stützen muss, und können mithin als besondere Form von Evidenz gelten, die Wissen rechtfertigt. Sie sind, unter der Voraussetzung ihrer Richtigkeit, (binär) codiert festgehaltene Beobachtungen von Tatsachen der Welt.</p>
        <p>Die Problematik der Dynamik von Wissen Die drei zuvor genannten Bedingungen als Startpunkt der Analyse von Wissen wurden insbesondere durch die Formulierung des Gettier-Problems (Gettier, 1963) in Frage gestellt. Gettier stellt darauf ab, dass eine gerechtfertigte wahre Meinung auch irrtümlich zustande kommen kann. Sie ist dann zwar wahr und man ist überzeugt von dieser Wahrheit. Es gibt auch gute Gründe, die die Annahme rechtfertigen, dennoch ist die Aussage aus anderen Gründen als den genannten wahr oder wird wahr. Lehrer und Paxson (1969) greifen diesen Einwand auf und schlagen hiervon ausgehend vor, Wissen als "undefeated completely justified true belief" (S. 225) zu definieren. Der Rechtfertigungsgrund dafür, eine Aussage als wahr zu betrachten, darf nicht durch eine andere wahre Aussage abgelehnt oder besiegt werden.Die Problematik der Dynamik von Wissen Die drei zuvor genannten Bedingungen als Startpunkt der Analyse von Wissen wurden insbesondere durch die Formulierung des Gettier-Problems (Gettier, 1963) in Frage gestellt. Gettier stellt darauf ab, dass eine gerechtfertigte wahre Meinung auch irrtümlich zustande kommen kann. Sie ist dann zwar wahr und man ist überzeugt von dieser Wahrheit. Es gibt auch gute Gründe, die die Annahme rechtfertigen, dennoch ist die Aussage aus anderen Gründen als den genannten wahr oder wird wahr. Lehrer und Paxson (1969) greifen diesen Einwand auf und schlagen hiervon ausgehend vor, Wissen als "undefeated completely justified true belief" (S. 225) zu definieren. Der Rechtfertigungsgrund dafür, eine Aussage als wahr zu betrachten, darf nicht durch eine andere wahre Aussage abgelehnt oder besiegt werden.</p>
        <p>Diese Betrachtung von Wissen lässt somit die Möglichkeit offen, dass einmal als wahr betrachtete Wissensaussagen auch falsifiziert werden können oder angepasst werden müssen, sobald neue Erkenntnisse hinzukommen. Dass die Möglichkeit besteht, dass es in meiner Welt einen schwarzen Schwan gibt, obwohl ich noch nie einen solchen mit meinen Sinnen unmittelbar beobachtet habe, ist also eine lediglich mit Wahrscheinlichkeit behaftete Aussage. Im Sinne des kritischen Rationalismus von Popper (1935Popper ( , 1973) ) kann daher eine Theorie auch nicht final bestätigt werden. Ihr Wert ergibt sich daraus, dass sie zwar Vorhersagen formulieren lässt, die empirisch geprüft werden können, jedoch immer die Möglichkeit offengelassen werden muss, dass die durch die Theorie formulierten Annahmen sowie die Theorie selbst falsifiziert werden können. Auch einmal etabliertes Wissen kann veralten oder überholt sein. Die Ansammlung von Beobachtungsdaten ist ein fortlaufendes Unterfangen, so dass neue Beobachtungen neue Evidenz zum Wissensbestand hinzufügen können. Wissen und Wissensbestände sind daher hoch dynamisch (Budin, 1996). Das ist insbesondere aus Sicht des wissenden Subjekts eine relevante Eigenschaft des Wissens, da nicht nur kritisch beurteilt werden muss, ob Wissensaussagen die genannten Bedingungen erfüllen, sondern auch laufend reflektiert werden müsste, ob das einmal erlernte Wissen die genannten Bedingungen noch immer erfüllt.Diese Betrachtung von Wissen lässt somit die Möglichkeit offen, dass einmal als wahr betrachtete Wissensaussagen auch falsifiziert werden können oder angepasst werden müssen, sobald neue Erkenntnisse hinzukommen. Dass die Möglichkeit besteht, dass es in meiner Welt einen schwarzen Schwan gibt, obwohl ich noch nie einen solchen mit meinen Sinnen unmittelbar beobachtet habe, ist also eine lediglich mit Wahrscheinlichkeit behaftete Aussage. Im Sinne des kritischen Rationalismus von Popper (1935Popper ( , 1973) ) kann daher eine Theorie auch nicht final bestätigt werden. Ihr Wert ergibt sich daraus, dass sie zwar Vorhersagen formulieren lässt, die empirisch geprüft werden können, jedoch immer die Möglichkeit offengelassen werden muss, dass die durch die Theorie formulierten Annahmen sowie die Theorie selbst falsifiziert werden können. Auch einmal etabliertes Wissen kann veralten oder überholt sein. Die Ansammlung von Beobachtungsdaten ist ein fortlaufendes Unterfangen, so dass neue Beobachtungen neue Evidenz zum Wissensbestand hinzufügen können. Wissen und Wissensbestände sind daher hoch dynamisch (Budin, 1996). Das ist insbesondere aus Sicht des wissenden Subjekts eine relevante Eigenschaft des Wissens, da nicht nur kritisch beurteilt werden muss, ob Wissensaussagen die genannten Bedingungen erfüllen, sondern auch laufend reflektiert werden müsste, ob das einmal erlernte Wissen die genannten Bedingungen noch immer erfüllt.</p>
        <p>Auch wenn es durchaus noch weitere relevante Ansätze und Einschränkungen bezüglich der theoretischen Konzeption von Erkenntnis und Wissen sowie deren Voraussetzungen gibt, bleibt hier zunächst festzuhalten, dass unter der Annahme der genannten Bedingungen von Wissen auch das Wissen auf Grundlage von digitalen Daten voraussetzungsreich und mitunter durchaus problembehaftet sein kann und womöglich diversen Einschränkungen unterliegt. Diese Einschränkungen liegen sowohl primär auf Seiten der Beschaffenheit der digitalen Daten (bspw. bezüglich ihrer Objektivität für die Bedingung von Wahrheit) als auch auf Seiten des Wissenden (bspw. bezüglich ihrer Belastbarkeit für die Bedingung von Überzeugung). Es ist fraglich, inwieweit diese auch laufend kritisch reflektiert oder gar geprüft werden (können). Sieht man hiervon jedoch zunächst ab und erkennt das Wissenspotential an, das digitale Daten durchaus innehaben, muss weitergehend auf den zweckdienlichen Charakter von Wissen eingegangen werden.Auch wenn es durchaus noch weitere relevante Ansätze und Einschränkungen bezüglich der theoretischen Konzeption von Erkenntnis und Wissen sowie deren Voraussetzungen gibt, bleibt hier zunächst festzuhalten, dass unter der Annahme der genannten Bedingungen von Wissen auch das Wissen auf Grundlage von digitalen Daten voraussetzungsreich und mitunter durchaus problembehaftet sein kann und womöglich diversen Einschränkungen unterliegt. Diese Einschränkungen liegen sowohl primär auf Seiten der Beschaffenheit der digitalen Daten (bspw. bezüglich ihrer Objektivität für die Bedingung von Wahrheit) als auch auf Seiten des Wissenden (bspw. bezüglich ihrer Belastbarkeit für die Bedingung von Überzeugung). Es ist fraglich, inwieweit diese auch laufend kritisch reflektiert oder gar geprüft werden (können). Sieht man hiervon jedoch zunächst ab und erkennt das Wissenspotential an, das digitale Daten durchaus innehaben, muss weitergehend auf den zweckdienlichen Charakter von Wissen eingegangen werden.</p>
        <p>Es Auch mit Blick auf die digitalen Daten ist nun in deklaratives Wissen und prozedurales Wissen zu unterscheiden. Es reicht also nicht aus, deklaratives Wissen auf Grundlage von digitalen Daten anzusammeln und in Form von digitalen Daten zu dokumentieren. Das deklarative Wissen über die in den Daten erkannten Muster und Zusammenhänge muss auch verwertet werden und es muss daher gewusst werden, wie diese Verwertung konkret aussehen und durchgeführt werden kann. Ohne prozedurales Wissen, der Verwertung des deklarativen Wissens, bleibt das Wissen der Gesellschaft -ganz allgemein, jedoch hier insbesondere das Wissen aus digitalen Daten -unvollständig und ohne Konsequenz. Beide Formen müssen daher zusammengebracht und in den allgemeinen Wissensbestand oder in spezifische Wissenssysteme 5 integriert werden. So muss für eine erfolgreiche statistische Datenanalyse nicht nur gewusst werden, wann und warum man bspw. eine lineare Regression berechnet, sondern auch, wie man diese mit Hilfe einer Datenanalysesoftware tatsächlich durchführt. Zwar besteht, wie in Abschnitt 3.6 dokumentiert, die Hoffnung, dass vor allem die Anwendungen der KI den Zugang zu und die Organisation von Daten sowie folglich den hieraus geschöpften Erkenntnisgewinn vereinfachen und auf dieser Grundlage bessere Vorhersagen und Entscheidungen produzieren. Ihre tatsächliche praktische gesellschaftliche Implementierung ist jedoch noch nicht allzu weit fortgeschritten. Es fehlen zudem nach einer Erhebung des Verband der Elektrotechnik Elektronik und Informationstechnik (2019) in Unternehmen und Hochschulen allerorts KI-Fachkräfte 6 und es ist somit noch nicht ersichtlich, ob die hohen Erwartungen, die mit dem gesellschaftsweiten Einsatz von KI, vor allem auch mit Bezug auf Wissensarbeit, verbunden sind, auch tatsächlich eingelöst werden. Wissen, und hier insbesondere prozedurales Wissen, kann und soll mit Hilfe der unterschiedlichen Werkzeuge der IuK verarbeitet und verwertet werden; unabhängig, ob dies nun einen einfachen Algorithmus betrifft oder eine voraussetzungsreichere KI. Allerdings ist an der Schnittstelle Daten, Information und Wissen nach wie vor auch immer noch der Mensch gefragt, der um Beschaffenheit, Affordanzen und Verwendung der datenverarbeitenden Werkzeuge wissen muss sowie um die spezifische Qualität der zugeführten Daten. Unmittelbarer menschlicher Zugang zu deklarativen und prozeduralen Wissensbeständen ist und bleibt trotz oder gerade wegen datenverarbeitender IuK zumindest auf absehbare Zeit unerlässlich.Es Auch mit Blick auf die digitalen Daten ist nun in deklaratives Wissen und prozedurales Wissen zu unterscheiden. Es reicht also nicht aus, deklaratives Wissen auf Grundlage von digitalen Daten anzusammeln und in Form von digitalen Daten zu dokumentieren. Das deklarative Wissen über die in den Daten erkannten Muster und Zusammenhänge muss auch verwertet werden und es muss daher gewusst werden, wie diese Verwertung konkret aussehen und durchgeführt werden kann. Ohne prozedurales Wissen, der Verwertung des deklarativen Wissens, bleibt das Wissen der Gesellschaft -ganz allgemein, jedoch hier insbesondere das Wissen aus digitalen Daten -unvollständig und ohne Konsequenz. Beide Formen müssen daher zusammengebracht und in den allgemeinen Wissensbestand oder in spezifische Wissenssysteme 5 integriert werden. So muss für eine erfolgreiche statistische Datenanalyse nicht nur gewusst werden, wann und warum man bspw. eine lineare Regression berechnet, sondern auch, wie man diese mit Hilfe einer Datenanalysesoftware tatsächlich durchführt. Zwar besteht, wie in Abschnitt 3.6 dokumentiert, die Hoffnung, dass vor allem die Anwendungen der KI den Zugang zu und die Organisation von Daten sowie folglich den hieraus geschöpften Erkenntnisgewinn vereinfachen und auf dieser Grundlage bessere Vorhersagen und Entscheidungen produzieren. Ihre tatsächliche praktische gesellschaftliche Implementierung ist jedoch noch nicht allzu weit fortgeschritten. Es fehlen zudem nach einer Erhebung des Verband der Elektrotechnik Elektronik und Informationstechnik (2019) in Unternehmen und Hochschulen allerorts KI-Fachkräfte 6 und es ist somit noch nicht ersichtlich, ob die hohen Erwartungen, die mit dem gesellschaftsweiten Einsatz von KI, vor allem auch mit Bezug auf Wissensarbeit, verbunden sind, auch tatsächlich eingelöst werden. Wissen, und hier insbesondere prozedurales Wissen, kann und soll mit Hilfe der unterschiedlichen Werkzeuge der IuK verarbeitet und verwertet werden; unabhängig, ob dies nun einen einfachen Algorithmus betrifft oder eine voraussetzungsreichere KI. Allerdings ist an der Schnittstelle Daten, Information und Wissen nach wie vor auch immer noch der Mensch gefragt, der um Beschaffenheit, Affordanzen und Verwendung der datenverarbeitenden Werkzeuge wissen muss sowie um die spezifische Qualität der zugeführten Daten. Unmittelbarer menschlicher Zugang zu deklarativen und prozeduralen Wissensbeständen ist und bleibt trotz oder gerade wegen datenverarbeitender IuK zumindest auf absehbare Zeit unerlässlich.</p>
        <p>So muss an dieser Stelle konstatiert werden: Von der Fragilität des Wissens auf Datengrundlage einmal abgesehen, verfügt kein einzelner Mensch dieser Welt über all ihr Wissen. Weder ist er im Besitz des Wissens noch hat er dieses Wissen internalisiert. Diese Aussage scheint zunächst trivial, führt jedoch zu den für diese Arbeit viel wichtigeren Fragen: Welche Beziehung haben die Menschen zu einem nicht-internalisierten Wissen? Welche Bedeutung besitzt das Wissen für das Individuum und die Gesellschaft? Wie viel Wissen glaubt der einzelne Mensch, der derzeit in der vermeintlich digitalisierten Gesellschaft lebt, über eben jene Gesellschaft und ihre digitalen Datenbestände zu haben und welche Konsequenzen ergeben sich für ihn aus seinen diesbezüglichen Überzeugungen? Es gibt keinen sogenannten ‚Renaissance Man', also Menschen, die einen umfassenden Überblick über das aktuell verfügbare Wissen besitzen (Jones, 2009). Zwar werden die Bedeutung und die Vorteile von Generalisten mit breitem Wissensstand in einer spezialisierten arbeitsteilig organisierten Welt in letzter Zeit wieder vermehrt von der Forschung in den Blick genommen (Epstein, 2019;Melero &amp; Palomeras, 2015). Dennoch bleibt es mit Blick auf den gesellschaftlichen Entstehungsund Verwertungskontext von Wissen und dessen Dynamik unmöglich für das Individuum, sich einen umfänglichen Wissenstand zu erarbeiten und zu halten. Keine Data Scientists und schon keine einfachen Bürger*innen haben trotz durchaus vorhandener Berührungspunkte einen Überblick über die Datenbestände, die Vielfalt der Datenauswertungsmöglichkeiten und das hierdurch generierte Wissen über sich selbst und die Gesellschaft.So muss an dieser Stelle konstatiert werden: Von der Fragilität des Wissens auf Datengrundlage einmal abgesehen, verfügt kein einzelner Mensch dieser Welt über all ihr Wissen. Weder ist er im Besitz des Wissens noch hat er dieses Wissen internalisiert. Diese Aussage scheint zunächst trivial, führt jedoch zu den für diese Arbeit viel wichtigeren Fragen: Welche Beziehung haben die Menschen zu einem nicht-internalisierten Wissen? Welche Bedeutung besitzt das Wissen für das Individuum und die Gesellschaft? Wie viel Wissen glaubt der einzelne Mensch, der derzeit in der vermeintlich digitalisierten Gesellschaft lebt, über eben jene Gesellschaft und ihre digitalen Datenbestände zu haben und welche Konsequenzen ergeben sich für ihn aus seinen diesbezüglichen Überzeugungen? Es gibt keinen sogenannten ‚Renaissance Man', also Menschen, die einen umfassenden Überblick über das aktuell verfügbare Wissen besitzen (Jones, 2009). Zwar werden die Bedeutung und die Vorteile von Generalisten mit breitem Wissensstand in einer spezialisierten arbeitsteilig organisierten Welt in letzter Zeit wieder vermehrt von der Forschung in den Blick genommen (Epstein, 2019;Melero &amp; Palomeras, 2015). Dennoch bleibt es mit Blick auf den gesellschaftlichen Entstehungsund Verwertungskontext von Wissen und dessen Dynamik unmöglich für das Individuum, sich einen umfänglichen Wissenstand zu erarbeiten und zu halten. Keine Data Scientists und schon keine einfachen Bürger*innen haben trotz durchaus vorhandener Berührungspunkte einen Überblick über die Datenbestände, die Vielfalt der Datenauswertungsmöglichkeiten und das hierdurch generierte Wissen über sich selbst und die Gesellschaft.</p>
        <p>Dieses Wissen liegt, wenn überhaupt, in großen Forschungseinrichtungen, staatlichen Institutionen und Unternehmen vor und selbst dort nur jeweils in Fragmenten. Auch hier gibt es keine zentrale Stelle oder Einheit, von der das gesellschaftliche Wissen aggregiert und verteilt wird. Bleibt man bei der Öl-Metapher, so sind die Ölfelder und Ölfördertechnik wie auch die digitalen Datenbestände und datenanalytische Infrastrukturen auf dieser Erde ungleich verteilt. Mit dem substantiellen Unterschied, dass Daten in ihrer spezifischen Qualität noch vielseitiger sind als Öl, zeigt sich hier folglich, dass die qualitativen Unterschiede auf Seiten derer, die viele und vor allem hochwertige Daten besitzen, und derjenigen, die wenige Daten mit geringer Güte besitzen, noch stärker ausfallen. So bemerken bspw. boyd und Crawford (2012): "The current ecosystem around Big Data creates a new kind of digital divide: the Big Data rich and the Big Data poor" (S. 674). Andrejevic (2014) spricht daher bezüglich dieser Ungleichverteilung auch von einem Big Data Divide (vgl. McCarthy, 2016).Dieses Wissen liegt, wenn überhaupt, in großen Forschungseinrichtungen, staatlichen Institutionen und Unternehmen vor und selbst dort nur jeweils in Fragmenten. Auch hier gibt es keine zentrale Stelle oder Einheit, von der das gesellschaftliche Wissen aggregiert und verteilt wird. Bleibt man bei der Öl-Metapher, so sind die Ölfelder und Ölfördertechnik wie auch die digitalen Datenbestände und datenanalytische Infrastrukturen auf dieser Erde ungleich verteilt. Mit dem substantiellen Unterschied, dass Daten in ihrer spezifischen Qualität noch vielseitiger sind als Öl, zeigt sich hier folglich, dass die qualitativen Unterschiede auf Seiten derer, die viele und vor allem hochwertige Daten besitzen, und derjenigen, die wenige Daten mit geringer Güte besitzen, noch stärker ausfallen. So bemerken bspw. boyd und Crawford (2012): "The current ecosystem around Big Data creates a new kind of digital divide: the Big Data rich and the Big Data poor" (S. 674). Andrejevic (2014) spricht daher bezüglich dieser Ungleichverteilung auch von einem Big Data Divide (vgl. McCarthy, 2016).</p>
        <p>Es muss also mit Blick auf die vorhergehenden Ausführungen zunächst die Möglichkeit offengelassen werden, dass in Daten nicht automatisch Wissen steckt und dass man nur eine mehr oder minder gerechtfertigte Überzeugung daran haben kann, aus diesen Daten Wissen zu erhalten; von einem eventuellen individuellen oder gesellschaftlichen Nutzen, der sich hierauf begründet, ganz ungeachtet. Dies ist zum einen bedingt durch die zweifelhafte Qualität unstrukturierter sowie strukturierter Datensätze, zum anderen durch den weitgehend limitierten Zugang zu den großen digitalen Datenbeständen überhaupt, die im Rahmen der weltweiten Nutzung von IuK entstehen. Es bleibt die Feststellung, dass Erkenntnisproduktion und Wissensgewinn auf Grundlage von Big Data aus Sicht des Individuums folglich mit etwaiger Unsicherheit bezüglich ihrer tatsächlichen Konsequenzen für einen Erkenntnisgewinn behaftet sind und hiermit verbundene Erwartungen durchaus auch ins Leere laufen können. Die Mustererkennung in digitalen Daten ist mithin oftmals uneindeutig und aufgrund ihres primär indirekten und mittelbaren Charakters lediglich eingeschränkt belastbar. Dort, wo jedoch weitgehend verlässliches Wissen produziert wird, das den zuvor besprochenen Kriterien genügt, wird unter den Vorzeichen der Vorhersagbarkeit zukünftiger Entwicklungen und seines Einflusses auf die Gestaltbarkeit von Natur, Umwelt und Gesellschaft durch wissensgeleitetes menschliches Handeln ein Nutzen für den Menschen in seiner sozialen Situation realisierbar. Diesem vermeintlichen Nutzen und diesbezüglich formulierten gesellschaftlichen Erwartungen im Verhältnis zu den großen digitalen Datenmengen widmet sich der nun folgende Abschnitt.Es muss also mit Blick auf die vorhergehenden Ausführungen zunächst die Möglichkeit offengelassen werden, dass in Daten nicht automatisch Wissen steckt und dass man nur eine mehr oder minder gerechtfertigte Überzeugung daran haben kann, aus diesen Daten Wissen zu erhalten; von einem eventuellen individuellen oder gesellschaftlichen Nutzen, der sich hierauf begründet, ganz ungeachtet. Dies ist zum einen bedingt durch die zweifelhafte Qualität unstrukturierter sowie strukturierter Datensätze, zum anderen durch den weitgehend limitierten Zugang zu den großen digitalen Datenbeständen überhaupt, die im Rahmen der weltweiten Nutzung von IuK entstehen. Es bleibt die Feststellung, dass Erkenntnisproduktion und Wissensgewinn auf Grundlage von Big Data aus Sicht des Individuums folglich mit etwaiger Unsicherheit bezüglich ihrer tatsächlichen Konsequenzen für einen Erkenntnisgewinn behaftet sind und hiermit verbundene Erwartungen durchaus auch ins Leere laufen können. Die Mustererkennung in digitalen Daten ist mithin oftmals uneindeutig und aufgrund ihres primär indirekten und mittelbaren Charakters lediglich eingeschränkt belastbar. Dort, wo jedoch weitgehend verlässliches Wissen produziert wird, das den zuvor besprochenen Kriterien genügt, wird unter den Vorzeichen der Vorhersagbarkeit zukünftiger Entwicklungen und seines Einflusses auf die Gestaltbarkeit von Natur, Umwelt und Gesellschaft durch wissensgeleitetes menschliches Handeln ein Nutzen für den Menschen in seiner sozialen Situation realisierbar. Diesem vermeintlichen Nutzen und diesbezüglich formulierten gesellschaftlichen Erwartungen im Verhältnis zu den großen digitalen Datenmengen widmet sich der nun folgende Abschnitt.</p>
        <p>An Der Gesellschaftsentwurf der Wissensgesellschaft liefert dabei nicht nur vermeintliche Erkenntnisse über die Bedeutung von Informationen und Wissen für eine gesellschaftliche Organisationsform, also der zentralen Funktion, die dem Wissen in der Strukturierung -sprich: der physischen wie auch der kulturellen Reproduktion -von Gesellschaft zukommt (Castells, 1996(Castells, , 1997(Castells, , 1998;;Degele, 2000). Der Entwurf hat darüber hinaus auch Eingang in den öffentlichen Diskurs jenseits von Wissenschaft und Ökonomie gefunden. In der Folge ist die Wissensgesellschaft eine vermeintlich wirkmächtige Erzählung, die die gesellschaftliche Selbstbeschreibung und Selbstreflexion prägt (Floridi, 2014;Kübler, 2009;Stehr, 2012). In dieser Erzählung formulierte Erwartungen haben, wie zu untersuchen ist, womöglich zentrale Bedeutung für soziales Handeln und müssen nun aufgezeigt werden.An Der Gesellschaftsentwurf der Wissensgesellschaft liefert dabei nicht nur vermeintliche Erkenntnisse über die Bedeutung von Informationen und Wissen für eine gesellschaftliche Organisationsform, also der zentralen Funktion, die dem Wissen in der Strukturierung -sprich: der physischen wie auch der kulturellen Reproduktion -von Gesellschaft zukommt (Castells, 1996(Castells, , 1997(Castells, , 1998;;Degele, 2000). Der Entwurf hat darüber hinaus auch Eingang in den öffentlichen Diskurs jenseits von Wissenschaft und Ökonomie gefunden. In der Folge ist die Wissensgesellschaft eine vermeintlich wirkmächtige Erzählung, die die gesellschaftliche Selbstbeschreibung und Selbstreflexion prägt (Floridi, 2014;Kübler, 2009;Stehr, 2012). In dieser Erzählung formulierte Erwartungen haben, wie zu untersuchen ist, womöglich zentrale Bedeutung für soziales Handeln und müssen nun aufgezeigt werden.</p>
        <p>Es finden sich allerdings unzählige Definitionsangebote und Konzeptionen von Wissensgesellschaft (vgl. Kübler, 2009, S. 89 ff.). 7 Gemeinsamer Ausgangspunkt ist dabei immer die spezielle Bedeutung, die Wissen für gesellschaftliche Transformationsprozesse zugeschrieben wird, wobei die Bedeutung von Wissen hier unterschiedlicher Natur sein kann. Denn der Wissensbegriff und seine Rolle für die Gesellschaft sind an sich erst einmal recht beliebig, kommt doch keine Gesellschaftsform gänzlich ohne Wissen aus. So sind die Feststellungen von Kübler (2009) fast schon als Anleitung zu lesen, den vielschichtigen Begriff des Wissens und seine mehrdimensionale, spezifische Qualität vor dem Hintergrund seiner sozialen Bedeutung nachvollziehbar zu erläutern, weshalb in den vorangegangenen Kapiteln zunächst verdeutlicht werden musste, wie digitale Daten Wissen herleiten können: Da man sich kaum mehr die Mühe macht, hinreichend zu definieren, was unter den Kernbegriffen verstanden wird bzw. sich mit reichlich willkürlicher Tautologie begnügt, wie vielfach schon gezeigt worden ist und weiter zu belegen sein wird, bemerkt sie indes kaum jemand. ‚Wissen' ist zum eindrucksvollen, autoritätsheischenden und Fortschrittlichkeit signalisierenden Paradigma avanciert -was eigentlich für ein so altes und unspektakuläres Wort erstaunlich ist -und wird daher nicht nur reichlich wahllos und unreflektiert verwendet, es wird auch beliebig kombiniert, damit vergewaltigt, verzerrt und entleert (…). (S. 89) Es wird hier also zum einen deutlich, dass es nicht den einen Zugang zur gesellschaftlichen Bedeutung von Wissen geben kann und der in dieser Arbeit hergeleitete einer von vielen möglichen ist. "Alle Objektivierungsversuche laufen daher substantiell fehl oder sind allenfalls partiell zutreffend" (Kübler, 2009, S. 194). Das bedeutet zum anderen jedoch auch, dass er als diskursiv anschlussfähiges Konstrukt offenbleibt für individuelle und gesellschaftliche Erwartungen, was Wissen nun im Einzelnen für Gesellschaft bedeutet und mit Blick auf einen Glauben an Big Data zu diskutieren sein wird (siehe Abschnitt 6.2.2). In diesem Zusammenhang hat das Wissen als Gegenstand vor allem im Rahmen wissenschaftlicher Diskurse Aufmerksamkeit erfahren. Relevante Fragen gesellschaftlicher Wissens-und Forschungsbezüge werden durch Wissenschaft aufgegriffen, bearbeitet und Erkenntnisgewinne mittlerweile unter Bedingungen und Erwartungen einer zunehmenden Medialisierung und Professionalisierung in die Öffentlichkeit zurückgespielt (Eisenegger &amp; Imhof, 2008;Marcinkowski &amp; Kohring, 2014;M. S. Schäfer, 2007). etwa der Dienstleistungsgesellschaft, der post-oder nach-industriellen Gesellschaft oder auch der Risikogesellschaft (Kübler, 2009).Es finden sich allerdings unzählige Definitionsangebote und Konzeptionen von Wissensgesellschaft (vgl. Kübler, 2009, S. 89 ff.). 7 Gemeinsamer Ausgangspunkt ist dabei immer die spezielle Bedeutung, die Wissen für gesellschaftliche Transformationsprozesse zugeschrieben wird, wobei die Bedeutung von Wissen hier unterschiedlicher Natur sein kann. Denn der Wissensbegriff und seine Rolle für die Gesellschaft sind an sich erst einmal recht beliebig, kommt doch keine Gesellschaftsform gänzlich ohne Wissen aus. So sind die Feststellungen von Kübler (2009) fast schon als Anleitung zu lesen, den vielschichtigen Begriff des Wissens und seine mehrdimensionale, spezifische Qualität vor dem Hintergrund seiner sozialen Bedeutung nachvollziehbar zu erläutern, weshalb in den vorangegangenen Kapiteln zunächst verdeutlicht werden musste, wie digitale Daten Wissen herleiten können: Da man sich kaum mehr die Mühe macht, hinreichend zu definieren, was unter den Kernbegriffen verstanden wird bzw. sich mit reichlich willkürlicher Tautologie begnügt, wie vielfach schon gezeigt worden ist und weiter zu belegen sein wird, bemerkt sie indes kaum jemand. ‚Wissen' ist zum eindrucksvollen, autoritätsheischenden und Fortschrittlichkeit signalisierenden Paradigma avanciert -was eigentlich für ein so altes und unspektakuläres Wort erstaunlich ist -und wird daher nicht nur reichlich wahllos und unreflektiert verwendet, es wird auch beliebig kombiniert, damit vergewaltigt, verzerrt und entleert (…). (S. 89) Es wird hier also zum einen deutlich, dass es nicht den einen Zugang zur gesellschaftlichen Bedeutung von Wissen geben kann und der in dieser Arbeit hergeleitete einer von vielen möglichen ist. "Alle Objektivierungsversuche laufen daher substantiell fehl oder sind allenfalls partiell zutreffend" (Kübler, 2009, S. 194). Das bedeutet zum anderen jedoch auch, dass er als diskursiv anschlussfähiges Konstrukt offenbleibt für individuelle und gesellschaftliche Erwartungen, was Wissen nun im Einzelnen für Gesellschaft bedeutet und mit Blick auf einen Glauben an Big Data zu diskutieren sein wird (siehe Abschnitt 6.2.2). In diesem Zusammenhang hat das Wissen als Gegenstand vor allem im Rahmen wissenschaftlicher Diskurse Aufmerksamkeit erfahren. Relevante Fragen gesellschaftlicher Wissens-und Forschungsbezüge werden durch Wissenschaft aufgegriffen, bearbeitet und Erkenntnisgewinne mittlerweile unter Bedingungen und Erwartungen einer zunehmenden Medialisierung und Professionalisierung in die Öffentlichkeit zurückgespielt (Eisenegger &amp; Imhof, 2008;Marcinkowski &amp; Kohring, 2014;M. S. Schäfer, 2007). etwa der Dienstleistungsgesellschaft, der post-oder nach-industriellen Gesellschaft oder auch der Risikogesellschaft (Kübler, 2009).</p>
        <p>Mit Blick auf ein allgemeines Verständnis von Wissen und seines gesellschaftlichen Nutzens wurde hier vor allem der ökonomische Verwertungszusammenhang untersucht, wobei aufbauend auf Heidenreich (2003) vier dominante Perspektiven auf die Wissensgesellschaft unterschieden werden. Diese setzen dabei jeweils unterschiedliche Schwerpunkte der gesellschaftlichen Konsequenz von Wissen für Arbeit und Wirtschaft und leiten entsprechende Analysen an. Erstens wird hier ebenfalls auf die auch in dieser Arbeit vielbesprochenen IuK abgestellt, die der gesellschaftlichen Produktion, Verteilung und Verwertung von Wissen einen entscheidenden Schub gegeben haben. Zweitens wird Wissen "als wichtige Ursache wirtschaftlichen Wachstums -neben den klassischen Faktoren Kapital und Arbeit -eingeführt" (Heidenreich, 2003, S. 25)Mit Blick auf ein allgemeines Verständnis von Wissen und seines gesellschaftlichen Nutzens wurde hier vor allem der ökonomische Verwertungszusammenhang untersucht, wobei aufbauend auf Heidenreich (2003) vier dominante Perspektiven auf die Wissensgesellschaft unterschieden werden. Diese setzen dabei jeweils unterschiedliche Schwerpunkte der gesellschaftlichen Konsequenz von Wissen für Arbeit und Wirtschaft und leiten entsprechende Analysen an. Erstens wird hier ebenfalls auf die auch in dieser Arbeit vielbesprochenen IuK abgestellt, die der gesellschaftlichen Produktion, Verteilung und Verwertung von Wissen einen entscheidenden Schub gegeben haben. Zweitens wird Wissen "als wichtige Ursache wirtschaftlichen Wachstums -neben den klassischen Faktoren Kapital und Arbeit -eingeführt" (Heidenreich, 2003, S. 25)</p>
        <p>Auch wenn der erwartete Nutzen im Rahmen der Bedeutung des Wissens bereits durchgeklungen ist, muss die Verbindung der zentralen Elemente der vorliegenden Untersuchung, des Erkenntnis-und Nutzengewinns, vor dem Hintergrund der öffentlichen Wahrnehmung digitaler Datenverwertung erläutert und veranschaulicht werden. So ist an dieser Stelle zunächst die Bedeutung von Wissen mit Fokus auf Big Data vor aktuellen gesellschaftlichen Entwicklungen und hiermit verbundenen Nutzenerwartungen zu erörtern. Diese Nutzenerwartungen sollen hierbei mit Blick auf datenverarbeitende Wissensanwendungen anhand zweier Ebenen verdeutlicht werden: der Nutzen für das Individuum und der Nutzen für die Gesellschaft.Auch wenn der erwartete Nutzen im Rahmen der Bedeutung des Wissens bereits durchgeklungen ist, muss die Verbindung der zentralen Elemente der vorliegenden Untersuchung, des Erkenntnis-und Nutzengewinns, vor dem Hintergrund der öffentlichen Wahrnehmung digitaler Datenverwertung erläutert und veranschaulicht werden. So ist an dieser Stelle zunächst die Bedeutung von Wissen mit Fokus auf Big Data vor aktuellen gesellschaftlichen Entwicklungen und hiermit verbundenen Nutzenerwartungen zu erörtern. Diese Nutzenerwartungen sollen hierbei mit Blick auf datenverarbeitende Wissensanwendungen anhand zweier Ebenen verdeutlicht werden: der Nutzen für das Individuum und der Nutzen für die Gesellschaft.</p>
        <p>Dabei muss nun auch der Datenbegriff noch einmal aufgegriffen und präzisiert werden. Es ist nicht irgendeine Funktion der Daten und es sind auch nicht irgendwelche digitalen Daten, die hier mit Blick auf das Soziale relevant sind, sondern ihr Funktionsbezug der Bewertung und Verwertung. Digitale Daten ganz allgemein und nur für sich betrachtet sind zunächst nicht zwingend numerische Wertzuweisungen. Auch Texte, Bilder oder audiovisuelle Medien fallen zunächst unter den Datenbegriff, da sie mit Hilfe numerischer Werte in einer binär codierten Sequenz von Zustandsbeschreibungen von den IuK gespeichert und verarbeitet werden. Wenn allerdings im Zusammenhang mit Big Data als sozialem Phänomen von einer Datafizierung, Metrifizierung oder auch Quantifizierung der Gesellschaft oder des Sozialen gesprochen wird (Filipović, 2015;Holtzhausen, 2016;Mau, 2017;Merry, 2016;Passoth &amp; Wehner, 2013; M. T. Schäfer &amp; van Es, 2017) 1 , dann betrifft dies die Überführung realweltlich zu beobachtender Phänomene materieller oder immaterieller Natur in digitale Daten mit dem vorrangigen Ziel, diese so digitalisierten Entitäten zählbar voneinander unterscheidbar und somit vergleichbar sowie bewertbar zu machen (Hubbard, 2010). Der Zusammenhang der Bewertung und hiermit verbundener Vergleichung stellt dann neue Informationen über die Welt bereit, die Eingang in Wissenssysteme finden können. Auf diesem Wege kann nicht nur der Wissensbegriff mit Leben gefüllt werden, sondern gleichzeitig unter dem Vorzeichen einer gesamtgesellschaftlichen Bedeutung von Wissen auch dessen Nutzen diskutiert werden.Dabei muss nun auch der Datenbegriff noch einmal aufgegriffen und präzisiert werden. Es ist nicht irgendeine Funktion der Daten und es sind auch nicht irgendwelche digitalen Daten, die hier mit Blick auf das Soziale relevant sind, sondern ihr Funktionsbezug der Bewertung und Verwertung. Digitale Daten ganz allgemein und nur für sich betrachtet sind zunächst nicht zwingend numerische Wertzuweisungen. Auch Texte, Bilder oder audiovisuelle Medien fallen zunächst unter den Datenbegriff, da sie mit Hilfe numerischer Werte in einer binär codierten Sequenz von Zustandsbeschreibungen von den IuK gespeichert und verarbeitet werden. Wenn allerdings im Zusammenhang mit Big Data als sozialem Phänomen von einer Datafizierung, Metrifizierung oder auch Quantifizierung der Gesellschaft oder des Sozialen gesprochen wird (Filipović, 2015;Holtzhausen, 2016;Mau, 2017;Merry, 2016;Passoth &amp; Wehner, 2013; M. T. Schäfer &amp; van Es, 2017) 1 , dann betrifft dies die Überführung realweltlich zu beobachtender Phänomene materieller oder immaterieller Natur in digitale Daten mit dem vorrangigen Ziel, diese so digitalisierten Entitäten zählbar voneinander unterscheidbar und somit vergleichbar sowie bewertbar zu machen (Hubbard, 2010). Der Zusammenhang der Bewertung und hiermit verbundener Vergleichung stellt dann neue Informationen über die Welt bereit, die Eingang in Wissenssysteme finden können. Auf diesem Wege kann nicht nur der Wissensbegriff mit Leben gefüllt werden, sondern gleichzeitig unter dem Vorzeichen einer gesamtgesellschaftlichen Bedeutung von Wissen auch dessen Nutzen diskutiert werden.</p>
        <p>Quantifizierung meint hierbei zunächst eine Übersetzungsleistung oder wie Mau (2017) verdeutlicht: "Phänomene, Eigenschaften oder Beschaffenheiten eines Sachverhalts werden in einer allgemeinen, abstrakten und universell anschlussfähigen Sprache repräsentiert, der der Mathematik" (S. 27). Daten entstehen hier vor allem auch durch das Messen, also einer proaktiven 2 Erhebung von Daten, bei der entsprechend ein empirisches Relativ in ein numerisches Relativ überführt wird (Rössler, 2017;Schnell et al., 2018). Hierbei wird im Rahmen der Messung ein vorher festgelegtes Regelwerk herangezogen, so dass Messen konkret auch wie folgt verstanden wird (Stevens, 1946): "The assignment of numerals to objects or events according to rules" (S. 677). Allerdings geht es zumindest im Rahmen sozialwissenschaftlicher Fragestellungen genauer um die Eigenschaften der beobachteten Objekte oder Ereignisse, denen Zahlenwerte zugewiesen werden (Bandalos, 2017;Hand, 2016) Bewertungen auf Basis quantitativer Wertzuweisungslogik eröffnen durch die vorgeblich saubere mathematische Ordnung der Umwelt einen rationalen und übersichtlichen Zugang zu dieser (Mau, 2017) und gehen einher mit einem weitgefassten Bestreben nach formaler taxonomischer Ordnung sowie Standardisierung (Higgins &amp; Larner, 2010;Timmermans &amp; Epstein, 2010). So durchzieht das kontinuierliche Abzählen und Wertzuweisen durch Quantifizierung mittlerweile alle gesellschaftlichen Bereiche (Lamont, 2012;Power, 1997): Wie in Kapitel 3 deutlich geworden ist, sind es mithin bei weitem nicht nur staatliche Institutionen, die im Rahmen einer staatlichen Steuerungslogik für alles Mögliche Daten erheben, oder im Rahmen einer ökonomischen Verwertungslogik agierende Unternehmen, die Produktion, Absatz und Konsum von Produkten und Dienstleistungen verdaten und optimieren. Auch auf der Ebene des Individuums wird das Selbst im Rahmen des Self-Trackings der laufenden Datenerhebung unterworfen (siehe Abschnitt 3.3). Den vermeintlichen Nutzen gesellschaftlicher Quantifizierung in den Blick nehmend, wird mithin auf den funktionalen Charakter digital quantifizierter Wertzuschreibungen abgestellt werden, der Unterscheidungen des Disparaten ermöglicht (Nassehi, 2019). Hier sind unlängst etliche soziologische Erklärungsansätze entstanden, die allesamt auch auf die durch digitale Daten bedingte Unterscheidungs-und Vergleichslogik abstellen und die vorliegende empirische Analyse der Erkenntnis-und Nutzenerwartungen bezüglich digitaler Daten argumentativ vorbereiten (Heintz, 2010(Heintz, , 2016;;Mau, 2017;Nassehi, 2019;Reckwitz, 2017).Quantifizierung meint hierbei zunächst eine Übersetzungsleistung oder wie Mau (2017) verdeutlicht: "Phänomene, Eigenschaften oder Beschaffenheiten eines Sachverhalts werden in einer allgemeinen, abstrakten und universell anschlussfähigen Sprache repräsentiert, der der Mathematik" (S. 27). Daten entstehen hier vor allem auch durch das Messen, also einer proaktiven 2 Erhebung von Daten, bei der entsprechend ein empirisches Relativ in ein numerisches Relativ überführt wird (Rössler, 2017;Schnell et al., 2018). Hierbei wird im Rahmen der Messung ein vorher festgelegtes Regelwerk herangezogen, so dass Messen konkret auch wie folgt verstanden wird (Stevens, 1946): "The assignment of numerals to objects or events according to rules" (S. 677). Allerdings geht es zumindest im Rahmen sozialwissenschaftlicher Fragestellungen genauer um die Eigenschaften der beobachteten Objekte oder Ereignisse, denen Zahlenwerte zugewiesen werden (Bandalos, 2017;Hand, 2016) Bewertungen auf Basis quantitativer Wertzuweisungslogik eröffnen durch die vorgeblich saubere mathematische Ordnung der Umwelt einen rationalen und übersichtlichen Zugang zu dieser (Mau, 2017) und gehen einher mit einem weitgefassten Bestreben nach formaler taxonomischer Ordnung sowie Standardisierung (Higgins &amp; Larner, 2010;Timmermans &amp; Epstein, 2010). So durchzieht das kontinuierliche Abzählen und Wertzuweisen durch Quantifizierung mittlerweile alle gesellschaftlichen Bereiche (Lamont, 2012;Power, 1997): Wie in Kapitel 3 deutlich geworden ist, sind es mithin bei weitem nicht nur staatliche Institutionen, die im Rahmen einer staatlichen Steuerungslogik für alles Mögliche Daten erheben, oder im Rahmen einer ökonomischen Verwertungslogik agierende Unternehmen, die Produktion, Absatz und Konsum von Produkten und Dienstleistungen verdaten und optimieren. Auch auf der Ebene des Individuums wird das Selbst im Rahmen des Self-Trackings der laufenden Datenerhebung unterworfen (siehe Abschnitt 3.3). Den vermeintlichen Nutzen gesellschaftlicher Quantifizierung in den Blick nehmend, wird mithin auf den funktionalen Charakter digital quantifizierter Wertzuschreibungen abgestellt werden, der Unterscheidungen des Disparaten ermöglicht (Nassehi, 2019). Hier sind unlängst etliche soziologische Erklärungsansätze entstanden, die allesamt auch auf die durch digitale Daten bedingte Unterscheidungs-und Vergleichslogik abstellen und die vorliegende empirische Analyse der Erkenntnis-und Nutzenerwartungen bezüglich digitaler Daten argumentativ vorbereiten (Heintz, 2010(Heintz, , 2016;;Mau, 2017;Nassehi, 2019;Reckwitz, 2017).</p>
        <p>Zahlen als Grundlage von Bewertungen und Vergleichen Heintz (2010Heintz ( , 2016) ) Reckwitz (2017) an: "Die vier genannten Sorten von Praktiken sind nur heuristisch zu trennen, denn es ist möglich, dass sie eng miteinander verzahnt sind oder sogar miteinander kombiniert auftreten (so dass etwa in der gleichen Praxis hergestellt und rezipiert wird). Sie können auch hochgradig spezialisiert und ausdifferenziert nebeneinanderstehen und sich zu ganzen institutionellen Komplexen verdichten" (S. 64, Hervorh. im Orig.). Als ein solcher institutioneller Komplex ist die Quantifizierung des Sozialen mit Hilfe von Digitaltechnik zu verstehen.Zahlen als Grundlage von Bewertungen und Vergleichen Heintz (2010Heintz ( , 2016) ) Reckwitz (2017) an: "Die vier genannten Sorten von Praktiken sind nur heuristisch zu trennen, denn es ist möglich, dass sie eng miteinander verzahnt sind oder sogar miteinander kombiniert auftreten (so dass etwa in der gleichen Praxis hergestellt und rezipiert wird). Sie können auch hochgradig spezialisiert und ausdifferenziert nebeneinanderstehen und sich zu ganzen institutionellen Komplexen verdichten" (S. 64, Hervorh. im Orig.). Als ein solcher institutioneller Komplex ist die Quantifizierung des Sozialen mit Hilfe von Digitaltechnik zu verstehen.</p>
        <p>Auch wenn der Ansatz von Statuseinschätzung und Selbstvergewisserung sowie anschließender Verwertung womöglich nicht zu einer umfassenden und abschließenden Erklärung taugt, da diese selbst etwa unter den Vorzeichen übergeordneter kapitalistischer oder anderweitiger idiosynkratischer Logiken erklärungswürdig sind: 4 Die Konsequenz ist, dass ein jeder, der einen irgendwie gearteten Nutzen aus der Mustererkennung und der eigenen Positionsverortung mittels vergleichender Bewertung ziehen möchte, sich selbstredend selbst der Logik der umfassenden und standardisierten Evaluation unterwerfen muss und somit das Fortschreiten der gesellschaftlichen Prozesse dieser Valorisierung begünstigt (Lamont, 2012;Muniesa, 2012;Reckwitz, 2017). Wie Mau (2017) diesbezüglich resümiert: "Permanente Vermessung und Bewertung führen dazu, dass sich sowohl die Fremd-als auch die Selbststeuerungsleistungen intensivieren" (S. 13). Eine einmal festgestellte (Un-)Gleichheit informiert dann mithin Anschlusshandlungen als Reaktion auf die Differenzbeobachtungen, die aus der jeweiligen inhärenten situativen Vergleichslogik folgen. Beispielhaft zeigt sich dann im Spitzensport und der Wirtschaft, wer gerade zur Leistungselite zählt, in Kunst und Kultur kann festgestellt werden, welche Kunstschaffenden, Stile oder Werke gerade en vogue sind, und auch in der von der Wählergunst abhängigen Politik zeigt sich, welche politischen Programme und Personen aktuell reüssieren. Diesbezügliche Erkenntnisse lassen sich auch und insbesondere unter den Vorzeichen der Ökonomie recht wechselhafter Aufmerksamkeit (Franck, 1998;Schroer, 2014) entsprechend verwerten. So erhält der Hollywoodstar mit den meisten Likes den lukrativen Werbevertrag. Oder man ist vielleicht auch einfach nur eher geneigt ein Buch zu lesen, das bei eben jenen Leuten populär ist, die auch den eigenen Lieblingsroman positiv bewertet haben. In Analogie zu den zuvor beschriebenen Algorithmen werden die festgestellten Unterscheidungen und Bewertungen folglich im Rahmen von Entscheidungsprogrammen zur Lösung bereichsspezifischer Probleme herangezogen. Es kann dann vom Modus einer Zustandsfeststellung in den Modus des zielgerichteten Handelns mit dem Ziel der Zustandsveränderung gewechselt werden.Auch wenn der Ansatz von Statuseinschätzung und Selbstvergewisserung sowie anschließender Verwertung womöglich nicht zu einer umfassenden und abschließenden Erklärung taugt, da diese selbst etwa unter den Vorzeichen übergeordneter kapitalistischer oder anderweitiger idiosynkratischer Logiken erklärungswürdig sind: 4 Die Konsequenz ist, dass ein jeder, der einen irgendwie gearteten Nutzen aus der Mustererkennung und der eigenen Positionsverortung mittels vergleichender Bewertung ziehen möchte, sich selbstredend selbst der Logik der umfassenden und standardisierten Evaluation unterwerfen muss und somit das Fortschreiten der gesellschaftlichen Prozesse dieser Valorisierung begünstigt (Lamont, 2012;Muniesa, 2012;Reckwitz, 2017). Wie Mau (2017) diesbezüglich resümiert: "Permanente Vermessung und Bewertung führen dazu, dass sich sowohl die Fremd-als auch die Selbststeuerungsleistungen intensivieren" (S. 13). Eine einmal festgestellte (Un-)Gleichheit informiert dann mithin Anschlusshandlungen als Reaktion auf die Differenzbeobachtungen, die aus der jeweiligen inhärenten situativen Vergleichslogik folgen. Beispielhaft zeigt sich dann im Spitzensport und der Wirtschaft, wer gerade zur Leistungselite zählt, in Kunst und Kultur kann festgestellt werden, welche Kunstschaffenden, Stile oder Werke gerade en vogue sind, und auch in der von der Wählergunst abhängigen Politik zeigt sich, welche politischen Programme und Personen aktuell reüssieren. Diesbezügliche Erkenntnisse lassen sich auch und insbesondere unter den Vorzeichen der Ökonomie recht wechselhafter Aufmerksamkeit (Franck, 1998;Schroer, 2014) entsprechend verwerten. So erhält der Hollywoodstar mit den meisten Likes den lukrativen Werbevertrag. Oder man ist vielleicht auch einfach nur eher geneigt ein Buch zu lesen, das bei eben jenen Leuten populär ist, die auch den eigenen Lieblingsroman positiv bewertet haben. In Analogie zu den zuvor beschriebenen Algorithmen werden die festgestellten Unterscheidungen und Bewertungen folglich im Rahmen von Entscheidungsprogrammen zur Lösung bereichsspezifischer Probleme herangezogen. Es kann dann vom Modus einer Zustandsfeststellung in den Modus des zielgerichteten Handelns mit dem Ziel der Zustandsveränderung gewechselt werden.</p>
        <p>Zunächst ist jedoch näher auf die IuK als Motor globaler Vergleichshorizonte einzugehen. IuK und die durch sie produzierten digitalen Daten eignen sich hierbei aufgrund ihrer immanenten mathematischen Übersetzungsleistung besonders auch für einen zu automatisierenden fortlaufenden Einsatz im Funktionszusammenhang der gesellschaftlichen Quantifizierung. Sie wirken somit vereinfachend auf die umfangreiche Fortentwicklung und Ausbreitung gesellschaftlicher Quantifizierung des Sozialen, da sie in besonderem Maße den an diesen Vergleichszusammenhang gestellten Anforderungen genügen:Zunächst ist jedoch näher auf die IuK als Motor globaler Vergleichshorizonte einzugehen. IuK und die durch sie produzierten digitalen Daten eignen sich hierbei aufgrund ihrer immanenten mathematischen Übersetzungsleistung besonders auch für einen zu automatisierenden fortlaufenden Einsatz im Funktionszusammenhang der gesellschaftlichen Quantifizierung. Sie wirken somit vereinfachend auf die umfangreiche Fortentwicklung und Ausbreitung gesellschaftlicher Quantifizierung des Sozialen, da sie in besonderem Maße den an diesen Vergleichszusammenhang gestellten Anforderungen genügen:</p>
        <p>Das Entstehen eines überlokalen, universalistischen Vergleichszusammenhangs setzt 1) die kontinuierliche Produktion öffentlicher Vergleichsereignisse voraus, denn nur dann kann kontinuierlich verglichen und laufend zwischen unterschiedlichen Vergleichsresultaten differenziert werden; sie setzt 2) die Herstellung von Vergleichbarkeit dieser Vergleichsereignisse jenseits ihrer lokalen Entstehungskontexte voraus, denn nur was unter bestimmten Gesichtspunkten plausibel als gleich beschrieben werden kann, kann unter anderen Gesichtspunkten plausibel als ungleich beschrieben werden; schließlich setzt es 3) die Etablierung von Vergleichskriterien voraus, die die Ereignisse in einen übergreifenden Vergleichszusammenhang integrieren. Gleichzeitig wird damit die Möglichkeit geschaffen, Ereignisse auf einer Zeitachse einzuordnen und sie mit anderen, vergangenen und zukünftigen Vergleichen in Beziehung zu setzen. (Heintz &amp; Werron, 2011, S. 365) So zeigt sich auch diesbezüglich die vermeintliche Leistungsfähigkeit digitaler Technik und hiermit einhergehender Entstehung und Verwertung digitaler Daten. Anstatt, dass Unterscheidungen und hierauf aufbauende Vergleiche laufend durch den Menschen getroffen und verarbeitet werden müssen, wird die kalkulative Praxis an die IuK ausgelagert und durch datenverarbeitende Algorithmen in standardisierter Form festgeschrieben, was eine gleichbleibende Qualität der Vergleiche in Datenform, ihrer Verarbeitung und der produzierten Ergebnisse verspricht. Mit der Konsequenz, dass dieses ‚Erfolgsmodell' selbstredend auch Vergleiche jenseits nationalstaatlicher Grenzen zulässt oder vielmehr erfordert. Die Logik von Wertzuweisungs-und Vergleichsprozessen gepaart mit den Nutzungsmöglichkeiten der IuK hat eine grenzüberschreitende Anziehungskraft und die Durchsetzung des Vergleichs ist diesbezüglich auch als Voraussetzung und Treiber von Globalisierungstendenzen zu analysieren und kann zum Verständnis von global übergreifenden Entwicklungen in unterschiedlichen gesellschaftlichen Feldern herangezogen werden (Bühler &amp; Heintz, 2017;Heintz, 2012;Heintz &amp; Werron, 2011). Wie bereits aufgezeigt, ist der Preis für Einsichten der verheißungsvollen Selbstverortung für alle Teilnehmenden gleich und besteht in einer Unterwerfung unter das Regelwerk von Standardisierung und Quantifizierung, das individuelle Eigentümlichkeiten ignoriert (Mau, 2017). So demonstrieren Heintz und Werron (2011) die Möglichkeit von Globalisierung durch die Entstehung globaler Vergleichshorizonte insbesondere am Beispiel der Wissenschaft und des Spitzensports. Doch gibt es auch in vielen anderen gesellschaftlichen Teilbereichen mittlerweile global institutionalisierte Vergleichslogiken (Blank, 2007;Erdi, 2019;Espeland &amp; Sauder, 2007;Ringel &amp; Werron, 2019;Sauder &amp; Espeland, 2009).Das Entstehen eines überlokalen, universalistischen Vergleichszusammenhangs setzt 1) die kontinuierliche Produktion öffentlicher Vergleichsereignisse voraus, denn nur dann kann kontinuierlich verglichen und laufend zwischen unterschiedlichen Vergleichsresultaten differenziert werden; sie setzt 2) die Herstellung von Vergleichbarkeit dieser Vergleichsereignisse jenseits ihrer lokalen Entstehungskontexte voraus, denn nur was unter bestimmten Gesichtspunkten plausibel als gleich beschrieben werden kann, kann unter anderen Gesichtspunkten plausibel als ungleich beschrieben werden; schließlich setzt es 3) die Etablierung von Vergleichskriterien voraus, die die Ereignisse in einen übergreifenden Vergleichszusammenhang integrieren. Gleichzeitig wird damit die Möglichkeit geschaffen, Ereignisse auf einer Zeitachse einzuordnen und sie mit anderen, vergangenen und zukünftigen Vergleichen in Beziehung zu setzen. (Heintz &amp; Werron, 2011, S. 365) So zeigt sich auch diesbezüglich die vermeintliche Leistungsfähigkeit digitaler Technik und hiermit einhergehender Entstehung und Verwertung digitaler Daten. Anstatt, dass Unterscheidungen und hierauf aufbauende Vergleiche laufend durch den Menschen getroffen und verarbeitet werden müssen, wird die kalkulative Praxis an die IuK ausgelagert und durch datenverarbeitende Algorithmen in standardisierter Form festgeschrieben, was eine gleichbleibende Qualität der Vergleiche in Datenform, ihrer Verarbeitung und der produzierten Ergebnisse verspricht. Mit der Konsequenz, dass dieses ‚Erfolgsmodell' selbstredend auch Vergleiche jenseits nationalstaatlicher Grenzen zulässt oder vielmehr erfordert. Die Logik von Wertzuweisungs-und Vergleichsprozessen gepaart mit den Nutzungsmöglichkeiten der IuK hat eine grenzüberschreitende Anziehungskraft und die Durchsetzung des Vergleichs ist diesbezüglich auch als Voraussetzung und Treiber von Globalisierungstendenzen zu analysieren und kann zum Verständnis von global übergreifenden Entwicklungen in unterschiedlichen gesellschaftlichen Feldern herangezogen werden (Bühler &amp; Heintz, 2017;Heintz, 2012;Heintz &amp; Werron, 2011). Wie bereits aufgezeigt, ist der Preis für Einsichten der verheißungsvollen Selbstverortung für alle Teilnehmenden gleich und besteht in einer Unterwerfung unter das Regelwerk von Standardisierung und Quantifizierung, das individuelle Eigentümlichkeiten ignoriert (Mau, 2017). So demonstrieren Heintz und Werron (2011) die Möglichkeit von Globalisierung durch die Entstehung globaler Vergleichshorizonte insbesondere am Beispiel der Wissenschaft und des Spitzensports. Doch gibt es auch in vielen anderen gesellschaftlichen Teilbereichen mittlerweile global institutionalisierte Vergleichslogiken (Blank, 2007;Erdi, 2019;Espeland &amp; Sauder, 2007;Ringel &amp; Werron, 2019;Sauder &amp; Espeland, 2009).</p>
        <p>Damit Vergleiche hier ihre globalgesellschaftliche Wirkmächtigkeit entfalten können, müssen sie zunächst weitläufig kommuniziert werden. Der Vergleich darf also nicht nur auf der mentalen Ebene verbleiben, sondern muss in einer sozialen Situation durch Kommunikation Eingang finden (Heintz, 2016). Denn nur, wenn Wissen um Differenz auf Grundlage eines Vergleichs dem breiten öffentlichen Diskurs zugeführt wird, entfaltet er gesellschaftliche Folgen. So blieben Hochschulrankings folgenlos, wenn nur wenige oder gar niemand von ihnen lesen oder erfahren würde, wenn sie also keinen Eingang in die mediale Berichterstattung oder die externe Kommunikation der Hochschulen selbst fänden (Heintz &amp; Werron, 2011). Erst wenn sie der öffentlichen Debatte zugeführt werden, können sie Bedeutung erhalten und führen dazu, dass Studierende, Forschende und andere Beteiligte sich in ihrem Handeln an ihnen orientieren. Dies drückt sich dann bspw. in der Entscheidung aus, sich aufgrund eines festgestellten Unterschieds in der Qualität von Forschung und Lehre an Hochschule A zu bewerben und nicht an Hochschule B.Damit Vergleiche hier ihre globalgesellschaftliche Wirkmächtigkeit entfalten können, müssen sie zunächst weitläufig kommuniziert werden. Der Vergleich darf also nicht nur auf der mentalen Ebene verbleiben, sondern muss in einer sozialen Situation durch Kommunikation Eingang finden (Heintz, 2016). Denn nur, wenn Wissen um Differenz auf Grundlage eines Vergleichs dem breiten öffentlichen Diskurs zugeführt wird, entfaltet er gesellschaftliche Folgen. So blieben Hochschulrankings folgenlos, wenn nur wenige oder gar niemand von ihnen lesen oder erfahren würde, wenn sie also keinen Eingang in die mediale Berichterstattung oder die externe Kommunikation der Hochschulen selbst fänden (Heintz &amp; Werron, 2011). Erst wenn sie der öffentlichen Debatte zugeführt werden, können sie Bedeutung erhalten und führen dazu, dass Studierende, Forschende und andere Beteiligte sich in ihrem Handeln an ihnen orientieren. Dies drückt sich dann bspw. in der Entscheidung aus, sich aufgrund eines festgestellten Unterschieds in der Qualität von Forschung und Lehre an Hochschule A zu bewerben und nicht an Hochschule B.</p>
        <p>Vor allem Entwicklungen auf der technologischen und organisationalen Ebene -und hier insbesondere die internationale Ausweitung massenmedialer Kommunikation -begünstigten die Ausdehnung von Vergleichshorizonten. Ein illustratives Beispiel für die Verbreitung der Vergleichslogik im Sport liefern Heintz und Werron (2011)Vor allem Entwicklungen auf der technologischen und organisationalen Ebene -und hier insbesondere die internationale Ausweitung massenmedialer Kommunikation -begünstigten die Ausdehnung von Vergleichshorizonten. Ein illustratives Beispiel für die Verbreitung der Vergleichslogik im Sport liefern Heintz und Werron (2011)</p>
        <p>Im Rahmen der Ausdehnung der Quantifizierung des Sozialen und der Entstehung und Verwertung entsprechender digitaler Datenbestände wird in der Literatur vielfach diskutiert, inwieweit die zuvor skizzierten Entwicklungen nun auch menschliche Vorstellungen von Realität und sozialer Wirklichkeit formen. In einem nun nachfolgend zu beschreibenden Wahrnehmungsmuster von Big Data fügen sich die in den vorangegangenen Kapiteln angesprochenen Ausführungen zusammen und es wird herausgearbeitet wie eine entsprechende Wahrnehmung aussehen und welche Folgen für eine Erwartungshaltung bezüglich der Quantifizierung sie haben könnte. Mit der Verfügung über immer mehr Daten begibt sich die Gesellschaft auf den Weg zu einer datengetriebenen Prüf-, Kontroll-und Bewertungsgesellschaft, die nur noch das glaubt, was in Zahlen vorliegt. Soziale Selbsterkenntnis und Regulierung beziehen sich inzwischen so intensiv auf Daten, dass das Erkennen dessen, was ist, ohne sie kaum mehr möglich erscheint. (S. 46) Eine durch Big Data geprägte Weltsicht kann dahingehend charakterisiert werden, als dass in der durch IuK angetriebenen kalkulativen sozialen Praxis der Quantifizierung des Sozialen überaus großes Potential für Erkenntnis-und Nutzengewinne gesehen wird. Diese Weltsicht ist also durch eben jene Potentiale von Big Data geprägt, die in Abschnitt 3.5 im Rahmen der sozio-technischen Betrachtung digitaler Datenbestände als konsequentiell-evaluative Dimensionen von Big Data besprochen wurden. Die zuvor thematisierten Versprechungen und Idealvorstellungen der Qualitäten von digitalen Daten werden dabei kommunikativ weiterverbreitet und weitgehend von der Bevölkerung übernommen. Ein Mythos lebt mithin davon, dass man ihn sich selbst und anderen immer wieder erzählt und seine wesentlichen Aussagen dabei beständig und affirmierend wiederholt werden (Barthes, 1964).Im Rahmen der Ausdehnung der Quantifizierung des Sozialen und der Entstehung und Verwertung entsprechender digitaler Datenbestände wird in der Literatur vielfach diskutiert, inwieweit die zuvor skizzierten Entwicklungen nun auch menschliche Vorstellungen von Realität und sozialer Wirklichkeit formen. In einem nun nachfolgend zu beschreibenden Wahrnehmungsmuster von Big Data fügen sich die in den vorangegangenen Kapiteln angesprochenen Ausführungen zusammen und es wird herausgearbeitet wie eine entsprechende Wahrnehmung aussehen und welche Folgen für eine Erwartungshaltung bezüglich der Quantifizierung sie haben könnte. Mit der Verfügung über immer mehr Daten begibt sich die Gesellschaft auf den Weg zu einer datengetriebenen Prüf-, Kontroll-und Bewertungsgesellschaft, die nur noch das glaubt, was in Zahlen vorliegt. Soziale Selbsterkenntnis und Regulierung beziehen sich inzwischen so intensiv auf Daten, dass das Erkennen dessen, was ist, ohne sie kaum mehr möglich erscheint. (S. 46) Eine durch Big Data geprägte Weltsicht kann dahingehend charakterisiert werden, als dass in der durch IuK angetriebenen kalkulativen sozialen Praxis der Quantifizierung des Sozialen überaus großes Potential für Erkenntnis-und Nutzengewinne gesehen wird. Diese Weltsicht ist also durch eben jene Potentiale von Big Data geprägt, die in Abschnitt 3.5 im Rahmen der sozio-technischen Betrachtung digitaler Datenbestände als konsequentiell-evaluative Dimensionen von Big Data besprochen wurden. Die zuvor thematisierten Versprechungen und Idealvorstellungen der Qualitäten von digitalen Daten werden dabei kommunikativ weiterverbreitet und weitgehend von der Bevölkerung übernommen. Ein Mythos lebt mithin davon, dass man ihn sich selbst und anderen immer wieder erzählt und seine wesentlichen Aussagen dabei beständig und affirmierend wiederholt werden (Barthes, 1964).</p>
        <p>Der Mythos Big Data bezieht sich in seiner originären Beschreibung bei boyd und Crawford (2012) zunächst lediglich auf die epistemische Qualität der Daten und ihre Konsequenz für die Möglichkeiten von Wissen.Der Mythos Big Data bezieht sich in seiner originären Beschreibung bei boyd und Crawford (2012) zunächst lediglich auf die epistemische Qualität der Daten und ihre Konsequenz für die Möglichkeiten von Wissen.</p>
        <p>Big data, it is implied, is the source of a different order of knowledge, a step change in human self-understanding that precisely bypasses humans' meagre attempts at selfunderstanding through interpreting the local details of what they think, say and do. (Couldry, 2017, S. 235) Die besondere Qualität von Big Data baut also auf der in Abschnitt 4. Insbesondere mit Blick auf Self-Tracking diskutieren Sharon und Zandbergen (2016) den Vorwurf eines innerhalb der Quantified-Self-Bewegung vorherrschenden Daten-Fetischismus, der von ihnen wie folgt charakterisiert wird: "The widespread idea that what draws self-trackers to numerical data is its perceived power of truth and objectivity" (S. 1695). Die besondere epistemische Qualität von digitalen Daten und deren Bedeutung für Wissen sind im Umkehrschluss auch von wesentlicher Bedeutung für die Wahrnehmung von Big Data: Es kann am besten auf Grundlage digitaler Daten gewusst werden, so dass alles, was und worüber gewusst werden soll, in digitale Daten überführt werden muss.Big data, it is implied, is the source of a different order of knowledge, a step change in human self-understanding that precisely bypasses humans' meagre attempts at selfunderstanding through interpreting the local details of what they think, say and do. (Couldry, 2017, S. 235) Die besondere Qualität von Big Data baut also auf der in Abschnitt 4. Insbesondere mit Blick auf Self-Tracking diskutieren Sharon und Zandbergen (2016) den Vorwurf eines innerhalb der Quantified-Self-Bewegung vorherrschenden Daten-Fetischismus, der von ihnen wie folgt charakterisiert wird: "The widespread idea that what draws self-trackers to numerical data is its perceived power of truth and objectivity" (S. 1695). Die besondere epistemische Qualität von digitalen Daten und deren Bedeutung für Wissen sind im Umkehrschluss auch von wesentlicher Bedeutung für die Wahrnehmung von Big Data: Es kann am besten auf Grundlage digitaler Daten gewusst werden, so dass alles, was und worüber gewusst werden soll, in digitale Daten überführt werden muss.</p>
        <p>Mit dem Verwertungs-und Steuerungspotential von Daten verbunden ist also weiterhin die Erwartung an einen Nutzen, welcher sich, wie gezeigt, auf unterschiedlichen Ebenen zwischen Individuum und Kollektiv manifestieren kann. Dabei ist der konkrete Nutzen zwar bereichsspezifisch jeweils völlig anders geartet, in seiner Valenz jedoch durchweg positiv. In Fragen der Mobilität ist ein Nutzen aus Datensammlung und -auswertung also anders gelagert als in der Medizin oder der Wirtschaft, jedoch ist er immer als Gewinn verstanden. Die positive Färbung ist, wie gezeigt, zum einen bedingt durch das Entstehen und die Förderung digitaler Datentechnik und IuK im wissenschaftlich-industriellen Komplex, welcher ein besonderes Interesse an der Hervorhebung ihrer Vorteile hat. Zum anderen wird sie jedoch auch allen Mitgliedern der Gesellschaft zugeschrieben. Diesen attestiert Schirrmacher (2009) einen "Wahn, aus Angst vor Kontrollverlust die Welt in Formeln, Systematiken und Algorithmen, kurzum in Mathematik zu verwandeln. Wir werden immer unfähiger, mit Unsicherheiten und Unwahrscheinlichkeiten umzugehen (…)" (S. 32). Als Ergebnis führen der Umgang mit dem Computer und die Auslagerung des Denkens und Entscheidens an die Digitaltechnik dazu, dass sich der menschliche Denkapparat verwandelt (Schirrmacher, 2009). Die gewichtige Konsequenz, die sich aus der Kombination wahrgenommener Erkenntnis-und Nutzenpotentiale der Daten in der Folge ergibt: "Wir erleben gerade in Echtzeit, wie eine Gesellschaft unwiderruflich die Fundamente ihres Weltbildes ändert" (Schirrmacher, 2009, S. 221).Mit dem Verwertungs-und Steuerungspotential von Daten verbunden ist also weiterhin die Erwartung an einen Nutzen, welcher sich, wie gezeigt, auf unterschiedlichen Ebenen zwischen Individuum und Kollektiv manifestieren kann. Dabei ist der konkrete Nutzen zwar bereichsspezifisch jeweils völlig anders geartet, in seiner Valenz jedoch durchweg positiv. In Fragen der Mobilität ist ein Nutzen aus Datensammlung und -auswertung also anders gelagert als in der Medizin oder der Wirtschaft, jedoch ist er immer als Gewinn verstanden. Die positive Färbung ist, wie gezeigt, zum einen bedingt durch das Entstehen und die Förderung digitaler Datentechnik und IuK im wissenschaftlich-industriellen Komplex, welcher ein besonderes Interesse an der Hervorhebung ihrer Vorteile hat. Zum anderen wird sie jedoch auch allen Mitgliedern der Gesellschaft zugeschrieben. Diesen attestiert Schirrmacher (2009) einen "Wahn, aus Angst vor Kontrollverlust die Welt in Formeln, Systematiken und Algorithmen, kurzum in Mathematik zu verwandeln. Wir werden immer unfähiger, mit Unsicherheiten und Unwahrscheinlichkeiten umzugehen (…)" (S. 32). Als Ergebnis führen der Umgang mit dem Computer und die Auslagerung des Denkens und Entscheidens an die Digitaltechnik dazu, dass sich der menschliche Denkapparat verwandelt (Schirrmacher, 2009). Die gewichtige Konsequenz, die sich aus der Kombination wahrgenommener Erkenntnis-und Nutzenpotentiale der Daten in der Folge ergibt: "Wir erleben gerade in Echtzeit, wie eine Gesellschaft unwiderruflich die Fundamente ihres Weltbildes ändert" (Schirrmacher, 2009, S. 221).</p>
        <p>Für Nassehi (2019) hingegen verändert die fortschreitende Digitalisierung nicht eben jenes gesellschaftliche Fundament, sondern ist ein elementarer Teil dessen: Sie ist für ihn "nicht nur eine soziale Erscheinung (…), sondern sogar ein soziologisches Projekt" (S. 18, Hervorh. im Orig.). So wie im Rahmen der Quantifizierung des Sozialen der empirische Ansatz des Messens zur sozialen Praxis wird, ist "vieles von dem, was die Digitalisierung betreibt, (…) von geradezu soziologischer Denkungsart: Sie nutzt soziale Strukturen, sie macht soziale Dynamiken sichtbar und sie erzeugt aus diesen Formen der Mustererkennung ihren Mehrwert" (S. 18). Digitalisierung sei "unmittelbar verwandt (…) mit der gesellschaftlichen Struktur" (S. 18, Hervorh. im Orig.). Die Möglichkeiten, Muster und Strukturen mit Hilfe von Digitaltechnik sichtbar zu machen, fallen eben daher auf so fruchtbaren Boden, da sie bereits auf eine entsprechende Erwartungsstruktur der Gesellschaft treffen -diese ist mithin nicht Konsequenz, sondern Bedingung von Digitalisierung.Für Nassehi (2019) hingegen verändert die fortschreitende Digitalisierung nicht eben jenes gesellschaftliche Fundament, sondern ist ein elementarer Teil dessen: Sie ist für ihn "nicht nur eine soziale Erscheinung (…), sondern sogar ein soziologisches Projekt" (S. 18, Hervorh. im Orig.). So wie im Rahmen der Quantifizierung des Sozialen der empirische Ansatz des Messens zur sozialen Praxis wird, ist "vieles von dem, was die Digitalisierung betreibt, (…) von geradezu soziologischer Denkungsart: Sie nutzt soziale Strukturen, sie macht soziale Dynamiken sichtbar und sie erzeugt aus diesen Formen der Mustererkennung ihren Mehrwert" (S. 18). Digitalisierung sei "unmittelbar verwandt (…) mit der gesellschaftlichen Struktur" (S. 18, Hervorh. im Orig.). Die Möglichkeiten, Muster und Strukturen mit Hilfe von Digitaltechnik sichtbar zu machen, fallen eben daher auf so fruchtbaren Boden, da sie bereits auf eine entsprechende Erwartungsstruktur der Gesellschaft treffen -diese ist mithin nicht Konsequenz, sondern Bedingung von Digitalisierung.</p>
        <p>Ganz gleich, welche Vorbedingungen, Ursachen oder konkreten Änderungen des Denkens und Beobachtens in Zusammenhang mit Big Data diagnostiziert werden: In der Literatur wird eine aus der Wahrnehmung der Digitalisierung abgeleitete Erwartungshaltung immer schon unter dem Vorzeichen ihrer bereits manifesten, meist negativen Konsequenzen für Individuum und Gesellschaft diskutiert. Es wird mithin nicht nur vor den Risiken und Gefahren selbst gewarnt, die mit dem unhinterfragten Einsatz der Systeme einhergehen (Eubanks, 2018;Zuboff, 2019) und sich aus den negativen Konsequenzen der Quantifizierung für Individuum und Gesellschaft ergeben (Muller, 2019;O'Neil, 2017;Tufekci, 2015). Es wird auch konkret vor einer kollektiven Mentalität gewarnt, die sich aus der stetigen Wiederholung der Ansprüche an datenbasiertes Wissen ergibt und die eine kritische Analyse und Reflexion der gesellschaftlichen Diffusion von Techniken der Quantifizierung verhindert oder zumindest erschwert (Mau, 2017;Merry, 2016;Schirrmacher, 2009). Für einen Daten-Fetischismus gilt dann bspw.: "As it seeks to reduce all phenomena and means of accounting for phenomena to numbers, it simultaneously displaces other less easily quantifiable albeit insightful ways of expressing phenomena" (Sharon &amp; Zandbergen, 2016, S. 1698, Hervorh. im Orig.).Ganz gleich, welche Vorbedingungen, Ursachen oder konkreten Änderungen des Denkens und Beobachtens in Zusammenhang mit Big Data diagnostiziert werden: In der Literatur wird eine aus der Wahrnehmung der Digitalisierung abgeleitete Erwartungshaltung immer schon unter dem Vorzeichen ihrer bereits manifesten, meist negativen Konsequenzen für Individuum und Gesellschaft diskutiert. Es wird mithin nicht nur vor den Risiken und Gefahren selbst gewarnt, die mit dem unhinterfragten Einsatz der Systeme einhergehen (Eubanks, 2018;Zuboff, 2019) und sich aus den negativen Konsequenzen der Quantifizierung für Individuum und Gesellschaft ergeben (Muller, 2019;O'Neil, 2017;Tufekci, 2015). Es wird auch konkret vor einer kollektiven Mentalität gewarnt, die sich aus der stetigen Wiederholung der Ansprüche an datenbasiertes Wissen ergibt und die eine kritische Analyse und Reflexion der gesellschaftlichen Diffusion von Techniken der Quantifizierung verhindert oder zumindest erschwert (Mau, 2017;Merry, 2016;Schirrmacher, 2009). Für einen Daten-Fetischismus gilt dann bspw.: "As it seeks to reduce all phenomena and means of accounting for phenomena to numbers, it simultaneously displaces other less easily quantifiable albeit insightful ways of expressing phenomena" (Sharon &amp; Zandbergen, 2016, S. 1698, Hervorh. im Orig.).</p>
        <p>Die Wahrnehmung bezüglich der Potentiale von IuK für Wissen, Verstehen, Denken und hierauf begründeten Nutzen ist dort, wo sie angesprochen wird, also immer schon präsent. Diese Diagnose der Konsequenz kalkulativer Praktiken schließt dabei an eine lange Tradition von Beschreibungen und Warnungen bezüglich vermeintlich weit verbreiteter irrationaler Wahrnehmungsmuster technokratischer gesellschaftlicher Steuerungslogik an, die sich bspw. bereits in den Arbeiten von Arendt (1972) und Roszak (1995) finden lassen. So kritisiert Arendt (1972) die Denkmuster der Entscheidungstragenden innerhalb des Pentagons im Zuge des Vietnamkrieges: "The problem-solvers did not judge; they calculated. (…) An utterly irrational confidence in the calculability of reality, becomes the leitmotif of the decision-making processes (…)" (S. 37-39, Hervorh. im Orig.). Roszak (1995) skizziert diese spezifische Logik einer von ihm analysierten technokratischen Gesellschaft demnach wie folgt:Die Wahrnehmung bezüglich der Potentiale von IuK für Wissen, Verstehen, Denken und hierauf begründeten Nutzen ist dort, wo sie angesprochen wird, also immer schon präsent. Diese Diagnose der Konsequenz kalkulativer Praktiken schließt dabei an eine lange Tradition von Beschreibungen und Warnungen bezüglich vermeintlich weit verbreiteter irrationaler Wahrnehmungsmuster technokratischer gesellschaftlicher Steuerungslogik an, die sich bspw. bereits in den Arbeiten von Arendt (1972) und Roszak (1995) finden lassen. So kritisiert Arendt (1972) die Denkmuster der Entscheidungstragenden innerhalb des Pentagons im Zuge des Vietnamkrieges: "The problem-solvers did not judge; they calculated. (…) An utterly irrational confidence in the calculability of reality, becomes the leitmotif of the decision-making processes (…)" (S. 37-39, Hervorh. im Orig.). Roszak (1995) skizziert diese spezifische Logik einer von ihm analysierten technokratischen Gesellschaft demnach wie folgt:</p>
        <p>[A] society in which those who govern justify themselves by appeal to technical experts who, in turn, justify themselves by appeal to scientific forms of knowledge. And beyond the authority of science, there is no appeal. (…) Its assumptions about reality and its values become as unobtrusively pervasive as the air we breathe. (S. 7-8) Auch hier steht der vermeintliche evidenzgetriebene Erkenntnisgewinn, das, was als scientific form of knowledge beschrieben wird, im Mittelpunkt gesellschaftlicher Wahrnehmungsmuster und prägt eine Erwartungshaltung bezüglich der Entscheidungspraktiken innerhalb der eingangs beschriebenen Wissensgesellschaft. Diese findet nun unter den Vorzeichen von Computertechnik und digitaler Daten verstärkt Widerhall. Weizenbaum (1976) thematisiert dieses technokratische Weltbild entsprechend früh mit Blick auf die aufkommende Computerisierung: "The introduction of computers into our already highly technological society has […] merely reinforced and amplified those antecedent pressures that have driven man to an ever more highly rationalistic view of his society and an ever more mechanistic image of himself" (S. 11). Er beschreibt dabei sein Erstaunen über die fehlende menschliche Einsicht zu reflektieren, zu welchem Denken eine Maschine den Menschen befähigt, der die Maschine zum Denken befähigt (vgl. auch Turkle, 1984). Die Konsequenz, den ein maschinenzentrierter Blick auf Vorstellungen der Denkprozesse von Mensch und Computer im Vergleich zu einem menschenzentrierten Blick hat, wird in der Folge von Norman (1993) Dass Daten zur Leitwährung des gesellschaftlichen Selbstbeobachtungs-und Selbstbeschreibungsgeschäfts geworden sind, ist allzu offensichtlich. Inwieweit sie andere Beschreibungs-und Beurteilungsformen des Sozialen nicht nur marginalisieren, sondern vollständig zu verdrängen vermögen, ist bislang eine offene Frage. Mit der Durchsetzung der Quantifizierung werden wir aber -mehr oder weniger -zu Gläubigen in der Kirche der Zahlen. (S. 47) Diese deterministisch anmutende Sichtweise, bei der eine eingangs skizzierte Wahrnehmung der Quantifizierung des Sozialen zu einer entsprechenden Erwartungshaltung führt, greift meiner Ansicht nach zu kurz. Erst muss der Versuch unternommen werden, etwas über das Vorhandensein entsprechender Annahmen und Erwartungen -oder das, was Mau auch als einen Glauben bezeichnetzu erfahren. Es muss also zunächst die tatsächliche Struktur und Ausprägung der Überzeugungen bezüglich der gewonnenen Erkenntnis und des Nutzens aus der Quantifizierung analysiert werden, bevor das Vorhandensein einer kollektiven Mentalität faktisch angenommen und etwaige Auswirkungen dieser untersucht werden können.[A] society in which those who govern justify themselves by appeal to technical experts who, in turn, justify themselves by appeal to scientific forms of knowledge. And beyond the authority of science, there is no appeal. (…) Its assumptions about reality and its values become as unobtrusively pervasive as the air we breathe. (S. 7-8) Auch hier steht der vermeintliche evidenzgetriebene Erkenntnisgewinn, das, was als scientific form of knowledge beschrieben wird, im Mittelpunkt gesellschaftlicher Wahrnehmungsmuster und prägt eine Erwartungshaltung bezüglich der Entscheidungspraktiken innerhalb der eingangs beschriebenen Wissensgesellschaft. Diese findet nun unter den Vorzeichen von Computertechnik und digitaler Daten verstärkt Widerhall. Weizenbaum (1976) thematisiert dieses technokratische Weltbild entsprechend früh mit Blick auf die aufkommende Computerisierung: "The introduction of computers into our already highly technological society has […] merely reinforced and amplified those antecedent pressures that have driven man to an ever more highly rationalistic view of his society and an ever more mechanistic image of himself" (S. 11). Er beschreibt dabei sein Erstaunen über die fehlende menschliche Einsicht zu reflektieren, zu welchem Denken eine Maschine den Menschen befähigt, der die Maschine zum Denken befähigt (vgl. auch Turkle, 1984). Die Konsequenz, den ein maschinenzentrierter Blick auf Vorstellungen der Denkprozesse von Mensch und Computer im Vergleich zu einem menschenzentrierten Blick hat, wird in der Folge von Norman (1993) Dass Daten zur Leitwährung des gesellschaftlichen Selbstbeobachtungs-und Selbstbeschreibungsgeschäfts geworden sind, ist allzu offensichtlich. Inwieweit sie andere Beschreibungs-und Beurteilungsformen des Sozialen nicht nur marginalisieren, sondern vollständig zu verdrängen vermögen, ist bislang eine offene Frage. Mit der Durchsetzung der Quantifizierung werden wir aber -mehr oder weniger -zu Gläubigen in der Kirche der Zahlen. (S. 47) Diese deterministisch anmutende Sichtweise, bei der eine eingangs skizzierte Wahrnehmung der Quantifizierung des Sozialen zu einer entsprechenden Erwartungshaltung führt, greift meiner Ansicht nach zu kurz. Erst muss der Versuch unternommen werden, etwas über das Vorhandensein entsprechender Annahmen und Erwartungen -oder das, was Mau auch als einen Glauben bezeichnetzu erfahren. Es muss also zunächst die tatsächliche Struktur und Ausprägung der Überzeugungen bezüglich der gewonnenen Erkenntnis und des Nutzens aus der Quantifizierung analysiert werden, bevor das Vorhandensein einer kollektiven Mentalität faktisch angenommen und etwaige Auswirkungen dieser untersucht werden können.</p>
        <p>Open Access Dieses Kapitel wird unter der Creative Commons Namensnennung 4.0 International Lizenz (http://creativecommons.org/licenses/by/4.0/deed.de) veröffentlicht, welche die Nutzung, Vervielfältigung, Bearbeitung, Verbreitung und Wiedergabe in jeglichem Medium und Format erlaubt, sofern Sie den/die ursprünglichen Autor(en) und die Quelle ordnungsgemäß nennen, einen Link zur Creative Commons Lizenz beifügen und angeben, ob Änderungen vorgenommen wurden.Open Access Dieses Kapitel wird unter der Creative Commons Namensnennung 4.0 International Lizenz (http://creativecommons.org/licenses/by/4.0/deed.de) veröffentlicht, welche die Nutzung, Vervielfältigung, Bearbeitung, Verbreitung und Wiedergabe in jeglichem Medium und Format erlaubt, sofern Sie den/die ursprünglichen Autor(en) und die Quelle ordnungsgemäß nennen, einen Link zur Creative Commons Lizenz beifügen und angeben, ob Änderungen vorgenommen wurden.</p>
        <p>Die in diesem Kapitel enthaltenen Bilder und sonstiges Drittmaterial unterliegen ebenfalls der genannten Creative Commons Lizenz, sofern sich aus der Abbildungslegende nichts anderes ergibt. Sofern das betreffende Material nicht unter der genannten Creative Commons Lizenz steht und die betreffende Handlung nicht nach gesetzlichen Vorschriften erlaubt ist, ist für die oben aufgeführten Weiterverwendungen des Materials die Einwilligung des jeweiligen Rechteinhabers einzuholen.Die in diesem Kapitel enthaltenen Bilder und sonstiges Drittmaterial unterliegen ebenfalls der genannten Creative Commons Lizenz, sofern sich aus der Abbildungslegende nichts anderes ergibt. Sofern das betreffende Material nicht unter der genannten Creative Commons Lizenz steht und die betreffende Handlung nicht nach gesetzlichen Vorschriften erlaubt ist, ist für die oben aufgeführten Weiterverwendungen des Materials die Einwilligung des jeweiligen Rechteinhabers einzuholen.</p>
        <p>In diesem Abschnitt wird nun mit Bezug auf die vorhergehenden Ausführungen zu Big Data argumentiert, dass sich das soeben beschriebene Wahrnehmungsmuster als ein Glaubenssystem beschreiben lässt: das Big-Data-Glaubenssystem (BDGS), das sich in seinen Glaubensüberzeugen insbesondere auf den Erkenntnis-und Nutzengewinn durch Big Data bezieht. Denn an dieser Stelle kommen die zuvor in den einzelnen Kapiteln gespannten konzeptuellen Fäden sozio-technischer Betrachtung des Phänomens Big Data zusammen und bereiten gleichzeitig ein genaueres Verständnis durch kognitions-psychologische Messung vor. Es muss daher zunächst die Bedeutung der zuvor beleuchteten Überlegungen für eine nachfolgende Analyse verdeutlicht werden.In diesem Abschnitt wird nun mit Bezug auf die vorhergehenden Ausführungen zu Big Data argumentiert, dass sich das soeben beschriebene Wahrnehmungsmuster als ein Glaubenssystem beschreiben lässt: das Big-Data-Glaubenssystem (BDGS), das sich in seinen Glaubensüberzeugen insbesondere auf den Erkenntnis-und Nutzengewinn durch Big Data bezieht. Denn an dieser Stelle kommen die zuvor in den einzelnen Kapiteln gespannten konzeptuellen Fäden sozio-technischer Betrachtung des Phänomens Big Data zusammen und bereiten gleichzeitig ein genaueres Verständnis durch kognitions-psychologische Messung vor. Es muss daher zunächst die Bedeutung der zuvor beleuchteten Überlegungen für eine nachfolgende Analyse verdeutlicht werden.</p>
        <p>Anhand der in Kapitel 3 eingeführten Beschreibungsdimensionen von Big Data können die zentralen Wesenszüge eines solchen Glaubenssystems nachfolgend erörtert werden. In diesem Zusammenhang musste als Vorbereitung einer Überzeugungshaltung zunächst auch thematisiert werden, dass die zuvor besprochenen sozio-technischen Dimensionen nicht als stabile Wesensmerkmale digitaler Daten zu verstehen sind, die immer und überall auf diese zutreffen. Ihre Ausprägung bewegt sich mithin auf einem qualitativen Kontinuum. Das sollte zwar auch für Überzeugungen gelten, die sich aus den eher deskriptiven und weitgehend übereinstimmend angenommenen Charakteristika von Big Data wie deren Ausmaß, die Geschwindigkeit der Datenentstehung und -verarbeitung und ihre Vielfalt ergeben. Es sind jedoch vor allem die Überzeugungen bezüglich der eher konsequentiell-evaluativen Dimensionen des Erkenntnis-und des Nutzengewinns durch digitale Daten, die in Betracht gezogen werden müssen und ihrer Voraussetzung nach eine besondere Ambivalenz zulassen. Dabei ist in Kapitel 4 dann veranschaulicht worden, wie und weshalb Daten ihre Bedeutung hier vor allem als Grundlage von Wissen und Wissenserwartungen erlangen. Denn es ist insbesondere die Möglichkeit, durch Daten vermeintlich wahrhaftig und wirklichkeitsabbildend Zustände der Welt festzuhalten, die dann Unterscheidungen zulassen und somit Wissen über die Welt bereitstellen. Erkenntnisse aus hieraus ermöglichten Vergleichen zwischen unterschiedlichen Entitäten auch über die Zeit hinweg nähren das Wissen, das als konstitutiv für heutige Gesellschaften angenommen wird. Die Ausführungen über die gesellschaftliche Verbreitung und Bedeutung von Vergleichen unter Voraussetzungen von IuK und digitalen Daten haben daher in Kapitel 5 gezeigt, dass auch in diesem Rahmen Prozesse der Erkenntnisgenerierung Gegenstand von menschlicher Wahrnehmung des Phänomens Big Data sind, wobei insbesondere Erwartungen an den Nutzen aus der Quantifizierung des Sozialen in den Blick gerieten.Anhand der in Kapitel 3 eingeführten Beschreibungsdimensionen von Big Data können die zentralen Wesenszüge eines solchen Glaubenssystems nachfolgend erörtert werden. In diesem Zusammenhang musste als Vorbereitung einer Überzeugungshaltung zunächst auch thematisiert werden, dass die zuvor besprochenen sozio-technischen Dimensionen nicht als stabile Wesensmerkmale digitaler Daten zu verstehen sind, die immer und überall auf diese zutreffen. Ihre Ausprägung bewegt sich mithin auf einem qualitativen Kontinuum. Das sollte zwar auch für Überzeugungen gelten, die sich aus den eher deskriptiven und weitgehend übereinstimmend angenommenen Charakteristika von Big Data wie deren Ausmaß, die Geschwindigkeit der Datenentstehung und -verarbeitung und ihre Vielfalt ergeben. Es sind jedoch vor allem die Überzeugungen bezüglich der eher konsequentiell-evaluativen Dimensionen des Erkenntnis-und des Nutzengewinns durch digitale Daten, die in Betracht gezogen werden müssen und ihrer Voraussetzung nach eine besondere Ambivalenz zulassen. Dabei ist in Kapitel 4 dann veranschaulicht worden, wie und weshalb Daten ihre Bedeutung hier vor allem als Grundlage von Wissen und Wissenserwartungen erlangen. Denn es ist insbesondere die Möglichkeit, durch Daten vermeintlich wahrhaftig und wirklichkeitsabbildend Zustände der Welt festzuhalten, die dann Unterscheidungen zulassen und somit Wissen über die Welt bereitstellen. Erkenntnisse aus hieraus ermöglichten Vergleichen zwischen unterschiedlichen Entitäten auch über die Zeit hinweg nähren das Wissen, das als konstitutiv für heutige Gesellschaften angenommen wird. Die Ausführungen über die gesellschaftliche Verbreitung und Bedeutung von Vergleichen unter Voraussetzungen von IuK und digitalen Daten haben daher in Kapitel 5 gezeigt, dass auch in diesem Rahmen Prozesse der Erkenntnisgenerierung Gegenstand von menschlicher Wahrnehmung des Phänomens Big Data sind, wobei insbesondere Erwartungen an den Nutzen aus der Quantifizierung des Sozialen in den Blick gerieten.</p>
        <p>Mit Blick auf die Vorstellungen der Bevölkerung, die mit digitalen Daten und der Quantifizierung des Sozialen einhergehen, wurde, wie im vorhergehenden Kapitel dokumentiert, in der Literatur ein ausgeprägtes kollektives Wahrnehmungsmuster bezüglich digitaler Daten vermutet. Es kann hier davon ausgegangen werden, dass es vor allem weit verbreitete gesellschaftliche, insbesondere medial vermittelte Erzählungen sind, durch die die meisten Menschen etwas über gesellschaftliche Mythen wie etwa Big Data oder die Wissensgesellschaft erfahren (Kübler, 2009;Rössler &amp; Krotz, 2005). Es ergibt sich dann aus der öffentlichen Thematisierung der digitalen Daten und diesbezüglicher Ereignisse und Phänomene im Rahmen kommunikativer Vermittlung eine womöglich durchaus individuell unterschiedlich geartete Überzeugungsleistung. Die in der dominanten Erzählung zu Big Data vorkommenden Beschreibungen, Mythen und Metaphern werden weiterhin vor dem Hintergrund individueller persönlicher Erfahrungen bewertet und ggf. angepasst oder gar revidiert. Diese Erwartungen an die Qualität und Wirkmächtigkeit der digitalen Daten, insbesondere vor dem Hintergrund des weitgehend indirekten und mittelbaren individuellen Zugangs zu diesen, können für zusätzliche Variabilität persönlicher Einschätzungen sorgen. Diese Einschätzungen bezüglich eines Erkenntnis-und Nutzengewinns sind dabei nicht nur bedingt durch die Unsicherheit der Qualität von digitalen Daten, sondern aufgrund der Unsicherheit von Zukunftserwartungen bezüglich der Konsequenzen der Datenverwertung kontingent. Der Grad der Überzeugung von Propositionen ist, wie in Abschnitt 4.1.2, ein zentrales Kriterium von Wissen und unterscheidet sich hier, wie auch nachfolgend gezeigt wird, von Glauben. Es ist mithin diese vermeintliche Variabilität, die auch in den nachfolgenden Merkmalen eines Glaubens zum Ausdruck kommen muss.Mit Blick auf die Vorstellungen der Bevölkerung, die mit digitalen Daten und der Quantifizierung des Sozialen einhergehen, wurde, wie im vorhergehenden Kapitel dokumentiert, in der Literatur ein ausgeprägtes kollektives Wahrnehmungsmuster bezüglich digitaler Daten vermutet. Es kann hier davon ausgegangen werden, dass es vor allem weit verbreitete gesellschaftliche, insbesondere medial vermittelte Erzählungen sind, durch die die meisten Menschen etwas über gesellschaftliche Mythen wie etwa Big Data oder die Wissensgesellschaft erfahren (Kübler, 2009;Rössler &amp; Krotz, 2005). Es ergibt sich dann aus der öffentlichen Thematisierung der digitalen Daten und diesbezüglicher Ereignisse und Phänomene im Rahmen kommunikativer Vermittlung eine womöglich durchaus individuell unterschiedlich geartete Überzeugungsleistung. Die in der dominanten Erzählung zu Big Data vorkommenden Beschreibungen, Mythen und Metaphern werden weiterhin vor dem Hintergrund individueller persönlicher Erfahrungen bewertet und ggf. angepasst oder gar revidiert. Diese Erwartungen an die Qualität und Wirkmächtigkeit der digitalen Daten, insbesondere vor dem Hintergrund des weitgehend indirekten und mittelbaren individuellen Zugangs zu diesen, können für zusätzliche Variabilität persönlicher Einschätzungen sorgen. Diese Einschätzungen bezüglich eines Erkenntnis-und Nutzengewinns sind dabei nicht nur bedingt durch die Unsicherheit der Qualität von digitalen Daten, sondern aufgrund der Unsicherheit von Zukunftserwartungen bezüglich der Konsequenzen der Datenverwertung kontingent. Der Grad der Überzeugung von Propositionen ist, wie in Abschnitt 4.1.2, ein zentrales Kriterium von Wissen und unterscheidet sich hier, wie auch nachfolgend gezeigt wird, von Glauben. Es ist mithin diese vermeintliche Variabilität, die auch in den nachfolgenden Merkmalen eines Glaubens zum Ausdruck kommen muss.</p>
        <p>Zunächst wird hierfür ausgeführt, was unter einem Glaubenssystem verstanden werden kann und wie es sich von Wissenssystemen unterscheidet, um anschließend anhand der Beschreibungsdimensionen den Glauben an Big Data zu skizzieren. Die Frage nach der tatsächlichen Ausprägung und den Konsequenzen dieses BDGS kann anschließend empirisch analysiert und beantwortet werden.Zunächst wird hierfür ausgeführt, was unter einem Glaubenssystem verstanden werden kann und wie es sich von Wissenssystemen unterscheidet, um anschließend anhand der Beschreibungsdimensionen den Glauben an Big Data zu skizzieren. Die Frage nach der tatsächlichen Ausprägung und den Konsequenzen dieses BDGS kann anschließend empirisch analysiert und beantwortet werden.</p>
        <p>Beschreibungen von kollektiven Vorstellungen von sozialer Wirklichkeit haben eine lange Tradition in den Sozialwissenschaften. Auch mit Blick auf das Verständnis der menschlichen Deutung der Konsequenzen digitaler Daten für Gesellschaft bieten sich etliche Erklärungsansätze für menschliche oder gar gesellschaftliche Erzählungen an. So wird oft von Frames (Matthes, 2014) und von Narrativen (Müller-Funk, 2008;Mumby, 1993) gesprochen. Psychologen beziehen sich bei der Untersuchung kognitiver menschlicher Vorstellungen von der Realität auch auf mentale Modelle (‚Mental Models'): "(…) People's views of the world, of themselves, of their own capabilities, and of the tasks that they are asked to perform, or topics they are asked to learn, depend heavily on the conceptualizations that they bring to the task" (Norman, 1983, S. 7) Vor dem Hintergrund der Nicht-Nachprüfbarkeit der faktischen Voraussetzungen sowie Tatsachen von digitalen Datenbeständen sowie der Nicht-Einsehbarkeit der Zusammenhänge zwischen seinen diffusen Konstrukten, der (Un-)Sicherheit getroffener Aussagen und der Abwesenheit theoretischer und empirischer Rigorosität soll anders als bei J. Hofmann (1993) auch nicht mit dem Begriff impliziter Theorien gearbeitet werden. Denn die dort analysierten Deutungsentwürfe werden als bereits bestehende recht klar umrissene Theoriegebäude politischer Diskurse oder Programme und daher als bestehendes "Ensemble von axiomatischen, kausal verknüpften Aussagen über soziale Wirklichkeit" (J. Hofmann, 1993, S. 13) untersucht, die erklärend für akteurszentrierte Handlungspraktiken herangezogen werden. Dieser Bestimmtheit entzieht sich einer als Glauben beschriebenen Erwartungshaltung im Rahmen des BDGS trotz feststehender Bezugspunkte aufgrund der Möglichkeit unterschiedlicher Zusammenhänge der Glaubensdimensionen untereinander. So kann man glauben, dass die digitalen Daten eher nicht objektiv sind, sich dennoch Wissen auf Grundlage der Daten generieren lässt, die Gesellschaft jedoch insgesamt eher nicht von ihnen profitiert, man selbst jedoch ganz sicher einen Nutzen aus ihnen zieht und vice versa.Beschreibungen von kollektiven Vorstellungen von sozialer Wirklichkeit haben eine lange Tradition in den Sozialwissenschaften. Auch mit Blick auf das Verständnis der menschlichen Deutung der Konsequenzen digitaler Daten für Gesellschaft bieten sich etliche Erklärungsansätze für menschliche oder gar gesellschaftliche Erzählungen an. So wird oft von Frames (Matthes, 2014) und von Narrativen (Müller-Funk, 2008;Mumby, 1993) gesprochen. Psychologen beziehen sich bei der Untersuchung kognitiver menschlicher Vorstellungen von der Realität auch auf mentale Modelle (‚Mental Models'): "(…) People's views of the world, of themselves, of their own capabilities, and of the tasks that they are asked to perform, or topics they are asked to learn, depend heavily on the conceptualizations that they bring to the task" (Norman, 1983, S. 7) Vor dem Hintergrund der Nicht-Nachprüfbarkeit der faktischen Voraussetzungen sowie Tatsachen von digitalen Datenbeständen sowie der Nicht-Einsehbarkeit der Zusammenhänge zwischen seinen diffusen Konstrukten, der (Un-)Sicherheit getroffener Aussagen und der Abwesenheit theoretischer und empirischer Rigorosität soll anders als bei J. Hofmann (1993) auch nicht mit dem Begriff impliziter Theorien gearbeitet werden. Denn die dort analysierten Deutungsentwürfe werden als bereits bestehende recht klar umrissene Theoriegebäude politischer Diskurse oder Programme und daher als bestehendes "Ensemble von axiomatischen, kausal verknüpften Aussagen über soziale Wirklichkeit" (J. Hofmann, 1993, S. 13) untersucht, die erklärend für akteurszentrierte Handlungspraktiken herangezogen werden. Dieser Bestimmtheit entzieht sich einer als Glauben beschriebenen Erwartungshaltung im Rahmen des BDGS trotz feststehender Bezugspunkte aufgrund der Möglichkeit unterschiedlicher Zusammenhänge der Glaubensdimensionen untereinander. So kann man glauben, dass die digitalen Daten eher nicht objektiv sind, sich dennoch Wissen auf Grundlage der Daten generieren lässt, die Gesellschaft jedoch insgesamt eher nicht von ihnen profitiert, man selbst jedoch ganz sicher einen Nutzen aus ihnen zieht und vice versa.</p>
        <p>Am ehesten ließe sich in Zusammenhang mit dem Glauben an digitale Daten noch auf ein Vertrauen Bezug nehmen. So hat die sozialwissenschaftliche Forschung in den letzten Jahren vor allem auf Vertrauen als einstellungsund handlungsrelevantes Phänomen für die Bedeutung von Digitaltechnologie abgestellt. Hierbei gerieten mit Blick auf die Nutzung digitaler Medien die kommunikativen Mechanismen für das Entstehen oder den Verlust von Vertrauen in den Fokus (Mesch, 2012;Nundy et al., 2019;Taddei &amp; Contena, 2013;Yagoda &amp; Gillan, 2012). Ein Datatrust, wie ihn Rieder und Simon (2016) formulieren, bezieht sich dabei dann jedoch nicht auf die Vorstellungen von Daten und hieraus abgeleiteten Erwartungen selbst, sondern auf die diesbezüglichen Handlungen derjenigen Akteur*innen, die am Entstehungs-und Verwertungskontext maßgeblich beteiligt sind und denen man vertrauen kann. Selbst wenn der Glaube einen Einfluss auf Vertrauen haben könnte, ist es hier im vorliegenden Fall jedoch nicht die Sicht der Bevölkerung auf eben diese Akteur*innen, die in den Blick gerät. Vielmehr ist es ihre unmittelbare Beziehung zu den großen digitalen Datenbeständen. Dieses Verhältnis der Bürger*innen zu den Big Data soll nun nachfolgend untersucht werden.Am ehesten ließe sich in Zusammenhang mit dem Glauben an digitale Daten noch auf ein Vertrauen Bezug nehmen. So hat die sozialwissenschaftliche Forschung in den letzten Jahren vor allem auf Vertrauen als einstellungsund handlungsrelevantes Phänomen für die Bedeutung von Digitaltechnologie abgestellt. Hierbei gerieten mit Blick auf die Nutzung digitaler Medien die kommunikativen Mechanismen für das Entstehen oder den Verlust von Vertrauen in den Fokus (Mesch, 2012;Nundy et al., 2019;Taddei &amp; Contena, 2013;Yagoda &amp; Gillan, 2012). Ein Datatrust, wie ihn Rieder und Simon (2016) formulieren, bezieht sich dabei dann jedoch nicht auf die Vorstellungen von Daten und hieraus abgeleiteten Erwartungen selbst, sondern auf die diesbezüglichen Handlungen derjenigen Akteur*innen, die am Entstehungs-und Verwertungskontext maßgeblich beteiligt sind und denen man vertrauen kann. Selbst wenn der Glaube einen Einfluss auf Vertrauen haben könnte, ist es hier im vorliegenden Fall jedoch nicht die Sicht der Bevölkerung auf eben diese Akteur*innen, die in den Blick gerät. Vielmehr ist es ihre unmittelbare Beziehung zu den großen digitalen Datenbeständen. Dieses Verhältnis der Bürger*innen zu den Big Data soll nun nachfolgend untersucht werden.</p>
        <p>Glaube ist in diesem Zusammenhang nicht als religiöser Glaube zu verstehen und insbesondere auch nicht als blinder Glauben. Sondern er lässt sich mit Blick auf das Phänomen, auf das er sich bezieht und das im vorliegenden Fall das Wesen und die Konsequenzen von Big Data sind, von Wissen und Wissenssystemen abgrenzen. Es handelt sich vor dem Hintergrund der in Abschnitt 4.1 ausgeführten Bedingungen von Wissen vielmehr um eine in wesentlichen Elementen von diesem Wissen verschiedene subjektive Überzeugungshaltung, deren Wahrheitsanspruch umstritten bzw. situativ zu bewerten ist und daher relational variabel aus Sicht der Gläubigen eingeordnet werden kann. Für deren Glaubenssystem werden bei Abelson (1979) nicht nur Merkmale an die Hand gegeben, anhand derer sich die Bezugspunkte zwischen individueller Wahrnehmung, bestehender Ungewissheit und Erwartung an digitale Daten mit denen eines Glaubens aufzeigen lassen (siehe Abschnitt 6.2.1). Er fokussiert auch auf die kommunikativen Mechanismen ihrer Vermittlung und Erwartungsformung (siehe Abschnitt 6.2.2).Glaube ist in diesem Zusammenhang nicht als religiöser Glaube zu verstehen und insbesondere auch nicht als blinder Glauben. Sondern er lässt sich mit Blick auf das Phänomen, auf das er sich bezieht und das im vorliegenden Fall das Wesen und die Konsequenzen von Big Data sind, von Wissen und Wissenssystemen abgrenzen. Es handelt sich vor dem Hintergrund der in Abschnitt 4.1 ausgeführten Bedingungen von Wissen vielmehr um eine in wesentlichen Elementen von diesem Wissen verschiedene subjektive Überzeugungshaltung, deren Wahrheitsanspruch umstritten bzw. situativ zu bewerten ist und daher relational variabel aus Sicht der Gläubigen eingeordnet werden kann. Für deren Glaubenssystem werden bei Abelson (1979) nicht nur Merkmale an die Hand gegeben, anhand derer sich die Bezugspunkte zwischen individueller Wahrnehmung, bestehender Ungewissheit und Erwartung an digitale Daten mit denen eines Glaubens aufzeigen lassen (siehe Abschnitt 6.2.1). Er fokussiert auch auf die kommunikativen Mechanismen ihrer Vermittlung und Erwartungsformung (siehe Abschnitt 6.2.2).</p>
        <p>Der Unterschied zwischen Glaubens-und Wissenssystemen Abelson (1979) unterscheidet nun hinsichtlich der Forschung zu KI-Anwendungen Glaubenssysteme (Belief Systems) von Wissenssystemen (Knowledge Systems).1 Letztere zeichnen sich durch gesichertes Wissen über Fakten und Zusammenhänge aus, die weitgehend allgemein als Tatsachen anerkannt werden. Es stellt bspw. niemand in Frage, dass ein Ball gravitationsbedingt eine Schräge herunterrollen wird. Aus erkenntnistheoretischer Perspektive haben Wissenssysteme daher auch einen unmittelbar prognostischen Charakter: Wenn etwas tatsächlich gesichertes Wissen ist, dann sollten sich anhand der wahren Aussagen eines Systems mit relativer Sicherheit eintretende Vorhersagen machen lassen. Ein Glaubenssystem unterscheidet sich hiervon in der Nicht-Nachprüfbarkeit der faktischen Voraussetzungen sowie realiteren Zusammenhänge zwischen seinen diffusen Konstrukten, der (Un-)Sicherheit getroffener Aussagen und der Abwesenheit theoretischer und empirischer Rigorosität (Abelson, 1979). Abelson konkretisiert weiterhin verschiedene Merkmale eines Glaubenssystems, anhand derer sich Unterschiede zwischen den beiden Systemtypen festmachen lassen -auch wenn es durchaus etliche Gemeinsamkeiten und Graubereiche zwischen ihnen geben kann. Im Folgenden werden diese Unterschiede anhand der Erwartungen und Ansprüche an Big Data und ihrer Diskussion in der Literatur besprochen und somit direkt auf einen Glauben an Big Data bezogen. Dabei werden zum einen die drei zentralen Merkmale, die auf die Qualität gemachter Aussagen von Glaubenssystemen abzielen, diskutiert (siehe Abschnitt 6.2.1) und zum anderen kommunikative Merkmale des diesbezüglichen Diskurses im Rahmen von Glaubenssystemen angesprochen (siehe Abschnitt 6.2.2). Es ist hierbei wichtig zu berücksichtigen, dass die von Abelson beschriebenen Differenzierungen in unterschiedlicher Ausprägung vorhanden sein können und wie von ihm vermerkt jedwedes Merkmal weder notwendig noch hinreichend für die Identifikation von Glaubenssystemen vorhanden sein muss. Allerdings, so stellt Abelson fest (1979): "Any system embodying most of them, however, will have the essential character of a 'belief system'" (S. 356). Dabei sind die eher deskriptiven Dimensionen von Big Data wie Volumen, Geschwindigkeit und Vielfalt wie dokumentiert weitgehend unstrittige definitorische Elemente. Es lassen sich daher vor allem die als konsequentiell-evaluativ charakterisierten Dimensionen als Bezugspunkte eines BDGS verstehen, da sich mit ihnen interpretative und faktisch nicht gesicherte Annahmen bezüglich der Richtigkeit der Daten sowie eines Erkenntnis-und Nutzengewinns verknüpfen. Es ist zu zeigen, dass obwohl definitorische Aussagen über Big Data getroffen werden, diese nicht in allen Fällen uneingeschränkt haltbar sind und somit kein allgemeines und gesichertes Wissen über und durch Big Data besteht, sondern ganz im Gegenteil viele mit Unsicherheit behaftete Hoffnungen und Erwartungen mit der Sammlung und Verwertung großer digitaler Datenbestände verbunden sind. Es ist also davon auszugehen, dass sich mit dem Wesen von Big Data verknüpfte Vorstellungen insbesondere an den genannten Bezugspunkten orientieren und eine grundsätzliche Existenz des Phänomens sowie seine Beschreibbarkeit nicht per se in Frage gestellt werden. Es geht weiterhin auch nicht um Aussagen, die mit Hilfe oder auf Grundlage großer digitaler Datenbestände getroffen werden, sondern um Propositionen über Wesen, Qualität und Konsequenzen von Big Data, die variabel sein können. Die Variabilität dieser Aussagen soll nachfolgend erörtert werden.Der Unterschied zwischen Glaubens-und Wissenssystemen Abelson (1979) unterscheidet nun hinsichtlich der Forschung zu KI-Anwendungen Glaubenssysteme (Belief Systems) von Wissenssystemen (Knowledge Systems).1 Letztere zeichnen sich durch gesichertes Wissen über Fakten und Zusammenhänge aus, die weitgehend allgemein als Tatsachen anerkannt werden. Es stellt bspw. niemand in Frage, dass ein Ball gravitationsbedingt eine Schräge herunterrollen wird. Aus erkenntnistheoretischer Perspektive haben Wissenssysteme daher auch einen unmittelbar prognostischen Charakter: Wenn etwas tatsächlich gesichertes Wissen ist, dann sollten sich anhand der wahren Aussagen eines Systems mit relativer Sicherheit eintretende Vorhersagen machen lassen. Ein Glaubenssystem unterscheidet sich hiervon in der Nicht-Nachprüfbarkeit der faktischen Voraussetzungen sowie realiteren Zusammenhänge zwischen seinen diffusen Konstrukten, der (Un-)Sicherheit getroffener Aussagen und der Abwesenheit theoretischer und empirischer Rigorosität (Abelson, 1979). Abelson konkretisiert weiterhin verschiedene Merkmale eines Glaubenssystems, anhand derer sich Unterschiede zwischen den beiden Systemtypen festmachen lassen -auch wenn es durchaus etliche Gemeinsamkeiten und Graubereiche zwischen ihnen geben kann. Im Folgenden werden diese Unterschiede anhand der Erwartungen und Ansprüche an Big Data und ihrer Diskussion in der Literatur besprochen und somit direkt auf einen Glauben an Big Data bezogen. Dabei werden zum einen die drei zentralen Merkmale, die auf die Qualität gemachter Aussagen von Glaubenssystemen abzielen, diskutiert (siehe Abschnitt 6.2.1) und zum anderen kommunikative Merkmale des diesbezüglichen Diskurses im Rahmen von Glaubenssystemen angesprochen (siehe Abschnitt 6.2.2). Es ist hierbei wichtig zu berücksichtigen, dass die von Abelson beschriebenen Differenzierungen in unterschiedlicher Ausprägung vorhanden sein können und wie von ihm vermerkt jedwedes Merkmal weder notwendig noch hinreichend für die Identifikation von Glaubenssystemen vorhanden sein muss. Allerdings, so stellt Abelson fest (1979): "Any system embodying most of them, however, will have the essential character of a 'belief system'" (S. 356). Dabei sind die eher deskriptiven Dimensionen von Big Data wie Volumen, Geschwindigkeit und Vielfalt wie dokumentiert weitgehend unstrittige definitorische Elemente. Es lassen sich daher vor allem die als konsequentiell-evaluativ charakterisierten Dimensionen als Bezugspunkte eines BDGS verstehen, da sich mit ihnen interpretative und faktisch nicht gesicherte Annahmen bezüglich der Richtigkeit der Daten sowie eines Erkenntnis-und Nutzengewinns verknüpfen. Es ist zu zeigen, dass obwohl definitorische Aussagen über Big Data getroffen werden, diese nicht in allen Fällen uneingeschränkt haltbar sind und somit kein allgemeines und gesichertes Wissen über und durch Big Data besteht, sondern ganz im Gegenteil viele mit Unsicherheit behaftete Hoffnungen und Erwartungen mit der Sammlung und Verwertung großer digitaler Datenbestände verbunden sind. Es ist also davon auszugehen, dass sich mit dem Wesen von Big Data verknüpfte Vorstellungen insbesondere an den genannten Bezugspunkten orientieren und eine grundsätzliche Existenz des Phänomens sowie seine Beschreibbarkeit nicht per se in Frage gestellt werden. Es geht weiterhin auch nicht um Aussagen, die mit Hilfe oder auf Grundlage großer digitaler Datenbestände getroffen werden, sondern um Propositionen über Wesen, Qualität und Konsequenzen von Big Data, die variabel sein können. Die Variabilität dieser Aussagen soll nachfolgend erörtert werden.</p>
        <p>In diesem Abschnitt soll daher zunächst auf drei zentrale Merkmale von Glaubenssystemen nach Abelson (1979) eingegangen werden, die die im Rahmen eines Glaubens an digitale Daten getroffenen Propositionen betreffen: (1) Dissens, (2) Unterschiede der Bewertung sowie (3) Ungewissheit. Dabei bedingen und beeinflussen sich die Merkmale gegenseitig. Es wird daher zunächst auf den Dissens eingegangen, um nachfolgend zu verdeutlichen, wovon dieser maßgeblich abhängt. Das Potential für Dissens betrifft die zentralen Elemente von Glaubenssystemen: "The elements (concepts, propositions, rules, etc.) of a belief system are not consensual" (Abelson, 1979, S. 356, Hervorh. im Orig.). In den vorangegangenen Kapiteln zum Wesen von Big Data ist dabei deutlich geworden, dass mit Blick auf deren Beschreibungsdimensionen in der Literatur zwar große Übereinstimmung darüber besteht, dass die anfallenden Datenmengen sehr groß sind und es spezieller Speicher-und Auswertungstechniken benötigt, um mit diesen Daten zu arbeiten. Auch über die Geschwindigkeit, mit der die Daten entstehen und dann am besten auch gleich ausgewertet werden, besteht Konsens und es gibt keine Hinweise darauf, dass ein Laienverständnis hiervon abweichen könnte.In diesem Abschnitt soll daher zunächst auf drei zentrale Merkmale von Glaubenssystemen nach Abelson (1979) eingegangen werden, die die im Rahmen eines Glaubens an digitale Daten getroffenen Propositionen betreffen: (1) Dissens, (2) Unterschiede der Bewertung sowie (3) Ungewissheit. Dabei bedingen und beeinflussen sich die Merkmale gegenseitig. Es wird daher zunächst auf den Dissens eingegangen, um nachfolgend zu verdeutlichen, wovon dieser maßgeblich abhängt. Das Potential für Dissens betrifft die zentralen Elemente von Glaubenssystemen: "The elements (concepts, propositions, rules, etc.) of a belief system are not consensual" (Abelson, 1979, S. 356, Hervorh. im Orig.). In den vorangegangenen Kapiteln zum Wesen von Big Data ist dabei deutlich geworden, dass mit Blick auf deren Beschreibungsdimensionen in der Literatur zwar große Übereinstimmung darüber besteht, dass die anfallenden Datenmengen sehr groß sind und es spezieller Speicher-und Auswertungstechniken benötigt, um mit diesen Daten zu arbeiten. Auch über die Geschwindigkeit, mit der die Daten entstehen und dann am besten auch gleich ausgewertet werden, besteht Konsens und es gibt keine Hinweise darauf, dass ein Laienverständnis hiervon abweichen könnte.</p>
        <p>In Anbetracht der weitreichenden Durchdringung aller Lebensbereiche durch die Digitalisierung und mit ihr aufkommender Phänomene wie Industrie 4.0 und dem IoT wird nicht nur die Allgegenwärtigkeit von Daten im privaten und beruflichen Alltag deutlich, sondern auch die Stetigkeit ihrer Entstehung und Auswertung sowie die hierfür notwendige Dauerhaftigkeit ihrer Speicherung. Es sind mithin weniger die konzeptionellen Elemente (sprich: die Beschreibungsdimensionen an sich) von Big Data selbst, über die Dissens bestehen kann. Im BDGS sind es die bezüglich der digitalen Datenbestände getroffenen Aussagen, die die Ausprägungen der einzelnen Dimensionen sowie deren Zusammenhänge und Mechanismen betreffen, die strittig sind.In Anbetracht der weitreichenden Durchdringung aller Lebensbereiche durch die Digitalisierung und mit ihr aufkommender Phänomene wie Industrie 4.0 und dem IoT wird nicht nur die Allgegenwärtigkeit von Daten im privaten und beruflichen Alltag deutlich, sondern auch die Stetigkeit ihrer Entstehung und Auswertung sowie die hierfür notwendige Dauerhaftigkeit ihrer Speicherung. Es sind mithin weniger die konzeptionellen Elemente (sprich: die Beschreibungsdimensionen an sich) von Big Data selbst, über die Dissens bestehen kann. Im BDGS sind es die bezüglich der digitalen Datenbestände getroffenen Aussagen, die die Ausprägungen der einzelnen Dimensionen sowie deren Zusammenhänge und Mechanismen betreffen, die strittig sind.</p>
        <p>Doch woher genau rührt dann ein vermeintlicher Dissens? Trotz konzeptueller Übereinstimmung zeigt sich mangelnde Konsensualität vor allem in Verbindung mit einem weiteren Merkmal des Glaubenssystems: "Belief systems rely heavily on evaluative and affective components" (Abelson, 1979, S. 358, Hervorh. im Orig.). Denn es sind erst diese Bewertungsunterschiede, die den Dissens offenbaren. Während nämlich die Sammlung und Auswertung der großen digitalen Datenbestände für die einen begründete Hoffnung ist, ist sie für andere eine Dystopie, bei der die Grenzen von Anstand und Privatheit überschritten werden. Wie aufgezeigt, gibt es durchaus etliche Warnungen bezüglich des Ausmaßes der Datensammlung und -verwertung in der Literatur, die dann gleichzeitig eine gegenteilige Auffassung bezüglich vermeintlicher Chancen und Risiken in der breiten Bevölkerung postulieren (siehe Abschnitt 5.4). Es soll hierbei nicht die Behauptung aufgestellt werden, dass die vermeintliche herrschende wissenschaftliche Einschätzung generell konträr zur Bevölkerungsmeinung verläuft. Es zeigt sich hier jedoch die Möglichkeit fundamentaler Bewertungsunterschiede bezüglich der Moralität der Sammlung und Verwertung von Big Data. Folglich gilt: "A belief system typically has large categories of concepts defined in one way or another as themselves 'good' or 'bad', or as leading to good or bad" (Abelson, 1979, S. 358). Auch wenn nicht zu erwarten ist, dass in absehbarer Zukunft Kameras, Eingabegeräte und Sensoren alle menschlichen Lebensbereiche vollständig durchdrungen haben, so laufen fortwährend gesellschaftliche Diskussionen, an welchen Orten und in welchen Situationen die digitale Erfassung und Speicherung von Zuständen und menschlichen Handlungen zulässig ist (Barnard-Wills, 2011;Zuboff, 2019). Ob flächendeckende (Gesichts-)Erfassung an öffentlichen Orten oder ein Chip in Haushaltsgeräten, in Kleidung oder gar unter der Haut: Es wird meist nicht darüber diskutiert, ob es (schon) möglich ist, Entitäten zu erfassen und in Daten zu überführen, sondern diskutiert, ob es ge-oder verboten sein sollte, dies zu tun.Doch woher genau rührt dann ein vermeintlicher Dissens? Trotz konzeptueller Übereinstimmung zeigt sich mangelnde Konsensualität vor allem in Verbindung mit einem weiteren Merkmal des Glaubenssystems: "Belief systems rely heavily on evaluative and affective components" (Abelson, 1979, S. 358, Hervorh. im Orig.). Denn es sind erst diese Bewertungsunterschiede, die den Dissens offenbaren. Während nämlich die Sammlung und Auswertung der großen digitalen Datenbestände für die einen begründete Hoffnung ist, ist sie für andere eine Dystopie, bei der die Grenzen von Anstand und Privatheit überschritten werden. Wie aufgezeigt, gibt es durchaus etliche Warnungen bezüglich des Ausmaßes der Datensammlung und -verwertung in der Literatur, die dann gleichzeitig eine gegenteilige Auffassung bezüglich vermeintlicher Chancen und Risiken in der breiten Bevölkerung postulieren (siehe Abschnitt 5.4). Es soll hierbei nicht die Behauptung aufgestellt werden, dass die vermeintliche herrschende wissenschaftliche Einschätzung generell konträr zur Bevölkerungsmeinung verläuft. Es zeigt sich hier jedoch die Möglichkeit fundamentaler Bewertungsunterschiede bezüglich der Moralität der Sammlung und Verwertung von Big Data. Folglich gilt: "A belief system typically has large categories of concepts defined in one way or another as themselves 'good' or 'bad', or as leading to good or bad" (Abelson, 1979, S. 358). Auch wenn nicht zu erwarten ist, dass in absehbarer Zukunft Kameras, Eingabegeräte und Sensoren alle menschlichen Lebensbereiche vollständig durchdrungen haben, so laufen fortwährend gesellschaftliche Diskussionen, an welchen Orten und in welchen Situationen die digitale Erfassung und Speicherung von Zuständen und menschlichen Handlungen zulässig ist (Barnard-Wills, 2011;Zuboff, 2019). Ob flächendeckende (Gesichts-)Erfassung an öffentlichen Orten oder ein Chip in Haushaltsgeräten, in Kleidung oder gar unter der Haut: Es wird meist nicht darüber diskutiert, ob es (schon) möglich ist, Entitäten zu erfassen und in Daten zu überführen, sondern diskutiert, ob es ge-oder verboten sein sollte, dies zu tun.</p>
        <p>Die unterschiedlichen Überzeugungen von der Notwendigkeit der Sammlung und Auswertung sowie der hiermit verbundenen Wirkmächtigkeit von Big Data, die sich aus den unterschiedlichen Bewertungen speisen und über die Dissens bestehen kann, können also weiterhin mit etwaiger gradueller Ungewissheit behaftet sein. Eigenschaften, Zweck sowie Nutzen sind somit nur relational, folglich subjektiv und immer situativ zu bewerten. Sie können nicht mit Absolutheit festgestellt werden und sind bezüglich zukünftiger Entwicklungen mit Erwartungsunsicherheit behaftet. Etwaige Überzeugungen grenzen sich somit von einer Gewissheit ab (Abelson, 1979), die als Bedingung von Wissen mit hoher Konfidenz bezüglich der tatsächlichen Auswirkungen von Big Data belegt sein sollte (siehe Abschnitt 4.1.2).Die unterschiedlichen Überzeugungen von der Notwendigkeit der Sammlung und Auswertung sowie der hiermit verbundenen Wirkmächtigkeit von Big Data, die sich aus den unterschiedlichen Bewertungen speisen und über die Dissens bestehen kann, können also weiterhin mit etwaiger gradueller Ungewissheit behaftet sein. Eigenschaften, Zweck sowie Nutzen sind somit nur relational, folglich subjektiv und immer situativ zu bewerten. Sie können nicht mit Absolutheit festgestellt werden und sind bezüglich zukünftiger Entwicklungen mit Erwartungsunsicherheit behaftet. Etwaige Überzeugungen grenzen sich somit von einer Gewissheit ab (Abelson, 1979), die als Bedingung von Wissen mit hoher Konfidenz bezüglich der tatsächlichen Auswirkungen von Big Data belegt sein sollte (siehe Abschnitt 4.1.2).</p>
        <p>Mit Blick auf das Wissen, das aus den Daten gewonnen werden soll, sowie die Genauigkeit und Objektivität dessen, was die Daten abbilden, lassen sich hinsichtlich des Glaubens an die großen digitalen Datenbestände Dissens, Bewertungsunterschiede und Ungewissheit beobachten. All jene Aspekte, die der Beschreibungsdimension der Richtigkeit zugerechnet werden können, wurden wie ausgeführt in der Literatur durchaus kritisch besprochen. So gehen u. a. boyd und Crawford (2012) in ihren Thesen zu Big Data auf die weitläufige Behauptung ein, Big Data seien objektiv und würden die Wirklichkeit genau abbilden, und hinterfragen diese. Sie widersprechen hierbei Erwartungen, eine Wissenschaft, die sich Big Data bedient, arbeite anders als sonst nun mit Daten, die reliabel erhoben sind und die Wirklichkeit detailgetreu und wahrhaftig abbilden. Jegliche Arbeit mit Daten ist laut Ansicht der Autorinnen ein interpretativer Prozess. Es gibt streng genommen keine Rohdaten, da die Entscheidung über die Art und Weise der Speicherung bereits subjektiv menschlich beeinflusst ist. Raw data is an oxymoron (so der plakative Titel eines Sammelbands von Gitelman, 2013). Angefangen damit, dass subjektive Entscheidungen getroffen werden, zu welchen Variablen Daten erhoben werden, wie diese erhoben werden, welche Variablen ausgewertet und welche nicht ausgewertet werden, wird auch darauf hingewiesen, dass die großen Datensätze fehleranfällig sind und hierdurch nicht zwangsläufig ein zuverlässiges und wahres Abbild der Realität wiedergeben (siehe Abschnitt 3.5.1). So kommt es durch Fehler und Ausfälle bei der Datenerhebung mitunter zu Verzerrungen, die im Falle der Fusion mit anderweitigen Datensätzen vergrößert werden können.Mit Blick auf das Wissen, das aus den Daten gewonnen werden soll, sowie die Genauigkeit und Objektivität dessen, was die Daten abbilden, lassen sich hinsichtlich des Glaubens an die großen digitalen Datenbestände Dissens, Bewertungsunterschiede und Ungewissheit beobachten. All jene Aspekte, die der Beschreibungsdimension der Richtigkeit zugerechnet werden können, wurden wie ausgeführt in der Literatur durchaus kritisch besprochen. So gehen u. a. boyd und Crawford (2012) in ihren Thesen zu Big Data auf die weitläufige Behauptung ein, Big Data seien objektiv und würden die Wirklichkeit genau abbilden, und hinterfragen diese. Sie widersprechen hierbei Erwartungen, eine Wissenschaft, die sich Big Data bedient, arbeite anders als sonst nun mit Daten, die reliabel erhoben sind und die Wirklichkeit detailgetreu und wahrhaftig abbilden. Jegliche Arbeit mit Daten ist laut Ansicht der Autorinnen ein interpretativer Prozess. Es gibt streng genommen keine Rohdaten, da die Entscheidung über die Art und Weise der Speicherung bereits subjektiv menschlich beeinflusst ist. Raw data is an oxymoron (so der plakative Titel eines Sammelbands von Gitelman, 2013). Angefangen damit, dass subjektive Entscheidungen getroffen werden, zu welchen Variablen Daten erhoben werden, wie diese erhoben werden, welche Variablen ausgewertet und welche nicht ausgewertet werden, wird auch darauf hingewiesen, dass die großen Datensätze fehleranfällig sind und hierdurch nicht zwangsläufig ein zuverlässiges und wahres Abbild der Realität wiedergeben (siehe Abschnitt 3.5.1). So kommt es durch Fehler und Ausfälle bei der Datenerhebung mitunter zu Verzerrungen, die im Falle der Fusion mit anderweitigen Datensätzen vergrößert werden können.</p>
        <p>Probleme mit Blick auf die Wahrhaftigkeit der Daten haben dann auch einen Einfluss auf das Wissen, das aus den Daten generiert werden kann. Wenn die Daten die Wirklichkeit fehlerhaft abbilden -und diese Gefahr besteht wie beschrieben durchaus -, dann bedeutet das in der Konsequenz auch, dass Wissensbestände, die auf Big-Data-Analysen basieren, Fehler aufweisen können und im schlimmsten Fall nicht wahrheitsgetreu sind. Zur Fehlerproblematik kommt zudem noch das Problem ökologischer Fehlschlüsse hinzu. Getreu des Diktums aus der Statistik, dass von Korrelationsbeziehungen nicht auch automatisch auf Kausalitätsbeziehungen zu schließen ist, sind Analysen von Big Data, die nicht theoriebasiert, sondern nur auf der Grundlage von Korrelationsbeziehungen argumentieren, auch im Hinblick auf das entstehende Wissen fehleranfällig. Für eine betriebswirtschaftliche Forschung, die nur darauf aus ist, auf Grundlage der aus den Daten gezogenen Erkenntnisse wirtschaftlichen Profit zu generieren, mögen solche Ergebnisse meist ‚gut genug' sein (C. Anderson, 2008). Sollte sich diese Perspektive allerdings durch viele andere wissenschaftliche Disziplinen verbreiten und Anerkennung finden, wäre dies als Rückschritt zu betrachten mit teils negativen Konsequenzen (Bowker, 2014). Aufgrund der skizzierten Unsicherheit bezüglich der Richtigkeit und Wahrhaftigkeit der digitalen Daten und eines sich hieraus ergebenden Erkenntnisgewinns kann man zwar dennoch davon überzeugt sein, dass sich auf Datengrundlage ein großer Wissensschatz heben lässt. Allerdings kann man auch anderer Ansicht sein, gegenteilige Überzeugungen hegen oder zumindest etwaige gewichtige Einschränkungen anmerken. Der Überzeugungsgrad ist daher intersubjektiv variabel.Probleme mit Blick auf die Wahrhaftigkeit der Daten haben dann auch einen Einfluss auf das Wissen, das aus den Daten generiert werden kann. Wenn die Daten die Wirklichkeit fehlerhaft abbilden -und diese Gefahr besteht wie beschrieben durchaus -, dann bedeutet das in der Konsequenz auch, dass Wissensbestände, die auf Big-Data-Analysen basieren, Fehler aufweisen können und im schlimmsten Fall nicht wahrheitsgetreu sind. Zur Fehlerproblematik kommt zudem noch das Problem ökologischer Fehlschlüsse hinzu. Getreu des Diktums aus der Statistik, dass von Korrelationsbeziehungen nicht auch automatisch auf Kausalitätsbeziehungen zu schließen ist, sind Analysen von Big Data, die nicht theoriebasiert, sondern nur auf der Grundlage von Korrelationsbeziehungen argumentieren, auch im Hinblick auf das entstehende Wissen fehleranfällig. Für eine betriebswirtschaftliche Forschung, die nur darauf aus ist, auf Grundlage der aus den Daten gezogenen Erkenntnisse wirtschaftlichen Profit zu generieren, mögen solche Ergebnisse meist ‚gut genug' sein (C. Anderson, 2008). Sollte sich diese Perspektive allerdings durch viele andere wissenschaftliche Disziplinen verbreiten und Anerkennung finden, wäre dies als Rückschritt zu betrachten mit teils negativen Konsequenzen (Bowker, 2014). Aufgrund der skizzierten Unsicherheit bezüglich der Richtigkeit und Wahrhaftigkeit der digitalen Daten und eines sich hieraus ergebenden Erkenntnisgewinns kann man zwar dennoch davon überzeugt sein, dass sich auf Datengrundlage ein großer Wissensschatz heben lässt. Allerdings kann man auch anderer Ansicht sein, gegenteilige Überzeugungen hegen oder zumindest etwaige gewichtige Einschränkungen anmerken. Der Überzeugungsgrad ist daher intersubjektiv variabel.</p>
        <p>Es stellen sich im Rahmen der Datensammlung und -auswertung nunmehr vor allem auch ethische Fragen des Zusammenlebens vor dem Hintergrund der technischen Möglichkeiten der Digitalisierung (Crawford et al., 2014;Filipović, 2015;Qiu, 2015;Richterich, 2018). In dieser Diskussion werden die Merkmale des Dissens, der Überzeugung und der Ungewissheit des Glaubenssystems besonders deutlich hervorgehoben. Kein Konsens besteht mithin darüber, in welchen Situationen des Lebens Daten entstehen und ausgewertet werden sollen und dürfen. In der Diskussion ethischer Fragen, wie auch in der mit ihr oftmals einhergehenden allgemeinen Kosten-Nutzen-Abwägung, zeigt sich die unterschiedliche Bewertungseinschätzung und mithin ein Dissens hinsichtlich eines individuellen und gesellschaftlichen Nutzens, der realisiert werden kann, sich jedoch erst einmal tatsächlich realisieren muss. Diese Nutzenbewertung kann zudem auch hinsichtlich individueller und gesellschaftlicher Bewertung auseinanderfallen und ist mithin variabel: Profitiert das Selbst, kann der erwartete Nutzen für die Gesellschaft dennoch geringfügig ausfallen und umgekehrt. Vor allem vor dem Hintergrund der konsequentiell-evaluativen Dimensionen offenbart sich also der mit Big Data verbundene Glaube. Man kann zwar vom individuellen und gesellschaftlichen Nutzen durch digitale Daten überzeugt sein. Diese Überzeugung ist jedoch wie erörtert eher ein Glaube als ein Wissen, da sie in Abhängigkeit der zuvor erörterten Tragweite ihrer Rechtfertigung eine weitgehend in die Zukunft gerichtete Erwartung ist, die durchaus intersubjektiv variabel ausfallen kann und erfüllt wird.Es stellen sich im Rahmen der Datensammlung und -auswertung nunmehr vor allem auch ethische Fragen des Zusammenlebens vor dem Hintergrund der technischen Möglichkeiten der Digitalisierung (Crawford et al., 2014;Filipović, 2015;Qiu, 2015;Richterich, 2018). In dieser Diskussion werden die Merkmale des Dissens, der Überzeugung und der Ungewissheit des Glaubenssystems besonders deutlich hervorgehoben. Kein Konsens besteht mithin darüber, in welchen Situationen des Lebens Daten entstehen und ausgewertet werden sollen und dürfen. In der Diskussion ethischer Fragen, wie auch in der mit ihr oftmals einhergehenden allgemeinen Kosten-Nutzen-Abwägung, zeigt sich die unterschiedliche Bewertungseinschätzung und mithin ein Dissens hinsichtlich eines individuellen und gesellschaftlichen Nutzens, der realisiert werden kann, sich jedoch erst einmal tatsächlich realisieren muss. Diese Nutzenbewertung kann zudem auch hinsichtlich individueller und gesellschaftlicher Bewertung auseinanderfallen und ist mithin variabel: Profitiert das Selbst, kann der erwartete Nutzen für die Gesellschaft dennoch geringfügig ausfallen und umgekehrt. Vor allem vor dem Hintergrund der konsequentiell-evaluativen Dimensionen offenbart sich also der mit Big Data verbundene Glaube. Man kann zwar vom individuellen und gesellschaftlichen Nutzen durch digitale Daten überzeugt sein. Diese Überzeugung ist jedoch wie erörtert eher ein Glaube als ein Wissen, da sie in Abhängigkeit der zuvor erörterten Tragweite ihrer Rechtfertigung eine weitgehend in die Zukunft gerichtete Erwartung ist, die durchaus intersubjektiv variabel ausfallen kann und erfüllt wird.</p>
        <p>Wenngleich die Diskussion um Wahrhaftigkeit, Wissensgewinn und hieraus entstehenden Nutzen von und durch Big Data an dieser Stelle nicht abschließend geklärt werden soll, so ist deutlich geworden, dass insbesondere mit Blick auf die soeben erwähnten Dimensionen (1) kein Konsens bezüglich der genannten Ausprägungen der sozio-technischen Beschreibungsdimensionen besteht und aufgrund der vielfältigen Entstehungskontexte und Verwendungszusammenhänge der Daten auch nicht bestehen kann, so dass (2) getroffene Aussagen deshalb mit wesentlicher Unsicherheit behaftet sind und mithin (3) eine starke evaluative und affektiv aufgeladene Auseinandersetzung mit der Sammlung und Verwertung von Big Data im Rahmen des BDGS besteht. Die Überzeugung, dass auf der Grundlage dieser digitalen Daten Erkenntnis-und Nutzengewinne realisiert werden können, sieht sich etwaigen Zweifeln ausgesetzt, kann folglich durchaus unterschiedlich ausfallen und verweist somit auf einen diesbezüglichen Glauben, den man mehr oder weniger haben kann oder auch nicht.Wenngleich die Diskussion um Wahrhaftigkeit, Wissensgewinn und hieraus entstehenden Nutzen von und durch Big Data an dieser Stelle nicht abschließend geklärt werden soll, so ist deutlich geworden, dass insbesondere mit Blick auf die soeben erwähnten Dimensionen (1) kein Konsens bezüglich der genannten Ausprägungen der sozio-technischen Beschreibungsdimensionen besteht und aufgrund der vielfältigen Entstehungskontexte und Verwendungszusammenhänge der Daten auch nicht bestehen kann, so dass (2) getroffene Aussagen deshalb mit wesentlicher Unsicherheit behaftet sind und mithin (3) eine starke evaluative und affektiv aufgeladene Auseinandersetzung mit der Sammlung und Verwertung von Big Data im Rahmen des BDGS besteht. Die Überzeugung, dass auf der Grundlage dieser digitalen Daten Erkenntnis-und Nutzengewinne realisiert werden können, sieht sich etwaigen Zweifeln ausgesetzt, kann folglich durchaus unterschiedlich ausfallen und verweist somit auf einen diesbezüglichen Glauben, den man mehr oder weniger haben kann oder auch nicht.</p>
        <p>Es gibt zudem noch einige weitere Merkmale von Glaubenssystemen, die von Abelson beschrieben werden und Erwähnung finden sollen: Sie betreffen dabei keine Qualitäten der im Rahmen des Glaubenssystems getroffenen Aussagen, sondern stellen auf zusätzliche kommunikative diskursive Merkmale und Elemente ab, die dem Glauben zuträglich sind und die sich auch mit Blick auf Big Data veranschaulichen lassen. Hier äußert sich dann auch die besondere Anschlussfähigkeit zu untersuchender Glaubenssysteme an die kommunikationswissenschaftliche Forschung und insbesondere an die Ideen der Kultivierungsforschung, da davon ausgegangen wird, dass die nachfolgenden diskursiven Merkmale in einem langfristigen Prozess stetig wiederholt aufgegriffen werden (Gerbner et al., 1980;Gerbner, 1998).Es gibt zudem noch einige weitere Merkmale von Glaubenssystemen, die von Abelson beschrieben werden und Erwähnung finden sollen: Sie betreffen dabei keine Qualitäten der im Rahmen des Glaubenssystems getroffenen Aussagen, sondern stellen auf zusätzliche kommunikative diskursive Merkmale und Elemente ab, die dem Glauben zuträglich sind und die sich auch mit Blick auf Big Data veranschaulichen lassen. Hier äußert sich dann auch die besondere Anschlussfähigkeit zu untersuchender Glaubenssysteme an die kommunikationswissenschaftliche Forschung und insbesondere an die Ideen der Kultivierungsforschung, da davon ausgegangen wird, dass die nachfolgenden diskursiven Merkmale in einem langfristigen Prozess stetig wiederholt aufgegriffen werden (Gerbner et al., 1980;Gerbner, 1998).</p>
        <p>Zu Glaubenssystemen gehört dabei eine generelle Offenheit und Anschlussfähigkeit für weiterführende konzeptuelle Entitäten sowie eine schwerpunktmäßige Beschäftigung mit der (Nicht-)Existenz einzelner Phänomene, auf die sich der Glaube bezieht (Abelson, 1979). Wie schon hinsichtlich der Vielzahl an Beschreibungsdimension mit dem Buchstaben V deutlich wurde (siehe Abschnitt 3.3), eignet sich Big Data auch in dieser Hinsicht als Projektionsfläche ausufernder Erwartungen, die allesamt anschlussfähig sind, sofern sich nur eine Erzählung findet, die dieser Bezeichnungskonvention folgt oder auf die gleichen Bezugspunkte wie etwa das aus Daten gewonnene Wissen und den hieraus gezogenen Nutzen Bezug nimmt (Shafer, 2017). Nicht nur über Zugehörigkeit zum Phänomen Big Data kann debattiert werden, sondern insbesondere über ihre Bedeutung und Konsequenz für Gesellschaft. Hier wurde wie in Abschnitt 3.6 auf Erwartungen an datenbasierte Anwendungen wie Machine Learning hingewiesen sowie auch die direkte Verbindung zu anderweitigen verwandten Erwartungshaltungen innerhalb der Gesellschaft hergestellt, wie mit Blick auf die Ausführungen zur Wissensgesellschaft in Abschnitt 4.2 hergeleitet wurde.Zu Glaubenssystemen gehört dabei eine generelle Offenheit und Anschlussfähigkeit für weiterführende konzeptuelle Entitäten sowie eine schwerpunktmäßige Beschäftigung mit der (Nicht-)Existenz einzelner Phänomene, auf die sich der Glaube bezieht (Abelson, 1979). Wie schon hinsichtlich der Vielzahl an Beschreibungsdimension mit dem Buchstaben V deutlich wurde (siehe Abschnitt 3.3), eignet sich Big Data auch in dieser Hinsicht als Projektionsfläche ausufernder Erwartungen, die allesamt anschlussfähig sind, sofern sich nur eine Erzählung findet, die dieser Bezeichnungskonvention folgt oder auf die gleichen Bezugspunkte wie etwa das aus Daten gewonnene Wissen und den hieraus gezogenen Nutzen Bezug nimmt (Shafer, 2017). Nicht nur über Zugehörigkeit zum Phänomen Big Data kann debattiert werden, sondern insbesondere über ihre Bedeutung und Konsequenz für Gesellschaft. Hier wurde wie in Abschnitt 3.6 auf Erwartungen an datenbasierte Anwendungen wie Machine Learning hingewiesen sowie auch die direkte Verbindung zu anderweitigen verwandten Erwartungshaltungen innerhalb der Gesellschaft hergestellt, wie mit Blick auf die Ausführungen zur Wissensgesellschaft in Abschnitt 4.2 hergeleitet wurde.</p>
        <p>Zudem wird auch die kommunikative Bedeutung episodischer Erzählungen aufgegriffen: "Belief systems are likely to include a substantial amount of episodic material from either personal experience or (for cultural belief systems) from folklore or (for political doctrines) from propaganda" (Abelson, 1979, S. 358, Hervorh. im Orig.). Wer die (populär-)wissenschaftliche Literatur zu Big Data verfolgt, der stolpert bei der Lektüre immer wieder über (die gleichen) Geschichten aus unterschiedlichen Anwendungskontexten. Um den Leser*innen das abstrakte Themengebiet nahezubringen, wird bspw. häufig auf Google-Suchanfragen verwiesen, die täglich von Millionen von Menschen ausgeführt werden und aus denen sich Erkenntnis und Nutzen ziehen lässt (siehe u. a. bei Harford, 2014;D. Lazer et al., 2014;Mayer-Schönberger &amp; Cukier, 2013;Stephens-Davidowitz, 2017) Dieser episodische Zugang im Diskurs von Big Data formt dann entsprechende Erwartungen, die formuliert werden. "Wenn bald mein Kühlschrank weiß, was ich einkaufen soll, dann kann mir mein Arzt doch wohl sagen, wie ich schnellstmöglich wieder gesundwerde." Dies befeuert einen diesbezüglichen Glauben womöglich dahingehend, als dass mit Blick auf die Zukunft einer Welt unter den Vorzeichen von Big Data Vorstellungen evoziert werden, die normativen Ansprüchen folgen, wie diese Zukunft und auch der Weg dorthin auszusehen haben. "Belief systems often include representations of 'alternative worlds', typically the world as it is and the world as it should be" (Abelson, 1979, S. 357, Hervorh. im Orig.). Es wird dann recht ausführlich skizziert, wie bspw. medizinische Big-Data-Anwendungen einen Wandel hin zu einer insgesamt besseren Gesundheitsversorgung bewirken und Menschen gesünder werden lassen, ungeachtet weiterhin wirksamer gesellschaftlicher Rahmenbedingungen. Für dieses vermeintlich durch Big Data problemlos erreichbare Ziel muss dann mithin auch mit überholten Überzeugungen bezüglich einer informationellen Selbstbestimmtheit und Vorstellungen von Privatheit gebrochen werden oder diese müssen zumindest fundamental überdacht werden (Donaldson &amp; Lohr, 1994;Sharon &amp; Lucivero, 2019). All dies wurde und wird mit Blick auf Big Data laufend kommunikativ verhandelt.Zudem wird auch die kommunikative Bedeutung episodischer Erzählungen aufgegriffen: "Belief systems are likely to include a substantial amount of episodic material from either personal experience or (for cultural belief systems) from folklore or (for political doctrines) from propaganda" (Abelson, 1979, S. 358, Hervorh. im Orig.). Wer die (populär-)wissenschaftliche Literatur zu Big Data verfolgt, der stolpert bei der Lektüre immer wieder über (die gleichen) Geschichten aus unterschiedlichen Anwendungskontexten. Um den Leser*innen das abstrakte Themengebiet nahezubringen, wird bspw. häufig auf Google-Suchanfragen verwiesen, die täglich von Millionen von Menschen ausgeführt werden und aus denen sich Erkenntnis und Nutzen ziehen lässt (siehe u. a. bei Harford, 2014;D. Lazer et al., 2014;Mayer-Schönberger &amp; Cukier, 2013;Stephens-Davidowitz, 2017) Dieser episodische Zugang im Diskurs von Big Data formt dann entsprechende Erwartungen, die formuliert werden. "Wenn bald mein Kühlschrank weiß, was ich einkaufen soll, dann kann mir mein Arzt doch wohl sagen, wie ich schnellstmöglich wieder gesundwerde." Dies befeuert einen diesbezüglichen Glauben womöglich dahingehend, als dass mit Blick auf die Zukunft einer Welt unter den Vorzeichen von Big Data Vorstellungen evoziert werden, die normativen Ansprüchen folgen, wie diese Zukunft und auch der Weg dorthin auszusehen haben. "Belief systems often include representations of 'alternative worlds', typically the world as it is and the world as it should be" (Abelson, 1979, S. 357, Hervorh. im Orig.). Es wird dann recht ausführlich skizziert, wie bspw. medizinische Big-Data-Anwendungen einen Wandel hin zu einer insgesamt besseren Gesundheitsversorgung bewirken und Menschen gesünder werden lassen, ungeachtet weiterhin wirksamer gesellschaftlicher Rahmenbedingungen. Für dieses vermeintlich durch Big Data problemlos erreichbare Ziel muss dann mithin auch mit überholten Überzeugungen bezüglich einer informationellen Selbstbestimmtheit und Vorstellungen von Privatheit gebrochen werden oder diese müssen zumindest fundamental überdacht werden (Donaldson &amp; Lohr, 1994;Sharon &amp; Lucivero, 2019). All dies wurde und wird mit Blick auf Big Data laufend kommunikativ verhandelt.</p>
        <p>The world must be changed in order to achieve an idealized state, and discussions of such change must elaborate how present reality operates deficiently, and what political, economic, social (etc.) factors must be manipulated in order to eliminate the deficiencies. (Abelson, 1979, S. 357) Der Diskurs um die Chancen und Risiken von Big Data bedient mithin die weiterführenden kommunikativen Merkmale von Glaubenssystemen. Zusammengefasst lässt sich daher sagen, dass aus den Beschreibungsdimensionen, anhand derer sich Big Data definieren lässt, auch die Elemente eines BDGS abgeleitet werden können. Ausgehend von der Diskussion der Beschreibungsdimensionen von Big Data in Kapitel 3 zeigt sich, dass es sich nicht um ein feststehendes faktengebundenes Wissenssystem handelt, innerhalb dessen gesicherte und allgemein anerkannte Fakten vorliegen, die von den Beteiligten als wahr erachtet werden. Sondern es werden unterschiedlich weitreichende Annahmen und Erwartungen formuliert, die wie beschrieben Wesensmerkmale eines Glaubenssystems repräsentieren können. Mit Rückbezug auf Abelson (1979) wurde gezeigt, dass insbesondere für Annahmen von Richtigkeit und Nutzen von Big Data unterschiedliche Wahrnehmungen und Widersprüche in der wissenschaftlichen Literatur besprochen werden, die eben nicht als faktisch und gesichert erachtet werden, sondern zu variablen Einschätzungen und Erwartungen führen können. Es besteht mithin kein Konsens über das Wesen von Big Data und seine einzelnen Beschreibungsdimensionen, weder, welche Dimensionen Big Data zu dem machen, was sie sind, noch ob sich Annahmen, die mit einzelnen Beschreibungsdimensionen verknüpft sind, uneingeschränkt gelten. Auf ihrer Grundlage kann fernab einer Beschäftigung mit einzelnen Fallbeispielen, an denen sich ein Glaube diskursiv analysieren ließe, abstrahiert auf die generalisierte gesellschaftliche Erwartungshaltung bezüglich der Wirkmacht oder Wirklosigkeit der Sammlung und Auswertung großer digitaler Datenbestände abgestellt werden.The world must be changed in order to achieve an idealized state, and discussions of such change must elaborate how present reality operates deficiently, and what political, economic, social (etc.) factors must be manipulated in order to eliminate the deficiencies. (Abelson, 1979, S. 357) Der Diskurs um die Chancen und Risiken von Big Data bedient mithin die weiterführenden kommunikativen Merkmale von Glaubenssystemen. Zusammengefasst lässt sich daher sagen, dass aus den Beschreibungsdimensionen, anhand derer sich Big Data definieren lässt, auch die Elemente eines BDGS abgeleitet werden können. Ausgehend von der Diskussion der Beschreibungsdimensionen von Big Data in Kapitel 3 zeigt sich, dass es sich nicht um ein feststehendes faktengebundenes Wissenssystem handelt, innerhalb dessen gesicherte und allgemein anerkannte Fakten vorliegen, die von den Beteiligten als wahr erachtet werden. Sondern es werden unterschiedlich weitreichende Annahmen und Erwartungen formuliert, die wie beschrieben Wesensmerkmale eines Glaubenssystems repräsentieren können. Mit Rückbezug auf Abelson (1979) wurde gezeigt, dass insbesondere für Annahmen von Richtigkeit und Nutzen von Big Data unterschiedliche Wahrnehmungen und Widersprüche in der wissenschaftlichen Literatur besprochen werden, die eben nicht als faktisch und gesichert erachtet werden, sondern zu variablen Einschätzungen und Erwartungen führen können. Es besteht mithin kein Konsens über das Wesen von Big Data und seine einzelnen Beschreibungsdimensionen, weder, welche Dimensionen Big Data zu dem machen, was sie sind, noch ob sich Annahmen, die mit einzelnen Beschreibungsdimensionen verknüpft sind, uneingeschränkt gelten. Auf ihrer Grundlage kann fernab einer Beschäftigung mit einzelnen Fallbeispielen, an denen sich ein Glaube diskursiv analysieren ließe, abstrahiert auf die generalisierte gesellschaftliche Erwartungshaltung bezüglich der Wirkmacht oder Wirklosigkeit der Sammlung und Auswertung großer digitaler Datenbestände abgestellt werden.</p>
        <p>An dieser Stelle beginnt der empirische Teil der vorliegenden Arbeit, der zum einen in diesem Kapitel 8 einen Vorschlag unterbreitet, wie man das Big-Data-Glaubenssystem (BDGS) einer empirischen Messung zuführen kann und wie die einzelnen konzeptuellen Dimensionen des BDGS im Rahmen dieser zu entwickelnden Messung operationalisiert werden können. Zum anderen sollen Untersuchungsergebnisse referiert werden, die erste Erkenntnisse über die Ausprägung des BDGS in der deutschen Bevölkerung (siehe Kapitel 9) und den Einfluss des BDGS auf kognitive, affektive und konative Komponenten der Einstellung in unterschiedlichen Lebensbereichen berichten, in denen KI-Anwendungen zum Einsatz kommen (siehe Kapitel 10).An dieser Stelle beginnt der empirische Teil der vorliegenden Arbeit, der zum einen in diesem Kapitel 8 einen Vorschlag unterbreitet, wie man das Big-Data-Glaubenssystem (BDGS) einer empirischen Messung zuführen kann und wie die einzelnen konzeptuellen Dimensionen des BDGS im Rahmen dieser zu entwickelnden Messung operationalisiert werden können. Zum anderen sollen Untersuchungsergebnisse referiert werden, die erste Erkenntnisse über die Ausprägung des BDGS in der deutschen Bevölkerung (siehe Kapitel 9) und den Einfluss des BDGS auf kognitive, affektive und konative Komponenten der Einstellung in unterschiedlichen Lebensbereichen berichten, in denen KI-Anwendungen zum Einsatz kommen (siehe Kapitel 10).</p>
        <p>Daher wird in den folgenden Abschnitten zunächst die Durchführung der Skalenkonstruktion dokumentiert und eine Messung vorgeschlagen, deren Einsatz in einer ersten Studie mit drei Erhebungen entwickelt und getestet wurde. Das empirische Vorgehen soll nachfolgend detailliert und intersubjektiv nachvollziehbar beschrieben werden, um den Aufbau und die Verwendung der Skala als zentrales Werkzeug der Arbeit zu erläutern und eine mögliche Datenanalyse für die produzierten Beobachtungen vorzuschlagen. Die Ausführungen orientieren sich dabei an den in der Literatur zur Testkonstruktion empfohlenen Richtlinien aus der Literatur zur Methodenforschung der standardisierten Befragung, allen voran an denen von (Bühner, 2011), sowie den Empfehlungen zur Skalenentwicklung von Carpenter (2017) und Bandalos (2017).Daher wird in den folgenden Abschnitten zunächst die Durchführung der Skalenkonstruktion dokumentiert und eine Messung vorgeschlagen, deren Einsatz in einer ersten Studie mit drei Erhebungen entwickelt und getestet wurde. Das empirische Vorgehen soll nachfolgend detailliert und intersubjektiv nachvollziehbar beschrieben werden, um den Aufbau und die Verwendung der Skala als zentrales Werkzeug der Arbeit zu erläutern und eine mögliche Datenanalyse für die produzierten Beobachtungen vorzuschlagen. Die Ausführungen orientieren sich dabei an den in der Literatur zur Testkonstruktion empfohlenen Richtlinien aus der Literatur zur Methodenforschung der standardisierten Befragung, allen voran an denen von (Bühner, 2011), sowie den Empfehlungen zur Skalenentwicklung von Carpenter (2017) und Bandalos (2017).</p>
        <p>Generell sollen die Beschreibungsdimensionen der Definition des Phänomens Big Data und ihr Wesensgehalt, der sich in einer Erwartungshaltung bezüglich der Potentiale von Big Data und digitalen Daten ausdrückt, in messbare Indikatoren überführt werden, deren jeweilige Messung eine Auskunft über das Vorhandensein oder eben die Abwesenheit der jeweiligen Überzeugungen gibt. Dabei sind die Bürger*innen Merkmalsträger*innen und deren Erwartungshaltung mit Bezug auf die digitalen Daten das zu untersuchende Merkmal (Brosius et al., 2008). Das BDGS und seine zugehörigen Dimensionen lassen sich -wie bei sozialwissenschaftlichen Konstrukten üblich -nicht direkt und unmittelbar beobachten; ihre Messung muss daher empirisch operationalisiert werden (Bandalos, 2017;Weiber &amp; Mühlhaus, 2014).Generell sollen die Beschreibungsdimensionen der Definition des Phänomens Big Data und ihr Wesensgehalt, der sich in einer Erwartungshaltung bezüglich der Potentiale von Big Data und digitalen Daten ausdrückt, in messbare Indikatoren überführt werden, deren jeweilige Messung eine Auskunft über das Vorhandensein oder eben die Abwesenheit der jeweiligen Überzeugungen gibt. Dabei sind die Bürger*innen Merkmalsträger*innen und deren Erwartungshaltung mit Bezug auf die digitalen Daten das zu untersuchende Merkmal (Brosius et al., 2008). Das BDGS und seine zugehörigen Dimensionen lassen sich -wie bei sozialwissenschaftlichen Konstrukten üblich -nicht direkt und unmittelbar beobachten; ihre Messung muss daher empirisch operationalisiert werden (Bandalos, 2017;Weiber &amp; Mühlhaus, 2014).</p>
        <p>Die vorliegende Arbeit zielt darauf ab, Personen nach der Stärke der Ausprägung des individuellen Glaubens an Charakteristika und Konsequenzen digitaler Daten und ihrer Verwertung zu unterscheiden. Wie zuvor ausgeführt, gibt es innerhalb des BDGS mitunter Überzeugungen, die dazu führen, eine ganz unterschiedliche Bewertung dieser digitalen Daten in ihrem Entstehungs-und Verwertungskontext vorzunehmen. Doch wie gelingt diesbezüglich eine Unterscheidung, kann man die Existenz und Stärke des Glaubens den jeweiligen Personen ja eben nicht von den Lippen ablesen. Das BDGS, das sich auf Glauben an digitale Daten bezieht, kann nicht aus eben jenen bestehenden großen digitalen Datenbeständen herausgelesen werden, sondern muss anhand geeigneter Indikatoren erhoben werden (Hubbard, 2010). Entsprechende Daten müssen aktiv produziert werden. Dabei ist das Glaubenssystem immateriell oder in anderen Worten: nicht greifbar. Es ist jedoch über die Reproduktion von Aussagen bezüglich eigener Glaubensüberzeugungen und die Zustimmung oder Ablehnung zu diesen zu operationalisieren und zu messen. Eine Person, die einen ausgeprägten Glauben an einzelne Dimensionen des Wesens und der Konsequenzen von Big Data hat, sollte in der Befragungssituation entsprechend Aussagen, die den digitalen Daten nun bspw. eine Eigenschaft wie detailgetreue Realitätsabbildung oder positive Konsequenzen für das Selbst zuschreiben, entsprechend zustimmen. Die (Nicht-)Zustimmung zu den Glaubenssätzen, also manifeste Äußerungen der Merkmalsträger, dienen als Indikatoren für die jeweilige konkrete Ausprägung des BDGS, die dokumentiert werden und Rückschlüsse zulassen. Genauer werden den Bürger*innen Aussagen zu digitalen Datenbeständen vorgelegt und sie sollen als Befragte selbst dazu Auskunft geben, inwieweit sie den Aussagen zustimmen oder auch nicht. Der Ansatz folgt dabei sozialwissenschaftlicher Forschung, die ebenfalls darum bemüht ist, die Messung von Glaubenssätzen mittels standardisierter Itembatterien für Befragungsstudien zu ermöglichen. Entsprechende Befragungsinstrumente wurden unter dem Stichwort der Messung von Glaubensüberzeugungen u. a. für die Erwartungshaltung mit dem zukünftigen Umgang mit positiven Emotionen vorgeschlagen (F. Bryant, 2011) und werden auch bei der Analyse politischer Überzeugungen eingesetzt (Baldassarri &amp; Goldberg, 2014;Boutyline &amp; Vaisey, 2017;Brandt et al., 2019).Die vorliegende Arbeit zielt darauf ab, Personen nach der Stärke der Ausprägung des individuellen Glaubens an Charakteristika und Konsequenzen digitaler Daten und ihrer Verwertung zu unterscheiden. Wie zuvor ausgeführt, gibt es innerhalb des BDGS mitunter Überzeugungen, die dazu führen, eine ganz unterschiedliche Bewertung dieser digitalen Daten in ihrem Entstehungs-und Verwertungskontext vorzunehmen. Doch wie gelingt diesbezüglich eine Unterscheidung, kann man die Existenz und Stärke des Glaubens den jeweiligen Personen ja eben nicht von den Lippen ablesen. Das BDGS, das sich auf Glauben an digitale Daten bezieht, kann nicht aus eben jenen bestehenden großen digitalen Datenbeständen herausgelesen werden, sondern muss anhand geeigneter Indikatoren erhoben werden (Hubbard, 2010). Entsprechende Daten müssen aktiv produziert werden. Dabei ist das Glaubenssystem immateriell oder in anderen Worten: nicht greifbar. Es ist jedoch über die Reproduktion von Aussagen bezüglich eigener Glaubensüberzeugungen und die Zustimmung oder Ablehnung zu diesen zu operationalisieren und zu messen. Eine Person, die einen ausgeprägten Glauben an einzelne Dimensionen des Wesens und der Konsequenzen von Big Data hat, sollte in der Befragungssituation entsprechend Aussagen, die den digitalen Daten nun bspw. eine Eigenschaft wie detailgetreue Realitätsabbildung oder positive Konsequenzen für das Selbst zuschreiben, entsprechend zustimmen. Die (Nicht-)Zustimmung zu den Glaubenssätzen, also manifeste Äußerungen der Merkmalsträger, dienen als Indikatoren für die jeweilige konkrete Ausprägung des BDGS, die dokumentiert werden und Rückschlüsse zulassen. Genauer werden den Bürger*innen Aussagen zu digitalen Datenbeständen vorgelegt und sie sollen als Befragte selbst dazu Auskunft geben, inwieweit sie den Aussagen zustimmen oder auch nicht. Der Ansatz folgt dabei sozialwissenschaftlicher Forschung, die ebenfalls darum bemüht ist, die Messung von Glaubenssätzen mittels standardisierter Itembatterien für Befragungsstudien zu ermöglichen. Entsprechende Befragungsinstrumente wurden unter dem Stichwort der Messung von Glaubensüberzeugungen u. a. für die Erwartungshaltung mit dem zukünftigen Umgang mit positiven Emotionen vorgeschlagen (F. Bryant, 2011) und werden auch bei der Analyse politischer Überzeugungen eingesetzt (Baldassarri &amp; Goldberg, 2014;Boutyline &amp; Vaisey, 2017;Brandt et al., 2019).</p>
        <p>Zuvor wurde dabei der Begriff des Messens unter den Bedingungen von Daten und seine Bedeutung für diese Arbeit bereits ausführlich aus analytischer Perspektive reflektiert. Für das handwerkliche Verständnis des Messens bei der empirischen Erhebung des BDGS im Rahmen von Sozialforschung wird sich nachfolgend hingegen an folgender Definition von Friedrichs (1990) Nutzen digitaler Daten zu geben und diese über Befragte und unterschiedliche Stichproben hinweg vergleichbar zu machen.Zuvor wurde dabei der Begriff des Messens unter den Bedingungen von Daten und seine Bedeutung für diese Arbeit bereits ausführlich aus analytischer Perspektive reflektiert. Für das handwerkliche Verständnis des Messens bei der empirischen Erhebung des BDGS im Rahmen von Sozialforschung wird sich nachfolgend hingegen an folgender Definition von Friedrichs (1990) Nutzen digitaler Daten zu geben und diese über Befragte und unterschiedliche Stichproben hinweg vergleichbar zu machen.</p>
        <p>Allein aus ökonomischen Gründen ist die zunächst zwar aufwändige, dann jedoch beliebig oft anzuwendende Erarbeitung eines standardisierten Befragungsinstruments sinnvoll, bei dem einige wenige Fragen mit Hilfe sich wiederholender vorgegebener Antwortmöglichkeiten in kurzer Zeit aus der Ferne ausgespielt werden können. Diese Erhebungs-und Messkonzeption ermöglicht daher besonders gut das Festhalten einer standardisiert quantifizierbaren Messung reproduzierter Überzeugungen des BDGS.Allein aus ökonomischen Gründen ist die zunächst zwar aufwändige, dann jedoch beliebig oft anzuwendende Erarbeitung eines standardisierten Befragungsinstruments sinnvoll, bei dem einige wenige Fragen mit Hilfe sich wiederholender vorgegebener Antwortmöglichkeiten in kurzer Zeit aus der Ferne ausgespielt werden können. Diese Erhebungs-und Messkonzeption ermöglicht daher besonders gut das Festhalten einer standardisiert quantifizierbaren Messung reproduzierter Überzeugungen des BDGS.</p>
        <p>Bevor jedoch die Testkonstruktion im Detail erläutert wird, sei bereits ein Hinweis gegeben, der auch unter Reflexion und Methodenkritik aufgegriffen wird: Sozialwissenschaftliche Messungen sind nicht perfekt und stellen lediglich Annäherungen an das abzubildende, nicht unmittelbar zu beobachtende Konstrukt dar, da es nicht die eine richtige Messung gibt (Bandalos, 2017). Testkonstruktionen sind mitunter fehlerbehaftet und setzen ein Bewusstsein und eine stetige Reflexion über diese Fehlbarkeit voraus, die sich aus unterschiedlichen Fehlerquellen ergeben kann (Weisberg, 2009). Auch wenn die nachfolgende Auswertung die Möglichkeit des Messfehlers zulässt (Kline, 2011;Weiber &amp; Mühlhaus, 2014): In den nachfolgenden Ausführungen müssen alle Entscheidungen auf dem Weg zur Messung des BDGS ausführlich begründet und ihre Pro-und Contra-Argumente abgewogen werden. 3Das Testziel der ‚Big-Data-Glaubenssystem'-Skala Bevor auf die konkreten Entscheidungen bei der Konstruktion der Skala und der Formulierung ihrer Items eingegangen werden kann, muss zunächst ein allgemeines Testziel festgelegt werden, das die einzelnen Entscheidungen leitet, die bei der Skalenentwicklung getroffen werden. Das Testziel besteht in der vorliegenden Arbeit darin, die Perzeptionen der Bürger*innen von Big Data und der mit Big Data verbundenen Datafizierung und Quantifizierung messbar zu machen. Es wird hier auf eine Erwartungshaltung abgestellt, die als BDGS im vorigen Teil der Arbeit konzeptuell beschrieben wurde. Die Messung durch standardisierte Befragung stellt hierbei also insbesondere auf Glaubensüberzeugungen bezüglich der in Abschnitt 3.5.1 bzw. Abschnitt 3.5.2 besprochenen Beschreibungsdimensionen Richtigkeit (Veracity) und Nutzen (Value) großer digitaler Datenbestände ab, die auch als Big Data bezeichnet werden.Bevor jedoch die Testkonstruktion im Detail erläutert wird, sei bereits ein Hinweis gegeben, der auch unter Reflexion und Methodenkritik aufgegriffen wird: Sozialwissenschaftliche Messungen sind nicht perfekt und stellen lediglich Annäherungen an das abzubildende, nicht unmittelbar zu beobachtende Konstrukt dar, da es nicht die eine richtige Messung gibt (Bandalos, 2017). Testkonstruktionen sind mitunter fehlerbehaftet und setzen ein Bewusstsein und eine stetige Reflexion über diese Fehlbarkeit voraus, die sich aus unterschiedlichen Fehlerquellen ergeben kann (Weisberg, 2009). Auch wenn die nachfolgende Auswertung die Möglichkeit des Messfehlers zulässt (Kline, 2011;Weiber &amp; Mühlhaus, 2014): In den nachfolgenden Ausführungen müssen alle Entscheidungen auf dem Weg zur Messung des BDGS ausführlich begründet und ihre Pro-und Contra-Argumente abgewogen werden. 3Das Testziel der ‚Big-Data-Glaubenssystem'-Skala Bevor auf die konkreten Entscheidungen bei der Konstruktion der Skala und der Formulierung ihrer Items eingegangen werden kann, muss zunächst ein allgemeines Testziel festgelegt werden, das die einzelnen Entscheidungen leitet, die bei der Skalenentwicklung getroffen werden. Das Testziel besteht in der vorliegenden Arbeit darin, die Perzeptionen der Bürger*innen von Big Data und der mit Big Data verbundenen Datafizierung und Quantifizierung messbar zu machen. Es wird hier auf eine Erwartungshaltung abgestellt, die als BDGS im vorigen Teil der Arbeit konzeptuell beschrieben wurde. Die Messung durch standardisierte Befragung stellt hierbei also insbesondere auf Glaubensüberzeugungen bezüglich der in Abschnitt 3.5.1 bzw. Abschnitt 3.5.2 besprochenen Beschreibungsdimensionen Richtigkeit (Veracity) und Nutzen (Value) großer digitaler Datenbestände ab, die auch als Big Data bezeichnet werden.</p>
        <p>In der Anfangsphase der vorliegenden Forschungsarbeit wurde zunächst auch erwogen, noch zusätzlich zwischen den drei Momenten der Entstehung, Speicherung und Auswertung von digitalen Daten unterscheiden zu wollen. Zudem wurde eine Bewertung des Ausmaßes, der Geschwindigkeit und der Vielfalt digitaler Datenentstehung und -verwertung erfragt. Diese feinteilige konzeptuelle Unterscheidung ist empirisch jedoch kaum oder gar nicht abzubilden, da etwaige Feinheiten in den entsprechenden (Item-)Formulierungen nur unzureichend wahrgenommen werden und sich im Aggregat nicht abbilden lassen. Siehe hierzu die entsprechenden Ergänzungen in Abschnitt 1.1 im Anhang im elektronischen Zusatzmaterial. Auf die jeweiligen Unterscheidungen wird nachfolgend nur jeweils an Stellen eingegangen, an denen ihr diskutierter Bezug zur Messung wichtig wird und zum Verständnis der empirischen Untersuchung beiträgt. Dies ist der Notwendigkeit der transparenten Dokumentation durchgeführter Forschung geschuldet.In der Anfangsphase der vorliegenden Forschungsarbeit wurde zunächst auch erwogen, noch zusätzlich zwischen den drei Momenten der Entstehung, Speicherung und Auswertung von digitalen Daten unterscheiden zu wollen. Zudem wurde eine Bewertung des Ausmaßes, der Geschwindigkeit und der Vielfalt digitaler Datenentstehung und -verwertung erfragt. Diese feinteilige konzeptuelle Unterscheidung ist empirisch jedoch kaum oder gar nicht abzubilden, da etwaige Feinheiten in den entsprechenden (Item-)Formulierungen nur unzureichend wahrgenommen werden und sich im Aggregat nicht abbilden lassen. Siehe hierzu die entsprechenden Ergänzungen in Abschnitt 1.1 im Anhang im elektronischen Zusatzmaterial. Auf die jeweiligen Unterscheidungen wird nachfolgend nur jeweils an Stellen eingegangen, an denen ihr diskutierter Bezug zur Messung wichtig wird und zum Verständnis der empirischen Untersuchung beiträgt. Dies ist der Notwendigkeit der transparenten Dokumentation durchgeführter Forschung geschuldet.</p>
        <p>Befragungsitems als manifest beobachtbare Indikatoren der Messung der latenten Konstrukte des BDGSBefragungsitems als manifest beobachtbare Indikatoren der Messung der latenten Konstrukte des BDGS</p>
        <p>Bei der Festlegung der Art der Indikatoren soll nach Bühner (2011)"die Frage beantwortet werden, ob der Test anhand objektiver oder subjektiver Indikatoren ein Konstrukt erfassen soll" (S. 85). Da das zu erhebende Charakteristikumanders als bei einem Wissenstest -keine eindeutige Falsch-oder Richtig-Klassifizierung erlaubt, sondern über Ratings und somit sogenannte Q-Daten (Questionnaire data) abgebildet wird, handelt es sich um subjektive Indikatoren, die mittels Selbstauskunft der Befragten deren Überzeugungen messen sollen (Cattell, 1973) (Bühner, 2011). Weiterhin müssen weitere Entscheidungen getroffen werden, die die Messung betreffen, wie bspw. die Skalierung der Items und die Benennung der Skalierungspunkte sowie die Einleitung, Darstellung und Aufteilung der Skala im Fragebogen (Scholl, 2018). Die folgenden Abschnitte formulieren die einzelnen Ansprüche, die an Skala und Items gestellt werden, und dokumentieren, wie diese bei der Testkonstruktion des BDGS umgesetzt wurden. 2018) fest: "The many definitions, understandings, and general ambiguity of the term 'big data' do not allow for direct work with this term in a survey" (S. 1). Daher wird an den entscheidenden Stellen in der Befragung wie etwa Einleitungstexten und Itemformulierungen von ‚großen digitalen Daten(beständen)' gesprochen.Bei der Festlegung der Art der Indikatoren soll nach Bühner (2011)"die Frage beantwortet werden, ob der Test anhand objektiver oder subjektiver Indikatoren ein Konstrukt erfassen soll" (S. 85). Da das zu erhebende Charakteristikumanders als bei einem Wissenstest -keine eindeutige Falsch-oder Richtig-Klassifizierung erlaubt, sondern über Ratings und somit sogenannte Q-Daten (Questionnaire data) abgebildet wird, handelt es sich um subjektive Indikatoren, die mittels Selbstauskunft der Befragten deren Überzeugungen messen sollen (Cattell, 1973) (Bühner, 2011). Weiterhin müssen weitere Entscheidungen getroffen werden, die die Messung betreffen, wie bspw. die Skalierung der Items und die Benennung der Skalierungspunkte sowie die Einleitung, Darstellung und Aufteilung der Skala im Fragebogen (Scholl, 2018). Die folgenden Abschnitte formulieren die einzelnen Ansprüche, die an Skala und Items gestellt werden, und dokumentieren, wie diese bei der Testkonstruktion des BDGS umgesetzt wurden. 2018) fest: "The many definitions, understandings, and general ambiguity of the term 'big data' do not allow for direct work with this term in a survey" (S. 1). Daher wird an den entscheidenden Stellen in der Befragung wie etwa Einleitungstexten und Itemformulierungen von ‚großen digitalen Daten(beständen)' gesprochen.</p>
        <p>Die allgemein gehaltene Zielgruppe der deutschsprachigen Bundesbürger*innen bedeutet mithin auch, dass der Test für alle Alters-und Bildungsstufen anwendbar sein sollte. Das hat vor allem Konsequenzen für die sogenannte psychometrische Itemschwierigkeit, da bspw. die Nutzung digitaler Medientechnologien durch das Alter beeinflusst wird (Seifert, 2016). Junge und hochgebildete Personen haben wahrscheinlich einen anderen Zugang zu einem Thema, das einen gewissen technischen Anspruch hat, und können aufgrund eines Wissensvorsprungs, der aus größerer Nutzungserfahrung entspringt, bestimmten Items nicht nur eher, sondern möglicherweise auch anders zustimmen als technisch unerfahrene Personen. Es besteht mithin die Möglichkeit, dass für spezielle Untergruppen der Zielgruppe Probleme bei der Skalenkonstruktion und der letztendlichen Befragung zum BDGS zu erwarten sind, die über die üblichen Probleme und Herausforderungen der Befragungsforschung hinausgehen (Scholl, 2018).Die allgemein gehaltene Zielgruppe der deutschsprachigen Bundesbürger*innen bedeutet mithin auch, dass der Test für alle Alters-und Bildungsstufen anwendbar sein sollte. Das hat vor allem Konsequenzen für die sogenannte psychometrische Itemschwierigkeit, da bspw. die Nutzung digitaler Medientechnologien durch das Alter beeinflusst wird (Seifert, 2016). Junge und hochgebildete Personen haben wahrscheinlich einen anderen Zugang zu einem Thema, das einen gewissen technischen Anspruch hat, und können aufgrund eines Wissensvorsprungs, der aus größerer Nutzungserfahrung entspringt, bestimmten Items nicht nur eher, sondern möglicherweise auch anders zustimmen als technisch unerfahrene Personen. Es besteht mithin die Möglichkeit, dass für spezielle Untergruppen der Zielgruppe Probleme bei der Skalenkonstruktion und der letztendlichen Befragung zum BDGS zu erwarten sind, die über die üblichen Probleme und Herausforderungen der Befragungsforschung hinausgehen (Scholl, 2018).</p>
        <p>Allerdings sollte eine Vertrautheit mit den allgemeinen technischen Begrifflichkeiten im Bereich Internet und Computer vorauszusetzen sein. Es wird erwartet, dass die Begriffe ‚Digitalisierung' bzw. ‚digital' und auch ‚Daten' bekannt sind und ein Alltags-bzw. Laienverständnis vorliegt, ohne dass die jeweiligen Befragten dazu befähigt sein müssen, eine präzise Definition wiederzugeben. Da es ja um die allgemeinen Perzeptionen von Big Data und eine diesbezügliche individuelle Erwartungshaltung geht und nicht bspw. um einen Wissenstest, sollte der Einfluss von Alter und Bildung zumindest auf die allgemeine Beantwortbarkeit der gestellten Fragen minimal sein. Alle Befragten sollten ein Verständnis von Datenerzeugung und -speicherung durch digitale Medien aus persönlicher Erfahrung sowie medienvermittelten Erzählungen mitbringen. Dass digitale Medientechnik Daten erzeugt und speichert, ist seit Jahren und auch aktuell Gegenstand öffentlicher Diskussionen (Knorre et al., 2020;Zeller et al., 2010). Alle potentiellen Befragten sollten durch die regelmäßigen Hinweise zu Datenerhebung und Datenschutz bei der Nutzung digitaler sowie nicht-digitaler Angebote auch damit vertraut sein, dass sie in gewissem -wenn auch nicht vollumfänglich nachvollziehbarem -Umfang laufend ihre Daten preisgeben und sich Unternehmen und Dienstleister vorbehalten, diese Daten für eigene Zwecke zu nutzen, ohne dass hiermit gleich eine kommerzielle Nutzung gemeint ist. So wird man beim Arztbesuch bedingt durch das Inkrafttreten der DSGVO im Mai 2018 neuerdings um die Einwilligung in Datenerhebung und -speicherung gebeten (Wensing, 2018).Allerdings sollte eine Vertrautheit mit den allgemeinen technischen Begrifflichkeiten im Bereich Internet und Computer vorauszusetzen sein. Es wird erwartet, dass die Begriffe ‚Digitalisierung' bzw. ‚digital' und auch ‚Daten' bekannt sind und ein Alltags-bzw. Laienverständnis vorliegt, ohne dass die jeweiligen Befragten dazu befähigt sein müssen, eine präzise Definition wiederzugeben. Da es ja um die allgemeinen Perzeptionen von Big Data und eine diesbezügliche individuelle Erwartungshaltung geht und nicht bspw. um einen Wissenstest, sollte der Einfluss von Alter und Bildung zumindest auf die allgemeine Beantwortbarkeit der gestellten Fragen minimal sein. Alle Befragten sollten ein Verständnis von Datenerzeugung und -speicherung durch digitale Medien aus persönlicher Erfahrung sowie medienvermittelten Erzählungen mitbringen. Dass digitale Medientechnik Daten erzeugt und speichert, ist seit Jahren und auch aktuell Gegenstand öffentlicher Diskussionen (Knorre et al., 2020;Zeller et al., 2010). Alle potentiellen Befragten sollten durch die regelmäßigen Hinweise zu Datenerhebung und Datenschutz bei der Nutzung digitaler sowie nicht-digitaler Angebote auch damit vertraut sein, dass sie in gewissem -wenn auch nicht vollumfänglich nachvollziehbarem -Umfang laufend ihre Daten preisgeben und sich Unternehmen und Dienstleister vorbehalten, diese Daten für eigene Zwecke zu nutzen, ohne dass hiermit gleich eine kommerzielle Nutzung gemeint ist. So wird man beim Arztbesuch bedingt durch das Inkrafttreten der DSGVO im Mai 2018 neuerdings um die Einwilligung in Datenerhebung und -speicherung gebeten (Wensing, 2018).</p>
        <p>Lediglich mit Bezug auf die technische Auswertbarkeit der Daten kann es durchaus unterschiedliche Vorstellungen geben. Allerdings sollte auch hier weitgehend klar sein, dass etwas mit den erzeugten und gespeicherten Daten geschieht, selbst wenn sich das explizite Wissen um die konkreten Auswertungsmöglichkeiten zwischen einzelnen Gruppen unterscheiden mag.Lediglich mit Bezug auf die technische Auswertbarkeit der Daten kann es durchaus unterschiedliche Vorstellungen geben. Allerdings sollte auch hier weitgehend klar sein, dass etwas mit den erzeugten und gespeicherten Daten geschieht, selbst wenn sich das explizite Wissen um die konkreten Auswertungsmöglichkeiten zwischen einzelnen Gruppen unterscheiden mag.</p>
        <p>Es muss jedoch diskutiert werden, inwieweit ältere Befragte -eine Gruppe, in der sich viele Nicht-Nutzer digitaler Medientechnologien befinden (Seifert &amp; Schelling, 2018) -sich möglicherweise mit der Beantwortung schwertun und es zu Verständnisproblemen in der Befragungssituation kommt.Es muss jedoch diskutiert werden, inwieweit ältere Befragte -eine Gruppe, in der sich viele Nicht-Nutzer digitaler Medientechnologien befinden (Seifert &amp; Schelling, 2018) -sich möglicherweise mit der Beantwortung schwertun und es zu Verständnisproblemen in der Befragungssituation kommt.</p>
        <p>Die Mehrheit der älteren Befragten sollte unter normalen Umständen in der Lage sein, die Befragungsitems sinnhaft zu beantworten. Um dies sicherzustellen, sollten die Frageitems mit einer Einleitung versehen werden, die ein Grundverständnis für das herstellt, was im Fragebogen unter digitalen Daten verstanden wird. Der Einleitungstext zum Test wird in Abschnitt 8.4.7 dokumentiert. Es sind hier des Weiteren keine oder vernachlässigbare Probleme mit Blick auf ältere Befragte zu erwarten, da "besondere Problemgruppen unter den Älteren üblicherweise in Surveys gar nicht oder nur selten befragt werden: die ganz Alten (Personen über 75 oder 80 Jahre), die institutionalisierten Alten und die (meist geistig) Labilen (Demente)" (Kühn &amp; Porst, 1999, S. 27). Mit Blick auf den nachfolgend dokumentierten Einsatz der BDGS-Skala in diversen Erhebungen wird deutlich werden, dass jene Personen der ganz Alten in vernachlässigbarer Anzahl teilgenommen haben. Dies liegt schon darin begründet, dass die durchgeführten Befragungen online stattfanden, was nachfolgend diskutiert wird. Dennoch kann diese Befragtengruppe nicht gänzlich vernachlässigt werden, da sie doch gleichsam zur Grundgesamtheit zählt und einen beachtlichen und zunehmenden Anteil an der Wahlbevölkerung umfasst (Falter &amp; Gehring, 1998). Etwaige Problemlagen müssen mithin mit Blick auf den zukünftigen Einsatz einer BDGS-Skala je nach Forschungsinteresse berücksichtigt werden. Zusammengefasst bedeutet dies zunächst, dass es keine Gruppe unter den potentiellen Befragten geben sollte, die aufgrund soziodemografischer Merkmale durch das Instrument systematisch benachteiligt wird und keine valide Beantwortung des Tests erbringen könnte.Die Mehrheit der älteren Befragten sollte unter normalen Umständen in der Lage sein, die Befragungsitems sinnhaft zu beantworten. Um dies sicherzustellen, sollten die Frageitems mit einer Einleitung versehen werden, die ein Grundverständnis für das herstellt, was im Fragebogen unter digitalen Daten verstanden wird. Der Einleitungstext zum Test wird in Abschnitt 8.4.7 dokumentiert. Es sind hier des Weiteren keine oder vernachlässigbare Probleme mit Blick auf ältere Befragte zu erwarten, da "besondere Problemgruppen unter den Älteren üblicherweise in Surveys gar nicht oder nur selten befragt werden: die ganz Alten (Personen über 75 oder 80 Jahre), die institutionalisierten Alten und die (meist geistig) Labilen (Demente)" (Kühn &amp; Porst, 1999, S. 27). Mit Blick auf den nachfolgend dokumentierten Einsatz der BDGS-Skala in diversen Erhebungen wird deutlich werden, dass jene Personen der ganz Alten in vernachlässigbarer Anzahl teilgenommen haben. Dies liegt schon darin begründet, dass die durchgeführten Befragungen online stattfanden, was nachfolgend diskutiert wird. Dennoch kann diese Befragtengruppe nicht gänzlich vernachlässigt werden, da sie doch gleichsam zur Grundgesamtheit zählt und einen beachtlichen und zunehmenden Anteil an der Wahlbevölkerung umfasst (Falter &amp; Gehring, 1998). Etwaige Problemlagen müssen mithin mit Blick auf den zukünftigen Einsatz einer BDGS-Skala je nach Forschungsinteresse berücksichtigt werden. Zusammengefasst bedeutet dies zunächst, dass es keine Gruppe unter den potentiellen Befragten geben sollte, die aufgrund soziodemografischer Merkmale durch das Instrument systematisch benachteiligt wird und keine valide Beantwortung des Tests erbringen könnte.</p>
        <p>Es gibt ebenso eine ganze Reihe von Personen mit einer spezifischen Perspektive auf ihr eigenes Erlebens-und Verhaltensspektrum im Rahmen digitaler Daten. Bspw. diejenigen, die aus der eigenen intensiven Beschäftigung mit digitalen Daten eine spezielle Wahrnehmung entwickelt haben, die auf die Beantwortung der zu entwickelnden Skala durchschlägt. Gemeint sind hier allen voran Technikaffine aus dem Spektrum der Self-Tracker und der Quantified-Self -Bewegung, für die ebenfalls die Itemschwierigkeit bedacht werden muss (Nafus &amp; Sherman, 2014;Neff &amp; Nafus, 2016). Diese Personen entstammen möglicherweise einem anderen Erlebens-und Verhaltensspektrum und es könnte für sie mithin einfacher sein, die Testfragen zu beantworten. Gleiches könnte auch für Expert*innen auf dem Gebiet der Digitalisierung zutreffen, die aufgrund ihres beruflichen Hintergrunds und der Nähe zu Themen der Digitalisierung ein entsprechend verändertes Erlebens-und Verhaltensspektrum aufweisen (van der Aalst, 2014). Allerdings sollte bei der Skalenkonstruktion so allgemein über die Qualität von großen Datenmengen für einen Erkenntnis-und Nutzengewinn befragt werden, dass es analog zu Alter und Bildung keinen fundamentalen Unterschied zwischen dieser Gruppe und anderen Gruppen gibt, die einer reliablen und vor allem validen Beantwortung des Tests in diesen speziellen Gruppen entgegensteht. Es liegt in der Natur des Tests, dass eben solche Personen, die sich ausgiebig beruflich oder privat mit der Digitalisierung oder mit digitalen Daten beschäftigen, eine andere Sicht auf die Befragungsitems haben. Jedoch ist dies noch kein Hinweis darauf, dass das BDGS bei diesen Personen, wenn auch möglicherweise anders ausgeprägt, mit der vorgeschlagenen Messung überhaupt nicht zu erfassen sein sollte, etwa, weil diese Personen etwas gänzlich anderes unter digitalen Daten verstehen, als es die vorliegende Skalenkonstruktion untersucht. 4Herausforderungen der BDGS-Messung bei Offlinern Es ist hingegen durchaus vorstellbar, dass Personen, ganz gleich welchen Alters, die sich der Digitalisierung aktiv oder zufällig entziehen, bspw. sogenannte Offliner (Cachelin, 2015), mit den auf digitale Daten abzielenden Formulierungen nichts anfangen können, weil ihnen möglicherweise die Begrifflichkeiten einfach unbekannt sind. Auch hier ist allerdings davon auszugehen, dass der Großteil der möglichen Befragten aus dieser Gruppe zumindest über allgemeine (Offline-) Medienrezeption durchaus mit den Begrifflichkeiten bezüglich der Digitalisierung vertraut ist.Es gibt ebenso eine ganze Reihe von Personen mit einer spezifischen Perspektive auf ihr eigenes Erlebens-und Verhaltensspektrum im Rahmen digitaler Daten. Bspw. diejenigen, die aus der eigenen intensiven Beschäftigung mit digitalen Daten eine spezielle Wahrnehmung entwickelt haben, die auf die Beantwortung der zu entwickelnden Skala durchschlägt. Gemeint sind hier allen voran Technikaffine aus dem Spektrum der Self-Tracker und der Quantified-Self -Bewegung, für die ebenfalls die Itemschwierigkeit bedacht werden muss (Nafus &amp; Sherman, 2014;Neff &amp; Nafus, 2016). Diese Personen entstammen möglicherweise einem anderen Erlebens-und Verhaltensspektrum und es könnte für sie mithin einfacher sein, die Testfragen zu beantworten. Gleiches könnte auch für Expert*innen auf dem Gebiet der Digitalisierung zutreffen, die aufgrund ihres beruflichen Hintergrunds und der Nähe zu Themen der Digitalisierung ein entsprechend verändertes Erlebens-und Verhaltensspektrum aufweisen (van der Aalst, 2014). Allerdings sollte bei der Skalenkonstruktion so allgemein über die Qualität von großen Datenmengen für einen Erkenntnis-und Nutzengewinn befragt werden, dass es analog zu Alter und Bildung keinen fundamentalen Unterschied zwischen dieser Gruppe und anderen Gruppen gibt, die einer reliablen und vor allem validen Beantwortung des Tests in diesen speziellen Gruppen entgegensteht. Es liegt in der Natur des Tests, dass eben solche Personen, die sich ausgiebig beruflich oder privat mit der Digitalisierung oder mit digitalen Daten beschäftigen, eine andere Sicht auf die Befragungsitems haben. Jedoch ist dies noch kein Hinweis darauf, dass das BDGS bei diesen Personen, wenn auch möglicherweise anders ausgeprägt, mit der vorgeschlagenen Messung überhaupt nicht zu erfassen sein sollte, etwa, weil diese Personen etwas gänzlich anderes unter digitalen Daten verstehen, als es die vorliegende Skalenkonstruktion untersucht. 4Herausforderungen der BDGS-Messung bei Offlinern Es ist hingegen durchaus vorstellbar, dass Personen, ganz gleich welchen Alters, die sich der Digitalisierung aktiv oder zufällig entziehen, bspw. sogenannte Offliner (Cachelin, 2015), mit den auf digitale Daten abzielenden Formulierungen nichts anfangen können, weil ihnen möglicherweise die Begrifflichkeiten einfach unbekannt sind. Auch hier ist allerdings davon auszugehen, dass der Großteil der möglichen Befragten aus dieser Gruppe zumindest über allgemeine (Offline-) Medienrezeption durchaus mit den Begrifflichkeiten bezüglich der Digitalisierung vertraut ist.</p>
        <p>Diese Annahme stützt sich auf aktuelle Umfragen zur Internetnutzung und Wahrnehmung der Digitalisierung. Während je nach Quelle im Jahr 2017 zwischen 81 % (Statista, 2018b) und 89,8 % (Koch &amp; Frees, 2017) der deutschen Bevölkerung zu den Internetnutzer*innen zählen, zeigen europaweite Umfragen zur öffentlichen Meinung zur Digitalisierung, dass sich ein Großteil der Bürger*innen ein Urteil über die Auswirkungen der Digitalisierung auf die Gesellschaft zutraut (Europäische Kommission, 2010). Gefragt nach ihrer Einschätzung zum Einfluss digitaler Technologien auf die Wirtschaft geben lediglich 2 % der befragten Personen in Europa offen zu, nicht genug über digitale Technologien zu wissen, um eine Einschätzung geben zu können, und weitere 8 % wählen die begründungslose "weiß nicht"-Option. Könnten sich Personen, die keine oder kaum persönliche Berührungspunkte mit der Digitalisierung haben, kein Urteil bilden, müssten eben jene Ausweichkategorien wie "keine Angabe", "weiß nicht" und insbesondere das qualifizierte Nicht-Wissen zu digitalen Technologien stärker besetzt sein. 5 So zeigen auch aktuelle Umfragen zu KI, einer speziellen datenbasierten Digitalisierungsanwendung (siehe Abschnitt 3.6), der in jüngster Zeit ein großes Interesse zukommt, dass sich auch hier ein Großteil der befragten Personen in Deutschland Aussagen zutraut: Laut einer Studie von Bitkom aus dem Herbst 2018 konnten nur 12 % der Befragten überhaupt nichts mit dem Begriff der KI anfangen (Bitkom, 2018b). Dies sagt an dieser Stelle noch nichts über die tatsächliche Validität der Messungen in den genannten Befragungen aus, sondern dokumentiert lediglich, dass für die BDGS-Skala nicht damit zu rechnen ist, dass in Befragungen mit einer heterogenen Zusammensetzung hohe Ausfallquoten (sprich: höher als ca. 10 %) zu erwarten sind. Die Möglichkeit von Befragungsartefakten wie Non-Opinions, also das Produzieren von Meinungsartefakten, obwohl keine Meinung oder kein Wissen über das Meinungsobjekt vorliegt, bleibt hiervon zunächst einmal unberührt (Bachleitner &amp; Aschauer, 2008;Brosius et al., 2008). Es wird daher davon ausgegangen, dass der Pool der Personen, die mit den Items zu digitalen Daten in Kontakt kommen und hiermit nichts anfangen können, zwar nicht vernachlässigbar, aber doch so gering ist, dass das Unterfangen einer allgemeinen Skala zum Glaubenssystem, die in der empirischen Sozialforschung eingesetzt werden kann, zunächst einmal nicht als aussichtslos erscheint. Allerdings wurde aus Vorsicht in der ersten Erhebung noch die Möglichkeit einer "weiß nicht"-Option gegeben. Auf das Ausmaß der Wahl dieser Option wird in Abschnitt 9.1.3 eingegangen und dokumentiert, inwiefern die Unmöglichkeit einer Antwort bei einem heterogenen Befragtensample zu erwarten ist. 5 Eine kurze Anmerkung zum zu erwartenden Ausmaß der Non-response-Quote auf einzelne Befragungsitems: Ferber (1966) berichtet aus einer postalischen Paper-and-Pencil-Studie, in der lediglich 37,5 % der Befragten vollständige Antworten gaben, also im Umkehrschluss 62,5 % der Befragten mindestens eine Frage nicht beantworteten. Mit Blick auf einzelne Items berichtet die Methodenforschung Non-response-Quoten zwischen 2,9 und 8 % (Craig &amp; Mccann, 1978). Anzumerken ist hierbei, dass in Befragungsstudien zu persönlich sensiblen Themen wie dem individuellen Gesundheitszustand durchaus hohe Item-Nonresponse-Quoten von bis zu 50 % auftreten können (Elliott et al., 2005). Auf dieser Grundlage erscheinen Item-Nonresponse-Quoten von ca. 10 % durchaus üblich und lassen demnach nicht erwarten, verzerrte oder nicht aussagekräftige Erkenntnisse bezüglich Digitalisierungs-Prädispositionen in der Bevölkerung zu produzieren. (Hatlevik et al., 2017;Steinmetz et al., 2009). Es bestehen dann auch durchaus strenge Ansprüche an die Entwicklung und Validierung einer Messung, die für komparative Forschung herangezogen werden kann und die eine einfache Übersetzung und den ungeprüften Einsatz der final verwendeten BDGS-Skala unzulässig erscheinen lässt (Harkness, 1998;Harkness et al., 2010).Diese Annahme stützt sich auf aktuelle Umfragen zur Internetnutzung und Wahrnehmung der Digitalisierung. Während je nach Quelle im Jahr 2017 zwischen 81 % (Statista, 2018b) und 89,8 % (Koch &amp; Frees, 2017) der deutschen Bevölkerung zu den Internetnutzer*innen zählen, zeigen europaweite Umfragen zur öffentlichen Meinung zur Digitalisierung, dass sich ein Großteil der Bürger*innen ein Urteil über die Auswirkungen der Digitalisierung auf die Gesellschaft zutraut (Europäische Kommission, 2010). Gefragt nach ihrer Einschätzung zum Einfluss digitaler Technologien auf die Wirtschaft geben lediglich 2 % der befragten Personen in Europa offen zu, nicht genug über digitale Technologien zu wissen, um eine Einschätzung geben zu können, und weitere 8 % wählen die begründungslose "weiß nicht"-Option. Könnten sich Personen, die keine oder kaum persönliche Berührungspunkte mit der Digitalisierung haben, kein Urteil bilden, müssten eben jene Ausweichkategorien wie "keine Angabe", "weiß nicht" und insbesondere das qualifizierte Nicht-Wissen zu digitalen Technologien stärker besetzt sein. 5 So zeigen auch aktuelle Umfragen zu KI, einer speziellen datenbasierten Digitalisierungsanwendung (siehe Abschnitt 3.6), der in jüngster Zeit ein großes Interesse zukommt, dass sich auch hier ein Großteil der befragten Personen in Deutschland Aussagen zutraut: Laut einer Studie von Bitkom aus dem Herbst 2018 konnten nur 12 % der Befragten überhaupt nichts mit dem Begriff der KI anfangen (Bitkom, 2018b). Dies sagt an dieser Stelle noch nichts über die tatsächliche Validität der Messungen in den genannten Befragungen aus, sondern dokumentiert lediglich, dass für die BDGS-Skala nicht damit zu rechnen ist, dass in Befragungen mit einer heterogenen Zusammensetzung hohe Ausfallquoten (sprich: höher als ca. 10 %) zu erwarten sind. Die Möglichkeit von Befragungsartefakten wie Non-Opinions, also das Produzieren von Meinungsartefakten, obwohl keine Meinung oder kein Wissen über das Meinungsobjekt vorliegt, bleibt hiervon zunächst einmal unberührt (Bachleitner &amp; Aschauer, 2008;Brosius et al., 2008). Es wird daher davon ausgegangen, dass der Pool der Personen, die mit den Items zu digitalen Daten in Kontakt kommen und hiermit nichts anfangen können, zwar nicht vernachlässigbar, aber doch so gering ist, dass das Unterfangen einer allgemeinen Skala zum Glaubenssystem, die in der empirischen Sozialforschung eingesetzt werden kann, zunächst einmal nicht als aussichtslos erscheint. Allerdings wurde aus Vorsicht in der ersten Erhebung noch die Möglichkeit einer "weiß nicht"-Option gegeben. Auf das Ausmaß der Wahl dieser Option wird in Abschnitt 9.1.3 eingegangen und dokumentiert, inwiefern die Unmöglichkeit einer Antwort bei einem heterogenen Befragtensample zu erwarten ist. 5 Eine kurze Anmerkung zum zu erwartenden Ausmaß der Non-response-Quote auf einzelne Befragungsitems: Ferber (1966) berichtet aus einer postalischen Paper-and-Pencil-Studie, in der lediglich 37,5 % der Befragten vollständige Antworten gaben, also im Umkehrschluss 62,5 % der Befragten mindestens eine Frage nicht beantworteten. Mit Blick auf einzelne Items berichtet die Methodenforschung Non-response-Quoten zwischen 2,9 und 8 % (Craig &amp; Mccann, 1978). Anzumerken ist hierbei, dass in Befragungsstudien zu persönlich sensiblen Themen wie dem individuellen Gesundheitszustand durchaus hohe Item-Nonresponse-Quoten von bis zu 50 % auftreten können (Elliott et al., 2005). Auf dieser Grundlage erscheinen Item-Nonresponse-Quoten von ca. 10 % durchaus üblich und lassen demnach nicht erwarten, verzerrte oder nicht aussagekräftige Erkenntnisse bezüglich Digitalisierungs-Prädispositionen in der Bevölkerung zu produzieren. (Hatlevik et al., 2017;Steinmetz et al., 2009). Es bestehen dann auch durchaus strenge Ansprüche an die Entwicklung und Validierung einer Messung, die für komparative Forschung herangezogen werden kann und die eine einfache Übersetzung und den ungeprüften Einsatz der final verwendeten BDGS-Skala unzulässig erscheinen lässt (Harkness, 1998;Harkness et al., 2010).</p>
        <p>Schwierigkeitsunterschiede einzelner Frageitems zwischen einzelnen Befragten-Gruppen können auch auf eine mangelnde Item-und Testfairness eines Tests hinweisen, die bestimmte Gruppen systematisch benachteiligt, bspw. durch schwer erkennbare Schriftgrößen für ältere Befragungsteilnehmer*innen (Bühner, 2011;Kühn &amp; Porst, 1999). Auch hier sollte mangelnde Testfairness dadurch verhindert werden, dass mit einem standardisierten und somit für alle Befragtengruppen gleich zugänglichen Fragebogendesign sowie allgemein verständlich formuliert über die Glaubensüberzeugungen bezüglich großer digitaler Datenmengen befragt wird und Frageinhalt und Frageformulierung es allen Befragten ermöglichen, ihre persönliche Einschätzung abzugeben. Eine Bevorzugung oder Benachteiligung durch die Vertrautheit mit ähnlichen Tests oder den Einfluss kultureller Zugehörigkeit sollte durch die Verwendung eines standardisierten Tests, der Q-Daten (d. h. Selbst-oder Fremdratings) mit allgemeinverständlicher Formulierung erhebt und sich auf die Zielgruppe der deutschsprachigen Bevölkerung beschränkt, vermieden sein.Schwierigkeitsunterschiede einzelner Frageitems zwischen einzelnen Befragten-Gruppen können auch auf eine mangelnde Item-und Testfairness eines Tests hinweisen, die bestimmte Gruppen systematisch benachteiligt, bspw. durch schwer erkennbare Schriftgrößen für ältere Befragungsteilnehmer*innen (Bühner, 2011;Kühn &amp; Porst, 1999). Auch hier sollte mangelnde Testfairness dadurch verhindert werden, dass mit einem standardisierten und somit für alle Befragtengruppen gleich zugänglichen Fragebogendesign sowie allgemein verständlich formuliert über die Glaubensüberzeugungen bezüglich großer digitaler Datenmengen befragt wird und Frageinhalt und Frageformulierung es allen Befragten ermöglichen, ihre persönliche Einschätzung abzugeben. Eine Bevorzugung oder Benachteiligung durch die Vertrautheit mit ähnlichen Tests oder den Einfluss kultureller Zugehörigkeit sollte durch die Verwendung eines standardisierten Tests, der Q-Daten (d. h. Selbst-oder Fremdratings) mit allgemeinverständlicher Formulierung erhebt und sich auf die Zielgruppe der deutschsprachigen Bevölkerung beschränkt, vermieden sein.</p>
        <p>Mithin wurde bei der folgenden Itemerstellung berücksichtigt, dass Format, Formulierung und Schwierigkeit des zu konzipierenden Tests weder einzelne Befragte noch ganze Teilgruppen der Zielgruppe systematisch benachteiligen. Da die Befragungsstudien in dieser Arbeit durchweg mit Hilfe der Fragebogen-Software 
            <rs type="software">SoSci Survey</rs>
            <rs type="version">6</rs> auf digitalen Computermedien durchgeführt wurden, waren so gut wie alle Fragebögen und die Fragebogenseite mit der BDGS-Skala barrierefrei zugänglich. So konnten auch Personen mit eingeschränktem Sehvermögen problemlos teilnehmen (bspw. durch Verwendung eines ScreenReaders).
        </p>
        <p>Neben Einflüssen auf die Beantwortung der Frageitems einer Skala, die durch spezielle Eigenschaften der Zielgruppe bedingt sein können, müssen auch allgemeine von der Zielgruppe unabhängige Entscheidungen bezüglich der Itemformulierung und insbesondere auch der Skalierung bei der Skalenkonstruktion berücksichtigt werden. Die gewählte Skala wird im Sinne der vorgeschlagenen Ratingskala von Likert (1932) erhoben, so dass mehrere Aussagen (im Folgenden auch Items genannt) als Indikatoren einer Dimension dienen. Die Antwortdimensionen der Skalen sollen den Grad der Zustimmung zu den Aussagen über das Wesen digitaler Daten und ihrer Speicherung und Auswertung abbilden, weshalb der "Grad der Zustimmung" (Faulbaum et al., 2009, S. 23) in der vorliegenden Arbeit durch eine Zustimmungsskala abgefragt wird. Die Aussagen, im Folgenden auch Glaubenssätze genannt, sind keine Fragen im eigentlichen Sinne, sondern als Aussagesätze formuliert. Als Antwort auf die vermeintlichen Fragen ist dann der explizite Zustimmungsgrad der Aussage zu werten, die von den Befragten erbeten wird. Die Zustimmung (ab hier immer auch gedacht als mögliche Nicht-Zustimmung) kann dann auf einer mehrstufigen Skala je nach Ausprägungsintensität abgestuft werden. Diese Stufen werden als Skalenpunkte bezeichnet. Es ist mit Blick auf die Skalenpunkte u. a. zu entscheiden, ob (a) die Skalierung gerade oder ungerade ausfallen soll, (b) auf wie vielen Skalenpunkten die Befragten ihre Antworten abstufen können und (c) ob und wie die einzelnen Skalenpunkte benannt werden.Neben Einflüssen auf die Beantwortung der Frageitems einer Skala, die durch spezielle Eigenschaften der Zielgruppe bedingt sein können, müssen auch allgemeine von der Zielgruppe unabhängige Entscheidungen bezüglich der Itemformulierung und insbesondere auch der Skalierung bei der Skalenkonstruktion berücksichtigt werden. Die gewählte Skala wird im Sinne der vorgeschlagenen Ratingskala von Likert (1932) erhoben, so dass mehrere Aussagen (im Folgenden auch Items genannt) als Indikatoren einer Dimension dienen. Die Antwortdimensionen der Skalen sollen den Grad der Zustimmung zu den Aussagen über das Wesen digitaler Daten und ihrer Speicherung und Auswertung abbilden, weshalb der "Grad der Zustimmung" (Faulbaum et al., 2009, S. 23) in der vorliegenden Arbeit durch eine Zustimmungsskala abgefragt wird. Die Aussagen, im Folgenden auch Glaubenssätze genannt, sind keine Fragen im eigentlichen Sinne, sondern als Aussagesätze formuliert. Als Antwort auf die vermeintlichen Fragen ist dann der explizite Zustimmungsgrad der Aussage zu werten, die von den Befragten erbeten wird. Die Zustimmung (ab hier immer auch gedacht als mögliche Nicht-Zustimmung) kann dann auf einer mehrstufigen Skala je nach Ausprägungsintensität abgestuft werden. Diese Stufen werden als Skalenpunkte bezeichnet. Es ist mit Blick auf die Skalenpunkte u. a. zu entscheiden, ob (a) die Skalierung gerade oder ungerade ausfallen soll, (b) auf wie vielen Skalenpunkten die Befragten ihre Antworten abstufen können und (c) ob und wie die einzelnen Skalenpunkte benannt werden.</p>
        <p>Bei einer ungeraden Anzahl an Skalenpunkten gibt es eine Mischkategorie, bei der man einen Übergang zwischen Zustimmung und Nicht-Zustimmung hat. Dies erleichtert vor allem unsicheren Befragten die Beantwortung und lässt Ambivalenz zu, führt allerdings auch häufig dazu, dass der Skalenmittelpunkt als eben jene Ausweichkategorie gesehen wird, die er eigentlich gar nicht darstellen soll. Zudem gibt es bei Befragten eine gut dokumentierte ‚Tendenz zur Mitte' (Menold &amp; Bogner, 2014). Es würden dann Personen, die eigentlich überhaupt keine Zustimmung zur Aussage geben können, mit jenen zusammengeworfen, die zwar eine Antwort geben können, jedoch zwischen Zustimmung und Ablehnung unentschieden sind und gute Argumente für beide Positionen haben. Die Itemformulierungen werden unter Verwendung von Ausweichmöglichkeiten, seien es Skalenmittelpunkte bei ungeraden Skalenpunkten oder eine "weiß nicht"-Option, möglicherweise nicht in der beabsichtigten Bearbeitungstiefe verarbeitet, da sich Befragte eben auf ihre Unentschiedenheit zurückziehen. Dieses Phänomen ist auch als Satisficing bekannt, eine Strategie der Befragten, um sich kognitive Arbeit bei der Beantwortung von Fragen zu ersparen (Krosnick, 1991;Krosnick et al., 1996;Krosnick et al., 2001). Bei gerader Anzahl an Skalenpunkten sind die Befragten hingegen gezwungen, sich zu entscheiden. Diese Festlegung könnte zum einen dazu führen, dass Befragte verunsichert werden können, sie insgesamt länger nachdenken und sich somit die Bearbeitungszeit verlängert. Dies in Kombination mit möglicher Reaktanz könnte schneller zu einer Ermüdung führen und die Abbruchquote erhöhen.Bei einer ungeraden Anzahl an Skalenpunkten gibt es eine Mischkategorie, bei der man einen Übergang zwischen Zustimmung und Nicht-Zustimmung hat. Dies erleichtert vor allem unsicheren Befragten die Beantwortung und lässt Ambivalenz zu, führt allerdings auch häufig dazu, dass der Skalenmittelpunkt als eben jene Ausweichkategorie gesehen wird, die er eigentlich gar nicht darstellen soll. Zudem gibt es bei Befragten eine gut dokumentierte ‚Tendenz zur Mitte' (Menold &amp; Bogner, 2014). Es würden dann Personen, die eigentlich überhaupt keine Zustimmung zur Aussage geben können, mit jenen zusammengeworfen, die zwar eine Antwort geben können, jedoch zwischen Zustimmung und Ablehnung unentschieden sind und gute Argumente für beide Positionen haben. Die Itemformulierungen werden unter Verwendung von Ausweichmöglichkeiten, seien es Skalenmittelpunkte bei ungeraden Skalenpunkten oder eine "weiß nicht"-Option, möglicherweise nicht in der beabsichtigten Bearbeitungstiefe verarbeitet, da sich Befragte eben auf ihre Unentschiedenheit zurückziehen. Dieses Phänomen ist auch als Satisficing bekannt, eine Strategie der Befragten, um sich kognitive Arbeit bei der Beantwortung von Fragen zu ersparen (Krosnick, 1991;Krosnick et al., 1996;Krosnick et al., 2001). Bei gerader Anzahl an Skalenpunkten sind die Befragten hingegen gezwungen, sich zu entscheiden. Diese Festlegung könnte zum einen dazu führen, dass Befragte verunsichert werden können, sie insgesamt länger nachdenken und sich somit die Bearbeitungszeit verlängert. Dies in Kombination mit möglicher Reaktanz könnte schneller zu einer Ermüdung führen und die Abbruchquote erhöhen.</p>
        <p>Unter Berücksichtigung des angesprochenen Für und Wider bei der Wahl zwischen einer geraden oder ungeraden Skalierung wurde sich für eine ungerade Skalierung entschieden, da vermeintliche Probleme wie Reaktanz und Verzögerung bei der Bearbeitung schwerer wiegen als die Tendenz zur Mitte sowie Satisficing und auch eher dazu führen könnten, auf die weitere Beantwortung in einer Befragungsstudie auszustrahlen, in der die BDGS eingesetzt wird. Eine finale Klärung der Frage nach der präferierten Art der Skalierung ist hier entsprechender Methodenforschung vorbehalten.Unter Berücksichtigung des angesprochenen Für und Wider bei der Wahl zwischen einer geraden oder ungeraden Skalierung wurde sich für eine ungerade Skalierung entschieden, da vermeintliche Probleme wie Reaktanz und Verzögerung bei der Bearbeitung schwerer wiegen als die Tendenz zur Mitte sowie Satisficing und auch eher dazu führen könnten, auf die weitere Beantwortung in einer Befragungsstudie auszustrahlen, in der die BDGS eingesetzt wird. Eine finale Klärung der Frage nach der präferierten Art der Skalierung ist hier entsprechender Methodenforschung vorbehalten.</p>
        <p>Ein Blick in die Methodenliteratur zur Befragungsforschung offenbart etliche unterschiedliche Empfehlungen zur Anzahl und visuellen Ausrichtung der Skalenpunkte (Faulbaum et al., 2009, S. 65-66;Menold &amp; Bogner, 2014;Scholl, 2018, S. 167 ff.). Eine Skalierung mit sieben Skalenpunkten scheint im vorliegenden Falle sinnvoll, da dies mit Verweis auf die Erkenntnisse der Methodenforschung zur Befragung eine ausreichend hohe Reliabilität gewährleistet (Alwin &amp; Krosnick, 1991;Groves et al., 2011). Die einzelnen Skalenpunkte werden im vorliegenden Fall von links nach rechts von Nicht-Zustimmung zu Zustimmung abgestuft, so dass bei der Zuweisung der numerischen Werte für die Datenanalyse eine 1 für Nicht-Zustimmung der Aussage steht und mit Zwischenschritten in ganzen Zahlen hin zu 7 verläuft, was für vollkommene Zustimmung steht. Die Skala ist somit unipolar und die Skalenorientierung verläuft von links nach rechts. Während es zu diesen Entscheidungen laut Menold und Bogner (2014) keine klaren Empfehlungen gibt, wurden die dokumentierten Entscheidungen hier entsprechend getroffen, um einen einheitlichen und weitgehend standardisierten Skalenaufbau zu gewährleisten.Ein Blick in die Methodenliteratur zur Befragungsforschung offenbart etliche unterschiedliche Empfehlungen zur Anzahl und visuellen Ausrichtung der Skalenpunkte (Faulbaum et al., 2009, S. 65-66;Menold &amp; Bogner, 2014;Scholl, 2018, S. 167 ff.). Eine Skalierung mit sieben Skalenpunkten scheint im vorliegenden Falle sinnvoll, da dies mit Verweis auf die Erkenntnisse der Methodenforschung zur Befragung eine ausreichend hohe Reliabilität gewährleistet (Alwin &amp; Krosnick, 1991;Groves et al., 2011). Die einzelnen Skalenpunkte werden im vorliegenden Fall von links nach rechts von Nicht-Zustimmung zu Zustimmung abgestuft, so dass bei der Zuweisung der numerischen Werte für die Datenanalyse eine 1 für Nicht-Zustimmung der Aussage steht und mit Zwischenschritten in ganzen Zahlen hin zu 7 verläuft, was für vollkommene Zustimmung steht. Die Skala ist somit unipolar und die Skalenorientierung verläuft von links nach rechts. Während es zu diesen Entscheidungen laut Menold und Bogner (2014) keine klaren Empfehlungen gibt, wurden die dokumentierten Entscheidungen hier entsprechend getroffen, um einen einheitlichen und weitgehend standardisierten Skalenaufbau zu gewährleisten.</p>
        <p>Zudem wird die Zustimmung durch adverbiale Modifikationen abgestuft, wobei alle Skalenpunkte und nicht nur die Skalenendpunkte beschriftet werden (Faulbaum et al., 2009). Es wurde zwar zunächst beabsichtigt, nur die Skalenendpunkte zu beschriften, nach einem Hinweis aus einem persönlichen Interview des Pre-Tests (siehe Abschnitt 8.5.3) wurde die vollständige Beschriftung der Skala beschlossen. In der Literatur der Methodenforschung finden sich auch hierzu Empfehlungen: Laut Krosnick (1999) können hierdurch die Reliabilität und Validität der Beantwortung erhöht werden. So kommen auch Weijters et al. (2010) zu dem Schluss, dass für die Skalenentwicklung vollständig beschriftete Skalenpunkte verwendet werden sollten. Dies kann zudem zu einer höheren Befragtenzufriedenheit führen (Dickinson &amp; Zellinger, 1980), Ambiguität reduzieren und die Test-Retest-Reliabilität verbessern (Weng, 2004).Zudem wird die Zustimmung durch adverbiale Modifikationen abgestuft, wobei alle Skalenpunkte und nicht nur die Skalenendpunkte beschriftet werden (Faulbaum et al., 2009). Es wurde zwar zunächst beabsichtigt, nur die Skalenendpunkte zu beschriften, nach einem Hinweis aus einem persönlichen Interview des Pre-Tests (siehe Abschnitt 8.5.3) wurde die vollständige Beschriftung der Skala beschlossen. In der Literatur der Methodenforschung finden sich auch hierzu Empfehlungen: Laut Krosnick (1999) können hierdurch die Reliabilität und Validität der Beantwortung erhöht werden. So kommen auch Weijters et al. (2010) zu dem Schluss, dass für die Skalenentwicklung vollständig beschriftete Skalenpunkte verwendet werden sollten. Dies kann zudem zu einer höheren Befragtenzufriedenheit führen (Dickinson &amp; Zellinger, 1980), Ambiguität reduzieren und die Test-Retest-Reliabilität verbessern (Weng, 2004).</p>
        <p>Mithin wird für den Skalenpunkt 1 die Antwort "stimme überhaupt nicht zu" und für den Skalenpunkt 7 die Antwort "stimme voll und ganz zu" vergeben, so dass die Valenz der Skalierung mit aufsteigender Zustimmung von links nach rechts verläuft. Der Skalenmittelpunkt, also Punkt 4 wurde mit "Teils/teils" beschriftet, um Ambivalenz zu signalisieren (Menold &amp; Bogner, 2014). Die zur Nicht-Zustimmung tendierenden Zwischenpunkte auf der Skala werden für Punkt 2 mit "stimme größtenteils nicht zu" und Punkt 3 mit "stimme eher nicht zu" beschriftet. Die zustimmenden Zwischenpunkte auf der Skala werden für Punkt 5 mit "stimme eher zu" und Punkt 6 mit "stimme größtenteils zu" beschriftet. Damit der Skalenmittelpunkt von den Befragten nicht als Fluchtkategorie verwendet wird, besteht in der ersten Erhebung für die Befragten die Möglichkeit, durch die Antwortoption "Kann ich nicht beantworten" anzuzeigen, dass das Item eben nicht beantwortet werden kann. Dies könnte dann ein Hinweis auf Formulierungsprobleme und die Beantwortungsschwierigkeit sein und wurde bei der Auswahl der finalen Items berücksichtigt.Mithin wird für den Skalenpunkt 1 die Antwort "stimme überhaupt nicht zu" und für den Skalenpunkt 7 die Antwort "stimme voll und ganz zu" vergeben, so dass die Valenz der Skalierung mit aufsteigender Zustimmung von links nach rechts verläuft. Der Skalenmittelpunkt, also Punkt 4 wurde mit "Teils/teils" beschriftet, um Ambivalenz zu signalisieren (Menold &amp; Bogner, 2014). Die zur Nicht-Zustimmung tendierenden Zwischenpunkte auf der Skala werden für Punkt 2 mit "stimme größtenteils nicht zu" und Punkt 3 mit "stimme eher nicht zu" beschriftet. Die zustimmenden Zwischenpunkte auf der Skala werden für Punkt 5 mit "stimme eher zu" und Punkt 6 mit "stimme größtenteils zu" beschriftet. Damit der Skalenmittelpunkt von den Befragten nicht als Fluchtkategorie verwendet wird, besteht in der ersten Erhebung für die Befragten die Möglichkeit, durch die Antwortoption "Kann ich nicht beantworten" anzuzeigen, dass das Item eben nicht beantwortet werden kann. Dies könnte dann ein Hinweis auf Formulierungsprobleme und die Beantwortungsschwierigkeit sein und wurde bei der Auswahl der finalen Items berücksichtigt.</p>
        <p>Die Zuweisung der numerischen Werte erfolgte lediglich für die Auswertung. Den Befragten selbst wurden keine numerischen Werte für die jeweiligen Skalenpunkte angezeigt, da es bei ihnen hierdurch zu unbeabsichtigten Interpretationsprozessen bezüglich der Wertigkeiten der einzelnen Skalenpunkte kommen kann, was vermieden werden sollte (Krosnick, 1999;Schwarz et al., 1991).Die Zuweisung der numerischen Werte erfolgte lediglich für die Auswertung. Den Befragten selbst wurden keine numerischen Werte für die jeweiligen Skalenpunkte angezeigt, da es bei ihnen hierdurch zu unbeabsichtigten Interpretationsprozessen bezüglich der Wertigkeiten der einzelnen Skalenpunkte kommen kann, was vermieden werden sollte (Krosnick, 1999;Schwarz et al., 1991).</p>
        <p>Wie bereits zuvor erwähnt, soll an dieser Stelle mit Blick auf mögliche Verständnisschwierigkeiten des Befragungsgegenstandes Big Data auf den Einleitungstext des konzipierten Tests eingegangen werden. Die Fragenbatterie der BDGS-Skala wurde in allen Erhebungen mit diesem Einleitungstext eingeführt, um ein Grundverständnis bei allen Befragten über das herzustellen, was in der Einleitung und den Frageitems als ‚Digitale Daten' beschrieben wurde. Mit Hilfe interner Diskussionen am Arbeitsbereich von Prof. Dr. Marcinkowski samt Kollegen (siehe nachfolgend Abschnitt 8.5.2) und persönlicher Interviews mit der Methode des lauten Denkens, die genutzt wurden, um die Verständlichkeit der Frageitems für die erste Erhebung zu prüfen (siehe nachfolgend Abschnitt 8.5.3), wurden allgemeinverständliche Formulierungen und Beispiele gesammelt. Hier sollte ein allgemeines Verständnis über den Entstehungs-und Verwendungszusammenhang digitaler Daten im Sinne der vorliegenden Untersuchung vermittelt werden. Dabei sollte der Einleitungstext so einfach und kurz wie möglich sein und sollten die Beispiele allgemein gehalten werden, um die Befragten zwar zu informieren und ein einheitliches Verständnis des Gegenstandes herzustellen, zu dem befragt wird, eine Beeinflussung jedoch so weit möglich ausschließen.Wie bereits zuvor erwähnt, soll an dieser Stelle mit Blick auf mögliche Verständnisschwierigkeiten des Befragungsgegenstandes Big Data auf den Einleitungstext des konzipierten Tests eingegangen werden. Die Fragenbatterie der BDGS-Skala wurde in allen Erhebungen mit diesem Einleitungstext eingeführt, um ein Grundverständnis bei allen Befragten über das herzustellen, was in der Einleitung und den Frageitems als ‚Digitale Daten' beschrieben wurde. Mit Hilfe interner Diskussionen am Arbeitsbereich von Prof. Dr. Marcinkowski samt Kollegen (siehe nachfolgend Abschnitt 8.5.2) und persönlicher Interviews mit der Methode des lauten Denkens, die genutzt wurden, um die Verständlichkeit der Frageitems für die erste Erhebung zu prüfen (siehe nachfolgend Abschnitt 8.5.3), wurden allgemeinverständliche Formulierungen und Beispiele gesammelt. Hier sollte ein allgemeines Verständnis über den Entstehungs-und Verwendungszusammenhang digitaler Daten im Sinne der vorliegenden Untersuchung vermittelt werden. Dabei sollte der Einleitungstext so einfach und kurz wie möglich sein und sollten die Beispiele allgemein gehalten werden, um die Befragten zwar zu informieren und ein einheitliches Verständnis des Gegenstandes herzustellen, zu dem befragt wird, eine Beeinflussung jedoch so weit möglich ausschließen.</p>
        <p>Im Folgenden werden die einzelnen Schritte der Skalenkonstruktion beschrieben, insbesondere der Erstellung des Itempools, der in einer ersten Befragung auf die zugrunde liegende und aus der Literatur abgeleitete Dimensionalität des BDGS geprüft werden soll. Auf Grundlage der Definitionen der einzelnen Beschreibungsdimensionen von Big Data aus der wissenschaftlichen Literatur wurden Wörter extrahiert, die Volumen, Vielfalt, Geschwindigkeit, Richtigkeit und den Nutzen von Big Data sowie die jeweiligen Subdimensionen beschreiben, wobei eine direkte Nennung der Dimensionsbezeichnungen vermieden werden sollte. In einem weiteren Schritt wurden daher Synonyme und Umschreibungen zu diesen Wörtern gesucht. Eine Übersicht über den entstandenen Wortkorpus findet sich in Tabelle 2.A im Anhang im elektronischen Zusatzmaterial. Dieser Wortkorpus diente als Vorlage für die Formulierung der Items. Hierbei wurden nicht alle Begriffe auch tatsächlich in Itemformulierungen überführt. Gründe hierfür waren bspw., dass einfachere Begriffe bevorzugt wurden oder Begriffe mehrdeutig und vermeintlich missverständlich sein konnten. So wurde ‚korrekt' als nicht synonym für Genauigkeit aufgenommen, da das Wort häufig wertend verwendet wird ("Er ist ein korrekter Typ").Im Folgenden werden die einzelnen Schritte der Skalenkonstruktion beschrieben, insbesondere der Erstellung des Itempools, der in einer ersten Befragung auf die zugrunde liegende und aus der Literatur abgeleitete Dimensionalität des BDGS geprüft werden soll. Auf Grundlage der Definitionen der einzelnen Beschreibungsdimensionen von Big Data aus der wissenschaftlichen Literatur wurden Wörter extrahiert, die Volumen, Vielfalt, Geschwindigkeit, Richtigkeit und den Nutzen von Big Data sowie die jeweiligen Subdimensionen beschreiben, wobei eine direkte Nennung der Dimensionsbezeichnungen vermieden werden sollte. In einem weiteren Schritt wurden daher Synonyme und Umschreibungen zu diesen Wörtern gesucht. Eine Übersicht über den entstandenen Wortkorpus findet sich in Tabelle 2.A im Anhang im elektronischen Zusatzmaterial. Dieser Wortkorpus diente als Vorlage für die Formulierung der Items. Hierbei wurden nicht alle Begriffe auch tatsächlich in Itemformulierungen überführt. Gründe hierfür waren bspw., dass einfachere Begriffe bevorzugt wurden oder Begriffe mehrdeutig und vermeintlich missverständlich sein konnten. So wurde ‚korrekt' als nicht synonym für Genauigkeit aufgenommen, da das Wort häufig wertend verwendet wird ("Er ist ein korrekter Typ").</p>
        <p>Es stellt sich bereits bei der ersten Formulierung die Frage, wie viele Items, die später als Indikatoren für die Operationalisierung der jeweiligen Dimension eingesetzt werden, denn nun tatsächlich gebraucht werden und wie viele Items man nun für den ersten Schritt der Skalenkonstruktion vorsorglich formulieren müsse. Insbesondere im Rahmen des datenanalytischen Auswertungsverfahrens der konfirmatorischen Faktorenanalyse (‚Confirmatory Factor Analysis' -kurz: CFA) gilt zu bedenken, dass für die Identifikation der geschätzten Lösung eines reflektiven Messmodells eine ausreichende Anzahl von Indikatorvariablen in die Modelspezifikation eingehen muss:Es stellt sich bereits bei der ersten Formulierung die Frage, wie viele Items, die später als Indikatoren für die Operationalisierung der jeweiligen Dimension eingesetzt werden, denn nun tatsächlich gebraucht werden und wie viele Items man nun für den ersten Schritt der Skalenkonstruktion vorsorglich formulieren müsse. Insbesondere im Rahmen des datenanalytischen Auswertungsverfahrens der konfirmatorischen Faktorenanalyse (‚Confirmatory Factor Analysis' -kurz: CFA) gilt zu bedenken, dass für die Identifikation der geschätzten Lösung eines reflektiven Messmodells eine ausreichende Anzahl von Indikatorvariablen in die Modelspezifikation eingehen muss:</p>
        <p>A common question about CFA concerns a minimum number of indicators per factor. In general, the absolute minimum for CFA models with two or more factors is two indicators per factor, which is required for identification. However, CFA models -and SR [Structural Regression] models, too -with factors that have only two indicators are more prone to problems in the analysis, especially in small samples. Also, it may be difficult to estimate measurement error correlation for factors with only two indicators, which can result in a specification error. Kenny's (1979) rule of thumb about the number of indicators is apropos: 'Two might be fine, three is better, four is best, and anything more is gravy' (p. 143; emphasis in original). (Kline, 2011, S. 114-115) Auch Weiber und Mühlhaus (2014) greifen die Diskussion um die Anzahl auszuwählender Indikatoren auf und empfehlen "bei Mehr-Konstrukt-Modellen reflektive Konstrukte mindestens mit jeweils zwei Indikatoren zu messen" (S. 113). Diese Minimalanforderung scheint jedoch mit Blick auf erstmalige Testkonstruktion und den erwogenen Einsatz einer BDGS-Skala in diversen Forschungsprojekten mit unterschiedlichen Stichprobenzusammensetzungen und -größen als zu gering. Insbesondere bei kleineren Stichproben (bspw. in Experimentalstudien) empfehlen Marsh et al. (1998) eine größere Anzahl an Indikatoren, wobei ihrer Ansicht nach mehr Indikatoren generell besser sind als weniger Indikatoren. Gleichzeitig muss bedacht werden, dass eine große Anzahl von formal identischen Likert-Skalen von den Befragten als monoton wahrgenommen wird, die zu konstruierende Skala also nicht zu lang werden darf (Petersen, 2014;Ring, 1976). Nach Abwägung der Argumente wurde entschieden, mindestens drei Indikatoren zur Messung der jeweiligen Dimension des BDGS anzustreben.A common question about CFA concerns a minimum number of indicators per factor. In general, the absolute minimum for CFA models with two or more factors is two indicators per factor, which is required for identification. However, CFA models -and SR [Structural Regression] models, too -with factors that have only two indicators are more prone to problems in the analysis, especially in small samples. Also, it may be difficult to estimate measurement error correlation for factors with only two indicators, which can result in a specification error. Kenny's (1979) rule of thumb about the number of indicators is apropos: 'Two might be fine, three is better, four is best, and anything more is gravy' (p. 143; emphasis in original). (Kline, 2011, S. 114-115) Auch Weiber und Mühlhaus (2014) greifen die Diskussion um die Anzahl auszuwählender Indikatoren auf und empfehlen "bei Mehr-Konstrukt-Modellen reflektive Konstrukte mindestens mit jeweils zwei Indikatoren zu messen" (S. 113). Diese Minimalanforderung scheint jedoch mit Blick auf erstmalige Testkonstruktion und den erwogenen Einsatz einer BDGS-Skala in diversen Forschungsprojekten mit unterschiedlichen Stichprobenzusammensetzungen und -größen als zu gering. Insbesondere bei kleineren Stichproben (bspw. in Experimentalstudien) empfehlen Marsh et al. (1998) eine größere Anzahl an Indikatoren, wobei ihrer Ansicht nach mehr Indikatoren generell besser sind als weniger Indikatoren. Gleichzeitig muss bedacht werden, dass eine große Anzahl von formal identischen Likert-Skalen von den Befragten als monoton wahrgenommen wird, die zu konstruierende Skala also nicht zu lang werden darf (Petersen, 2014;Ring, 1976). Nach Abwägung der Argumente wurde entschieden, mindestens drei Indikatoren zur Messung der jeweiligen Dimension des BDGS anzustreben.</p>
        <p>Es muss an dieser Stelle jedoch nicht nur die final gewünschte Anzahl an Indikatoren pro Faktor bedacht werden, sondern auch, wie viele Items zunächst für einen ersten Aufschlag zur Testkonzeption vorbereitet werden, die dann womöglich aufgrund mangelnder Messgüte wieder eliminiert werden. Sowohl hier am Beginn der Testkonstruktion als auch mit Blick auf den letztendlichen Einsatz des Tests zur BDGS ist daher zwischen einer notwendigen Anzahl von Indikatoren für die jeweilige zu messende Dimension und der gebotenen Sparsamkeit bei der Fragebogenlänge abzuwägen. Hierbei muss neben Rücksicht auf die Konzentrationsfähigkeit auch der ‚Respondent Fatigue', also der generellen Unlust, an Befragungsstudien teilzunehmen (S. R. Porter et al., 2004), durch die Verwendung möglichst kurzer Skalen entgegengewirkt werden. Es erschien daher sinnvoll, mindestens drei Items für die jeweiligen Subdimensionen zu formulieren, um sowohl zumindest die Unterscheidungsfähigkeit der Subdimensionen Entstehung, Speicherung und Auswertung zu prüfen (siehe Seite 93) als auch die Möglichkeit zuzulassen, ggf. unpassende Items zu eliminieren, weshalb immer mindestens vier, vereinzelt jedoch auch acht Items formuliert wurden.Es muss an dieser Stelle jedoch nicht nur die final gewünschte Anzahl an Indikatoren pro Faktor bedacht werden, sondern auch, wie viele Items zunächst für einen ersten Aufschlag zur Testkonzeption vorbereitet werden, die dann womöglich aufgrund mangelnder Messgüte wieder eliminiert werden. Sowohl hier am Beginn der Testkonstruktion als auch mit Blick auf den letztendlichen Einsatz des Tests zur BDGS ist daher zwischen einer notwendigen Anzahl von Indikatoren für die jeweilige zu messende Dimension und der gebotenen Sparsamkeit bei der Fragebogenlänge abzuwägen. Hierbei muss neben Rücksicht auf die Konzentrationsfähigkeit auch der ‚Respondent Fatigue', also der generellen Unlust, an Befragungsstudien teilzunehmen (S. R. Porter et al., 2004), durch die Verwendung möglichst kurzer Skalen entgegengewirkt werden. Es erschien daher sinnvoll, mindestens drei Items für die jeweiligen Subdimensionen zu formulieren, um sowohl zumindest die Unterscheidungsfähigkeit der Subdimensionen Entstehung, Speicherung und Auswertung zu prüfen (siehe Seite 93) als auch die Möglichkeit zuzulassen, ggf. unpassende Items zu eliminieren, weshalb immer mindestens vier, vereinzelt jedoch auch acht Items formuliert wurden.</p>
        <p>Der so entstandene Itempool wurde zusammen mit zwei Wissenschaftlern mit langjähriger Erfahrung mit empirischer Sozialforschung und insbesondere Befragungsstudien in einem gemeinsamen Workshop am 23. August 2017 diskutiert. 7Die dort gemachten Anmerkungen zum besprochenen Itempool wurden aufgegriffen und der Itempool wurde erneut überarbeitet. Folgende Aspekte und Anmerkungen waren die Grundlage der Überarbeitung:Der so entstandene Itempool wurde zusammen mit zwei Wissenschaftlern mit langjähriger Erfahrung mit empirischer Sozialforschung und insbesondere Befragungsstudien in einem gemeinsamen Workshop am 23. August 2017 diskutiert. 7Die dort gemachten Anmerkungen zum besprochenen Itempool wurden aufgegriffen und der Itempool wurde erneut überarbeitet. Folgende Aspekte und Anmerkungen waren die Grundlage der Überarbeitung:</p>
        <p>• Formulierungen wurden aus der Perspektive eines normalen Nutzers auf Verständlichkeit geprüft und ggf. entsprechend vereinfacht. • Es wurde diskutiert, inwieweit jedes einer Dimension zugewiesene Item als repräsentativ für die Dimension gewertet werden könnte. • Items, deren Formulierung einander zu sehr ähnelten, wurden gestrichen.• Formulierungen wurden aus der Perspektive eines normalen Nutzers auf Verständlichkeit geprüft und ggf. entsprechend vereinfacht. • Es wurde diskutiert, inwieweit jedes einer Dimension zugewiesene Item als repräsentativ für die Dimension gewertet werden könnte. • Items, deren Formulierung einander zu sehr ähnelten, wurden gestrichen.</p>
        <p>Im Anschluss an diese Überarbeitung der Frageformulierungen fanden sich 82 Frageitems im Itempool für die BDGS-Skala.Im Anschluss an diese Überarbeitung der Frageformulierungen fanden sich 82 Frageitems im Itempool für die BDGS-Skala.</p>
        <p>In einem weiteren Schritt wurden, wie in der Literatur vorgeschlagen, persönliche Interviews mit einfachen Nutzer*innen digitaler Medientechnik mit dem Ansatz des lauten Denkens durchgeführt, um die 82 Items auf Verständlichkeit zu prüfen und mögliche Probleme bei der Beantwortung der Items zu identifizieren (Prüfer &amp; Rexroth, 2000, 2005). Beim lauten Denken "werden Personen aufgefordert, ihre Gedanken laut auszusprechen, während sie sich einer Aufgabe oder Tätigkeit widmen" (Bilandzic, 2017, S. 406).In einem weiteren Schritt wurden, wie in der Literatur vorgeschlagen, persönliche Interviews mit einfachen Nutzer*innen digitaler Medientechnik mit dem Ansatz des lauten Denkens durchgeführt, um die 82 Items auf Verständlichkeit zu prüfen und mögliche Probleme bei der Beantwortung der Items zu identifizieren (Prüfer &amp; Rexroth, 2000, 2005). Beim lauten Denken "werden Personen aufgefordert, ihre Gedanken laut auszusprechen, während sie sich einer Aufgabe oder Tätigkeit widmen" (Bilandzic, 2017, S. 406).</p>
        <p>Insgesamt wurden im Zeitraum zwischen dem 30. August und dem 6. September 2017 sechs Interviews geführt. Bei der Rekrutierung der Gesprächsteilnehmer lag der Fokus insbesondere auf Internetnutzer*innen, die auf eine gewisse Online-Erfahrung zurückblicken konnten und ein Grundverständnis der Begriffe ‚Digitalisierung' und ‚digitale Daten' mitbrachten, da ihnen an dieser Stelle noch kein standardisierter Einleitungstext vorgelegt wurde. In Tabelle 2.B im Anhang im elektronischen Zusatzmaterial finden sich Informationen zu den persönlichen Angaben der Personen und der Interviewlänge. Insgesamt wurde in jedem Interview aus Zeitgründen lediglich ein Drittel der Items vorgelegt, so dass jeweils zwei Interviewte annähernd die gleichen Aussagen evaluiert haben.8 Zu diesem Zweck wurden die Items vor dem ersten Interview randomisiert, um zu gewährleisten, dass nicht nur Items aus einer bestimmten Dimension besprochen, sondern von allen Befragten möglichst viele Aussagen aus jeder der vorgeschlagenen Dimensionen eingeschätzt wurden.Insgesamt wurden im Zeitraum zwischen dem 30. August und dem 6. September 2017 sechs Interviews geführt. Bei der Rekrutierung der Gesprächsteilnehmer lag der Fokus insbesondere auf Internetnutzer*innen, die auf eine gewisse Online-Erfahrung zurückblicken konnten und ein Grundverständnis der Begriffe ‚Digitalisierung' und ‚digitale Daten' mitbrachten, da ihnen an dieser Stelle noch kein standardisierter Einleitungstext vorgelegt wurde. In Tabelle 2.B im Anhang im elektronischen Zusatzmaterial finden sich Informationen zu den persönlichen Angaben der Personen und der Interviewlänge. Insgesamt wurde in jedem Interview aus Zeitgründen lediglich ein Drittel der Items vorgelegt, so dass jeweils zwei Interviewte annähernd die gleichen Aussagen evaluiert haben.8 Zu diesem Zweck wurden die Items vor dem ersten Interview randomisiert, um zu gewährleisten, dass nicht nur Items aus einer bestimmten Dimension besprochen, sondern von allen Befragten möglichst viele Aussagen aus jeder der vorgeschlagenen Dimensionen eingeschätzt wurden.</p>
        <p>Die Gespräche wurden mit Hilfe eines Tonbandgeräts aufgezeichnet. Zudem wurden handschriftliche Notizen zu den jeweiligen Items gemacht, die die Anmerkungen der Interviewten dokumentierten. Darüber hinaus wurde langes Zögern bei der Beantwortung einzelner Items notiert, um festzuhalten, welche Items möglicherweise problematisch sein könnten. Die ursprünglich formulierten Items wurden auf Grundlage der Interviews überarbeitet und angepasst. Folgende Anmerkungen waren die Grundlage der Überarbeitung:Die Gespräche wurden mit Hilfe eines Tonbandgeräts aufgezeichnet. Zudem wurden handschriftliche Notizen zu den jeweiligen Items gemacht, die die Anmerkungen der Interviewten dokumentierten. Darüber hinaus wurde langes Zögern bei der Beantwortung einzelner Items notiert, um festzuhalten, welche Items möglicherweise problematisch sein könnten. Die ursprünglich formulierten Items wurden auf Grundlage der Interviews überarbeitet und angepasst. Folgende Anmerkungen waren die Grundlage der Überarbeitung:</p>
        <p>• Missverständliche Items wurden verständlicher formuliert.• Missverständliche Items wurden verständlicher formuliert.</p>
        <p>• Items, deren Formulierung als identisch wahrgenommen wurde, wurden gestrichen oder angepasst.• Items, deren Formulierung als identisch wahrgenommen wurde, wurden gestrichen oder angepasst.</p>
        <p>Insgesamt ergab sich mit Blick auf die vorgelegten Itemlisten, dass die Items insgesamt als verständlich und erfolgreich zu beantworten wahrgenommen wurden. Es zeigten sich bei den verwendeten Ausdrücken keinerlei Schwierigkeiten für die Beantwortung, so dass nach Streichung als identisch wahrgenommener Items 69 Frageitems vorlagen. Auch eine Verortung auf der geplanten 7-Punkt-Likert-Skala konnte von allen Interviewten für die Items vorgenommen werden.Insgesamt ergab sich mit Blick auf die vorgelegten Itemlisten, dass die Items insgesamt als verständlich und erfolgreich zu beantworten wahrgenommen wurden. Es zeigten sich bei den verwendeten Ausdrücken keinerlei Schwierigkeiten für die Beantwortung, so dass nach Streichung als identisch wahrgenommener Items 69 Frageitems vorlagen. Auch eine Verortung auf der geplanten 7-Punkt-Likert-Skala konnte von allen Interviewten für die Items vorgenommen werden.</p>
        <p>AlleAlle</p>
        <p>Im Folgenden wird die Durchführung der Online-Befragungen der ersten Studie zur Skalenkonstruktion dokumentiert. In diesem Rahmen wurden drei Erhebungen durchgeführt, die nachfolgend als Erhebung 1.1, 1.2 und 1.3 bezeichnet werden. Die erste Erhebung 1.1 diente der Identifikation geeigneter Frageitems und der Prüfung der zugrunde liegenden Modellstruktur, die Erhebungen 1.2. und 1.3 der Validierung der in Erhebung 1.1 ermittelten Modellstruktur. Dabei wird zunächst am Beispiel der Erhebung 1.1 detailliert auf den Aufbau und den empirischen Einsatz der Skala in der Befragung eingegangen. Zudem werden einmal ganz allgemein die Auswertungsschritte der Datenanalyse mittels Strukturgleichungsmodellierung nachvollziehbar begründet und dargelegt.Im Folgenden wird die Durchführung der Online-Befragungen der ersten Studie zur Skalenkonstruktion dokumentiert. In diesem Rahmen wurden drei Erhebungen durchgeführt, die nachfolgend als Erhebung 1.1, 1.2 und 1.3 bezeichnet werden. Die erste Erhebung 1.1 diente der Identifikation geeigneter Frageitems und der Prüfung der zugrunde liegenden Modellstruktur, die Erhebungen 1.2. und 1.3 der Validierung der in Erhebung 1.1 ermittelten Modellstruktur. Dabei wird zunächst am Beispiel der Erhebung 1.1 detailliert auf den Aufbau und den empirischen Einsatz der Skala in der Befragung eingegangen. Zudem werden einmal ganz allgemein die Auswertungsschritte der Datenanalyse mittels Strukturgleichungsmodellierung nachvollziehbar begründet und dargelegt.</p>
        <p>Ziel dieser Erhebung war die Identifikation geeigneter Frageitems und eine erste Prüfung der konzeptuellen Modellstruktur. Nachdem die entwickelten Items die Experten-und Nutzerinterviews durchlaufen hatten und der Fragepool angepasst und überarbeitet wurde, wurden die Items mit Hilfe der Fragebogensoftware SoSci Survey 1 für die Erhebung 1.1 in einen Online-Fragebogen überführt.Ziel dieser Erhebung war die Identifikation geeigneter Frageitems und eine erste Prüfung der konzeptuellen Modellstruktur. Nachdem die entwickelten Items die Experten-und Nutzerinterviews durchlaufen hatten und der Fragepool angepasst und überarbeitet wurde, wurden die Items mit Hilfe der Fragebogensoftware SoSci Survey 1 für die Erhebung 1.1 in einen Online-Fragebogen überführt.</p>
        <p>Um sogenannte Durchklicker zu identifizieren, deren Antwortverhalten sich auf fast immer die gleiche Antwort auf alle Frageitems auszeichnet, wurden die Antworthäufigkeiten über alle 93 Items der Skala zur Wahrnehmung digitaler Daten ausgezählt. Da es hier jedoch keine allgemeingültigen Daumenregeln zur Identifizierung gibt, wurde recht liberal festgelegt, dass nicht mehr als 90 % der Antworten auf den gleichen Skalenpunkt entfallen durften, was ab 83 von 93 möglichen Antworten der Fall war. Immerhin ist es möglich, dass bestimmte Befragte eine Tendenz zur Mitte hatten und durchweg "Teils/teils" angaben oder gar keine Antwort geben konnten und "Kann ich nicht beantworten" ankreuzten. Daher wurden lediglich Befragte ausgeschlossen, die 83 oder mehr gleiche Antworten gaben, was auf 36 Befragte, also eine ‚Click-Through-Rate' von 11,8 % des Samples zutraf.Um sogenannte Durchklicker zu identifizieren, deren Antwortverhalten sich auf fast immer die gleiche Antwort auf alle Frageitems auszeichnet, wurden die Antworthäufigkeiten über alle 93 Items der Skala zur Wahrnehmung digitaler Daten ausgezählt. Da es hier jedoch keine allgemeingültigen Daumenregeln zur Identifizierung gibt, wurde recht liberal festgelegt, dass nicht mehr als 90 % der Antworten auf den gleichen Skalenpunkt entfallen durften, was ab 83 von 93 möglichen Antworten der Fall war. Immerhin ist es möglich, dass bestimmte Befragte eine Tendenz zur Mitte hatten und durchweg "Teils/teils" angaben oder gar keine Antwort geben konnten und "Kann ich nicht beantworten" ankreuzten. Daher wurden lediglich Befragte ausgeschlossen, die 83 oder mehr gleiche Antworten gaben, was auf 36 Befragte, also eine ‚Click-Through-Rate' von 11,8 % des Samples zutraf.</p>
        <p>Da es Befragte gab, die zu beiden Gruppen gehörten, wurden 51 Personen aus dem Auswertungsdatensatz ausgeschlossen, so dass von 306 vollständig ausgefüllten Fragebögen noch 255 Fragebögen in die Auswertung eingingen.Da es Befragte gab, die zu beiden Gruppen gehörten, wurden 51 Personen aus dem Auswertungsdatensatz ausgeschlossen, so dass von 306 vollständig ausgefüllten Fragebögen noch 255 Fragebögen in die Auswertung eingingen.</p>
        <p>Der Tabelle 9.1 kann nicht nur die demografische Zusammensetzung des finalen Samples entnommen werden, sondern sie enthält auch die demografische Zusammensetzung der ausgeschlossenen Fälle.Der Tabelle 9.1 kann nicht nur die demografische Zusammensetzung des finalen Samples entnommen werden, sondern sie enthält auch die demografische Zusammensetzung der ausgeschlossenen Fälle.</p>
        <p>Im folgenden Abschnitt wird die Datenanalyse ausführlich erörtert, wobei zunächst allgemein auf das Vorgehen bei der konfirmatorischen Faktorenanalyse (‚Confirmatory Factor Analysis' -kurz: CFA) durch Strukturgleichungsmodellierung eingegangen wird -ein Datenanalyseverfahren, das in allen nachfolgenden Erhebungen angewandt wurde und daher an dieser Stelle grundlegend begründet und erörtert werden soll. Da die Items der einzelnen Dimensionen auf Grundlage der konzeptuellen Modellierung des ersten Teils der Arbeit zum BDGS gezielt als manifeste Indikatoren eines zugehörigen latenten Faktors formuliert waren und in ihrem Verhältnis zueinander ausgewogen erstellt wurden, gebot es sich, die vermutete Modellstruktur direkt durch eine konfirmatorische Faktorenanalyse zu prüfen (Bandalos, 2017). Es wurde mithin darauf verzichtet, eine Strukturprüfung ohne vorherige Annahmen durchzuführen wie etwa im Rahmen der explorativen Faktorenanalyse. Die Auswertung der ersten Erhebung zielte darauf ab, die Items zu identifizieren, die geeignete reflektive Indikatoren sind, die zuvor beschriebenen einzelnen Dimensionen abzubilden und zu erheben. In den nachfolgenden Erhebungen wurden diese Indikatoren dann wiederholt erhoben und die Modellstruktur wurde erneut mittels CFA geprüft. Das datenanalytische Vorgehen unterscheidet sich daher zwischen den Erhebungen kaum: Die Auswertungslogik und die verwendeten Kennwerte bleiben konstant, lediglich in der ersten Erhebung wurde aufgrund der ersten Identifikation geeigneter Indikatoren eine ausführliche Modellrespezifikation vorgenommen.Im folgenden Abschnitt wird die Datenanalyse ausführlich erörtert, wobei zunächst allgemein auf das Vorgehen bei der konfirmatorischen Faktorenanalyse (‚Confirmatory Factor Analysis' -kurz: CFA) durch Strukturgleichungsmodellierung eingegangen wird -ein Datenanalyseverfahren, das in allen nachfolgenden Erhebungen angewandt wurde und daher an dieser Stelle grundlegend begründet und erörtert werden soll. Da die Items der einzelnen Dimensionen auf Grundlage der konzeptuellen Modellierung des ersten Teils der Arbeit zum BDGS gezielt als manifeste Indikatoren eines zugehörigen latenten Faktors formuliert waren und in ihrem Verhältnis zueinander ausgewogen erstellt wurden, gebot es sich, die vermutete Modellstruktur direkt durch eine konfirmatorische Faktorenanalyse zu prüfen (Bandalos, 2017). Es wurde mithin darauf verzichtet, eine Strukturprüfung ohne vorherige Annahmen durchzuführen wie etwa im Rahmen der explorativen Faktorenanalyse. Die Auswertung der ersten Erhebung zielte darauf ab, die Items zu identifizieren, die geeignete reflektive Indikatoren sind, die zuvor beschriebenen einzelnen Dimensionen abzubilden und zu erheben. In den nachfolgenden Erhebungen wurden diese Indikatoren dann wiederholt erhoben und die Modellstruktur wurde erneut mittels CFA geprüft. Das datenanalytische Vorgehen unterscheidet sich daher zwischen den Erhebungen kaum: Die Auswertungslogik und die verwendeten Kennwerte bleiben konstant, lediglich in der ersten Erhebung wurde aufgrund der ersten Identifikation geeigneter Indikatoren eine ausführliche Modellrespezifikation vorgenommen.</p>
        <p>Für die Datenauswertung der Messmodelle in den insgesamt sieben Erhebungen wurden konfirmatorische Faktorenanalysen durchgeführt, um die jeweiligen reflektiven Messmodelle sowie die Zusammenhänge und die Dimensionalitätszugehörigkeit der beobachteten Messungen zu prüfen. Ziel der Datenanalyse mittels Strukturgleichungsmodellierung ist "die empirische Prüfung der durch das Strukturmodell abgebildeten theoretisch vermuteten Zusammenhänge" (Weiber &amp; Mühlhaus, 2014, S. 126). Grundannahme der CFA ist, dass das modellierte latente Konstrukt -im vorliegenden Fall somit die jeweilige interessierende Dimension -als exogene Variable einen Einfluss auf die Beantwortung der Fragebogenitems hat, die als Indikatoren für die Dimension herangezogen werden und im jeweiligen Modell als manifeste (d. h. tatsächliche Beobachtungen) endogene Variablen aufgenommen werden. Alle nachfolgenden Auswertungen zur Prüfung wurden mit den Datenanalyseprogrammen 
            <rs type="software">SPSS</rs>
            <rs type="version">23</rs> vorbereitet und mit 
            <rs type="software">AMOS</rs>
            <rs type="version">23</rs> (Analysis of 
            <rs type="software">Moment Structures</rs>) durchgeführt, das einem kovarianzanalytischen Ansatz folgt (Weiber &amp; Mühlhaus, 2014). Die Prüfung der Messinvarianz wurde aus Gründen der Praktikabilität in Teilen mit dem 
            <rs type="software">Datenanalyse-Programm R</rs> (
            <rs type="creator">R Core Team</rs>, 
            <rs type="version">2020</rs>) und dem Package lavaan durchgeführt (Rosseel, 2012). Für alle Analysen wurde die standardmäßig in 
            <rs type="software">AMOS</rs> voreingestellte Maximum-Likelihood-Methode zur Modellschätzung gewählt. 4 Da es jedoch zu fehlenden Daten kam und Modifikationsindizes zur Modellrespezifikation herangezogen werden sollten, die jedoch nur für vollständige Datensets bereitgestellt werden können, wurden Daten teilweise imputiert. Das Vorgehen bei der Modell-Schätzung unter Berücksichtigung der Datenimputation wird nachfolgend erläutert.
        </p>
        <p>Da es vorkam, dass Befragte nicht alle Items beantworteten oder die "weiß nicht"-Option wählten, kam es vor, dass nicht für jeden Fall im Datensatz für alle 93 abgefragten Items Daten vorlagen. Für die Identifikation der auszuwählenden Items sollte jedoch auf die Modifikationsindizes des Programms AMOS zurückgegriffen werden, um Items bzw. deren Fehlervarianzen zu identifizieren, die miteinander oder den latenten Faktoren kovariierten, obwohl das die theoretischen Überlegungen und folglich auch das Messmodell nicht vorsehen. Da AMOS Modifikationsindizes nur ausgeben kann, wenn vollständige Daten vorliegen und die Schätzung nach der Maximum-Likelihood-Methode durchgeführt wird, wurden für die Datenauswertung die fehlenden Daten im Datensatz der Erhebung 1.1 mittels der AMOS-Funktion Regression Imputation imputiert. Bei der Imputation ist davon auszugehen, dass die fehlenden Daten "missing at random" (Kline, 2011, S. 55 f.) sind, also fehlende Angaben nicht systematisch zustande kommen. Insbesondere für die "weiß nicht"-Antworten kann bei fehlenden Werten nicht davon ausgegangen werden, dass diese "missing completely at random" sind -eine Annahme, die laut Kline (2011, S. 56) bei realen Datensätzen jedoch kaum gegeben sein dürfte und nur schwer zu prüfen ist. Für die Antworten, die bewusst keine Angabe auf der 7-Punkt-Likert-Skala enthalten, kann diese Annahme des zufälligen Fehlens daher nicht gemacht werden. Sie wird für die Imputation jedoch angenommen, um die Modellprüfung mit einem ausreichend 4 Es wird mithin von einer Normalverteilung der erhobenen Indikatoren ausgegangen. Diese Annahme wird nach visueller Inspektion der Verteilungen der Variablen beibehalten, auch wenn ein Kolmogorov-Smirnov-Test auf Normalverteilung der Fallzahlen zu einem gegenteiligen Ergebnis kommt. Für eine Übersicht über alternative Modell-Schätzverfahren bei der groben Verletzung dieser Annahme siehe die Übersicht von Bandalos (2017, S. 368 ff.).Da es vorkam, dass Befragte nicht alle Items beantworteten oder die "weiß nicht"-Option wählten, kam es vor, dass nicht für jeden Fall im Datensatz für alle 93 abgefragten Items Daten vorlagen. Für die Identifikation der auszuwählenden Items sollte jedoch auf die Modifikationsindizes des Programms AMOS zurückgegriffen werden, um Items bzw. deren Fehlervarianzen zu identifizieren, die miteinander oder den latenten Faktoren kovariierten, obwohl das die theoretischen Überlegungen und folglich auch das Messmodell nicht vorsehen. Da AMOS Modifikationsindizes nur ausgeben kann, wenn vollständige Daten vorliegen und die Schätzung nach der Maximum-Likelihood-Methode durchgeführt wird, wurden für die Datenauswertung die fehlenden Daten im Datensatz der Erhebung 1.1 mittels der AMOS-Funktion Regression Imputation imputiert. Bei der Imputation ist davon auszugehen, dass die fehlenden Daten "missing at random" (Kline, 2011, S. 55 f.) sind, also fehlende Angaben nicht systematisch zustande kommen. Insbesondere für die "weiß nicht"-Antworten kann bei fehlenden Werten nicht davon ausgegangen werden, dass diese "missing completely at random" sind -eine Annahme, die laut Kline (2011, S. 56) bei realen Datensätzen jedoch kaum gegeben sein dürfte und nur schwer zu prüfen ist. Für die Antworten, die bewusst keine Angabe auf der 7-Punkt-Likert-Skala enthalten, kann diese Annahme des zufälligen Fehlens daher nicht gemacht werden. Sie wird für die Imputation jedoch angenommen, um die Modellprüfung mit einem ausreichend 4 Es wird mithin von einer Normalverteilung der erhobenen Indikatoren ausgegangen. Diese Annahme wird nach visueller Inspektion der Verteilungen der Variablen beibehalten, auch wenn ein Kolmogorov-Smirnov-Test auf Normalverteilung der Fallzahlen zu einem gegenteiligen Ergebnis kommt. Für eine Übersicht über alternative Modell-Schätzverfahren bei der groben Verletzung dieser Annahme siehe die Übersicht von Bandalos (2017, S. 368 ff.).</p>
        <p>großen Datensatz zu ermöglichen. Insgesamt lagen von 199 Befragten vollständige Datensätze vor. Im Schnitt fehlten pro Item rund 3,5 % der Werte, die mittels der Regressionsimputation imputiert werden mussten. Lediglich bei zwei Variablen 5 wurden 18 "weiß nicht"-Antworten gezählt, so dass im Maximalfall knapp 7 % der Angaben für ein Item fehlten.großen Datensatz zu ermöglichen. Insgesamt lagen von 199 Befragten vollständige Datensätze vor. Im Schnitt fehlten pro Item rund 3,5 % der Werte, die mittels der Regressionsimputation imputiert werden mussten. Lediglich bei zwei Variablen 5 wurden 18 "weiß nicht"-Antworten gezählt, so dass im Maximalfall knapp 7 % der Angaben für ein Item fehlten.</p>
        <p>Das finale Modell wurde aufgrund der Imputation der Daten daher auch noch einmal mittels der Full-Information-Maximum-Likelihood-Methode (FIML) berechnet (siehe Abschnitt 9.1.6), um sich gegen etwaige Probleme abzusichern, die durch die Imputation entstanden sein könnten (Kline, 2011). Die erste Spezifikation sowie die Respezifikationsschritte wurden auf Grundlage des durch Imputation neu entstandenen Datensatzes durchgeführt. Um geeignete Fragebogenitems zu identifizieren und ungeeignete Items auszuschließen, wurden drei unterschiedliche Strategien angewendet, die nachfolgend allgemein beschrieben werden. Dabei werden im Laufe der jeweiligen Respezifikationsschritte unzählige kleine und größere Entscheidungen getroffen, die hier im Rahmen der Verschriftlichung des Vorgehens nicht alle bis ins Detail gelistet und nachvollzogen werden können. Es ist bei der Modellspezifizierung abzuwägen zwischen größtmöglicher Transparenz und Sparsamkeit in der Dokumentation. Anhand des zur Verfügung gestellten Datensatzes und der berichteten Modelle können jedoch jederzeit alternative oder (fast-)äquivalente Modelle geprüft werden ((Near-)Equivalent-Models, Kline, 2011).Das finale Modell wurde aufgrund der Imputation der Daten daher auch noch einmal mittels der Full-Information-Maximum-Likelihood-Methode (FIML) berechnet (siehe Abschnitt 9.1.6), um sich gegen etwaige Probleme abzusichern, die durch die Imputation entstanden sein könnten (Kline, 2011). Die erste Spezifikation sowie die Respezifikationsschritte wurden auf Grundlage des durch Imputation neu entstandenen Datensatzes durchgeführt. Um geeignete Fragebogenitems zu identifizieren und ungeeignete Items auszuschließen, wurden drei unterschiedliche Strategien angewendet, die nachfolgend allgemein beschrieben werden. Dabei werden im Laufe der jeweiligen Respezifikationsschritte unzählige kleine und größere Entscheidungen getroffen, die hier im Rahmen der Verschriftlichung des Vorgehens nicht alle bis ins Detail gelistet und nachvollzogen werden können. Es ist bei der Modellspezifizierung abzuwägen zwischen größtmöglicher Transparenz und Sparsamkeit in der Dokumentation. Anhand des zur Verfügung gestellten Datensatzes und der berichteten Modelle können jedoch jederzeit alternative oder (fast-)äquivalente Modelle geprüft werden ((Near-)Equivalent-Models, Kline, 2011).</p>
        <p>Zunächst wurden Items ausgeschlossen, die nur einen geringen Erklärungsbeitrag zum jeweiligen latenten Konstrukt lieferten. Dies war der Fall, wenn die standardisierten Faktorladungen der gemessenen Variable unter einem Wert von .70 lagen, da hier weniger als die Hälfte der Varianz einer Variable durch das zugrunde liegende Konstrukt erklärt werden kann. Werte &gt; .70 der standardisierten Faktorladungen hingegen indizieren Konvergenzvalidität der manifesten Indikatoren eines latenten Konstrukts (Kline, 2011).Zunächst wurden Items ausgeschlossen, die nur einen geringen Erklärungsbeitrag zum jeweiligen latenten Konstrukt lieferten. Dies war der Fall, wenn die standardisierten Faktorladungen der gemessenen Variable unter einem Wert von .70 lagen, da hier weniger als die Hälfte der Varianz einer Variable durch das zugrunde liegende Konstrukt erklärt werden kann. Werte &gt; .70 der standardisierten Faktorladungen hingegen indizieren Konvergenzvalidität der manifesten Indikatoren eines latenten Konstrukts (Kline, 2011).</p>
        <p>Weiterhin wurden mittels der Modifikationsindizes Items identifiziert, deren Fehlervarianzen miteinander kovariierten (Weiber &amp; Mühlhaus, 2014). Das bedeutet konkret, dass diese Items noch durch eine andere zusätzliche latente Variable, die nicht im Modell abgebildet war, beeinflusst wurden, die deren gemeinsam geteilte Varianz zusätzlich zum zufälligen Messfehler erklären kann. Ist dieser Pfad nicht vorhanden, also nicht im Modell abgebildet7 und somit nicht freigegeben, ist die Annahme, dass in vorliegendem Fall keine Beziehung zwischen den Fehlervarianzen besteht, weil sich gemeinsame Varianz nur über den modellierten latenten Faktor erklären sollte. Hierauf stellen nun die berechneten Modifikationsindizes ab: "(…) A modification index estimates the amount by which the overall model chi-square statistic, X 2 M , would decrease if a particular fixed-to-zero parameter were freely estimated" (Kline, 2011, S. 217). Die Modifikationsindizes schlagen dann vor, diesen nicht vorhandenen Pfad in das Modell einzufügen; die Fehlerterme können frei variieren. Je größer der Modifikationsindex, desto größer die Verringerung des Chi-Quadrat-Wertes und folglich auch die Stärke des geschätzten Zusammenhangs. Dabei ist zu berücksichtigen, dass dieser Weg der Respezifikation rein empirisch begründet wird und laut Kline (2011) anfällig für statistische Fehlentscheidungen, genauer den Alpha-und Beta-Fehler, ist. Es wird daher nicht empfohlen, die Fehlerterme eines Messmodells miteinander kovariieren zulassen. Dies ist auch messtheoretisch nicht gerechtfertigt, da mit Blick auf die Konzeption des Messmodells von der Uni-Dimensionalität der Indikatoren ausgegangen wird (Hermida, 2015).Weiterhin wurden mittels der Modifikationsindizes Items identifiziert, deren Fehlervarianzen miteinander kovariierten (Weiber &amp; Mühlhaus, 2014). Das bedeutet konkret, dass diese Items noch durch eine andere zusätzliche latente Variable, die nicht im Modell abgebildet war, beeinflusst wurden, die deren gemeinsam geteilte Varianz zusätzlich zum zufälligen Messfehler erklären kann. Ist dieser Pfad nicht vorhanden, also nicht im Modell abgebildet7 und somit nicht freigegeben, ist die Annahme, dass in vorliegendem Fall keine Beziehung zwischen den Fehlervarianzen besteht, weil sich gemeinsame Varianz nur über den modellierten latenten Faktor erklären sollte. Hierauf stellen nun die berechneten Modifikationsindizes ab: "(…) A modification index estimates the amount by which the overall model chi-square statistic, X 2 M , would decrease if a particular fixed-to-zero parameter were freely estimated" (Kline, 2011, S. 217). Die Modifikationsindizes schlagen dann vor, diesen nicht vorhandenen Pfad in das Modell einzufügen; die Fehlerterme können frei variieren. Je größer der Modifikationsindex, desto größer die Verringerung des Chi-Quadrat-Wertes und folglich auch die Stärke des geschätzten Zusammenhangs. Dabei ist zu berücksichtigen, dass dieser Weg der Respezifikation rein empirisch begründet wird und laut Kline (2011) anfällig für statistische Fehlentscheidungen, genauer den Alpha-und Beta-Fehler, ist. Es wird daher nicht empfohlen, die Fehlerterme eines Messmodells miteinander kovariieren zulassen. Dies ist auch messtheoretisch nicht gerechtfertigt, da mit Blick auf die Konzeption des Messmodells von der Uni-Dimensionalität der Indikatoren ausgegangen wird (Hermida, 2015).</p>
        <p>Um den Einfluss dieser zusätzlichen, jedoch unberücksichtigten und nicht zu identifizierenden latenten Variable(n) auszuschließen, wurden die entsprechenden Items aus dem Modell entfernt. Dass bedeutet nicht, dass sie keinen Erklärungsbeitrag für die jeweils abgebildete Dimension lieferten, sondern, dass es vermutlich noch einen anderen nicht zu identifizierenden Einfluss gab, der die Beantwortung durch die Befragten beeinflusste. Nun kann zum einen davon ausgegangen werden, dass möglicherweise ein nicht beabsichtigtes Konstrukt einen Einfluss auf die Beantwortung der in Frage kommenden Variablen hat, die miteinander über das eigentlich zu messende Konstrukt hinaus kovariieren. Es lässt sich nur vermuten, welche zusätzlichen Einflüsse es auf das Antwortverhalten gab. Allerdings kann aufgrund der auffallend häufig vorkommenden unerklärten gemeinsamen Varianz zweier sich in ihrer Formulierung ähnelnden Variablen, die noch nicht durch das gemeinsame latente Konstrukt erklärt wird, zumindest auch davon ausgegangen werden, dass die gewählten Ausdrücke bei der Frageformulierung einen Einfluss haben.Um den Einfluss dieser zusätzlichen, jedoch unberücksichtigten und nicht zu identifizierenden latenten Variable(n) auszuschließen, wurden die entsprechenden Items aus dem Modell entfernt. Dass bedeutet nicht, dass sie keinen Erklärungsbeitrag für die jeweils abgebildete Dimension lieferten, sondern, dass es vermutlich noch einen anderen nicht zu identifizierenden Einfluss gab, der die Beantwortung durch die Befragten beeinflusste. Nun kann zum einen davon ausgegangen werden, dass möglicherweise ein nicht beabsichtigtes Konstrukt einen Einfluss auf die Beantwortung der in Frage kommenden Variablen hat, die miteinander über das eigentlich zu messende Konstrukt hinaus kovariieren. Es lässt sich nur vermuten, welche zusätzlichen Einflüsse es auf das Antwortverhalten gab. Allerdings kann aufgrund der auffallend häufig vorkommenden unerklärten gemeinsamen Varianz zweier sich in ihrer Formulierung ähnelnden Variablen, die noch nicht durch das gemeinsame latente Konstrukt erklärt wird, zumindest auch davon ausgegangen werden, dass die gewählten Ausdrücke bei der Frageformulierung einen Einfluss haben.</p>
        <p>Das Phänomen dieser begrifflichen Ähnlichkeit soll hier anhand dreier Items der Dimension Volume verdeutlicht werden:Das Phänomen dieser begrifflichen Ähnlichkeit soll hier anhand dreier Items der Dimension Volume verdeutlicht werden:</p>
        <p>• Es ist gut, dass immer mehr digitale Daten ausgewertet werden.• Es ist gut, dass immer mehr digitale Daten ausgewertet werden.</p>
        <p>• Es ist gut, so viele digitale Daten wie möglich auszuwerten.• Es ist gut, so viele digitale Daten wie möglich auszuwerten.</p>
        <p>• Es ist erstrebenswert, so viele digitale Daten wie möglich auszuwerten.• Es ist erstrebenswert, so viele digitale Daten wie möglich auszuwerten.</p>
        <p>Diese drei Items sind Indikatoren einer Dimension. Wenn nun Befragte den Items 2 und 3 auf der 7er-Likert-Skala mit "stimme voll und ganz zu" den Wert 7 zuwiesen, Item 1 jedoch nur "stimme größtenteils zu" und somit den Wert 6, ist das für sich genommen unproblematisch. Wenn allerdings über alle Befragten hinweg solch ein Muster auftritt und begriffliche Ähnlichkeit in der Formulierung dazu führt, dass zwei Items nicht nur wegen der gemeinsamen Zugehörigkeit zu einem gleichen Konstrukt, sondern auch aus speziell diesem Grund ähnlich beantwortet werden, kann dies zu einem systematischen Messfehler führen, der im Modell eben nicht berücksichtigt wird. In diesem Fall kann eines der beiden Items eliminiert werden, unter der Voraussetzung, dass die Faktorladung des beibehaltenen Items gleich oder höher ausfällt, aber mind. größer als .70 ist.Diese drei Items sind Indikatoren einer Dimension. Wenn nun Befragte den Items 2 und 3 auf der 7er-Likert-Skala mit "stimme voll und ganz zu" den Wert 7 zuwiesen, Item 1 jedoch nur "stimme größtenteils zu" und somit den Wert 6, ist das für sich genommen unproblematisch. Wenn allerdings über alle Befragten hinweg solch ein Muster auftritt und begriffliche Ähnlichkeit in der Formulierung dazu führt, dass zwei Items nicht nur wegen der gemeinsamen Zugehörigkeit zu einem gleichen Konstrukt, sondern auch aus speziell diesem Grund ähnlich beantwortet werden, kann dies zu einem systematischen Messfehler führen, der im Modell eben nicht berücksichtigt wird. In diesem Fall kann eines der beiden Items eliminiert werden, unter der Voraussetzung, dass die Faktorladung des beibehaltenen Items gleich oder höher ausfällt, aber mind. größer als .70 ist.</p>
        <p>Es wurde beim Ausschluss nach Modifikationsindizes darauf geachtet, zuerst Items zu eliminieren, für die mehrere (hohe) Modifikationsindizes vorlagen und deren addierte Werte größer waren als für andere Items (Kline, 2011). So wurden zunächst Items eliminiert, die auf mehrere latente Konstrukte luden und deren Fehlerterme mit denen anderer Variablen kovariierten.Es wurde beim Ausschluss nach Modifikationsindizes darauf geachtet, zuerst Items zu eliminieren, für die mehrere (hohe) Modifikationsindizes vorlagen und deren addierte Werte größer waren als für andere Items (Kline, 2011). So wurden zunächst Items eliminiert, die auf mehrere latente Konstrukte luden und deren Fehlerterme mit denen anderer Variablen kovariierten.</p>
        <p>Bei der Respezifikation der Messmodelle wurde zudem auch auf die jeweiligen Formulierungen der Items einer (Sub-)Dimension geachtet, um eine Vergleichbarkeit der Dimensionen und ihrer Items auch im Hinblick auf den Wortlaut der Fragebogenitems zu gewährleisten. Als Beispiel diente hier die Unterscheidung des Umgangs mit digitalen Daten in Erzeugung, Speicherung und Auswertung der Daten.Bei der Respezifikation der Messmodelle wurde zudem auch auf die jeweiligen Formulierungen der Items einer (Sub-)Dimension geachtet, um eine Vergleichbarkeit der Dimensionen und ihrer Items auch im Hinblick auf den Wortlaut der Fragebogenitems zu gewährleisten. Als Beispiel diente hier die Unterscheidung des Umgangs mit digitalen Daten in Erzeugung, Speicherung und Auswertung der Daten.</p>
        <p>Es wurde eingangs vermutet, dass durchaus zwischen diesen Handlungen unterschieden werden kann und auch die Befragten hier Unterschiede machen könnten. Wenn sich allerdings zeigen würde, dass Befragte (in einer oder mehreren der Dimensionen) keinen Unterschied sähen, sobald beide Formulierungen vorhanden sind, dann wäre es nach Ansicht des Autors dennoch sinnvoll, eine der gewählten Formulierungsweisen für die finale Zusammensetzung der Skalenitems beizubehalten. Das bedeutet, entweder nur von Erzeugung oder Speicherung zu sprechen, selbst wenn sich zeigen sollte, dass die Befragten bei der Beantwortung der Items der ersten Erhebung keinen Unterschied machen sollten, um zu vermeiden, dass es in der weiteren Verwendung der Skalenitems in Folgestudien dann nicht doch zu einer möglichen Verwirrung bei manchen Befragten kommt. Diese könnten bspw. nun plötzlich doch vermuten, dass ein Unterschied gemeint sein könnte, wenn plötzlich für eine Dimension von Erzeugung und in der anderen von Speicherung gesprochen würde. Das heißt in der Konsequenz, dass auch Items aus dem Modell entfernt werden konnten, für die möglicherweise keine Anhaltspunkte vorlagen, die nach den beiden zuvor vorgestellten Ausschlusskriterien zu einem Ausschluss geführt hätten. Weitere Ausführungen hierzu finden sich nachfolgend in den Abschnitten zu den jeweiligen Dimensionen.Es wurde eingangs vermutet, dass durchaus zwischen diesen Handlungen unterschieden werden kann und auch die Befragten hier Unterschiede machen könnten. Wenn sich allerdings zeigen würde, dass Befragte (in einer oder mehreren der Dimensionen) keinen Unterschied sähen, sobald beide Formulierungen vorhanden sind, dann wäre es nach Ansicht des Autors dennoch sinnvoll, eine der gewählten Formulierungsweisen für die finale Zusammensetzung der Skalenitems beizubehalten. Das bedeutet, entweder nur von Erzeugung oder Speicherung zu sprechen, selbst wenn sich zeigen sollte, dass die Befragten bei der Beantwortung der Items der ersten Erhebung keinen Unterschied machen sollten, um zu vermeiden, dass es in der weiteren Verwendung der Skalenitems in Folgestudien dann nicht doch zu einer möglichen Verwirrung bei manchen Befragten kommt. Diese könnten bspw. nun plötzlich doch vermuten, dass ein Unterschied gemeint sein könnte, wenn plötzlich für eine Dimension von Erzeugung und in der anderen von Speicherung gesprochen würde. Das heißt in der Konsequenz, dass auch Items aus dem Modell entfernt werden konnten, für die möglicherweise keine Anhaltspunkte vorlagen, die nach den beiden zuvor vorgestellten Ausschlusskriterien zu einem Ausschluss geführt hätten. Weitere Ausführungen hierzu finden sich nachfolgend in den Abschnitten zu den jeweiligen Dimensionen.</p>
        <p>Zusammenfassend wurden für die Identifikation geeigneter Frageitems die drei zuvor beschriebenen Strategien angewendet: 1) die Betrachtung der standardisierten Faktorladungen, 2) die Verwendung der Modifikationsindizes und 3) die möglichst konstante Begriffsverwendung in der Itemformulierung.Zusammenfassend wurden für die Identifikation geeigneter Frageitems die drei zuvor beschriebenen Strategien angewendet: 1) die Betrachtung der standardisierten Faktorladungen, 2) die Verwendung der Modifikationsindizes und 3) die möglichst konstante Begriffsverwendung in der Itemformulierung.</p>
        <p>Die Evaluation der CFA-Modelle -notwendige Prüfschritte für die Beurteilung reflektiver Messmodelle Für die Beurteilung der reflektiven Messmodelle wird ein schrittweises Prüfverfahren angewendet. Zunächst wird die Reliabilität der Indikatoren der reflektiven Messmodelle geprüft und eine allgemeine Plausibilitätsprüfung der geschätzten Lösung vorgenommen, bevor die Anpassungsgüte der spezifizierten CFA-Modelle geprüft wird.Die Evaluation der CFA-Modelle -notwendige Prüfschritte für die Beurteilung reflektiver Messmodelle Für die Beurteilung der reflektiven Messmodelle wird ein schrittweises Prüfverfahren angewendet. Zunächst wird die Reliabilität der Indikatoren der reflektiven Messmodelle geprüft und eine allgemeine Plausibilitätsprüfung der geschätzten Lösung vorgenommen, bevor die Anpassungsgüte der spezifizierten CFA-Modelle geprüft wird.</p>
        <p>Die Reliabilität gibt Auskunft über die Zuverlässigkeit bzw. die Genauigkeit der Messung (Bandalos, 2017). Die Faktorladungen der reflektiven Indikatoren sollten daher &gt; .7 sein. Zudem wird für die jeweiligen Indikatoren einer Dimension die tau-äquivalente Reliabilität angegeben werden. Dieses Maß, dass auch unter dem Begriff des Cronbachschen α firmiert, findet in den Sozialwissenschaften weite Verbreitung, ist in der Vergangenheit jedoch zunehmend als ungenau in die Kritik geraten, da es kein geeignetes Maß für die Homogenität und die Eindimensionalität der Indikatoren ist (Cho, 2016;Schmitt, 1996). Es wird daher ebenfalls häufig empfohlen, die durchschnittlich extrahierte Varianz (DEV) zu berichten. "Diese gibt an, wie viel Prozent der Streuung des latenten Konstruktes über die Indikatoren durchschnittlich erklärt wird" (Weiber &amp; Mühlhaus, 2014, S. 151). Als Schwellenwert wird üblicherweise ein DEV-Wert von ≥ .5 angesehen, da durchschnittlich die Hälfte der Varianz auf den latenten Faktor des gemessenen Konstrukts zurückgeht (Fornell &amp; Larcker, 1981;Segars, 1997;Weiber &amp; Mühlhaus, 2014)Die Reliabilität gibt Auskunft über die Zuverlässigkeit bzw. die Genauigkeit der Messung (Bandalos, 2017). Die Faktorladungen der reflektiven Indikatoren sollten daher &gt; .7 sein. Zudem wird für die jeweiligen Indikatoren einer Dimension die tau-äquivalente Reliabilität angegeben werden. Dieses Maß, dass auch unter dem Begriff des Cronbachschen α firmiert, findet in den Sozialwissenschaften weite Verbreitung, ist in der Vergangenheit jedoch zunehmend als ungenau in die Kritik geraten, da es kein geeignetes Maß für die Homogenität und die Eindimensionalität der Indikatoren ist (Cho, 2016;Schmitt, 1996). Es wird daher ebenfalls häufig empfohlen, die durchschnittlich extrahierte Varianz (DEV) zu berichten. "Diese gibt an, wie viel Prozent der Streuung des latenten Konstruktes über die Indikatoren durchschnittlich erklärt wird" (Weiber &amp; Mühlhaus, 2014, S. 151). Als Schwellenwert wird üblicherweise ein DEV-Wert von ≥ .5 angesehen, da durchschnittlich die Hälfte der Varianz auf den latenten Faktor des gemessenen Konstrukts zurückgeht (Fornell &amp; Larcker, 1981;Segars, 1997;Weiber &amp; Mühlhaus, 2014)</p>
        <p>Die Plausibilitätsprüfung der geschätzten Lösung Alle berichteten Modelle wurden zudem zunächst auf Heywood Cases geprüft, d. h., es wurde eine Plausibilitätsprüfung durchgeführt. Heywood Cases liegen bei geschätzten Modellen vor, bei denen die Parametermatrizen nicht ‚positiv definit' sind, was sich an negativen Varianzen, Kommunalitäten &gt; 1 und Korrelationen &gt; 1 äußert (Kline, 2011;Weiber &amp; Mühlhaus, 2014). Solche Werte sind unplausibel, weshalb Modelle mit Heywood Cases abgelehnt werden müssen. Es gibt keine Möglichkeiten, Heywood Cases bei einem Datensatz zu heilen, außer den Datensatz zu verändern, bspw., indem man neue zusätzliche Fälle erhebt (West et al., 1995).Die Plausibilitätsprüfung der geschätzten Lösung Alle berichteten Modelle wurden zudem zunächst auf Heywood Cases geprüft, d. h., es wurde eine Plausibilitätsprüfung durchgeführt. Heywood Cases liegen bei geschätzten Modellen vor, bei denen die Parametermatrizen nicht ‚positiv definit' sind, was sich an negativen Varianzen, Kommunalitäten &gt; 1 und Korrelationen &gt; 1 äußert (Kline, 2011;Weiber &amp; Mühlhaus, 2014). Solche Werte sind unplausibel, weshalb Modelle mit Heywood Cases abgelehnt werden müssen. Es gibt keine Möglichkeiten, Heywood Cases bei einem Datensatz zu heilen, außer den Datensatz zu verändern, bspw., indem man neue zusätzliche Fälle erhebt (West et al., 1995).</p>
        <p>Um die Anpassungsgüte des spezifizierten Modells zu prüfen, gibt es eine Vielzahl von Kriterien sowie Kennwerten für die Evaluation des Kausalmodells, wobei Letztere auch als Fit-Maße bezeichnet werden. "Eine hohe Güte eines Kausalmodells (sog. Modell-Fit) ist allgemein dann gegeben, wenn die mit Hilfe der Parameterschätzer berechneten Varianzen und Kovarianzen möglichst gut mit den empirisch gewonnenen Varianzen und Kovarianzen übereinstimmen" (Weiber &amp; Mühlhaus, 2014, S. 203).Um die Anpassungsgüte des spezifizierten Modells zu prüfen, gibt es eine Vielzahl von Kriterien sowie Kennwerten für die Evaluation des Kausalmodells, wobei Letztere auch als Fit-Maße bezeichnet werden. "Eine hohe Güte eines Kausalmodells (sog. Modell-Fit) ist allgemein dann gegeben, wenn die mit Hilfe der Parameterschätzer berechneten Varianzen und Kovarianzen möglichst gut mit den empirisch gewonnenen Varianzen und Kovarianzen übereinstimmen" (Weiber &amp; Mühlhaus, 2014, S. 203).</p>
        <p>Das wichtigste Gütekriterium ist dabei der Chi-Quadrat-Test, dessen Bedeutung und Gültigkeit in der Literatur jedoch kontrovers diskutiert wird. Bspw. neigt der Test dazu, leicht auf die Stichprobengröße zu reagieren, was laut Kline (2011) bei Samplegrößen von 200 bis 300 Probanden noch unproblematisch ist, bei größeren Stichproben 9 aber leicht zu einer Ablehnung des Modells führen kann. Während etliche Autoren für eine strenge Beachtung des Chi-Quadrat-Tests argumentieren (Barrett, 2007;Kline, 2011), gibt es auch Quellen, die diese Strenge ablehnen (Bentler &amp; Bonett, 1980) oder zumindest im Gesamtkontext der Modellkonzeption betrachten möchten (Vandenberg, 2006). 10 Um auf die Strenge des Chi-Quadrat-Tests zu reagieren, hat sich zudem etabliert, bei der Evaluation eines Gesamtmodells zur Güteprüfung noch absolute und inkrementelle Fit-Maße heranzuziehen (Holbert &amp; Stephenson, 2002;Weiber &amp; Mühlhaus, 2014). Absolute Fit-Maße prüfen, ob das Modell konsistent mit den Daten ist, ohne ein Vergleichsmodell heranzuziehen. Inkrementelle Fit-Maße hingegen stellen auf einen Vergleich zwischen dem spezifizierten Modell (auch Default-Modell genannt) und einem unabhängigen Modell ab. Das Heranziehen 9 Hierzu zählen laut Kenny (2015) bereits Stichproben mit mehr als 400 Fällen. 10 Für eine weitere Übersicht über die Debatte sei an dieser Stelle auch auf das Sonderheft von Personality and Individual Differences (2007, 42(5)) verwiesen.Das wichtigste Gütekriterium ist dabei der Chi-Quadrat-Test, dessen Bedeutung und Gültigkeit in der Literatur jedoch kontrovers diskutiert wird. Bspw. neigt der Test dazu, leicht auf die Stichprobengröße zu reagieren, was laut Kline (2011) bei Samplegrößen von 200 bis 300 Probanden noch unproblematisch ist, bei größeren Stichproben 9 aber leicht zu einer Ablehnung des Modells führen kann. Während etliche Autoren für eine strenge Beachtung des Chi-Quadrat-Tests argumentieren (Barrett, 2007;Kline, 2011), gibt es auch Quellen, die diese Strenge ablehnen (Bentler &amp; Bonett, 1980) oder zumindest im Gesamtkontext der Modellkonzeption betrachten möchten (Vandenberg, 2006). 10 Um auf die Strenge des Chi-Quadrat-Tests zu reagieren, hat sich zudem etabliert, bei der Evaluation eines Gesamtmodells zur Güteprüfung noch absolute und inkrementelle Fit-Maße heranzuziehen (Holbert &amp; Stephenson, 2002;Weiber &amp; Mühlhaus, 2014). Absolute Fit-Maße prüfen, ob das Modell konsistent mit den Daten ist, ohne ein Vergleichsmodell heranzuziehen. Inkrementelle Fit-Maße hingegen stellen auf einen Vergleich zwischen dem spezifizierten Modell (auch Default-Modell genannt) und einem unabhängigen Modell ab. Das Heranziehen 9 Hierzu zählen laut Kenny (2015) bereits Stichproben mit mehr als 400 Fällen. 10 Für eine weitere Übersicht über die Debatte sei an dieser Stelle auch auf das Sonderheft von Personality and Individual Differences (2007, 42(5)) verwiesen.</p>
        <p>dieser Gütekriterien hat sich in den Sozialwissenschaften etabliert, selbst wenn es keine einheitlichen Standards gibt, welche Fit-Maße herangezogen und welche Cut-off-Kriterien angelegt werden sollten (Holbert &amp; Stephenson, 2002).dieser Gütekriterien hat sich in den Sozialwissenschaften etabliert, selbst wenn es keine einheitlichen Standards gibt, welche Fit-Maße herangezogen und welche Cut-off-Kriterien angelegt werden sollten (Holbert &amp; Stephenson, 2002).</p>
        <p>Letztendlich empfiehlt es sich a priori festzulegen, welche Evaluationskriterien herangezogen werden, um die Anpassungsgüte der geprüften Modelle zu beurteilen. In der vorliegenden Arbeit wird der Modellfit daher durch die Angaben der folgenden Kriterien und Werte geprüft: Für die Evaluation des Gesamtmodells werden der Chi-Quadrat-Test (X 2 ) und der ‚Root Mean Square Error of Approximation' (RMSEA) herangezogen. Während der ermittelte Chi-Quadrat-Test nicht-signifikant sein sollte, ist seine Anwendung voraussetzungsreich und unterliegt, wie zuvor diskutiert, diversen Limitationen (Kline, 2011;Weiber &amp; Mühlhaus, 2014). Mit Blick auf den RMSEA besagt eine geläufige Daumenregel, dass der jeweilige Test-Wert im Idealfall nicht größer als .05 sein sollte (Browne &amp; Cudeck, 1992), wobei zusätzlich das 90 %-Konfidenzintervall (Confidence Interval -CI) angegeben wird. Hier sollte die untere Grenze (LO90) nahe 0 liegen und die obere Grenze (HI90) nicht größer als .08 sein (Kenny, 2015).Letztendlich empfiehlt es sich a priori festzulegen, welche Evaluationskriterien herangezogen werden, um die Anpassungsgüte der geprüften Modelle zu beurteilen. In der vorliegenden Arbeit wird der Modellfit daher durch die Angaben der folgenden Kriterien und Werte geprüft: Für die Evaluation des Gesamtmodells werden der Chi-Quadrat-Test (X 2 ) und der ‚Root Mean Square Error of Approximation' (RMSEA) herangezogen. Während der ermittelte Chi-Quadrat-Test nicht-signifikant sein sollte, ist seine Anwendung voraussetzungsreich und unterliegt, wie zuvor diskutiert, diversen Limitationen (Kline, 2011;Weiber &amp; Mühlhaus, 2014). Mit Blick auf den RMSEA besagt eine geläufige Daumenregel, dass der jeweilige Test-Wert im Idealfall nicht größer als .05 sein sollte (Browne &amp; Cudeck, 1992), wobei zusätzlich das 90 %-Konfidenzintervall (Confidence Interval -CI) angegeben wird. Hier sollte die untere Grenze (LO90) nahe 0 liegen und die obere Grenze (HI90) nicht größer als .08 sein (Kenny, 2015).</p>
        <p>Zudem wird nachfolgend der Tucker-Lewis-Index (TLI) als inkrementelles Fit-Maß herangezogen. Der Nachteil des TLI ist, dass dieser nicht-normiert ist, also auch Werte &gt; 1 annehmen kann, wobei ein Wert &gt; 1 für gewöhnlich auf 1.00 abgerundet wird. Weiber und Mühlhaus (2014) geben als Schwellenwert für den TLI Werte von mind. .90 an, laut L. Hu und Bentler (1999) sollte der Wert mind. bei .95 oder besser liegen. Es wird zusätzlich zum TLI auch häufig noch der Wert des Comparative Fit Index (CFI) angegeben (L. Hu &amp; Bentler, 1999;Schreiber et al., 2006). Kenny (2015) rät hiervon jedoch mit folgender Begründung ab: "Because the TLI and CFI are highly correlated only one of the two should be reported. The CFI is reported more often than the TLI, but I think the CFI's penalty for complexity of just 1 is too low and so I prefer the TLI even though the CFI is reported much more frequently than the TLI" (Kenny, 2015, § 10). Nachfolgend werden daher für alle Modelle der Chi-Quadrat-Test, der RMSEA samt 90 %-Konfidenzintervall sowie der TLI angegeben. Die Werte werden durchgängig wie folgt berichtet, wobei kursiv gesetzte Wörter durch die entsprechenden Werte ersetzt werden: (X 2 (df -Freiheitsgrade) = Chi-Quadrat-Wert, p &lt; Signifikanzwert; RMSEA = RMSEA-Wert [90 %-Konfidenzintervall: LO90-Wert, HI90-Wert]; TLI = TLI-Wert). Bei den Messmodellen der unidimensionalen Faktoren werden zudem noch das Cronbachsche α und die durchschnittlich extrahierte Varianz (DEV) ausgewiesen. Für den Vergleich von hierarchischen Modellen (‚Model Comparisons') wird zudem der Chi-Quadrat-Differenz-Test herangezogen (Weiber &amp; Mühlhaus, 2014). Dies ist bspw. der Fall, wenn man die spezifizierten latenten Faktoren auf Diskriminanzvalidität prüfen möchte (siehe nachfolgender Abschnitt), aber auch bei der Prüfung von Messinvarianz sowie der Restriktion anderweitiger Modellparameter. Für die Evaluation nicht-hierarchischer Modelle, also Modelle, die zwar auf Grundlage der gleichen Indikatoren und Daten spezifiziert werden, jedoch eine gänzlich andere Spezifikation der Kausalpfade haben, wird zudem das Akaike Information Criterion (AIC) herangezogen (Kline, 2011).Zudem wird nachfolgend der Tucker-Lewis-Index (TLI) als inkrementelles Fit-Maß herangezogen. Der Nachteil des TLI ist, dass dieser nicht-normiert ist, also auch Werte &gt; 1 annehmen kann, wobei ein Wert &gt; 1 für gewöhnlich auf 1.00 abgerundet wird. Weiber und Mühlhaus (2014) geben als Schwellenwert für den TLI Werte von mind. .90 an, laut L. Hu und Bentler (1999) sollte der Wert mind. bei .95 oder besser liegen. Es wird zusätzlich zum TLI auch häufig noch der Wert des Comparative Fit Index (CFI) angegeben (L. Hu &amp; Bentler, 1999;Schreiber et al., 2006). Kenny (2015) rät hiervon jedoch mit folgender Begründung ab: "Because the TLI and CFI are highly correlated only one of the two should be reported. The CFI is reported more often than the TLI, but I think the CFI's penalty for complexity of just 1 is too low and so I prefer the TLI even though the CFI is reported much more frequently than the TLI" (Kenny, 2015, § 10). Nachfolgend werden daher für alle Modelle der Chi-Quadrat-Test, der RMSEA samt 90 %-Konfidenzintervall sowie der TLI angegeben. Die Werte werden durchgängig wie folgt berichtet, wobei kursiv gesetzte Wörter durch die entsprechenden Werte ersetzt werden: (X 2 (df -Freiheitsgrade) = Chi-Quadrat-Wert, p &lt; Signifikanzwert; RMSEA = RMSEA-Wert [90 %-Konfidenzintervall: LO90-Wert, HI90-Wert]; TLI = TLI-Wert). Bei den Messmodellen der unidimensionalen Faktoren werden zudem noch das Cronbachsche α und die durchschnittlich extrahierte Varianz (DEV) ausgewiesen. Für den Vergleich von hierarchischen Modellen (‚Model Comparisons') wird zudem der Chi-Quadrat-Differenz-Test herangezogen (Weiber &amp; Mühlhaus, 2014). Dies ist bspw. der Fall, wenn man die spezifizierten latenten Faktoren auf Diskriminanzvalidität prüfen möchte (siehe nachfolgender Abschnitt), aber auch bei der Prüfung von Messinvarianz sowie der Restriktion anderweitiger Modellparameter. Für die Evaluation nicht-hierarchischer Modelle, also Modelle, die zwar auf Grundlage der gleichen Indikatoren und Daten spezifiziert werden, jedoch eine gänzlich andere Spezifikation der Kausalpfade haben, wird zudem das Akaike Information Criterion (AIC) herangezogen (Kline, 2011).</p>
        <p>Es ist zu diskutieren, inwieweit mit Blick auf die unterschiedenen Faktoren von diskriminanter Validität ausgegangen werden kann, d. h., messen die Indikatoren tatsächlich auch empirisch die konzeptuell unterschiedlichen Dimensionen der BDGS-Skala oder kann empirisch eben nicht unterschieden werden. Letzteres wäre bspw. der Fall, wenn die Befragten nicht zwischen den Indikatoren der einzelnen Dimensionen unterscheiden würden, also die einzelnen Indikatoren so hoch miteinander korrelieren, dass davon ausgegangen werden muss, dass sie die gleiche Ursache teilen (sprich: ein gemeinsames latentes Konstrukt, das ihre jeweilige Ausprägung beeinflusst). Weiber und Mühlhaus (2014) merken hierzu an: "Diskriminanzvalidität als Teilaspekt der Konstruktvalidität liegt vor, wenn sich die Messungen verschiedener Konstrukte signifikant unterscheiden" (S. 164). Im Rahmen der CFA gibt es zwei Möglichkeiten der Prüfung auf Diskriminanzvalidität: 1) den Chi-Quadrat-Differenztest und 2) das Fornell-Larcker-Kriterium, das dem ‚DEV vs. geteilte Varianz'-Test zugrunde liegt (Farrell, 2010;Weiber &amp; Mühlhaus, 2014).Es ist zu diskutieren, inwieweit mit Blick auf die unterschiedenen Faktoren von diskriminanter Validität ausgegangen werden kann, d. h., messen die Indikatoren tatsächlich auch empirisch die konzeptuell unterschiedlichen Dimensionen der BDGS-Skala oder kann empirisch eben nicht unterschieden werden. Letzteres wäre bspw. der Fall, wenn die Befragten nicht zwischen den Indikatoren der einzelnen Dimensionen unterscheiden würden, also die einzelnen Indikatoren so hoch miteinander korrelieren, dass davon ausgegangen werden muss, dass sie die gleiche Ursache teilen (sprich: ein gemeinsames latentes Konstrukt, das ihre jeweilige Ausprägung beeinflusst). Weiber und Mühlhaus (2014) merken hierzu an: "Diskriminanzvalidität als Teilaspekt der Konstruktvalidität liegt vor, wenn sich die Messungen verschiedener Konstrukte signifikant unterscheiden" (S. 164). Im Rahmen der CFA gibt es zwei Möglichkeiten der Prüfung auf Diskriminanzvalidität: 1) den Chi-Quadrat-Differenztest und 2) das Fornell-Larcker-Kriterium, das dem ‚DEV vs. geteilte Varianz'-Test zugrunde liegt (Farrell, 2010;Weiber &amp; Mühlhaus, 2014).</p>
        <p>Es wird bei der Prüfung auf Diskriminanzvalidität daher zunächst ein Chi-Quadrat-Differenztest durchgeführt, bei dem das nicht-restringierte Modell, für das die Kovarianz zwischen den beiden Faktoren frei geschätzt wird, einem restringierten Modell gegenübergestellt wird, "wobei das restringierte Modell bei Vorliegen von Diskriminanzvalidität auf jeden Fall die schlechtere Güte aufweisen muss" (Weiber &amp; Mühlhaus, 2014, S. 164). Beim restringierten Modell wird folglich die Kovarianz zwischen den beiden Faktoren auf den Wert 1 fixiert. Ist der Chi-Quadrat-Differenztest für den Modellvergleich signifikant, spricht dies aus empirischer Sicht für Diskriminanzvalidität.Es wird bei der Prüfung auf Diskriminanzvalidität daher zunächst ein Chi-Quadrat-Differenztest durchgeführt, bei dem das nicht-restringierte Modell, für das die Kovarianz zwischen den beiden Faktoren frei geschätzt wird, einem restringierten Modell gegenübergestellt wird, "wobei das restringierte Modell bei Vorliegen von Diskriminanzvalidität auf jeden Fall die schlechtere Güte aufweisen muss" (Weiber &amp; Mühlhaus, 2014, S. 164). Beim restringierten Modell wird folglich die Kovarianz zwischen den beiden Faktoren auf den Wert 1 fixiert. Ist der Chi-Quadrat-Differenztest für den Modellvergleich signifikant, spricht dies aus empirischer Sicht für Diskriminanzvalidität.</p>
        <p>Die zweite Möglichkeit, Diskriminanzvalidität zu prüfen, ist die Verwendung des Fornell-Larcker-Kriteriums, eines Tests, bei dem das Verhältnis der DEV der Faktoren zur gemeinsam geteilten Varianz in Beziehung gesetzt wird (Farrell, 2010;Fornell &amp; Larcker, 1981).Die zweite Möglichkeit, Diskriminanzvalidität zu prüfen, ist die Verwendung des Fornell-Larcker-Kriteriums, eines Tests, bei dem das Verhältnis der DEV der Faktoren zur gemeinsam geteilten Varianz in Beziehung gesetzt wird (Farrell, 2010;Fornell &amp; Larcker, 1981).</p>
        <p>Dieses Kriterium ist dabei wesentlich strenger [als der Chi-Quadrat-Differenztest] und stellt die durchschnittlich durch einen Faktor erfasste Varianz (…) mit jeder quadrierten Korrelation ( 2 ij ), die der betrachtete Faktor i mit einem anderen Faktor j aufweist, gegenüber. Da die quadrierte Korrelation zwischen zwei Faktoren als gemeinsame Varianz dieser Faktoren interpretiert werden kann, liegt nach Fornell/Larcker Diskriminanzvalidität dann vor, wenn diese gemeinsame Varianz kleiner ist als die DEV der jeweiligen Faktoren. (Weiber &amp; Mühlhaus, 2014, S. 165) Auch mit Blick auf die Prüfung der Diskriminanzvalidität ist an dieser Stelle der Skalenkonstruktion erneut auf das Verhältnis zwischen der Konzeption und dem Erkenntnisinteresse des BDGS und der empirischen Messung einzugehen. Für die Bewertung der Datenpassung zum vorgeschlagenen Modell haben sich die im vorigen Abschnitt beschriebenen Konventionen etabliert. Auch hier muss an der entsprechenden Stelle jedes Mal erneut abgewogen werden, zwischen strengem statistischen Test (der wohlgemerkt wie jede zur Konvention gewordene Daumenregel recht willkürlich gewählte Grenzen festlegt) und der konzeptionellen Unterscheidung in einzelne Dimensionen, denen innerhalb des BDGS eine bestimmte Bedeutung zukommt. Da die einzelnen Dimensionen des BDGS konzeptuell zusammenhängen und -insbesondere im Aggregat -eine Verbindung zwischen hoch ausgeprägten Wissensüberzeugungen und Nutzenerwartungen erwartet wird, werden nachfolgend die Prüfungen auf Diskriminanzvalidität entsprechend den Vorgaben aus der Literatur durchgeführt, jedoch nicht unhinterfragt auf Grundlage von Grenzwerten angenommen oder abgelehnt, sondern jeweils im Lichte der Skalenkonzeption reflektiert.Dieses Kriterium ist dabei wesentlich strenger [als der Chi-Quadrat-Differenztest] und stellt die durchschnittlich durch einen Faktor erfasste Varianz (…) mit jeder quadrierten Korrelation ( 2 ij ), die der betrachtete Faktor i mit einem anderen Faktor j aufweist, gegenüber. Da die quadrierte Korrelation zwischen zwei Faktoren als gemeinsame Varianz dieser Faktoren interpretiert werden kann, liegt nach Fornell/Larcker Diskriminanzvalidität dann vor, wenn diese gemeinsame Varianz kleiner ist als die DEV der jeweiligen Faktoren. (Weiber &amp; Mühlhaus, 2014, S. 165) Auch mit Blick auf die Prüfung der Diskriminanzvalidität ist an dieser Stelle der Skalenkonstruktion erneut auf das Verhältnis zwischen der Konzeption und dem Erkenntnisinteresse des BDGS und der empirischen Messung einzugehen. Für die Bewertung der Datenpassung zum vorgeschlagenen Modell haben sich die im vorigen Abschnitt beschriebenen Konventionen etabliert. Auch hier muss an der entsprechenden Stelle jedes Mal erneut abgewogen werden, zwischen strengem statistischen Test (der wohlgemerkt wie jede zur Konvention gewordene Daumenregel recht willkürlich gewählte Grenzen festlegt) und der konzeptionellen Unterscheidung in einzelne Dimensionen, denen innerhalb des BDGS eine bestimmte Bedeutung zukommt. Da die einzelnen Dimensionen des BDGS konzeptuell zusammenhängen und -insbesondere im Aggregat -eine Verbindung zwischen hoch ausgeprägten Wissensüberzeugungen und Nutzenerwartungen erwartet wird, werden nachfolgend die Prüfungen auf Diskriminanzvalidität entsprechend den Vorgaben aus der Literatur durchgeführt, jedoch nicht unhinterfragt auf Grundlage von Grenzwerten angenommen oder abgelehnt, sondern jeweils im Lichte der Skalenkonzeption reflektiert.</p>
        <p>Die Prüfung der Diskriminanzvalidität hoch korrelierter und konzeptuell ähnlicher Dimensionen wird in Abschnitt 9.1.6 ergänzt um eine Diskussion und Prüfung der ‚dimensionalen Verschiedenheit' (DV) des spezifizierten Models, bei der alle miteinander korrelierten latenten Konstrukte im Correlated-Factor-Modell (CFM) einem Second-Order-Factor-Modell (SOFM) gegenübergestellt werden (Gignac &amp; Kretzschmar, 2017). Die Prüfung DV bezieht sich dabei auf das Gesamtmodell und die Plausibilität der Annahme separierbarer Dimensionen im Gesamtmodell.Die Prüfung der Diskriminanzvalidität hoch korrelierter und konzeptuell ähnlicher Dimensionen wird in Abschnitt 9.1.6 ergänzt um eine Diskussion und Prüfung der ‚dimensionalen Verschiedenheit' (DV) des spezifizierten Models, bei der alle miteinander korrelierten latenten Konstrukte im Correlated-Factor-Modell (CFM) einem Second-Order-Factor-Modell (SOFM) gegenübergestellt werden (Gignac &amp; Kretzschmar, 2017). Die Prüfung DV bezieht sich dabei auf das Gesamtmodell und die Plausibilität der Annahme separierbarer Dimensionen im Gesamtmodell.</p>
        <p>Ausgehend von der in Abschnitt 3. Eine CFA, die mit den imputierten Daten für das Messmodell gerechnet wird und bei dem jeweils sechs Indikatoren in einem Single-Factor-Modell (SFM) auf einen zugrunde liegenden latenten Faktor laden, zeigt eine geringe Anpassungsgüte (X 2 (132) = 365.32, p &lt; .001; RMSEA = .083 [.073, .094]; TLI = .922) und wird abgelehnt. Mit einer Ausnahme 11 haben alle Items eine Faktorladung von mindestens λ = .714. Zwar zeigt sich mit Blick auf die interne Konsistenz der Faktoren, dass die jeweiligen Indikatoren der Dimensionen Genauigkeit (α = .908; DEV = .636), Wahrhaftigkeit (α = .895; DEV = .591) und Wissensgewinn (α = .914; DEV = .649) hohe Reliabilitätswerte aufweisen. Doch auch hier haben etliche Items der distinkten Faktoren eine gemeinsam geteilte Varianz, die nicht durch den gemeinsamen latenten Faktor erklärt wird, so dass die Kovarianz der Fehlerterme freigegeben werden müsste, um frei zu variieren. Es zeigt sich mit Blick auf die beiden latenten Konstrukte Genauigkeit und Wahrhaftigkeit der digitalen Daten eine sehr hohe Korrelation (r Genauigkeit,Wahrhaftigkeit = .903), die auch hier darauf hinweist, dass möglicherweise nicht von diskriminanter Validität zwischen den beiden Faktoren ausgegangen werden kann. Die Korrelationen zwischen dem Faktor Genauigkeit und dem Faktor Wissensgewinn (r Genauigkeit,Wissensgewinn = .874) bzw. zwischen dem Faktor Wahrhaftigkeit und dem Faktor Wissensgewinn (r Wahrhaftigkeit,Wissensgewinn = .734) sind ebenfalls hoch.Ausgehend von der in Abschnitt 3. Eine CFA, die mit den imputierten Daten für das Messmodell gerechnet wird und bei dem jeweils sechs Indikatoren in einem Single-Factor-Modell (SFM) auf einen zugrunde liegenden latenten Faktor laden, zeigt eine geringe Anpassungsgüte (X 2 (132) = 365.32, p &lt; .001; RMSEA = .083 [.073, .094]; TLI = .922) und wird abgelehnt. Mit einer Ausnahme 11 haben alle Items eine Faktorladung von mindestens λ = .714. Zwar zeigt sich mit Blick auf die interne Konsistenz der Faktoren, dass die jeweiligen Indikatoren der Dimensionen Genauigkeit (α = .908; DEV = .636), Wahrhaftigkeit (α = .895; DEV = .591) und Wissensgewinn (α = .914; DEV = .649) hohe Reliabilitätswerte aufweisen. Doch auch hier haben etliche Items der distinkten Faktoren eine gemeinsam geteilte Varianz, die nicht durch den gemeinsamen latenten Faktor erklärt wird, so dass die Kovarianz der Fehlerterme freigegeben werden müsste, um frei zu variieren. Es zeigt sich mit Blick auf die beiden latenten Konstrukte Genauigkeit und Wahrhaftigkeit der digitalen Daten eine sehr hohe Korrelation (r Genauigkeit,Wahrhaftigkeit = .903), die auch hier darauf hinweist, dass möglicherweise nicht von diskriminanter Validität zwischen den beiden Faktoren ausgegangen werden kann. Die Korrelationen zwischen dem Faktor Genauigkeit und dem Faktor Wissensgewinn (r Genauigkeit,Wissensgewinn = .874) bzw. zwischen dem Faktor Wahrhaftigkeit und dem Faktor Wissensgewinn (r Wahrhaftigkeit,Wissensgewinn = .734) sind ebenfalls hoch.</p>
        <p>Es ist zu diskutieren, inwieweit mit Blick auf die drei unterschiedenen Faktoren im CFM noch von diskriminanter Validität ausgegangen werden kann, d. h., messen die Indikatoren tatsächlich auch empirisch die drei konzeptuell unterschiedlichen Dimensionen der Richtigkeit oder kann empirisch eben nicht unterschieden werden. Wie in Abschnitt 9.1.3 beschrieben, gibt es im Rahmen 11 Das Item ‚Digitale Daten können als eine höhere Form von Intelligenz betrachtet werden' hat lediglich eine Faktorladung von λ = .606. Dies ist insofern erwähnenswert, als dass dieses Item unmittelbar auf den von boyd und Crawford benannten Kern des Mythos Big Data abstellt: "large data sets offer a higher form of intelligence and knowledge" (2012, S. 663). Unbenommen ist hier, dass die wortwörtliche Übersetzung aus dem Englischen ins Deutsche im Original anders verstanden werden kann und geläufiger ist als die zugegebenermaßen holprig klingende deutsche Version.Es ist zu diskutieren, inwieweit mit Blick auf die drei unterschiedenen Faktoren im CFM noch von diskriminanter Validität ausgegangen werden kann, d. h., messen die Indikatoren tatsächlich auch empirisch die drei konzeptuell unterschiedlichen Dimensionen der Richtigkeit oder kann empirisch eben nicht unterschieden werden. Wie in Abschnitt 9.1.3 beschrieben, gibt es im Rahmen 11 Das Item ‚Digitale Daten können als eine höhere Form von Intelligenz betrachtet werden' hat lediglich eine Faktorladung von λ = .606. Dies ist insofern erwähnenswert, als dass dieses Item unmittelbar auf den von boyd und Crawford benannten Kern des Mythos Big Data abstellt: "large data sets offer a higher form of intelligence and knowledge" (2012, S. 663). Unbenommen ist hier, dass die wortwörtliche Übersetzung aus dem Englischen ins Deutsche im Original anders verstanden werden kann und geläufiger ist als die zugegebenermaßen holprig klingende deutsche Version.</p>
        <p>der CFA zwei Möglichkeiten der Prüfung auf Diskriminanzvalidität: 1) den Chi-Quadrat-Differenztest und 2) das Fornell-Larcker-Kriterium (Weiber &amp; Mühlhaus, 2014). Wie erwähnt, ist das Fornell-Larcker-Kriterium der strengere Test und es wird schnell deutlich, dass die quadrierten Korrelationen der Faktoren Genauigkeit und Wahrhaftigkeit (r 2 Genauigkeit,Wahrhaftigkeit = .815) sowie Genauigkeit und Wissensgewinn (r 2 Genauigkeit,Wissensgewinn = .764), mit Blick auf die Angaben zur DEV weiter oben, die Annahme der Diskriminanzvalidität nicht bestätigen können, während er für die Faktoren Wahrhaftigkeit und Wissensgewinn angenommen wird (r 2 Wahrhaftigkeit,Wissensgewinn = .539). Das bedeutet, dass zwar konzeptionell zwischen der Genauigkeit und der Wahrhaftigkeit der Daten unterschieden werden kann, dieser Unterschied jedoch von den Befragten in der Zustimmung zu den Frageitems nicht gemacht wird, eine getroffene Unterscheidung zwischen diesen Konzeptdimensionen also nicht beobachtbar ist. Jemand, der erwartet, dass Daten ein genaues Verständnis der Welt ermöglichen, bewertet diese Erkenntnis auf Datengrundlage auch als objektiv und wahrhaftig. So ist bspw. die mögliche Einschätzung, dass ein möglicher Bias in präzise dokumentierten Daten dazu führt, dass die Daten zwar genau das wiedergeben, was sie messen, aber dennoch nicht ‚objektiv' sind und diskriminieren, zumindest über alle Befragten hinweg auf dem Abstraktionsniveau der vorliegenden Indikatoren nicht zu beobachten.der CFA zwei Möglichkeiten der Prüfung auf Diskriminanzvalidität: 1) den Chi-Quadrat-Differenztest und 2) das Fornell-Larcker-Kriterium (Weiber &amp; Mühlhaus, 2014). Wie erwähnt, ist das Fornell-Larcker-Kriterium der strengere Test und es wird schnell deutlich, dass die quadrierten Korrelationen der Faktoren Genauigkeit und Wahrhaftigkeit (r 2 Genauigkeit,Wahrhaftigkeit = .815) sowie Genauigkeit und Wissensgewinn (r 2 Genauigkeit,Wissensgewinn = .764), mit Blick auf die Angaben zur DEV weiter oben, die Annahme der Diskriminanzvalidität nicht bestätigen können, während er für die Faktoren Wahrhaftigkeit und Wissensgewinn angenommen wird (r 2 Wahrhaftigkeit,Wissensgewinn = .539). Das bedeutet, dass zwar konzeptionell zwischen der Genauigkeit und der Wahrhaftigkeit der Daten unterschieden werden kann, dieser Unterschied jedoch von den Befragten in der Zustimmung zu den Frageitems nicht gemacht wird, eine getroffene Unterscheidung zwischen diesen Konzeptdimensionen also nicht beobachtbar ist. Jemand, der erwartet, dass Daten ein genaues Verständnis der Welt ermöglichen, bewertet diese Erkenntnis auf Datengrundlage auch als objektiv und wahrhaftig. So ist bspw. die mögliche Einschätzung, dass ein möglicher Bias in präzise dokumentierten Daten dazu führt, dass die Daten zwar genau das wiedergeben, was sie messen, aber dennoch nicht ‚objektiv' sind und diskriminieren, zumindest über alle Befragten hinweg auf dem Abstraktionsniveau der vorliegenden Indikatoren nicht zu beobachten.</p>
        <p>Als Konsequenz wurden in einem ersten Schritt die Faktoren Genauigkeit und Wahrhaftigkeit zusammengelegt, so dass die zwölf Items, die diesen Faktoren zugrunde lagen, nun auf einen gemeinsamen Faktor luden und ein Modell mit zwei Faktoren ‚Wahrhaftigkeit/Genauigkeit' und ‚Wissensgewinn' geprüft wurde. Die CFA für dieses Modell, das mit den imputierten Daten gerechnet wurde, zeigt weiterhin eine geringe Anpassungsgüte (X 2 (135) = 640.598, p &lt; .001; RMSEA = .121 [.112, .131 Die CFA für dieses Modell, das mit den nicht-imputierten Daten gerechnet wurde, kommt zu einer plausiblen Lösung und zeigt eine zufriedenstellende Anpassungsgüte (X 2 (8) = 11.062, p = .198; RMSEA = .039 [.000, .089]; TLI = .990) und wird folglich angenommen. Allerdings zeigt sich auch hier für Genauigkeit (α = .867; DEV = .679) und Wissensgewinn (α = .853; DEV = .679) eine hohe Interkorrelation beider Faktoren (r = .829, r 2 = .687), welche die Diskriminanzvalidität in Frage stellt. Da die DEV beider Faktoren mit jeweils genau .679 leicht niedriger liegt als die quadrierte Korrelation wird hier dennoch zugunsten der Zwei-Faktor-Lösung entschieden, wobei zu prüfen sein wird, inwieweit sich Diskriminanzvalidität in Folgeerhebungen zeigt oder nicht. Die Aufrechterhaltung der konzeptionellen und der empirischen Trennung in der Modellierung und der Erhebung der Items für die zwei Faktoren wird auch dahingehend fortgeführt, als dass vorstellbar ist, dass je nach Studienschwerpunkt und Forschungsfragen in der Anschlussforschung eine Aufteilung sinnvoll sein könnte. Es muss hier jedoch auch bedacht werden, dass die Multi-Kollinearität beim BDGS ein generelles Problem darstellt, da sich zeigt, dass alle Dimensionen hoch miteinander korreliert sind. Diese Fragen betreffen nachfolgend auch die Trennung der nun folgenden Nutzendimension.Als Konsequenz wurden in einem ersten Schritt die Faktoren Genauigkeit und Wahrhaftigkeit zusammengelegt, so dass die zwölf Items, die diesen Faktoren zugrunde lagen, nun auf einen gemeinsamen Faktor luden und ein Modell mit zwei Faktoren ‚Wahrhaftigkeit/Genauigkeit' und ‚Wissensgewinn' geprüft wurde. Die CFA für dieses Modell, das mit den imputierten Daten gerechnet wurde, zeigt weiterhin eine geringe Anpassungsgüte (X 2 (135) = 640.598, p &lt; .001; RMSEA = .121 [.112, .131 Die CFA für dieses Modell, das mit den nicht-imputierten Daten gerechnet wurde, kommt zu einer plausiblen Lösung und zeigt eine zufriedenstellende Anpassungsgüte (X 2 (8) = 11.062, p = .198; RMSEA = .039 [.000, .089]; TLI = .990) und wird folglich angenommen. Allerdings zeigt sich auch hier für Genauigkeit (α = .867; DEV = .679) und Wissensgewinn (α = .853; DEV = .679) eine hohe Interkorrelation beider Faktoren (r = .829, r 2 = .687), welche die Diskriminanzvalidität in Frage stellt. Da die DEV beider Faktoren mit jeweils genau .679 leicht niedriger liegt als die quadrierte Korrelation wird hier dennoch zugunsten der Zwei-Faktor-Lösung entschieden, wobei zu prüfen sein wird, inwieweit sich Diskriminanzvalidität in Folgeerhebungen zeigt oder nicht. Die Aufrechterhaltung der konzeptionellen und der empirischen Trennung in der Modellierung und der Erhebung der Items für die zwei Faktoren wird auch dahingehend fortgeführt, als dass vorstellbar ist, dass je nach Studienschwerpunkt und Forschungsfragen in der Anschlussforschung eine Aufteilung sinnvoll sein könnte. Es muss hier jedoch auch bedacht werden, dass die Multi-Kollinearität beim BDGS ein generelles Problem darstellt, da sich zeigt, dass alle Dimensionen hoch miteinander korreliert sind. Diese Fragen betreffen nachfolgend auch die Trennung der nun folgenden Nutzendimension.</p>
        <p>Mit Blick auf den aus den Daten gezogenen Nutzen wird im BDGS und somit auch in den Befragungsitems zwischen einem persönlichen Nutzen für das Individuum (‚Individueller Nutzen') und dem Nutzen für die Gesamtgesellschaft (‚Gesellschaftlicher Nutzen') unterschieden (siehe Abschnitt 3.5.2). Mit Blick auf die Frageitems der letzteren Dimension blieb in der Einleitung und den Aussagen offen, wer oder was unter dem Begriff der Gesellschaft gemeint ist. Es wurde nicht zwischen einer vermeintlich vagen Allgemeinheit oder einer konkreten Gesellschaft (wie bspw. einer europäischen oder einer nationalen Gesellschaft) abgestuft. Das hat zur Folge, dass Befragte ganz verschiedene Dinge mit dem Gesellschaftsbegriff verbinden, mithin unterschiedliche Vorstellungen davon haben können, was Gesellschaft ausmacht, woraus und aus wem sie jeweils besteht (Kölbl &amp; Althof, 2014). Es zeigt sich dann auch, dass mit Blick auf das Individuum und die menschliche Identitätswahrnehmung ganz unterschiedliche Verständnisse von Gesellschaft zwischen einem Zugehörigkeitsgefühl zu einer Weltgesellschaft und regionalen, gar lokalen Verbünden existieren (Herrmann et al., 2004). Dieses feinteilige Verständnis kann auch mit Blick auf die Messung der gesellschaftlichen Nutzenwahrnehmung nur unzureichend operationalisiert werden. Während also offenbleibt, was oder wen die Befragten nun zur situativ imaginierten Gesellschaft zählen, so sollte durch die Kontrastierung mit Items, die auf den individuellen Nutzen aus digitaler Datensammlung und -verwertung abstellen, deutlich werden, dass hier bezüglich eines Kollektivs gefragt wird, zu dem die Befragten in Beziehung stehen, als dessen vollständig zugehörige Mitglieder sich die Befragten jedoch nicht zwingend verstehen müssen. Die Modellierung der beiden Dimensionen und die Datenanalyse der Frageitems werden im folgenden Abschnitt nachvollzogen.Mit Blick auf den aus den Daten gezogenen Nutzen wird im BDGS und somit auch in den Befragungsitems zwischen einem persönlichen Nutzen für das Individuum (‚Individueller Nutzen') und dem Nutzen für die Gesamtgesellschaft (‚Gesellschaftlicher Nutzen') unterschieden (siehe Abschnitt 3.5.2). Mit Blick auf die Frageitems der letzteren Dimension blieb in der Einleitung und den Aussagen offen, wer oder was unter dem Begriff der Gesellschaft gemeint ist. Es wurde nicht zwischen einer vermeintlich vagen Allgemeinheit oder einer konkreten Gesellschaft (wie bspw. einer europäischen oder einer nationalen Gesellschaft) abgestuft. Das hat zur Folge, dass Befragte ganz verschiedene Dinge mit dem Gesellschaftsbegriff verbinden, mithin unterschiedliche Vorstellungen davon haben können, was Gesellschaft ausmacht, woraus und aus wem sie jeweils besteht (Kölbl &amp; Althof, 2014). Es zeigt sich dann auch, dass mit Blick auf das Individuum und die menschliche Identitätswahrnehmung ganz unterschiedliche Verständnisse von Gesellschaft zwischen einem Zugehörigkeitsgefühl zu einer Weltgesellschaft und regionalen, gar lokalen Verbünden existieren (Herrmann et al., 2004). Dieses feinteilige Verständnis kann auch mit Blick auf die Messung der gesellschaftlichen Nutzenwahrnehmung nur unzureichend operationalisiert werden. Während also offenbleibt, was oder wen die Befragten nun zur situativ imaginierten Gesellschaft zählen, so sollte durch die Kontrastierung mit Items, die auf den individuellen Nutzen aus digitaler Datensammlung und -verwertung abstellen, deutlich werden, dass hier bezüglich eines Kollektivs gefragt wird, zu dem die Befragten in Beziehung stehen, als dessen vollständig zugehörige Mitglieder sich die Befragten jedoch nicht zwingend verstehen müssen. Die Modellierung der beiden Dimensionen und die Datenanalyse der Frageitems werden im folgenden Abschnitt nachvollzogen.</p>
        <p>Die ersten sieben der 15 in Tabelle 2.C gelisteten Items betrafen die Erwartung eines individuellen Nutzens aus dem Entstehungs-und Verwertungskontext digitaler Daten. Sprich: Glaubt bspw. eine bestimmte Befragte, dass sie persönlich einen Nutzen für sich selbst aus der Datensammlung und -verwertung zieht. Dabei wurde nicht zwischen dem Entstehungs-und Verwertungskontext unterschieden, sondern die Items fragten im Präsens formuliert, ob ein Nutzen wahrgenommen wird. Die letzten acht Items stellten dann auf den gesellschaftlichen Nutzen ab, der sich aus dem Entstehungs-und Verwertungskontext digitaler Daten ergibt.Die ersten sieben der 15 in Tabelle 2.C gelisteten Items betrafen die Erwartung eines individuellen Nutzens aus dem Entstehungs-und Verwertungskontext digitaler Daten. Sprich: Glaubt bspw. eine bestimmte Befragte, dass sie persönlich einen Nutzen für sich selbst aus der Datensammlung und -verwertung zieht. Dabei wurde nicht zwischen dem Entstehungs-und Verwertungskontext unterschieden, sondern die Items fragten im Präsens formuliert, ob ein Nutzen wahrgenommen wird. Die letzten acht Items stellten dann auf den gesellschaftlichen Nutzen ab, der sich aus dem Entstehungs-und Verwertungskontext digitaler Daten ergibt.</p>
        <p>Eine CFA, die mit den imputierten Daten für das Messmodell gerechnet wird und bei dem alle 15 Nutzen-Indikatoren im SFM auf einen latenten Faktor laden, zeigte eine unzureichende Anpassungsgüte (X 2 (90) = 299.515, p &lt; .001; RMSEA = .096 [.084, .108]; TLI = .924) und wird abgelehnt. Zwar haben alle Items eine Faktorladung von mindestens λ = .709. Doch auch hier haben etliche Items eine gemeinsame geteilte Varianz, die nicht durch den gemeinsamen latenten Faktor erklärt wird, so dass hier entweder die Kovarianz der Fehlerterme freigegeben werden müsste, um frei zu variieren, oder aber eine mehrdimensionale Lösung mit zwei oder mehr Faktoren gerechnet werden sollte.Eine CFA, die mit den imputierten Daten für das Messmodell gerechnet wird und bei dem alle 15 Nutzen-Indikatoren im SFM auf einen latenten Faktor laden, zeigte eine unzureichende Anpassungsgüte (X 2 (90) = 299.515, p &lt; .001; RMSEA = .096 [.084, .108]; TLI = .924) und wird abgelehnt. Zwar haben alle Items eine Faktorladung von mindestens λ = .709. Doch auch hier haben etliche Items eine gemeinsame geteilte Varianz, die nicht durch den gemeinsamen latenten Faktor erklärt wird, so dass hier entweder die Kovarianz der Fehlerterme freigegeben werden müsste, um frei zu variieren, oder aber eine mehrdimensionale Lösung mit zwei oder mehr Faktoren gerechnet werden sollte.</p>
        <p>Es wurde anschließend ein Modell geprüft, bei dem zwischen dem individuellen und gesellschaftlichen Nutzen unterschieden wurde, der aus digitalen Datenbeständen gezogen wird. Das Modell bestand aus den zwei latenten Faktoren individueller Nutzen (sieben reflektive Indikatoren) und gesellschaftlicher Nutzen (acht reflektive Indikatoren). Die jeweiligen Items luden allein auf den jeweiligen latenten Faktor. Das Modell sah keine Kreuzladungen vor und die latenten Faktoren konnten frei miteinander kovariieren. Die geschätzte Lösung der CFA ist zulässig. Das Modell, das mit den imputierten Daten gerechnet wurde, zeigt weiterhin eine insgesamt noch akzeptable Anpassungsgüte (X 2 (89) = 156.822, p &lt; .001; RMSEA = .055 [.040, .069]; TLI = .975), auch wenn es mit Blick auf den Chi-Quadrat-Test abgelehnt werden muss. Es zeigt sich darüber hinaus, dass zwischen den beiden latenten Konstrukten eine hohe Korrelation besteht (r individueller Nutzen, gesellschaftlicher Nutzen = .897), was mit Blick auf die diskriminante Validität der beiden konzeptuell unterschiedlichen Dimensionen näher zu betrachten ist.Es wurde anschließend ein Modell geprüft, bei dem zwischen dem individuellen und gesellschaftlichen Nutzen unterschieden wurde, der aus digitalen Datenbeständen gezogen wird. Das Modell bestand aus den zwei latenten Faktoren individueller Nutzen (sieben reflektive Indikatoren) und gesellschaftlicher Nutzen (acht reflektive Indikatoren). Die jeweiligen Items luden allein auf den jeweiligen latenten Faktor. Das Modell sah keine Kreuzladungen vor und die latenten Faktoren konnten frei miteinander kovariieren. Die geschätzte Lösung der CFA ist zulässig. Das Modell, das mit den imputierten Daten gerechnet wurde, zeigt weiterhin eine insgesamt noch akzeptable Anpassungsgüte (X 2 (89) = 156.822, p &lt; .001; RMSEA = .055 [.040, .069]; TLI = .975), auch wenn es mit Blick auf den Chi-Quadrat-Test abgelehnt werden muss. Es zeigt sich darüber hinaus, dass zwischen den beiden latenten Konstrukten eine hohe Korrelation besteht (r individueller Nutzen, gesellschaftlicher Nutzen = .897), was mit Blick auf die diskriminante Validität der beiden konzeptuell unterschiedlichen Dimensionen näher zu betrachten ist.</p>
        <p>Zunächst wurde das Modell jedoch wiederum nach dem in Abschnitt 9.1.3 dargestellten Vorgehen respezifiziert, um Items zu eliminieren, die hoch miteinander kovariierten oder im Vergleich schlechter auf die jeweiligen latenten Faktoren luden. Das finale Modell besteht aus zwei latenten Faktoren, auf die jeweils die folgenden drei Indikatoren laden. Auch hier werden nachfolgend die angegebenen Item-IDs von nun an durchgängig vergeben und gebraucht, um das jeweilige Frageitem zu identifizieren. Die CFA für dieses Modell, gerechnet mit den nicht-imputierten Daten, kommt zu einer plausiblen Lösung und zeigt eine hohe Anpassungsgüte (X 2 (8) = 2.174, p = .975; RMSEA = .000 [.000, .000]; TLI = 1.016), mit Faktorladungen von mindestens λ = .801.Zunächst wurde das Modell jedoch wiederum nach dem in Abschnitt 9.1.3 dargestellten Vorgehen respezifiziert, um Items zu eliminieren, die hoch miteinander kovariierten oder im Vergleich schlechter auf die jeweiligen latenten Faktoren luden. Das finale Modell besteht aus zwei latenten Faktoren, auf die jeweils die folgenden drei Indikatoren laden. Auch hier werden nachfolgend die angegebenen Item-IDs von nun an durchgängig vergeben und gebraucht, um das jeweilige Frageitem zu identifizieren. Die CFA für dieses Modell, gerechnet mit den nicht-imputierten Daten, kommt zu einer plausiblen Lösung und zeigt eine hohe Anpassungsgüte (X 2 (8) = 2.174, p = .975; RMSEA = .000 [.000, .000]; TLI = 1.016), mit Faktorladungen von mindestens λ = .801.</p>
        <p>Die jeweils drei Indikatoren der final modellierten Faktoren individueller Nutzen (α = .874; DEV = .700) und gesellschaftlicher Nutzen (α = .863; DEV = .676) zeigen eine hohe Reliabilität und konvergente Validität der Indikatoren, jedoch auch eine sehr hohe Korrelation zwischen den Faktoren (r individueller Nutzen, gesellschaftlicher Nutzen = .915). Wie bereits im vorhergehenden Abschnitt angedeutet, ist zu diskutieren, inwieweit mit Blick auf die beiden Faktoren noch von diskriminanter Validität ausgegangen werden kann: D. h., messen die Indikatoren tatsächlich auch empirisch die zwei konzeptuell unterschiedlichen Dimensionen des Nutzens oder kann empirisch eben nicht unterschieden werden? Auch hier wurden, wie eingangs in Abschnitt 9.1.3 beschrieben, zur Prüfung auf Diskriminanzvalidität 1) der Chi-Quadrat-Differenztest und 2) das Fornell-Larcker-Kriterium herangezogen (Weiber &amp; Mühlhaus, 2014).Die jeweils drei Indikatoren der final modellierten Faktoren individueller Nutzen (α = .874; DEV = .700) und gesellschaftlicher Nutzen (α = .863; DEV = .676) zeigen eine hohe Reliabilität und konvergente Validität der Indikatoren, jedoch auch eine sehr hohe Korrelation zwischen den Faktoren (r individueller Nutzen, gesellschaftlicher Nutzen = .915). Wie bereits im vorhergehenden Abschnitt angedeutet, ist zu diskutieren, inwieweit mit Blick auf die beiden Faktoren noch von diskriminanter Validität ausgegangen werden kann: D. h., messen die Indikatoren tatsächlich auch empirisch die zwei konzeptuell unterschiedlichen Dimensionen des Nutzens oder kann empirisch eben nicht unterschieden werden? Auch hier wurden, wie eingangs in Abschnitt 9.1.3 beschrieben, zur Prüfung auf Diskriminanzvalidität 1) der Chi-Quadrat-Differenztest und 2) das Fornell-Larcker-Kriterium herangezogen (Weiber &amp; Mühlhaus, 2014).</p>
        <p>Es wurde daher zunächst ein Chi-Quadrat-Differenztest durchgeführt, bei dem das nicht-restringierte Modell einem restringierten Modell gegenübergestellt wird. Der Chi-Quadrat-Differenztest für den Modellvergleich ( X 2 = 6.56, df = 1, p &lt; .05) ist signifikant, was für Diskriminanzvalidität spricht.Es wurde daher zunächst ein Chi-Quadrat-Differenztest durchgeführt, bei dem das nicht-restringierte Modell einem restringierten Modell gegenübergestellt wird. Der Chi-Quadrat-Differenztest für den Modellvergleich ( X 2 = 6.56, df = 1, p &lt; .05) ist signifikant, was für Diskriminanzvalidität spricht.</p>
        <p>Eine weitere Möglichkeit, Diskriminanzvalidität zu prüfen, ist die Verwendung des Fornell-Larcker-Kriteriums. Da die durchschnittlich extrahierten Varianzen beider Faktoren mit .700, bzw. .676 kleiner sind als deren quadrierte Korrelation (r 2 individueller Nutzen, gesellschaftlicher Nutzen = .837), wäre im vorliegenden Fall keine Diskriminanzvalidität gegeben.Eine weitere Möglichkeit, Diskriminanzvalidität zu prüfen, ist die Verwendung des Fornell-Larcker-Kriteriums. Da die durchschnittlich extrahierten Varianzen beider Faktoren mit .700, bzw. .676 kleiner sind als deren quadrierte Korrelation (r 2 individueller Nutzen, gesellschaftlicher Nutzen = .837), wäre im vorliegenden Fall keine Diskriminanzvalidität gegeben.</p>
        <p>Die sich widersprechenden Ergebnisse zeigen, dass es auch hier keine einheitliche Antwort auf die Frage nach der Diskriminanzvalidität gibt, da diese von den willkürlich gesetzten Cut-off-Kriterien abhängt. Auch hier ist mit Blick auf konzeptuelle Modellierung und die empirischen Ergebnisse abzuwägen, welcher Modellierungsvariante der Vorzug gegeben wird. Mit Blick auf die Nutzendimension des BDGS wird der weniger strengen Auslegung gefolgt und die Aufteilung in zwei Faktoren beibehalten, die mit persönlichem individuellen und dem allgemeinen gesellschaftlichen Nutzen zwei distinkte Dimensionen des Nutzengewinns auf Grundlage digitaler Daten unterscheidet. Das wird zum einen damit begründet, dass mit Blick auf die positive öffentliche Betrachtung der gesamtgesellschaftlichen Konsequenzen der Digitalisierung und der eigenen Erfahrung mit digitalen Werkzeugen eine hohe Korrelation des individuell gesehenen Nutzens mit dem gesellschaftlichen Nutzen zu erwarten ist. Haben Personen jedoch eine negative Bewertung der Folgen für die Gesellschaft, schlägt diese Einschätzung möglicherweise auch auf die Bewertung der eigenen Lage durch. Es werden an dieser Stelle noch keine Hypothesen aufgestellt oder Prognosen abgegeben. So gibt es zumindest keine Hinweise darauf, dass die Nutzenerwartungen für das Individuum systematisch vom Gesamtgesellschaftlichen entkoppelt sind. Auch wenn dies für bestimmte Personen und Digitalisierungskontexte durchaus möglich erscheint, müssten entsprechende Annahmen zunächst einmal argumentativ für den spezifischen Fall hergeleitet werden. Die Ausführungen zum Glaubenssystem in Kapitel 6 legen hingegen eher nahe, dass eine Aktivierung des BDGS, unter der Annahme eines nicht vollständig durchschaubaren Ursache-Wirkungs-Zusammenhangs digitaler Datenentstehung und -verwertung und die hieraus entstehenden Konsequenzen, eine im Aggregat relativ undifferenzierte Gesamtevaluation bezüglich der Nutzenerwartung zur Folge hat. Zudem soll ja gerade die feinteilige Unterscheidung in die diskreten Dimensionen des BDGS nachfolgend genutzt werden, um zu prüfen, inwieweit einzeln erhobene Glaubenssätze als erklärende Variablen für die empirische Forschung dienen können, wobei es je nach Forschungszusammenhang und Befragungskontext sinnvoll ist, zwischen den Nutzendimensionen unterscheiden zu können. Es ist denkbar, dass es Lebensbereiche und mithin Forschungsfragen gibt, für die unterschiedliche Bewertungen und Auswirkungen der Nutzenerwartungen dokumentiert werden könnten. Aus diesen Gründen ist der konzeptuellen sowie der empirischen Trennung der Dimensionen in der Modellierung an dieser Stelle zunächst der Vorzug zu geben.Die sich widersprechenden Ergebnisse zeigen, dass es auch hier keine einheitliche Antwort auf die Frage nach der Diskriminanzvalidität gibt, da diese von den willkürlich gesetzten Cut-off-Kriterien abhängt. Auch hier ist mit Blick auf konzeptuelle Modellierung und die empirischen Ergebnisse abzuwägen, welcher Modellierungsvariante der Vorzug gegeben wird. Mit Blick auf die Nutzendimension des BDGS wird der weniger strengen Auslegung gefolgt und die Aufteilung in zwei Faktoren beibehalten, die mit persönlichem individuellen und dem allgemeinen gesellschaftlichen Nutzen zwei distinkte Dimensionen des Nutzengewinns auf Grundlage digitaler Daten unterscheidet. Das wird zum einen damit begründet, dass mit Blick auf die positive öffentliche Betrachtung der gesamtgesellschaftlichen Konsequenzen der Digitalisierung und der eigenen Erfahrung mit digitalen Werkzeugen eine hohe Korrelation des individuell gesehenen Nutzens mit dem gesellschaftlichen Nutzen zu erwarten ist. Haben Personen jedoch eine negative Bewertung der Folgen für die Gesellschaft, schlägt diese Einschätzung möglicherweise auch auf die Bewertung der eigenen Lage durch. Es werden an dieser Stelle noch keine Hypothesen aufgestellt oder Prognosen abgegeben. So gibt es zumindest keine Hinweise darauf, dass die Nutzenerwartungen für das Individuum systematisch vom Gesamtgesellschaftlichen entkoppelt sind. Auch wenn dies für bestimmte Personen und Digitalisierungskontexte durchaus möglich erscheint, müssten entsprechende Annahmen zunächst einmal argumentativ für den spezifischen Fall hergeleitet werden. Die Ausführungen zum Glaubenssystem in Kapitel 6 legen hingegen eher nahe, dass eine Aktivierung des BDGS, unter der Annahme eines nicht vollständig durchschaubaren Ursache-Wirkungs-Zusammenhangs digitaler Datenentstehung und -verwertung und die hieraus entstehenden Konsequenzen, eine im Aggregat relativ undifferenzierte Gesamtevaluation bezüglich der Nutzenerwartung zur Folge hat. Zudem soll ja gerade die feinteilige Unterscheidung in die diskreten Dimensionen des BDGS nachfolgend genutzt werden, um zu prüfen, inwieweit einzeln erhobene Glaubenssätze als erklärende Variablen für die empirische Forschung dienen können, wobei es je nach Forschungszusammenhang und Befragungskontext sinnvoll ist, zwischen den Nutzendimensionen unterscheiden zu können. Es ist denkbar, dass es Lebensbereiche und mithin Forschungsfragen gibt, für die unterschiedliche Bewertungen und Auswirkungen der Nutzenerwartungen dokumentiert werden könnten. Aus diesen Gründen ist der konzeptuellen sowie der empirischen Trennung der Dimensionen in der Modellierung an dieser Stelle zunächst der Vorzug zu geben.</p>
        <p>Die einzelnen Dimensionen wurden nun, wie in Abbildung 9.2 dargestellt, in einem CFM zusammengefasst spezifiziert.Die einzelnen Dimensionen wurden nun, wie in Abbildung 9.2 dargestellt, in einem CFM zusammengefasst spezifiziert.</p>
        <p>er Nutzener Nutzen</p>
        <p>Abbildung 9.2 Messmodell der vier Dimensionen des BDGS (CFM)Abbildung 9.2 Messmodell der vier Dimensionen des BDGS (CFM)</p>
        <p>Um zu prüfen, ob das finale Messmodell auch zu den ursprünglichen nichtimputierten Daten passt, wurde das finale Gesamt-Modell also noch einmal mit dem Ursprungsdatensatz berechnet. Hierbei kommt bei der Parameterschätzung die Full-Information-Maximum-Likelihood-Schätzung (FIML) zum Einsatz, für die in Amos die Funktion ‚Estimate Means and Intercepts' ausgewählt werden muss, die Durchschnittswerte und Achsenabschnitte der Variablen im Modell berechnet. Dabei wurde für jede Dimension eines der drei jeweiligen Items als Referenzindikator festgelegt (siehe Tabelle 9.2), d. h., dass dessen Regressionsgewicht auf den Wert 1 restringiert wurde. Diese Referenzindikatoren werden auch in den weiteren Erhebungen beibehalten. Zudem wurden die Mittelwerte der latenten Konstrukte jeweils auf den Wert null restringiert. Um in den späteren Abschnitten im Rahmen der Hypothesenprüfung zu testen, ob sich bspw. die Werte der Achsenabschnitte signifikant vom Skalenmittelpunkt unterscheiden, wurde an den entsprechenden Stellen zusätzlich ein Bootstrapping in AMOS für ‚Bias-corrected confidence intervals' nach Efron (1987) mit insgesamt 500 Stichproben durchgeführt. Dieses Bootstrapping-Verfahren wird auch in allen nachfolgenden Analysen entsprechend angewandt.Um zu prüfen, ob das finale Messmodell auch zu den ursprünglichen nichtimputierten Daten passt, wurde das finale Gesamt-Modell also noch einmal mit dem Ursprungsdatensatz berechnet. Hierbei kommt bei der Parameterschätzung die Full-Information-Maximum-Likelihood-Schätzung (FIML) zum Einsatz, für die in Amos die Funktion ‚Estimate Means and Intercepts' ausgewählt werden muss, die Durchschnittswerte und Achsenabschnitte der Variablen im Modell berechnet. Dabei wurde für jede Dimension eines der drei jeweiligen Items als Referenzindikator festgelegt (siehe Tabelle 9.2), d. h., dass dessen Regressionsgewicht auf den Wert 1 restringiert wurde. Diese Referenzindikatoren werden auch in den weiteren Erhebungen beibehalten. Zudem wurden die Mittelwerte der latenten Konstrukte jeweils auf den Wert null restringiert. Um in den späteren Abschnitten im Rahmen der Hypothesenprüfung zu testen, ob sich bspw. die Werte der Achsenabschnitte signifikant vom Skalenmittelpunkt unterscheiden, wurde an den entsprechenden Stellen zusätzlich ein Bootstrapping in AMOS für ‚Bias-corrected confidence intervals' nach Efron (1987) mit insgesamt 500 Stichproben durchgeführt. Dieses Bootstrapping-Verfahren wird auch in allen nachfolgenden Analysen entsprechend angewandt.</p>
        <p>In Tabelle 9.2 finden sich nun die Itemformulierungen und Kennwerte der einzelnen Items der Dimensionsindikatoren sowie Kennwerte für die gesamte Dimension. Zudem sind dort die Variablennamen aus dem Originaldatensatz zu finden, so wie diese noch in der Tabelle 2.C im Anhang im elektronischen Zusatzmaterial vermerkt waren. Diese Variablennamen werden ab hier in eine standardisierte, oben bei den Items sowie im Anhang im elektronischen Zusatzmaterial erwähnte Indikatorbenennung geändert, so dass ab hier eine durchgängig konsistente Bezeichnung der einzelnen Indikatoren verwendet wird. Es ist somit an jeder Stelle in den nachfolgenden Ausführungen zu den Datenauswertungen der einzelnen Erhebungen deutlich, über welchen Indikator gesprochen wird. Die CFA für dieses Modell kommt zu einer plausiblen Lösung und zeigt eine hohe Anpassungsgüte (X 2 (48) = 39.138, p = .815; RMSEA = .000 [.000, .026]; TLI = 1.007). Die Regressionskonstanten der einzelnen Indikatoren indizieren für die Dimensionen Genauigkeit sowie individueller und gesellschaftlicher Nutzen Werte nahe dem Skalenmittelpunkt. Dies ist so zu interpretieren, dass bei einer durchschnittlichen Ausprägung des latenten Faktors bei einem Befragten der Skalenmittelpunkt des entsprechenden Frageitems gewählt wird. Die Regressionskonstanten sind daher wie die Mittelwerte einer Stichprobe zu interpretieren, wobei es sich aufgrund der ML-Schätzung und der fehlenden Werte für manche Befragten nicht um einen beobachteten Mittelwert handelt, sondern eine durch FIML geschätzte Konstante der Regressionsgleichung. Für die Indikatoren der Dimension Wissensgewinn werden nun höhere Regressionskonstanten beobachtet, wenn der Mittelwert des latenten Faktors auf null restringiert wird. Im Durchschnitt liegen die Befragten einen halben bis fast einen ganzen Skalenpunkt von der Skalenmitte entfernt, was eine hohe Zustimmung zu den jeweiligen Frageitems signalisiert. In Tabelle 9.3 finden sich darüber hinaus die Angaben zu den Korrelationen der latenten Faktoren, die allesamt hoch miteinander korrelieren. Mit drei Indikatoren pro latentem Faktor ist zudem eine ausreichende Anzahl an Indikatoren gegeben, ohne dass die Erhebung des BDGS mit einer zwölf Items zählenden Itembatterie unnötig lang geraten ist.In Tabelle 9.2 finden sich nun die Itemformulierungen und Kennwerte der einzelnen Items der Dimensionsindikatoren sowie Kennwerte für die gesamte Dimension. Zudem sind dort die Variablennamen aus dem Originaldatensatz zu finden, so wie diese noch in der Tabelle 2.C im Anhang im elektronischen Zusatzmaterial vermerkt waren. Diese Variablennamen werden ab hier in eine standardisierte, oben bei den Items sowie im Anhang im elektronischen Zusatzmaterial erwähnte Indikatorbenennung geändert, so dass ab hier eine durchgängig konsistente Bezeichnung der einzelnen Indikatoren verwendet wird. Es ist somit an jeder Stelle in den nachfolgenden Ausführungen zu den Datenauswertungen der einzelnen Erhebungen deutlich, über welchen Indikator gesprochen wird. Die CFA für dieses Modell kommt zu einer plausiblen Lösung und zeigt eine hohe Anpassungsgüte (X 2 (48) = 39.138, p = .815; RMSEA = .000 [.000, .026]; TLI = 1.007). Die Regressionskonstanten der einzelnen Indikatoren indizieren für die Dimensionen Genauigkeit sowie individueller und gesellschaftlicher Nutzen Werte nahe dem Skalenmittelpunkt. Dies ist so zu interpretieren, dass bei einer durchschnittlichen Ausprägung des latenten Faktors bei einem Befragten der Skalenmittelpunkt des entsprechenden Frageitems gewählt wird. Die Regressionskonstanten sind daher wie die Mittelwerte einer Stichprobe zu interpretieren, wobei es sich aufgrund der ML-Schätzung und der fehlenden Werte für manche Befragten nicht um einen beobachteten Mittelwert handelt, sondern eine durch FIML geschätzte Konstante der Regressionsgleichung. Für die Indikatoren der Dimension Wissensgewinn werden nun höhere Regressionskonstanten beobachtet, wenn der Mittelwert des latenten Faktors auf null restringiert wird. Im Durchschnitt liegen die Befragten einen halben bis fast einen ganzen Skalenpunkt von der Skalenmitte entfernt, was eine hohe Zustimmung zu den jeweiligen Frageitems signalisiert. In Tabelle 9.3 finden sich darüber hinaus die Angaben zu den Korrelationen der latenten Faktoren, die allesamt hoch miteinander korrelieren. Mit drei Indikatoren pro latentem Faktor ist zudem eine ausreichende Anzahl an Indikatoren gegeben, ohne dass die Erhebung des BDGS mit einer zwölf Items zählenden Itembatterie unnötig lang geraten ist.</p>
        <p>Die Annahme eines SFM wurde zuvor an den entsprechenden Stellen in einem ersten Schritt geprüft und alle Modelle zeigen eine entsprechend schlechtere Anpassungsgüte, so dass die Annahme verworfen wurde. Beim finalen BDGS-Modell handelt es sich daher zunächst um ein CFM, bei dem davon ausgegangen wird, dass es sich um eigenständige voneinander trennbare Dimensionen handelt, die hoch miteinander korrelieren, jedoch konzeptuell und datenanalytisch voneinander trennbar sind. Um zu prüfen, inwieweit diese Annahme haltbar ist, empfehlen sich zwei weitere Prüfschritte. Zunächst sollte das CFM einem Second-Order-Factor-Modell (SOFM) gegenübergestellt werden, bei dem ein Faktor zweiter Ordnung auf die vier Dimensionen lädt. In einem weiteren Schritt erlaubt die Spezifikation eines SOFM laut Gignac und Kretzschmar (2017) auch bei Annahme des CFM dann, ob die Annahme der DV haltbar ist. Diese erlaubt eine spezifische Interpretation der einzelnen Dimensionen innerhalb des BDGS und geht somit über die Prüfung der Diskriminanzvalidität zweier hoch korrelierter latenter Faktoren hinaus. Letztere fragt danach, ob man zwischen zwei Dimensionen unterscheiden kann. Die DV nimmt das Gesamtmodell aller latenten Faktoren in den Blick und untersucht die Plausibilität der Annahme separierbarer Dimensionen im Gesamtmodell. Die Analyse einzelner Dimensionen wird bspw. relevant, wenn sie als eigenständige Erklärungsvariablen in der Forschung eingesetzt werden oder wenn man zwischen Befragten mit Blick auf die einzelnen Dimensionen differenzieren möchte, ohne auf die Ausprägung des Gesamtmodells Bezug nehmen zu müssen.Die Annahme eines SFM wurde zuvor an den entsprechenden Stellen in einem ersten Schritt geprüft und alle Modelle zeigen eine entsprechend schlechtere Anpassungsgüte, so dass die Annahme verworfen wurde. Beim finalen BDGS-Modell handelt es sich daher zunächst um ein CFM, bei dem davon ausgegangen wird, dass es sich um eigenständige voneinander trennbare Dimensionen handelt, die hoch miteinander korrelieren, jedoch konzeptuell und datenanalytisch voneinander trennbar sind. Um zu prüfen, inwieweit diese Annahme haltbar ist, empfehlen sich zwei weitere Prüfschritte. Zunächst sollte das CFM einem Second-Order-Factor-Modell (SOFM) gegenübergestellt werden, bei dem ein Faktor zweiter Ordnung auf die vier Dimensionen lädt. In einem weiteren Schritt erlaubt die Spezifikation eines SOFM laut Gignac und Kretzschmar (2017) auch bei Annahme des CFM dann, ob die Annahme der DV haltbar ist. Diese erlaubt eine spezifische Interpretation der einzelnen Dimensionen innerhalb des BDGS und geht somit über die Prüfung der Diskriminanzvalidität zweier hoch korrelierter latenter Faktoren hinaus. Letztere fragt danach, ob man zwischen zwei Dimensionen unterscheiden kann. Die DV nimmt das Gesamtmodell aller latenten Faktoren in den Blick und untersucht die Plausibilität der Annahme separierbarer Dimensionen im Gesamtmodell. Die Analyse einzelner Dimensionen wird bspw. relevant, wenn sie als eigenständige Erklärungsvariablen in der Forschung eingesetzt werden oder wenn man zwischen Befragten mit Blick auf die einzelnen Dimensionen differenzieren möchte, ohne auf die Ausprägung des Gesamtmodells Bezug nehmen zu müssen.</p>
        <p>Die Prüfung auf DV erfolgt also in einem ersten Schritt über den Vergleich mit einem SOFM, bei der die einzelnen latenten Faktoren im Gesamtmodell auf einen einzelnen Faktor zweiter Ordnung laden. Um die Stärke der einzelnen latenten Faktoren zu ermitteln, wird deren Varianz im SOFM auf Signifikanz getestet, selbst wenn dieses Modell eine schlechtere Anpassungsgüte zeigt als das CFM 12 .Die Prüfung auf DV erfolgt also in einem ersten Schritt über den Vergleich mit einem SOFM, bei der die einzelnen latenten Faktoren im Gesamtmodell auf einen einzelnen Faktor zweiter Ordnung laden. Um die Stärke der einzelnen latenten Faktoren zu ermitteln, wird deren Varianz im SOFM auf Signifikanz getestet, selbst wenn dieses Modell eine schlechtere Anpassungsgüte zeigt als das CFM 12 .</p>
        <p>Mit Blick auf die vier Dimensionen des BDGS zeigt das SOFM, bei dem ein Faktor zweiter Ordnung auf die vier latenten Faktoren Wahrhaftigkeit, Wissensgewinn 13 , individueller Nutzen sowie gesellschaftlicher Nutzen lädt, eine gute Anpassungsgüte (X 2 (50) = 53.415, p = .344; RMSEA = .016 [.000, .045]; TLI = .997). Im Vergleich der nicht-hierarchischen Modelle zeigt das SOFM jedoch 12 Gignac und Kretzschmar (2017) schlagen weitergehend einen Test mittels des Koeffizienten Omega hierarchical subscale' (OmegaHS) vor, der das Verhältnis von Faktorvarianz zur Gesamtvarianz ermittelt und standardisiert, so dass Vergleiche zwischen latenten Faktoren möglich sind. Diese weitergehende Betrachtung der spezifischen Faktorvarianz wird nachfolgend nicht ermittelt, da lediglich die dimensionale Verschiedenheit geprüft werden soll. 13 Die unstandardisierte Faktorladung des Faktors zweiter Ordnung auf den Faktor Wissensgewinn wurde auf 1 restringiert, wodurch diese Dimension als Referenzindikator festgelegt wird. Dies wird für alle nachfolgenden Modelle zur Prüfung der DV beibehalten. Angaben zur Modellgüte des SOFM werden nachfolgend nicht mehr gemacht, da dem CFM konzeptuell und datenanalytisch an dieser Stelle der Vorzug gegeben wird. Das SOFM wird lediglich zur Analyse der DV herangezogen. einen höheren AIC-Wert 14 ( AIC = 10.277), weshalb dem CFM nicht nur auf Grundlage der definitorisch abgeleiteten mehrdimensionalen Konzeption, sondern auch aus empirischer Sicht der Vorzug zu geben ist. An dieser Stelle richtet sich der Blick jedoch auf die Varianz der einzelnen Dimensionen des BDGS, die hier als latente Faktoren erster Ordnung vorliegen. Es zeigen sich signifikante Varianzen der Faktoren Genauigkeit (σ 2 Genauigkeit = .268, S.E. = .065, p &lt; .001), Wissensgewinn (σ 2 Wissensgewinn = .360, S.E. = .068, p &lt; .001) und individueller Nutzen (σ 2Mit Blick auf die vier Dimensionen des BDGS zeigt das SOFM, bei dem ein Faktor zweiter Ordnung auf die vier latenten Faktoren Wahrhaftigkeit, Wissensgewinn 13 , individueller Nutzen sowie gesellschaftlicher Nutzen lädt, eine gute Anpassungsgüte (X 2 (50) = 53.415, p = .344; RMSEA = .016 [.000, .045]; TLI = .997). Im Vergleich der nicht-hierarchischen Modelle zeigt das SOFM jedoch 12 Gignac und Kretzschmar (2017) schlagen weitergehend einen Test mittels des Koeffizienten Omega hierarchical subscale' (OmegaHS) vor, der das Verhältnis von Faktorvarianz zur Gesamtvarianz ermittelt und standardisiert, so dass Vergleiche zwischen latenten Faktoren möglich sind. Diese weitergehende Betrachtung der spezifischen Faktorvarianz wird nachfolgend nicht ermittelt, da lediglich die dimensionale Verschiedenheit geprüft werden soll. 13 Die unstandardisierte Faktorladung des Faktors zweiter Ordnung auf den Faktor Wissensgewinn wurde auf 1 restringiert, wodurch diese Dimension als Referenzindikator festgelegt wird. Dies wird für alle nachfolgenden Modelle zur Prüfung der DV beibehalten. Angaben zur Modellgüte des SOFM werden nachfolgend nicht mehr gemacht, da dem CFM konzeptuell und datenanalytisch an dieser Stelle der Vorzug gegeben wird. Das SOFM wird lediglich zur Analyse der DV herangezogen. einen höheren AIC-Wert 14 ( AIC = 10.277), weshalb dem CFM nicht nur auf Grundlage der definitorisch abgeleiteten mehrdimensionalen Konzeption, sondern auch aus empirischer Sicht der Vorzug zu geben ist. An dieser Stelle richtet sich der Blick jedoch auf die Varianz der einzelnen Dimensionen des BDGS, die hier als latente Faktoren erster Ordnung vorliegen. Es zeigen sich signifikante Varianzen der Faktoren Genauigkeit (σ 2 Genauigkeit = .268, S.E. = .065, p &lt; .001), Wissensgewinn (σ 2 Wissensgewinn = .360, S.E. = .068, p &lt; .001) und individueller Nutzen (σ 2</p>
        <p>Ind. Nutzen = .311, S.E. = .069, p &lt; .001), jedoch nicht für den Faktor gesellschaftlicher Nutzen (σ 2Ind. Nutzen = .311, S.E. = .069, p &lt; .001), jedoch nicht für den Faktor gesellschaftlicher Nutzen (σ 2</p>
        <p>Ges. Nutzen = .023, S.E. = .041, p = .577). Für letztere Dimension kann die DV im vorliegenden Sample nicht angenommen werden. Das bedeutet, dass die Bewertung des gesellschaftlichen Nutzens sich nicht ausreichend von den drei anderen Dimensionen unterscheidet. Allerdings weisen Simulationen von Sinharay (2010) darauf hin, dass bei hoch ausgeprägten allgemeinen Faktoren (hier der Faktor zweiter Ordnung) bis zu zehn Indikatorvariablen notwendig sind, um die Signifikanz eines spezifischen Faktors erster Ordnung festzustellen. Mit Blick auf die gebotene Kürze der BDGS-Skala ist von dieser Erweiterung der Indikatoren jedoch im vorliegenden Fall aus forschungsökonomischen Gründen abzusehen. Die Prüfung der DV wird nachfolgend an der entsprechenden Stelle für die Erhebung 1.2 und Erhebung 1.3 wiederholt.Ges. Nutzen = .023, S.E. = .041, p = .577). Für letztere Dimension kann die DV im vorliegenden Sample nicht angenommen werden. Das bedeutet, dass die Bewertung des gesellschaftlichen Nutzens sich nicht ausreichend von den drei anderen Dimensionen unterscheidet. Allerdings weisen Simulationen von Sinharay (2010) darauf hin, dass bei hoch ausgeprägten allgemeinen Faktoren (hier der Faktor zweiter Ordnung) bis zu zehn Indikatorvariablen notwendig sind, um die Signifikanz eines spezifischen Faktors erster Ordnung festzustellen. Mit Blick auf die gebotene Kürze der BDGS-Skala ist von dieser Erweiterung der Indikatoren jedoch im vorliegenden Fall aus forschungsökonomischen Gründen abzusehen. Die Prüfung der DV wird nachfolgend an der entsprechenden Stelle für die Erhebung 1.2 und Erhebung 1.3 wiederholt.</p>
        <p>Es ist nun im Rahmen der Validität der Messung des BDGS zu prüfen, inwieweit die vier Dimensionen der BDGS-Skala mit der Bewertungsdimension Volumen zusammenhängen. Dies wird auch als kriteriumsbezogene Validität bezeichnet (Bandalos, 2017). Die im Anhang 1 im elektronischen Zusatzmaterial dokumentierte Messung zur Bewertung des Ausmaßes zielte darauf ab, zu erheben, inwiefern die Befragten eine weitreichende Datensammlung und -auswertung begrüßen. Zum latenten Faktor gehören hierbei die folgenden vier Indikatoritems: Bewertung Volumen (α = .905; DEV = .703)Es ist nun im Rahmen der Validität der Messung des BDGS zu prüfen, inwieweit die vier Dimensionen der BDGS-Skala mit der Bewertungsdimension Volumen zusammenhängen. Dies wird auch als kriteriumsbezogene Validität bezeichnet (Bandalos, 2017). Die im Anhang 1 im elektronischen Zusatzmaterial dokumentierte Messung zur Bewertung des Ausmaßes zielte darauf ab, zu erheben, inwiefern die Befragten eine weitreichende Datensammlung und -auswertung begrüßen. Zum latenten Faktor gehören hierbei die folgenden vier Indikatoritems: Bewertung Volumen (α = .905; DEV = .703)</p>
        <p>• Es ist gut, dass immer mehr digitale Daten ausgewertet werden. (λ = .768, Referenzindikator)• Es ist gut, dass immer mehr digitale Daten ausgewertet werden. (λ = .768, Referenzindikator)</p>
        <p>14 Zum AIC-Wert äußert Kline (2011): "The AlC and related indexes are generally used in SEM to select among competing nonhierarchical models estimated with the same data. Specifically, the model with the smallest AlC value is chosen as the one most likely to replicate" (Kline, 2011, S. 220).14 Zum AIC-Wert äußert Kline (2011): "The AlC and related indexes are generally used in SEM to select among competing nonhierarchical models estimated with the same data. Specifically, the model with the smallest AlC value is chosen as the one most likely to replicate" (Kline, 2011, S. 220).</p>
        <p>• Je stärker zugestimmt wird, dass Daten ein genaues und objektives Verständnis der Welt ermöglichen, dass aus ihnen Wissen gewonnen und Nutzen gezogen wird, desto positiver wird eine umfangreiche Datenspeicherung und -auswertung bewertet. Dies spricht für die erwartete positive Valenz der Sichtweise auf die digitalen Daten im Rahmen des besprochenen Glaubenssystems und somit auch für die Validität der Messung des BDGS.• Je stärker zugestimmt wird, dass Daten ein genaues und objektives Verständnis der Welt ermöglichen, dass aus ihnen Wissen gewonnen und Nutzen gezogen wird, desto positiver wird eine umfangreiche Datenspeicherung und -auswertung bewertet. Dies spricht für die erwartete positive Valenz der Sichtweise auf die digitalen Daten im Rahmen des besprochenen Glaubenssystems und somit auch für die Validität der Messung des BDGS.</p>
        <p>Als erste Erkenntnis vorweg und es ist dabei nicht banal das festzustellen: Die befragten Personen haben sich in der überwiegenden Mehrheit zugetraut, die ihnen gestellten Fragen unabhängig der Dimensionszugehörigkeit der einzelnen Items zu beantworten, auch wenn die Möglichkeit bestand, die Ausweichkategorie "Kann ich nicht beantworten" auszuwählen. Dies wurde mit Blick auf die in Abschnitt 9.1.3 besprochenen Resultate dort jedoch nur von höchstens 6,3 % der Befragten bei Item GE3 ("Digitale Daten ermöglichen ein objektives Verständnis der Wirklichkeit") auch gewählt und lag unter diesem Wert für die anderen erfragten Items. Das ist zwar keine vernachlässigbar geringe Anzahl an Personen, die in der Befragungssituation ein generelles oder zumindest partielles Nicht-Wissen angegeben haben. Man könnte jedoch genauso gut erwarten, dass sich eine noch höhere Anzahl an Personen keine Beantwortung der Fragen zutraut. Basierend auf dem Digitalindex 2018/2019 von Initiative D21 e. V. (2019) lässt sich die deutsche Bevölkerung in ‚Digitale Vorreiter' (37 %), ‚Digital Mithaltende' (42 %) und ‚Digital Abseitsstehende' (21 %) einteilen. Die Abseitsstehenden zeichnen sich durch einen geringen Zugang, geringe Kompetenz, wenig vielfältiges Nutzungsverhalten und geringe Offenheit gegenüber digitalen Anwendungen aus. Hier ist eine hohe Quote von Non-Responses zu erwarten. Nun kann es sein, dass sich in den jeweiligen Stichproben weniger Personen dieser Gruppe sammeln und andere Subgruppen überrepräsentiert waren. Der Samplequalität und dem Zufall muss an dieser Stelle zumindest Rechnung getragen werden. Doch selbst wenn alle Befragten zu den Mitgliedern der als "Digitale Vorreiter" definierten Gruppe entstammten, dann ist mit Blick auf die derzeitigen Zugangschancen und das Berührungspotential mit dem Phänomen Big Data (siehe Kapitel 3) in den Samples über alle Befragten hinweg ein Ausdruck des Selbstvertrauens in die Beantwortungsfähigkeit der gestellten Fragen zu erkennen, das nicht unerheblich ist.Als erste Erkenntnis vorweg und es ist dabei nicht banal das festzustellen: Die befragten Personen haben sich in der überwiegenden Mehrheit zugetraut, die ihnen gestellten Fragen unabhängig der Dimensionszugehörigkeit der einzelnen Items zu beantworten, auch wenn die Möglichkeit bestand, die Ausweichkategorie "Kann ich nicht beantworten" auszuwählen. Dies wurde mit Blick auf die in Abschnitt 9.1.3 besprochenen Resultate dort jedoch nur von höchstens 6,3 % der Befragten bei Item GE3 ("Digitale Daten ermöglichen ein objektives Verständnis der Wirklichkeit") auch gewählt und lag unter diesem Wert für die anderen erfragten Items. Das ist zwar keine vernachlässigbar geringe Anzahl an Personen, die in der Befragungssituation ein generelles oder zumindest partielles Nicht-Wissen angegeben haben. Man könnte jedoch genauso gut erwarten, dass sich eine noch höhere Anzahl an Personen keine Beantwortung der Fragen zutraut. Basierend auf dem Digitalindex 2018/2019 von Initiative D21 e. V. (2019) lässt sich die deutsche Bevölkerung in ‚Digitale Vorreiter' (37 %), ‚Digital Mithaltende' (42 %) und ‚Digital Abseitsstehende' (21 %) einteilen. Die Abseitsstehenden zeichnen sich durch einen geringen Zugang, geringe Kompetenz, wenig vielfältiges Nutzungsverhalten und geringe Offenheit gegenüber digitalen Anwendungen aus. Hier ist eine hohe Quote von Non-Responses zu erwarten. Nun kann es sein, dass sich in den jeweiligen Stichproben weniger Personen dieser Gruppe sammeln und andere Subgruppen überrepräsentiert waren. Der Samplequalität und dem Zufall muss an dieser Stelle zumindest Rechnung getragen werden. Doch selbst wenn alle Befragten zu den Mitgliedern der als "Digitale Vorreiter" definierten Gruppe entstammten, dann ist mit Blick auf die derzeitigen Zugangschancen und das Berührungspotential mit dem Phänomen Big Data (siehe Kapitel 3) in den Samples über alle Befragten hinweg ein Ausdruck des Selbstvertrauens in die Beantwortungsfähigkeit der gestellten Fragen zu erkennen, das nicht unerheblich ist.</p>
        <p>Mit Blick auf die Verteilungswerte der Indikatoren der vier Dimensionen zeigt sich, dass eine variable Einschätzung bezüglich der Genauigkeit digitaler Daten sowie des hieraus gezogenen individuellen und gesellschaftlichen Nutzens besteht. Die Befragten haben hier im Mittel eine abwägende Wahrnehmung, die durchaus eine kritische Sicht auf die vermeintliche Genauigkeit und Objektivität der Daten und hieraus gezogene Nutzengewinne offenbart, da diesen Eigenschaften der Daten nicht automatisch zugestimmt wird. Geht es jedoch um den Wissensgewinn, so wird den jeweiligen Glaubenssätzen im Aggregat zugestimmt, die Überzeugungen von aus den digitalen Daten gewonnener Erkenntnis formulieren.Mit Blick auf die Verteilungswerte der Indikatoren der vier Dimensionen zeigt sich, dass eine variable Einschätzung bezüglich der Genauigkeit digitaler Daten sowie des hieraus gezogenen individuellen und gesellschaftlichen Nutzens besteht. Die Befragten haben hier im Mittel eine abwägende Wahrnehmung, die durchaus eine kritische Sicht auf die vermeintliche Genauigkeit und Objektivität der Daten und hieraus gezogene Nutzengewinne offenbart, da diesen Eigenschaften der Daten nicht automatisch zugestimmt wird. Geht es jedoch um den Wissensgewinn, so wird den jeweiligen Glaubenssätzen im Aggregat zugestimmt, die Überzeugungen von aus den digitalen Daten gewonnener Erkenntnis formulieren.</p>
        <p>Neben der erneuten Validierung der Modellstruktur wurde die dritte Erhebung zur Skalenkonstruktion dazu genutzt, den Einfluss der Präsentationsweise der BDGS-Skala auf die diskriminante Validität zu untersuchen. Die Ergebnisse der Erhebung 1.1 indizieren, dass es aufgrund der hohen Inter-Korrelation der latenten Faktoren im CFA-Modell mitunter fraglich ist, ob überhaupt von diskriminanter Validität ausgegangen werden kann. Ein Grund für die hohen Korrelationswerte könnte darin liegen, dass die Präsentationsweise der BDGS-Skala mit den zwölf Frageitems auf einer Seite zu sogenannten Reihenfolgeeffekten auf Seiten der Befragten führt (Scholl, 2018). Es wäre bspw. ein Konsistenzeffekt zu beobachten, wenn die Beantwortung der ersten präsentierten Frage einen Einfluss auf die Beantwortung der nachfolgenden Frageitems hat. Es käme womöglich zu einem Auseinanderfallen der vom Befragten erwarteten oder ‚geratenen' Dimensionierung und der konzeptuellen sowie mutmaßlich empirischen Dimensionierung. Aufgrund der Rotation der Fragebogenitems auf der Seite befand sich zwar immer eine andere der insgesamt zwölf Aussagen am Anfang der jeweiligen Skala, es könnten jedoch auch der Gesamteindruck der Skala und die von den Befragten erwartete Zusammengehörigkeit der Items zu einem allgemeinen Test einen kognitiven Befragungseffekt auslösen. Die Befragten würden dann erwarten, dass die Items -unabhängig von der konkreten Formulierung -alle in eine bestimmte Richtung abzielen, so dass man auch alle Items ähnlich beantworten müsse. Scholl (2018) merkt hierzu Folgendes an:Neben der erneuten Validierung der Modellstruktur wurde die dritte Erhebung zur Skalenkonstruktion dazu genutzt, den Einfluss der Präsentationsweise der BDGS-Skala auf die diskriminante Validität zu untersuchen. Die Ergebnisse der Erhebung 1.1 indizieren, dass es aufgrund der hohen Inter-Korrelation der latenten Faktoren im CFA-Modell mitunter fraglich ist, ob überhaupt von diskriminanter Validität ausgegangen werden kann. Ein Grund für die hohen Korrelationswerte könnte darin liegen, dass die Präsentationsweise der BDGS-Skala mit den zwölf Frageitems auf einer Seite zu sogenannten Reihenfolgeeffekten auf Seiten der Befragten führt (Scholl, 2018). Es wäre bspw. ein Konsistenzeffekt zu beobachten, wenn die Beantwortung der ersten präsentierten Frage einen Einfluss auf die Beantwortung der nachfolgenden Frageitems hat. Es käme womöglich zu einem Auseinanderfallen der vom Befragten erwarteten oder ‚geratenen' Dimensionierung und der konzeptuellen sowie mutmaßlich empirischen Dimensionierung. Aufgrund der Rotation der Fragebogenitems auf der Seite befand sich zwar immer eine andere der insgesamt zwölf Aussagen am Anfang der jeweiligen Skala, es könnten jedoch auch der Gesamteindruck der Skala und die von den Befragten erwartete Zusammengehörigkeit der Items zu einem allgemeinen Test einen kognitiven Befragungseffekt auslösen. Die Befragten würden dann erwarten, dass die Items -unabhängig von der konkreten Formulierung -alle in eine bestimmte Richtung abzielen, so dass man auch alle Items ähnlich beantworten müsse. Scholl (2018) merkt hierzu Folgendes an:</p>
        <p>Zu vermeiden sind solche Kontexteffekte nicht, es sei denn, man verzichtet darauf, mehrere Fragen zum gleichen Thema zu stellen. Eine andere Möglichkeit besteht darin, die Fragen zu trennen und an unterschiedlichen Stellen im Fragebogen abzufragen. Allerdings gefährdet diese Maßnahme die Stringenz der Befragung. Außerdem ist ihre Wirkung zweifelhaft, weil das Gedächtnis des Befragten durch die Folgefrage(n) reaktiviert wird. Wenn bekannt ist, wie Kontexteffekte funktionieren, kann man sie je nach Forschungsziel nutzen. (S. 217) Um erste Erkenntnisse über eben jene Kontexteffekte auf die Beantwortung der BDGS-Skala zu gewinnen und zu prüfen, inwieweit die Präsentation der BDGS-Skala einen Einfluss auf die diskriminante Validität hat, wurde die Skala im vorliegenden Fragebogen aufgeteilt: Die Frageitems der Dimensionen Genauigkeit und Wissensgewinn fanden sich auf einer gemeinsamen Seite und die der Dimensionen zum individuellen und gesellschaftlichen Nutzen nach ein paar dazwischengeschobenen Fragenblöcken ein paar Seiten später gemeinsam auf einer Seite. Auch wenn die beiden Nutzendimensionen hoch miteinander korrelieren, wurde davon abgesehen, gerade die thematisch ähnlichen Dimensionen auf unterschiedliche Seiten aufzuteilen. Grund hierfür war, Irritationen auf Seiten der Befragten zu vermeiden, die durch mögliche mangelnde Unterscheidungsfähigkeit von auf mehreren Seiten aufgeteilten Fragen zum epistemischen Charakter der Daten und dem hieraus gezogenen Nutzen hervorgerufen werden könnte. Eine direkte Kontrastierung erschien bei diesen Dimensionen geboten.Zu vermeiden sind solche Kontexteffekte nicht, es sei denn, man verzichtet darauf, mehrere Fragen zum gleichen Thema zu stellen. Eine andere Möglichkeit besteht darin, die Fragen zu trennen und an unterschiedlichen Stellen im Fragebogen abzufragen. Allerdings gefährdet diese Maßnahme die Stringenz der Befragung. Außerdem ist ihre Wirkung zweifelhaft, weil das Gedächtnis des Befragten durch die Folgefrage(n) reaktiviert wird. Wenn bekannt ist, wie Kontexteffekte funktionieren, kann man sie je nach Forschungsziel nutzen. (S. 217) Um erste Erkenntnisse über eben jene Kontexteffekte auf die Beantwortung der BDGS-Skala zu gewinnen und zu prüfen, inwieweit die Präsentation der BDGS-Skala einen Einfluss auf die diskriminante Validität hat, wurde die Skala im vorliegenden Fragebogen aufgeteilt: Die Frageitems der Dimensionen Genauigkeit und Wissensgewinn fanden sich auf einer gemeinsamen Seite und die der Dimensionen zum individuellen und gesellschaftlichen Nutzen nach ein paar dazwischengeschobenen Fragenblöcken ein paar Seiten später gemeinsam auf einer Seite. Auch wenn die beiden Nutzendimensionen hoch miteinander korrelieren, wurde davon abgesehen, gerade die thematisch ähnlichen Dimensionen auf unterschiedliche Seiten aufzuteilen. Grund hierfür war, Irritationen auf Seiten der Befragten zu vermeiden, die durch mögliche mangelnde Unterscheidungsfähigkeit von auf mehreren Seiten aufgeteilten Fragen zum epistemischen Charakter der Daten und dem hieraus gezogenen Nutzen hervorgerufen werden könnte. Eine direkte Kontrastierung erschien bei diesen Dimensionen geboten.</p>
        <p>Erhebung 1.2 Feldphase, Sample und Fragebogenaufbau Die Feldphase der Befragung in Erhebung 1.2 lief vom 5. bis zum 13. Dezember 2017. Die Rekrutierung der Befragten erfolgte erneut durch die Respondi AG, die hierzu auf ihr Online-Access-Panel zugriff. Die Teilnehmer*innen der Untersuchung, die durch eine Vergütung für ihre Teilnahme incentiviert wurden, wurden nach Geschlecht, Alter (ab 14 Jahre) und Bildungsniveau quotiert auf Grundlage der aktuellen Zusammensetzung der deutschen Bevölkerung mit Onlinezugang, womit das Sample repräsentativ für diese Population ist (Arbeitsgemeinschaft Online Forschung -agof, 2017). Es wurden 9266 Personen aus dem Panel eingeladen. Insgesamt wurde der Fragebogen 1921-mal aufgerufen. Mit der Beantwortung begannen 1807 Befragte, wovon wiederum 1320 Befragte den Fragebogen beendeten und die letzte Fragebogenseite erreichten. Die Antwortrate lag somit bei 14,2 %.Erhebung 1.2 Feldphase, Sample und Fragebogenaufbau Die Feldphase der Befragung in Erhebung 1.2 lief vom 5. bis zum 13. Dezember 2017. Die Rekrutierung der Befragten erfolgte erneut durch die Respondi AG, die hierzu auf ihr Online-Access-Panel zugriff. Die Teilnehmer*innen der Untersuchung, die durch eine Vergütung für ihre Teilnahme incentiviert wurden, wurden nach Geschlecht, Alter (ab 14 Jahre) und Bildungsniveau quotiert auf Grundlage der aktuellen Zusammensetzung der deutschen Bevölkerung mit Onlinezugang, womit das Sample repräsentativ für diese Population ist (Arbeitsgemeinschaft Online Forschung -agof, 2017). Es wurden 9266 Personen aus dem Panel eingeladen. Insgesamt wurde der Fragebogen 1921-mal aufgerufen. Mit der Beantwortung begannen 1807 Befragte, wovon wiederum 1320 Befragte den Fragebogen beendeten und die letzte Fragebogenseite erreichten. Die Antwortrate lag somit bei 14,2 %.</p>
        <p>Insgesamt wurden also n = 1320 Personen befragt, für die vollständig ausgefüllte Fragebögen vorlagen. Im Anschluss an die Datenerhebung wurde der Datensatz bereinigt. Dabei wurden, wie in Abschnitt 9.1.2 dokumentiert, auch hier Befragte von der Auswertung ausgeschlossen, die auffällig schnell durch den Fragebogen geklickt haben. Die Zeit für den Screenout lag hier bei weniger als 7 Minuten und 34 Sekunden; die Zeit, die man nach internen Tests in der Projektgruppe mindestens benötigte, um alle Fragen gewissenhaft zu bearbeiten. Das finale Sample enthält mithin n = 1114 Fälle und setzt sich wie folgt zusammen: Männer und Frauen waren in ungefähr gleichen Anteilen vertreten (50,7 % männlich, 49,3 % weiblich). Im Durchschnitt waren die Befragten 45 Jahre alt (SD = 15,54). Knapp 29,8 % der Untersuchungsteilnehmer*innen wiesen eine niedrige Bildung auf (Volks-oder Hauptschule), 33,7 % eine mittlere Bildung (mittlere Reife) sowie 36,5 % eine hohe Bildung (mindestens Hochschulreife oder Hochschulabschluss). Die Verteilung der drei Teilstichproben war annähernd gleich (E-Commerce: n = 372, 33,4 %; Politische Online-Partizipation: n = 375, 33,7 %; Self-Tracking: n = 367, 32,9 %). 15Die BDGS-Skala fand sich in der Mitte des Fragebogens auf der zwölften von 23 Seiten (siehe Fragebogen im Anhang 3.2 im elektronischen Zusatzmaterial). Die Frageitems der BDGS-Skala wurden rotiert, so dass die Reihenfolge der gezeigten Aussagen jeweils zufällig festgelegt wurde. Die drei untersuchten Kontexte wurden vor der Beantwortung der BDGS-Skala eingeführt und jeweils mit einem eigenen Einleitungstext erklärt. Da es in den drei Kontexten explizit um die Sammlung und Auswertung privater digitaler Daten ging, ist es wahrscheinlich, dass bedingt durch diesen geteilten Fragebogenaufbau jeweils Befragungseffekte bei der Beantwortung der BDGS-Skala zu erwarten sind. Deshalb werden nachfolgend für die Kontexte E-Commerce (nachfolgend Erhebung 1.2a), politische Online-Kommunikation (Erhebung 1.2b) und Self-Tracking (Erhebung 1.2c) die jeweiligen Kennwerte für Indikatoren und Messmodelle gesondert berichtet, jedoch jeweils gemeinsam besprochen.Insgesamt wurden also n = 1320 Personen befragt, für die vollständig ausgefüllte Fragebögen vorlagen. Im Anschluss an die Datenerhebung wurde der Datensatz bereinigt. Dabei wurden, wie in Abschnitt 9.1.2 dokumentiert, auch hier Befragte von der Auswertung ausgeschlossen, die auffällig schnell durch den Fragebogen geklickt haben. Die Zeit für den Screenout lag hier bei weniger als 7 Minuten und 34 Sekunden; die Zeit, die man nach internen Tests in der Projektgruppe mindestens benötigte, um alle Fragen gewissenhaft zu bearbeiten. Das finale Sample enthält mithin n = 1114 Fälle und setzt sich wie folgt zusammen: Männer und Frauen waren in ungefähr gleichen Anteilen vertreten (50,7 % männlich, 49,3 % weiblich). Im Durchschnitt waren die Befragten 45 Jahre alt (SD = 15,54). Knapp 29,8 % der Untersuchungsteilnehmer*innen wiesen eine niedrige Bildung auf (Volks-oder Hauptschule), 33,7 % eine mittlere Bildung (mittlere Reife) sowie 36,5 % eine hohe Bildung (mindestens Hochschulreife oder Hochschulabschluss). Die Verteilung der drei Teilstichproben war annähernd gleich (E-Commerce: n = 372, 33,4 %; Politische Online-Partizipation: n = 375, 33,7 %; Self-Tracking: n = 367, 32,9 %). 15Die BDGS-Skala fand sich in der Mitte des Fragebogens auf der zwölften von 23 Seiten (siehe Fragebogen im Anhang 3.2 im elektronischen Zusatzmaterial). Die Frageitems der BDGS-Skala wurden rotiert, so dass die Reihenfolge der gezeigten Aussagen jeweils zufällig festgelegt wurde. Die drei untersuchten Kontexte wurden vor der Beantwortung der BDGS-Skala eingeführt und jeweils mit einem eigenen Einleitungstext erklärt. Da es in den drei Kontexten explizit um die Sammlung und Auswertung privater digitaler Daten ging, ist es wahrscheinlich, dass bedingt durch diesen geteilten Fragebogenaufbau jeweils Befragungseffekte bei der Beantwortung der BDGS-Skala zu erwarten sind. Deshalb werden nachfolgend für die Kontexte E-Commerce (nachfolgend Erhebung 1.2a), politische Online-Kommunikation (Erhebung 1.2b) und Self-Tracking (Erhebung 1.2c) die jeweiligen Kennwerte für Indikatoren und Messmodelle gesondert berichtet, jedoch jeweils gemeinsam besprochen.</p>
        <p>Der Aufbau und die Formulierungen der BDGS-Skala blieben identisch zu Erhebung 1.1, wobei nur noch 18 Items gezeigt wurden. Dazu zählen die zwölf Items der vier Dimensionen Genauigkeit, Wissensgewinn, individueller Nutzen und gesellschaftlicher Nutzen sowie jeweils drei Items zur Bewertung des Ausmaßes (Volume) und der Geschwindigkeit (Velocity) der Datenspeicherung und -auswertung. Letztere werden in der vorliegenden Arbeit jedoch aus oben genannten Gründen nicht weiter berücksichtigt. Zudem wurde die Ausweichoption "weiß nicht" ab Erhebung 1.2 für alle BDGS-Items gestrichen, so dass nur noch eine Verortung auf der siebenstufigen Beantwortungsskala möglich war.Der Aufbau und die Formulierungen der BDGS-Skala blieben identisch zu Erhebung 1.1, wobei nur noch 18 Items gezeigt wurden. Dazu zählen die zwölf Items der vier Dimensionen Genauigkeit, Wissensgewinn, individueller Nutzen und gesellschaftlicher Nutzen sowie jeweils drei Items zur Bewertung des Ausmaßes (Volume) und der Geschwindigkeit (Velocity) der Datenspeicherung und -auswertung. Letztere werden in der vorliegenden Arbeit jedoch aus oben genannten Gründen nicht weiter berücksichtigt. Zudem wurde die Ausweichoption "weiß nicht" ab Erhebung 1.2 für alle BDGS-Items gestrichen, so dass nur noch eine Verortung auf der siebenstufigen Beantwortungsskala möglich war.</p>
        <p>Die Feldphase der Befragung lief vom 5. bis zum 12. Juni 2018. Die Rekrutierung der Befragten erfolgte auch hier durch die Respondi AG, die hierzu auf ihr Online-Access-Panel zugriff. Die Teilnehmer*innen der Untersuchung, die durch eine Vergütung für ihre Teilnahme incentiviert wurden, wurden zufällig gezogen. Es wurden 2767 Einladungen an das Panel versendet. Insgesamt wurde der Fragebogen 1364-mal aufgerufen. Mit der Beantwortung begannen 1288 Befragte, wovon wiederum 836 Befragte den Fragebogen beendeten und die letzte Fragebogenseite erreichten. Die Antwortrate lag somit bei 30,2 %. Hierbei ist anzumerken, dass kurz vor Ende der Befragung ein Attention-Check eingebaut wurde, der die Befragten aufforderte, bei einem Item in der Fragebatterie einen bestimmten Skalenpunkt anzukreuzen. 209 Personen kreuzten hier falsch und wurden ohne Vergütung zum Panelanbieter zurückgeleitet, da anzunehmen ist, dass sie nicht alle Fragen aufmerksam und gewissenhaft gelesen und bearbeitet haben.Die Feldphase der Befragung lief vom 5. bis zum 12. Juni 2018. Die Rekrutierung der Befragten erfolgte auch hier durch die Respondi AG, die hierzu auf ihr Online-Access-Panel zugriff. Die Teilnehmer*innen der Untersuchung, die durch eine Vergütung für ihre Teilnahme incentiviert wurden, wurden zufällig gezogen. Es wurden 2767 Einladungen an das Panel versendet. Insgesamt wurde der Fragebogen 1364-mal aufgerufen. Mit der Beantwortung begannen 1288 Befragte, wovon wiederum 836 Befragte den Fragebogen beendeten und die letzte Fragebogenseite erreichten. Die Antwortrate lag somit bei 30,2 %. Hierbei ist anzumerken, dass kurz vor Ende der Befragung ein Attention-Check eingebaut wurde, der die Befragten aufforderte, bei einem Item in der Fragebatterie einen bestimmten Skalenpunkt anzukreuzen. 209 Personen kreuzten hier falsch und wurden ohne Vergütung zum Panelanbieter zurückgeleitet, da anzunehmen ist, dass sie nicht alle Fragen aufmerksam und gewissenhaft gelesen und bearbeitet haben.</p>
        <p>Insgesamt wurden also n = 836 Personen befragt, für die vollständig ausgefüllte Fragebögen vorlagen. Im Anschluss an die Datenerhebung wurde der Datensatz bereinigt. Dabei wurden auch hier Befragte von der Auswertung ausgeschlossen, die auffällig schnell durch den Fragebogen geklickt haben. Die Zeit für den Screenout lag hier bei weniger als 2 Minuten und 30 Sekunden, also mindestens zwei Standardabweichungen weniger als die durchschnittliche Beantwortungszeit von 11 Minuten und 27 Sekunden. Dies traf jedoch nur auf einen Fall zu. Zudem wurden Befragte von der Datenanalyse ausgeschlossen, bei denen nicht sichergestellt werden konnte, dass der Fragebogen technisch einwandfrei funktioniert hat (n = 19). Schließlich wurden Befragte ausgeschlossen, die entgegen der ihnen zugewiesenen Experimentalkondition angaben, keine Informationen zum Datenschutz (n = 9) oder zu den ethischen Leitlinien im Umgang mit personensensiblen Daten (n = 3) gesehen zu haben. Das finale Sample enthält mithin n = 784 Fälle und setzt sich wie folgt zusammen: Männer und Frauen waren in etwa gleichen Anteilen vertreten (48,9 % männlich, 51,5 % weiblich). Im Durchschnitt waren die Befragten 47,7 Jahre alt (SD = 14,52). Knapp 13,3 % der Untersuchungsteilnehmer*innen wiesen eine niedrige Bildung auf (Volks-oder Hauptschule), 35,2 % eine mittlere Bildung (mittlere Reife) sowie 51,1 % eine hohe Bildung (mind. Hochschulreife oder Hochschulabschluss). Damit ist das Sample etwas höher gebildet als in Erhebung 1.2.Insgesamt wurden also n = 836 Personen befragt, für die vollständig ausgefüllte Fragebögen vorlagen. Im Anschluss an die Datenerhebung wurde der Datensatz bereinigt. Dabei wurden auch hier Befragte von der Auswertung ausgeschlossen, die auffällig schnell durch den Fragebogen geklickt haben. Die Zeit für den Screenout lag hier bei weniger als 2 Minuten und 30 Sekunden, also mindestens zwei Standardabweichungen weniger als die durchschnittliche Beantwortungszeit von 11 Minuten und 27 Sekunden. Dies traf jedoch nur auf einen Fall zu. Zudem wurden Befragte von der Datenanalyse ausgeschlossen, bei denen nicht sichergestellt werden konnte, dass der Fragebogen technisch einwandfrei funktioniert hat (n = 19). Schließlich wurden Befragte ausgeschlossen, die entgegen der ihnen zugewiesenen Experimentalkondition angaben, keine Informationen zum Datenschutz (n = 9) oder zu den ethischen Leitlinien im Umgang mit personensensiblen Daten (n = 3) gesehen zu haben. Das finale Sample enthält mithin n = 784 Fälle und setzt sich wie folgt zusammen: Männer und Frauen waren in etwa gleichen Anteilen vertreten (48,9 % männlich, 51,5 % weiblich). Im Durchschnitt waren die Befragten 47,7 Jahre alt (SD = 14,52). Knapp 13,3 % der Untersuchungsteilnehmer*innen wiesen eine niedrige Bildung auf (Volks-oder Hauptschule), 35,2 % eine mittlere Bildung (mittlere Reife) sowie 51,1 % eine hohe Bildung (mind. Hochschulreife oder Hochschulabschluss). Damit ist das Sample etwas höher gebildet als in Erhebung 1.2.</p>
        <p>Die Frageitems der BDGS-Skala fanden sich mit Genauigkeit und Wissensgewinn auf Seite 3 und individueller und gesellschaftlicher Nutzen auf Seite 7 (siehe Fragebogen im Anhang 3.3 im elektronischen Zusatzmaterial). Auf den drei Seiten dazwischen fanden sich Fragen zu informationellen Privatheitsbedenken bei der Internetnutzung, der Intensität der Online-und Smartphone-Nutzung sowie der Intensität der Nutzung von Medienberichterstattung über die Digitalisierung.Die Frageitems der BDGS-Skala fanden sich mit Genauigkeit und Wissensgewinn auf Seite 3 und individueller und gesellschaftlicher Nutzen auf Seite 7 (siehe Fragebogen im Anhang 3.3 im elektronischen Zusatzmaterial). Auf den drei Seiten dazwischen fanden sich Fragen zu informationellen Privatheitsbedenken bei der Internetnutzung, der Intensität der Online-und Smartphone-Nutzung sowie der Intensität der Nutzung von Medienberichterstattung über die Digitalisierung.</p>
        <p>Die Datenauswertung der Erhebungen 1.2 und 1.3 folgt der Modellspezifikation des Gesamtmodells des BDGS aus Erhebung 1.1 (siehe Abbildung 9.2) und dem in Abschnitt 9.1.3 beschrieben Vorgehen bei der Datenanalyse mit AMOS 23.Die Datenauswertung der Erhebungen 1.2 und 1.3 folgt der Modellspezifikation des Gesamtmodells des BDGS aus Erhebung 1.1 (siehe Abbildung 9.2) und dem in Abschnitt 9.1.3 beschrieben Vorgehen bei der Datenanalyse mit AMOS 23.</p>
        <p>Alle Modelle wurden erneut mit der FIML-Schätzung geschätzt. Die Mittelwerte der latenten Faktoren wurden erneut auf den Wert null restringiert, so dass die Achsenabschnitte (Regressionskonstanten) aller beobachteten Indikatoren geschätzt werden konnten.Alle Modelle wurden erneut mit der FIML-Schätzung geschätzt. Die Mittelwerte der latenten Faktoren wurden erneut auf den Wert null restringiert, so dass die Achsenabschnitte (Regressionskonstanten) aller beobachteten Indikatoren geschätzt werden konnten.</p>
        <p>Die Datenauswertung für Erhebung 1.2 greift zudem die Logik der Kontextunterscheidung in der Untersuchungsanlage auf und berichtet nachfolgend die Ergebnisse für jeweils eine CFA für das Szenario E-Commerce, politische Online-Partizipation und Self-Tracking.Die Datenauswertung für Erhebung 1.2 greift zudem die Logik der Kontextunterscheidung in der Untersuchungsanlage auf und berichtet nachfolgend die Ergebnisse für jeweils eine CFA für das Szenario E-Commerce, politische Online-Partizipation und Self-Tracking.</p>
        <p>Die CFA für das jeweils identisch spezifizierte Modell kommt in allen drei Kontexten der Erhebung 1.2 zu einer plausiblen Lösung. Im Sinne der einfachen Vergleichbarkeit der drei Kontexte finden sich die jeweiligen Werte für die drei CFAs in den folgenden Tabellen nebeneinander abgetragen. Es zeigt sich mit Blick auf die in Tabelle 9.5 berichteten Fit-Maße, dass der strenge Chi-Quadrat-Test jeweils eine unzureichende Anpassungsgüte zeigt, die inkrementellen Fit-Maße des RMSEA und der TLI jedoch jeweils eine hohe Anpassungsgüte indizieren. Auch für diese Modelle würden freizusetzende Korrelationen der Fehlerterme den Modellfit jeweils verbessern, diese folgen jedoch mit Blick auf die Modifikationsindizes und gemeinsam geteilte Varianz keiner Systematik.Die CFA für das jeweils identisch spezifizierte Modell kommt in allen drei Kontexten der Erhebung 1.2 zu einer plausiblen Lösung. Im Sinne der einfachen Vergleichbarkeit der drei Kontexte finden sich die jeweiligen Werte für die drei CFAs in den folgenden Tabellen nebeneinander abgetragen. Es zeigt sich mit Blick auf die in Tabelle 9.5 berichteten Fit-Maße, dass der strenge Chi-Quadrat-Test jeweils eine unzureichende Anpassungsgüte zeigt, die inkrementellen Fit-Maße des RMSEA und der TLI jedoch jeweils eine hohe Anpassungsgüte indizieren. Auch für diese Modelle würden freizusetzende Korrelationen der Fehlerterme den Modellfit jeweils verbessern, diese folgen jedoch mit Blick auf die Modifikationsindizes und gemeinsam geteilte Varianz keiner Systematik.</p>
        <p>Die CFA für das spezifizierte Modell kommt auch für das Sample der Erhebung 1.3 zu einer plausiblen Lösung und zeigt mit Blick auf den strengen Chi-Quadrat-Test eine unzureichende Anpassungsgüte (X 2 (48) = 136.608, p &lt; .001; RMSEA = .049 [.039, .058]; TLI = .981). Der RMSEA und der TLI indizieren jedoch eine ausreichend hohe Anpassungsgüte. Auch für dieses Modell würden freizusetzende Korrelationen der Fehlerterme den Modellfit jeweils verbessern. Zudem ist hier ebenfalls zu bedenken, dass das vorliegende Modell bei ganzen 784 Beobachtungen zu einem signifikanten Chi-Quadrat-Test tendiert (siehe hierzu Abschnitt 9.1.3). In Tabelle 9.6 finden sich die jeweiligen Angaben zum Cronbachschen α und der DEV der jeweiligen Dimensionen in Erhebung 1.2 und 1.3. Die Werte indizieren für alle Modelle über alle vier Dimensionen hinweg eine hohe interne Konsistenz.Die CFA für das spezifizierte Modell kommt auch für das Sample der Erhebung 1.3 zu einer plausiblen Lösung und zeigt mit Blick auf den strengen Chi-Quadrat-Test eine unzureichende Anpassungsgüte (X 2 (48) = 136.608, p &lt; .001; RMSEA = .049 [.039, .058]; TLI = .981). Der RMSEA und der TLI indizieren jedoch eine ausreichend hohe Anpassungsgüte. Auch für dieses Modell würden freizusetzende Korrelationen der Fehlerterme den Modellfit jeweils verbessern. Zudem ist hier ebenfalls zu bedenken, dass das vorliegende Modell bei ganzen 784 Beobachtungen zu einem signifikanten Chi-Quadrat-Test tendiert (siehe hierzu Abschnitt 9.1.3). In Tabelle 9.6 finden sich die jeweiligen Angaben zum Cronbachschen α und der DEV der jeweiligen Dimensionen in Erhebung 1.2 und 1.3. Die Werte indizieren für alle Modelle über alle vier Dimensionen hinweg eine hohe interne Konsistenz.</p>
        <p>Darüber hinaus finden sich in der Tabelle 9.7 für Erhebung 1.2 und Tabelle 9.8 für Erhebung 1.3 jeweils die Regressionskonstanten, die Regressionswerte sowie die geschätzten Faktorladungen der einzelnen Indikatoren samt deren Dimensionszugehörigkeit innerhalb des BDGS. Es zeigt sich, wie auch in Erhebung 1.1, dass die Regressionskonstanten für die Indikatoren der Dimensionen Genauigkeit, individueller Nutzen und gesellschaftlicher Nutzen nahe dem Skalenmittelpunkt liegen. Für die Indikatoren der Dimension des Wissensgewinns hingegen liegen die Regressionskonstanten in der Erhebung 1.2 rund einen halben Skalenpunkt oberhalb der Skalenmitte, in Erhebung 1.3 sogar einen ganzen Skalenpunkt.Darüber hinaus finden sich in der Tabelle 9.7 für Erhebung 1.2 und Tabelle 9.8 für Erhebung 1.3 jeweils die Regressionskonstanten, die Regressionswerte sowie die geschätzten Faktorladungen der einzelnen Indikatoren samt deren Dimensionszugehörigkeit innerhalb des BDGS. Es zeigt sich, wie auch in Erhebung 1.1, dass die Regressionskonstanten für die Indikatoren der Dimensionen Genauigkeit, individueller Nutzen und gesellschaftlicher Nutzen nahe dem Skalenmittelpunkt liegen. Für die Indikatoren der Dimension des Wissensgewinns hingegen liegen die Regressionskonstanten in der Erhebung 1.2 rund einen halben Skalenpunkt oberhalb der Skalenmitte, in Erhebung 1.3 sogar einen ganzen Skalenpunkt.</p>
        <p>In Tabelle 9.9 finden sich die Inter-Korrelationen der vier Dimensionen des BDGS in den Erhebungen 1.2 und 1.3, die erneut hoch miteinander korrelieren. Online-Kommunikation Erhebung 1.2c (Putnick &amp; Bornstein, 2016). Mithin werden auch hier häufig inkrementelle Fit-Maße zur Beurteilung der Messinvarianz herangezogen (F. F. Chen, 2007;Meade et al., 2008), die eine Einschätzung erlauben, in welchem Grad sich das Modell durch die Gleichheitsrestriktionen verschlechtert. So wird mit Blick auf Tabelle 9.10 ersichtlich, dass das Modell mit der skalaren Invarianz bezüglich der inkrementellen Fit-Maße des TLI und des RMSEA eine höhere bzw. mindestens gleich hohe Anpassungsgüte zeigt, verglichen mit den Modellen mit konfiguraler Invarianz bzw. metrischer Invarianz. Das bedeutet, dass das Modell mit den Gleichheitsrestriktionen eine signifikant, jedoch nicht substantiell schlechtere Anpassungsgüte zeigt und mithin von starker Messinvarianz ausgegangen wird.In Tabelle 9.9 finden sich die Inter-Korrelationen der vier Dimensionen des BDGS in den Erhebungen 1.2 und 1.3, die erneut hoch miteinander korrelieren. Online-Kommunikation Erhebung 1.2c (Putnick &amp; Bornstein, 2016). Mithin werden auch hier häufig inkrementelle Fit-Maße zur Beurteilung der Messinvarianz herangezogen (F. F. Chen, 2007;Meade et al., 2008), die eine Einschätzung erlauben, in welchem Grad sich das Modell durch die Gleichheitsrestriktionen verschlechtert. So wird mit Blick auf Tabelle 9.10 ersichtlich, dass das Modell mit der skalaren Invarianz bezüglich der inkrementellen Fit-Maße des TLI und des RMSEA eine höhere bzw. mindestens gleich hohe Anpassungsgüte zeigt, verglichen mit den Modellen mit konfiguraler Invarianz bzw. metrischer Invarianz. Das bedeutet, dass das Modell mit den Gleichheitsrestriktionen eine signifikant, jedoch nicht substantiell schlechtere Anpassungsgüte zeigt und mithin von starker Messinvarianz ausgegangen wird.</p>
        <p>Durch die Festsetzung der Gleichheitsrestriktionen lassen sich bei starker Messinvarianz die Mittelwerte der latenten Konstrukte über die Gruppen hinweg vergleichen, wobei die Stichprobe der Erhebung 1.1 als Referenzgruppe festgelegt wird, deren Faktor-Mittelwerte auf 0 restringiert sind (siehe Tabelle 9.11).Durch die Festsetzung der Gleichheitsrestriktionen lassen sich bei starker Messinvarianz die Mittelwerte der latenten Konstrukte über die Gruppen hinweg vergleichen, wobei die Stichprobe der Erhebung 1.1 als Referenzgruppe festgelegt wird, deren Faktor-Mittelwerte auf 0 restringiert sind (siehe Tabelle 9.11).</p>
        <p>Es zeigt sich mit Blick auf die Mittelwerte, dass für alle Dimensionen des BDGS kein Unterschied zwischen den Erhebungen 1.1 und 1.2 besteht, die Mittelwerte der Dimensionen in Erhebung 1.3 jedoch signifikant höher ausfallen als in Erhebung 1.1 und in Teilen auch als in der Erhebung 1.2.Es zeigt sich mit Blick auf die Mittelwerte, dass für alle Dimensionen des BDGS kein Unterschied zwischen den Erhebungen 1.1 und 1.2 besteht, die Mittelwerte der Dimensionen in Erhebung 1.3 jedoch signifikant höher ausfallen als in Erhebung 1.1 und in Teilen auch als in der Erhebung 1.2.</p>
        <p>Wie im Rahmen der Erhebung 1.1 diskutiert, stellt sich die Frage der DV. Daher wurde zur erneuten Prüfung der DV auch in Erhebung 1.2 sowie Erhebung 1.3 ein SOFM spezifiziert, das Aussagen über die spezifische Varianz der latenten Faktoren erlaubt.Wie im Rahmen der Erhebung 1.1 diskutiert, stellt sich die Frage der DV. Daher wurde zur erneuten Prüfung der DV auch in Erhebung 1.2 sowie Erhebung 1.3 ein SOFM spezifiziert, das Aussagen über die spezifische Varianz der latenten Faktoren erlaubt.</p>
        <p>Für alle drei Kontexte in Erhebung 1.2 zeigen sich signifikante Varianzen der FaktorenFür alle drei Kontexte in Erhebung 1.2 zeigen sich signifikante Varianzen der Faktoren</p>
        <p>• Genauigkeit (σ 2• Genauigkeit (σ 2</p>
        <p>Genauigkeit_1.2a = .263, SE = .048, p &lt; .001; σ 2 Genauigkeit_1.2bGenauigkeit_1.2a = .263, SE = .048, p &lt; .001; σ 2 Genauigkeit_1.2b</p>
        <p>= .348, SE = .051, p &lt; .001; σ 2 Genauigkeit_1.2c = .345, S.E. = .062, p &lt; .001), • Wissensgewinn (σ 2= .348, SE = .051, p &lt; .001; σ 2 Genauigkeit_1.2c = .345, S.E. = .062, p &lt; .001), • Wissensgewinn (σ 2</p>
        <p>Wissensgewinn_1.2a = .377, SE = .055, p &lt; .001; σ 2Wissensgewinn_1.2a = .377, SE = .055, p &lt; .001; σ 2</p>
        <p>Wissensgewinn_1.2b = .398, SE = .055, p &lt; .001; σ 2 Wissensgewinn_1.2c = .385, S.E. = .053, p &lt; .001),Wissensgewinn_1.2b = .398, SE = .055, p &lt; .001; σ 2 Wissensgewinn_1.2c = .385, S.E. = .053, p &lt; .001),</p>
        <p>• Individueller Nutzen (σ 2 Ind. Nutzen_1.2a = .153, SE = .041, p &lt; .001; σ 2 Ind. Nutzen_1.2b = .391, SE = .054, p &lt; .001; σ 2 Ind. Nutzen_1.2c = .454, S.E. = .063, p &lt; .001).• Individueller Nutzen (σ 2 Ind. Nutzen_1.2a = .153, SE = .041, p &lt; .001; σ 2 Ind. Nutzen_1.2b = .391, SE = .054, p &lt; .001; σ 2 Ind. Nutzen_1.2c = .454, S.E. = .063, p &lt; .001).</p>
        <p>Ges. Nutzen_1.2a = .055, SE = .032, p = .088; σ 2 Ges. Nutzen_1.2b = .006, SE = .032, p = .854; σ 2 Ges. Nutzen_1.2c = -.003, S.E. = .036, p = .932). 16Auch in Erhebung 1.2 indizieren die Ergebnisse daher, dass sich mit Blick auf die DV die Dimensionen Genauigkeit, Wissensgewinn und individueller Nutzen voneinander unterscheiden lassen, die Bewertung des gesellschaftlichen Nutzens sich jedoch nicht ausreichend von den drei anderen Dimensionen innerhalb des BDGS unterscheidet (Gignac &amp; Kretzschmar, 2017).Ges. Nutzen_1.2a = .055, SE = .032, p = .088; σ 2 Ges. Nutzen_1.2b = .006, SE = .032, p = .854; σ 2 Ges. Nutzen_1.2c = -.003, S.E. = .036, p = .932). 16Auch in Erhebung 1.2 indizieren die Ergebnisse daher, dass sich mit Blick auf die DV die Dimensionen Genauigkeit, Wissensgewinn und individueller Nutzen voneinander unterscheiden lassen, die Bewertung des gesellschaftlichen Nutzens sich jedoch nicht ausreichend von den drei anderen Dimensionen innerhalb des BDGS unterscheidet (Gignac &amp; Kretzschmar, 2017).</p>
        <p>Daher wurde zur erneuten Prüfung der DV in Erhebung 1.3 ebenfalls ein SOFM spezifiziert, das Aussagen über die spezifische Varianz der latenten Faktoren erlaubt. Es zeigen sich hier signifikante Varianzen der Faktoren Genauigkeit (σ 2 Genauigkeit = .898, S.E. = .068, p &lt; .001), Wissensgewinn (σ 2 Wissensgewinn = .852, S.E. = .062, p &lt; .001), individueller Nutzen (σ 2Daher wurde zur erneuten Prüfung der DV in Erhebung 1.3 ebenfalls ein SOFM spezifiziert, das Aussagen über die spezifische Varianz der latenten Faktoren erlaubt. Es zeigen sich hier signifikante Varianzen der Faktoren Genauigkeit (σ 2 Genauigkeit = .898, S.E. = .068, p &lt; .001), Wissensgewinn (σ 2 Wissensgewinn = .852, S.E. = .062, p &lt; .001), individueller Nutzen (σ 2</p>
        <p>Ind. Nutzen = .176, S.E. = .033, p &lt; .001) sowie, anders als bei den Erhebungen 1.1 und 1.2 zuvor, auch des gesellschaftlichen Nutzens (σ 2Ind. Nutzen = .176, S.E. = .033, p &lt; .001) sowie, anders als bei den Erhebungen 1.1 und 1.2 zuvor, auch des gesellschaftlichen Nutzens (σ 2</p>
        <p>Ges. Nutzen = .115, S.E. = .026, p &lt; .001). Die Varianz der Nutzendimensionen fällt jedoch im Vergleich mit den anderen beiden Dimensionen trotz Signifikanz deutlich geringer aus und begründet sich auch in der größeren Stichprobe.Ges. Nutzen = .115, S.E. = .026, p &lt; .001). Die Varianz der Nutzendimensionen fällt jedoch im Vergleich mit den anderen beiden Dimensionen trotz Signifikanz deutlich geringer aus und begründet sich auch in der größeren Stichprobe.</p>
        <p>An dieser Stelle der Skalenkonstruktion erfolgt daher folgendes Fazit bezüglich der dimensionalen Struktur des Modells: Einem CFM mit Korrelationen zwischen den vier latenten Faktoren wird der Vorzug vor einem Single-Factor-Modell oder einem Second-Order-Factor-Modell gegeben. Die einzelnen Dimensionen lassen sich als eigenständige latente Faktoren identifizieren und voneinander unterscheiden, auch wenn es leichte Einschränkungen mit Blick auf die Stärke der dimensionalen Verschiedenheit gibt. Bei ausgeprägtem BDGS variieren die Befragten stärker mit Blick auf ihre Einschätzungen der Wahrhaftigkeitsdimensionen als mit Blick auf den wahrgenommenen Nutzen.An dieser Stelle der Skalenkonstruktion erfolgt daher folgendes Fazit bezüglich der dimensionalen Struktur des Modells: Einem CFM mit Korrelationen zwischen den vier latenten Faktoren wird der Vorzug vor einem Single-Factor-Modell oder einem Second-Order-Factor-Modell gegeben. Die einzelnen Dimensionen lassen sich als eigenständige latente Faktoren identifizieren und voneinander unterscheiden, auch wenn es leichte Einschränkungen mit Blick auf die Stärke der dimensionalen Verschiedenheit gibt. Bei ausgeprägtem BDGS variieren die Befragten stärker mit Blick auf ihre Einschätzungen der Wahrhaftigkeitsdimensionen als mit Blick auf den wahrgenommenen Nutzen.</p>
        <p>Explizites Ziel der Erhebung 1.3 war zudem die Prüfung von Reihenfolgeeffekten auf die Diskriminanzvalidität der latenten Faktoren. Die Inter-Korrelationen zwischen den latenten Faktoren in den Erhebungen 1.1 und 1.2 erreichten in Teilen so hohe Werte, dass gemäß dem Fornell-Larcker-Kriterium keine Diskriminanzvalidität festgestellt werden konnte. Durch eine Aufteilung der Skala auf zwei Befragungsseiten sollte der Einfluss der Skalenpräsentation auf einer Seite geprüft werden, wobei zwischen den beiden Seiten der nun aufgeteilten Skala weitere Itembatterien positioniert wurden, um einen Ablenkungseffekt zu erzielen.Explizites Ziel der Erhebung 1.3 war zudem die Prüfung von Reihenfolgeeffekten auf die Diskriminanzvalidität der latenten Faktoren. Die Inter-Korrelationen zwischen den latenten Faktoren in den Erhebungen 1.1 und 1.2 erreichten in Teilen so hohe Werte, dass gemäß dem Fornell-Larcker-Kriterium keine Diskriminanzvalidität festgestellt werden konnte. Durch eine Aufteilung der Skala auf zwei Befragungsseiten sollte der Einfluss der Skalenpräsentation auf einer Seite geprüft werden, wobei zwischen den beiden Seiten der nun aufgeteilten Skala weitere Itembatterien positioniert wurden, um einen Ablenkungseffekt zu erzielen.</p>
        <p>Zunächst richtet sich der Blick auf die Dimension Genauigkeit und deren quadrierte Korrelation mit der Dimension des individuellen Nutzens (r 2 Genauigkeit, individueller Nutzen = .262) und der Dimension des gesellschaftlichen Nutzens (r 2 Genauigkeit, gesellschaftlicher Nutzen = .279). Die in Tabelle 9.6 berichtete DEV der Faktoren zeigt nun deutlich, dass von diskriminanter Validität ausgegangen werden kann, da die jeweilige DEV größer als die gemeinsam geteilte Varianz der Faktoren ist. Schaut man auf die Dimension Wissensgewinn und individueller Nutzen (r 2 Wissensgewinn, individueller Nutzen = .210) und gesellschaftlicher Nutzen (r 2 Wissensgewinn, gesellschaftlicher Nutzen = .228), fallen die Werte für die quadrierten Korrelationen ebenfalls deutlich niedriger aus als jeweils beide DEV-Werte. Vergleicht man gemeinsam geteilte Varianz der latenten Faktoren, die sich auf unterschiedlichen Fragebogenseiten befanden, mit denen aus Erhebung 1.1 (siehe Tabelle 9.3) und Erhebung 1.2 (siehe Tabelle 9.9), die auf einer Seite angezeigt wurden, so lässt sich rund die Hälfte bis zwei Drittel der Varianz durch den Reihenfolgeeffekt erklären.Zunächst richtet sich der Blick auf die Dimension Genauigkeit und deren quadrierte Korrelation mit der Dimension des individuellen Nutzens (r 2 Genauigkeit, individueller Nutzen = .262) und der Dimension des gesellschaftlichen Nutzens (r 2 Genauigkeit, gesellschaftlicher Nutzen = .279). Die in Tabelle 9.6 berichtete DEV der Faktoren zeigt nun deutlich, dass von diskriminanter Validität ausgegangen werden kann, da die jeweilige DEV größer als die gemeinsam geteilte Varianz der Faktoren ist. Schaut man auf die Dimension Wissensgewinn und individueller Nutzen (r 2 Wissensgewinn, individueller Nutzen = .210) und gesellschaftlicher Nutzen (r 2 Wissensgewinn, gesellschaftlicher Nutzen = .228), fallen die Werte für die quadrierten Korrelationen ebenfalls deutlich niedriger aus als jeweils beide DEV-Werte. Vergleicht man gemeinsam geteilte Varianz der latenten Faktoren, die sich auf unterschiedlichen Fragebogenseiten befanden, mit denen aus Erhebung 1.1 (siehe Tabelle 9.3) und Erhebung 1.2 (siehe Tabelle 9.9), die auf einer Seite angezeigt wurden, so lässt sich rund die Hälfte bis zwei Drittel der Varianz durch den Reihenfolgeeffekt erklären.</p>
        <p>Die Anpassungsgüte des BDGS-Modells wird auch in den beiden Erhebungen 1.2 und 1.3 der Studie 1 als ausreichend bis zufriedenstellend bewertet. Zwar verfehlt die Modellierung des BDGS in beiden Erhebungen den strengen Chi-Quadrat-Test. Dennoch wurde auf Grundlage der vorliegenden Konzeption die Freisetzung der restringierten Parameter, also die Zulässigkeit korrelierter Fehlerterme, vermieden, da die inkrementellen Fit-Maße eine gute Passung indizieren.Die Anpassungsgüte des BDGS-Modells wird auch in den beiden Erhebungen 1.2 und 1.3 der Studie 1 als ausreichend bis zufriedenstellend bewertet. Zwar verfehlt die Modellierung des BDGS in beiden Erhebungen den strengen Chi-Quadrat-Test. Dennoch wurde auf Grundlage der vorliegenden Konzeption die Freisetzung der restringierten Parameter, also die Zulässigkeit korrelierter Fehlerterme, vermieden, da die inkrementellen Fit-Maße eine gute Passung indizieren.</p>
        <p>Erhebung 1.2 Die Mittelwerte der Dimensionen des BDGS zeigen im Vergleich der Erhebung 1.1 mit der Erhebung 1.2 über alle drei Kontexte einen ähnlichen Gesamteindruck. Diese Ähnlichkeit der Resultate führt zu der Einschätzung, dass die Messung des BDGS mit dem vorgeschlagenen Skalen-Instrument zum einen reliabel möglich ist und die in Erhebung 1.1 gewählten Indikatoren insgesamt geeignet sind, die konzeptuelle Dimensionierung abzubilden. Zum anderen indizieren die Ergebnisse, dass das BDGS als ein stabiles Wahrnehmungsmuster erscheint. Die Ausprägung der Dimensionen zeigt, dass mit Blick auf die Genauigkeit der Daten sowie auf den hieraus gezogenen individuellen und gesellschaftlichen Nutzen von den Befragten durchaus abgewogen und im Durchschnitt keine eindeutig negative oder positive Bewertung abgegeben wird. Die Einschätzung der Datensammlung und -auswertung ist mithin durchaus ambivalent, während die Befragten durchweg einen Wissensgewinn aus den Daten erwarten.Erhebung 1.2 Die Mittelwerte der Dimensionen des BDGS zeigen im Vergleich der Erhebung 1.1 mit der Erhebung 1.2 über alle drei Kontexte einen ähnlichen Gesamteindruck. Diese Ähnlichkeit der Resultate führt zu der Einschätzung, dass die Messung des BDGS mit dem vorgeschlagenen Skalen-Instrument zum einen reliabel möglich ist und die in Erhebung 1.1 gewählten Indikatoren insgesamt geeignet sind, die konzeptuelle Dimensionierung abzubilden. Zum anderen indizieren die Ergebnisse, dass das BDGS als ein stabiles Wahrnehmungsmuster erscheint. Die Ausprägung der Dimensionen zeigt, dass mit Blick auf die Genauigkeit der Daten sowie auf den hieraus gezogenen individuellen und gesellschaftlichen Nutzen von den Befragten durchaus abgewogen und im Durchschnitt keine eindeutig negative oder positive Bewertung abgegeben wird. Die Einschätzung der Datensammlung und -auswertung ist mithin durchaus ambivalent, während die Befragten durchweg einen Wissensgewinn aus den Daten erwarten.</p>
        <p>Erhebung 1.3 Die Ähnlichkeit der Resultate von Erhebung 1.3 führt auch hier zunächst zu der Einschätzung, dass die Messung des BDGS mit dem vorgeschlagenen Skalen-Instrument reliabel möglich ist und die gewählten Indikatoren geeignet sind, die konzeptuelle Dimensionierung abzubilden. Es zeigt sich mit Blick auf die erste Forschungsfrage (siehe Kapitel 7), die danach fragt, inwieweit sich ein Glaube an digitale Daten in seinen mehrdimensionalen Bezugspunkten von Überzeugungen empirisch messen lässt, dass die vorgeschlagene Operationalisierung und Datenanalyse geeignet ist, das theoretisch hergeleitete BDGS abzubilden.Erhebung 1.3 Die Ähnlichkeit der Resultate von Erhebung 1.3 führt auch hier zunächst zu der Einschätzung, dass die Messung des BDGS mit dem vorgeschlagenen Skalen-Instrument reliabel möglich ist und die gewählten Indikatoren geeignet sind, die konzeptuelle Dimensionierung abzubilden. Es zeigt sich mit Blick auf die erste Forschungsfrage (siehe Kapitel 7), die danach fragt, inwieweit sich ein Glaube an digitale Daten in seinen mehrdimensionalen Bezugspunkten von Überzeugungen empirisch messen lässt, dass die vorgeschlagene Operationalisierung und Datenanalyse geeignet ist, das theoretisch hergeleitete BDGS abzubilden.</p>
        <p>Bezüglich der zweiten aufgeworfenen Forschungsfrage, die nach der Ausprägung der Überzeugungen und ihrer Beziehungen untereinander fragt, zeigt sich, dass die Mittelwerte der einzelnen Dimensionen in Erhebung 1.3 hierbei etwas größer ausfallen als in den beiden Erhebungen zuvor. Dieses Ergebnis indiziert, dass trotz der generellen Stabilität des BDGS je nach Stichprobe unterschiedlich hohe Ausprägungen des BDGS beobachtet werden können. Es zeigt sich auch hier erneut, dass der erwartete Wissensgewinn positiv ausgeprägt ist, während die Ausprägungen der anderen Dimensionen um den Skalenmittelpunkt liegen.Bezüglich der zweiten aufgeworfenen Forschungsfrage, die nach der Ausprägung der Überzeugungen und ihrer Beziehungen untereinander fragt, zeigt sich, dass die Mittelwerte der einzelnen Dimensionen in Erhebung 1.3 hierbei etwas größer ausfallen als in den beiden Erhebungen zuvor. Dieses Ergebnis indiziert, dass trotz der generellen Stabilität des BDGS je nach Stichprobe unterschiedlich hohe Ausprägungen des BDGS beobachtet werden können. Es zeigt sich auch hier erneut, dass der erwartete Wissensgewinn positiv ausgeprägt ist, während die Ausprägungen der anderen Dimensionen um den Skalenmittelpunkt liegen.</p>
        <p>Im Aggregat erfahren die Aussagen, dass digitale Daten zu einem Wissensgewinn führen, durchweg eine hohe Zustimmung. Dies ist als erstes Indiz dafür zu werten, dass der Mythos eines weitreichenden Erkenntnisgewinns durch die Sammlung und Auswertung großer digitaler Datenbestände einen Niederschlag in der Wahrnehmung der Befragten gefunden hat. Diese positive Konnotation von Wissen vor dem Hintergrund der Wissensgesellschaft ist dabei eng verbunden mit Erwartungen an einen individuellen und gesellschaftlichen Nutzen.Im Aggregat erfahren die Aussagen, dass digitale Daten zu einem Wissensgewinn führen, durchweg eine hohe Zustimmung. Dies ist als erstes Indiz dafür zu werten, dass der Mythos eines weitreichenden Erkenntnisgewinns durch die Sammlung und Auswertung großer digitaler Datenbestände einen Niederschlag in der Wahrnehmung der Befragten gefunden hat. Diese positive Konnotation von Wissen vor dem Hintergrund der Wissensgesellschaft ist dabei eng verbunden mit Erwartungen an einen individuellen und gesellschaftlichen Nutzen.</p>
        <p>Insgesamt zeigen sich hohe Inter-Korrelationen zwischen den einzelnen Dimensionen des BDGS, was indiziert, dass ihre jeweilige Ausprägung untereinander in einer engen Beziehung steht. Dabei gibt Erhebung 1.3 entscheidende Hinweise zur Diskriminanzvalidität der latenten Faktoren des Modells. Die Präsentation der Items führt zu einem kognitiven Befragungseffekt. Mit Blick auf die Ergebnisse sind Befragte eher dazu geneigt, zwischen den einzelnen Dimensionen des BDGS zu unterscheiden, wenn diese auf unterschiedlichen Fragebogenseiten zu finden sind.Insgesamt zeigen sich hohe Inter-Korrelationen zwischen den einzelnen Dimensionen des BDGS, was indiziert, dass ihre jeweilige Ausprägung untereinander in einer engen Beziehung steht. Dabei gibt Erhebung 1.3 entscheidende Hinweise zur Diskriminanzvalidität der latenten Faktoren des Modells. Die Präsentation der Items führt zu einem kognitiven Befragungseffekt. Mit Blick auf die Ergebnisse sind Befragte eher dazu geneigt, zwischen den einzelnen Dimensionen des BDGS zu unterscheiden, wenn diese auf unterschiedlichen Fragebogenseiten zu finden sind.</p>
        <p>Es wird allerdings aus diversen Gründen nur in den wenigsten Befragungsstudien möglich sein, eine Skala, wie sie mit der Messung des BDGS vorliegt, so in den Fragebogenverlauf einzubetten, dass ihr Einsatz gänzlich unproblematisch ist. Dies wird vermutlich nur dort der Fall sein, wo eine ganz spezielle Dimension von Forschungsinteresse ist. Sind alle Dimensionen gleich bedeutend, so stellt sich das Problem, dass (a) die BDGS-Skala aus forschungsökonomischen Gründen nicht auf mehrere Seiten aufgeteilt werden kann, (b) berücksichtigt werden muss, dass auch eine Aufteilung Reihenfolgeeffekte nach sich ziehen kann und (c) eine Aufteilung über mehrere Seiten immer dann problematisch ist, wenn die gesamte Befragung auf ein Phänomen oder Artefakt im Digitalisierungskontext abstellt und der restliche Fragebogen weitere Skalen mit Bezug zur Digitalisierung beinhaltet. Diese Problematik sollte bei jedem Einsatz der BDGS-Skala erneut sorgfältig geprüft werden.Es wird allerdings aus diversen Gründen nur in den wenigsten Befragungsstudien möglich sein, eine Skala, wie sie mit der Messung des BDGS vorliegt, so in den Fragebogenverlauf einzubetten, dass ihr Einsatz gänzlich unproblematisch ist. Dies wird vermutlich nur dort der Fall sein, wo eine ganz spezielle Dimension von Forschungsinteresse ist. Sind alle Dimensionen gleich bedeutend, so stellt sich das Problem, dass (a) die BDGS-Skala aus forschungsökonomischen Gründen nicht auf mehrere Seiten aufgeteilt werden kann, (b) berücksichtigt werden muss, dass auch eine Aufteilung Reihenfolgeeffekte nach sich ziehen kann und (c) eine Aufteilung über mehrere Seiten immer dann problematisch ist, wenn die gesamte Befragung auf ein Phänomen oder Artefakt im Digitalisierungskontext abstellt und der restliche Fragebogen weitere Skalen mit Bezug zur Digitalisierung beinhaltet. Diese Problematik sollte bei jedem Einsatz der BDGS-Skala erneut sorgfältig geprüft werden.</p>
        <p>Mit dem Wissen um die Reihenfolgeeffekte des Fragebogenaufbaus bedeutet das Folgendes: In Studien, in denen die Wechselwirkungen zwischen den einzelnen Dimensionen im Vordergrund stehen und einer Aufteilung aus forschungsökonomischen Gründen nichts entgegensteht, können und sollten die Dimensionen auf unterschiedlichen Fragebogenseiten präsentiert werden, wobei sich auch hier die Frage stellt, in welcher Reihenfolge die Dimensionen abgefragt werden. So ließen sich womöglich konvergente und diskriminante Validität besser sicherstellen, als wenn alle Items rotiert auf einer Seite zu finden sind. 17 Letzteres ist jedoch aus Gründen der Fragebogenlänge eine zu präferierende Lösung, wenn wie in den nachfolgenden Erhebungen die BDGS-Skala in Fragebögen mitläuft, die noch andere Forschungsziele verfolgen. Deshalb und aus forschungsökonomischen sowie Konsistenzgründen wurde daher in den nachfolgenden Erhebungen auf eine Aufteilung der BDGS-Skala verzichtet und diese jeweils auf einer Seite abgebildet, wobei die Reihenfolge der Items zufällig rotiert wurde. 17 Da dies tatsächlich nur für die beiden Dimensionen der Richtigkeit und der Nutzendimensionen geprüft wurde und nicht zwischen den jeweils zu den beiden Oberdimensionen gehörenden Subdimensionen, liegen noch keine umfassenden empirischen Belege vor und es bleibt zunächst bei einer Vermutung, dass dies für alle Dimensionen gelten könnte. Dies beinhaltet zudem noch keine Aussagen oder Erkenntnisse über mögliche Reihenfolgeeffekte bedingt durch die Abfolge der einzelnen Dimensionen.Mit dem Wissen um die Reihenfolgeeffekte des Fragebogenaufbaus bedeutet das Folgendes: In Studien, in denen die Wechselwirkungen zwischen den einzelnen Dimensionen im Vordergrund stehen und einer Aufteilung aus forschungsökonomischen Gründen nichts entgegensteht, können und sollten die Dimensionen auf unterschiedlichen Fragebogenseiten präsentiert werden, wobei sich auch hier die Frage stellt, in welcher Reihenfolge die Dimensionen abgefragt werden. So ließen sich womöglich konvergente und diskriminante Validität besser sicherstellen, als wenn alle Items rotiert auf einer Seite zu finden sind. 17 Letzteres ist jedoch aus Gründen der Fragebogenlänge eine zu präferierende Lösung, wenn wie in den nachfolgenden Erhebungen die BDGS-Skala in Fragebögen mitläuft, die noch andere Forschungsziele verfolgen. Deshalb und aus forschungsökonomischen sowie Konsistenzgründen wurde daher in den nachfolgenden Erhebungen auf eine Aufteilung der BDGS-Skala verzichtet und diese jeweils auf einer Seite abgebildet, wobei die Reihenfolge der Items zufällig rotiert wurde. 17 Da dies tatsächlich nur für die beiden Dimensionen der Richtigkeit und der Nutzendimensionen geprüft wurde und nicht zwischen den jeweils zu den beiden Oberdimensionen gehörenden Subdimensionen, liegen noch keine umfassenden empirischen Belege vor und es bleibt zunächst bei einer Vermutung, dass dies für alle Dimensionen gelten könnte. Dies beinhaltet zudem noch keine Aussagen oder Erkenntnisse über mögliche Reihenfolgeeffekte bedingt durch die Abfolge der einzelnen Dimensionen.</p>
        <p>Um eine Vergleichbarkeit der Ergebnisse aus den einzelnen Erhebungen der Skalenerstellung herzustellen, wurde die Skala wie dokumentiert in allen Erhebungen in nahezu gleicher Weise eingesetzt und wurden dabei die Einleitung der Fragebatterie, die Formulierungen der einzelnen Items sowie die Skalierung und die Benennung aller Skalenpunkte durchweg konstant gehalten. Es liegt in der Natur der Skalenerstellung, dass durch den Einsatz der Skala Erkenntnisse gewonnen wurden, die nach wiederholtem Einsatz für eine Anpassung sprächen.Um eine Vergleichbarkeit der Ergebnisse aus den einzelnen Erhebungen der Skalenerstellung herzustellen, wurde die Skala wie dokumentiert in allen Erhebungen in nahezu gleicher Weise eingesetzt und wurden dabei die Einleitung der Fragebatterie, die Formulierungen der einzelnen Items sowie die Skalierung und die Benennung aller Skalenpunkte durchweg konstant gehalten. Es liegt in der Natur der Skalenerstellung, dass durch den Einsatz der Skala Erkenntnisse gewonnen wurden, die nach wiederholtem Einsatz für eine Anpassung sprächen.</p>
        <p>Aufgrund des Anspruchs an Vergleichbarkeit und weiterer Gründe, wie etwa der vermeintlichen Geringfügigkeit der Bedeutung vieler einzelner Probleme, wurden Änderungen jedoch nicht umgesetzt. Allerdings sollen Erkenntnisse, die u. a. aus der Rückmeldung der Befragten und Reviewer*innen gewonnen wurden, sowie die gesammelten Erfahrungen des federführenden Autors (die über die Diskussion der Diskriminanzvalidität im vorherigen Abschnitt hinausgehen) in diesem Abschnitt dokumentiert und reflektiert werden. Zum einen zur Dokumentation, um ein besseres Verständnis für die Verwendung der Skala herzustellen und etwaige Rückmeldungen der Befragten in zukünftigen Studien zu antizipieren. Zum anderen als Empfehlung, um bei zukünftigen Skalenentwicklungen frühzeitig bedacht zu werden und mögliche Befragungsprobleme zu vermeiden. Man könnte dann aufgrund dieser Erfahrungen und weitergehendem Interesse mit Blick auf die Methodenforschung der Befragung bei der zukünftigen Verwendung mit Hilfe eines Split-Sample-Designs etwaige Änderungen testen und mögliche Auswirkungen auf die Beantwortung der Skala prüfen. Mögliche Probleme und entsprechende Änderungen lassen sich dabei ganz grob unterscheiden nach (a) der Problematik der Formulierungen und (b) der Präsentation der Fragebogenitems.Aufgrund des Anspruchs an Vergleichbarkeit und weiterer Gründe, wie etwa der vermeintlichen Geringfügigkeit der Bedeutung vieler einzelner Probleme, wurden Änderungen jedoch nicht umgesetzt. Allerdings sollen Erkenntnisse, die u. a. aus der Rückmeldung der Befragten und Reviewer*innen gewonnen wurden, sowie die gesammelten Erfahrungen des federführenden Autors (die über die Diskussion der Diskriminanzvalidität im vorherigen Abschnitt hinausgehen) in diesem Abschnitt dokumentiert und reflektiert werden. Zum einen zur Dokumentation, um ein besseres Verständnis für die Verwendung der Skala herzustellen und etwaige Rückmeldungen der Befragten in zukünftigen Studien zu antizipieren. Zum anderen als Empfehlung, um bei zukünftigen Skalenentwicklungen frühzeitig bedacht zu werden und mögliche Befragungsprobleme zu vermeiden. Man könnte dann aufgrund dieser Erfahrungen und weitergehendem Interesse mit Blick auf die Methodenforschung der Befragung bei der zukünftigen Verwendung mit Hilfe eines Split-Sample-Designs etwaige Änderungen testen und mögliche Auswirkungen auf die Beantwortung der Skala prüfen. Mögliche Probleme und entsprechende Änderungen lassen sich dabei ganz grob unterscheiden nach (a) der Problematik der Formulierungen und (b) der Präsentation der Fragebogenitems.</p>
        <p>Das Gros der Rückmeldungen betraf problematische Formulierungen innerhalb des Einleitungstextes sowie der Itemformulierungen selbst, die einen Einfluss auf das Verständnis der Frageitems haben könnten und dadurch auch auf die Ergebnisse der Testbatterie. Probleme konnten hier mit Blick auf (a) Synonyme und subjektiv identische Begriffe sowie (b) Einflüsse aktueller Ereignisse und Modewörter unterschieden werden.Das Gros der Rückmeldungen betraf problematische Formulierungen innerhalb des Einleitungstextes sowie der Itemformulierungen selbst, die einen Einfluss auf das Verständnis der Frageitems haben könnten und dadurch auch auf die Ergebnisse der Testbatterie. Probleme konnten hier mit Blick auf (a) Synonyme und subjektiv identische Begriffe sowie (b) Einflüsse aktueller Ereignisse und Modewörter unterschieden werden.</p>
        <p>Manche Formulierungen waren laut einigen wenigen Rückmeldungen für manche Befragte subjektiv nicht unterscheidbar, was durch die hierdurch ausgelöste Irritation zu einer Verzögerung in der Bearbeitung führen könnte. So erfolgte hin und wieder der Hinweis (v. a. in der nachfolgenden Erhebung 2.4 KI &amp; Hochschule), dass die Worte exakt und genau, die in den Frageitems mit den IDs GE1 und GE2 der Subdimension Genauigkeit vorkamen, identisch sind oder synonym verwendet werden. Dies schließt sich an übliche Rückmeldungen aus Befragungen an, dass bei den Befragten das Gefühl bestand, eigentlich immer das Gleiche gefragt zu werden. Im Sinne der Drei-Item-Messung, die für Indikatoren von latenten Konstrukten empfohlen wird (J. C. Anderson &amp; Gerbing, 1984, 1988;Weiber &amp; Mühlhaus, 2014) und in den vorliegenden Erhebungen eingesetzt wurde, besteht durchgängig die Schwierigkeit, Items so zu formulieren, dass sie zwar sprachlich zu unterscheiden sind, gleichzeitig jedoch das Wesen und den Kern des zugrunde liegenden Konstrukts so genau und repräsentativ wie möglich reflektieren sollten. Die Items sollen gut, also hoch, auf das jeweilige latente Konstrukt laden und gleichzeitig nicht zu ähnlich verfasst sein, was mitunter zur Monotonie des Fragebogens führt (Petersen, 2014;Weiber &amp; Mühlhaus, 2014). Dies muss bei der Formulierung fortlaufend abgewogen werden und führte im vorliegenden Fall letztendlich dennoch zur Wahl synonymer Begrifflichkeiten. Das geringe Ausmaß entsprechender Rückmeldungen der Befragten in den einzelnen Erhebungen veranlassen hier dann auch nicht zur Beunruhigung bezüglich der Reliabilität und Validität der entsprechenden Items. Jedoch hat die sprachliche Nähe synonymer Formulierung einen Einfluss auf die Modellgüte der Messmodelle in der konfirmatorischen Faktorenanalyse, was mit Verweis auf die Modifikationsindizes nachfolgend an den entsprechenden Stellen vermerkt wird. Je nach Rotation der Items innerhalb der Skala kommt es zudem zu Unterschieden in der Stärke geteilter Varianz einzelner Frageitems einer Dimension. Mit Blick auf die Fallzahlen der Stichprobengrößen sollten sich diese zufällig zustande kommenden geteilten Varianzen aufgrund der Rotation zwar nur selten ergeben, auszuschließen sind sie jedoch nicht.Manche Formulierungen waren laut einigen wenigen Rückmeldungen für manche Befragte subjektiv nicht unterscheidbar, was durch die hierdurch ausgelöste Irritation zu einer Verzögerung in der Bearbeitung führen könnte. So erfolgte hin und wieder der Hinweis (v. a. in der nachfolgenden Erhebung 2.4 KI &amp; Hochschule), dass die Worte exakt und genau, die in den Frageitems mit den IDs GE1 und GE2 der Subdimension Genauigkeit vorkamen, identisch sind oder synonym verwendet werden. Dies schließt sich an übliche Rückmeldungen aus Befragungen an, dass bei den Befragten das Gefühl bestand, eigentlich immer das Gleiche gefragt zu werden. Im Sinne der Drei-Item-Messung, die für Indikatoren von latenten Konstrukten empfohlen wird (J. C. Anderson &amp; Gerbing, 1984, 1988;Weiber &amp; Mühlhaus, 2014) und in den vorliegenden Erhebungen eingesetzt wurde, besteht durchgängig die Schwierigkeit, Items so zu formulieren, dass sie zwar sprachlich zu unterscheiden sind, gleichzeitig jedoch das Wesen und den Kern des zugrunde liegenden Konstrukts so genau und repräsentativ wie möglich reflektieren sollten. Die Items sollen gut, also hoch, auf das jeweilige latente Konstrukt laden und gleichzeitig nicht zu ähnlich verfasst sein, was mitunter zur Monotonie des Fragebogens führt (Petersen, 2014;Weiber &amp; Mühlhaus, 2014). Dies muss bei der Formulierung fortlaufend abgewogen werden und führte im vorliegenden Fall letztendlich dennoch zur Wahl synonymer Begrifflichkeiten. Das geringe Ausmaß entsprechender Rückmeldungen der Befragten in den einzelnen Erhebungen veranlassen hier dann auch nicht zur Beunruhigung bezüglich der Reliabilität und Validität der entsprechenden Items. Jedoch hat die sprachliche Nähe synonymer Formulierung einen Einfluss auf die Modellgüte der Messmodelle in der konfirmatorischen Faktorenanalyse, was mit Verweis auf die Modifikationsindizes nachfolgend an den entsprechenden Stellen vermerkt wird. Je nach Rotation der Items innerhalb der Skala kommt es zudem zu Unterschieden in der Stärke geteilter Varianz einzelner Frageitems einer Dimension. Mit Blick auf die Fallzahlen der Stichprobengrößen sollten sich diese zufällig zustande kommenden geteilten Varianzen aufgrund der Rotation zwar nur selten ergeben, auszuschließen sind sie jedoch nicht.</p>
        <p>In der nachfolgend besprochenen Erhebung 2.1 merkten zwei Befragte nach der Teilnahme an, dass die Formulierung "Digitale Daten führen zu neuen Fakten" (Item-ID W2) vor dem Hintergrund der Debatte um sogenannte Fake News und alternative Fakten als problematisch wahrgenommen wurde. 18 Der Begriff ‚Alternative Fakten' fand im Januar 2017 öffentliche Aufmerksamkeit, als Kellyanne Conway, Beraterin des 45. US-Präsidenten Donald Trump, mit diesem Ausspruch widersprüchliche Angaben eines Pressesprechers des Präsidenten rechtfertigte. Das Wort erfuhr im Jahresverlauf wiederholt große Beachtung und wurde in Deutschland und Österreich zum Unwort des Jahres 2017 gewählt (Der Standard, 2018;Frankfurter Allgemeine Zeitung, 2018). Es ist nicht auszuschließen, dass einzelne Befragte sich während der Beantwortung des Items an jene Debatte erinnern. Allerdings ergibt die Datenauswertung der Erhebung 1.1 bis 1.3 keine Hinweise darauf, dass dies zu einer schlechteren Ladung des entsprechenden Items auf das latente Konstrukt geführt hat. Wie sich jedoch nachfolgend zeigen wird, weist das entsprechende Item ab Erhebung 2.1 tatsächlich eine entsprechend schlechtere Ladung auf, worauf an der entsprechenden Stelle hingewiesen wird.In der nachfolgend besprochenen Erhebung 2.1 merkten zwei Befragte nach der Teilnahme an, dass die Formulierung "Digitale Daten führen zu neuen Fakten" (Item-ID W2) vor dem Hintergrund der Debatte um sogenannte Fake News und alternative Fakten als problematisch wahrgenommen wurde. 18 Der Begriff ‚Alternative Fakten' fand im Januar 2017 öffentliche Aufmerksamkeit, als Kellyanne Conway, Beraterin des 45. US-Präsidenten Donald Trump, mit diesem Ausspruch widersprüchliche Angaben eines Pressesprechers des Präsidenten rechtfertigte. Das Wort erfuhr im Jahresverlauf wiederholt große Beachtung und wurde in Deutschland und Österreich zum Unwort des Jahres 2017 gewählt (Der Standard, 2018;Frankfurter Allgemeine Zeitung, 2018). Es ist nicht auszuschließen, dass einzelne Befragte sich während der Beantwortung des Items an jene Debatte erinnern. Allerdings ergibt die Datenauswertung der Erhebung 1.1 bis 1.3 keine Hinweise darauf, dass dies zu einer schlechteren Ladung des entsprechenden Items auf das latente Konstrukt geführt hat. Wie sich jedoch nachfolgend zeigen wird, weist das entsprechende Item ab Erhebung 2.1 tatsächlich eine entsprechend schlechtere Ladung auf, worauf an der entsprechenden Stelle hingewiesen wird.</p>
        <p>Die Aufteilung der BDGS-Skala auf zwei Fragebogenseiten in Erhebung 1.3 verfolgte das Ziel, Erkenntnisse über den Einfluss von Reihenfolgeeffekten auf die diskriminante Validität zu gewinnen, und zeigt, dass die Präsentation der Fragebogenitems einen Einfluss auf die Beantwortung der Skala hat.Die Aufteilung der BDGS-Skala auf zwei Fragebogenseiten in Erhebung 1.3 verfolgte das Ziel, Erkenntnisse über den Einfluss von Reihenfolgeeffekten auf die diskriminante Validität zu gewinnen, und zeigt, dass die Präsentation der Fragebogenitems einen Einfluss auf die Beantwortung der Skala hat.</p>
        <p>Zusammen mit der zuvor diskutierten begrifflichen Ähnlichkeit der Fragebogenitems könnte überlegt werden, die Frageitems der Skala über verschiedene Fragebogenseiten aufzuteilen oder die Anzahl der Fragebogenitems zu reduzieren. Beide Entscheidungen können jedoch nur in Abhängigkeit von der jeweiligen Forschungsfrage und dem Ziel des Einsatzes der BDGS-Skala oder einzelner benötigter Dimensionen der BDGS-Skala getroffen werden. Muss der Fragebogen möglichst kurz ausfallen, kann zudem eine Reduktion der BDGS-Skala auf die zentralen Frageitems einer Dimension (bspw. die Referenzindikatoren) vorgenommen werden, die auf einer Seite präsentiert werden. 18 Weitere Informationen zur wissenschaftlichen Untersuchung von Fake News finden sich bei D. M. J. Lazer et al. (2018). Zur Bedeutung von Fake News in der politischen Kommunikation siehe Schulz et al. (2017).Zusammen mit der zuvor diskutierten begrifflichen Ähnlichkeit der Fragebogenitems könnte überlegt werden, die Frageitems der Skala über verschiedene Fragebogenseiten aufzuteilen oder die Anzahl der Fragebogenitems zu reduzieren. Beide Entscheidungen können jedoch nur in Abhängigkeit von der jeweiligen Forschungsfrage und dem Ziel des Einsatzes der BDGS-Skala oder einzelner benötigter Dimensionen der BDGS-Skala getroffen werden. Muss der Fragebogen möglichst kurz ausfallen, kann zudem eine Reduktion der BDGS-Skala auf die zentralen Frageitems einer Dimension (bspw. die Referenzindikatoren) vorgenommen werden, die auf einer Seite präsentiert werden. 18 Weitere Informationen zur wissenschaftlichen Untersuchung von Fake News finden sich bei D. M. J. Lazer et al. (2018). Zur Bedeutung von Fake News in der politischen Kommunikation siehe Schulz et al. (2017).</p>
        <p>Open Access Dieses Kapitel wird unter der Creative Commons Namensnennung 4.0 International Lizenz (http://creativecommons.org/licenses/by/4.0/deed.de) veröffentlicht, welche die Nutzung, Vervielfältigung, Bearbeitung, Verbreitung und Wiedergabe in jeglichem Medium und Format erlaubt, sofern Sie den/die ursprünglichen Autor(en) und die Quelle ordnungsgemäß nennen, einen Link zur Creative Commons Lizenz beifügen und angeben, ob Änderungen vorgenommen wurden.Open Access Dieses Kapitel wird unter der Creative Commons Namensnennung 4.0 International Lizenz (http://creativecommons.org/licenses/by/4.0/deed.de) veröffentlicht, welche die Nutzung, Vervielfältigung, Bearbeitung, Verbreitung und Wiedergabe in jeglichem Medium und Format erlaubt, sofern Sie den/die ursprünglichen Autor(en) und die Quelle ordnungsgemäß nennen, einen Link zur Creative Commons Lizenz beifügen und angeben, ob Änderungen vorgenommen wurden.</p>
        <p>Die in diesem Kapitel enthaltenen Bilder und sonstiges Drittmaterial unterliegen ebenfalls der genannten Creative Commons Lizenz, sofern sich aus der Abbildungslegende nichts anderes ergibt. Sofern das betreffende Material nicht unter der genannten Creative Commons Lizenz steht und die betreffende Handlung nicht nach gesetzlichen Vorschriften erlaubt ist, ist für die oben aufgeführten Weiterverwendungen des Materials die Einwilligung des jeweiligen Rechteinhabers einzuholen.Die in diesem Kapitel enthaltenen Bilder und sonstiges Drittmaterial unterliegen ebenfalls der genannten Creative Commons Lizenz, sofern sich aus der Abbildungslegende nichts anderes ergibt. Sofern das betreffende Material nicht unter der genannten Creative Commons Lizenz steht und die betreffende Handlung nicht nach gesetzlichen Vorschriften erlaubt ist, ist für die oben aufgeführten Weiterverwendungen des Materials die Einwilligung des jeweiligen Rechteinhabers einzuholen.</p>
        <p>Im Nachgang zu Skalenkonstruktion und -validierung wurde die BDGS-Skala zwischen Januar und Oktober 2019 in vier weiteren empirischen Forschungszusammenhängen eingesetzt und wurden Daten für die Ausprägung des BDGS in den vier jeweiligen Stichproben erhoben. Diese werden nachfolgend entsprechend Erhebung 2.1 EU und KI, Erhebung 2.2 KI-Bedrohung, Erhebung 2.3 Krankenversicherung und Erhebung 2.4 KI und Hochschule benannt. In den nachfolgenden Abschnitten werden die vier empirischen Forschungszusammenhänge mit dem jeweiligen Erkenntnisinteresse besprochen und wird das empirische Vorgehen so knapp und dennoch so nachvollziehbar wie möglich dokumentiert. Ziel der Erhebungen, die zur zweiten Studie dieser Arbeit gehören, war es, die dritte aufgeworfene Forschungsfrage zu beantworten, die danach fragt, welche Auswirkung die Überzeugungen des Glaubens an große digitale Datenbestände auf Einstellungen zum Einsatz von KI-Anwendungen haben (siehe Kapitel 7). Hierzu wurde die BDGS-Skala im Rahmen unterschiedlicher Anwendungsfälle als unabhängige Variable modelliert und ihre vermutete Erklärungskraft in unterschiedlichen Forschungszusammenhängen gesellschaftlicher Datensammlung und -verwertung geprüft. Den untersuchten Forschungskontexten ist dabei gemein, dass sie sich auf datenbasierte KI-Anwendungen beziehen, denen derzeit eine hohe Aufmerksamkeit zukommt und für die sich immer besonders hohe Ansprüche an die Qualität und den Umfang der Preisgabe digitaler Daten stellen. Die Erhebungen folgen dabei einer aufeinander aufbauenden Logik: Am Beispiel von Modellanwendungen der KI, die derzeit in unterschiedlichen Lebensbereichen implementiert Studie 2 -Die Auswirkungen der … werden oder deren Implementierung in naher Zukunft angedacht ist, wird der erwartete Einfluss des BDGS auf kognitive, affektive sowie konative Komponenten der Einstellungen der Bürger*innen zu diesen Anwendungen untersucht (Maio et al., 2018).Im Nachgang zu Skalenkonstruktion und -validierung wurde die BDGS-Skala zwischen Januar und Oktober 2019 in vier weiteren empirischen Forschungszusammenhängen eingesetzt und wurden Daten für die Ausprägung des BDGS in den vier jeweiligen Stichproben erhoben. Diese werden nachfolgend entsprechend Erhebung 2.1 EU und KI, Erhebung 2.2 KI-Bedrohung, Erhebung 2.3 Krankenversicherung und Erhebung 2.4 KI und Hochschule benannt. In den nachfolgenden Abschnitten werden die vier empirischen Forschungszusammenhänge mit dem jeweiligen Erkenntnisinteresse besprochen und wird das empirische Vorgehen so knapp und dennoch so nachvollziehbar wie möglich dokumentiert. Ziel der Erhebungen, die zur zweiten Studie dieser Arbeit gehören, war es, die dritte aufgeworfene Forschungsfrage zu beantworten, die danach fragt, welche Auswirkung die Überzeugungen des Glaubens an große digitale Datenbestände auf Einstellungen zum Einsatz von KI-Anwendungen haben (siehe Kapitel 7). Hierzu wurde die BDGS-Skala im Rahmen unterschiedlicher Anwendungsfälle als unabhängige Variable modelliert und ihre vermutete Erklärungskraft in unterschiedlichen Forschungszusammenhängen gesellschaftlicher Datensammlung und -verwertung geprüft. Den untersuchten Forschungskontexten ist dabei gemein, dass sie sich auf datenbasierte KI-Anwendungen beziehen, denen derzeit eine hohe Aufmerksamkeit zukommt und für die sich immer besonders hohe Ansprüche an die Qualität und den Umfang der Preisgabe digitaler Daten stellen. Die Erhebungen folgen dabei einer aufeinander aufbauenden Logik: Am Beispiel von Modellanwendungen der KI, die derzeit in unterschiedlichen Lebensbereichen implementiert Studie 2 -Die Auswirkungen der … werden oder deren Implementierung in naher Zukunft angedacht ist, wird der erwartete Einfluss des BDGS auf kognitive, affektive sowie konative Komponenten der Einstellungen der Bürger*innen zu diesen Anwendungen untersucht (Maio et al., 2018).</p>
        <p>Erkenntnisinteresse BDGSErkenntnisinteresse BDGS</p>
        <p>Zuletzt bestehen mit Blick auf die Struktur des BDGS und der hierzu gesammelten Daten Herausforderungen für die Auswertung. Hier ist u. a. auf die hohe Inter-Korrelation der BDGS-Dimensionen einzugehen, welche in den voraussetzungsreicheren Strukturregressionsmodellen gepaart mit kleinen Stichprobengrößen, einer geringen Anzahl von Indikatoren, der hierdurch bedingten geringen dimensionalen Verschiedenheit sowie hoher Multikollinearität zu Problemen bei der Modellschätzung und Ergebnisinterpretation führen kann (Grewal et al., 2004;Jagpal, 1982;Marsh et al., 2004)Zuletzt bestehen mit Blick auf die Struktur des BDGS und der hierzu gesammelten Daten Herausforderungen für die Auswertung. Hier ist u. a. auf die hohe Inter-Korrelation der BDGS-Dimensionen einzugehen, welche in den voraussetzungsreicheren Strukturregressionsmodellen gepaart mit kleinen Stichprobengrößen, einer geringen Anzahl von Indikatoren, der hierdurch bedingten geringen dimensionalen Verschiedenheit sowie hoher Multikollinearität zu Problemen bei der Modellschätzung und Ergebnisinterpretation führen kann (Grewal et al., 2004;Jagpal, 1982;Marsh et al., 2004)</p>
        <p>Um effektive Politikentscheidungen zu treffen und aktuellen Herausforderungen zu begegnen, ist die EU auf politische Legitimität angewiesen. Hierfür ist die EU insbesondere auf das Wohlwollen und die Unterstützung ihrer politischen Subjekte, also der Bürger*innen angewiesen: "Governance can be considered legitimate in so far as its subjects regard it as proper and deserving of support" (Gurr, 1971, S. 185). Dabei wurde von Scharpf (1999) zunächst zwischen der Legitimität des Inputs und des Outputs unterschieden. Gemäß V. A. Schmidt (2013) wird Input-Legitimität wie folgt beschrieben: "Responsiveness to citizen concerns as a result of participation by the people" (V. A. Schmidt, 2013, S. 2, Hervorh. im Orig.). Sie ist mithin abhängig von freien und fairen Wahlen, hoher Wahlbeteiligung und einem lebhaften politischen Diskurs der Öffentlichkeit (Scharpf, 1999). Output-Legitimität meint hingegen Folgendes: "The effectiveness of the EU's policy outcomes for the people" (V. A. Schmidt, 2013, S. 2).Um effektive Politikentscheidungen zu treffen und aktuellen Herausforderungen zu begegnen, ist die EU auf politische Legitimität angewiesen. Hierfür ist die EU insbesondere auf das Wohlwollen und die Unterstützung ihrer politischen Subjekte, also der Bürger*innen angewiesen: "Governance can be considered legitimate in so far as its subjects regard it as proper and deserving of support" (Gurr, 1971, S. 185). Dabei wurde von Scharpf (1999) zunächst zwischen der Legitimität des Inputs und des Outputs unterschieden. Gemäß V. A. Schmidt (2013) wird Input-Legitimität wie folgt beschrieben: "Responsiveness to citizen concerns as a result of participation by the people" (V. A. Schmidt, 2013, S. 2, Hervorh. im Orig.). Sie ist mithin abhängig von freien und fairen Wahlen, hoher Wahlbeteiligung und einem lebhaften politischen Diskurs der Öffentlichkeit (Scharpf, 1999). Output-Legitimität meint hingegen Folgendes: "The effectiveness of the EU's policy outcomes for the people" (V. A. Schmidt, 2013, S. 2).</p>
        <p>Dies betrifft die tatsächliche Fähigkeit der EU, durch ihr politisches Wirken Herausforderungen wie die Sicherung von Frieden, Umweltschutz und wirtschaftlichem Wohlstand zu erreichen (Føllesdal, 2006). Schließlich wird auch noch die Throughput-Legitimität ergänzt, die auf die Rechenschaftspflicht, Wirksamkeit und Transparenz der politischen Entscheidungstragenden im Entscheidungsprozess abstellt (V. A. Schmidt, 2013;V. A. Schmidt &amp; Wood, 2019;Steffek, 2019). Diese Legitimitätsdimension stellt mithin folgende Anforderung an den Entscheidungsprozess: "Inclusiveness and openness to consultation with the people" (V. A. Schmidt, 2013, S. 2, Hervorh. im Orig.).Dies betrifft die tatsächliche Fähigkeit der EU, durch ihr politisches Wirken Herausforderungen wie die Sicherung von Frieden, Umweltschutz und wirtschaftlichem Wohlstand zu erreichen (Føllesdal, 2006). Schließlich wird auch noch die Throughput-Legitimität ergänzt, die auf die Rechenschaftspflicht, Wirksamkeit und Transparenz der politischen Entscheidungstragenden im Entscheidungsprozess abstellt (V. A. Schmidt, 2013;V. A. Schmidt &amp; Wood, 2019;Steffek, 2019). Diese Legitimitätsdimension stellt mithin folgende Anforderung an den Entscheidungsprozess: "Inclusiveness and openness to consultation with the people" (V. A. Schmidt, 2013, S. 2, Hervorh. im Orig.).</p>
        <p>Mit Blick auf den europäischen Integrationsprozess wurde vielfach über die mangelnde politische Legitimität der EU und ihrer politischen Entscheidungen diskutiert, wobei demokratische Defizite sowie das Fehlen einer europäischen Identität und einer gesamt-europäischen Öffentlichkeit als Gründe für eine Legitimitätskrise der EU angeführt wurden (Føllesdal &amp; Hix, 2006;Habermas, 2009).Mit Blick auf den europäischen Integrationsprozess wurde vielfach über die mangelnde politische Legitimität der EU und ihrer politischen Entscheidungen diskutiert, wobei demokratische Defizite sowie das Fehlen einer europäischen Identität und einer gesamt-europäischen Öffentlichkeit als Gründe für eine Legitimitätskrise der EU angeführt wurden (Føllesdal &amp; Hix, 2006;Habermas, 2009).</p>
        <p>Vor dem Hintergrund dieser Legitimitätskrise der EU gibt es Bestrebungen innerhalb der EU-Institutionen, dem wahrgenommenen Legitimitätsdefizit durch das sogenannte ‚Evidence-based Policy-Making' zu begegnen, was sich mit evidenzbasierter Politikgestaltung übersetzen lässt. "Against the backdrop of multiple crises, policymakers seem ever more inclined to legitimize specific ways of action by referring to 'hard' scientific evidence suggesting that a particular initiative will eventually yield the desired outcomes" (Rieder &amp; Simon, 2016, S. 1). Politische Entscheidungen und Programme werden hierbei also auf Grundlage wissenschaftlicher Erkenntnis begründet. Dies geht einher mit der in dieser Arbeit diskutierten Durchdringung der Gesellschaft mit digitaler Computertechnologie, bei der Unmengen von digitalen Daten erzeugt und gespeichert werden. Zur Erinnerung: Diesen als Big Data bezeichneten digitalen Daten werden große Potentiale für einen Erkenntnisgewinn zugeschrieben, der eben auch jenem in dieser Arbeit thematisierten Glauben an Big Data zugrunde liegt und der auch mit Blick auf die evidenzbasierte Politikgestaltung zum Tragen kommt. Es liegt daher nahe, diese Big Data auch aus Sicht der EU als ein wichtiges Gut im Rahmen evidenzbasierter Politikgestaltung zu begreifen, die nunmehr datenbasiert getroffen werden können (Esty &amp; Rushing, 2007;Giest, 2017;Poel et al., 2018). So hat bspw. die Europäische Kommission die Initiative Data4Policy mit folgender Überzeugung ins Leben gerufen: "Data technologies are amongst the valuable tools that policymakers have at hand for informing the policy process, Studie 2 -Die Auswirkungen der … from identifying issues, to designing their intervention and monitoring results" (Europäische Kommission, 2017a, § 1).Vor dem Hintergrund dieser Legitimitätskrise der EU gibt es Bestrebungen innerhalb der EU-Institutionen, dem wahrgenommenen Legitimitätsdefizit durch das sogenannte ‚Evidence-based Policy-Making' zu begegnen, was sich mit evidenzbasierter Politikgestaltung übersetzen lässt. "Against the backdrop of multiple crises, policymakers seem ever more inclined to legitimize specific ways of action by referring to 'hard' scientific evidence suggesting that a particular initiative will eventually yield the desired outcomes" (Rieder &amp; Simon, 2016, S. 1). Politische Entscheidungen und Programme werden hierbei also auf Grundlage wissenschaftlicher Erkenntnis begründet. Dies geht einher mit der in dieser Arbeit diskutierten Durchdringung der Gesellschaft mit digitaler Computertechnologie, bei der Unmengen von digitalen Daten erzeugt und gespeichert werden. Zur Erinnerung: Diesen als Big Data bezeichneten digitalen Daten werden große Potentiale für einen Erkenntnisgewinn zugeschrieben, der eben auch jenem in dieser Arbeit thematisierten Glauben an Big Data zugrunde liegt und der auch mit Blick auf die evidenzbasierte Politikgestaltung zum Tragen kommt. Es liegt daher nahe, diese Big Data auch aus Sicht der EU als ein wichtiges Gut im Rahmen evidenzbasierter Politikgestaltung zu begreifen, die nunmehr datenbasiert getroffen werden können (Esty &amp; Rushing, 2007;Giest, 2017;Poel et al., 2018). So hat bspw. die Europäische Kommission die Initiative Data4Policy mit folgender Überzeugung ins Leben gerufen: "Data technologies are amongst the valuable tools that policymakers have at hand for informing the policy process, Studie 2 -Die Auswirkungen der … from identifying issues, to designing their intervention and monitoring results" (Europäische Kommission, 2017a, § 1).</p>
        <p>Zusammen mit dem gerade aufkommenden öffentlichen Interesse und den großen Erwartungen an Anwendungen von KI geraten auch diese aktuellen Vorstöße zu datengetriebener evidenzbasierter Politikgestaltung und der diesbezüglichen Verwertung der großen digitalen Datenbestände in den Fokus der politischen Entscheidungstragenden. Rieder und Simon (2016) sehen die skizzierten Entwicklungen und das Vertrauen auf Grundlage datenbasierter Verfahren -der bei ihnen sogenannte ‚Datatrust' -bei der Politikgestaltung insbesondere auch im Lichte der Legitimitätskrise der EU. So kommen van Veenstra und Kotterink (2017) zu dem Ergebnis: "Data-driven policy making is not only expected to result in better policies, but also aims to create legitimacy" (S. 101).Zusammen mit dem gerade aufkommenden öffentlichen Interesse und den großen Erwartungen an Anwendungen von KI geraten auch diese aktuellen Vorstöße zu datengetriebener evidenzbasierter Politikgestaltung und der diesbezüglichen Verwertung der großen digitalen Datenbestände in den Fokus der politischen Entscheidungstragenden. Rieder und Simon (2016) sehen die skizzierten Entwicklungen und das Vertrauen auf Grundlage datenbasierter Verfahren -der bei ihnen sogenannte ‚Datatrust' -bei der Politikgestaltung insbesondere auch im Lichte der Legitimitätskrise der EU. So kommen van Veenstra und Kotterink (2017) zu dem Ergebnis: "Data-driven policy making is not only expected to result in better policies, but also aims to create legitimacy" (S. 101).</p>
        <p>Dabei werden automatisierte Anwendungen der Entscheidungsfindung auf Grundlage fortlaufender computerisierter Datenauswertung u. a. dafür eingesetzt, öffentliche Dienstleistungen zu erbringen, den Verkehrsfluss zu optimieren oder Sozialbetrug aufzudecken (AlgorithmWatch, 2019;Bansak et al., 2018;Poel et al., 2018). Mithin können Anwendungen des ADM potenziell zu einer Erhöhung der Legitimität in allen drei Dimensionen beitragen: Auf Seiten des Inputs, indem sie neue Formen demokratischer Beteiligung ermöglichen und neue Datenquellen und Eingabeformate erschließen, die zuvor keinen Eingang in den Entscheidungsprozess fanden. Bezüglich des Throughputs, indem sie den politischen Prozess standardisieren und so weniger anfällig für bestimmte menschliche Fehler machen, wobei auch auf eine verbesserte Transparenz automatisierter Prozesse hingewirkt wird (Fine Licht &amp; Fine Licht, 2020). Letztlich mit Blick auf den Output, indem sie die Qualität politischer Programme und Entscheidungen sowie deren Ergebnisse verbessern sollen (B. W. Wirtz et al., 2018).Dabei werden automatisierte Anwendungen der Entscheidungsfindung auf Grundlage fortlaufender computerisierter Datenauswertung u. a. dafür eingesetzt, öffentliche Dienstleistungen zu erbringen, den Verkehrsfluss zu optimieren oder Sozialbetrug aufzudecken (AlgorithmWatch, 2019;Bansak et al., 2018;Poel et al., 2018). Mithin können Anwendungen des ADM potenziell zu einer Erhöhung der Legitimität in allen drei Dimensionen beitragen: Auf Seiten des Inputs, indem sie neue Formen demokratischer Beteiligung ermöglichen und neue Datenquellen und Eingabeformate erschließen, die zuvor keinen Eingang in den Entscheidungsprozess fanden. Bezüglich des Throughputs, indem sie den politischen Prozess standardisieren und so weniger anfällig für bestimmte menschliche Fehler machen, wobei auch auf eine verbesserte Transparenz automatisierter Prozesse hingewirkt wird (Fine Licht &amp; Fine Licht, 2020). Letztlich mit Blick auf den Output, indem sie die Qualität politischer Programme und Entscheidungen sowie deren Ergebnisse verbessern sollen (B. W. Wirtz et al., 2018).</p>
        <p>Gleichzeitig finden sich in der Literatur jedoch auch immer wieder Beispiele, die auf die Nachteile von automatisierten Systemen hindeuten, bei denen KI-Anwendungen zum Einsatz kommen (Richardson, Schultz &amp; Southerland, 2019). Situationen, in denen Bürger*innen durch ADM fälschlicherweise des Betrugs beschuldigt werden, sie irrtümlich von Nahrungsmittelhilfeprogrammen ausgeschlossen oder ihre Sozialleistungen gekürzt werden, führen nicht nur zu folgenschweren Nachteilen bei den Betroffenen und verfehlen somit das Ziel, qualitativ hochwertige Ergebnisse zu produzieren. Sie führen zudem auch nicht zu effizienterer Entscheidungsfindung, wenn diese Fehlentscheidungen zu Klagewellen durch die Betroffenen führen. Letztlich sind hierdurch jedoch auch und insbesondere negative Effekte auf die wahrgenommene Legitimität der ADM-Anwendungen zu erwarten. Es bestehen allgemein im Hinblick auf die drei Dimensionen der Legitimität bei den Bürger*innen wichtige Herausforderungen, die jene ADM-Anwendungen mit sich bringen: Auf Seiten des Inputs haben die Betroffenen möglicherweise mangelnden Einblick und Einfluss auf die Kriterien oder Datenbanken, die Algorithmen zur Entscheidungsfindung nutzen. In Hinsicht auf den Throughput sind sie möglicherweise nicht in der Lage, die komplexe und oft undurchschaubare Logik zu verstehen, die den algorithmischen Vorhersagen, Empfehlungen oder Entscheidungen zugrunde liegt. So haben die Betroffenen in Bezug auf den Output möglicherweise grundlegende Zweifel, ob ADM-Anwendungen tatsächlich zu einer effizienteren Politik beitragen.Gleichzeitig finden sich in der Literatur jedoch auch immer wieder Beispiele, die auf die Nachteile von automatisierten Systemen hindeuten, bei denen KI-Anwendungen zum Einsatz kommen (Richardson, Schultz &amp; Southerland, 2019). Situationen, in denen Bürger*innen durch ADM fälschlicherweise des Betrugs beschuldigt werden, sie irrtümlich von Nahrungsmittelhilfeprogrammen ausgeschlossen oder ihre Sozialleistungen gekürzt werden, führen nicht nur zu folgenschweren Nachteilen bei den Betroffenen und verfehlen somit das Ziel, qualitativ hochwertige Ergebnisse zu produzieren. Sie führen zudem auch nicht zu effizienterer Entscheidungsfindung, wenn diese Fehlentscheidungen zu Klagewellen durch die Betroffenen führen. Letztlich sind hierdurch jedoch auch und insbesondere negative Effekte auf die wahrgenommene Legitimität der ADM-Anwendungen zu erwarten. Es bestehen allgemein im Hinblick auf die drei Dimensionen der Legitimität bei den Bürger*innen wichtige Herausforderungen, die jene ADM-Anwendungen mit sich bringen: Auf Seiten des Inputs haben die Betroffenen möglicherweise mangelnden Einblick und Einfluss auf die Kriterien oder Datenbanken, die Algorithmen zur Entscheidungsfindung nutzen. In Hinsicht auf den Throughput sind sie möglicherweise nicht in der Lage, die komplexe und oft undurchschaubare Logik zu verstehen, die den algorithmischen Vorhersagen, Empfehlungen oder Entscheidungen zugrunde liegt. So haben die Betroffenen in Bezug auf den Output möglicherweise grundlegende Zweifel, ob ADM-Anwendungen tatsächlich zu einer effizienteren Politik beitragen.</p>
        <p>Es ist folglich fraglich, ob und inwieweit ADM-Anwendungen im Rahmen der datengetriebenen evidenzbasierten Politikgestaltung als positiv oder negativ wahrgenommen werden und ob sie die erhoffte Steigerung politischer Legitimität der EU herbeiführen können. Wie üblich hängen hierbei Erfolg und Misserfolg des weitläufigen Einsatzes von ADM-Anwendungen auch von der öffentlichen Bewertung und Akzeptanz ab (Bauer, 1995b). Eine aktuelle Befragung von Rubio und Lastra (2019) liefert diesbezüglich folgendes Indiz: Rund ein Viertel aller Europäer sei derzeit eher oder voll und ganz dafür, KI wichtige Entscheidungen über die Geschicke des eigenen Landes anzuvertrauen. Das primäre Erkenntnisinteresse der vorliegenden Studie war es nun, zu untersuchen, inwieweit ADM auf Ebene der EU zu einer erhöhten Wahrnehmung politischer Input-, Throughputund Output-Legitimität führt. Um die Hypothese zu beantworten, wurde im Rahmen der experimentellen Befragungsstudie auch die BDGS-Skala eingesetzt, deren Einfluss auf die jeweiligen Legitimitätsdimensionen eingesetzter ADM-Anwendungen nachfolgend geprüft und berichtet wird. Dabei muss zur Prüfung der Einschätzung der Legitimität auch ein Szenario mit dem Status quo aufgenommen und durch die Befragten bewertet werden. In diesem werden politische Entscheidungen, wie es aktuell der Fall ist, von EU-Politiker*innen getroffen. In einer experimentellen Logik kann hier auch von der Kontrollgruppe gesprochen werden.Es ist folglich fraglich, ob und inwieweit ADM-Anwendungen im Rahmen der datengetriebenen evidenzbasierten Politikgestaltung als positiv oder negativ wahrgenommen werden und ob sie die erhoffte Steigerung politischer Legitimität der EU herbeiführen können. Wie üblich hängen hierbei Erfolg und Misserfolg des weitläufigen Einsatzes von ADM-Anwendungen auch von der öffentlichen Bewertung und Akzeptanz ab (Bauer, 1995b). Eine aktuelle Befragung von Rubio und Lastra (2019) liefert diesbezüglich folgendes Indiz: Rund ein Viertel aller Europäer sei derzeit eher oder voll und ganz dafür, KI wichtige Entscheidungen über die Geschicke des eigenen Landes anzuvertrauen. Das primäre Erkenntnisinteresse der vorliegenden Studie war es nun, zu untersuchen, inwieweit ADM auf Ebene der EU zu einer erhöhten Wahrnehmung politischer Input-, Throughputund Output-Legitimität führt. Um die Hypothese zu beantworten, wurde im Rahmen der experimentellen Befragungsstudie auch die BDGS-Skala eingesetzt, deren Einfluss auf die jeweiligen Legitimitätsdimensionen eingesetzter ADM-Anwendungen nachfolgend geprüft und berichtet wird. Dabei muss zur Prüfung der Einschätzung der Legitimität auch ein Szenario mit dem Status quo aufgenommen und durch die Befragten bewertet werden. In diesem werden politische Entscheidungen, wie es aktuell der Fall ist, von EU-Politiker*innen getroffen. In einer experimentellen Logik kann hier auch von der Kontrollgruppe gesprochen werden.</p>
        <p>Allerdings ist solch ein Anwendungsfall des ADM, in dem jegliche Entscheidungsfindung vollständig an eine KI-Anwendung ausgelagert wird, als Extremszenario zu sehen. Es ist unwahrscheinlich, dass demokratisch legitimierte politische Handlungsfreiheit direkt außer Kraft gesetzt und durch ein technisches System abgelöst wird. Vielmehr sollen Systeme der KI als unterstützende Anwendungen herangezogen werden, die eine Entscheidungsfindung befördern und vorbereiten. Es stellt sich mithin die Frage, inwieweit ADM akzeptiert wird, jedoch aus Sicht der Bürger*innen menschliche Aufsicht und Interventionsfähigkeit bewahrt bleiben sollten, also eine Form hybrider Entscheidungsfindung begrüßt wird. Auch in diesem Rahmen wird erwartet, dass Personen mit einem hohen Glauben an die Wirkmächtigkeit digitaler Daten einem solchen Anwendungsfall datenbasierter KI-Anwendungen eine höhere Legitimität zusprechen. Entsprechend wird folgende Hypothese aufgestellt: Informationen finden sich bei Kieslich et al. (2021). Im Rahmen dieser Befragungsstudie kam erneut die BDGS-Skala zum Einsatz. Aufgrund des explorativen Charakters der Studie und der sich mehrfach bestätigten Struktur des BDGS und der Ausprägung seiner Dimensionen wurde keine Präregistrierung durchgeführt. Im Vordergrund des Erkenntnisinteresses stand hier eine differenzierte Messung der Bedrohungswahrnehmung durch KI in Abhängigkeit von den Funktionen sowie den Einsatzgebieten der KI. Ausgangspunkt ist also die Analyse einer affektiven Komponente der Einstellung gegenüber datenverarbeitender KI (Maio et al., 2018). Geht es im Rahmen der Mensch-Maschine-Interaktion um Affekte, so wird häufig auf eine Bedrohungswahrnehmung und hierauf begründete Ängste Bezug genommen: So untersucht bspw. auch die Technikakzeptanzforschung Bedrohungspotentiale und durch sie ausgelöste Ängste nicht nur im Hinblick auf Großtechnologien wie Atomkraft, Nano-oder Biotechnologie, sondern insbesondere auch auf Computertechnik (Bauer, 1995a). 4 Mit Blick auf KI hat dabei unlängst die Arbeit von Liang und Lee (2017) die Ängste der US-Bürger*innen vor autonomen Robotern und KI untersucht. Sie kommen zu der Einschätzung, dass rund ein Viertel der Befragten in der repräsentativen Stichprobe aus dem Mai 2015 Angst vor KI äußert. Auch für Deutschland zeigen aktuelle Zahlen von Bitkom (2018b), dass neben überwiegender positiver Erwartungen an KI bei manchen Menschen in Deutschland auch etwaige Befürchtungen mit KI verbunden sind und ein Drittel der Befragten KI als Gefahr sieht.Allerdings ist solch ein Anwendungsfall des ADM, in dem jegliche Entscheidungsfindung vollständig an eine KI-Anwendung ausgelagert wird, als Extremszenario zu sehen. Es ist unwahrscheinlich, dass demokratisch legitimierte politische Handlungsfreiheit direkt außer Kraft gesetzt und durch ein technisches System abgelöst wird. Vielmehr sollen Systeme der KI als unterstützende Anwendungen herangezogen werden, die eine Entscheidungsfindung befördern und vorbereiten. Es stellt sich mithin die Frage, inwieweit ADM akzeptiert wird, jedoch aus Sicht der Bürger*innen menschliche Aufsicht und Interventionsfähigkeit bewahrt bleiben sollten, also eine Form hybrider Entscheidungsfindung begrüßt wird. Auch in diesem Rahmen wird erwartet, dass Personen mit einem hohen Glauben an die Wirkmächtigkeit digitaler Daten einem solchen Anwendungsfall datenbasierter KI-Anwendungen eine höhere Legitimität zusprechen. Entsprechend wird folgende Hypothese aufgestellt: Informationen finden sich bei Kieslich et al. (2021). Im Rahmen dieser Befragungsstudie kam erneut die BDGS-Skala zum Einsatz. Aufgrund des explorativen Charakters der Studie und der sich mehrfach bestätigten Struktur des BDGS und der Ausprägung seiner Dimensionen wurde keine Präregistrierung durchgeführt. Im Vordergrund des Erkenntnisinteresses stand hier eine differenzierte Messung der Bedrohungswahrnehmung durch KI in Abhängigkeit von den Funktionen sowie den Einsatzgebieten der KI. Ausgangspunkt ist also die Analyse einer affektiven Komponente der Einstellung gegenüber datenverarbeitender KI (Maio et al., 2018). Geht es im Rahmen der Mensch-Maschine-Interaktion um Affekte, so wird häufig auf eine Bedrohungswahrnehmung und hierauf begründete Ängste Bezug genommen: So untersucht bspw. auch die Technikakzeptanzforschung Bedrohungspotentiale und durch sie ausgelöste Ängste nicht nur im Hinblick auf Großtechnologien wie Atomkraft, Nano-oder Biotechnologie, sondern insbesondere auch auf Computertechnik (Bauer, 1995a). 4 Mit Blick auf KI hat dabei unlängst die Arbeit von Liang und Lee (2017) die Ängste der US-Bürger*innen vor autonomen Robotern und KI untersucht. Sie kommen zu der Einschätzung, dass rund ein Viertel der Befragten in der repräsentativen Stichprobe aus dem Mai 2015 Angst vor KI äußert. Auch für Deutschland zeigen aktuelle Zahlen von Bitkom (2018b), dass neben überwiegender positiver Erwartungen an KI bei manchen Menschen in Deutschland auch etwaige Befürchtungen mit KI verbunden sind und ein Drittel der Befragten KI als Gefahr sieht.</p>
        <p>Es zeigt sich, dass etliche Bürger*innen eine Bedrohung durch KI und autonome Roboter äußern, also affektive Reaktionen durchaus relevant für Einstellungsbildung gegenüber KI sein können. Es ist daher notwendig, die Konsequenzen des BDGS auch und insbesondere in Verbindung mit den affektiven Wahrnehmungskomponenten von datenbasierter KI zu beleuchten. Es ist anzunehmen, dass die Prädisposition des BDGS je nach Ausprägung zu einer unterschiedlichen Bedrohungswahrnehmung führen könnte. Personen mit ausgeprägtem Glauben an die Potentiale von digitaler Datensammlung und -auswertung mögen auch hierauf aufbauende Computertechnik als weniger bedrohlich empfinden. Zunächst gilt es jedoch genauer herauszuarbeiten, warum und in welchem Zusammenhang genau Computertechnik im Form von KI und autonomen Robotern als Bedrohung empfunden werden könnte. Bauer (1995a) äußert im Rahmen der Forschung zu Computerphobie (die selbstverständlich weiter gefasst ist als bloße Angstgefühle) folgende Skepsis, die auch für die vorliegende Studie zur Skalenkonstruktion der Angstmessung zunächst in Betracht gezogen werden muss:Es zeigt sich, dass etliche Bürger*innen eine Bedrohung durch KI und autonome Roboter äußern, also affektive Reaktionen durchaus relevant für Einstellungsbildung gegenüber KI sein können. Es ist daher notwendig, die Konsequenzen des BDGS auch und insbesondere in Verbindung mit den affektiven Wahrnehmungskomponenten von datenbasierter KI zu beleuchten. Es ist anzunehmen, dass die Prädisposition des BDGS je nach Ausprägung zu einer unterschiedlichen Bedrohungswahrnehmung führen könnte. Personen mit ausgeprägtem Glauben an die Potentiale von digitaler Datensammlung und -auswertung mögen auch hierauf aufbauende Computertechnik als weniger bedrohlich empfinden. Zunächst gilt es jedoch genauer herauszuarbeiten, warum und in welchem Zusammenhang genau Computertechnik im Form von KI und autonomen Robotern als Bedrohung empfunden werden könnte. Bauer (1995a) äußert im Rahmen der Forschung zu Computerphobie (die selbstverständlich weiter gefasst ist als bloße Angstgefühle) folgende Skepsis, die auch für die vorliegende Studie zur Skalenkonstruktion der Angstmessung zunächst in Betracht gezogen werden muss:</p>
        <p>Most empirical research works with operational definitions of computer phobia [sic] using self-report rating scales. (…) However, a test score is an insufficient criterion for real 'cyberphobia'; it can at best efficiently reproduce a pre-existing expert judgement, which, as it seems, is more suggested by popular expectations, than by insisting on phenomenological evidence. (S. 102-105) Bauer verweist darauf, dass die meisten Phobien eine Prävalenzrate von bis 8 % für ein Jahr und 13 % über den Lebenszeitraum haben (1995a). Generell ist die Messung von Angst durch Selbstauskunft zwar möglich, jedoch grob und nicht unproblematisch (Hersen, 1973;Kogan &amp; Edelstein, 2004;Lanyon &amp; Manosevitz, 1966;Scherer, 2005). Angst äußert sich insbesondere durch ein körperliches Erleben, welches physiologische Reaktionen beinhaltet, die wie angemerkt nur eingeschränkt durch Selbstauskunft erhoben werden können. Zudem sollte sorgfältig zwischen Bedrohungsobjekt und seinem Bedrohungspotential, wahrgenommener Bedrohung und hierdurch bedingter Angst unterschieden werden (Freeman &amp; Freeman, 2012;Scherer, 2005). Nicht jede Bedrohungswahrnehmung löst auch zwingend Angst als emotionale Reaktion aus (Witte, 1992(Witte, , 1994)). Neben Fragen zur theoretischen Unterscheidung zwischen Bedrohung und Angst sowie der reliablen und validen Erhebung von empfundener Angst gibt es jedoch eine weitere mögliche Einschränkung der Studie 2 -Die Auswirkungen der … Reichweite der Befunde. Die durchaus hoch ausgeprägte Bedrohungswahrnehmung durch KI überrascht, hängt jedoch auch mit der vorliegenden Messung von Angst im Rahmen des Chapman Survey of American Fears zusammen (Liang &amp; Lee, 2017). Das Erhebungsinstrument legt seinen Schwerpunkt nur teilweise auf eine allgemeine Bedrohungswahrnehmung durch KI-Systeme: Einer der vier Indikatoren der Messung zielte explizit auf Roboter ab, die menschliche Arbeitsplätze ersetzen, und ein zweiter Indikator stellte auf das Vertrauen von anderen Personen in die Arbeit von KI ab. 5 Gerade in diesem Bereich werden wiederholt mögliche Zukunftsszenarien diskutiert, bei denen es mittelfristig zum Verlust einer großen Anzahl an Arbeitsplätzen und generell Konsequenzen für die Zukunft der Arbeit kommt (Bonin et al., 2015;Dengler &amp; Matthes, 2015;Ford, 2015;Frey &amp; Osborne, 2017;Hirsch-Kreinsen, 2015). Diese weitreichenden Prognosen finden anschließend Eingang in die Medienberichterstattung sowie die politische Debatte und können Ängste auslösen (Brynjolfsson &amp; McAfee, 2015;Grass &amp; Weber, 2016;Pellegrino, 2015). So äußerten bereits 2016 9 % der Berufstätigen in Deutschland Sorgen um ihren Arbeitsplatz (INSM, 2016). Die Verbreitung von Robotern in unterschiedlichen Branchen, gepaart mit einer zunehmenden medialen Aufmerksamkeit, wirft hier zum einen Fragen nach einer möglichen Veränderung der allgemeinen öffentlichen Wahrnehmung von künstlicher Intelligenz und autonomen Robotern auf (Gnambs &amp; Appel, 2018). Sie bedarf zum anderen jedoch weiterführender Ansätze, die eine differenziertere Analyse eben jener wahrgenommenen Bedrohungspotentiale ermöglicht und hierbei zwischen Anwendungen und Anwendungsgebieten unterscheidet. Diese Fragen drehen sich dann nicht immer um den Einfluss von Computertechnik auf menschliche Arbeit, sondern ganz allgemein um die Konsequenzen des Vordringens datenverarbeitender KI-Systeme auf Individuum und Gesellschaft in allen möglichen Lebensbereichen.Most empirical research works with operational definitions of computer phobia [sic] using self-report rating scales. (…) However, a test score is an insufficient criterion for real 'cyberphobia'; it can at best efficiently reproduce a pre-existing expert judgement, which, as it seems, is more suggested by popular expectations, than by insisting on phenomenological evidence. (S. 102-105) Bauer verweist darauf, dass die meisten Phobien eine Prävalenzrate von bis 8 % für ein Jahr und 13 % über den Lebenszeitraum haben (1995a). Generell ist die Messung von Angst durch Selbstauskunft zwar möglich, jedoch grob und nicht unproblematisch (Hersen, 1973;Kogan &amp; Edelstein, 2004;Lanyon &amp; Manosevitz, 1966;Scherer, 2005). Angst äußert sich insbesondere durch ein körperliches Erleben, welches physiologische Reaktionen beinhaltet, die wie angemerkt nur eingeschränkt durch Selbstauskunft erhoben werden können. Zudem sollte sorgfältig zwischen Bedrohungsobjekt und seinem Bedrohungspotential, wahrgenommener Bedrohung und hierdurch bedingter Angst unterschieden werden (Freeman &amp; Freeman, 2012;Scherer, 2005). Nicht jede Bedrohungswahrnehmung löst auch zwingend Angst als emotionale Reaktion aus (Witte, 1992(Witte, , 1994)). Neben Fragen zur theoretischen Unterscheidung zwischen Bedrohung und Angst sowie der reliablen und validen Erhebung von empfundener Angst gibt es jedoch eine weitere mögliche Einschränkung der Studie 2 -Die Auswirkungen der … Reichweite der Befunde. Die durchaus hoch ausgeprägte Bedrohungswahrnehmung durch KI überrascht, hängt jedoch auch mit der vorliegenden Messung von Angst im Rahmen des Chapman Survey of American Fears zusammen (Liang &amp; Lee, 2017). Das Erhebungsinstrument legt seinen Schwerpunkt nur teilweise auf eine allgemeine Bedrohungswahrnehmung durch KI-Systeme: Einer der vier Indikatoren der Messung zielte explizit auf Roboter ab, die menschliche Arbeitsplätze ersetzen, und ein zweiter Indikator stellte auf das Vertrauen von anderen Personen in die Arbeit von KI ab. 5 Gerade in diesem Bereich werden wiederholt mögliche Zukunftsszenarien diskutiert, bei denen es mittelfristig zum Verlust einer großen Anzahl an Arbeitsplätzen und generell Konsequenzen für die Zukunft der Arbeit kommt (Bonin et al., 2015;Dengler &amp; Matthes, 2015;Ford, 2015;Frey &amp; Osborne, 2017;Hirsch-Kreinsen, 2015). Diese weitreichenden Prognosen finden anschließend Eingang in die Medienberichterstattung sowie die politische Debatte und können Ängste auslösen (Brynjolfsson &amp; McAfee, 2015;Grass &amp; Weber, 2016;Pellegrino, 2015). So äußerten bereits 2016 9 % der Berufstätigen in Deutschland Sorgen um ihren Arbeitsplatz (INSM, 2016). Die Verbreitung von Robotern in unterschiedlichen Branchen, gepaart mit einer zunehmenden medialen Aufmerksamkeit, wirft hier zum einen Fragen nach einer möglichen Veränderung der allgemeinen öffentlichen Wahrnehmung von künstlicher Intelligenz und autonomen Robotern auf (Gnambs &amp; Appel, 2018). Sie bedarf zum anderen jedoch weiterführender Ansätze, die eine differenziertere Analyse eben jener wahrgenommenen Bedrohungspotentiale ermöglicht und hierbei zwischen Anwendungen und Anwendungsgebieten unterscheidet. Diese Fragen drehen sich dann nicht immer um den Einfluss von Computertechnik auf menschliche Arbeit, sondern ganz allgemein um die Konsequenzen des Vordringens datenverarbeitender KI-Systeme auf Individuum und Gesellschaft in allen möglichen Lebensbereichen.</p>
        <p>Es ist zu vermuten, dass es einen Unterschied macht, in welchem Rahmen und wofür KI eingesetzt wird. Dabei ist zum einen der Anwendungsbereich der KI gemeint, der im folgenden Abschnitt besprochen wird. Zum anderen ist es die Reichweite bzw. das Ausmaß, mit dem die Computertechnik in einer Situation eingesetzt wird und einen Einfluss auf das Bedrohungsempfinden nehmen kann. So unterscheidet das von Bitkom (2018a) herausgegebene Periodensystem der KI auf Basis der Vorarbeit von Hammond (2016) zwischen den Fähigkeiten Assess, Infer und Respond, welche grob übersetzt werden können in Beurteilen, Schlussfolgern und Reagieren. Diese Fähigkeiten von KI lassen sich im Rahmen verschiedener Funktionen nutzen (P. Hofmann et al., 2020). Mit Blick auf den tatsächlichen Anwendungsfall dürfen die Funktionen der KI allerdings nicht zu feinteilig unterschieden werden, da ein Grundverständnis, aber auch die Fähigkeit der Unterscheidung auf den Seiten des Laien möglich sein muss. Es ist fraglich, ob bspw. das Reagieren der KI-Systeme tatsächlich wie von P. Hofmann et al. (2020) vorgeschlagen von technisch unversierten Befragten wie folgt unterteilt werden kann:Es ist zu vermuten, dass es einen Unterschied macht, in welchem Rahmen und wofür KI eingesetzt wird. Dabei ist zum einen der Anwendungsbereich der KI gemeint, der im folgenden Abschnitt besprochen wird. Zum anderen ist es die Reichweite bzw. das Ausmaß, mit dem die Computertechnik in einer Situation eingesetzt wird und einen Einfluss auf das Bedrohungsempfinden nehmen kann. So unterscheidet das von Bitkom (2018a) herausgegebene Periodensystem der KI auf Basis der Vorarbeit von Hammond (2016) zwischen den Fähigkeiten Assess, Infer und Respond, welche grob übersetzt werden können in Beurteilen, Schlussfolgern und Reagieren. Diese Fähigkeiten von KI lassen sich im Rahmen verschiedener Funktionen nutzen (P. Hofmann et al., 2020). Mit Blick auf den tatsächlichen Anwendungsfall dürfen die Funktionen der KI allerdings nicht zu feinteilig unterschieden werden, da ein Grundverständnis, aber auch die Fähigkeit der Unterscheidung auf den Seiten des Laien möglich sein muss. Es ist fraglich, ob bspw. das Reagieren der KI-Systeme tatsächlich wie von P. Hofmann et al. (2020) vorgeschlagen von technisch unversierten Befragten wie folgt unterteilt werden kann:</p>
        <p>• "Decision-making, i. e., choosing between known, discrete alternatives • Generating, i. e., producing or creating something • Acting, i. e., executing goal-oriented actions (e.g., movement, navigate, control)" (P. Hofmann et al., 2020, S. 9).• "Decision-making, i. e., choosing between known, discrete alternatives • Generating, i. e., producing or creating something • Acting, i. e., executing goal-oriented actions (e.g., movement, navigate, control)" (P. Hofmann et al., 2020, S. 9).</p>
        <p>Dem Produzieren und der Bewegung liegen ja bspw. mitunter bereits getroffene Entscheidungen durch KI-Systeme zugrunde. Mit Blick auf den vorliegenden Untersuchungszusammenhang der Bedrohungswahrnehmung von KI-Systemen wurde daher zunächst vereinfacht unterschieden in die Erkennung/Identifikation von Mustern in den Daten und hierauf aufbauenden Vorhersagen für die Zukunft. Weiterhin besteht die Möglichkeit, dass die KI auf Basis der Mustererkennung und Vorhersage direkt eine Entscheidungsempfehlung abgibt oder gar die Entscheidung im Rahmen des ADM direkt selbst trifft (Burton et al., 2019;Lepri et al., 2018;Packin, 2019). Es wird davon ausgegangen, dass die unterschiedliche Reichweite und Konsequenz der Funktionen und die Autonomie des jeweiligen KI-Systems zu einer unterschiedlich hoch ausgeprägten Bedrohungswahrnehmung führen. Mit Blick auf die gebotene Sparsamkeit der Modellierung und der Erwartung, dass insbesondere die weitreichenden und konsequenzbehafteten Ergebnisse des Einsatzes der KI zu einer stärker ausgeprägten Bedrohungswahrnehmung führen, beschränkt sich die nachfolgende Analyse auf Empfehlungen und Entscheidungen durch KI. Erste Ergebnisse aus den Pre-Tests indizierten, dass die erhobenen Indikatoren bei diesen beiden Funktionen bessere Verteilungswerte aufwiesen, während bei den weniger weitreichenden Funktionen geringere und einseitig ausgeprägte Verteilungswerte der jeweiligen Indikatoren zu beobachten waren -die Bedrohungseinschätzung war zu gering und fast alle Befragten waren dieser Ansicht, so dass sich schiefe Verteilungen mit Boden-und Deckeneffekten abbildeten (Ho &amp; Yu, 2015). Im Folgenden werden daher nur die beiden Studie 2 -Die Auswirkungen der …Dem Produzieren und der Bewegung liegen ja bspw. mitunter bereits getroffene Entscheidungen durch KI-Systeme zugrunde. Mit Blick auf den vorliegenden Untersuchungszusammenhang der Bedrohungswahrnehmung von KI-Systemen wurde daher zunächst vereinfacht unterschieden in die Erkennung/Identifikation von Mustern in den Daten und hierauf aufbauenden Vorhersagen für die Zukunft. Weiterhin besteht die Möglichkeit, dass die KI auf Basis der Mustererkennung und Vorhersage direkt eine Entscheidungsempfehlung abgibt oder gar die Entscheidung im Rahmen des ADM direkt selbst trifft (Burton et al., 2019;Lepri et al., 2018;Packin, 2019). Es wird davon ausgegangen, dass die unterschiedliche Reichweite und Konsequenz der Funktionen und die Autonomie des jeweiligen KI-Systems zu einer unterschiedlich hoch ausgeprägten Bedrohungswahrnehmung führen. Mit Blick auf die gebotene Sparsamkeit der Modellierung und der Erwartung, dass insbesondere die weitreichenden und konsequenzbehafteten Ergebnisse des Einsatzes der KI zu einer stärker ausgeprägten Bedrohungswahrnehmung führen, beschränkt sich die nachfolgende Analyse auf Empfehlungen und Entscheidungen durch KI. Erste Ergebnisse aus den Pre-Tests indizierten, dass die erhobenen Indikatoren bei diesen beiden Funktionen bessere Verteilungswerte aufwiesen, während bei den weniger weitreichenden Funktionen geringere und einseitig ausgeprägte Verteilungswerte der jeweiligen Indikatoren zu beobachten waren -die Bedrohungseinschätzung war zu gering und fast alle Befragten waren dieser Ansicht, so dass sich schiefe Verteilungen mit Boden-und Deckeneffekten abbildeten (Ho &amp; Yu, 2015). Im Folgenden werden daher nur die beiden Studie 2 -Die Auswirkungen der …</p>
        <p>Funktionen der Empfehlung und der autonomen Entscheidung (ADM) durch die KI in den Blick genommen, da hier die größte Bedrohungswahrnehmung sowie ausreichende Varianz zwischen den Befragten vermutet werden.Funktionen der Empfehlung und der autonomen Entscheidung (ADM) durch die KI in den Blick genommen, da hier die größte Bedrohungswahrnehmung sowie ausreichende Varianz zwischen den Befragten vermutet werden.</p>
        <p>In Hinsicht auf die Bedrohungswahrnehmung von KI und autonomen Robotern ist auch zwischen den Anwendungsbereichen zu unterscheiden, in denen KI-Systeme eingesetzt werden. Hier lässt sich an das eingangs erwähnte Arbeitsmarkt-Beispiel anknüpfen. So spielen KI-Systeme mit Bezug auf die Ökonomie und wirtschaftliche Entwicklungen in der öffentlichen Diskussion eine große Rolle. Brennen et al. (2018) finden in einer Medieninhaltsanalyse der Berichterstattung in Großbritannien, dass fast 60 % aller Berichte auf kommerzielle KI-Anwendungen aus der Industrie abstellen. Diese werden dabei nicht immer als nur positiv diskutiert. Zwar werden in vielen Wirtschaftsbereichen mittel-und langfristig Nutzengewinne erwartet (Brynjolfsson et al., 2017). Jedoch lassen sich wie bereits angedeutet in einigen Branchen negative Konsequenzen gerade für die Beschäftigten in Niedriglohnstufen erwarten (Furman &amp; Seamans, 2019) (Topol, 2019). Diese Diskussion neuer Problemlagen im Rahmen der Einführung von KI-Systemen in unterschiedlichen Lebensbereichen macht deutlich, dass eine Analyse des wahrgenommenen Bedrohungspotentials auf Seiten der Bürger*innen immer einen jeweils spezifischen Zuschnitt haben muss und folglich auch standardisierte Erhebungsinstrumente flexibel an das jeweilige Forschungsinteresse anpassbar sein müssen. Deshalb wurde die Skalenentwicklung auch vorangetrieben, um eine verbesserte standardisierte Messung der Bedrohungswahrnehmung zu produzieren, die auf möglichst viele Kontexte angewandt werden kann. Getestet wurde die Skalenentwicklung für die drei aktuellen und relevanten Anwendungsbereiche des KI-Einsatzes in Medizin, Personalwesen und im Bankensektor.In Hinsicht auf die Bedrohungswahrnehmung von KI und autonomen Robotern ist auch zwischen den Anwendungsbereichen zu unterscheiden, in denen KI-Systeme eingesetzt werden. Hier lässt sich an das eingangs erwähnte Arbeitsmarkt-Beispiel anknüpfen. So spielen KI-Systeme mit Bezug auf die Ökonomie und wirtschaftliche Entwicklungen in der öffentlichen Diskussion eine große Rolle. Brennen et al. (2018) finden in einer Medieninhaltsanalyse der Berichterstattung in Großbritannien, dass fast 60 % aller Berichte auf kommerzielle KI-Anwendungen aus der Industrie abstellen. Diese werden dabei nicht immer als nur positiv diskutiert. Zwar werden in vielen Wirtschaftsbereichen mittel-und langfristig Nutzengewinne erwartet (Brynjolfsson et al., 2017). Jedoch lassen sich wie bereits angedeutet in einigen Branchen negative Konsequenzen gerade für die Beschäftigten in Niedriglohnstufen erwarten (Furman &amp; Seamans, 2019) (Topol, 2019). Diese Diskussion neuer Problemlagen im Rahmen der Einführung von KI-Systemen in unterschiedlichen Lebensbereichen macht deutlich, dass eine Analyse des wahrgenommenen Bedrohungspotentials auf Seiten der Bürger*innen immer einen jeweils spezifischen Zuschnitt haben muss und folglich auch standardisierte Erhebungsinstrumente flexibel an das jeweilige Forschungsinteresse anpassbar sein müssen. Deshalb wurde die Skalenentwicklung auch vorangetrieben, um eine verbesserte standardisierte Messung der Bedrohungswahrnehmung zu produzieren, die auf möglichst viele Kontexte angewandt werden kann. Getestet wurde die Skalenentwicklung für die drei aktuellen und relevanten Anwendungsbereiche des KI-Einsatzes in Medizin, Personalwesen und im Bankensektor.</p>
        <p>Im Rahmen dieser Arbeit wird das BDGS als eine prädispositive Kognition der Bürger*innen behandelt, deren Ausprägung einen Einfluss auf Einstellungen und Verhalten in allen Bereichen hat, in denen digitale Technologien wie bspw. die KI im Entstehungs-und Verwertungskontext von digitalen Daten Anwendung finden. So ist auch mit Blick auf die Untersuchung der Bedrohungswahrnehmung der Funktionen von KI und deren Einsatz in unterschiedlichen Anwendungsbereichen zu vermuten, dass das BDGS einen Einfluss auf die affektive Komponente von Einstellungen nimmt und mithin die Einschätzung der Bedrohung durch KI beeinflusst. Allerdings gibt es keine genauen Annahmen und Hinweise, die zu einer Hypothesenbildung führen, dass eine spezifische Dimension des BDGS (wie bspw. der erwartete individuelle Nutzen) sich stark auf die Bedrohungswahrnehmung auswirkt. Zumal auch hier mit Blick auf die Kontextunterscheidung Unterschiede zu erwarten wären. Konkrete Annahmen würden daher lediglich einer intuitiven Erwartung an einen möglichen Zusammenhang entspringen und wären nicht deduktiv aus der theoretischen Beschreibung etwaiger zugrunde liegender Mechanismen abgeleitet. Mithin wird für den untersuchten Einfluss des BDGS als Prädisposition auf Seiten der Befragten auf deren Bedrohungswahrnehmung der KI folgende Hypothese aufgestellt: (Lünich &amp; Starke, 2020).Im Rahmen dieser Arbeit wird das BDGS als eine prädispositive Kognition der Bürger*innen behandelt, deren Ausprägung einen Einfluss auf Einstellungen und Verhalten in allen Bereichen hat, in denen digitale Technologien wie bspw. die KI im Entstehungs-und Verwertungskontext von digitalen Daten Anwendung finden. So ist auch mit Blick auf die Untersuchung der Bedrohungswahrnehmung der Funktionen von KI und deren Einsatz in unterschiedlichen Anwendungsbereichen zu vermuten, dass das BDGS einen Einfluss auf die affektive Komponente von Einstellungen nimmt und mithin die Einschätzung der Bedrohung durch KI beeinflusst. Allerdings gibt es keine genauen Annahmen und Hinweise, die zu einer Hypothesenbildung führen, dass eine spezifische Dimension des BDGS (wie bspw. der erwartete individuelle Nutzen) sich stark auf die Bedrohungswahrnehmung auswirkt. Zumal auch hier mit Blick auf die Kontextunterscheidung Unterschiede zu erwarten wären. Konkrete Annahmen würden daher lediglich einer intuitiven Erwartung an einen möglichen Zusammenhang entspringen und wären nicht deduktiv aus der theoretischen Beschreibung etwaiger zugrunde liegender Mechanismen abgeleitet. Mithin wird für den untersuchten Einfluss des BDGS als Prädisposition auf Seiten der Befragten auf deren Bedrohungswahrnehmung der KI folgende Hypothese aufgestellt: (Lünich &amp; Starke, 2020).</p>
        <p>Das Erkenntnisinteresse betraf den Anwendungsbereich datenintensiver KI-Anwendungen im Gesundheitswesen. Mit der Sammlung und Auswertung von Big Data sind insbesondere im Gesundheitswesen große Hoffnungen verbunden (Aitken et al., 2018;Bitkom Research, 2019). Nicht nur, dass ganz allgemein die medizinische Forschung von weitreichender Datensammlung und deren Auswertung profitiert. Auch die personalisierte, auf das Individuum abgestimmte Medizin ist auf dem Vormarsch (Eberbach, 2017). Gleichzeitig weckt die Sammlung großer digitaler Datenbestände Begehrlichkeiten der Versicherungsbranche (Braun &amp; Nürnberg, 2015). Es besteht die Erwartung, dass Versicherungstarife, die bislang nach dem Prinzip kollektiver Risikoübernahme funktionieren, noch feiner für die einzelnen Versicherten ausgesteuert oder gar Personen mit hohen Risiken gar nicht erst in einen Tarif aufgenommen werden. Während es in vielen Versicherungsklassen (wie z. B. in der Automobilversicherung) bereits weit fortgeschrittene Versicherungsmodelle gibt, bei denen laufend digitale Daten über die Versicherten erhoben werden (Arisov et al., 2019), experimentieren in Deutschland auch aufgrund strenger Datenschutzbestimmungen erst einige wenige Krankenkassen mit der Datensammlung, etwa mit verhaltensbasierten Versicherungstarifen zur Verhaltenssteuerung durch Bonussysteme (Braun &amp; Nürnberg, 2015;Weichert, 2014). Versicherte werden für die Teilnahme an Programmen belohnt, bei denen sie sich verpflichten, der Krankenversicherung ihre Daten bereitzustellen oder zumindest sich selbst zu beobachten, bspw. durch die Nutzung eines Fitnessarmbands, das laufend Daten über Vitalparameter erhebt, oder durch die manuelle Eingabe dieser Daten in eine Smartphone-App. Dies führt laut einer Stellungnahme des Deutschen Ethikrats (2017) zu der Sorge, dass die Annahme einer allen gemeinsamen Vulnerabilität gegenüber Krankheitsrisiken, die nicht sicher zu antizipieren sind, als Grundlage der Solidargemeinschaft in der gesetzlichen Krankenversicherung und der fairen Vertragsgestaltung in der privaten Krankenversicherung infrage gestellt werden könnte. Dann könnten Niedrigrisikogruppen verstärkt die Solidargemeinschaft verlassen, wodurch für Letztere erhebliche Mehrbelastungen entstünden. (S. 34)Das Erkenntnisinteresse betraf den Anwendungsbereich datenintensiver KI-Anwendungen im Gesundheitswesen. Mit der Sammlung und Auswertung von Big Data sind insbesondere im Gesundheitswesen große Hoffnungen verbunden (Aitken et al., 2018;Bitkom Research, 2019). Nicht nur, dass ganz allgemein die medizinische Forschung von weitreichender Datensammlung und deren Auswertung profitiert. Auch die personalisierte, auf das Individuum abgestimmte Medizin ist auf dem Vormarsch (Eberbach, 2017). Gleichzeitig weckt die Sammlung großer digitaler Datenbestände Begehrlichkeiten der Versicherungsbranche (Braun &amp; Nürnberg, 2015). Es besteht die Erwartung, dass Versicherungstarife, die bislang nach dem Prinzip kollektiver Risikoübernahme funktionieren, noch feiner für die einzelnen Versicherten ausgesteuert oder gar Personen mit hohen Risiken gar nicht erst in einen Tarif aufgenommen werden. Während es in vielen Versicherungsklassen (wie z. B. in der Automobilversicherung) bereits weit fortgeschrittene Versicherungsmodelle gibt, bei denen laufend digitale Daten über die Versicherten erhoben werden (Arisov et al., 2019), experimentieren in Deutschland auch aufgrund strenger Datenschutzbestimmungen erst einige wenige Krankenkassen mit der Datensammlung, etwa mit verhaltensbasierten Versicherungstarifen zur Verhaltenssteuerung durch Bonussysteme (Braun &amp; Nürnberg, 2015;Weichert, 2014). Versicherte werden für die Teilnahme an Programmen belohnt, bei denen sie sich verpflichten, der Krankenversicherung ihre Daten bereitzustellen oder zumindest sich selbst zu beobachten, bspw. durch die Nutzung eines Fitnessarmbands, das laufend Daten über Vitalparameter erhebt, oder durch die manuelle Eingabe dieser Daten in eine Smartphone-App. Dies führt laut einer Stellungnahme des Deutschen Ethikrats (2017) zu der Sorge, dass die Annahme einer allen gemeinsamen Vulnerabilität gegenüber Krankheitsrisiken, die nicht sicher zu antizipieren sind, als Grundlage der Solidargemeinschaft in der gesetzlichen Krankenversicherung und der fairen Vertragsgestaltung in der privaten Krankenversicherung infrage gestellt werden könnte. Dann könnten Niedrigrisikogruppen verstärkt die Solidargemeinschaft verlassen, wodurch für Letztere erhebliche Mehrbelastungen entstünden. (S. 34)</p>
        <p>Die angesprochenen Niedrigrisikogruppen wären -so die Annahme -eher geneigt, auf die neuen individualisierten Krankenversicherungstarife umzusteigen, da sie hiervon überproportional profitieren würden. Der Gedanke folgt dabei einer einfachen Kosten-Nutzen-Kalkulation im Sinne der Rational-Choice-Logik (Diekmann &amp; Voß, 2004a;Kunz, 2004), bei der "Akteure in Entscheidungssituationen unter Restriktionen versuchen, ihre Präferenzen möglichst gut zu realisieren" (Diekmann &amp; Voß, 2004b, S. 15). Personen, die einen Nutzen aus den neuen Studie 2 -Die Auswirkungen der …Die angesprochenen Niedrigrisikogruppen wären -so die Annahme -eher geneigt, auf die neuen individualisierten Krankenversicherungstarife umzusteigen, da sie hiervon überproportional profitieren würden. Der Gedanke folgt dabei einer einfachen Kosten-Nutzen-Kalkulation im Sinne der Rational-Choice-Logik (Diekmann &amp; Voß, 2004a;Kunz, 2004), bei der "Akteure in Entscheidungssituationen unter Restriktionen versuchen, ihre Präferenzen möglichst gut zu realisieren" (Diekmann &amp; Voß, 2004b, S. 15). Personen, die einen Nutzen aus den neuen Studie 2 -Die Auswirkungen der …</p>
        <p>Versicherungstarifen ziehen, etwa indem sie Geld sparen, könnten eher geneigt sein, in individualisierte Krankenversicherungsangebote zu wechseln.Versicherungstarifen ziehen, etwa indem sie Geld sparen, könnten eher geneigt sein, in individualisierte Krankenversicherungsangebote zu wechseln.</p>
        <p>Gleichzeitig geht das Ausmaß der Datensammlung und -auswertung von personenbezogenen Daten (seien es nun Daten über Vitalparameter o. ä.) mit großen Herausforderungen an den Datenschutz einher (Weichert, 2014). Zwar geben laut einer Untersuchung des Branchenverbands Bitkom (2019) aus dem Frühjahr 2019 zwei Drittel der Smartphone-Nutzer*innen an, Gesundheits-Apps auf dem Handy zu nutzen. Dennoch zeigt sich mit Blick auf die Ergebnisse der gleichen Umfrage, dass bspw. für die Befürworter*innen der elektronischen Patientenakte Datenhoheit und -sicherheit zu den wichtigsten Anforderungen zählen oder dass 71 % der Befragten bei sogenannten E-Rezepten Risiken beim Datenschutz und Datensicherheit sehen. Der Einfluss solcher Privatheitsbedenken auf die Datenpreisgabe und Selbstoffenbarung von Privatpersonen gibt daher immer wieder Anlass für dezidierte Forschung (Acquisti et al., 2015;Barth &amp; Jong, 2017;Baruh et al., 2017;Kokolakis, 2017). Auch hier spielen Kosten-Nutzen-Abwägungen eine Rolle, wobei mögliche oder bereits realisierte Nachteile bei Datensicherheit und Verletzungen der Privatsphäre sich auf der Kostenseite verbuchen lassen (Bol et al., 2018). Als vorrangiges Erkenntnisinteresse der Studie wurde daher der Einfluss des individuellen Profits und der Notwendigkeit der Preisgabe persönlicher Daten auf die Wechselbereitschaft in einen individualisierten datenbasierten Krankenversicherungstarif mittels eines Experimentaldesigns untersucht. Damit rückt in der vorliegenden Erhebung mit der Verhaltensintention der Wechselbereitschaft eine konative Komponente der Einstellung in den Fokus, deren Beeinflussung durch das BDGS fraglich ist.Gleichzeitig geht das Ausmaß der Datensammlung und -auswertung von personenbezogenen Daten (seien es nun Daten über Vitalparameter o. ä.) mit großen Herausforderungen an den Datenschutz einher (Weichert, 2014). Zwar geben laut einer Untersuchung des Branchenverbands Bitkom (2019) aus dem Frühjahr 2019 zwei Drittel der Smartphone-Nutzer*innen an, Gesundheits-Apps auf dem Handy zu nutzen. Dennoch zeigt sich mit Blick auf die Ergebnisse der gleichen Umfrage, dass bspw. für die Befürworter*innen der elektronischen Patientenakte Datenhoheit und -sicherheit zu den wichtigsten Anforderungen zählen oder dass 71 % der Befragten bei sogenannten E-Rezepten Risiken beim Datenschutz und Datensicherheit sehen. Der Einfluss solcher Privatheitsbedenken auf die Datenpreisgabe und Selbstoffenbarung von Privatpersonen gibt daher immer wieder Anlass für dezidierte Forschung (Acquisti et al., 2015;Barth &amp; Jong, 2017;Baruh et al., 2017;Kokolakis, 2017). Auch hier spielen Kosten-Nutzen-Abwägungen eine Rolle, wobei mögliche oder bereits realisierte Nachteile bei Datensicherheit und Verletzungen der Privatsphäre sich auf der Kostenseite verbuchen lassen (Bol et al., 2018). Als vorrangiges Erkenntnisinteresse der Studie wurde daher der Einfluss des individuellen Profits und der Notwendigkeit der Preisgabe persönlicher Daten auf die Wechselbereitschaft in einen individualisierten datenbasierten Krankenversicherungstarif mittels eines Experimentaldesigns untersucht. Damit rückt in der vorliegenden Erhebung mit der Verhaltensintention der Wechselbereitschaft eine konative Komponente der Einstellung in den Fokus, deren Beeinflussung durch das BDGS fraglich ist.</p>
        <p>Im Zuge des Aufkommens von KI-Systemen geraten gerade auch solche Anwendungen in den Blick, die im Bildungssektor erfolgversprechend eingesetzt werden können (Attaran et al., 2018;Daniel, 2015;Eynon, 2013). Die vorliegende Studie sollte ganz allgemein ergründen, inwieweit in der Studierendenschaft Akzeptanz für KI-basierte Zulassungsverfahren für Studiengänge besteht und welche Reaktionen mit der Einführung eines solchen Systems verbunden sind.Im Zuge des Aufkommens von KI-Systemen geraten gerade auch solche Anwendungen in den Blick, die im Bildungssektor erfolgversprechend eingesetzt werden können (Attaran et al., 2018;Daniel, 2015;Eynon, 2013). Die vorliegende Studie sollte ganz allgemein ergründen, inwieweit in der Studierendenschaft Akzeptanz für KI-basierte Zulassungsverfahren für Studiengänge besteht und welche Reaktionen mit der Einführung eines solchen Systems verbunden sind.</p>
        <p>Aufgrund limitierter Ressourcen und großem Andrang der Bewerber*innen auf eine unzureichende Anzahl an Studienplätzen in einigen Fächern sind hierzulande seit jeher viele Studiengänge zulassungsbeschränkt und es muss in Bereichen wie etwa der Medizin oder Psychologie ein Studienzulassungsverfahren durchlaufen werden. Je nach Fach ist dieses Zulassungsverfahren bundesweit geregelt oder wird direkt von der jeweiligen Hochschule selbst festgelegt. Aktuell gibt es hierbei vorher festgelegte Kriterien (bspw. die Abiturnote im Rahmen des Numerus Clausus), die je nach Zulassungsverfahren um eignungsdiagnostische Elemente ergänzt werden können, die unterschiedliche ‚harte' und ‚weiche' Kriterien (bspw. Wissenstests sowie Motivationsschreiben oder unstrukturierte Interviews) umfassen (Klusmann et al., 2011;Stemmler, 2005). 6 Dabei sind die entsprechenden Verfahren zeit-und ressourcenintensiv und gehen häufig zu Lasten des Forschungs-und Hochschulverwaltungspersonals. Denn die Einschätzung der Studieneignung wird bei letzterem Verfahren in der Gesamtschau vom Menschen abgegeben, der Bewerbungen überblicken und bewerten muss. Eine Automatisierung der Eignungseinschätzungen könnte dabei nicht nur aus Gründen des Bearbeitungsaufwandes von Vorteil sein. Denn die Eignung für ein Studium, die auf einer persönlicher Einschätzung der Bewerber*innen basiert, ist anfällig für Vorwürfe mangelnder Objektivität und kognitiver Verzerrungen im Rahmen der Bewertung (Dawes, 1971). Es wird mithin die Validität und Vorhersagekraft dieser Verfahren bemängelt und kontrovers diskutiert (Hell et al., 2007). 7 Gleichzeitig gibt es jedoch auch Hinweise darauf, dass die Durchführung von Interviews neben Studierfähigkeitstests von Seite der Studieninteressierten durchaus positiv bewertet wird (Hell &amp; Schuler, 2005). Kritisiert wird hier von Studierenden der mangelnde Informationsgehalt von Schulnoten und Leistungstests, welcher hingegen persönlichen Interviews zugeschrieben wird. Gleichzeitig haben Letztere jedoch eine negative affektive Wirkung, da Bewerbungsgespräche als "vergleichsweise wenig beruhigend und überdurchschnittlich unangenehm sowie als wenig durchschaubar eingeschätzt werden" (Hell &amp; Schuler, 2005, S. 370). Im Endeffekt bedeutet der derzeitige Zulassungsprozess viel Aufwand und Unsicherheit für die beteiligten Parteien, bei fraglichen Ergebnissen. Mithin wird hier oft diskutiert und erprobt Datenanalysesoftware einzusetzen (Maltz et al., 2007;Walczak &amp; Sincich, 1999).Aufgrund limitierter Ressourcen und großem Andrang der Bewerber*innen auf eine unzureichende Anzahl an Studienplätzen in einigen Fächern sind hierzulande seit jeher viele Studiengänge zulassungsbeschränkt und es muss in Bereichen wie etwa der Medizin oder Psychologie ein Studienzulassungsverfahren durchlaufen werden. Je nach Fach ist dieses Zulassungsverfahren bundesweit geregelt oder wird direkt von der jeweiligen Hochschule selbst festgelegt. Aktuell gibt es hierbei vorher festgelegte Kriterien (bspw. die Abiturnote im Rahmen des Numerus Clausus), die je nach Zulassungsverfahren um eignungsdiagnostische Elemente ergänzt werden können, die unterschiedliche ‚harte' und ‚weiche' Kriterien (bspw. Wissenstests sowie Motivationsschreiben oder unstrukturierte Interviews) umfassen (Klusmann et al., 2011;Stemmler, 2005). 6 Dabei sind die entsprechenden Verfahren zeit-und ressourcenintensiv und gehen häufig zu Lasten des Forschungs-und Hochschulverwaltungspersonals. Denn die Einschätzung der Studieneignung wird bei letzterem Verfahren in der Gesamtschau vom Menschen abgegeben, der Bewerbungen überblicken und bewerten muss. Eine Automatisierung der Eignungseinschätzungen könnte dabei nicht nur aus Gründen des Bearbeitungsaufwandes von Vorteil sein. Denn die Eignung für ein Studium, die auf einer persönlicher Einschätzung der Bewerber*innen basiert, ist anfällig für Vorwürfe mangelnder Objektivität und kognitiver Verzerrungen im Rahmen der Bewertung (Dawes, 1971). Es wird mithin die Validität und Vorhersagekraft dieser Verfahren bemängelt und kontrovers diskutiert (Hell et al., 2007). 7 Gleichzeitig gibt es jedoch auch Hinweise darauf, dass die Durchführung von Interviews neben Studierfähigkeitstests von Seite der Studieninteressierten durchaus positiv bewertet wird (Hell &amp; Schuler, 2005). Kritisiert wird hier von Studierenden der mangelnde Informationsgehalt von Schulnoten und Leistungstests, welcher hingegen persönlichen Interviews zugeschrieben wird. Gleichzeitig haben Letztere jedoch eine negative affektive Wirkung, da Bewerbungsgespräche als "vergleichsweise wenig beruhigend und überdurchschnittlich unangenehm sowie als wenig durchschaubar eingeschätzt werden" (Hell &amp; Schuler, 2005, S. 370). Im Endeffekt bedeutet der derzeitige Zulassungsprozess viel Aufwand und Unsicherheit für die beteiligten Parteien, bei fraglichen Ergebnissen. Mithin wird hier oft diskutiert und erprobt Datenanalysesoftware einzusetzen (Maltz et al., 2007;Walczak &amp; Sincich, 1999).</p>
        <p>Dabei sollen neuerdings Machine-Learning-Anwendungen auf einer breitgefächerten Datengrundlage die vielversprechendsten Studienbewerber*innen identifizieren. Insgesamt, so die Hoffnung, soll dieser Computereinsatz den Zulassungsprozess effektiver und nicht zuletzt fairer gestalten. Es wird davon ausgegangen, dass für die Akzeptanz solcher Verfahren durch die betroffenen Studienbewerber*innen insbesondere die wahrgenommene Fairness ausschlaggebend 6 "Mit der nach dem 7. Gesetz zur Änderung des Hochschulrahmengesetzes nunmehr gültigen 20-20-60-Regelung (20 % der Studienplätze gehen in den bundesweit zulassungsbeschränkten Studiengängen an die Abiturbesten, 20 % werden nach Wartezeit, 60 % von den Hochschulen im Rahmen eines Auswahlverfahrens selbst vergeben) bekommen die Universitäten nun eine aktivere Rolle im Zulassungs-und Auswahlverfahren zugewiesen" (Gold &amp; Souvignier, 2005, S. 214). 7 Für einen Überblick über die Debatte um Zulassungsverfahren siehe bspw. das Heft Nr. 2 (2005) des Fachjournals Psychologische Rundschau, das sich des Themas annimmt. Studie 2 -Die Auswirkungen der … ist (Marcinkowski &amp; Starke, 2019), die daher mit Blick auf die Fairnessperzeptionen der Studiereden auch im Fokus der vorliegenden Untersuchung stand (Marcinkowski et al., 2020). Neben allgemeinen Fairnessperzeptionen gegenüber dem Verfahren stellt dabei auch das Vertrauen in die Richtigkeit der Entscheidung eine Grundvoraussetzung für die positive Evaluation eines solchen Zulassungssystems dar. Hier ist davon auszugehen, dass die Voreinstellungen gegenüber technologischen Innovationen einen Einfluss auf die Erwartungshaltung haben, die technische Anwendung könne die gemachten Versprechen auch tatsächlich einlösen. In der Argumentationslinie dieser Arbeit bedeutet dies, dass bezüglich der datenbasierten KI-Anwendungen, die im Rahmen der Studienzulassung an der Hochschule zum Einsatz kommen können, die Bewertung dieses Einsatzes womöglich auch durch die generelle Wahrnehmung und Erwartungen an das Potential der Sammlung und Auswertung digitaler Daten beeinflusst ist.Dabei sollen neuerdings Machine-Learning-Anwendungen auf einer breitgefächerten Datengrundlage die vielversprechendsten Studienbewerber*innen identifizieren. Insgesamt, so die Hoffnung, soll dieser Computereinsatz den Zulassungsprozess effektiver und nicht zuletzt fairer gestalten. Es wird davon ausgegangen, dass für die Akzeptanz solcher Verfahren durch die betroffenen Studienbewerber*innen insbesondere die wahrgenommene Fairness ausschlaggebend 6 "Mit der nach dem 7. Gesetz zur Änderung des Hochschulrahmengesetzes nunmehr gültigen 20-20-60-Regelung (20 % der Studienplätze gehen in den bundesweit zulassungsbeschränkten Studiengängen an die Abiturbesten, 20 % werden nach Wartezeit, 60 % von den Hochschulen im Rahmen eines Auswahlverfahrens selbst vergeben) bekommen die Universitäten nun eine aktivere Rolle im Zulassungs-und Auswahlverfahren zugewiesen" (Gold &amp; Souvignier, 2005, S. 214). 7 Für einen Überblick über die Debatte um Zulassungsverfahren siehe bspw. das Heft Nr. 2 (2005) des Fachjournals Psychologische Rundschau, das sich des Themas annimmt. Studie 2 -Die Auswirkungen der … ist (Marcinkowski &amp; Starke, 2019), die daher mit Blick auf die Fairnessperzeptionen der Studiereden auch im Fokus der vorliegenden Untersuchung stand (Marcinkowski et al., 2020). Neben allgemeinen Fairnessperzeptionen gegenüber dem Verfahren stellt dabei auch das Vertrauen in die Richtigkeit der Entscheidung eine Grundvoraussetzung für die positive Evaluation eines solchen Zulassungssystems dar. Hier ist davon auszugehen, dass die Voreinstellungen gegenüber technologischen Innovationen einen Einfluss auf die Erwartungshaltung haben, die technische Anwendung könne die gemachten Versprechen auch tatsächlich einlösen. In der Argumentationslinie dieser Arbeit bedeutet dies, dass bezüglich der datenbasierten KI-Anwendungen, die im Rahmen der Studienzulassung an der Hochschule zum Einsatz kommen können, die Bewertung dieses Einsatzes womöglich auch durch die generelle Wahrnehmung und Erwartungen an das Potential der Sammlung und Auswertung digitaler Daten beeinflusst ist.</p>
        <p>Wenn sich die Richtigkeit der getroffenen Auswahlentscheidung nicht direkt prüfen lässt und eine Bewertung des Verfahrens mit Unsicherheit und gar dem Risiko behaftet ist, fälschlich nicht angenommen zu werden, bedarf es nach Mayer et al. (1995) Vertrauen in die Richtigkeit der von der Hochschule getroffenen Entscheidungen: "The definition of trust (…) is the willingness of a party to be vulnerable to the actions of another party based on the expectation that the other will perform a particular action important to the trustor, irrespective of the ability to monitor or control that other party" (S. 712). Werden Studierende mit einem KI-basierten Eignungsfeststellungsverfahren konfrontiert, dessen Entscheidung sie unterworfen sind und dessen konkreten Auswertungsprozess sie nicht unmittelbar einsehen und hinterfragen können, wird erwartet, dass diejenigen Personen mit ausgeprägtem Glauben an digitale Daten im Sinne dieser Arbeit auch ein höheres Vertrauen in die Richtigkeit der Entscheidung einer KI über Annahme oder Ablehnung für einen Studienplatz zeigen. Daher wird folgende Hypothese formuliert:8 H2.4a: Je ausgeprägter das BDGS, desto höher das Vertrauen in die Richtigkeit der KI-basierten Auswahlentscheidung.Wenn sich die Richtigkeit der getroffenen Auswahlentscheidung nicht direkt prüfen lässt und eine Bewertung des Verfahrens mit Unsicherheit und gar dem Risiko behaftet ist, fälschlich nicht angenommen zu werden, bedarf es nach Mayer et al. (1995) Vertrauen in die Richtigkeit der von der Hochschule getroffenen Entscheidungen: "The definition of trust (…) is the willingness of a party to be vulnerable to the actions of another party based on the expectation that the other will perform a particular action important to the trustor, irrespective of the ability to monitor or control that other party" (S. 712). Werden Studierende mit einem KI-basierten Eignungsfeststellungsverfahren konfrontiert, dessen Entscheidung sie unterworfen sind und dessen konkreten Auswertungsprozess sie nicht unmittelbar einsehen und hinterfragen können, wird erwartet, dass diejenigen Personen mit ausgeprägtem Glauben an digitale Daten im Sinne dieser Arbeit auch ein höheres Vertrauen in die Richtigkeit der Entscheidung einer KI über Annahme oder Ablehnung für einen Studienplatz zeigen. Daher wird folgende Hypothese formuliert:8 H2.4a: Je ausgeprägter das BDGS, desto höher das Vertrauen in die Richtigkeit der KI-basierten Auswahlentscheidung.</p>
        <p>Erwartungen an die Genauigkeit digitaler Daten sind dabei eine zentrale Überzeugung innerhalb des BDGS. Sie äußern sich in einem Glauben an die Objektivität und Exaktheit der Daten. Es muss daher davon ausgegangen werden, dass es eben diese Überzeugung von der Genauigkeit digitaler Daten ist, die in besonderem Maße zur angenommenen Richtigkeit der zu treffenden Auswahlentscheidung führt. Der erwartete Erklärungsbeitrag dieser Überzeugung könnte sich daher von den anderen Dimensionen des BDGS unterscheiden. Es wird daher folgende Frage aufgeworfen:Erwartungen an die Genauigkeit digitaler Daten sind dabei eine zentrale Überzeugung innerhalb des BDGS. Sie äußern sich in einem Glauben an die Objektivität und Exaktheit der Daten. Es muss daher davon ausgegangen werden, dass es eben diese Überzeugung von der Genauigkeit digitaler Daten ist, die in besonderem Maße zur angenommenen Richtigkeit der zu treffenden Auswahlentscheidung führt. Der erwartete Erklärungsbeitrag dieser Überzeugung könnte sich daher von den anderen Dimensionen des BDGS unterscheiden. Es wird daher folgende Frage aufgeworfen:</p>
        <p>Ausgehend vom Vertrauen in die Richtigkeit der getroffenen Zulassungsentscheidung interessiert nun aus Sicht der Hochschulen, die gedenken, ein KI-basiertes Zulassungsverfahren einzuführen, dessen Konsequenzen. Dabei rücken zwei Variablen in den Blick: die Reputation der Hochschule und die Reaktionen der Studierenden.Ausgehend vom Vertrauen in die Richtigkeit der getroffenen Zulassungsentscheidung interessiert nun aus Sicht der Hochschulen, die gedenken, ein KI-basiertes Zulassungsverfahren einzuführen, dessen Konsequenzen. Dabei rücken zwei Variablen in den Blick: die Reputation der Hochschule und die Reaktionen der Studierenden.</p>
        <p>Die Reputation der Hochschule in der Öffentlichkeit und insbesondere bei Studienbewerber*innen ist ein wichtiges Gut im Wettbewerb der Universitäten um den akademischen Nachwuchs. Ein guter Ruf lockt geeignete Kandidat*innen (Bowman &amp; Bastedo, 2009;Comm &amp; LaBay, 1997;Theus, 1993). Mit hohen Bewerbungszahlen gehen die Möglichkeit der Selektivität der besten Köpfe und die universitätsinterne Daseinsrechtfertigung von Studiengängen einher. Von der Ausschöpfung der Lehrkapazitäten hängen zugewiesene Stellenprozente und Mittelzuwendungen ab. Ein gutes Image bei den Bewerber*innen ist mithin ein gewichtiger Kredit, den die Universitäten und ihre Fakultäten nicht verspielen und möglichst erhöhen wollen (Habicht, 2009;Probst, 2008).Die Reputation der Hochschule in der Öffentlichkeit und insbesondere bei Studienbewerber*innen ist ein wichtiges Gut im Wettbewerb der Universitäten um den akademischen Nachwuchs. Ein guter Ruf lockt geeignete Kandidat*innen (Bowman &amp; Bastedo, 2009;Comm &amp; LaBay, 1997;Theus, 1993). Mit hohen Bewerbungszahlen gehen die Möglichkeit der Selektivität der besten Köpfe und die universitätsinterne Daseinsrechtfertigung von Studiengängen einher. Von der Ausschöpfung der Lehrkapazitäten hängen zugewiesene Stellenprozente und Mittelzuwendungen ab. Ein gutes Image bei den Bewerber*innen ist mithin ein gewichtiger Kredit, den die Universitäten und ihre Fakultäten nicht verspielen und möglichst erhöhen wollen (Habicht, 2009;Probst, 2008).</p>
        <p>Ein Vertrauen in die Richtigkeit der Entscheidung sollte dahingehend die Bewertung der Reputation der Hochschule besser ausfallen lassen bzw. sollte eine geringe Vertrauensneigung dazu führen, dass die Reputation der Hochschule sinkt. Nach Hosmer (1995) Protestneigung der Studierenden gegen die KI-basierte Auswahlentscheidung Auch die Reaktion der Studierenden ist für die Hochschulen von Interesse. Evoziert der Einsatz automatisierter Auswahlentscheidungen Kritik und Einwände in der Studierendenschaft? In diesem Zusammenhang sollte sich dabei ebenso ein Einfluss des BDGS feststellen lassen. Da Studierende mit ausgeprägtem Glauben an die digitalen Daten, auch die vermeintlichen Vorteile datenbasierter KI-Anwendungen zur Studienplatzvergabe wahrnehmen, sollten sie eine geringere Protestneigung zeigen. In diesem Zusammenhang wird auch der Einfluss des Vertrauens von Personen auf ihr Protestverhalten untersucht (Camaj, 2014;Moy et al., 2005;Moy &amp; Pfau, 2000). Dabei zeigt sich, dass sich hohes Vertrauen negativ auf die Protestneigung auswirkt (Moy et al., 2005;Nilson &amp; Nilson, 1980). Unter der Annahme, dass abhängig von der Ausprägung des BDGS und des Vertrauens in die Richtigkeit der Entscheidung Akzeptanz des KI-basierten Auswahlverfahrens besteht, ist letztlich zu erwarten, dass dies eine geringere Absicht des Protests gegen den Einsatz des KI-basierten Auswahlverfahrens durch die Hochschule nach sich zieht. Es wird mithin folgende Hypothese aufgestellt: H2.4c: Je ausgeprägter das BDGS, desto geringer die Protestneigung gegen eine KI-basierte Auswahlentscheidung.Ein Vertrauen in die Richtigkeit der Entscheidung sollte dahingehend die Bewertung der Reputation der Hochschule besser ausfallen lassen bzw. sollte eine geringe Vertrauensneigung dazu führen, dass die Reputation der Hochschule sinkt. Nach Hosmer (1995) Protestneigung der Studierenden gegen die KI-basierte Auswahlentscheidung Auch die Reaktion der Studierenden ist für die Hochschulen von Interesse. Evoziert der Einsatz automatisierter Auswahlentscheidungen Kritik und Einwände in der Studierendenschaft? In diesem Zusammenhang sollte sich dabei ebenso ein Einfluss des BDGS feststellen lassen. Da Studierende mit ausgeprägtem Glauben an die digitalen Daten, auch die vermeintlichen Vorteile datenbasierter KI-Anwendungen zur Studienplatzvergabe wahrnehmen, sollten sie eine geringere Protestneigung zeigen. In diesem Zusammenhang wird auch der Einfluss des Vertrauens von Personen auf ihr Protestverhalten untersucht (Camaj, 2014;Moy et al., 2005;Moy &amp; Pfau, 2000). Dabei zeigt sich, dass sich hohes Vertrauen negativ auf die Protestneigung auswirkt (Moy et al., 2005;Nilson &amp; Nilson, 1980). Unter der Annahme, dass abhängig von der Ausprägung des BDGS und des Vertrauens in die Richtigkeit der Entscheidung Akzeptanz des KI-basierten Auswahlverfahrens besteht, ist letztlich zu erwarten, dass dies eine geringere Absicht des Protests gegen den Einsatz des KI-basierten Auswahlverfahrens durch die Hochschule nach sich zieht. Es wird mithin folgende Hypothese aufgestellt: H2.4c: Je ausgeprägter das BDGS, desto geringer die Protestneigung gegen eine KI-basierte Auswahlentscheidung.</p>
        <p>Es ist darüber hinaus fraglich, inwieweit die Reputation der Hochschule und die Neigung zum Protest gegen die Auswahlentscheidung zusammenhängen. Es kann durchaus erwartet werden, dass es hier einen möglichen Zusammenhang gibt, allerdings ist dessen Richtung fraglich und wird im Rahmen des vorliegenden Forschungsinteresses nicht näher untersucht.Es ist darüber hinaus fraglich, inwieweit die Reputation der Hochschule und die Neigung zum Protest gegen die Auswahlentscheidung zusammenhängen. Es kann durchaus erwartet werden, dass es hier einen möglichen Zusammenhang gibt, allerdings ist dessen Richtung fraglich und wird im Rahmen des vorliegenden Forschungsinteresses nicht näher untersucht.</p>
        <p>Die zu testenden Zusammenhänge finden sich in einem in Abbildung 10.4 dargestellten und nachfolgend spezifizierten und geschätzten Modell, welches mit Hilfe einer Befragungsstudie geprüft wurde.Die zu testenden Zusammenhänge finden sich in einem in Abbildung 10.4 dargestellten und nachfolgend spezifizierten und geschätzten Modell, welches mit Hilfe einer Befragungsstudie geprüft wurde.</p>
        <p>Mit Blick auf die durchgeführten Studien wurden im Rahmen des Dissertationsprojekts erste Erfahrungen mit der Präregistrierung von empirischer Forschung gesammelt. Im Zuge der sogenannten Replikationskrise in den Sozialwissenschaften etabliert sich nach und nach die Präregistrierung von empirischen Studien (Dienlin et al., 2020;Humphreys et al., 2013;Simmons et al., 2011). Da viele Zusammenhänge bei der Wiederholung von Studien nicht erneut beobachtbar sind (Ioannidis, 2005), soll die Präregistrierung sicherstellen, dass das empirische Vorgehen, die Hypothesen sowie die Datenauswertung, die die Hypothesen prüft, im Voraus festgelegt werden. Dieses Vorgehen soll verhindern, dass Datensätze, Variablen und Konstrukte beliebig angepasst werden, bis sich erwartete, insbesondere positive Ergebnisse zeigen (Fanelli, 2010;Wagenmakers et al., 2012). Die jeweilige Untersuchungsanlage der Studien, in deren Rahmen Erhebung 2.1 EU und KI sowie die Erhebung 2.3 Krankenversicherung (hier Teilerhebung 2.3b) durchgeführt wurden, wurde vor der Datenerhebung einzeln präregistriert. Dabei wurden das Studiendesign samt Hypothesen, die erhobenen Variablen sowie das Vorgehen bei der Datenauswertung festgelegt. Nähere Informationen hierzu finden sich in den jeweils untenstehenden Quellenverweisen für die Studien. Studie 2 -Die Auswirkungen der … Darüber hinaus wurde speziell für die vorliegende Arbeit eine gemeinsame zusätzliche Präregistrierung von Erhebung 2.1 EU und KI und Erhebung 2.3 Krankenversicherung auf der Plattform der Open Science Foundation (OSF) durchgeführt, wobei zunächst lediglich zwei Hypothesen mit Blick auf die Ausprägung des BDGS formuliert wurden, die im nachfolgenden Abschnitt besprochen werden. Die Präregistrierung wurde am 23. April 2019 durchgeführt.9 Zu diesem Zeitpunkt waren die Daten von Erhebung 2.1 EU und KI zwar bereits erhoben, es wurde jedoch noch von niemandem auf den Datensatz zugegriffen. Es fand also noch keine Datenbereinigung oder sonstige Datenanalyse statt. Die Daten von Teilerhebung 2.3b Krankenversicherung waren zu diesem Zeitpunkt noch nicht erhoben.Mit Blick auf die durchgeführten Studien wurden im Rahmen des Dissertationsprojekts erste Erfahrungen mit der Präregistrierung von empirischer Forschung gesammelt. Im Zuge der sogenannten Replikationskrise in den Sozialwissenschaften etabliert sich nach und nach die Präregistrierung von empirischen Studien (Dienlin et al., 2020;Humphreys et al., 2013;Simmons et al., 2011). Da viele Zusammenhänge bei der Wiederholung von Studien nicht erneut beobachtbar sind (Ioannidis, 2005), soll die Präregistrierung sicherstellen, dass das empirische Vorgehen, die Hypothesen sowie die Datenauswertung, die die Hypothesen prüft, im Voraus festgelegt werden. Dieses Vorgehen soll verhindern, dass Datensätze, Variablen und Konstrukte beliebig angepasst werden, bis sich erwartete, insbesondere positive Ergebnisse zeigen (Fanelli, 2010;Wagenmakers et al., 2012). Die jeweilige Untersuchungsanlage der Studien, in deren Rahmen Erhebung 2.1 EU und KI sowie die Erhebung 2.3 Krankenversicherung (hier Teilerhebung 2.3b) durchgeführt wurden, wurde vor der Datenerhebung einzeln präregistriert. Dabei wurden das Studiendesign samt Hypothesen, die erhobenen Variablen sowie das Vorgehen bei der Datenauswertung festgelegt. Nähere Informationen hierzu finden sich in den jeweils untenstehenden Quellenverweisen für die Studien. Studie 2 -Die Auswirkungen der … Darüber hinaus wurde speziell für die vorliegende Arbeit eine gemeinsame zusätzliche Präregistrierung von Erhebung 2.1 EU und KI und Erhebung 2.3 Krankenversicherung auf der Plattform der Open Science Foundation (OSF) durchgeführt, wobei zunächst lediglich zwei Hypothesen mit Blick auf die Ausprägung des BDGS formuliert wurden, die im nachfolgenden Abschnitt besprochen werden. Die Präregistrierung wurde am 23. April 2019 durchgeführt.9 Zu diesem Zeitpunkt waren die Daten von Erhebung 2.1 EU und KI zwar bereits erhoben, es wurde jedoch noch von niemandem auf den Datensatz zugegriffen. Es fand also noch keine Datenbereinigung oder sonstige Datenanalyse statt. Die Daten von Teilerhebung 2.3b Krankenversicherung waren zu diesem Zeitpunkt noch nicht erhoben.</p>
        <p>Das Studiendesign samt Hypothesen für Erhebung 2.4 KI und Hochschule, die dort erhobenen Variablen und das Vorgehen bei der Datenauswertung wurden am 15. Juni 2019 bei OSF präregistriert. 10 Die Hypothesen bezüglich des BDGS wurde analog zu den Erhebungen 2.1 und 2.3 aufgestellt. Zudem wurde das finale Auswertungsmodell festgelegt, das nachfolgend beschrieben wird. Die Datenauswertung, die über die präregistrierten Hypothesen hinausgeht, ist nach strenger Auslegung als explorativ zu betrachten, folgt allerdings konsistent der Grundannahme der vorliegenden Arbeit, dass sich ein ausgeprägter Glaube positiv auf kognitive, affektive und konative Komponenten der Einstellungen auswirkt.Das Studiendesign samt Hypothesen für Erhebung 2.4 KI und Hochschule, die dort erhobenen Variablen und das Vorgehen bei der Datenauswertung wurden am 15. Juni 2019 bei OSF präregistriert. 10 Die Hypothesen bezüglich des BDGS wurde analog zu den Erhebungen 2.1 und 2.3 aufgestellt. Zudem wurde das finale Auswertungsmodell festgelegt, das nachfolgend beschrieben wird. Die Datenauswertung, die über die präregistrierten Hypothesen hinausgeht, ist nach strenger Auslegung als explorativ zu betrachten, folgt allerdings konsistent der Grundannahme der vorliegenden Arbeit, dass sich ein ausgeprägter Glaube positiv auf kognitive, affektive und konative Komponenten der Einstellungen auswirkt.</p>
        <p>Feldphasen, Sample und FragebogenaufbauFeldphasen, Sample und Fragebogenaufbau</p>
        <p>Die Feldphase lief vom 30. September bis zum 14. Oktober 2019. Rekrutiert wurden die Befragten auch in dieser Studie über das SoSci-Panel (D. J. Leiner, 2016). Die Befragten aus dem Panel-Pool wurden von den SoSci-Administratoren zur Befragung eingeladen, wobei 4919 Einladungen erfolgreich versendet werden konnten. Es gab keine Incentivierung oder Vergütung für die Teilnahme an der Studie. Insgesamt wurde der Fragebogen 1046-mal aufgerufen und 1026 Personen begannen mit der Befragung. Davon füllten 917 Teilnehmer*innen den Fragebogen vollständig aus, was einer Beantwortungsrate von 18,6 % entspricht. Davon wurden n = 26 Fälle von der Auswertung ausgeschlossen, da sie auch hier entweder mehr als 50 Maluspunkte für extrem schnelles Ausfüllen des Fragebogens erhielten oder den Fragebogen in weniger als fünf Minuten beantworteten. Studie 2 -Die Auswirkungen der … Dieses Zeitkriterium wurde durch Prüfung im Rahmen des Pre-Tests des Fragebogens als Mindestwert festgesetzt, der erreicht werden musste, um von sinnhafter Beantwortung ausgehen zu können. Letztendlich gingen n = 891 Fälle in die Auswertung ein. Die Geschlechtsverteilung ist mit 50.0 % Frauen, 49.2 % Männer sowie 0.8 % Befragten, die sich der diversen Geschlechtskategorie zuordnen, im Gesamtsample und auch in den einzelnen Gruppen ausgeglichen. Das Durchschnittsalter betrug 46 Jahre (SD = 15.66). Aufgrund der demografischen Struktur des Online-Access-Panels von SoSci haben 82 % der Befragten mindestens den Bildungsabschluss Abitur.Die Feldphase lief vom 30. September bis zum 14. Oktober 2019. Rekrutiert wurden die Befragten auch in dieser Studie über das SoSci-Panel (D. J. Leiner, 2016). Die Befragten aus dem Panel-Pool wurden von den SoSci-Administratoren zur Befragung eingeladen, wobei 4919 Einladungen erfolgreich versendet werden konnten. Es gab keine Incentivierung oder Vergütung für die Teilnahme an der Studie. Insgesamt wurde der Fragebogen 1046-mal aufgerufen und 1026 Personen begannen mit der Befragung. Davon füllten 917 Teilnehmer*innen den Fragebogen vollständig aus, was einer Beantwortungsrate von 18,6 % entspricht. Davon wurden n = 26 Fälle von der Auswertung ausgeschlossen, da sie auch hier entweder mehr als 50 Maluspunkte für extrem schnelles Ausfüllen des Fragebogens erhielten oder den Fragebogen in weniger als fünf Minuten beantworteten. Studie 2 -Die Auswirkungen der … Dieses Zeitkriterium wurde durch Prüfung im Rahmen des Pre-Tests des Fragebogens als Mindestwert festgesetzt, der erreicht werden musste, um von sinnhafter Beantwortung ausgehen zu können. Letztendlich gingen n = 891 Fälle in die Auswertung ein. Die Geschlechtsverteilung ist mit 50.0 % Frauen, 49.2 % Männer sowie 0.8 % Befragten, die sich der diversen Geschlechtskategorie zuordnen, im Gesamtsample und auch in den einzelnen Gruppen ausgeglichen. Das Durchschnittsalter betrug 46 Jahre (SD = 15.66). Aufgrund der demografischen Struktur des Online-Access-Panels von SoSci haben 82 % der Befragten mindestens den Bildungsabschluss Abitur.</p>
        <p>Die Befragten wurden per Zufall einer von drei Anwendungsbereichen von KI (Medizin, Personalwesen oder im Bankensektor) zugelost und bekamen dementsprechend angepasste Items zur Beantwortung vorgelegt (siehe Abschnitt 10.6.2, der Fragebogen findet sich in Anhang 3.5 im elektronischen Zusatzmaterial). Von den n = 891 Fällen fanden sich 301 Befragte in der Gruppe ‚Medizin', 294 in der Gruppe ‚Personalwesen' und 296 in der Gruppe ‚Bankensektor'. Die Platzierung auf der sechsten Fragebogenseite und die Formulierungen BDGS-Skala waren in den drei Konditionen gleich, lediglich die zwölf Items der Skala wurden zufällig in der präsentierten Reihenfolge rotiert.Die Befragten wurden per Zufall einer von drei Anwendungsbereichen von KI (Medizin, Personalwesen oder im Bankensektor) zugelost und bekamen dementsprechend angepasste Items zur Beantwortung vorgelegt (siehe Abschnitt 10.6.2, der Fragebogen findet sich in Anhang 3.5 im elektronischen Zusatzmaterial). Von den n = 891 Fällen fanden sich 301 Befragte in der Gruppe ‚Medizin', 294 in der Gruppe ‚Personalwesen' und 296 in der Gruppe ‚Bankensektor'. Die Platzierung auf der sechsten Fragebogenseite und die Formulierungen BDGS-Skala waren in den drei Konditionen gleich, lediglich die zwölf Items der Skala wurden zufällig in der präsentierten Reihenfolge rotiert.</p>
        <p>Zu Beginn des Jahres 2019 erfolgte in Teilerhebung 2.3a Krankenversicherung eine Befragung im Labor, bei der Studierende der HHU unter Laborbedingungen an der Befragung mit Experimentaldesign teilnahmen. Im April begann dann für Teilerhebung 2.3b Krankenversicherung eine zweite Befragung mit Experimentaldesign, die als Online-Befragung konzipiert war und für die wie in Erhebung 2.1 EU und KI und Erhebung 2.3 Krankenversicherung Befragte über das SoSci-Panel rekrutiert wurden (D. J. Leiner, 2016).Zu Beginn des Jahres 2019 erfolgte in Teilerhebung 2.3a Krankenversicherung eine Befragung im Labor, bei der Studierende der HHU unter Laborbedingungen an der Befragung mit Experimentaldesign teilnahmen. Im April begann dann für Teilerhebung 2.3b Krankenversicherung eine zweite Befragung mit Experimentaldesign, die als Online-Befragung konzipiert war und für die wie in Erhebung 2.1 EU und KI und Erhebung 2.3 Krankenversicherung Befragte über das SoSci-Panel rekrutiert wurden (D. J. Leiner, 2016).</p>
        <p>Die Feldphase der Teilerhebung 2.3a Krankenversicherung lief vom 9. Januar bis zum 21. Januar 2019. Rekrutiert wurden die Befragten auf dem Campus der HHU durch direkte Ansprache und das Verteilen von Werbeflyern. Für die Teilnahme an der Studie erhielten alle Probanden nach Abschluss der Befragung fünf Euro. Die Teilnahme erfolgte im Labor, so dass zeitgleich bis zu vier Probanden an einem jeweils gleich aufgebauten Computerterminal teilnehmen konnten. Insgesamt nahmen n = 164 Personen erfolgreich an der Laborbefragung teil und es wurden keine Fälle aus dem Datensatz vor der Auswertung entfernt.Die Feldphase der Teilerhebung 2.3a Krankenversicherung lief vom 9. Januar bis zum 21. Januar 2019. Rekrutiert wurden die Befragten auf dem Campus der HHU durch direkte Ansprache und das Verteilen von Werbeflyern. Für die Teilnahme an der Studie erhielten alle Probanden nach Abschluss der Befragung fünf Euro. Die Teilnahme erfolgte im Labor, so dass zeitgleich bis zu vier Probanden an einem jeweils gleich aufgebauten Computerterminal teilnehmen konnten. Insgesamt nahmen n = 164 Personen erfolgreich an der Laborbefragung teil und es wurden keine Fälle aus dem Datensatz vor der Auswertung entfernt.</p>
        <p>Die Feldphase der Teilerhebung 2.3b Krankenversicherung lief vom 24. April bis zum 24. Juni 2019. Rekrutiert wurden die Befragten über das SoSci-Panel (D. J. Leiner, 2016)Die Feldphase der Teilerhebung 2.3b Krankenversicherung lief vom 24. April bis zum 24. Juni 2019. Rekrutiert wurden die Befragten über das SoSci-Panel (D. J. Leiner, 2016)</p>
        <p>Die Feldphase der Befragung lief vom 17. bis zum 28. Juni 2019. Die Rekrutierung der Befragten erfolgte durch Aushänge und direkte Ansprache von Studierenden auf dem Universitätscampus der HHU Düsseldorf durch Studierende aus dem Masterseminar. Ziel war es, Studierende aller Fachrichtungen zu erreichen. Die Teilnahme wurde mit fünf Euro pro Person vergütet. Insgesamt haben n = 305 Studierende an der Laborbefragung teilgenommen. Lediglich ein Fall musste von der Analyse ausgeschlossen werden, da die Bearbeitungszeit unrealistisch kurz war, so dass n = 304 Fälle in die Auswertung eingingen (Kieslich et al., 2019).Die Feldphase der Befragung lief vom 17. bis zum 28. Juni 2019. Die Rekrutierung der Befragten erfolgte durch Aushänge und direkte Ansprache von Studierenden auf dem Universitätscampus der HHU Düsseldorf durch Studierende aus dem Masterseminar. Ziel war es, Studierende aller Fachrichtungen zu erreichen. Die Teilnahme wurde mit fünf Euro pro Person vergütet. Insgesamt haben n = 305 Studierende an der Laborbefragung teilgenommen. Lediglich ein Fall musste von der Analyse ausgeschlossen werden, da die Bearbeitungszeit unrealistisch kurz war, so dass n = 304 Fälle in die Auswertung eingingen (Kieslich et al., 2019).</p>
        <p>Die BDGS-Skala fand sich auf Seite 14 von 20 Fragebogenseiten (siehe Fragebogen im Anhang 3.7 im elektronischen Zusatzmaterial). Bevor die Befragten die Frageitems der BDGS-Skala beantworteten, wurden u. a. Fragen zum Einsatz von KI an der Hochschule gestellt, insbesondere die Bewertung solcher Anwendungen und die wahrgenommene Fairness der KI-gestützten Verfahrensweise, die im vorrangigen Erkenntnisinteresse der Studie standen. Es wurde hier darauf hingewiesen, dass KI Muster in den digitalen Daten erkennen, hieraus Schlüsse ziehen und Vorhersagen treffen, die im vorliegenden Fall wiederum eine unmittelbare Auswirkung für die Studierenden hätten. Es könnte mithin davon ausgegangen werden, dass diese Ordnung einen Ausstrahlungseffekt auf die Beantwortung der BDGS-Skala hatte, da die Befragung zuvor auf KI-Verfahren abstellte. Mit dem vorliegenden Untersuchungsdesign lässt sich diese experimentell zu klärende Frage zwar nicht prüfen. Sie ist aufgrund der angenommenen Stabilität der Kognitionen des BDGS jedoch an dieser Stelle zu vernachlässigen.Die BDGS-Skala fand sich auf Seite 14 von 20 Fragebogenseiten (siehe Fragebogen im Anhang 3.7 im elektronischen Zusatzmaterial). Bevor die Befragten die Frageitems der BDGS-Skala beantworteten, wurden u. a. Fragen zum Einsatz von KI an der Hochschule gestellt, insbesondere die Bewertung solcher Anwendungen und die wahrgenommene Fairness der KI-gestützten Verfahrensweise, die im vorrangigen Erkenntnisinteresse der Studie standen. Es wurde hier darauf hingewiesen, dass KI Muster in den digitalen Daten erkennen, hieraus Schlüsse ziehen und Vorhersagen treffen, die im vorliegenden Fall wiederum eine unmittelbare Auswirkung für die Studierenden hätten. Es könnte mithin davon ausgegangen werden, dass diese Ordnung einen Ausstrahlungseffekt auf die Beantwortung der BDGS-Skala hatte, da die Befragung zuvor auf KI-Verfahren abstellte. Mit dem vorliegenden Untersuchungsdesign lässt sich diese experimentell zu klärende Frage zwar nicht prüfen. Sie ist aufgrund der angenommenen Stabilität der Kognitionen des BDGS jedoch an dieser Stelle zu vernachlässigen.</p>
        <p>Operationalisierung der untersuchten KonstrukteOperationalisierung der untersuchten Konstrukte</p>
        <p>Alle Befragten beantworteten zwei Fragen, die als Manipulationsprüfung dienten, um zu prüfen, dass die manipulierten Unterschiede zwischen den Konditionen auch wahrgenommen wurden. Zum einen wurde die wahrgenommene Reichweite der technischen Automatisierung des Entscheidungsprozesses mittels der folgenden Frage bewertet: "Wie technisch automatisiert lief der Entscheidungsprozess ab?" (Antwortoptionen auf der 5-stufigen Likert-Skala von 1 "überhaupt nicht technisch automatisiert" zu 5 "sehr technisch automatisiert"). Die Ergebnisse zeigen einen signifikanten Unterschied zwischen den Konditionen (F(2, 524) = 389.71, p &lt; .001). Mit Hilfe eines Games-Howell Post-Hoc-Tests zeigte sich, dass die Befragten die unterschiedliche Reichweite der technischen Automatisierung wahrnahmen, kond HDM (M = 2.11; SD = .97), kond ADM (M = 4.52; SD = .77) und kond Hybrid (M = 4.16; SD = .80).Alle Befragten beantworteten zwei Fragen, die als Manipulationsprüfung dienten, um zu prüfen, dass die manipulierten Unterschiede zwischen den Konditionen auch wahrgenommen wurden. Zum einen wurde die wahrgenommene Reichweite der technischen Automatisierung des Entscheidungsprozesses mittels der folgenden Frage bewertet: "Wie technisch automatisiert lief der Entscheidungsprozess ab?" (Antwortoptionen auf der 5-stufigen Likert-Skala von 1 "überhaupt nicht technisch automatisiert" zu 5 "sehr technisch automatisiert"). Die Ergebnisse zeigen einen signifikanten Unterschied zwischen den Konditionen (F(2, 524) = 389.71, p &lt; .001). Mit Hilfe eines Games-Howell Post-Hoc-Tests zeigte sich, dass die Befragten die unterschiedliche Reichweite der technischen Automatisierung wahrnahmen, kond HDM (M = 2.11; SD = .97), kond ADM (M = 4.52; SD = .77) und kond Hybrid (M = 4.16; SD = .80).</p>
        <p>Zum anderen wurde der Einfluss der menschlichen politischen Akteure im dargestellten Prozess erfragt: "Welche Rolle spielten Politiker oder politische Institutionen in dem Entscheidungsprozess?" (Antwortoptionen auf der 5-stufigen Likert-Skala von 1 "überhaupt keine Rolle" zu 5 "eine sehr große Rolle"). Erneut fanden sich signifikante Unterschiede zwischen den drei Konditionen (F(2, 548) = 161.98, p &lt; .001). Mit Hilfe eines Games-Howell Post-Hoc-Tests zeigte sich, dass die Befragten die unterschiedliche Reichweite des menschlichen Einflusses der politischen Akteure und Institutionen wahrnahmen, kond HDM (M = 4.45; SD = .88), kond ADM (M = 2.63; SD = .99) und kond Hybrid (M = 3.41; SD = 1.04).Zum anderen wurde der Einfluss der menschlichen politischen Akteure im dargestellten Prozess erfragt: "Welche Rolle spielten Politiker oder politische Institutionen in dem Entscheidungsprozess?" (Antwortoptionen auf der 5-stufigen Likert-Skala von 1 "überhaupt keine Rolle" zu 5 "eine sehr große Rolle"). Erneut fanden sich signifikante Unterschiede zwischen den drei Konditionen (F(2, 548) = 161.98, p &lt; .001). Mit Hilfe eines Games-Howell Post-Hoc-Tests zeigte sich, dass die Befragten die unterschiedliche Reichweite des menschlichen Einflusses der politischen Akteure und Institutionen wahrnahmen, kond HDM (M = 4.45; SD = .88), kond ADM (M = 2.63; SD = .99) und kond Hybrid (M = 3.41; SD = 1.04).</p>
        <p>Die BDGS-Skala ging wie üblich mit allen vier Dimensionen in den Fragebogen mit ein und diese wurden als unabhängige Variablen herangezogen. Am Aufbau und an der Aufmachung der Skala wurde im Vergleich zu den vorangegangenen Studien nichts geändert.Die BDGS-Skala ging wie üblich mit allen vier Dimensionen in den Fragebogen mit ein und diese wurden als unabhängige Variablen herangezogen. Am Aufbau und an der Aufmachung der Skala wurde im Vergleich zu den vorangegangenen Studien nichts geändert.</p>
        <p>Abhängige Variablen -Die Input-, Throughput-und Output-Legitimität Die drei Dimensionen der Input-, der Throughput-und der Output-Legitimität wurden als abhängige Variablen modelliert und wie folgt gemessen:Abhängige Variablen -Die Input-, Throughput-und Output-Legitimität Die drei Dimensionen der Input-, der Throughput-und der Output-Legitimität wurden als abhängige Variablen modelliert und wie folgt gemessen:</p>
        <p>Die Input-Legitimität wurde auf Grundlage relevanter Vorarbeiten (Colquitt &amp; Rodell, 2015;Lindgren &amp; Persson, 2010;Persson et al., 2013) Diese Fragen wurden auf einer 5-stufigen Likert-Skala erhoben, bei der die Extrema mit "stimme nicht zu" (zugewiesener Wert 1) und "stimme zu" (zugewiesener Wert 5) beschriftet waren. Zudem gab es die Möglichkeit einer "weiß nicht"-Option. Die drei Items hatten eine hohe interne Konsistenz (α = .881; DEV = .715). Bei der Modellierung eines latenten Faktors, der auf die drei Indikatoren lädt, zeigten sich ausreichend hohe Faktorladungen (λ TL1 = .822, λ TL2 = .833, λ TL3 = .880). 13Mit Blick auf die Output-Legitimität unterscheidet die Literatur zum einen, inwieweit die vorgegebenen Ziele von politischen Entscheidungen erreicht werden (Lindgren &amp; Persson, 2010) und ob die Entscheidungen von den Bürger*innen auch begrüßt und für vorteilhaft befunden werden (Esaiasson et al., 2012;Werner &amp; Marien, 2018), wobei ein Zusammenhang zwischen beiden Elementen bestehen kann, aber nicht bestehen muss. Daher wird bei der Messung von Output-Legitimität zwischen der bewerteten Zielerreichung und der Akzeptanz der Entscheidung unterschieden. Diese Fragen wurden auf einer 5-stufigen Likert-Skala erhoben, bei der die Extrema mit "stimme nicht zu" (zugewiesener Wert 1) und "stimme zu" (zugewiesener Wert 5) beschriftet waren. Zudem gab es die Möglichkeit einer "weiß nicht"-Option. Die drei Items hatten eine hohe interne Konsistenz (α = .875; DEV = .726). Bei der Modellierung eines latenten Faktors, der auf die drei Indikatoren lädt, zeigen sich ausreichend hohe Faktorladungen (λ OL1 = .678, λ OL2 = .993, λ OL3 = .856). 16 Prüfung der Messäquivalenz Im vorliegenden Fall muss aufgrund der separaten Messung der Variablen in den drei Experimentalgruppen zunächst im Rahmen einer Mehrgruppen-Kausalanalyse (MGKA) die Messäquivalenz geprüft werden. Die MGKA erlaubt 14 Die Messung von Werner und Marien (2018) beinhaltet neben den Items OL1 und OL2 noch zwei Indikatoren, die Reaktanz indizieren. Diese wurden nicht aufgenommen und Item OL3 wurde selbst formuliert und ergänzt. 15 Item OL2 dient hier als Referenzindikator, da bei der nachfolgenden Prüfung auf Messäquivalenz festgestellt wurde, dass Item OL1 nicht messinvariant ist. 16 Da auch hier ein Messmodell mit einem auf die drei Indikatoren ladenden latenten Faktor vollständig identifiziert ist, wird keine Anpassungsgüte berichtet. Studie 2 -Die Auswirkungen der … die "die simultane Schätzung eines Kausalmodells über mehrere Gruppen hinweg" (Weiber &amp; Mühlhaus, 2014, S. 287, Hervorh. im Orig.). Für die Dimensionen des BDGS wird dies nachfolgend in Abschnitt 10.7 geprüft. An dieser Stelle soll daher lediglich auf die Prüfung der Messäquivalenz der als latente Faktoren abgebildeten Legitimitäts-Dimensionen eingegangen werden (siehe Tabelle 2.D im Anhang im elektronischen Zusatzmaterial).Die Input-Legitimität wurde auf Grundlage relevanter Vorarbeiten (Colquitt &amp; Rodell, 2015;Lindgren &amp; Persson, 2010;Persson et al., 2013) Diese Fragen wurden auf einer 5-stufigen Likert-Skala erhoben, bei der die Extrema mit "stimme nicht zu" (zugewiesener Wert 1) und "stimme zu" (zugewiesener Wert 5) beschriftet waren. Zudem gab es die Möglichkeit einer "weiß nicht"-Option. Die drei Items hatten eine hohe interne Konsistenz (α = .881; DEV = .715). Bei der Modellierung eines latenten Faktors, der auf die drei Indikatoren lädt, zeigten sich ausreichend hohe Faktorladungen (λ TL1 = .822, λ TL2 = .833, λ TL3 = .880). 13Mit Blick auf die Output-Legitimität unterscheidet die Literatur zum einen, inwieweit die vorgegebenen Ziele von politischen Entscheidungen erreicht werden (Lindgren &amp; Persson, 2010) und ob die Entscheidungen von den Bürger*innen auch begrüßt und für vorteilhaft befunden werden (Esaiasson et al., 2012;Werner &amp; Marien, 2018), wobei ein Zusammenhang zwischen beiden Elementen bestehen kann, aber nicht bestehen muss. Daher wird bei der Messung von Output-Legitimität zwischen der bewerteten Zielerreichung und der Akzeptanz der Entscheidung unterschieden. Diese Fragen wurden auf einer 5-stufigen Likert-Skala erhoben, bei der die Extrema mit "stimme nicht zu" (zugewiesener Wert 1) und "stimme zu" (zugewiesener Wert 5) beschriftet waren. Zudem gab es die Möglichkeit einer "weiß nicht"-Option. Die drei Items hatten eine hohe interne Konsistenz (α = .875; DEV = .726). Bei der Modellierung eines latenten Faktors, der auf die drei Indikatoren lädt, zeigen sich ausreichend hohe Faktorladungen (λ OL1 = .678, λ OL2 = .993, λ OL3 = .856). 16 Prüfung der Messäquivalenz Im vorliegenden Fall muss aufgrund der separaten Messung der Variablen in den drei Experimentalgruppen zunächst im Rahmen einer Mehrgruppen-Kausalanalyse (MGKA) die Messäquivalenz geprüft werden. Die MGKA erlaubt 14 Die Messung von Werner und Marien (2018) beinhaltet neben den Items OL1 und OL2 noch zwei Indikatoren, die Reaktanz indizieren. Diese wurden nicht aufgenommen und Item OL3 wurde selbst formuliert und ergänzt. 15 Item OL2 dient hier als Referenzindikator, da bei der nachfolgenden Prüfung auf Messäquivalenz festgestellt wurde, dass Item OL1 nicht messinvariant ist. 16 Da auch hier ein Messmodell mit einem auf die drei Indikatoren ladenden latenten Faktor vollständig identifiziert ist, wird keine Anpassungsgüte berichtet. Studie 2 -Die Auswirkungen der … die "die simultane Schätzung eines Kausalmodells über mehrere Gruppen hinweg" (Weiber &amp; Mühlhaus, 2014, S. 287, Hervorh. im Orig.). Für die Dimensionen des BDGS wird dies nachfolgend in Abschnitt 10.7 geprüft. An dieser Stelle soll daher lediglich auf die Prüfung der Messäquivalenz der als latente Faktoren abgebildeten Legitimitäts-Dimensionen eingegangen werden (siehe Tabelle 2.D im Anhang im elektronischen Zusatzmaterial).</p>
        <p>Hier zeigt die Prüfung der Messäquivalenz, dass die Voraussetzung der metrischen und skalaren Invarianz verletzt ist. Die Prüfung der Indikatoren offenbart, dass Item IL02 und OL1 nicht messinvariant sind. Daher wurden Identitätsrestriktionen für das Regressionsgewicht und die Regressionskonstante des Indikators freigegeben. Ein Chi-Quadrat-Differenztest zwischen dem unrestringierten Modell M1 und dem Modell mit partieller Messäquivalenz M4 zeigt, dass die Restriktionen nicht signifikant zu einer Verschlechterung der Anpassungsgüte führen ( X 2 = 21.715, df = 16; p = .153). Mithin besteht für die Messung der Input-Legitimität sowie der Output-Legitimität lediglich partielle Messinvarianz, was in den nachfolgend geprüften Modellen berücksichtigt wird.Hier zeigt die Prüfung der Messäquivalenz, dass die Voraussetzung der metrischen und skalaren Invarianz verletzt ist. Die Prüfung der Indikatoren offenbart, dass Item IL02 und OL1 nicht messinvariant sind. Daher wurden Identitätsrestriktionen für das Regressionsgewicht und die Regressionskonstante des Indikators freigegeben. Ein Chi-Quadrat-Differenztest zwischen dem unrestringierten Modell M1 und dem Modell mit partieller Messäquivalenz M4 zeigt, dass die Restriktionen nicht signifikant zu einer Verschlechterung der Anpassungsgüte führen ( X 2 = 21.715, df = 16; p = .153). Mithin besteht für die Messung der Input-Legitimität sowie der Output-Legitimität lediglich partielle Messinvarianz, was in den nachfolgend geprüften Modellen berücksichtigt wird.</p>
        <p>Unabhängige Variablen -die Dimensionen des BDGS Die BDGS-Skala wurde in unveränderter Form in den Fragebogen aufgenommen.Unabhängige Variablen -die Dimensionen des BDGS Die BDGS-Skala wurde in unveränderter Form in den Fragebogen aufgenommen.</p>
        <p>Abhängige Variablen -Operationalisierung des Konstruktes der Bedrohungswahrnehmung durch KI Da die Messung der Bedrohungswahrnehmung durch KI zwar standardisiert durchgeführt werden sollte, allerdings an den jeweiligen Untersuchungskontext angepasst werden musste, wurde die Ausarbeitung teil-standardisiert und mit Platzhaltern gearbeitet (Kieslich et al., 2021).Abhängige Variablen -Operationalisierung des Konstruktes der Bedrohungswahrnehmung durch KI Da die Messung der Bedrohungswahrnehmung durch KI zwar standardisiert durchgeführt werden sollte, allerdings an den jeweiligen Untersuchungskontext angepasst werden musste, wurde die Ausarbeitung teil-standardisiert und mit Platzhaltern gearbeitet (Kieslich et al., 2021).</p>
        <p>Zunächst sollte wie auch bei der BDGS-Skala ein Grundverständnis für KI und deren Einsatzmöglichkeiten hergestellt werden. Im direkten Anschluss zum Text der Vignette wurden die vier zuvor genannten Funktionen der KI unterschieden und es fanden sich für jede der Funktionen drei Frageitems als Indikatoren. In Tabelle 10.1 findet sich die Formulierung der Items samt den Platzhaltern für den jeweiligen Anwendungsbereich. [OBJEKT] erkennen.Zunächst sollte wie auch bei der BDGS-Skala ein Grundverständnis für KI und deren Einsatzmöglichkeiten hergestellt werden. Im direkten Anschluss zum Text der Vignette wurden die vier zuvor genannten Funktionen der KI unterschieden und es fanden sich für jede der Funktionen drei Frageitems als Indikatoren. In Tabelle 10.1 findet sich die Formulierung der Items samt den Platzhaltern für den jeweiligen Anwendungsbereich. [OBJEKT] erkennen.</p>
        <p>[OBJEKT] erfassen.[OBJEKT] erfassen.</p>
        <p>[OBJEKT] identifizieren.[OBJEKT] identifizieren.</p>
        <p>Entwicklungen von [OBJEKT] vorhersagen.Entwicklungen von [OBJEKT] vorhersagen.</p>
        <p>die Entwicklung von [OBJEKT] prognostizieren.die Entwicklung von [OBJEKT] prognostizieren.</p>
        <p>die Entwicklung von [OBJEKT] berechnet.die Entwicklung von [OBJEKT] berechnet.</p>
        <p>[HANDLUNG] empfehlen.[HANDLUNG] empfehlen.</p>
        <p>[HANDLUNG] vorschlagen.[HANDLUNG] vorschlagen.</p>
        <p>[HANDLUNG] nahelegen.[HANDLUNG] nahelegen.</p>
        <p>Decision-Making -Entscheidung über [HANDLUNG] entscheiden.Decision-Making -Entscheidung über [HANDLUNG] entscheiden.</p>
        <p>[HANDLUNG] festlegen.[HANDLUNG] festlegen.</p>
        <p>[HANDLUNG] vorgeben.[HANDLUNG] vorgeben.</p>
        <p>Für den Einsatz von KI-Systemen im medizinischen Bereich wurde folglich für die Erkennung das Objekt ‚Krankheit' eingefügt, die ‚Entwicklung von Krankheiten' vorhergesagt und eine ‚medizinische Behandlung' empfohlen oder bereits entschieden und festgelegt.Für den Einsatz von KI-Systemen im medizinischen Bereich wurde folglich für die Erkennung das Objekt ‚Krankheit' eingefügt, die ‚Entwicklung von Krankheiten' vorhergesagt und eine ‚medizinische Behandlung' empfohlen oder bereits entschieden und festgelegt.</p>
        <p>Für den Einsatz von KI-Systemen im Personalwesen wurde die Bewerbungssituation auf einen Arbeitsplatz als Beispiel gewählt. Folglich wurde für die Erkennung das Objekt ‚Eignung von Bewerber*innen' eingefügt, die ‚Arbeitsleistung von Bewerber*innen' vorhergesagt und eine ‚Einstellung von Bewerber*innen' empfohlen oder bereits entschieden und festgelegt.Für den Einsatz von KI-Systemen im Personalwesen wurde die Bewerbungssituation auf einen Arbeitsplatz als Beispiel gewählt. Folglich wurde für die Erkennung das Objekt ‚Eignung von Bewerber*innen' eingefügt, die ‚Arbeitsleistung von Bewerber*innen' vorhergesagt und eine ‚Einstellung von Bewerber*innen' empfohlen oder bereits entschieden und festgelegt.</p>
        <p>Für den Einsatz von KI-Systemen im Bankensektor wurde die KI-basierte Vergabe von Krediten durch Bankinstitute als Beispiel gewählt. Folglich wurde für die Erkennung das Objekt ‚Kreditwürdigkeit von Kunden' eingefügt, die ‚Ausfallwahrscheinlichkeit von Krediten' vorhergesagt und eine ‚Entscheidung über die Kreditvergabe' empfohlen oder die ‚Kreditvergabe' bereits direkt entschieden und festgelegt. Der finale Fragebogen mit der Umsetzung der Vorlage und des Zuschnitts auf den jeweiligen Anwendungsbereich findet sich in Anhang 3.5 im elektronischen Zusatzmaterial. Für die nachfolgende Analyse wurde, wie in Abschnitt 10.3.2 diskutiert, lediglich auf die letztgenannten Dimensionen der Entscheidungsempfehlung und der tatsächlichen Entscheidung durch die KI-Systeme abgestellt.Für den Einsatz von KI-Systemen im Bankensektor wurde die KI-basierte Vergabe von Krediten durch Bankinstitute als Beispiel gewählt. Folglich wurde für die Erkennung das Objekt ‚Kreditwürdigkeit von Kunden' eingefügt, die ‚Ausfallwahrscheinlichkeit von Krediten' vorhergesagt und eine ‚Entscheidung über die Kreditvergabe' empfohlen oder die ‚Kreditvergabe' bereits direkt entschieden und festgelegt. Der finale Fragebogen mit der Umsetzung der Vorlage und des Zuschnitts auf den jeweiligen Anwendungsbereich findet sich in Anhang 3.5 im elektronischen Zusatzmaterial. Für die nachfolgende Analyse wurde, wie in Abschnitt 10.3.2 diskutiert, lediglich auf die letztgenannten Dimensionen der Entscheidungsempfehlung und der tatsächlichen Entscheidung durch die KI-Systeme abgestellt.</p>
        <p>Unabhängige Variablen -die Manipulation des zu erwartenden Profits und der Notwendigkeit der Datenabgabe Als Ergebnis der vorgeblichen Berechnung eines individualisierten Tarifs wurde nach der zehn Sekunden langen simulierten Berechnung randomisiert eine Seite ausgespielt, die das jeweilige experimentelle Treatment enthielt.Unabhängige Variablen -die Manipulation des zu erwartenden Profits und der Notwendigkeit der Datenabgabe Als Ergebnis der vorgeblichen Berechnung eines individualisierten Tarifs wurde nach der zehn Sekunden langen simulierten Berechnung randomisiert eine Seite ausgespielt, die das jeweilige experimentelle Treatment enthielt.</p>
        <p>Zum einen wurde der zu erwartende finanzielle Vorteil variiert, der nachfolgend als der individuelle Profit bezeichnet wird. Entweder wurde den Befragten mitgeteilt, dass auf Grundlage ihrer Angaben eine Ersparnis von 19,74 % (Faktorstufe ‚Profit') möglich sei, oder 1,03 % (Faktorstufe ‚Kein Profit'). 17 Die jeweiligen Faktorstufen wurden mit 0 (‚Kein Profit' und ‚Keine Datenabgabe') oder 1 (‚Profit' und ‚Datenabgabe') in zwei entsprechenden Variablen im Datensatz dummy-codiert.Zum einen wurde der zu erwartende finanzielle Vorteil variiert, der nachfolgend als der individuelle Profit bezeichnet wird. Entweder wurde den Befragten mitgeteilt, dass auf Grundlage ihrer Angaben eine Ersparnis von 19,74 % (Faktorstufe ‚Profit') möglich sei, oder 1,03 % (Faktorstufe ‚Kein Profit'). 17 Die jeweiligen Faktorstufen wurden mit 0 (‚Kein Profit' und ‚Keine Datenabgabe') oder 1 (‚Profit' und ‚Datenabgabe') in zwei entsprechenden Variablen im Datensatz dummy-codiert.</p>
        <p>Es wurde eine Manipulationsprüfung durchgeführt, um zu prüfen, ob das Stimulusmaterial von den Befragten wahrgenommen und der Inhalt verstanden wurde. Wird bspw. der Nutzen variiert, sollte für Personen in der Kondition mit hohem Nutzen die Nutzenwahrnehmung auch entsprechend höher ausfallen als in der Kondition mit geringfügigem Nutzen. Allerdings ist hiermit noch nicht verifiziert, dass es tatsächlich zu einer Variation auf Seiten der unabhängigen Variable gekommen ist. Es ist lediglich die Voraussetzung geprüft, dass im Falle des Ausbleibens dieser beobachteten Variation zumindest ausgeschlossen werden kann, dass dies nicht an einer schwachen oder unverständlichen Manipulation liegt. Hierzu beantworteten die Befragten nach der Manipulation Fragen bezüglich des jeweils präsentierten Stimulusmaterials. Zum einen sollten die Probanden also den individuellen Nutzen bewerten ("Ich würde finanziell stark von dem für mich berechneten individualisierten Tarif profitieren"). 18 Zum anderen wurde die Notwendigkeit der Datenabgabe erfragt ("Ich wurde im Text explizit darauf hingewiesen, dass ich in Zukunft meine persönlichen Daten abgeben müsste"). 19 In Teilerhebung 2.3a Krankenversicherung nahmen die Befragten, denen ein hoher Nutzen ausgegeben wurde, diesen auch eher wahr (M = 3.53, SD = 1.03, n = 72) als die Befragten, denen eine geringfügiger Nutzen angezeigt wurde (M = 2.44, SD = 1.03, n = 77; t(147) = -6.372; p &lt; .001). Auch in Teilerhebung 2.3b Krankenversicherung war die Manipulation erfolgreich. Hier nahmen die Befragten, denen ein hoher Nutzen ausgegeben wurde, diesen auch eher wahr (M = 3.16, SD = 1.26, n = 203) als die Befragten, denen ein geringfügiger Nutzen angezeigt wurde (M = 1.98, SD = 1.12, n = 205; t(406) = -9.956; p &lt; .001). Für die Notwendigkeit der Datenabgabe zeigte sich, dass in Teilerhebung 2.3a Krankenversicherung die Befragten, denen in Verbindung mit dem Tarifangebot explizit die Datenabgabe auferlegt wurde, diese Notwendigkeit auch eher wahrgenommen haben (M = 3.22, SD = 1.30, n = 64) als die Befragten, die hierzu nicht explizit aufgefordert wurden (M = 2.88, SD = 1.31, n = 68). Allerdings ist dieser Unterschied hier statistisch nicht signifikant, t(130) = -1.478; p = .142. Um auszuschließen, dass dieser Umstand durch die Frageformulierung begründet ist, wurde diese noch einmal konkretisiert.71 In Teilerhebung 2.3b Krankenversicherung wurde die Notwendigkeit letztlich von den Befragten, die hierzu aufgefordert waren, eher wahrgenommen (M = 3.55, SD = 1.57, n = 183) als von den Befragten, die hierzu nicht explizit aufgefordert wurden (M = 2.31, SD = 1.49, n = 177). Der Unterschied ist signifikant, t(438) = -7.692; p &lt; .001).Es wurde eine Manipulationsprüfung durchgeführt, um zu prüfen, ob das Stimulusmaterial von den Befragten wahrgenommen und der Inhalt verstanden wurde. Wird bspw. der Nutzen variiert, sollte für Personen in der Kondition mit hohem Nutzen die Nutzenwahrnehmung auch entsprechend höher ausfallen als in der Kondition mit geringfügigem Nutzen. Allerdings ist hiermit noch nicht verifiziert, dass es tatsächlich zu einer Variation auf Seiten der unabhängigen Variable gekommen ist. Es ist lediglich die Voraussetzung geprüft, dass im Falle des Ausbleibens dieser beobachteten Variation zumindest ausgeschlossen werden kann, dass dies nicht an einer schwachen oder unverständlichen Manipulation liegt. Hierzu beantworteten die Befragten nach der Manipulation Fragen bezüglich des jeweils präsentierten Stimulusmaterials. Zum einen sollten die Probanden also den individuellen Nutzen bewerten ("Ich würde finanziell stark von dem für mich berechneten individualisierten Tarif profitieren"). 18 Zum anderen wurde die Notwendigkeit der Datenabgabe erfragt ("Ich wurde im Text explizit darauf hingewiesen, dass ich in Zukunft meine persönlichen Daten abgeben müsste"). 19 In Teilerhebung 2.3a Krankenversicherung nahmen die Befragten, denen ein hoher Nutzen ausgegeben wurde, diesen auch eher wahr (M = 3.53, SD = 1.03, n = 72) als die Befragten, denen eine geringfügiger Nutzen angezeigt wurde (M = 2.44, SD = 1.03, n = 77; t(147) = -6.372; p &lt; .001). Auch in Teilerhebung 2.3b Krankenversicherung war die Manipulation erfolgreich. Hier nahmen die Befragten, denen ein hoher Nutzen ausgegeben wurde, diesen auch eher wahr (M = 3.16, SD = 1.26, n = 203) als die Befragten, denen ein geringfügiger Nutzen angezeigt wurde (M = 1.98, SD = 1.12, n = 205; t(406) = -9.956; p &lt; .001). Für die Notwendigkeit der Datenabgabe zeigte sich, dass in Teilerhebung 2.3a Krankenversicherung die Befragten, denen in Verbindung mit dem Tarifangebot explizit die Datenabgabe auferlegt wurde, diese Notwendigkeit auch eher wahrgenommen haben (M = 3.22, SD = 1.30, n = 64) als die Befragten, die hierzu nicht explizit aufgefordert wurden (M = 2.88, SD = 1.31, n = 68). Allerdings ist dieser Unterschied hier statistisch nicht signifikant, t(130) = -1.478; p = .142. Um auszuschließen, dass dieser Umstand durch die Frageformulierung begründet ist, wurde diese noch einmal konkretisiert.71 In Teilerhebung 2.3b Krankenversicherung wurde die Notwendigkeit letztlich von den Befragten, die hierzu aufgefordert waren, eher wahrgenommen (M = 3.55, SD = 1.57, n = 183) als von den Befragten, die hierzu nicht explizit aufgefordert wurden (M = 2.31, SD = 1.49, n = 177). Der Unterschied ist signifikant, t(438) = -7.692; p &lt; .001).</p>
        <p>Unabhängige Variablen -die Dimensionen des BDGS Zusätzlich zu den Manipulationen wurde die BDGS-Skala in unveränderter Form in den Fragebogen aufgenommen.Unabhängige Variablen -die Dimensionen des BDGS Zusätzlich zu den Manipulationen wurde die BDGS-Skala in unveränderter Form in den Fragebogen aufgenommen.</p>
        <p>Option "weiß nicht", um einen Abbruch oder den Skalenmittelpunkt als Ausweichkategorie zu vermeiden. Um einen Bias zu vermeiden, wurden die entsprechenden Befragten nicht aus der Stichprobe entfernt (Aronow et al., 2019). 19 Aufgrund des nicht signifikanten Ergebnisses der Manipulationsprüfung wurde diese Frage in Erhebung 2.3b noch einmal spezifiziert und lautete hier "Ich wurde bei der Berechnung meines individualisierten Versicherungstarifs explizit darauf hingewiesen, dass ich in Zukunft meine persönlichen Daten abgeben müsste". Eine Veränderung des Stimulusmaterials selbst erfolgte jedoch nicht. Studie 2 -Die Auswirkungen der … Abhängige Variable -die Bereitschaft zum Wechsel in eine digitale individualisierte Krankenversicherung Mittels der folgenden Frage wurde die Bereitschaft zum Wechsel in die vorgestellte individualisierte Krankenversicherung erhoben: "Wären Sie bereit, auf Grundlage des gezeigten Angebots und seiner Konditionen, zur INDIVIDUA-Krankenversicherung zu wechseln?" Die Antwort erfolgte auf einer 5-stufigen Antwortskala, die wie folgt codiert wurde: 1 -"Ja, auf jeden Fall", 2 -"Eher ja", 3 -"Unentschieden", 4 -"Eher nein", sowie 5 -"Nein, auf keinen Fall". Für die Datenauswertung wurde die Variable anschließend invertiert, so dass hohe Werte eine hohe Wechselbereitschaft bedeuten (Erhebung 2.3a: M = 2.26, SD = 1.05; Erhebung 2.3b: M = 1.61, SD = .87).Option "weiß nicht", um einen Abbruch oder den Skalenmittelpunkt als Ausweichkategorie zu vermeiden. Um einen Bias zu vermeiden, wurden die entsprechenden Befragten nicht aus der Stichprobe entfernt (Aronow et al., 2019). 19 Aufgrund des nicht signifikanten Ergebnisses der Manipulationsprüfung wurde diese Frage in Erhebung 2.3b noch einmal spezifiziert und lautete hier "Ich wurde bei der Berechnung meines individualisierten Versicherungstarifs explizit darauf hingewiesen, dass ich in Zukunft meine persönlichen Daten abgeben müsste". Eine Veränderung des Stimulusmaterials selbst erfolgte jedoch nicht. Studie 2 -Die Auswirkungen der … Abhängige Variable -die Bereitschaft zum Wechsel in eine digitale individualisierte Krankenversicherung Mittels der folgenden Frage wurde die Bereitschaft zum Wechsel in die vorgestellte individualisierte Krankenversicherung erhoben: "Wären Sie bereit, auf Grundlage des gezeigten Angebots und seiner Konditionen, zur INDIVIDUA-Krankenversicherung zu wechseln?" Die Antwort erfolgte auf einer 5-stufigen Antwortskala, die wie folgt codiert wurde: 1 -"Ja, auf jeden Fall", 2 -"Eher ja", 3 -"Unentschieden", 4 -"Eher nein", sowie 5 -"Nein, auf keinen Fall". Für die Datenauswertung wurde die Variable anschließend invertiert, so dass hohe Werte eine hohe Wechselbereitschaft bedeuten (Erhebung 2.3a: M = 2.26, SD = 1.05; Erhebung 2.3b: M = 1.61, SD = .87).</p>
        <p>Unabhängige Variablen -die Dimensionen des BDGS Die BDGS-Skala wurde in unveränderter Form in den Fragebogen aufgenommen.Unabhängige Variablen -die Dimensionen des BDGS Die BDGS-Skala wurde in unveränderter Form in den Fragebogen aufgenommen.</p>
        <p>Abhängige Variablen -Vertrauen in die Richtigkeit der KI-basierten Entscheidung, Reputation der Hochschule und Protest gegen die Auswahlentscheidung Die Variable Vertrauen in die Richtigkeit der KI-basierten Entscheidung wurde ausgehend von der Arbeit von Lee (2018) Diese Fragen wurden auf einer 5-stufigen Likert-Skala erhoben, bei der die Extrema mit ‚stimme überhaupt nicht zu' (zugewiesener Wert 1) und ‚stimme voll und ganz zu' (zugewiesener Wert 5) beschriftet waren. Die vier Items hatte eine hohe interne Konsistenz (α = .872; DEV = .636). Eine CFA, bei der ein latenter Faktor auf die vier Items lud, zeigte eine hohe Anpassungsgüte (X 2 (12) = 5.047, p = .08; RMSEA = .071 [.000, .151]; TLI = .985). Bis auf Item Rep4 zeigen sich ausreichend hohe Faktorladungen (λ Rep1 = .862, λ Rep2 = .858, λ Rep3 = .783, λ Rep4 = .671). Trotzdem wird Item Rep4 mit in die Datenanalyse aufgenommen, da die Faktorladung zwar etwas gering ausfällt, der Indikator dennoch zusätzliche Information bereitstellt.Abhängige Variablen -Vertrauen in die Richtigkeit der KI-basierten Entscheidung, Reputation der Hochschule und Protest gegen die Auswahlentscheidung Die Variable Vertrauen in die Richtigkeit der KI-basierten Entscheidung wurde ausgehend von der Arbeit von Lee (2018) Diese Fragen wurden auf einer 5-stufigen Likert-Skala erhoben, bei der die Extrema mit ‚stimme überhaupt nicht zu' (zugewiesener Wert 1) und ‚stimme voll und ganz zu' (zugewiesener Wert 5) beschriftet waren. Die vier Items hatte eine hohe interne Konsistenz (α = .872; DEV = .636). Eine CFA, bei der ein latenter Faktor auf die vier Items lud, zeigte eine hohe Anpassungsgüte (X 2 (12) = 5.047, p = .08; RMSEA = .071 [.000, .151]; TLI = .985). Bis auf Item Rep4 zeigen sich ausreichend hohe Faktorladungen (λ Rep1 = .862, λ Rep2 = .858, λ Rep3 = .783, λ Rep4 = .671). Trotzdem wird Item Rep4 mit in die Datenanalyse aufgenommen, da die Faktorladung zwar etwas gering ausfällt, der Indikator dennoch zusätzliche Information bereitstellt.</p>
        <p>Zudem wurde erhoben, inwieweit die Befragten bereit wären, gegen die von der KI getroffene Auswahlentscheidung zu protestieren. Die abhängige Variable Protest gegen die KI-basierte Auswahlentscheidung wird dabei als Handlungsintention im Sinne politischer Mitsprache betrachtet. Ähnlich dem Konzept Political Voice, das in der politikwissenschaftlichen Literatur als eine Kategorie von Handlungsmacht begriffen wird (Hirschman, 1970), zielt das Konstrukt darauf ab, inwieweit eine aktive Missbilligung durch die Probanden geäußert wird. Hierfür wurden die folgenden vier Fragen eigenständig formuliert:Zudem wurde erhoben, inwieweit die Befragten bereit wären, gegen die von der KI getroffene Auswahlentscheidung zu protestieren. Die abhängige Variable Protest gegen die KI-basierte Auswahlentscheidung wird dabei als Handlungsintention im Sinne politischer Mitsprache betrachtet. Ähnlich dem Konzept Political Voice, das in der politikwissenschaftlichen Literatur als eine Kategorie von Handlungsmacht begriffen wird (Hirschman, 1970), zielt das Konstrukt darauf ab, inwieweit eine aktive Missbilligung durch die Probanden geäußert wird. Hierfür wurden die folgenden vier Fragen eigenständig formuliert:</p>
        <p>• Ich würde mich aktiv gegen das Auswahlverfahren einsetzen. (Item-ID Prot1;• Ich würde mich aktiv gegen das Auswahlverfahren einsetzen. (Item-ID Prot1;</p>
        <p>Referenzindikator) • An einer Demonstration gegen das Auswahlverfahren würde ich teilnehmen.Referenzindikator) • An einer Demonstration gegen das Auswahlverfahren würde ich teilnehmen.</p>
        <p>(Item-ID Prot2) In Erhebung 2.1 EU und KI wurde die BDGS-Skala dabei vor der randomisierten Zuweisung zu den Experimentalkonditionen und somit vor der Manipulation beantwortet. Es sind daher mit Blick auf die Ausprägung des BDGS bei den Befragten zum einen keine systematischen Unterschiede zwischen den Gruppen und zum anderen keine Ausstrahlungs-und Befragungseffekte durch den Fragebogenaufbau zu erwarten und auch nicht zu beobachten. 20 In Erhebung 2.2 KI-Bedrohung wurde das Modell für drei Gruppen der unterschiedlichen Anwendungskontexte spezifiziert (siehe Abschnitt 10.6.2). Da die Bedrohungswahrnehmung durch KI in den einzelnen Anwendungsbereichen im Fragebogen vor der Erhebung der BDGS-Skala erfragt wurde, ist neben der allgemeinen Modellspezifikation auch wie für Erhebung 2.3 Krankenversicherung auf Messäquivalenz zwischen den einzelnen Gruppen zu prüfen, um einen Befragungseffekt auf die BDGS-Skala auszuschließen. Da es anders als in Erhebung 2.3 jedoch nicht um eine identische Befragung mit einer anderen Stichprobe ging, sondern nachfolgend ja insbesondere Unterschiede der Pfadkoeffizienten zwischen BDGS und KI-Bedrohungswahrnehmung geprüft werden sollen, beschränkt sich die Prüfung der Messäquivalenz nur auf die BDGS-Skala. Es wird mithin getestet, ob die vermutete Beziehungsstruktur des BDGS in beiden Stichproben äquivalent 20 Eine Prüfung auf Messinvarianz der BDGS-Skala zwischen den Experimentalgruppen mittels MGKA zeigt, dass bis auf die Messinvarianz der Messfehler Messäquivalenz zwischen den Gruppen bestand. Das Modell mit Gleichheitsrestriktionen für Regressionsgewichte, -konstanten und die Kovarianzen zeigt keine signifikant schlechtere Anpassung als das Modell ohne diese Identitätsrestriktionen ( X 2 = 60.116, df = 60, p = .472).(Item-ID Prot2) In Erhebung 2.1 EU und KI wurde die BDGS-Skala dabei vor der randomisierten Zuweisung zu den Experimentalkonditionen und somit vor der Manipulation beantwortet. Es sind daher mit Blick auf die Ausprägung des BDGS bei den Befragten zum einen keine systematischen Unterschiede zwischen den Gruppen und zum anderen keine Ausstrahlungs-und Befragungseffekte durch den Fragebogenaufbau zu erwarten und auch nicht zu beobachten. 20 In Erhebung 2.2 KI-Bedrohung wurde das Modell für drei Gruppen der unterschiedlichen Anwendungskontexte spezifiziert (siehe Abschnitt 10.6.2). Da die Bedrohungswahrnehmung durch KI in den einzelnen Anwendungsbereichen im Fragebogen vor der Erhebung der BDGS-Skala erfragt wurde, ist neben der allgemeinen Modellspezifikation auch wie für Erhebung 2.3 Krankenversicherung auf Messäquivalenz zwischen den einzelnen Gruppen zu prüfen, um einen Befragungseffekt auf die BDGS-Skala auszuschließen. Da es anders als in Erhebung 2.3 jedoch nicht um eine identische Befragung mit einer anderen Stichprobe ging, sondern nachfolgend ja insbesondere Unterschiede der Pfadkoeffizienten zwischen BDGS und KI-Bedrohungswahrnehmung geprüft werden sollen, beschränkt sich die Prüfung der Messäquivalenz nur auf die BDGS-Skala. Es wird mithin getestet, ob die vermutete Beziehungsstruktur des BDGS in beiden Stichproben äquivalent 20 Eine Prüfung auf Messinvarianz der BDGS-Skala zwischen den Experimentalgruppen mittels MGKA zeigt, dass bis auf die Messinvarianz der Messfehler Messäquivalenz zwischen den Gruppen bestand. Das Modell mit Gleichheitsrestriktionen für Regressionsgewichte, -konstanten und die Kovarianzen zeigt keine signifikant schlechtere Anpassung als das Modell ohne diese Identitätsrestriktionen ( X 2 = 60.116, df = 60, p = .472).</p>
        <p>ist. Die zu prüfenden Modelle wurden gemäß der Konfiguration in Abbildung 2 spezifiziert und mit den entsprechenden Gleichheitsrestriktionen für die jeweilige Stufe der Messinvarianz versehen (Weiber &amp; Mühlhaus, 2014) In Tabelle 10.4 finden sich die jeweiligen Angaben zum Cronbachschen α und der DEV der jeweiligen Dimensionen in den einzelnen Erhebungen. Die jeweiligen Werte indizieren für das Modell in den Erhebungen über alle vier Dimensionen hinweg eine hohe interne Konsistenz der Indikatoren.ist. Die zu prüfenden Modelle wurden gemäß der Konfiguration in Abbildung 2 spezifiziert und mit den entsprechenden Gleichheitsrestriktionen für die jeweilige Stufe der Messinvarianz versehen (Weiber &amp; Mühlhaus, 2014) In Tabelle 10.4 finden sich die jeweiligen Angaben zum Cronbachschen α und der DEV der jeweiligen Dimensionen in den einzelnen Erhebungen. Die jeweiligen Werte indizieren für das Modell in den Erhebungen über alle vier Dimensionen hinweg eine hohe interne Konsistenz der Indikatoren.</p>
        <p>Darüber hinaus finden sich in Tabelle 10.5, Tabelle 10.6, Tabelle 10.7 und Tabelle 10.8 die geschätzten Regressionskonstanten und -gewichte sowie die Faktorladungen der einzelnen Indikatoren samt deren Dimensionszugehörigkeit innerhalb des BDGS. Um zu prüfen, ob sich die Werte der Regressionskonstanten signifikant vom Skalenmittelpunkt unterscheiden, wurde in allen Modellen zusätzlich ein Bootstrapping in AMOS für ‚Bias-corrected confidence intervals' nach (Efron, 1987) Mit Blick auf die Regressionskonstanten fällt auf, dass bei den Items der Dimension Genauigkeit die Regressionskonstanten in den Erhebungen um den Skalenmittelpunkt oder leicht darunterliegen, was eine differenzierte Einschätzung dieser Dimension indiziert. Gleiches gilt für die Dimensionen des individuellen Nutzens sowie des gesellschaftlichen Nutzens, deren Regressionskonstanten ebenfalls um den Skalenmittelpunkt liegen. Allerdings ist der individuelle Nutzen im Verhältnis fast durchgängig geringer ausgeprägt als der gesellschaftliche Nutzen. Besonders hoch ausgeprägt sind in den vorliegenden Erhebungen hingegen erneut die Indikatoren der Dimension des Wissensgewinns: In allen Erhebungen ist diese Dimension mit Blick auf die Regressionskonstanten der einzelnen Indikatoren stark positiv ausgeprägt, weshalb die entsprechend formulierte Hypothese 1a angenommen wird.Darüber hinaus finden sich in Tabelle 10.5, Tabelle 10.6, Tabelle 10.7 und Tabelle 10.8 die geschätzten Regressionskonstanten und -gewichte sowie die Faktorladungen der einzelnen Indikatoren samt deren Dimensionszugehörigkeit innerhalb des BDGS. Um zu prüfen, ob sich die Werte der Regressionskonstanten signifikant vom Skalenmittelpunkt unterscheiden, wurde in allen Modellen zusätzlich ein Bootstrapping in AMOS für ‚Bias-corrected confidence intervals' nach (Efron, 1987) Mit Blick auf die Regressionskonstanten fällt auf, dass bei den Items der Dimension Genauigkeit die Regressionskonstanten in den Erhebungen um den Skalenmittelpunkt oder leicht darunterliegen, was eine differenzierte Einschätzung dieser Dimension indiziert. Gleiches gilt für die Dimensionen des individuellen Nutzens sowie des gesellschaftlichen Nutzens, deren Regressionskonstanten ebenfalls um den Skalenmittelpunkt liegen. Allerdings ist der individuelle Nutzen im Verhältnis fast durchgängig geringer ausgeprägt als der gesellschaftliche Nutzen. Besonders hoch ausgeprägt sind in den vorliegenden Erhebungen hingegen erneut die Indikatoren der Dimension des Wissensgewinns: In allen Erhebungen ist diese Dimension mit Blick auf die Regressionskonstanten der einzelnen Indikatoren stark positiv ausgeprägt, weshalb die entsprechend formulierte Hypothese 1a angenommen wird.</p>
        <p>In Tabelle 10.9 finden sich die Inter-Korrelationen der vier Dimensionen des BDGS, die wie in Studie 1 auch in allen Erhebungen der Studie 2 erneut hoch miteinander korrelieren. Hohe Ausprägungen einer Dimension gehen für gewöhnlich mit hohen Ausprägungen der anderen Dimensionen einher. Die Hypothese 1b, die besagt, dass die Dimensionen des BDGS positiv miteinander kovariieren, wird mithin angenommen.In Tabelle 10.9 finden sich die Inter-Korrelationen der vier Dimensionen des BDGS, die wie in Studie 1 auch in allen Erhebungen der Studie 2 erneut hoch miteinander korrelieren. Hohe Ausprägungen einer Dimension gehen für gewöhnlich mit hohen Ausprägungen der anderen Dimensionen einher. Die Hypothese 1b, die besagt, dass die Dimensionen des BDGS positiv miteinander kovariieren, wird mithin angenommen.</p>
        <p>Auch für die vier Erhebungen 2.1 bis 2.4 in Studie 2 wurde eine Prüfung auf Messinvarianz durchgeführt. Die Ergebnisse in Tabelle 10.10 zeigen, dass mit Blick auf den Chi-Quadrat-Differenztest die Modelle mit metrischer und skalarer Invarianz eine signifikant schlechtere Anpassungsgüte zeigen. Allerdings müssen erneut die Stichprobengröße (n = 2364) sowie die Anzahl der verglichenen Gruppen sowie die Größe des geschätzten Modells berücksichtigt werden, die einen Einfluss auf den Test auf Messinvarianz haben. Auch hier tendiert der strenge Chi-Quadrat-Differenztest schnell dazu, ein signifikantes Ergebnis zu erbringen (Putnick &amp; Bornstein, 2016). Es werden aus diesem Grund an dieser Stelle inkrementelle Fit-Maße zur Beurteilung der Messinvarianz herangezogen (F. F. Chen, 2007;Meade et al., 2008), die eine Einschätzung erlauben, in welchem Grad sich das Modell durch die Gleichheitsrestriktionen verschlechtert. So wird mit Blick auf Tabelle 10.10 ersichtlich, dass das Modell mit der skalaren Invarianz bezüglich der inkrementellen Fit-Maße des TLI und des RMSEA eine höhere bzw. mindestens gleich hohe Anpassungsgüte zeigt, verglichen mit den Modellen mit konfiguraler Invarianz bzw. metrischer Invarianz. Das bedeutet, dass das Modell mit den Gleichheitsrestriktionen eine signifikant, jedoch nicht substantiell schlechtere Anpassungsgüte zeigt und mithin von starker Messinvarianz ausgegangen wird. Bildungsberichterstattung, 2018). Es verwundert daher nicht, dass der Mythos der digitalen Daten auch von dieser Gruppe aufgenommen wird und hohe Erwartungen an das positive Veränderungspotential digitaler Datensammlung und -verwertung bestehen.Auch für die vier Erhebungen 2.1 bis 2.4 in Studie 2 wurde eine Prüfung auf Messinvarianz durchgeführt. Die Ergebnisse in Tabelle 10.10 zeigen, dass mit Blick auf den Chi-Quadrat-Differenztest die Modelle mit metrischer und skalarer Invarianz eine signifikant schlechtere Anpassungsgüte zeigen. Allerdings müssen erneut die Stichprobengröße (n = 2364) sowie die Anzahl der verglichenen Gruppen sowie die Größe des geschätzten Modells berücksichtigt werden, die einen Einfluss auf den Test auf Messinvarianz haben. Auch hier tendiert der strenge Chi-Quadrat-Differenztest schnell dazu, ein signifikantes Ergebnis zu erbringen (Putnick &amp; Bornstein, 2016). Es werden aus diesem Grund an dieser Stelle inkrementelle Fit-Maße zur Beurteilung der Messinvarianz herangezogen (F. F. Chen, 2007;Meade et al., 2008), die eine Einschätzung erlauben, in welchem Grad sich das Modell durch die Gleichheitsrestriktionen verschlechtert. So wird mit Blick auf Tabelle 10.10 ersichtlich, dass das Modell mit der skalaren Invarianz bezüglich der inkrementellen Fit-Maße des TLI und des RMSEA eine höhere bzw. mindestens gleich hohe Anpassungsgüte zeigt, verglichen mit den Modellen mit konfiguraler Invarianz bzw. metrischer Invarianz. Das bedeutet, dass das Modell mit den Gleichheitsrestriktionen eine signifikant, jedoch nicht substantiell schlechtere Anpassungsgüte zeigt und mithin von starker Messinvarianz ausgegangen wird. Bildungsberichterstattung, 2018). Es verwundert daher nicht, dass der Mythos der digitalen Daten auch von dieser Gruppe aufgenommen wird und hohe Erwartungen an das positive Veränderungspotential digitaler Datensammlung und -verwertung bestehen.</p>
        <p>Ergebnisse der Erhebung 2.1 EU und KI In der Kond ADM zeigt sich, dass die BDGS-Dimension des individuellen Nutzens einen mittleren negativen Einfluss (B = -.205, SE = .099. p = .038, β = -.411) auf die wahrgenommene Legitimität des Inputs hat (siehe Tabelle 10.14). Zudem ergab sich, dass das BDGS insgesamt einen positiven Einfluss auf die wahrgenommene Throughput-Legitimität hat (B = .061, SE = .015. p &lt; .001), der als gering zu bewerten ist (β Genauigkeit = .086; β Wissensgewinn = .080; β Individueller_Nutzen = .092; β Gesellschaftlicher_Nutzen = .085). Darüber hinaus gibt es einen positiven Einfluss des BDGS auf die Zielerreichung (B = .059, SE = .015. p &lt; .001) sowie die Akzeptanz der Entscheidung (B = .048, SE = .018. p = .036). Sowohl für den Einfluss des BDGS auf die Zielerreichung (β Genauigkeit = .080; β Wissensgewinn = .075; β Individueller_Nutzen = .086; β Gesellschaftlicher_Nutzen = .080) als auch auf die Akzeptanz der Entscheidung (β Genauigkeit = .054; β Wissensgewinn = .051; β Individueller_Nutzen = .058; β Gesellschaftlicher_Nutzen = .054) ist der Effekt ebenfalls gering.Ergebnisse der Erhebung 2.1 EU und KI In der Kond ADM zeigt sich, dass die BDGS-Dimension des individuellen Nutzens einen mittleren negativen Einfluss (B = -.205, SE = .099. p = .038, β = -.411) auf die wahrgenommene Legitimität des Inputs hat (siehe Tabelle 10.14). Zudem ergab sich, dass das BDGS insgesamt einen positiven Einfluss auf die wahrgenommene Throughput-Legitimität hat (B = .061, SE = .015. p &lt; .001), der als gering zu bewerten ist (β Genauigkeit = .086; β Wissensgewinn = .080; β Individueller_Nutzen = .092; β Gesellschaftlicher_Nutzen = .085). Darüber hinaus gibt es einen positiven Einfluss des BDGS auf die Zielerreichung (B = .059, SE = .015. p &lt; .001) sowie die Akzeptanz der Entscheidung (B = .048, SE = .018. p = .036). Sowohl für den Einfluss des BDGS auf die Zielerreichung (β Genauigkeit = .080; β Wissensgewinn = .075; β Individueller_Nutzen = .086; β Gesellschaftlicher_Nutzen = .080) als auch auf die Akzeptanz der Entscheidung (β Genauigkeit = .054; β Wissensgewinn = .051; β Individueller_Nutzen = .058; β Gesellschaftlicher_Nutzen = .054) ist der Effekt ebenfalls gering.</p>
        <p>Hypothese Dies sind durchaus relevante Befunde zur Bewertung des menschlichen Korrektivs im Rahmen der Akzeptanz von automatisierter Entscheidungsfindung durch KI, die vor dem Hintergrund der Diskussionen um korrigierende menschliche Eingriffe in Daten und Algorithmen zu bewerten sind (Dietvorst et al., 2018;Goldenfein, 2019). Soll die Fehlbarkeit der KI-Anwendungen durch eine Letztentscheidungsbefugnis von Menschen abgefedert oder gänzlich vermieden werden, führt dies hier in den Augen von Personen mit ausgeprägten Überzeugungen des BDGS nur zu einer zu leicht verringerten Legitimitätswahrnehmung im Vergleich mit der vollständig automatisierten Kondition.Hypothese Dies sind durchaus relevante Befunde zur Bewertung des menschlichen Korrektivs im Rahmen der Akzeptanz von automatisierter Entscheidungsfindung durch KI, die vor dem Hintergrund der Diskussionen um korrigierende menschliche Eingriffe in Daten und Algorithmen zu bewerten sind (Dietvorst et al., 2018;Goldenfein, 2019). Soll die Fehlbarkeit der KI-Anwendungen durch eine Letztentscheidungsbefugnis von Menschen abgefedert oder gänzlich vermieden werden, führt dies hier in den Augen von Personen mit ausgeprägten Überzeugungen des BDGS nur zu einer zu leicht verringerten Legitimitätswahrnehmung im Vergleich mit der vollständig automatisierten Kondition.</p>
        <p>Dass im Szenario des Status quo das BDGS dann doch ausgerechnet einen Einfluss auf die Akzeptanz der Entscheidung hat, verwundert und sollte im Rahmen weiterführender Untersuchungen geprüft werden. Mögliche Einflüsse und Wechselwirkungen mit anderen Eigenschaften der Person wie etwa soziodemografischer Variablen oder anderweitiger Einstellungen sind jedoch mit dem vorliegenden Design und der Stichprobengröße nicht realisierbar.Dass im Szenario des Status quo das BDGS dann doch ausgerechnet einen Einfluss auf die Akzeptanz der Entscheidung hat, verwundert und sollte im Rahmen weiterführender Untersuchungen geprüft werden. Mögliche Einflüsse und Wechselwirkungen mit anderen Eigenschaften der Person wie etwa soziodemografischer Variablen oder anderweitiger Einstellungen sind jedoch mit dem vorliegenden Design und der Stichprobengröße nicht realisierbar.</p>
        <p>Die Ergebnisse haben auch verdeutlicht, dass im vorliegenden Erklärungszusammenhang das BDGS meist gesamt genommen einen Einfluss zeitigte und nicht zwischen dem Einfluss einzelner Dimensionen unterschieden werden konnte. Das führt zu der Erkenntnis, dass je nach Forschungszusammenhang gut überlegt und geplant werden sollte, wie die Messung des BDGS in die Erhebung und Analyse eingeht. Im vorliegenden Fall wäre es bspw. aus forschungsökonomischen Gründen möglicherweise ausreichend gewesen, eine besonders relevante Dimension zu identifizieren oder es könnte generell angedacht werden, für ähnlich gelagerte Studien eine Kurzskala mit den als wichtig befundenen Referenzindikatoren zu bilden. Da der Einsatz der BDGS-Skala jedoch noch weitgehend unerprobt war und in den vorliegenden Studien teils explorative Forschungsfragen und Erkenntnisinteressen formuliert wurden, bei denen durchaus individuelle Effekte der Dimensionen zu erwarten waren, ging weiterhin die vierdimensionale BDGS-Skala in die Untersuchungen mit ein.Die Ergebnisse haben auch verdeutlicht, dass im vorliegenden Erklärungszusammenhang das BDGS meist gesamt genommen einen Einfluss zeitigte und nicht zwischen dem Einfluss einzelner Dimensionen unterschieden werden konnte. Das führt zu der Erkenntnis, dass je nach Forschungszusammenhang gut überlegt und geplant werden sollte, wie die Messung des BDGS in die Erhebung und Analyse eingeht. Im vorliegenden Fall wäre es bspw. aus forschungsökonomischen Gründen möglicherweise ausreichend gewesen, eine besonders relevante Dimension zu identifizieren oder es könnte generell angedacht werden, für ähnlich gelagerte Studien eine Kurzskala mit den als wichtig befundenen Referenzindikatoren zu bilden. Da der Einsatz der BDGS-Skala jedoch noch weitgehend unerprobt war und in den vorliegenden Studien teils explorative Forschungsfragen und Erkenntnisinteressen formuliert wurden, bei denen durchaus individuelle Effekte der Dimensionen zu erwarten waren, ging weiterhin die vierdimensionale BDGS-Skala in die Untersuchungen mit ein.</p>
        <p>Alles in allem lässt sich abschließend feststellen, dass der Einfluss des BDGS im Rahmen der aufwändigen Untersuchungsanlage verhältnismäßig gering ist und die Reichweite der Befunde auf den ersten Blick insgesamt eher ernüchternd wirkt. Möglicherweise waren die vorgestellten hypothetischen Szenarien zu abstrakt und aktuell nicht relevant und realistisch für die Befragten, als dass sich große Unterschiede in der Bewertung der Kondition zwischen Personen mit unterschiedlich ausgeprägtem BDGS manifestieren. Auch die Unterscheidung zwischen einzelnen BDGS-Dimensionen war insgesamt zu voraussetzungsvoll und weitreichend, als dass sie in der vorliegenden Untersuchung mit der vorhandenen Samplegröße realisiert werden konnte. Dennoch zeigten sich etliche vermutete Einflüsse des BDGS. Auch kleine Effekte können dabei im Rahmen politischer Fragen weitreichende Folgen haben. So können schon geringe Unterschiede und schwache Effekte bspw. im Rahmen knapper Wahlabstimmungen in politischen Fragen entscheidend sein und Einfluss auf die Gesellschaft haben. Der Glaube an den gesellschaftlichen Nutzen der Verwertung digitaler Datenbestände sowie der erwartete Wissensgewinn haben einen negativen Einfluss auf die Ausprägung der Bedrohungswahrnehmung der ausgesprochenen KI-Empfehlungen bei der Bewerbung auf einen Arbeitsplatz. Je stärker der Glaube daran, dass digitale Daten Wissen bereitstellen (β Wissensgewinn = -.238) sowie der Gesellschaft einen Nutzen bringen (β Gesellschaftlicher_Nutzen = -.251), desto geringer die Bedrohungswahrnehmung einer KI-Anwendung, die eine Empfehlung über die Einstellung von Bewerber*innen auf einen Arbeitsplatz ausspricht. Die Dimensionen der Genauigkeit und des individuellen Nutzens haben hingegen keinen signifikanten Einfluss.Alles in allem lässt sich abschließend feststellen, dass der Einfluss des BDGS im Rahmen der aufwändigen Untersuchungsanlage verhältnismäßig gering ist und die Reichweite der Befunde auf den ersten Blick insgesamt eher ernüchternd wirkt. Möglicherweise waren die vorgestellten hypothetischen Szenarien zu abstrakt und aktuell nicht relevant und realistisch für die Befragten, als dass sich große Unterschiede in der Bewertung der Kondition zwischen Personen mit unterschiedlich ausgeprägtem BDGS manifestieren. Auch die Unterscheidung zwischen einzelnen BDGS-Dimensionen war insgesamt zu voraussetzungsvoll und weitreichend, als dass sie in der vorliegenden Untersuchung mit der vorhandenen Samplegröße realisiert werden konnte. Dennoch zeigten sich etliche vermutete Einflüsse des BDGS. Auch kleine Effekte können dabei im Rahmen politischer Fragen weitreichende Folgen haben. So können schon geringe Unterschiede und schwache Effekte bspw. im Rahmen knapper Wahlabstimmungen in politischen Fragen entscheidend sein und Einfluss auf die Gesellschaft haben. Der Glaube an den gesellschaftlichen Nutzen der Verwertung digitaler Datenbestände sowie der erwartete Wissensgewinn haben einen negativen Einfluss auf die Ausprägung der Bedrohungswahrnehmung der ausgesprochenen KI-Empfehlungen bei der Bewerbung auf einen Arbeitsplatz. Je stärker der Glaube daran, dass digitale Daten Wissen bereitstellen (β Wissensgewinn = -.238) sowie der Gesellschaft einen Nutzen bringen (β Gesellschaftlicher_Nutzen = -.251), desto geringer die Bedrohungswahrnehmung einer KI-Anwendung, die eine Empfehlung über die Einstellung von Bewerber*innen auf einen Arbeitsplatz ausspricht. Die Dimensionen der Genauigkeit und des individuellen Nutzens haben hingegen keinen signifikanten Einfluss.</p>
        <p>Im Rahmen der Bedrohungswahrnehmung einer automatisierten Entscheidung zeigt sich, dass die Dimensionen Wissensgewinn (β Wissensgewinn = .208) und der erwartete individuelle Nutzen (β Individueller_Nutzen = .253) einen steigernden Einfluss haben. Je höher jedoch der erwartete Nutzen für die Gesellschaft, desto deutlich geringer die Bedrohungswahrnehmung (β Gesellschaftlicher_Nutzen = -.484). Die Genauigkeit hat keinen signifikanten Einfluss. Auch der Blick auf die SMC offenbart einen geringen Erklärungsanteil der BDGS-Dimensionen an den beiden Funktionen: Es werden 12.5 % der Varianz der Empfehlung (SMC Empfehlung_Personalwesen = .125) und 7.4 % der Varianz der ADM (SMC ADM_Personalwesen = .074) durch die Dimensionen des BDGS erklärt. Geht es um die Kreditvergabe, zeigt sich, dass das BDGS allgemein bei zunehmender Ausprägung die Bedrohungswahrnehmung bei der Empfehlung und automatisierter Kreditvergabe mindert. Hier wird der Einsatz von datenbasierten KI-Anwendungen von den Befragten, die eine positive Erwartungshaltung gegenüber Datensammlung und -verwertung haben, entsprechend weniger kritisch gesehen. Die vermeintlichen Vorteile der automatisierten Kreditvergabe werden von diesen Personen also eher erwartet.Im Rahmen der Bedrohungswahrnehmung einer automatisierten Entscheidung zeigt sich, dass die Dimensionen Wissensgewinn (β Wissensgewinn = .208) und der erwartete individuelle Nutzen (β Individueller_Nutzen = .253) einen steigernden Einfluss haben. Je höher jedoch der erwartete Nutzen für die Gesellschaft, desto deutlich geringer die Bedrohungswahrnehmung (β Gesellschaftlicher_Nutzen = -.484). Die Genauigkeit hat keinen signifikanten Einfluss. Auch der Blick auf die SMC offenbart einen geringen Erklärungsanteil der BDGS-Dimensionen an den beiden Funktionen: Es werden 12.5 % der Varianz der Empfehlung (SMC Empfehlung_Personalwesen = .125) und 7.4 % der Varianz der ADM (SMC ADM_Personalwesen = .074) durch die Dimensionen des BDGS erklärt. Geht es um die Kreditvergabe, zeigt sich, dass das BDGS allgemein bei zunehmender Ausprägung die Bedrohungswahrnehmung bei der Empfehlung und automatisierter Kreditvergabe mindert. Hier wird der Einsatz von datenbasierten KI-Anwendungen von den Befragten, die eine positive Erwartungshaltung gegenüber Datensammlung und -verwertung haben, entsprechend weniger kritisch gesehen. Die vermeintlichen Vorteile der automatisierten Kreditvergabe werden von diesen Personen also eher erwartet.</p>
        <p>Mit Blick auf die eher kleinen Effektstärken des Einflusses des BDGS und seiner Dimensionen überwiegen anscheinend jedoch andere Gründe, die dazu führen, KI-Anwendungen in den einzelnen Kontexten als eine Bedrohung zu empfinden. Hierzu mag beitragen, dass die gewählten Anwendungsbereiche für einen Teil der Befragten womöglich keine Relevanz besitzen -und dahingehend unabhängig von den Glaubenssätzen mit Bezug zu digitalen Daten sind. Wer keinen Kredit benötigt oder bereits im Rentenalter ist, der hat durch die KI-Anwendungen nichts zu befürchten. Oder aber die Konsequenzen sind bei einigen Befragten so weitreichend, dass die Reichweite der individuellen Konsequenzen hinter die allgemeinen Einstellungen des BDGS im vorliegenden Fall zurücktritt. In beiden Fällen wäre es notwendig, die individuelle Betroffenheit der Befragten zu kontrollieren, wobei keine Angaben zur persönlichen Betroffenheit erhoben wurden. Hier sei auch auf den speziellen Einfluss der Fairness-Wahrnehmung abgestellt, der womöglich einen zusätzlichen moderierenden Einfluss darstellt (Marcinkowski &amp; Starke, 2019): Ein Verfahren muss nicht nur datenbasiert ablaufen, sondern dies muss auch dazu führen, dass die KI-Anwendung als vermeintlich fairer wahrgenommen wird, was in zukünftigen Studien mithin geprüft werden sollte.Mit Blick auf die eher kleinen Effektstärken des Einflusses des BDGS und seiner Dimensionen überwiegen anscheinend jedoch andere Gründe, die dazu führen, KI-Anwendungen in den einzelnen Kontexten als eine Bedrohung zu empfinden. Hierzu mag beitragen, dass die gewählten Anwendungsbereiche für einen Teil der Befragten womöglich keine Relevanz besitzen -und dahingehend unabhängig von den Glaubenssätzen mit Bezug zu digitalen Daten sind. Wer keinen Kredit benötigt oder bereits im Rentenalter ist, der hat durch die KI-Anwendungen nichts zu befürchten. Oder aber die Konsequenzen sind bei einigen Befragten so weitreichend, dass die Reichweite der individuellen Konsequenzen hinter die allgemeinen Einstellungen des BDGS im vorliegenden Fall zurücktritt. In beiden Fällen wäre es notwendig, die individuelle Betroffenheit der Befragten zu kontrollieren, wobei keine Angaben zur persönlichen Betroffenheit erhoben wurden. Hier sei auch auf den speziellen Einfluss der Fairness-Wahrnehmung abgestellt, der womöglich einen zusätzlichen moderierenden Einfluss darstellt (Marcinkowski &amp; Starke, 2019): Ein Verfahren muss nicht nur datenbasiert ablaufen, sondern dies muss auch dazu führen, dass die KI-Anwendung als vermeintlich fairer wahrgenommen wird, was in zukünftigen Studien mithin geprüft werden sollte.</p>
        <p>Prüfung der Messäquivalenz Bevor die Prüfung der Hypothesen durchgeführt werden kann, sollte zunächst die Messinvarianz des Gesamtmodells überprüft werden, also inwieweit sich die Beziehungsstruktur des Modells für die beiden Stichproben in Erhebung 2.3a Krankenversicherung und Erhebung 2.3b Krankenversicherung unterscheidet (van de Schoot et al., 2012;Weiber &amp; Mühlhaus, 2014). Zum einen ist wichtig zu prüfen, ob die Messung der latenten Konstrukte des BDGS in beiden Stichproben messäquivalent ist. Nur bei Messäquivalenz kann davon ausgegangen werden, dass die latenten Faktoren das gleich Konstrukt messen und sinnvoll miteinander verglichen werden können (Widaman &amp; Reise, 1997) Notizen. a,b,c Werte der Regressionskonstanten mit gleichen Buchstaben wurden mit Gleichheitsrestriktionen der Strukturgewichte spezifiziert und haben daher identische Parameterschätzungen.Prüfung der Messäquivalenz Bevor die Prüfung der Hypothesen durchgeführt werden kann, sollte zunächst die Messinvarianz des Gesamtmodells überprüft werden, also inwieweit sich die Beziehungsstruktur des Modells für die beiden Stichproben in Erhebung 2.3a Krankenversicherung und Erhebung 2.3b Krankenversicherung unterscheidet (van de Schoot et al., 2012;Weiber &amp; Mühlhaus, 2014). Zum einen ist wichtig zu prüfen, ob die Messung der latenten Konstrukte des BDGS in beiden Stichproben messäquivalent ist. Nur bei Messäquivalenz kann davon ausgegangen werden, dass die latenten Faktoren das gleich Konstrukt messen und sinnvoll miteinander verglichen werden können (Widaman &amp; Reise, 1997) Notizen. a,b,c Werte der Regressionskonstanten mit gleichen Buchstaben wurden mit Gleichheitsrestriktionen der Strukturgewichte spezifiziert und haben daher identische Parameterschätzungen.</p>
        <p>Der direkte Effekt des BDGS auf die eingeschätzte Reputation der Hochschule zeigt einen kleinen signifikanten positiven Effekt (B = .027, SE = .011, p = .015), der jedoch als gering zu bewerten ist (β Genauigkeit = .035; β Wissensgewinn = .028; β Individueller_Nutzen = .042; β Gesellschaftlicher_Nutzen = .036). Es zeigt sich zudem, dass das Vertrauen in die Richtigkeit der Entscheidung zu einer höheren Reputation der Hochschule bei den Befragten führt (β = .685). Der starke gesamte Effekt der Dimension Genauigkeit auf die Reputation der Hochschule (β = .303) wird daher zum Großteil durch den indirekten Effekt (β = .268) der Genauigkeit über das Vertrauen in die Richtigkeit der Auswahlentscheidung erklärt. Hypothese 2.4b wird dahingehend angenommen, dass auch hier das BDGS einen positiven Einfluss auf die Reputation der Hochschule hat, in diesem Rahmen jedoch insbesondere die Überzeugungen von der Genauigkeit der Daten ausschlaggebend sind.Der direkte Effekt des BDGS auf die eingeschätzte Reputation der Hochschule zeigt einen kleinen signifikanten positiven Effekt (B = .027, SE = .011, p = .015), der jedoch als gering zu bewerten ist (β Genauigkeit = .035; β Wissensgewinn = .028; β Individueller_Nutzen = .042; β Gesellschaftlicher_Nutzen = .036). Es zeigt sich zudem, dass das Vertrauen in die Richtigkeit der Entscheidung zu einer höheren Reputation der Hochschule bei den Befragten führt (β = .685). Der starke gesamte Effekt der Dimension Genauigkeit auf die Reputation der Hochschule (β = .303) wird daher zum Großteil durch den indirekten Effekt (β = .268) der Genauigkeit über das Vertrauen in die Richtigkeit der Auswahlentscheidung erklärt. Hypothese 2.4b wird dahingehend angenommen, dass auch hier das BDGS einen positiven Einfluss auf die Reputation der Hochschule hat, in diesem Rahmen jedoch insbesondere die Überzeugungen von der Genauigkeit der Daten ausschlaggebend sind.</p>
        <p>Die Effekte auf die Bereitschaft gegen die Entscheidung zu protestieren sind im Vergleich insgesamt kleiner. So ist auch der direkte Effekt des BDGS kleiner und nicht signifikant (B = -.022, SE = .015, p = .138). Allerdings zeigt sich auch hier, dass das Vertrauen in die Richtigkeit der Entscheidung erneut einen direkten Einfluss hat (β = -.519). 27 Der starke gesamte Effekt der Dimension Genauigkeit auf die Reputation der Hochschule (β = -.228) wird daher zum Großteil durch den indirekten Effekt (β = -.174) der Genauigkeit über das Vertrauen in die Richtigkeit der Auswahlentscheidung erklärt. Hypothese 2.4c wird auch hier dahingehend angenommen, dass das BDGS einen negativen Einfluss auf die Protestneigung hat, in diesem Rahmen jedoch insbesondere die Überzeugungen von der Genauigkeit der Daten ausschlaggebend sind. Bevor auf die Ausprägung dieser Dimensionen des BDGS und auf etwaige hieraus entstehende Konsequenzen eingegangen wird, muss jedoch zunächst zur Einordnung des Resümees eine Frage beantwortet werden, die quer zur Argumentationslinie und dem Vorgehen der Konzeption und Durchführung der Forschung liegt: Ist der Autor der vorliegenden Arbeit selbst von den eigens hierfür gewonnenen Daten und das hierdurch generierte Wissen über das Konzept des BDGS überzeugt? Wie in den vorangegangenen Abschnitten deutlich wurde, sind die Bedingungen reliabler und valider empirischer Sozialforschung und die hierfür zur Verfügung stehenden Werkzeuge durchaus voraussetzungsreich. Nicht immer kommt man daher an die gewünschte Qualität der Messung und der Daten heran, was mit Blick auf die Limitationen der Beschaffenheit der Messung, der Stichproben und der daraus resultierenden Daten sowie Kausalitätsfragen an den entsprechenden Stellen diskutiert wurde. Der Einsatz des Befragungsinstruments hat jedoch deutlich gemacht, dass dort, wo Menschen zu den Glaubenssätzen des BDGS befragt wurden, eine Verortung des individuellen Zustimmungsgrads zu den formulierten Aussagen erfolgte, und ein überwiegender Teil der Befragten bereitwillig eine persönliche Einschätzung vornahm. Die Messung hat sich im Forschungsfeld erfolgreich einsetzen lassen und ermöglicht erste weiterführende Erkenntnisse über die Beschaffenheit und Ausprägung des konzipierten Glaubens an digitale Daten, die sogleich diskutiert werden. Die vorliegende Konzeption des BDGS und seiner Messung muss sich dann jedoch im weiteren Einsatz in der Forschung bewähren und sich dabei fortwährend an der Erklärungskraft im Rahmen von Theoriebildung und -prüfung messen lassen. In diesem Rahmen stellen sich daher aktuelle weiterführende Forschungsfragen, die anschließend aufgeworfen werden. Die Befunde zeigen also nicht nur, dass sich die BDGS-Skala reliabel und erfolgreich zur Messung in unterschiedlichen Forschungszusammenhängen einsetzen lässt und Erkenntnisse bezüglich der Ausprägung einzelner Glaubensüberzeugungen erlaubt. Sie besitzt unter der Annahme eines stabilen Glaubensmusters dann weiterhin auch Einflüsse auf situativ aufzurufende Kognitionen, wenn Personen auf neue Anwendungen der datenverarbeitenden, mustererkennenden KI in unterschiedlichen Anwendungsfeldern und Lebensbereichen treffen.Die Effekte auf die Bereitschaft gegen die Entscheidung zu protestieren sind im Vergleich insgesamt kleiner. So ist auch der direkte Effekt des BDGS kleiner und nicht signifikant (B = -.022, SE = .015, p = .138). Allerdings zeigt sich auch hier, dass das Vertrauen in die Richtigkeit der Entscheidung erneut einen direkten Einfluss hat (β = -.519). 27 Der starke gesamte Effekt der Dimension Genauigkeit auf die Reputation der Hochschule (β = -.228) wird daher zum Großteil durch den indirekten Effekt (β = -.174) der Genauigkeit über das Vertrauen in die Richtigkeit der Auswahlentscheidung erklärt. Hypothese 2.4c wird auch hier dahingehend angenommen, dass das BDGS einen negativen Einfluss auf die Protestneigung hat, in diesem Rahmen jedoch insbesondere die Überzeugungen von der Genauigkeit der Daten ausschlaggebend sind. Bevor auf die Ausprägung dieser Dimensionen des BDGS und auf etwaige hieraus entstehende Konsequenzen eingegangen wird, muss jedoch zunächst zur Einordnung des Resümees eine Frage beantwortet werden, die quer zur Argumentationslinie und dem Vorgehen der Konzeption und Durchführung der Forschung liegt: Ist der Autor der vorliegenden Arbeit selbst von den eigens hierfür gewonnenen Daten und das hierdurch generierte Wissen über das Konzept des BDGS überzeugt? Wie in den vorangegangenen Abschnitten deutlich wurde, sind die Bedingungen reliabler und valider empirischer Sozialforschung und die hierfür zur Verfügung stehenden Werkzeuge durchaus voraussetzungsreich. Nicht immer kommt man daher an die gewünschte Qualität der Messung und der Daten heran, was mit Blick auf die Limitationen der Beschaffenheit der Messung, der Stichproben und der daraus resultierenden Daten sowie Kausalitätsfragen an den entsprechenden Stellen diskutiert wurde. Der Einsatz des Befragungsinstruments hat jedoch deutlich gemacht, dass dort, wo Menschen zu den Glaubenssätzen des BDGS befragt wurden, eine Verortung des individuellen Zustimmungsgrads zu den formulierten Aussagen erfolgte, und ein überwiegender Teil der Befragten bereitwillig eine persönliche Einschätzung vornahm. Die Messung hat sich im Forschungsfeld erfolgreich einsetzen lassen und ermöglicht erste weiterführende Erkenntnisse über die Beschaffenheit und Ausprägung des konzipierten Glaubens an digitale Daten, die sogleich diskutiert werden. Die vorliegende Konzeption des BDGS und seiner Messung muss sich dann jedoch im weiteren Einsatz in der Forschung bewähren und sich dabei fortwährend an der Erklärungskraft im Rahmen von Theoriebildung und -prüfung messen lassen. In diesem Rahmen stellen sich daher aktuelle weiterführende Forschungsfragen, die anschließend aufgeworfen werden. Die Befunde zeigen also nicht nur, dass sich die BDGS-Skala reliabel und erfolgreich zur Messung in unterschiedlichen Forschungszusammenhängen einsetzen lässt und Erkenntnisse bezüglich der Ausprägung einzelner Glaubensüberzeugungen erlaubt. Sie besitzt unter der Annahme eines stabilen Glaubensmusters dann weiterhin auch Einflüsse auf situativ aufzurufende Kognitionen, wenn Personen auf neue Anwendungen der datenverarbeitenden, mustererkennenden KI in unterschiedlichen Anwendungsfeldern und Lebensbereichen treffen.</p>
        <p>Je nachdem aus welcher Perspektive man die vorliegenden Erkenntnisse zum Glauben an die digitalen Daten betrachtet, ergeben sich nun unterschiedliche Schlussfolgerungen und Frageschwerpunkte für eine anschließende Beschäftigung mit gesellschaftlichen Fragen zur Digitalisierung und der Quantifizierung des Sozialen.Je nachdem aus welcher Perspektive man die vorliegenden Erkenntnisse zum Glauben an die digitalen Daten betrachtet, ergeben sich nun unterschiedliche Schlussfolgerungen und Frageschwerpunkte für eine anschließende Beschäftigung mit gesellschaftlichen Fragen zur Digitalisierung und der Quantifizierung des Sozialen.</p>
        <p>Insbesondere die Zivilgesellschaft sollte dabei eine Erwartungshaltung an die Potentiale und Wirkmächtigkeit von IuK sowie der Sammlung und Auswertung digitaler Daten bedenken und hinterfragen. Diese Arbeit, die auch vor dem Eindruck einer seit dem Frühjahr 2020 andauernden gesellschaftlichen Krisenlage der weltweiten COVID-19-Pandemie entstanden ist, attestiert einen weit verbreiteten Glauben an den Erkenntnis-und Nutzengewinn aus den digitalen Daten. Die aktuelle Krisensituation hat dabei allerdings vor Augen geführt, dass auch der technische Fortschritt die Gesellschaft nicht ausreichend vor dem Hereinbrechen des Ausnahmezustands schützen, geschweige denn vor der Wucht der Veränderung warnen oder auf diese vorbereiten konnte. Die Vorhersagefähigkeiten datenbasierter Prognosemodelle versagten oder kamen schnell an ihre Grenzen. Die Bedeutung dieser Daten wird nun auch immer wieder zur Bewältigung der Krisensituation hervorgehoben, hat aber zumindest ihr Aufkommen nicht verhindern können. Es stellt sich die Frage, ob dies auch Konsequenzen für die gesellschaftliche Wahrnehmung digitaler Daten hat. Ist der Glaube an das Potential von Big Data womöglich erschüttert worden durch das Versagen steuerbarer Normalität; und falls ja, wie nachhaltig? Oder führt der Glaube dazu, dass nun neue und weitreichendere Forderungen nach der Quantifizierung des Sozialen entstehen, um der Krise nun Herr zu werden oder Frühwarnsysteme einzurichten? So wird im Rahmen der Bewältigung der COVID-19-Pandemie auch immer wieder das Potential datenbasierter Lösungen hervorgehoben wie bspw. das Tracking von persönlichen Bewegungsprofilen auf Grundlage der Daten von Mobiltelefonen (Föderl-Schmid &amp; Hurtz, 2020). Die Ausbreitung der Krankheit könne -so zumindest die Hoffnung -somit besser verfolgt, verstanden und eingedämmt werden. Hierbei richtet sich der Blick auch auf andere Länder wie Israel, Südkorea und China, die schnell entsprechende Maßnahmen einleiteten, die sich zumindest auf den ersten Blick bewährt haben. Während sich in Ländern wie Deutschland hier immer auch Fragen und Einwände bezüglich der informationellen Selbstbestimmung stellen, könnte ein ausgeprägter Glaube an die digitalen Daten bei manchen nun den Ruf nach noch umfangreicherer und systematischer Datensammlung laut werden lassen. Es stellen sich mit Blick auf Privatsphäre und Freiheitsrechten konkrete Fragen der Abwägung von etwaigem Nutzen und Schaden extensiver Speicherung und Verwertung digitaler Individualdaten, die ob der Dringlichkeit der Entwicklungen schnell vom Tisch gewischt werden könnten. Denn große Versprechungen vermeintlicher Erkenntnisgewinne, die im Rahmen gesellschaftlicher Steuerungslogik so dringend benötigt werden, können insbesondere in Notsituationen dazu führen, dass etwaige Nutzengewinne überbewertet und Nachteile ausgeblendet werden. In diesem Zusammenhang ist auch die enge Verzahnung der Nutzenerwartungen bezüglich digitaler Daten für das Selbst mit einem Nutzen für die Gesellschaft als durchaus problematisch zu werten. So könnte die Angst vor dem Virus uns dazu bewegen, unsere Gesundheitsdaten anderen bereitwilliger zur Verfügung zu stellen. Getrieben vom Glauben, dass diese Daten genaue Einblicke in den Verbreitungs-und Krankheitsverlauf von COVID-19 erlauben und Erkenntnisgewinne im Kampf gegen die Epidemie liefern. Dieser Erkenntnisgewinn nützt dann im Fall der Fälle vielleicht nicht nur der Gesellschaft, sondern sogar einem höchst persönlich, so womöglich die Erwartung. Gleichzeitig macht man sich angreifbar und verletzlich, wenn die Daten von anderen missbraucht werden sollten. Was dem Kollektiv nützen mag, steht womöglich nicht immer im Einklang mit Individualinteressen, sondern kann sich im Widerstreit zwischen individueller Freiheit und gesellschaftlicher Sicherheit voneinander entkoppeln und auseinanderfallen. Vor dem Hintergrund eines sodann trügerischen Glaubens an datenbasierte Allheilmittel sollte daher stets kritisch geprüft und reflektiert werden, inwieweit man dem Drängen nach schnellen und allumfassenden technischen Lösungen hier nachgibt, die eine weitreichende Datenpreisgabe erfordern und zur eingeschlichenen Normalität werden. Es stellen sich daher viele hochgradig aktuelle Fragen für die Zivilgesellschaft nach den Konsequenzen eines Glaubens an die digitalen Daten, die sich eine starke Zivilgesellschaft trotz oder gerade aufgrund der aktuellen Dringlichkeit der gesellschaftlichen Krisenlage weiterhin stellen sollte.Insbesondere die Zivilgesellschaft sollte dabei eine Erwartungshaltung an die Potentiale und Wirkmächtigkeit von IuK sowie der Sammlung und Auswertung digitaler Daten bedenken und hinterfragen. Diese Arbeit, die auch vor dem Eindruck einer seit dem Frühjahr 2020 andauernden gesellschaftlichen Krisenlage der weltweiten COVID-19-Pandemie entstanden ist, attestiert einen weit verbreiteten Glauben an den Erkenntnis-und Nutzengewinn aus den digitalen Daten. Die aktuelle Krisensituation hat dabei allerdings vor Augen geführt, dass auch der technische Fortschritt die Gesellschaft nicht ausreichend vor dem Hereinbrechen des Ausnahmezustands schützen, geschweige denn vor der Wucht der Veränderung warnen oder auf diese vorbereiten konnte. Die Vorhersagefähigkeiten datenbasierter Prognosemodelle versagten oder kamen schnell an ihre Grenzen. Die Bedeutung dieser Daten wird nun auch immer wieder zur Bewältigung der Krisensituation hervorgehoben, hat aber zumindest ihr Aufkommen nicht verhindern können. Es stellt sich die Frage, ob dies auch Konsequenzen für die gesellschaftliche Wahrnehmung digitaler Daten hat. Ist der Glaube an das Potential von Big Data womöglich erschüttert worden durch das Versagen steuerbarer Normalität; und falls ja, wie nachhaltig? Oder führt der Glaube dazu, dass nun neue und weitreichendere Forderungen nach der Quantifizierung des Sozialen entstehen, um der Krise nun Herr zu werden oder Frühwarnsysteme einzurichten? So wird im Rahmen der Bewältigung der COVID-19-Pandemie auch immer wieder das Potential datenbasierter Lösungen hervorgehoben wie bspw. das Tracking von persönlichen Bewegungsprofilen auf Grundlage der Daten von Mobiltelefonen (Föderl-Schmid &amp; Hurtz, 2020). Die Ausbreitung der Krankheit könne -so zumindest die Hoffnung -somit besser verfolgt, verstanden und eingedämmt werden. Hierbei richtet sich der Blick auch auf andere Länder wie Israel, Südkorea und China, die schnell entsprechende Maßnahmen einleiteten, die sich zumindest auf den ersten Blick bewährt haben. Während sich in Ländern wie Deutschland hier immer auch Fragen und Einwände bezüglich der informationellen Selbstbestimmung stellen, könnte ein ausgeprägter Glaube an die digitalen Daten bei manchen nun den Ruf nach noch umfangreicherer und systematischer Datensammlung laut werden lassen. Es stellen sich mit Blick auf Privatsphäre und Freiheitsrechten konkrete Fragen der Abwägung von etwaigem Nutzen und Schaden extensiver Speicherung und Verwertung digitaler Individualdaten, die ob der Dringlichkeit der Entwicklungen schnell vom Tisch gewischt werden könnten. Denn große Versprechungen vermeintlicher Erkenntnisgewinne, die im Rahmen gesellschaftlicher Steuerungslogik so dringend benötigt werden, können insbesondere in Notsituationen dazu führen, dass etwaige Nutzengewinne überbewertet und Nachteile ausgeblendet werden. In diesem Zusammenhang ist auch die enge Verzahnung der Nutzenerwartungen bezüglich digitaler Daten für das Selbst mit einem Nutzen für die Gesellschaft als durchaus problematisch zu werten. So könnte die Angst vor dem Virus uns dazu bewegen, unsere Gesundheitsdaten anderen bereitwilliger zur Verfügung zu stellen. Getrieben vom Glauben, dass diese Daten genaue Einblicke in den Verbreitungs-und Krankheitsverlauf von COVID-19 erlauben und Erkenntnisgewinne im Kampf gegen die Epidemie liefern. Dieser Erkenntnisgewinn nützt dann im Fall der Fälle vielleicht nicht nur der Gesellschaft, sondern sogar einem höchst persönlich, so womöglich die Erwartung. Gleichzeitig macht man sich angreifbar und verletzlich, wenn die Daten von anderen missbraucht werden sollten. Was dem Kollektiv nützen mag, steht womöglich nicht immer im Einklang mit Individualinteressen, sondern kann sich im Widerstreit zwischen individueller Freiheit und gesellschaftlicher Sicherheit voneinander entkoppeln und auseinanderfallen. Vor dem Hintergrund eines sodann trügerischen Glaubens an datenbasierte Allheilmittel sollte daher stets kritisch geprüft und reflektiert werden, inwieweit man dem Drängen nach schnellen und allumfassenden technischen Lösungen hier nachgibt, die eine weitreichende Datenpreisgabe erfordern und zur eingeschlichenen Normalität werden. Es stellen sich daher viele hochgradig aktuelle Fragen für die Zivilgesellschaft nach den Konsequenzen eines Glaubens an die digitalen Daten, die sich eine starke Zivilgesellschaft trotz oder gerade aufgrund der aktuellen Dringlichkeit der gesellschaftlichen Krisenlage weiterhin stellen sollte.</p>
        <p>Aus Sicht der Politik ist mitzunehmen, dass in weiten Kreisen der Bevölkerung eine hohe Akzeptanz der Digitalisierung besteht, die mit dem skizzierten Glauben an digitalen Daten zusammenhängt. Das Feld ist -zumindest dem momentanen Anschein nach -bestellt. Politische Programme und Maßnahmen stoßen auf eine positive Grundhaltung in der deutschen Bevölkerung, wenn sie sich mit dem Digitallabel schmücken können. Der Ruf nach Digitalisierung und hier insbesondere der Datensammlung und -verwertung erfährt aktuell insgesamt kaum breite Ablehnung. Dementsprechend steht die Bevölkerung auch verwandten Phänomenen, die derzeit eine hohe Aufmerksamkeit erfahren, wie etwa der KI, weitgehend positiv gegenüber. Bestrebungen, Reformen und Innovationen auf Grundlage digitaler IuK in unterschiedlichen gesellschaftlichen Bereichen politisch durchzusetzen und zu implementieren, erscheinen vor diesem Hintergrund vielversprechend. Zumindest solange sie nicht ohne guten Grund den Kern bürgerlicher Rechte und Freiheiten gravierend einschränken oder verletzen. Gleichzeitig besteht jedoch auch die Gefahr, dass hohe Erwartungen, genährt durch einen Glauben an die Potentiale digitaler Daten, durchaus enttäuscht werden können. Politische Programme und Reformen sollten daher in enger Abstimmung mit den direkt von ihnen Betroffenen erarbeitet werden, die häufig auch eine ganz eigene Expertise für die wirksame politische Gestaltung des Entwurfs einer digitalen Gesellschaft haben. Die beschlossenen Programme bedürfen dabei einer fortlaufenden Evaluation, die sie auf tatsächliche Erkenntnis-und Nutzengewinne hin analysiert. Daher sollten sich auch die politischen Akteur*innen und Parteien nicht dem Glauben hingeben, dass irgendwie immer und überall digitalisiert werden oder alles Mögliche in digitale Daten übersetzt werden müsste. Es sollte beständig abgewogen werden, weshalb digitalisiert wird, wofür Daten gesammelt werden und welche konkreten Maßnahmen vor dem Hintergrund begrenzter öffentlicher Ressourcen am erfolgversprechendsten sind. Ziel sollte es sein, den Wähler*innen die gesellschaftlichen Veränderungen nicht einfach vorzusetzen und sich dabei in mancher Hinsicht einem Überbietungswettbewerb zu ergeben, der das technisch Mögliche ausreizt, während andere Themen verschlafen werden. Dabei sollten konkrete Begehren und Befürchtungen in der Bevölkerung ernst genommen werden. So sind Digitalisierung und diesbezügliche Bedenken bspw. gar nicht so einfach in eine Rangfolge zu bringen, sondern beeinflussen sich fortwährend gegenseitig. Hiermit müssen sich Politiktreibende zwingend auseinandersetzen, wollen sie politische Macht erhalten und ausüben sowie in Fragen der Digitalisierung der Gesellschaft als kompetent wahrgenommen werden. In der Beschäftigung mit der Digitalisierung erwerben sie selbst dabei ganz eigene Vorstellungen von der Beschaffenheit datenbasierter Techniken und Anwendungen und den Möglichkeiten und Konsequenzen der Quantifizierung des Sozialen. Auch Personen in politischen Ämtern und Funktionen sollten daher ihre eigenen Überzeugungen und Ideen vor dem Hintergrund ihres öffentlichen Auftrags hinterfragen. Daher sollte sich Anschlussforschung auch auf die Glaubensüberzeugungen von Akteur*innen des politischen Systems beziehen, seien es Politiktreibende oder Personen aus der Leitungsebene öffentlicher Verwaltung, da ihnen nicht nur in Krisenzeiten durch ihre besondere Rolle eine immense Bedeutung bei der Gestaltung und Organisation der digitalen Gesellschaft zukommt.Aus Sicht der Politik ist mitzunehmen, dass in weiten Kreisen der Bevölkerung eine hohe Akzeptanz der Digitalisierung besteht, die mit dem skizzierten Glauben an digitalen Daten zusammenhängt. Das Feld ist -zumindest dem momentanen Anschein nach -bestellt. Politische Programme und Maßnahmen stoßen auf eine positive Grundhaltung in der deutschen Bevölkerung, wenn sie sich mit dem Digitallabel schmücken können. Der Ruf nach Digitalisierung und hier insbesondere der Datensammlung und -verwertung erfährt aktuell insgesamt kaum breite Ablehnung. Dementsprechend steht die Bevölkerung auch verwandten Phänomenen, die derzeit eine hohe Aufmerksamkeit erfahren, wie etwa der KI, weitgehend positiv gegenüber. Bestrebungen, Reformen und Innovationen auf Grundlage digitaler IuK in unterschiedlichen gesellschaftlichen Bereichen politisch durchzusetzen und zu implementieren, erscheinen vor diesem Hintergrund vielversprechend. Zumindest solange sie nicht ohne guten Grund den Kern bürgerlicher Rechte und Freiheiten gravierend einschränken oder verletzen. Gleichzeitig besteht jedoch auch die Gefahr, dass hohe Erwartungen, genährt durch einen Glauben an die Potentiale digitaler Daten, durchaus enttäuscht werden können. Politische Programme und Reformen sollten daher in enger Abstimmung mit den direkt von ihnen Betroffenen erarbeitet werden, die häufig auch eine ganz eigene Expertise für die wirksame politische Gestaltung des Entwurfs einer digitalen Gesellschaft haben. Die beschlossenen Programme bedürfen dabei einer fortlaufenden Evaluation, die sie auf tatsächliche Erkenntnis-und Nutzengewinne hin analysiert. Daher sollten sich auch die politischen Akteur*innen und Parteien nicht dem Glauben hingeben, dass irgendwie immer und überall digitalisiert werden oder alles Mögliche in digitale Daten übersetzt werden müsste. Es sollte beständig abgewogen werden, weshalb digitalisiert wird, wofür Daten gesammelt werden und welche konkreten Maßnahmen vor dem Hintergrund begrenzter öffentlicher Ressourcen am erfolgversprechendsten sind. Ziel sollte es sein, den Wähler*innen die gesellschaftlichen Veränderungen nicht einfach vorzusetzen und sich dabei in mancher Hinsicht einem Überbietungswettbewerb zu ergeben, der das technisch Mögliche ausreizt, während andere Themen verschlafen werden. Dabei sollten konkrete Begehren und Befürchtungen in der Bevölkerung ernst genommen werden. So sind Digitalisierung und diesbezügliche Bedenken bspw. gar nicht so einfach in eine Rangfolge zu bringen, sondern beeinflussen sich fortwährend gegenseitig. Hiermit müssen sich Politiktreibende zwingend auseinandersetzen, wollen sie politische Macht erhalten und ausüben sowie in Fragen der Digitalisierung der Gesellschaft als kompetent wahrgenommen werden. In der Beschäftigung mit der Digitalisierung erwerben sie selbst dabei ganz eigene Vorstellungen von der Beschaffenheit datenbasierter Techniken und Anwendungen und den Möglichkeiten und Konsequenzen der Quantifizierung des Sozialen. Auch Personen in politischen Ämtern und Funktionen sollten daher ihre eigenen Überzeugungen und Ideen vor dem Hintergrund ihres öffentlichen Auftrags hinterfragen. Daher sollte sich Anschlussforschung auch auf die Glaubensüberzeugungen von Akteur*innen des politischen Systems beziehen, seien es Politiktreibende oder Personen aus der Leitungsebene öffentlicher Verwaltung, da ihnen nicht nur in Krisenzeiten durch ihre besondere Rolle eine immense Bedeutung bei der Gestaltung und Organisation der digitalen Gesellschaft zukommt.</p>
        <p>Für empirisch forschende Wissenschaft, deren Auftrag es ist, sich der Beantwortung der aufgeworfenen Fragen anzunehmen, wird der Glaube an digitale Daten in zweierlei Hinsicht relevant, gehören Daten doch für sie zum Kerngeschäft. So sollte zum einen die durch boyd und Crawford (2012) Der Anteil der EU und ihrer Mitgliedsländer an der Weltbevölkerung und am Weltwirtschaftsprodukt ist rückläufig (Europäische Kommission, 2014;International Monetary Fund, 2019). Das gilt auch bezüglich des Anteils an den weltweit produzierten Daten. Längst entsteht ein Großteil der Daten nicht mehr innerhalb der EU. Von den 100 am meisten besuchten Webseiten kamen 2019 zwei aus der EU und stammen von der britischen öffentlich-rechtlichen Rundfunkanstalt BBC (Routley, 2019). Nach dem Brexit gibt es also keine europäische Webseite in den Top 100. Auch in der von Forbes rausgegebenen Rangliste der umsatzstärksten Unternehmen finden sich für den Sektor Technologie wenige europäische Unternehmen. Als erstes europäisches Unternehmen kommt das in Irland ansässige Technologieberatungsunternehmen Accenture auf Platz 20, gefolgt vom deutschen Unternehmen SAP auf Rang 33. Die umsatzstärksten Unternehmen kommen überwiegend aus den USA oder Südost-Asien. Selbstredend erzeugen und verwerten heutzutage nicht nur Technologie-Unternehmen digitale Daten. Auch in der Industrie, einer starken Domäne der deutschen Wirtschaft, fallen viele digitale Daten an, die ökonomisch verwertet werden können. Doch der europäische Einfluss auf der Weltbühne schwindet.Für empirisch forschende Wissenschaft, deren Auftrag es ist, sich der Beantwortung der aufgeworfenen Fragen anzunehmen, wird der Glaube an digitale Daten in zweierlei Hinsicht relevant, gehören Daten doch für sie zum Kerngeschäft. So sollte zum einen die durch boyd und Crawford (2012) Der Anteil der EU und ihrer Mitgliedsländer an der Weltbevölkerung und am Weltwirtschaftsprodukt ist rückläufig (Europäische Kommission, 2014;International Monetary Fund, 2019). Das gilt auch bezüglich des Anteils an den weltweit produzierten Daten. Längst entsteht ein Großteil der Daten nicht mehr innerhalb der EU. Von den 100 am meisten besuchten Webseiten kamen 2019 zwei aus der EU und stammen von der britischen öffentlich-rechtlichen Rundfunkanstalt BBC (Routley, 2019). Nach dem Brexit gibt es also keine europäische Webseite in den Top 100. Auch in der von Forbes rausgegebenen Rangliste der umsatzstärksten Unternehmen finden sich für den Sektor Technologie wenige europäische Unternehmen. Als erstes europäisches Unternehmen kommt das in Irland ansässige Technologieberatungsunternehmen Accenture auf Platz 20, gefolgt vom deutschen Unternehmen SAP auf Rang 33. Die umsatzstärksten Unternehmen kommen überwiegend aus den USA oder Südost-Asien. Selbstredend erzeugen und verwerten heutzutage nicht nur Technologie-Unternehmen digitale Daten. Auch in der Industrie, einer starken Domäne der deutschen Wirtschaft, fallen viele digitale Daten an, die ökonomisch verwertet werden können. Doch der europäische Einfluss auf der Weltbühne schwindet.</p>
        <p>Dabei ist die europäische Idee nach wie vor mit bestimmten Werten und einem aufgeklärten Menschenbild verbunden -und das ist nicht nur eine Floskel, sondern zeigt sich an konkreten Beispielen. Informationelle Selbstbestimmung ist ein Gut, das in anderen Ländern dieser Welt durchaus anders bewertet wird als in der EU. Auch deshalb hat sich die EU mit der Europäischen Datenschutz-Grundverordnung (EU-DSGVO) einen rechtlichen Rahmen der Datenverwertung gegeben, der weit über den Datenschutz hinausgeht, der anderswo praktiziert wird. Bei aller Kritik an der tatsächlichen Umsetzung zeigt der Gedanke, den Menschen mit Blick auf die Digitalisierung gewisse Rechte einzuräumen, dass es den europäischen Gesellschaften nicht egal ist, was den Bürger*innen im Rahmen der Digitalisierung widerfährt. Mit Blick auf Rechtsstaat und Zivilgesellschaft stehen die europäischen Gesellschaften im internationalen Vergleich bislang gut da, auch und insbesondere, was die Digitalisierung betrifft. Nun stößt natürlich auch jenes Regelwerk in einer globalisierten Welt schnell an seine Grenzen und es wird mit Nachdruck darauf verwiesen, dass Politik und Rechtsprechung kaum mit der Digitalisierung Schritt halten können. Die Bürger*innen Europas sollten und dürfen sich dabei keiner Illusion über Europas Gewicht auf der digitalen Weltbühne hingeben. Europas Anziehung speist sich aus einem anderswo unerreichten Lebensstil und dem relativen Wohlstand, der eine notwendige, jedoch nicht hinreichende Bedingung dieser Strahlkraft ist.Dabei ist die europäische Idee nach wie vor mit bestimmten Werten und einem aufgeklärten Menschenbild verbunden -und das ist nicht nur eine Floskel, sondern zeigt sich an konkreten Beispielen. Informationelle Selbstbestimmung ist ein Gut, das in anderen Ländern dieser Welt durchaus anders bewertet wird als in der EU. Auch deshalb hat sich die EU mit der Europäischen Datenschutz-Grundverordnung (EU-DSGVO) einen rechtlichen Rahmen der Datenverwertung gegeben, der weit über den Datenschutz hinausgeht, der anderswo praktiziert wird. Bei aller Kritik an der tatsächlichen Umsetzung zeigt der Gedanke, den Menschen mit Blick auf die Digitalisierung gewisse Rechte einzuräumen, dass es den europäischen Gesellschaften nicht egal ist, was den Bürger*innen im Rahmen der Digitalisierung widerfährt. Mit Blick auf Rechtsstaat und Zivilgesellschaft stehen die europäischen Gesellschaften im internationalen Vergleich bislang gut da, auch und insbesondere, was die Digitalisierung betrifft. Nun stößt natürlich auch jenes Regelwerk in einer globalisierten Welt schnell an seine Grenzen und es wird mit Nachdruck darauf verwiesen, dass Politik und Rechtsprechung kaum mit der Digitalisierung Schritt halten können. Die Bürger*innen Europas sollten und dürfen sich dabei keiner Illusion über Europas Gewicht auf der digitalen Weltbühne hingeben. Europas Anziehung speist sich aus einem anderswo unerreichten Lebensstil und dem relativen Wohlstand, der eine notwendige, jedoch nicht hinreichende Bedingung dieser Strahlkraft ist.</p>
        <p>Die Generationen, die nach den großen Kriegen des 20. Jahrhundert geboren sind, schauen auf Europa und fragen sich, wie es jemals anders sein könnte -im Guten wie im Schlechten. Das ist nicht als Abgesang auf Europa zu verstehen, sondern als Aufforderung vor dem Hintergrund der Überzeugungen vom Potential und der Wirkmächtigkeit digitaler Daten in Europa und Deutschland weiterhin kritisch über die Digitalisierung nachzudenken. Es ist das Resümee der vorliegenden Arbeit: Es reicht nicht daran zu glauben, dass Sammeln und Auswerten digitaler Daten Erkenntnisse ermöglichen, die dem Individuum und der Gesellschaft Nutzen bringen, man muss sich auch aktiv und selbstkritisch darum bemühen. Meine Hoffnung ist, dass diese Arbeit einige Erkenntnisse und Denkanstöße zur Reflexion über den Menschen in der digitalen Gesellschaft liefert. Nicht nur, was die Gesellschaft über und durch die Sammlung und Verwertung digitaler Daten weiß, sondern insbesondere, was wir glauben durch und über diese Daten wissen zu können, ist und bleibt eine der wichtigen Fragen unserer Zeit.Die Generationen, die nach den großen Kriegen des 20. Jahrhundert geboren sind, schauen auf Europa und fragen sich, wie es jemals anders sein könnte -im Guten wie im Schlechten. Das ist nicht als Abgesang auf Europa zu verstehen, sondern als Aufforderung vor dem Hintergrund der Überzeugungen vom Potential und der Wirkmächtigkeit digitaler Daten in Europa und Deutschland weiterhin kritisch über die Digitalisierung nachzudenken. Es ist das Resümee der vorliegenden Arbeit: Es reicht nicht daran zu glauben, dass Sammeln und Auswerten digitaler Daten Erkenntnisse ermöglichen, die dem Individuum und der Gesellschaft Nutzen bringen, man muss sich auch aktiv und selbstkritisch darum bemühen. Meine Hoffnung ist, dass diese Arbeit einige Erkenntnisse und Denkanstöße zur Reflexion über den Menschen in der digitalen Gesellschaft liefert. Nicht nur, was die Gesellschaft über und durch die Sammlung und Verwertung digitaler Daten weiß, sondern insbesondere, was wir glauben durch und über diese Daten wissen zu können, ist und bleibt eine der wichtigen Fragen unserer Zeit.</p>
        <p>Open Access Dieses Kapitel wird unter der Creative Commons Namensnennung 4.0 International Lizenz (http://creativecommons.org/licenses/by/4.0/deed.de) veröffentlicht, welche die Nutzung, Vervielfältigung, Bearbeitung, Verbreitung und Wiedergabe in jeglichem Medium und Format erlaubt, sofern Sie den/die ursprünglichen Autor(en) und die Quelle ordnungsgemäß nennen, einen Link zur Creative Commons Lizenz beifügen und angeben, ob Änderungen vorgenommen wurden.Open Access Dieses Kapitel wird unter der Creative Commons Namensnennung 4.0 International Lizenz (http://creativecommons.org/licenses/by/4.0/deed.de) veröffentlicht, welche die Nutzung, Vervielfältigung, Bearbeitung, Verbreitung und Wiedergabe in jeglichem Medium und Format erlaubt, sofern Sie den/die ursprünglichen Autor(en) und die Quelle ordnungsgemäß nennen, einen Link zur Creative Commons Lizenz beifügen und angeben, ob Änderungen vorgenommen wurden.</p>
        <p>Die in diesem Kapitel enthaltenen Bilder und sonstiges Drittmaterial unterliegen ebenfalls der genannten Creative Commons Lizenz, sofern sich aus der Abbildungslegende nichts anderes ergibt. Sofern das betreffende Material nicht unter der genannten Creative Commons Lizenz steht und die betreffende Handlung nicht nach gesetzlichen Vorschriften erlaubt ist, ist für die oben aufgeführten Weiterverwendungen des Materials die Einwilligung des jeweiligen Rechteinhabers einzuholen.Die in diesem Kapitel enthaltenen Bilder und sonstiges Drittmaterial unterliegen ebenfalls der genannten Creative Commons Lizenz, sofern sich aus der Abbildungslegende nichts anderes ergibt. Sofern das betreffende Material nicht unter der genannten Creative Commons Lizenz steht und die betreffende Handlung nicht nach gesetzlichen Vorschriften erlaubt ist, ist für die oben aufgeführten Weiterverwendungen des Materials die Einwilligung des jeweiligen Rechteinhabers einzuholen.</p>
        <p>und Erhebung 1.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156 9.2.1 Feldphasen und Sample . . . . . . . . . . . . . . . . . . . . . . . . 158 9.2.2 Datenauswertung und Ergebnisse . . . . . . . . . . . . . . . 161 9.2.3 Diskussion der Ergebnisse . . . . . . . . . . . . . . . . . . . . . 173 9.3 Reflexion über die Skalenerstellung im Anschluss an Skalenkonstruktion und Validierung . . . . . . . . . . . . . . . . . . . 176 9.3.1 Problematik der Formulierungen der Fragebogenitems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176 9.3.2 Problematik der Präsentation der Fragebogenitems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181 10.1 den Menschen stößtund Erhebung 1.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156 9.2.1 Feldphasen und Sample . . . . . . . . . . . . . . . . . . . . . . . . 158 9.2.2 Datenauswertung und Ergebnisse . . . . . . . . . . . . . . . 161 9.2.3 Diskussion der Ergebnisse . . . . . . . . . . . . . . . . . . . . . 173 9.3 Reflexion über die Skalenerstellung im Anschluss an Skalenkonstruktion und Validierung . . . . . . . . . . . . . . . . . . . 176 9.3.1 Problematik der Formulierungen der Fragebogenitems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176 9.3.2 Problematik der Präsentation der Fragebogenitems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181 10.1 den Menschen stößt</p>
        <p>ger Zahlen illustriert, entstehen jede Sekunde Unmengen von digitalen Daten. Zeit spielt also im Entstehungskontext der Daten eine elementare Rolle, denn zu den Unmengen an bereits vorhandenen Daten kommen laufend neue hinzu. Es kann also bei Big Data keine umfassende Betrachtung des Phänomens erfolgen, ohne sich die Zeitlichkeit als notwendige Komponente einer Definition vor Augen zu führen (Ylijoki &amp; Porras, 2016). Allein die Nutzung von Online-Services durch Internetnutzer trägt zu einem beständig wachsenden Berg an digitalen Daten bei. Seiten wie Internet Live Stats 6 , die das Verhalten der Nutzer und den dabei entstehenden Internetverkehr visualisieren, veranschaulichen dies eindrucksvoll. So werden weltweit jede Sekunde abertausende Bilder und Textbeiträge auf Internetserver hochgeladen, geteilt, bewertet und kommentiert. Nicht nur das Ausmaß der digitalen Daten ist also sehr groß, sondern auch die Geschwindigkeit, mit der die vielen Daten entstehen. Laut den Internet Live Stats sind das Stand Februar 2021 rund 112 Gigabyte -jede Sekunde. Dadurch fordert das Phänomen Big Data auch gängige Datenspeicherungsmöglichkeiten heraus. So haben die meisten Unternehmen mittlerweile entsprechende Kapazitäten aufgebaut, um die bei der Verwendung ihrer Dienste anfallenden Daten zu speichern. Für das Jahr 2017 berichtet Thibodeau (2017) von weltweit 8,4ger Zahlen illustriert, entstehen jede Sekunde Unmengen von digitalen Daten. Zeit spielt also im Entstehungskontext der Daten eine elementare Rolle, denn zu den Unmengen an bereits vorhandenen Daten kommen laufend neue hinzu. Es kann also bei Big Data keine umfassende Betrachtung des Phänomens erfolgen, ohne sich die Zeitlichkeit als notwendige Komponente einer Definition vor Augen zu führen (Ylijoki &amp; Porras, 2016). Allein die Nutzung von Online-Services durch Internetnutzer trägt zu einem beständig wachsenden Berg an digitalen Daten bei. Seiten wie Internet Live Stats 6 , die das Verhalten der Nutzer und den dabei entstehenden Internetverkehr visualisieren, veranschaulichen dies eindrucksvoll. So werden weltweit jede Sekunde abertausende Bilder und Textbeiträge auf Internetserver hochgeladen, geteilt, bewertet und kommentiert. Nicht nur das Ausmaß der digitalen Daten ist also sehr groß, sondern auch die Geschwindigkeit, mit der die vielen Daten entstehen. Laut den Internet Live Stats sind das Stand Februar 2021 rund 112 Gigabyte -jede Sekunde. Dadurch fordert das Phänomen Big Data auch gängige Datenspeicherungsmöglichkeiten heraus. So haben die meisten Unternehmen mittlerweile entsprechende Kapazitäten aufgebaut, um die bei der Verwendung ihrer Dienste anfallenden Daten zu speichern. Für das Jahr 2017 berichtet Thibodeau (2017) von weltweit 8,4</p>
        <p>Mauro et al. (2016)Mauro et al. (2016)</p>
        <p>haben mit Blick auf die allgemeine Literatur zu Big Data den Versuch einer Synthese von Definitionen unternommen. Die Autoren legen ihrer Betrachtung einen ganzen Korpus an Literatur aus Industrie und Wissenschaft zu Grunde. Die finale Definition von Big Data von Mauro et al. (2016) liest sich mithin ähnlich der bereits besprochenen Beschreibungsdimensionen: "Big Data is the Information asset characterised by such a High Volume, Velocity and Variety to require specific Technology and Analytical Methods for its transformation into Value [sic]" (S. 131).haben mit Blick auf die allgemeine Literatur zu Big Data den Versuch einer Synthese von Definitionen unternommen. Die Autoren legen ihrer Betrachtung einen ganzen Korpus an Literatur aus Industrie und Wissenschaft zu Grunde. Die finale Definition von Big Data von Mauro et al. (2016) liest sich mithin ähnlich der bereits besprochenen Beschreibungsdimensionen: "Big Data is the Information asset characterised by such a High Volume, Velocity and Variety to require specific Technology and Analytical Methods for its transformation into Value [sic]" (S. 131).</p>
        <p>rung und konfirmatorischer Faktorenanalyserung und konfirmatorischer Faktorenanalyse</p>
        <p>(Kline, 2011;Weiber &amp; Mühlhaus, 2014)(Kline, 2011;Weiber &amp; Mühlhaus, 2014)</p>
        <p>. Anhand eines Beispiels mit Bezug auf das BDGS verdeutlicht: Je ausgeprägter also die Glaubensüberzeugung bei einer Person, dass die digitalen Daten einen Nutzen für die Gesellschaft haben, desto eher stimmt diese Person auch in der Befragungssituation einer Aussage zu, die diesen Nutzen für die Gesellschaft postuliert. Die befragte Person signalisiert die Zustimmung durch ein vorgegebenes Antwortschema, was im vorliegenden Fall digital registriert wird. Der Zustimmung wird ein hoher Zahlenwert zugewiesen. Wird hingegen in der Befragungssituation Nicht-Zustimmung signalisiert und ein Nutzen verneint, wird ein niedrigerer Zahlenwert festgehalten. Die Wirkungsrichtung läuft also vom zu messenden, nicht unmittelbar zu beobachtenden Konstrukt hin zur tatsächlich geäußerten Zustimmung, die im Rahmen des standardisierten Instruments registriert wird.. Anhand eines Beispiels mit Bezug auf das BDGS verdeutlicht: Je ausgeprägter also die Glaubensüberzeugung bei einer Person, dass die digitalen Daten einen Nutzen für die Gesellschaft haben, desto eher stimmt diese Person auch in der Befragungssituation einer Aussage zu, die diesen Nutzen für die Gesellschaft postuliert. Die befragte Person signalisiert die Zustimmung durch ein vorgegebenes Antwortschema, was im vorliegenden Fall digital registriert wird. Der Zustimmung wird ein hoher Zahlenwert zugewiesen. Wird hingegen in der Befragungssituation Nicht-Zustimmung signalisiert und ein Nutzen verneint, wird ein niedrigerer Zahlenwert festgehalten. Die Wirkungsrichtung läuft also vom zu messenden, nicht unmittelbar zu beobachtenden Konstrukt hin zur tatsächlich geäußerten Zustimmung, die im Rahmen des standardisierten Instruments registriert wird.</p>
        <p>Nachdem nun das Ziel und die Logik der Konstruktmessung erörtert und die Art der geeigneten Indikatoren festgelegt wurden, folgen nun allgemeine Überlegungen zur Ausgestaltung der Indikatoren in der Befragung. Bei der Formulierung der Indikatoren muss zunächst bedacht werden, welche Zielgruppe später einmal mit dem Befragungs-Instrument konfrontiert wird, um mögliche problematische Einflüsse auf die Messung durch bestimmte Eigenheiten der Befragten (bspw. Einflüsse der Soziodemografie, des Sprachverständnisses sowie des Erlebens-und Verhaltensspektrums) zu vermeidenNachdem nun das Ziel und die Logik der Konstruktmessung erörtert und die Art der geeigneten Indikatoren festgelegt wurden, folgen nun allgemeine Überlegungen zur Ausgestaltung der Indikatoren in der Befragung. Bei der Formulierung der Indikatoren muss zunächst bedacht werden, welche Zielgruppe später einmal mit dem Befragungs-Instrument konfrontiert wird, um mögliche problematische Einflüsse auf die Messung durch bestimmte Eigenheiten der Befragten (bspw. Einflüsse der Soziodemografie, des Sprachverständnisses sowie des Erlebens-und Verhaltensspektrums) zu vermeiden</p>
        <p>5.1 getroffenen Unterteilung der Richtigkeit der digitalen Daten in die zugehörigen Dimensionen Genauigkeit, Wahrhaftigkeit und Objektivität sowie den5.1 getroffenen Unterteilung der Richtigkeit der digitalen Daten in die zugehörigen Dimensionen Genauigkeit, Wahrhaftigkeit und Objektivität sowie den</p>
        <p>Die in den vorherigen Abschnitten angesprochene aus der ersten Erhebung gewonnene Erkenntnis ist, dass es nicht ganz unerheblich ist, eine "weiß nicht"-Option bei der Beantwortung der BDGS-Skala anzubieten -da ihre Frageitems zumindest in Teilen das Wissen und den Erkenntnisgewinn selbst betreffen. So wurde auch in Reviewerkommentaren zur Skala aus den nachfolgenden Erhebungen 2.1 und 2.2 der Wunsch geäußert, befragten Personen die Möglichkeit zu geben, Unsicherheit und Nicht-Wissen bezüglich des Erkenntnisgewinns gezielt anzugeben.Die in den vorherigen Abschnitten angesprochene aus der ersten Erhebung gewonnene Erkenntnis ist, dass es nicht ganz unerheblich ist, eine "weiß nicht"-Option bei der Beantwortung der BDGS-Skala anzubieten -da ihre Frageitems zumindest in Teilen das Wissen und den Erkenntnisgewinn selbst betreffen. So wurde auch in Reviewerkommentaren zur Skala aus den nachfolgenden Erhebungen 2.1 und 2.2 der Wunsch geäußert, befragten Personen die Möglichkeit zu geben, Unsicherheit und Nicht-Wissen bezüglich des Erkenntnisgewinns gezielt anzugeben.</p>
        <p>Das Anbieten einer solchen "weiß nicht"-Option könnte nachDas Anbieten einer solchen "weiß nicht"-Option könnte nach</p>
        <p>Krosnick et al. (Krosnick et al. (</p>
        <p>aa</p>
        <p>(van de Schoot et al., 2012;Weiber &amp; Mühlhaus, 2014)(van de Schoot et al., 2012;Weiber &amp; Mühlhaus, 2014)</p>
        <p>. Nur bei Messäquivalenz kann davon ausgegangen werden, dass die latenten Faktoren das gleiche. Nur bei Messäquivalenz kann davon ausgegangen werden, dass die latenten Faktoren das gleiche</p>
        <p>" Für die vorliegende Auswertung in Abschnitt 10.7 werden jedoch die Mittelwerte der einzelnen Dimensionen auf null restringiert, so dass die geschätzten Regressionskonstanten (Intercepts) zur Prüfung der Hypothese herangezogen werden." Für die vorliegende Auswertung in Abschnitt 10.7 werden jedoch die Mittelwerte der einzelnen Dimensionen auf null restringiert, so dass die geschätzten Regressionskonstanten (Intercepts) zur Prüfung der Hypothese herangezogen werden.</p>
        <p>H2: Je ausgeprägter das BDGS, desto positiver die kognitiven, affektiven und konativen Komponenten der Einstellung gegenüber datenbasierten KI-Anwendungen.H2: Je ausgeprägter das BDGS, desto positiver die kognitiven, affektiven und konativen Komponenten der Einstellung gegenüber datenbasierten KI-Anwendungen.</p>
        <p>aa</p>
        <p>22</p>
        <p>-Werte in einem von ihm analysierten Modell von 0,19 als ‚schwach', von 0,33 als ‚moderat" und von 0,66 als ‚substantiell'"-Werte in einem von ihm analysierten Modell von 0,19 als ‚schwach', von 0,33 als ‚moderat" und von 0,66 als ‚substantiell'"</p>
        <p>(Weiber &amp; Mühlhaus, 2014, S. 230)(Weiber &amp; Mühlhaus, 2014, S. 230)</p>
        <p>. Studie 2 -Die Auswirkungen der …. Studie 2 -Die Auswirkungen der …</p>
        <p>10.10.</p>
        <p>Es sei an dieser Stelle darauf verwiesen, dass der Begriff Digitalisierung im Deutschen umfassender gebraucht wird als im Englischen. Wenn dort vom technischen oder sozialen Phänomen Digitalisierung die Rede ist, wird meist entsprechend genauer differenziert: So meint Digitization meist nur die Abbildung von Informationen in einem digitalen Format(Storsul &amp; Fagerjord,Es sei an dieser Stelle darauf verwiesen, dass der Begriff Digitalisierung im Deutschen umfassender gebraucht wird als im Englischen. Wenn dort vom technischen oder sozialen Phänomen Digitalisierung die Rede ist, wird meist entsprechend genauer differenziert: So meint Digitization meist nur die Abbildung von Informationen in einem digitalen Format(Storsul &amp; Fagerjord,</p>
        <p>2008), wenn es um soziale Konsequenzen geht, wird häufig von Computerization, ‚digital Revolution' etc. gesprochen(Kling &amp; Iacono, 1988). Zwar definieren auchBrennen und Kreiss (2016): "digitalization as the way many domains of social life are restructured around digital communication and media infrastructures" (S. 1). Eine einfache Übersetzung in Digitalization ist jedoch weithin weniger gebräuchlich und auch nicht zielführend, genauso wie die undifferenzierte Verwendung des Digitalisierungslabels zugunsten einer konkreten Benennung dessen, worüber man gerade spricht, vermieden werden sollte(Mahn, 2019). In loser Assoziation subsumieren sich in der deutschsprachigen Verwendung unter diesem Oberbegriff die materiellen Dinge der Digitalisierung, also die technischen Artefakte wie bspw. Computer oder Smartphone sowie auch die Infrastruktur des Internets mit ihren Rechenzentren, Glasfaserkabeln und Satelliten. Über diese greifbaren Objekte betrifft der Begriff Digitalisierung darüber hinaus jedoch auch weitreichendere Konzepte wie die sogenannten Sozialen Medien, vage Konzepte wie Industrie 4.0, das Internet of Things (IOT) usw. In diesen Konzepten kommt der Digitalisierung dann noch konkreter eine sozio-technologische Bedeutung zu, nämlich beim Einsatz von Computertechnologie als ‚Werkzeug' durch den Menschen. Der Mensch prägt ihre Verwendung und ihre Verwendung prägt den Menschen, ohne hier einen Technikdeterminismus zu unterstellen(Smith &amp; Marx, 1994;Wyatt, 2008).2008), wenn es um soziale Konsequenzen geht, wird häufig von Computerization, ‚digital Revolution' etc. gesprochen(Kling &amp; Iacono, 1988). Zwar definieren auchBrennen und Kreiss (2016): "digitalization as the way many domains of social life are restructured around digital communication and media infrastructures" (S. 1). Eine einfache Übersetzung in Digitalization ist jedoch weithin weniger gebräuchlich und auch nicht zielführend, genauso wie die undifferenzierte Verwendung des Digitalisierungslabels zugunsten einer konkreten Benennung dessen, worüber man gerade spricht, vermieden werden sollte(Mahn, 2019). In loser Assoziation subsumieren sich in der deutschsprachigen Verwendung unter diesem Oberbegriff die materiellen Dinge der Digitalisierung, also die technischen Artefakte wie bspw. Computer oder Smartphone sowie auch die Infrastruktur des Internets mit ihren Rechenzentren, Glasfaserkabeln und Satelliten. Über diese greifbaren Objekte betrifft der Begriff Digitalisierung darüber hinaus jedoch auch weitreichendere Konzepte wie die sogenannten Sozialen Medien, vage Konzepte wie Industrie 4.0, das Internet of Things (IOT) usw. In diesen Konzepten kommt der Digitalisierung dann noch konkreter eine sozio-technologische Bedeutung zu, nämlich beim Einsatz von Computertechnologie als ‚Werkzeug' durch den Menschen. Der Mensch prägt ihre Verwendung und ihre Verwendung prägt den Menschen, ohne hier einen Technikdeterminismus zu unterstellen(Smith &amp; Marx, 1994;Wyatt, 2008).</p>
        <p>Schon an diesem Beispiel wird deutlich, dass nicht automatisch von Daten auf Information und Wissen geschlossen werden kann. Daten, in ihrem Wesen bis hier nun lediglich verstanden als Symbole, können Informationen für Mensch und/oder Maschine sein, müssen dies jedoch selbstredend nicht zwingend für jeden Menschen und jede Maschine sein und sie führen somit nicht auch automatisch zu Wissen.Schon an diesem Beispiel wird deutlich, dass nicht automatisch von Daten auf Information und Wissen geschlossen werden kann. Daten, in ihrem Wesen bis hier nun lediglich verstanden als Symbole, können Informationen für Mensch und/oder Maschine sein, müssen dies jedoch selbstredend nicht zwingend für jeden Menschen und jede Maschine sein und sie führen somit nicht auch automatisch zu Wissen.</p>
        <p>So finden sich in über 95 % der Definitionen von Big Data eben jene Bezüge auf das quantitative Ausmaß der Daten(Ylijoki &amp; Porras, 2016).So finden sich in über 95 % der Definitionen von Big Data eben jene Bezüge auf das quantitative Ausmaß der Daten(Ylijoki &amp; Porras, 2016).</p>
        <p>http://www.internetlivestats.com/one-second/http://www.internetlivestats.com/one-second/</p>
        <p>Siehe hierzu bspw. die Diskussion um Datenlöschung im Rahmen des Rechts auf Vergessenwerden(Jandt et al., 2013;Koops, 2011;Rosen, 2012;Roßnagel, 2016).Siehe hierzu bspw. die Diskussion um Datenlöschung im Rahmen des Rechts auf Vergessenwerden(Jandt et al., 2013;Koops, 2011;Rosen, 2012;Roßnagel, 2016).</p>
        <p>Value meint hier nicht Wert im Sinne eines Nutzens, der in Zusammenhang mit digitalen Daten nachfolgend besprochen wird, sondern stellt auf subjektive Sichtweisen und Präferenzen sozialer Werte und Normen ab.Value meint hier nicht Wert im Sinne eines Nutzens, der in Zusammenhang mit digitalen Daten nachfolgend besprochen wird, sondern stellt auf subjektive Sichtweisen und Präferenzen sozialer Werte und Normen ab.</p>
        <p>So fragt auch die EuropäischeKommission (2017b) bei ihren Bürger*innen explizit nach den wahrgenommenen Auswirkungen der Digitalisierung auf das Selbst, die Gesellschaft sowie die Wirtschaft.So fragt auch die EuropäischeKommission (2017b) bei ihren Bürger*innen explizit nach den wahrgenommenen Auswirkungen der Digitalisierung auf das Selbst, die Gesellschaft sowie die Wirtschaft.</p>
        <p>Auch sei hier analog zu den Fallstricken mit Blick auf die Richtigkeitsdimension der Big Data auf die Fehleranfälligkeit dieser vermeintlich intelligenten Systeme verwiesen. So kam es am 6. Mai 2010 zu einem sogenannten Flash Crash, bei denen Aufträge der Programme kurzzeitige Börsenturbulenzen ausgelöst haben(Kirilenko et al., 2017).Auch sei hier analog zu den Fallstricken mit Blick auf die Richtigkeitsdimension der Big Data auf die Fehleranfälligkeit dieser vermeintlich intelligenten Systeme verwiesen. So kam es am 6. Mai 2010 zu einem sogenannten Flash Crash, bei denen Aufträge der Programme kurzzeitige Börsenturbulenzen ausgelöst haben(Kirilenko et al., 2017).</p>
        <p>Zum Begriff der post-industriellen Gesellschaft siehe D.Bell (1973) undDrucker (1993).© Der/die Autor(en)Zum Begriff der post-industriellen Gesellschaft siehe D.Bell (1973) undDrucker (1993).© Der/die Autor(en)</p>
        <p>M. Lünich, Der Glaube an Big Data, https://doi.org/10.1007/978-3-658-36368-0_4M. Lünich, Der Glaube an Big Data, https://doi.org/10.1007/978-3-658-36368-0_4</p>
        <p>Darüber hinaus interessierten Leser*innen seien hier die Einführungen zur Erkenntnistheorie vonBaumann (2015) und die Einführung in die Wissenssoziologie vonKnoblauch (2014) empfohlen.Darüber hinaus interessierten Leser*innen seien hier die Einführungen zur Erkenntnistheorie vonBaumann (2015) und die Einführung in die Wissenssoziologie vonKnoblauch (2014) empfohlen.</p>
        <p>Laut Kiefer (1988) ist "der Inhalt des Wissens (…) Information über irgendetwas, (…) wobei der Begriff des ontologischen Bereichs am allgemeinsten ist, er kann für alles mögliche [sic] stehen, für Entitäten wie Zahlen, Atome, Götter, Schmetterlinge und Gedanken, um einige Beispiele zu nennen" (S. 70).Laut Kiefer (1988) ist "der Inhalt des Wissens (…) Information über irgendetwas, (…) wobei der Begriff des ontologischen Bereichs am allgemeinsten ist, er kann für alles mögliche [sic] stehen, für Entitäten wie Zahlen, Atome, Götter, Schmetterlinge und Gedanken, um einige Beispiele zu nennen" (S. 70).</p>
        <p>Andere Definitionen folgen einem umgekehrten Verständnis von Information und Daten. So definiert bspw.Porat (1977): "Information is data that have been organized and communicated" (S. 2).Andere Definitionen folgen einem umgekehrten Verständnis von Information und Daten. So definiert bspw.Porat (1977): "Information is data that have been organized and communicated" (S. 2).</p>
        <p>Hier ist anzumerken, dass der Begriff der Wissenssysteme an dieser Stelle zunächst allgemein als eine Ordnung von Wissen verstanden wird. In der Informatik werden unter diesem Label jedoch bereits wissensverarbeitende Computersysteme verstanden: "Computer systems that use knowledge are called knowledge-based systems, or simply knowledge systems"(Stefik, 1995, S. XV). Sofern nicht anders vermerkt ist nachfolgend die allgemeinere Bedeutung gemeint.Hier ist anzumerken, dass der Begriff der Wissenssysteme an dieser Stelle zunächst allgemein als eine Ordnung von Wissen verstanden wird. In der Informatik werden unter diesem Label jedoch bereits wissensverarbeitende Computersysteme verstanden: "Computer systems that use knowledge are called knowledge-based systems, or simply knowledge systems"(Stefik, 1995, S. XV). Sofern nicht anders vermerkt ist nachfolgend die allgemeinere Bedeutung gemeint.</p>
        <p>Ein überzeugender Hinweis darauf, wie es insbesondere um das prozedurale Wissen über datenverarbeitende IuK-Anwendungen einem Hochtechnologieland wie Deutschland bestellt ist und der das hier vorliegende Argument stützt, dass die menschliche Komponente im Zusammenhang der Wissenserzeugung und -verarbeitung bezüglich digitaler Daten auf absehbare Zeit nicht unterschätzt werden sollte.Ein überzeugender Hinweis darauf, wie es insbesondere um das prozedurale Wissen über datenverarbeitende IuK-Anwendungen einem Hochtechnologieland wie Deutschland bestellt ist und der das hier vorliegende Argument stützt, dass die menschliche Komponente im Zusammenhang der Wissenserzeugung und -verarbeitung bezüglich digitaler Daten auf absehbare Zeit nicht unterschätzt werden sollte.</p>
        <p>Diese werden je nach analytischer Schwerpunktsetzung mal in Abgrenzung und mal in Überschneidung mit anderweitigen Paradigmen gesellschaftlichen Wandels diskutiert wieDiese werden je nach analytischer Schwerpunktsetzung mal in Abgrenzung und mal in Überschneidung mit anderweitigen Paradigmen gesellschaftlichen Wandels diskutiert wie</p>
        <p>In der vorliegenden Arbeit wird dem Begriff der Quantifizierung (des Sozialen) Vorzug gegeben, da unter Metrifizierung auch die Einführung metrischer Einheitssysteme verstanden © Der/die Autor(en)In der vorliegenden Arbeit wird dem Begriff der Quantifizierung (des Sozialen) Vorzug gegeben, da unter Metrifizierung auch die Einführung metrischer Einheitssysteme verstanden © Der/die Autor(en)</p>
        <p>M. Lünich, Der Glaube an Big Data, https://doi.org/10.1007/978-3-658-36368-0_5M. Lünich, Der Glaube an Big Data, https://doi.org/10.1007/978-3-658-36368-0_5</p>
        <p>In der Konsequenz auf diese Beobachtungen formuliertCampbell (1979) folgendes Gesetz: "The more any quantitative social indicator is used for social decision-making, the more subject it will be to corruption pressures and the more apt it will be to distort and corrupt the social processes it is intended to monitor" (S. 85).In der Konsequenz auf diese Beobachtungen formuliertCampbell (1979) folgendes Gesetz: "The more any quantitative social indicator is used for social decision-making, the more subject it will be to corruption pressures and the more apt it will be to distort and corrupt the social processes it is intended to monitor" (S. 85).</p>
        <p>Das Big-Data-Glaubenssystem (BDGS)Das Big-Data-Glaubenssystem (BDGS)</p>
        <p>Dabei geht es beiAbelson (1979) nicht um einen Glauben an die KI selbst, sondern um die Möglichkeit der Repräsentation und Verarbeitung von Glaubenssystemen durch KI. Vor diesem Hintergrund skizziert er die Merkmale und Eigenschaften von Glaubens-im Unterschied zu Wissenssystemen, ohne die KI zum Gegenstand selbiger zu machen.Dabei geht es beiAbelson (1979) nicht um einen Glauben an die KI selbst, sondern um die Möglichkeit der Repräsentation und Verarbeitung von Glaubenssystemen durch KI. Vor diesem Hintergrund skizziert er die Merkmale und Eigenschaften von Glaubens-im Unterschied zu Wissenssystemen, ohne die KI zum Gegenstand selbiger zu machen.</p>
        <p>Es wird an der jeweiligen Stelle im Text deutlich gemacht, ob von der Gesamt-oder Sub-Skala, also der gesamten Itembatterie, oder einem Teilausschnitt dieser Batterie gesprochen wird. Ein Teilausschnitt umfasst dabei meist immer eine konkrete Dimension des BDGS. Skala kann sich jedoch auch auf das Messniveau und die den Befragten vorgegebenen standardisierten Antwortoptionen der Fragen einer Itembatterie beziehen (siehe Abschnitt 8.4.6).Es wird an der jeweiligen Stelle im Text deutlich gemacht, ob von der Gesamt-oder Sub-Skala, also der gesamten Itembatterie, oder einem Teilausschnitt dieser Batterie gesprochen wird. Ein Teilausschnitt umfasst dabei meist immer eine konkrete Dimension des BDGS. Skala kann sich jedoch auch auf das Messniveau und die den Befragten vorgegebenen standardisierten Antwortoptionen der Fragen einer Itembatterie beziehen (siehe Abschnitt 8.4.6).</p>
        <p>Vermeintliche Fehler sind dem Verfasser anzulasten, wobei die Dokumentation der empirischen Datenerhebung und der spezifizierten Modelle es Dritten mit Hilfe der Daten im Anhang im elektronischen Zusatzmaterial erlauben, das empirische Vorgehen bei Datenerhebung und -auswertung zu prüfen.Vermeintliche Fehler sind dem Verfasser anzulasten, wobei die Dokumentation der empirischen Datenerhebung und der spezifizierten Modelle es Dritten mit Hilfe der Daten im Anhang im elektronischen Zusatzmaterial erlauben, das empirische Vorgehen bei Datenerhebung und -auswertung zu prüfen.</p>
        <p>In den nachfolgenden Abschnitten wird an den entsprechenden Stellen eine Prüfung auf Messinvarianz durchgeführt, die prüft, ob die Messung von unterschiedlichen Gruppen gleich verstanden und somit mess-äquivalent ist(Weiber &amp; Mühlhaus, 2014).In den nachfolgenden Abschnitten wird an den entsprechenden Stellen eine Prüfung auf Messinvarianz durchgeführt, die prüft, ob die Messung von unterschiedlichen Gruppen gleich verstanden und somit mess-äquivalent ist(Weiber &amp; Mühlhaus, 2014).</p>
        <p>Die browserbasierte Befragungssoftware steht für nicht-kommerzielle Studien im wissenschaftlichen Kontext kostenlos zur Verfügung (D. J.Leiner, 2019a).Die browserbasierte Befragungssoftware steht für nicht-kommerzielle Studien im wissenschaftlichen Kontext kostenlos zur Verfügung (D. J.Leiner, 2019a).</p>
        <p>An dieser Stelle möchte ich Herrn Christopher Starke und Pero Došenović für ihre hilfreichen Anmerkungen danken.An dieser Stelle möchte ich Herrn Christopher Starke und Pero Došenović für ihre hilfreichen Anmerkungen danken.</p>
        <p>Aufgrund direkter Überarbeitung von missverständlichen und fehlerhaften Items, die im Anschluss an jedes Interview stattfanden, wichen auch die jeweils gleichen vorgestellten Itemlisten in Teilen voneinander ab.Aufgrund direkter Überarbeitung von missverständlichen und fehlerhaften Items, die im Anschluss an jedes Interview stattfanden, wichen auch die jeweils gleichen vorgestellten Itemlisten in Teilen voneinander ab.</p>
        <p>Alle Fragebögen der berichteten Studien im Rahmen dieser Arbeit wurden mit der Befragungssoftware des Anbieters SoSci Survey GmbH programmiert (D. J.Leiner,Alle Fragebögen der berichteten Studien im Rahmen dieser Arbeit wurden mit der Befragungssoftware des Anbieters SoSci Survey GmbH programmiert (D. J.Leiner,</p>
        <p>2019a). Weitere Informationen unter und https://www.soscisurvey.de/ [zuletzt zugegriffen am 25.04.2020].2019a). Weitere Informationen unter und https://www.soscisurvey.de/ [zuletzt zugegriffen am 25.04.2020].</p>
        <p>Studie 1 -Durchführung der SkalenkonstruktionStudie 1 -Durchführung der Skalenkonstruktion</p>
        <p>Weitere Informationen finden sich unter https://www.respondi.com/access-panel [zuletzt zugegriffen am 31. Mai 2019].Weitere Informationen finden sich unter https://www.respondi.com/access-panel [zuletzt zugegriffen am 31. Mai 2019].</p>
        <p>Potentiell mögliche Pfade oder Kovarianzen zwischen Variablen im Modell, die jedoch nicht freigegeben oder mit einer Identitätsrestriktion belegt sind, werden bei der Modellschätzung als nicht vorhanden und somit = 0 behandelt.Potentiell mögliche Pfade oder Kovarianzen zwischen Variablen im Modell, die jedoch nicht freigegeben oder mit einer Identitätsrestriktion belegt sind, werden bei der Modellschätzung als nicht vorhanden und somit = 0 behandelt.</p>
        <p>Die Befragten wurden mittels ‚Urnenziehung ohne Zurücklegen' einer der drei Befragungskonditionen zugelost.Die Befragten wurden mittels ‚Urnenziehung ohne Zurücklegen' einer der drei Befragungskonditionen zugelost.</p>
        <p>Die Varianz des latenten Faktors in Kontext 1.2c ist negativ, so dass es aufgrund dieses Heywood Cases (siehe Abschnitt 9.1.3) zu einer unzulässigen Lösung des Schätzalgorithmus im SOFM kommt.Die Varianz des latenten Faktors in Kontext 1.2c ist negativ, so dass es aufgrund dieses Heywood Cases (siehe Abschnitt 9.1.3) zu einer unzulässigen Lösung des Schätzalgorithmus im SOFM kommt.</p>
        <p>In der Präregistrierung fand sich in der Hypothese noch die folgende Ergänzung als Hilfsbeispiel für die Interpretation: "Je höher bspw. die Zustimmung zum beinhalteten Wissen in den Daten, desto positiver der erwartete Nutzen für das Selbst."In der Präregistrierung fand sich in der Hypothese noch die folgende Ergänzung als Hilfsbeispiel für die Interpretation: "Je höher bspw. die Zustimmung zum beinhalteten Wissen in den Daten, desto positiver der erwartete Nutzen für das Selbst."</p>
        <p>Kurz vor Einreichung dieser Arbeit wurde im April 2020 von Y. A. Wang und Rhemtulla (2020) ein neues Tool zur Parameterschätzung im Rahmen der Strukturgleichungsmodellierung vorgestellt.Kurz vor Einreichung dieser Arbeit wurde im April 2020 von Y. A. Wang und Rhemtulla (2020) ein neues Tool zur Parameterschätzung im Rahmen der Strukturgleichungsmodellierung vorgestellt.</p>
        <p>Bauer unterscheidet hier zwischen genereller Technophobie, die sich auch auf Flugzeuge, Eisenbahnen etc. beziehen kann, und Cyberphobie, die sich explizit auf den privaten, schulischen und beruflichen Computergebrauch bezieht. Aufgrund der ungebräuchlichen Verwendung des Cyberbegriffs wird hier daher allgemein von Computerphobie gesprochen.Bauer unterscheidet hier zwischen genereller Technophobie, die sich auch auf Flugzeuge, Eisenbahnen etc. beziehen kann, und Cyberphobie, die sich explizit auf den privaten, schulischen und beruflichen Computergebrauch bezieht. Aufgrund der ungebräuchlichen Verwendung des Cyberbegriffs wird hier daher allgemein von Computerphobie gesprochen.</p>
        <p>"The question asked 'How afraid are you of the following?' and the items included: 'Robots that can make their own decisions and take their own actions,' 'Robots replacing people in the workforce,' 'Artificial intelligence,' and 'People trusting artificial intelligence to do work'."(Liang &amp; Lee, 2017, S. 381)"The question asked 'How afraid are you of the following?' and the items included: 'Robots that can make their own decisions and take their own actions,' 'Robots replacing people in the workforce,' 'Artificial intelligence,' and 'People trusting artificial intelligence to do work'."(Liang &amp; Lee, 2017, S. 381)</p>
        <p>In der Präregistrierung wurden die nachfolgenden Hypothesen H2.4a, H2.4b und H2.4c in einer Hypothese zusammengefasst und hier aus Gründen der übersichtlicheren Darstellung entsprechend aufgeteilt. Dabei wurden Hypothesenformulierungen und Modell angepasst, um den Fokus auf den Einfluss des BDGS zu verdeutlichen. Zudem wurde hier kein gerichteter Zusammenhang der Variablen Reputation der Hochschule und Protestneigung untersucht.In der Präregistrierung wurden die nachfolgenden Hypothesen H2.4a, H2.4b und H2.4c in einer Hypothese zusammengefasst und hier aus Gründen der übersichtlicheren Darstellung entsprechend aufgeteilt. Dabei wurden Hypothesenformulierungen und Modell angepasst, um den Fokus auf den Einfluss des BDGS zu verdeutlichen. Zudem wurde hier kein gerichteter Zusammenhang der Variablen Reputation der Hochschule und Protestneigung untersucht.</p>
        <p>Informationen zur Präregistrierung sind unter folgendem Link zu finden: https://osf.io/ gyn7k/?view_only=c58a5e1b4a804b488aceec24d05dc9a1Informationen zur Präregistrierung sind unter folgendem Link zu finden: https://osf.io/ gyn7k/?view_only=c58a5e1b4a804b488aceec24d05dc9a1</p>
        <p>Informationen zur Präregistrierung sind unter folgendem Link zu finden: https://osf.io/ 83t7s/?view_only=8acca193bba04e169b91534f74ced263Informationen zur Präregistrierung sind unter folgendem Link zu finden: https://osf.io/ 83t7s/?view_only=8acca193bba04e169b91534f74ced263</p>
        <p>Für mehr Informationen zu den Maluspunkten, die mittels der DEG_TIME von SoSci Survey erhoben werden, siehe die SoSci-Dokumentation (D. J.Leiner, 2019b) unter: https:// www.soscisurvey.de/help/doku.php/de:results:variables [zuletzt aufgerufen am 24. Oktober 2019]Für mehr Informationen zu den Maluspunkten, die mittels der DEG_TIME von SoSci Survey erhoben werden, siehe die SoSci-Dokumentation (D. J.Leiner, 2019b) unter: https:// www.soscisurvey.de/help/doku.php/de:results:variables [zuletzt aufgerufen am 24. Oktober 2019]</p>
        <p>Da ein Messmodell mit einem auf die drei Indikatoren ladenden latenten Faktor vollständig identifiziert ist, wird keine Anpassungsgüte berichtet.Da ein Messmodell mit einem auf die drei Indikatoren ladenden latenten Faktor vollständig identifiziert ist, wird keine Anpassungsgüte berichtet.</p>
        <p>Da auch hier ein Messmodell mit einem auf die drei Indikatoren ladenden latenten Faktor vollständig identifiziert ist, wird keine Anpassungsgüte berichtet.Da auch hier ein Messmodell mit einem auf die drei Indikatoren ladenden latenten Faktor vollständig identifiziert ist, wird keine Anpassungsgüte berichtet.</p>
        <p>Alle Items der Manipulationsprüfung wurden auf einer 5-stufigen Likert-Skala erhoben, die wie folgt abgestuft war: 1 "trifft überhaupt nicht zu", 2 "trifft eher nicht zu", 3 "trifft teils zu, teils nicht zu", 4 "trifft eher zu" sowie 5 "trifft voll und ganz zu". Es gab zudem eineAlle Items der Manipulationsprüfung wurden auf einer 5-stufigen Likert-Skala erhoben, die wie folgt abgestuft war: 1 "trifft überhaupt nicht zu", 2 "trifft eher nicht zu", 3 "trifft teils zu, teils nicht zu", 4 "trifft eher zu" sowie 5 "trifft voll und ganz zu". Es gab zudem eine</p>
        <p>Die Fehlerterme der beiden letztgenannten Variablen weisen eine mittlere negative Korrelation auf (r = -.318).Die Fehlerterme der beiden letztgenannten Variablen weisen eine mittlere negative Korrelation auf (r = -.318).</p>
        <p>Maximum Likelihood RMSEA Root Mean Square Error of Approximation SD Standard Deviation (Standardabweichung) SE Standard Error (Standardfehler)Maximum Likelihood RMSEA Root Mean Square Error of Approximation SD Standard Deviation (Standardabweichung) SE Standard Error (Standardfehler)</p>
    </text>
</tei>
