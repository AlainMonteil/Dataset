<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T09:45+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>Artificial Intelligence (AI) implementation in public administration is gaining momentum heralded by the hope of smart public services that are personalised, lean, and efficient. However, the use of AI in public administration is riddled with ethical tensions of fairness, transparency, privacy, and human rights. We call these AI tensions. The current literature lacks a contextual and processual understanding of AI adoption and diffusion in public administration to be able to explore such tensions. Previous studies have outlined risks, benefits, and challenges with the use of AI in public administration. However, a large gap remains in understanding AI tensions as they relate to public value creation. Through a systematic literature review grounded in public value management and the resource-based view of the firms, we identify technology-organisational-environmental (TOE) contextual variables and absorptive capacity as factors influencing AI adoption as discussed in the literature. To our knowledge, this is the first paper that outlines distinct AI tensions from an AI implementation and diffusion perspective within public administration. We develop a future research agenda for the full AI innovation lifecycle of adoption, implementation, and diffusion.</p>
        <p>Technological innovation driven by Artificial Intelligence (AI) is making headways in public administration on the heels of the last decade's e-government innovations focused on the goals of efficiency and cost savings. The smart technology-centric model of public governance engages citizens through digital platforms and advocates for a lean service delivery without compromising quality (Dunleavy, Margetts, Bastow, &amp; Tinkler, 2006;Wirtz &amp; Müller, 2018). AI-driven innovation is expected to have a profound impact on not only public sector employees but also on citizens and society. When AI becomes an agent for making public decisions, a profound transformation of public administration ensues questioning the roles and functions of government in society. The age-old dilemmas of power, trust, and legitimacy become embedded in AI influencing citizens' lives and societies. A comprehensive understanding of contextual variables influencing the adoption and diffusion is essential for determining public value creation from the use of AI in public administration.</p>
        <p>Defining AI presents terminological challenges. Dwivedi et al. (2021, p. 24) suggest an "institutional hybrid" approach to defining AI and its typology as per the context and discipline. Thus, AI is defined as "a cluster of digital technologies that enable machines to learn and solve cognitive problems autonomously without human intervention" (Madan &amp; Ashok, 2022, pg. 188). The context for this paper is public administration which is defined as public organisations that implement government policies and may contribute to its development. Key applications of AI in this context include process automation, virtual agents and speech analytics, predictive analytics for decision-making, sentiment analysis, and document reviews (Ojo, Mellouli, &amp; Zeleti, 2019;Wirtz, Weyerer, &amp; Geyer, 2018). We focus on two specific AI technologies: machine learning (ML) and natural language processing (NLP). These two technologies characterise most public administration AI applications exemplified by Madan and Ashok (2022)'s cross-case analysis and European Commission and Joint Research Center (JRC) (2021) AI case study archive.</p>
        <p>The implementation of AI represents radical innovations involving not only technology but also culture, processes, and workforce (Agarwal, 2018;Ashok, Narula, &amp; Martinez-Noya, 2016). The use of AI in public administration is riddled with ethical tensions such as questions of fairness, transparency, privacy, and human rights (Ashok, Madan, Joha, &amp; Sivarajah, 2022;Helbing et al., 2019;Kuziemski &amp; Misuraca, 2020). Notwithstanding the use of AI provides immense benefits, the risks of harm to society require the assessment of the overall impact of AI from a public values perspective (Medaglia, Gil-Garcia, &amp; Pardo, 2021).</p>
        <p>Several governments and technology companies have published ethical guidelines on the use of AI such as EU's ethical guidelines (European Commission, 2019), Canada's Algorithmic Impact Assessment (Canada, 2020), UK's guidance (Gov.uk, 2019b), etc. In the context of public administration, these ethical principles at the macro level provide overall boundaries for the use of AI. However, at the meso and micro levels of public administration, the resolution of AI tensions resulting from public value conflicts remains elusive. Morley, Floridi, Kinsey, and Elhalal (2020) state that AI scholars need to translate the largely agreed AI principles to the 'what' and 'how' of implementation.</p>
        <p>The majority of AI literature views the government as a regulator. The discussion of the role of public administration from a vantage of a user of AI is scarce even though public administration is increasingly becoming a significant user of AI (Kuziemski &amp; Misuraca, 2020;Medaglia et al., 2021). Wirtz et al. (2018)'s literature review showcases research gaps on public sector challenges related to AI applications. Madan and Ashok (2022)'s cross-case analysis highlights the scarcity of research on the implementation and use of AI within governments. The mechanisms behind public value creation through the use of AI are not well understood (Wang, Teo, &amp; Janssen, 2021). Scholars (Alsheibani, Cheung, &amp; Messom, 2018;Medaglia et al., 2021;Misuraca, van Noordt, &amp; Boukli, 2020;David Valle-Cruz, Alejandro Ruvalcaba-Gomez, Sandoval-Almazan, &amp; Ignacio Criado, 2019;Wang et al., 2021) have called for research to develop a theoretical framework of environmental factors, organisational capabilities, and challenges with AI adoption and diffusion in public administration.</p>
        <p>In light of these literature gaps, this review intends to answer two research questions:</p>
        <p>RQ1. : What are the key factors discussed in the literature that influence AI adoption in public administration? RQ2. : What are the key tensions discussed in the literature that might be associated with AI implementation and diffusion in public administration? AI adoption is the process of "integration of new and diverse knowledge through the creation…of new capabilities, technologies and training programmes" (Ashok et al., 2016(Ashok et al., , p. 1008)). AI implementation and diffusion refers to "events and actions that pertain to … preparing the organization for its use, trial use, acceptance of the innovation by the users [and finally] use of the innovation until it becomes a routine feature of the organization" (Damanpour &amp; Schneider, 2006, p. 217).</p>
        <p>The review adopts a multi-disciplinary approach using theories from technology adoption, strategic management, and public administration literature. In the next section, public value theory, the resource-based view (RBV), and the technology-organisation-environment (TOE) framework are introduced as key theoretical underpinnings for this review. The following section details the systematic literature review methodology followed by a summary of key themes and results. In the corresponding discussion section, the resulting themes are synthesised to develop a future research agenda.</p>
        <p>Public values management (PVM) argues public managers' key role is determination and pursuit of public values through engagement and deliberation with elected politicians, stakeholders, and citizens (Moore, 1995;Stoker, 2006). Stoker (2006) contends public values debate grew as a response to the narrow economic focus of New Public Management (NPM) reforms. NPM tried to limit the role of politics in determining public goals and reducing them to efficiency and performance-based measures (Ibid.). Technology not only serves as a catalyst for value creation as enabled by digitalisation but also as a platform for higher engagement with citizens (Ashok, 2018;Ranerup &amp; Henriksen, 2019). Thus, PVM's focus on citizen and political engagement provides an appropriate democratic means for the resolution of tensions emerging from the implementation of AI in public administration (Andrews, 2018;Panagiotopoulos, Klievink, &amp; Cordella, 2019).</p>
        <p>The generative perspective of PVM suggests public value is contextdriven and part of the deliberations themselves (Davis &amp; West, 2008). The institutional perspective focuses on developing a typology of public values such as Hood (1991) and Bannister and Connolly (2014). This research adopts an integrated framework adapted from Davis and West (2008) consolidating generative and institutional perspectives. We build on the already established typology of public values developed by Bannister and Connolly (2014) in the context of technology. We argue dominant public value orientations are embedded in the fabric of organisational routines as cultural values and beliefs. Stakeholder engagement might challenge existing values and give rise to new public values in specific contexts, especially in terms of tensions put forth by AI implementation. Drawing on Moore (1995)'s strategic triangle, we further contend a key role of a public manager is to build capabilities in pursuit of these public values, existing or emergent. Hence, as opposed to external strategy-based planning, public managers need to focus on internal capabilities building. In this respect, a resource-based view of the firm is suitable for exploring the implementation of AI and the corresponding transformation it entails. The resource-based view (RBV) is discussed in the next section as a key theoretical underpinning for this paper.</p>
        <p>The resource-based view (RBV) has been extensively used in literature to explain organisational performance in terms of heterogeneity of internal resources (Barney, 1991). Public organisations generally control large societal resources both in terms of workforce and tangible assets such as land, buildings, infrastructure, etc. (Clausen, Demircioglu, &amp; Alsos, 2020;Harvey, Skelcher, Spencer, Jas, &amp; Walshe, 2010). Organisational capabilities, distinct from resources, refer to business capabilities, enterprise systems and processes, and culture. Organisations function as a collection of resources and capabilities that are aimed at value creation by putting resources to their best use (Piening, 2013). The flip side of organisational capabilities is incumbent inertia in the form of routine rigidity inhibiting change and the development of new capabilities (Ashok, Narula, &amp; Martinez-Noya, 2014;Leonard-Barton, 1992).</p>
        <p>Public administration faces a constantly changing external environment characterised by ongoing policy changes and election cycles. The external environment turbulence and a need for public value deliberations require public managers to develop internal knowledge processes to navigate opposing demands and counter inertia to change (Ashok, Al Dhaheri, Madan, &amp; Dzandu, 2021). Thus, public managers need to build dynamic capabilities defined as "a firm's ability to integrate, build and reconfigure internal and external competencies to address rapidly changing environments" (Teece, Pisano, &amp; Shuen, 1997, p. 516). Derived from the RBV, dynamic capabilities are essential for public administration, just as the private sector, to successfully renew core capabilities and overcome routine rigidity; this is because, dynamic capabilities enable public sector organisations to fulfil policies and provide services (Piening, 2013). Moore (1995)'s strategic triangle consists of public values, legitimacy and support, and internal capabilities. In the context of AI implementation, internal capabilities can be viewed as dynamic capabilities and internal knowledge processes needed to implement such radical innovations with a multitude of public value configurations. Legitimacy and support for AI come from the political leadership and central governments pursuing digital transformation agendas. Citizens' co-creation and adoption of AI-driven services act as another aspect of legitimacy and support. And the specific AI characteristics and design determines public value creation. Thus, three key contexts emerge influencing AI innovations: technology, organisation, and environment.</p>
        <p>In the next section, we detail the use of the technology-organisation environment (TOE) framework for exploring our research questions.</p>
        <p>The Technology-Organisation-Environment (TOE) framework (Tornatzky &amp; Fleischer, 1990) has been extensively used in literature to explore technology adoption in different settings. The key premise of the TOE framework is that organisational and environmental contexts are equally important as technological contexts when studying technology adoption and diffusion at the organisational level.</p>
        <p>AI introduces a higher level of complexity to change associated with its implementation. AI-driven public administration builds on e-government initiatives introducing AI as an agent of the government and governance shifts to citizen-AI-government interactions (Williamson, 2014). This resulting "institutional matrix" consists of human contextual knowledge, AI technologies, and data (Chris &amp; Susan, 2018, p. 207;Gao &amp; Janssen, 2020). Crawford (2021, p. 8) argues AI in the current version is far from being artificial or intelligent but depends on a "set of political and social structures … designed to serve … dominant interests [and] in this sense a registry of power". Similarly, Coombs et al. (2021, p. 5) ask the pertinent question as to "whose interests do AI serve [and] who owns the machines". The political and democratic institutions influenced by technology companies driving the AI agenda in public administration will determine if AI can reduce or enhance the problems of inequality and power.</p>
        <p>Thus, the adoption and diffusion of AI within public administration are not only driven by the purported benefits of the technology but also by citizens, organisational culture, and institutional arrangements. The TOE framework provides a theoretical lens to explore these variables.</p>
        <p>The 'Preferred Reporting Items for Systematic Reviews and Meta-Analyses' (PRISMA) methodology was used to conduct a systematic literature review and qualitative synthesis (Moher et al., 2009). The objective of this review was "theory landscaping" (Okoli, 2015a, p. 888) to synthesise key constructs and relationships discussed in the literature related to the phenomenon of AI adoption in public administration and the key tensions that are likely to be associated with AI implementation and diffusion. A critical realist approach was adopted towards theory landscaping goals and both empirical and conceptual studies were included in the review (Okoli, 2015b). The empirical studies, quantitative or qualitative, help identify what concepts and relationships have been tested and explanations provided for the underlying mechanisms. The conceptual studies propose constructs and relationships that may produce the phenomena based on existing theory, discursive analysis, philosophical deduction, or legal argumentation. The qualitative synthesis of empirical and conceptual studies thus provides a rich snapshot of the current thought in the multi-disciplinary disciplines and the empirical evidence related to the phenomenon for future theory development and testing.</p>
        <p>The review was conducted in three phases as shown in the PRISMA flow in Fig. 1.</p>
        <p>The goal during the identification stage was literature sensitisation and identification of a range of keywords. A combination of seven keyword strings (as shown in Table 1) was used to conduct a literature search 1 in three databases: EBSCO Host, SCOPUS and Web of Science. The search strings include the terms AI, machine learning, algorithms, and natural language processing denoting AI technologies within the scope of this review; and big data and blockchains as technologies supporting these applications. This string was combined with a range of public administration terms and paradigms. The search criteria were limited to English language publications or conference proceedings published after 2010. The research protocol was developed outlining the inclusion and exclusion criteria. The inclusion criterion was quantitative, qualitative, mixed-method, literature reviews or conceptual papers on AI in public administration settings, papers related to big data in the context of AI, and technical papers that at a minimum discuss AI development or implementation. The exclusion criteria included: eGovernment papers that do not discuss AI or big data; AI technologies other than ML or NLP; studies not focusing on public administration applications such as smart city, medicine, universities, policing, healthcare; open data, data governance, cyber security that do not discuss AI applications; use of AI in the public sector for promoting private sector innovation; macro-level studies on AI policies and guidelines developed by national and supranational bodies; and big data and blockchain studies that do not discuss these technologies in the context of AI.</p>
        <p>In the screening stage, a total of 221 records were identified following the above search protocol. Furthermore, through citation review, recommendations from other scholars and reviewers, and a 
            <rs type="software">Google Scholar</rs> search (first five result pages) we identified 27 additional records. After removing duplicates, 166 total publications were identified for the title and abstract review. This screening of the records resulted in 117 papers for the full-text article review. Following the full article review, 73 papers (shown in supplementary materials in Appendix A) were finally included in the qualitative synthesis.
        </p>
        <p>During the qualitative synthesis stage, template analysis was conducted using a three-step analysis (King, 2004). In step one, an a priori template (as shown in Table 2) was developed using the theoretical frameworks discussed above. In step two, each publication was coded to explore the phenomenon of AI adoption and diffusion in public administration identifying factors influencing adoption, outcomes, and AI tensions as discussed in the literature. The data extraction included the type of study (quantitative, qualitative, mixed-method, conceptual); AI technology or application; public administration paradigms; key constructs, measures, and relationships; benefits and outcomes; risks and challenges; and tensions. After coding a set of five papers, organising and conceptual themes were identified (Attride-Stirling, 2001). This was repeated as a new set of papers were coded and reflectivity checks conducted. After a further reorganisation of themes and discussions between the authors, the final template was developed. In step three, the results of the analysis were synthesised.</p>
        <p>This section discusses the results of the analysis. The first part provides a descriptive analysis of the publications included in the review followed by content analysis which discusses the findings of qualitative synthesis.</p>
        <p>The review included 73 publications of which 66% were journal articles and 34% were conference proceedings as shown in Table 3. The highest number of articles (ten) were published in Government Information Quarterly and the highest number of conference proceedings (eight) were from the Annual International Conference on Digital Government Research. Fig. 2 shows the distribution of the journals by year; 85% of the publications are since 2019 showing the recency of the discussions on AI in public administration.</p>
        <p>As shown in Fig. 3, there is a lack of quantitative research and testing of conceptual models with only 7 publications (10%) in this category. 58% of publications are either conceptual or literature reviews. 29% are qualitative studies and represent the second-highest type of publications; 4% are mixed-method studies.</p>
        <p>As shown in Fig. 4, in terms of technology discussed in the papers, 1 The search was conducted in March-April 2021 and an update using the same keywords was undertaken in August 2021. Additional papers suggested by reviewers were added through the peer-review process when relevant.</p>
        <p>37% of the publications mention AI broadly and focus on the application outcomes such as crowdsourcing, delivery of e-services, citizen engagement, achieving efficiency, process automation, etc. Another 12% of the studies refer to several related technologies and applications that can be categorised as cognitive computing including ML, big data analytics, image processing, machine vision, NLP, etc. 45% of the studies discuss AI in terms of machine learning, big data analytics, algorithmic decision making, automated decision making. And 5% of the studies refer specifically to natural language processing in terms of implementation of text or voice chatbots or processing of large documents and texts as a percussor to machine learning and automation.</p>
        <p>This sub-section discusses the findings of the qualitative synthesis. The factors influencing AI adoption, implementation strategies related to AI implementation, and outcomes related to AI diffusion, as discussed in the literature, are outlined. Finally, the themes of AI tensions and data governance embedded in both the implementation and diffusion stages are discussed. The final template developed from template analysis is attached in the supplementary materials as Appendix B.</p>
        <p>Keyword strings used for systematic literature review.</p>
        <p>Search 1</p>
        <p>(digital AND era AND governance) AND (ai OR "artificial intelligence" OR "machine learning" OR blockchain* OR "big data" OR algorithm* OR "natural language processing" OR nlp) Search 2</p>
        <p>("public value*") AND (ai OR "artificial intelligence" OR "machine learning" OR blockchain* OR "big data" OR algorithm* OR "natural language processing" OR nlp) Search 3</p>
        <p>e-government AND adoption AND (ai OR "artificial intelligence" OR "machine learning" OR blockchain* OR "big data" OR algorithm* OR "natural language processing" OR nlp) Search 4</p>
        <p>e-government AND diffusion AND (ai OR "artificial intelligence" OR "machine learning" OR blockchain* OR "big data" OR algorithm* OR "natural language processing" OR nlp) Search 5</p>
        <p>(government OR "public sector" OR "public administration") AND (ai OR "artificial intelligence" OR "machine learning" OR blockchain* OR "big data" OR algorithm* OR "natural language processing" OR nlp) AND adoption Search 6</p>
        <p>(government OR "public sector" OR "public administration") AND (ai OR "artificial intelligence" OR "machine learning" OR blockchain* OR "big data" OR algorithm* OR "natural language processing" OR nlp) AND diffusion Search 7</p>
        <p>(npm OR "new public management") AND (ai OR "artificial intelligence" OR "machine learning" OR blockchain* OR "big data" OR algorithm* OR "natural language processing" OR nlp)</p>
        <p>Deriving from the TOE framework, contextual factors under technology, organisation, and environment are identified as influencing AI adoption. A global theme of absorptive capacity also emerged influencing AI adoption from the literature review. Table 4 summarises the main themes and codes, which are discussed below.</p>
        <p>The technology context identifies two themes of IT assets and capabilities. These encompass the current level of e-government adoption and digitalisation capabilities. The third theme is identified as characteristics of adopting technology in terms of its perceived benefits.</p>
        <p>The theme of IT assets identifies an organisation's digital maturity as the determinant of AI adoption. IT assets include cloud computing capabilities (Coglianese &amp; Lehr, 2017); digital infrastructure in terms of connectivity, bandwidth, processing power, and networks (Alshahrani, Dennehy, &amp; Mäntymäki, 2021;Chatfield &amp; Reddick, 2018;Desouza, Dawson, &amp; Chenok, 2020;Schedler, Guenduez, &amp; Frischknecht, 2019;van Noordt &amp; Misuraca, 2020a;van Noordt &amp; Misuraca, 2020b;Wirtz &amp; Müller, 2018); "compatibility" of existing assets with new AI technologies (Schaefer et al., 2021, p. 6); and ability to integrate systems and data (Erkut, 2020;Mikalef, Fjortoft, &amp; Torvatn, 2019;Rogge, Agasisti, &amp; De Witte, 2017). The data related assets are identified as data accessibility, internally within the organisation or externally, and quality (Alshahrani et al., 2021;Ballester, 2021;Fatima, Desouza, Buck, &amp; Fielt, 2021;Gao &amp; Janssen, 2020;Wirtz et al., 2018); database management infrastructure and enterprise architecture (Gong &amp; Janssen, 2021;A. Ojo et al., 2019); ownership and sharing of data between governmental agencies (Alshahrani et al., 2021;Campion, Gasco-Hernandez, Mikhaylov, &amp; Esteve, 2020;Janssen, Brous, Estevez, Barbosa, &amp; Janowski, 2020;Makasi, Tate, Desouza, &amp; Nili, 2021;Pencheva, Esteve, &amp; Mikhaylov, 2020;Rogge et al., 2017;Vogl, Seidelin, Ganesh, &amp; Bright, 2019); and cloud storage (Coglianese &amp; Lehr, 2017).</p>
        <p>The related theme of IT capabilities identifies current capabilities in managing IT assets, basic employee knowledge in AI and big data, and a data-oriented culture essential to building AI capabilities (Ballester, 2021;Campion et al., 2020;Casalino, Saso, Borin, Massella, &amp; Lancioni, 2020;Chatfield &amp; Reddick, 2018;Chen, Ran, &amp; Gao, 2019;Clarke &amp; Margetts, 2014;Desouza et al., 2020;Giest, 2017;Janssen, Brous, et al., 2020;Medaglia et al., 2021;Ojo et al., 2019;Pencheva et al., 2020;van Noordt &amp; Misuraca, 2020a;van Noordt &amp; Misuraca, 2020b). Specialised capabilities are required to develop, deploy, and manage AI assets. A lack of AI experts within public administration requires access to an ecosystem of commercial partners and external AI specialists (Alexopoulos et al., 2019;Campion et al., 2020;Desouza et al., 2020;Makasi et al., 2021;Medaglia et al., 2021;Wirtz &amp; Müller, 2018).</p>
        <p>The third theme of perceived benefits encompasses adopting AI's direct benefits such as cost savings, novel solutions and the ability to meet users' needs or indirect benefits of increased collaboration with peers and industry partners (Alshahrani et al., 2021;Cordella &amp; Dodd, 2019;Mikalef et al., 2021;Schaefer et al., 2021).</p>
        <p>The organisational context identifies three themes of organisational culture, leadership, and inertia.</p>
        <p>The theme of an organisational culture incorporates innovative culture as more receptive to AI adoption and successful diffusion given these new technologies represent high risks and an experimentation attitude (Kuziemski &amp; Misuraca, 2020;Schaefer et al., 2021;van Noordt &amp; Misuraca, 2020a;van Noordt &amp; Misuraca, 2020b;Zuiderwijk, Chen, &amp; Salem, 2021). Ojo et al. (2019) and Schedler et al. (2019) discuss institutional arrangements such as NPM orientation, bureaucratic structure, or digital-era governance mandates embedded in the culture of the organisations that influence AI-related innovations. These arrangements further manifest in terms of alignment between the organisational structure and big data (Giest, 2017), cross-agency collaborations, and the need for a redesign of processes and routines (Campion et al., 2020;Pencheva et al., 2020).</p>
        <p>The theme of leadership stresses transformational leadership traits in leading change associated with AI adoption and diffusion (Campion et al., 2020;De Vries, Bekkers, &amp; Tummers, 2016;Schedler et al., 2019). Transformational leaders can influence culture by establishing personal and social identification related to innovation and institutionalising learning (Alblooshi, Shamsuzzaman, &amp; Haridy, 2020;Alshahrani et al., 2021;Jia, Chen, Mei, &amp; Wu, 2018). Such leaders motivate employees to experiment and consider novel ways of working with AI. Specific to AI adoption and diffusion, the leadership qualities of the CIO are also highlighted as critical. CIOs should not only have technical knowledge of AI but also political acumen to effectively influence enterprise systems design within and across governmental agencies (Chatfield &amp; Reddick, 2018).</p>
        <p>The theme of organisational inertia specific to public administration was identified as a major inhibiting factor for AI adoption and diffusion. Inertia can be in terms of routine rigidity associated with bureaucracy, centralised decision-making, lack of employee empowerment, statusquo bias, and resistance to sharing data within or across agencies (Alshahrani et al., 2021;Campion et al., 2020;Chen et al., 2019;Fatima et al., 2021;Pencheva et al., 2020;van Noordt &amp; Misuraca, 2020b;Zuiderwijk et al., 2021). Or inertia can manifest in terms of resource rigidity with resource scarcity for innovative projects, high demand for AI experts, economic investment requiring political approvals, and insufficient budget for piloting and experimentation (Campion et al., 2020;Mikalef et al., 2019;Schaefer et al., 2021;Schedler et al., 2019;Wirtz et al., 2018). In addition, there is expected to be resistance from unions to the perceived threat to the workforce and displacement of jobs (Young, Bullock, &amp; Lecy, 2019).</p>
        <p>The mandates of public administration are determined by the political leadership and often influenced by election cycles. In addition, such organisations are influenced by peer governmental bodies, citizen demands, private industry, and media scrutiny. Thus, two themes under the environmental context are identified as vertical pressures and horizontal pressures.</p>
        <p>The theme of vertical pressure relates to policy signals, directives, and mandates encouraging digital service delivery and automation (Alshahrani et al., 2021;Clarke &amp; Craft, 2017;Janssen, Brous, et al., 2020;Pencheva et al., 2020;Schaefer et al., 2021;Schedler et al., 2019;Wang, Zhang, &amp; Zhao, 2020). Examples include the digital-first directives in Canada (Canada, 2021), UK's GovTech fund under the AI Sector Deal (Gov.uk, 2019a), US's National AI Initiative (AI.gov, 2021), and UAE's National AI Strategy 2031 (AI.gov.ae, 2021). The vertical pressure is further influenced by macro-level guidelines, regulations, and procurement practices related to the use of AI. Such as algorithmic impact assessment by the Government of Canada (Canada, 2020), EU's General Data Protection Regulation (European Commission, 2016), and the UK's AI procurement in a box (Forum, 2020). The theme of horizontal pressures incorporates intergovernmental competition, citizen demands, industry pressure, and media scrutiny. Public administration is under pressure to implement innovations when its shown to improve performance, save costs, and satisfy citizen demands for personalised and 24/7 services (Schaefer et al., 2021;Wang et al., 2021). The availability of AI technologies to meet these citizen demands exerts industry pressures (Schaefer et al., 2021). This pressure is further influenced by the public sector's fishbowl effect with constant media scrutiny and opposition parties' critiques (Desouza et al., 2020) forcing public administrative bodies to emulate peer agencies' successes. Citizens' perceptions of sharing data and its use by algorithms to make public decisions play a crucial role in public value deliberations related to innovations (Chohan, Hu, Khan, Pasha, &amp; Sheikh, 2021;Criado &amp; Gil-Garcia, 2019;Giest, 2017;Lopes, Macadar, &amp; Luciano, 2019;Misuraca, 2020). Wang et al. (2021) highlight the dual role of public value creation with AI and consider citizens' perception as the demand component. The supply side is driven by political and administrative contexts as discussed under organisational and environmental contexts.</p>
        <p>A global theme of absorptive capacity emerged across all the TOE contexts. In the context of AI adoption, absorptive capacity is manifested through a strong path dependency on existing infrastructure developed through previous e-government innovations, collaborations between organisations, and a network of external technical specialists (Aboelmaged &amp; Mouakket, 2020;Ballester, 2021;Campion et al., 2020;Casalino et al., 2020;Janssen, Brous, et al., 2020;Kuziemski &amp; Misuraca, 2020). The knowledge management practices developing technical skills and data-oriented culture facilitate the exploration of AI technologies in response to citizens' needs, external environmental pressures, and fiscal austerity. Dynamic capabilities ensure optimal resource configurations can be mobilised during the assimilation of AI technologies (Erkut, 2020;Medaglia et al., 2021;Ojo, 2019). The experience acquired through the use of deterministic systems facilitates clarity on the public value outcomes desired from AI (Alshahrani et al., 2021;Ballester, 2021;Campion et al., 2020;Chatfield &amp; Reddick, 2018;Coglianese &amp; Lehr, 2017;Desouza et al., 2020;Erkut, 2020;Fatima et al., 2021;Gao &amp; Janssen, 2020;Gong &amp; Janssen, 2021;Janssen, Brous, et al., 2020;Makasi et al., 2021;Mikalef et al., 2019;Ojo et al., 2019;Pencheva et al., 2020;Rogge et al., 2017;Schaefer et al., 2021;Schedler et al., 2019;van Noordt &amp; Misuraca, 2020a;van Noordt &amp; Misuraca, 2020b;Vogl et al., 2019;Wirtz et al., 2018;Wirtz &amp; Müller, 2018) IT capabilities</p>
        <p>• Current capabilities in managing IT assets (Aboelmaged &amp; Mouakket, 2020;Ballester, 2021;Campion et al., 2020;Casalino et al., 2020;Erkut, 2020;Janssen, Brous, et al., 2020;Janssen, Hartog, Matheus, Yi Ding, &amp; Kuk, 2022;Kuziemski &amp; Misuraca, 2020;Medaglia et al., 2021;Ojo, 2019) than just following the herd and succumbing to external pressures (Janssen et al., 2022).</p>
        <p>The AI implementation strategies discussed are similar to those used in technology implementation projects in public administration such as requirements identification, collaboration with citizens, a need for clear communications, change management, and skills training. Two specific themes emerge as distinct for AI-related technologies: innovative procurement and experimentation. Table 5 summarises the themes and codes which are discussed below. 4.2.2.1. Experimentation. Pilot testing and experimentation are considered critical for AI applications in public administration to identify and mitigate risks of failure which may prove disastrous in eroding citizen trust (Fatima et al., 2021). The majority of ML projects in governments are currently pilot applications (Alexopoulos et al., 2019). The proliferation of innovation labs is a testament to a realised need for experimentation with new technology applications. Smaller successes enable organisations to mature and build capabilities before undertaking a large-scale AI-driven challenge (Desouza et al., 2020;van Veenstra &amp; Kotterink, 2017).</p>
        <p>To support experimentation, the standard government procurements used for established technologies involving comprehensive bidding and evaluation processes are not suitable. Instead, the agile procurement process allows iterative development lifecycles through the acquisition of hardware and software in stages (Desouza et al., 2020). This ensures early access to industry expertise and focuses on defining the problem than developing detailed solution specifications.</p>
        <p>Co-creation of AI solutions with stakeholders provides varied viewpoints and helps develop a clear definition of the problem (Fatima et al., 2021). Citizen collaboration enhances positive perceptions of AI decisions and higher adoption (Criado &amp; Gil-Garcia, 2019;Gesk &amp; Leyer, 2022;Lopes et al., 2019;van Veenstra &amp; Kotterink, 2017). Collaborating with employees on service design alleviates concerns of AI replacing jobs and enhances internal use and adoption (A. Ojo et al., 2019). Collaboration and sharing of data between government departments (Alexopoulos et al., 2019;Janssen, Brous, et al., 2020) help develop better models. Collaboration with private technology companies is key for the development of AI solutions in public administration which generally lack technical expertise (Gao &amp; Janssen, 2020).</p>
        <p>In addition to agile being the preferred implementation approach, a strong project management culture remains a critical component for AI implementations. Project management best practices are required to support citizen and stakeholder engagement (Campion et al., 2020). Furthermore, collaboration and sharing between government departments increase complexity and require additional coordination (Giest, 2017). Project management practices are also required to manage inertia towards sharing of data between government departments, status quo bias, and resistance from unions (Pencheva et al., 2020;van Noordt &amp; Misuraca, 2020b;Young et al., 2019).</p>
        <p>The outcomes of AI diffusion are discussed as two themes: public values and public sector transformation. Table 6 summarises these outcomes and is discussed below.</p>
        <p>The three public values themes are duty, service, and social.</p>
        <p>The public value of duty is characterised by using AI in facilitating the democratic will by enabling citizen engagement and participation at scale (Fatima et al., 2021;Marri, Albloosh, Moussa, &amp; Elmessiry, 2019;Rogge et al., 2017;Schedler et al., 2019). Technologies such as NLP enable public managers to collect unstructured data taking into account the wisdom of the crowd as input to policy development and decisionmaking (Höchtl, Parycek, &amp; Schöllhammer, 2016). Citizens and businesses can co-produce public services using AI-enabled platforms (Ojo, 2019). AI-based decision-making is discussed as techno-rational eliminating human biases and being objective and neutral (Kuziemski &amp; Misuraca, 2020;Young et al., 2019). This objectivity strengthens values of integrity, honesty, and accountability in the efficient use of public funds.</p>
        <p>The use of AI in public administration is mostly discussed in terms of enhancing service-oriented public values. AI technologies enhance external public service delivery capabilities through personalisation, responsiveness, and citizen orientation. Personalised services providing relevant information at the point of interest are achieved by developing detailed profiles of individuals and businesses (Androutsopoulou, Karacapilidis, Loukis, &amp; Charalabidis, 2019;Chatfield &amp; Reddick, 2018;Marri et al., 2019;Ojo, 2019;Rogge et al., 2017). This enables responsiveness to the needs of micro-clusters of citizens (Giest, 2017). Automation of application processes enables instant approval and feedback (Androutsopoulou et al., 2019;Fatima et al., 2021) improving quality and service time. Intelligent virtual agents and chatbots enable 24/7 access to information quickly and reliably (van Noordt &amp; Misuraca, 2019; Wang et al., 2020). The internal aspect of service-oriented values relates to the use of AI in achieving efficiency goals. The automation of simple processes and repetitive tasks enables the allocation of human resources towards higher-order tasks alleviating workloads, improving efficiency, and enhancing productivity (Androutsopoulou et al., 2019;Chen et al., 2019;Fatima et al., 2021;Mikalef et al., 2019;van Noordt &amp; Misuraca, 2019;Wang et al.;Young et al., 2019). For complex interdependent problems, AI-augmented decision-making uncovers new options, anomaly detection, rigorous risk identification, and better service planning and interventions (Gao &amp; Janssen, 2020;Lopes et al., 2019;A. Ojo et al., 2019).</p>
        <p>Socially oriented public values are sparsely discussed as specific planned outcomes from the use of AI. Societal outcomes are instead considered in terms of ethical AI principles and implicit values. These are discussed either as secondary benefits or tensions when pursuing service and duty-oriented values. For example, citizen collaboration (duty values) helps with equality and inclusiveness (Ojo et al., 2019;van Noordt &amp; Misuraca, 2020a). Or, the ability to redirect public managers towards complex societal issues by automation of mundane tasks (service values) (Ojo, 2019).</p>
        <p>The adoption of AI in public administration represents disruptive innovation leading to a reconfiguration of organisational structures (Desouza et al., 2020). This is a step towards realising the DEG vision envisaged with the first wave of technological innovation. Referred to as algorithmic bureaucracy, the use of AI transforms street-level bureaucrats into system-level (Henman, 2019). The positive aspects of the transformation are manifested in terms of achieving duty and service-oriented values as discussed in Section 4.2.3.1. Scholars have argued building AI capabilities leads to a more innovative culture and thus a virtuous cycle ensues further reenforcing DEG vision (James &amp; Whelan, 2022;Mikalef et al., 2021;Young et al., 2019). The accompanying negative aspect is distancing public servants from citizens and inhibiting a rich knowledge generation avenue (Bullock, Young, &amp; Wang, 2020;Young et al., 2019). Other negative implications include the social costs of job losses, re-skilling, and workforce displacement (Al Mutawa &amp; Rashid, 2020;Fatima et al., 2021). Similar to the public values discussion, the resolution of AI tensions drives the positive and negative aspects of public sector transformation with the use of AI.</p>
        <p>The theme of AI tensions emerged as a global construct impacting the outcomes of AI implementation and diffusion in terms of public value creation and public sector transformation. Five sets of tensions are identified that arise as a result of a conflict between competing values. Such tensions can be "true dilemmas" where two or more values are inherently contradictory or "dilemmas in practice where tensions are not inherent" but as a result of limitations of technology or resources (Whittlestone, Nyrup, Alexandrova, Dihal, &amp; Cave, 2019, p. 24). Table 7 summarises the themes and codes related to AI tensions which are discussed below.</p>
        <p>The essence of automation versus augmentation tension can be distilled into three related issues. First, the level of control and public decision-making power humans should retain over AI. Second, is the pursuit of efficiency and cost-saving goals. Third, is the debate on the impact of technological advancement on jobs.</p>
        <p>The common agreement between scholars is that automation using AI is only appropriate for repetitive and low discretionary tasks (Ahmad, Najm-ul-Islam, &amp; Ahmed, 2017;Bullock et al., 2020;Mikalef et al., 2019). Gesk &amp; Leyer, 2022's analysis shows citizen disposition towards humans for delivery of specific public services while the acceptance of AI for general services is inhibited by "fear of failure" (p. 8) reflecting citizen's perception of AI's inability to handle exceptions. Higher discretionary tasks that may directly impact an individual or community are typically characterised by fuzzy success criteria and multiple interdependent systems that are difficult to model (Ballester, 2021;Young et al., 2019). The use of AI as an augmented decision-support system for such tasks has immense benefits for generating hybrid knowledge combining complex analytical correlational options and human contextual intelligence (Ahmad et al., 2017;Liu, Tang, &amp; Chen, 2020;Mikalef et al., 2019). The tensions arise between those seeking to implement AI for generating novel inputs to public decision-making versus those seeking efficiency (James &amp; Whelan, 2022;Veale, Van Kleek, &amp; Binns, 2018). In a fiscally constrained environment, the pressures to adopt AI for achieving efficiency and cost savings might seem obligatory. The unknown risk of losing control to self-learning algorithms managing machine-to-machine interactions and critical public resources needs to be balanced against the apparent advantage in terms of task scalability and costs (Wirtz et al., 2018;Young et al., 2019). The socially-oriented ethos of protecting citizens from algorithmic harm might conflict with the temptations of efficiency and cost savings (Fatima et al., 2021;Höchtl et al., 2016;Kuziemski &amp; Misuraca, 2020;Marri et al., 2019;Ojo, 2019;Rogge et al., 2017;Schedler et al., 2019;Young et al., 2019) Service</p>
        <p>• Personalised services and enhanced responsiveness • Instant case approvals and feedback • 24/7 services and access to reliable information • Efficiency goals • Allocation of human resources to higherorder tasks • Augmented decision making (Androutsopoulou et al., 2019;Chatfield &amp; Reddick, 2018;Chen et al., 2019;Fatima et al., 2021;Gao &amp; Janssen, 2020;Giest, 2017;Lopes et al., 2019;Marri et al., 2019;Mikalef et al., 2019;Ojo, 2019;Ojo et al., 2019;Rogge et al., 2017;van Noordt &amp; Misuraca, 2019;Wang et al.;Young et al., 2019)</p>
        <p>• Primarily discussed as ethical AI principles and AI tensions (discussed in Rashid, 2020;Bullock et al., 2020;Desouza et al., 2020;Fatima et al., 2021;Henman, 2019, p. 74;James &amp; Whelan, 2022;Mikalef et al., 2021;Young et al., 2019) (Misuraca, 2020). Ahn and Chen (2020, p. 249) ask the pertinent question, "how far are we going to allow AI to make [public] decisions?" and "… the process of reconciliation when there is a conflict … with human-based decisions."</p>
        <p>The impact of AI on labour markets continues the age-old debate on workforce substitution and job losses with technological advancement. However, with AI able to automate or augment cognitive tasks, both front-line and managerial jobs are at risk (Alshahrani et al., 2021;Androutsopoulou et al., 2019;Casares, 2018;Reis, Santo, &amp; Melão, 2019;van Noordt &amp; Misuraca, 2020a;Wirtz et al., 2018;Zuiderwijk et al., 2021). Public administration is one of the largest employers in society and the replacement of employees with AI will have significant societal implications.</p>
        <p>The tension between nudging and autonomy can be viewed from the vantage of collective rights versus individual freedoms. State surveillance and behavioural control are often justified in terms of maintaining security and advancing collective well-being. This contrasts with individual values of liberalism and selfdetermination. When a public administration adopts AI, citizens do not have the right to object to receiving public services (Gesk &amp; Leyer, 2022;Reis et al., 2019). Large-scale surveillance enables governments to observe citizens and use algorithmic predictions to plan interventions influencing people's lives, decisions, and economies (Erkut, 2020;Misuraca, 2020;Pencheva et al., 2020). The question of legitimacy and trust in officials in power becomes even more critical. Behavioural science and social engineering techniques using AI to influence citizens towards a policy goal might be socially beneficial but can be equally exploited for political or private motives (Kuziemski &amp; Misuraca, 2020;Liaropoulos, 2019;van Noordt &amp; Misuraca, 2020b). Others argue such nudging even for altruistic policy goals threatens the core of modern democratic and liberal societies characterised by autonomy, free decision, and self-determination (Wirtz &amp; Müller, 2018).</p>
        <p>The pursuit of personalised services using AI enhances serviceoriented values and customer satisfaction. However, this level of personalisation can create filter bubbles (Pariser, 2011) against the ethos of public service delivery in providing consistent services and messages to all citizens alike. The filter bubbles can further enable classification and behavioural control of citizens ensuing in a negative feedback loop towards algorithmic authoritarianism benefiting individuals or groups in power in the name of collective well-being. 4.2.4.3. Data accessibility versus security and privacy. Data privacy and security are among the most contentious topics debated in media and politics. Such debates have motivated national data protection legislation in several countries such as the EU's General Data Protection Regulation (GDPR) (European Commission, 2016). Governments generally have access to sensitive data related to taxes, health records,</p>
        <p>AI tensions and data governance.</p>
        <p>Codes References</p>
        <p>• Automation of repetitive and low discretionary tasks • Augmentation for higher discretionary tasks • Tensions between cost and efficiency motives versus novel inputs to decision making and protecting citizens from algorithmic harm • Impact on the labour markets (Ahmad et al., 2017;Ahn &amp; Chen, 2020;Alshahrani et al., 2021;Androutsopoulou et al., 2019;Ballester, 2021;Bullock et al., 2020;Casares, 2018;Gesk &amp; Leyer, 2022;James &amp; Whelan, 2022;Liu et al., 2020;Mikalef et al., 2019;Misuraca, 2020;Reis et al., 2019;van Noordt &amp; Misuraca, 2020a;Veale et al., 2018;Wirtz et al., 2018;Young et al., 2019;Zuiderwijk et al., 2021) Nudging versus autonomy</p>
        <p>• Collective rights versus individual freedoms • State surveillance and behaviour control for achieving policy goals using AI • Citizen's right to object to being governed by AI • Personalised services and creation of filter bubbles (Erkut, 2020;Gesk &amp; Leyer, 2022;Kuziemski &amp; Misuraca, 2020;Liaropoulos, 2019;Misuraca, 2020;Pariser, 2011;Pencheva et al., 2020;Reis et al., 2019;van Noordt &amp; Misuraca, 2020b;Wirtz &amp; Müller, 2018) Data accessibility versus security and privacy</p>
        <p>• Accessibility and use of existing citizen data collected for other purposes • Consent and providing data as a precondition for receiving public services • Constant threats to the security of sensitive data (Al Mutawa &amp; Rashid, 2020;Chen et al., 2019;Clarke &amp; Margetts, 2014;Coglianese &amp; Lehr, 2017;Erkut, 2020;Fatima et al., 2021;Kuziemski &amp; Misuraca, 2020;Marri et al., 2019;Ojo, 2019;Ojo et al., 2019;Pencheva et al., 2020;Reis et al., 2019;Rogge et al., 2017;Schedler et al., 2019;van Noordt &amp; Misuraca, 2020a;Veale et al., 2018;Wirtz et al., 2018) Predictive accuracy versus discrimination, biases, citizen rights</p>
        <p>• Use of sensitive variables for higher predictive power versus embedding biases and discrimination • Acceptable error rates against the risk of marginalisation of vulnerable communities • Digital divide • Negative learnings from the environment • Correlational knowledge versus contextual human knowledge (Ahn &amp; Chen, 2020;Andrews, 2018;Casares, 2018;Coglianese &amp; Lehr, 2017;Criado et al., 2020;Fatima et al., 2021;Harrison &amp; Luna-Reyes, 2022;Henman, 2019;Höchtl et al., 2016;Janssen, Brous, et al., 2020;Liaropoulos, 2019;Marri et al., 2019;Ojo et al., 2019;Scurich &amp; Krauss, 2020;Selbst et al., 2019;Valle-Cruz et al., 2019;van Noordt &amp; Misuraca, 2020b;Wirtz et al., 2018;Young et al., 2019;Zuiderwijk et al., 2021) Predictive accuracy versus transparency and accountability versus gaming the system</p>
        <p>• Higher predictive accuracy versus transparency and interpretation of results • Lacks casual intuition • Accountability and responsibility of AI decisions • Justification of AI based public decisions • Ability to game the system with higher transparency (Chen et al., 2019;Harrison &amp; Luna-Reyes, 2022;Henman, 2019;Janssen, Brous, et al., 2020;Janssen et al., 2022;Makasi et al., 2021;Mulligan &amp; Bamberger, 2019;Ojo et al., 2019;Sousa et al., 2019;Veale et al., 2018;Veale &amp; Brass, 2019;Wirtz et al., 2018;Young et al., 2019;Zuiderwijk et al., 2021) Data governance</p>
        <p>• Big, Open, and Linked Data (BOLD is dependent on multiple organisations or systems with different data management practices • AI lacking contextual domain knowledge can exacerbate the data quality and validity issues • Analogous management practices towards higher data quality and trustworthiness • Increasing the data literacy of public administrators (Alexopoulos et al., 2019;Alshahrani et al., 2021;Gong &amp; Janssen, 2021;Harrison &amp; Luna-Reyes, 2022;Janssen, Brous, et al., 2020) properties, and social benefits. The use of this data can provide a near accurate profile of citizens classified into micro-population clusters (Pencheva et al., 2020). Citizens and front-line bureaucrats are unaware of how data generated through their interactions might be used downstream for data mining and machine learning (Veale et al., 2018) raising concerns about consent. In some cases, the government can go to the extreme in encouraging citizens to part with data in return for getting services (Marri et al., 2019). Thus, accessibility to data and its use by governments for purposes other than what it was collected raises severe privacy-related concerns. On one hand use of data can lead to superior public policy and service delivery towards duty and service-oriented public values. However, at the same time undermines the social public value of privacy.</p>
        <p>A related tension is due to limitations in technology and a constant threat to the security of collected data. This requires specialised skills and technology to properly secure sensitive data and constantly monitor for threats that can become cost-prohibitive (Al Mutawa &amp; Rashid, 2020;Chen et al., 2019;Clarke &amp; Margetts, 2014;Coglianese &amp; Lehr, 2017;Erkut, 2020;Fatima et al., 2021;Kuziemski &amp; Misuraca, 2020;Ojo, 2019;Ojo et al., 2019;Reis et al., 2019;Rogge et al., 2017;Schedler et al., 2019;van Noordt &amp; Misuraca, 2020a;Wirtz et al., 2018). 4.2.4.4. Predictive accuracy versus discrimination, biases, citizen rights. The tension between service and social-oriented values is the most severe in terms of achieving predictive accuracy at the cost of undermining citizen rights and amplifying biases and discrimination. A related debate is on the appropriateness of the type of knowledge used for decisionmaking by AI, i.e. correlational versus causation.</p>
        <p>The use of sensitive variables such as gender, religion, and race can increase the predictive power of algorithms. Even when such variables are prohibited from use in AI models, other related variables such as employment stability, two-parent households, neighbourhoods, etc. can become proxies for race and socio-economic clusters leading to higher predictability (Scurich &amp; Krauss, 2020). However, this accuracy comes at the cost of propagating human biases and discrimination inherent in the data used for machine training (Janssen, Brous, et al., 2020;van Noordt &amp; Misuraca, 2020b;Young et al., 2019). Public managers must decide on the acceptable error rates against the risk of marginalisation of vulnerable communities (Andrews, 2018;Coglianese &amp; Lehr, 2017;Criado, Valero, &amp; Villodre, 2020;Henman, 2019;Marri et al., 2019;D. Valle-Cruz et al., 2019). The issue of the digital divide can become a double-edged sword. Disadvantaged groups are unable to provide sufficient data in the first place due to socio-economic barriers. Any policy interventions based on AI models will lack statistically significant perspectives on such clusters and thereby further exasperating the digital divide (D. Valle-Cruz et al., 2019).</p>
        <p>AI systems are prone to failures and malfunctions from time to time learning negative behaviour from the environment (A. Ojo et al., 2019;Wirtz et al., 2018;Zuiderwijk et al., 2021). This will be detrimental to the well-being and justice of citizens and public administration employees (Fatima et al., 2021;Selbst, Boyd, Friedler, Venkatasubramanian, &amp; Vertesi, 2019). Maintenance of AI to ensure detections and rectification of models can become cost-prohibitive requiring specialised skills and ongoing audits (Höchtl et al., 2016).</p>
        <p>Another aspect of the predictive power of AI relates to the epistemology of knowledge. Predictions generated through AI are based on historical data and correlational analysis of signs and associations found in the data (Höchtl et al., 2016;Liaropoulos, 2019). This epistemological stance of rationality lacking theory and context is contrasted with human traits of emotions, values, and ethics. These traits combined with domain knowledge establish causal links for making decisions on high discretion tasks (Harrison &amp; Luna-Reyes, 2022;Wirtz et al., 2018). When moral judgements are transformed into probabilistic ratios, the questions of power and legitimacy become critical. One needs to consider who is coding whose interests and the nature of the objective truth when communicated by algorithms (Ahn &amp; Chen, 2020;Casares, 2018). AI making public sector decisions is akin to reducing citizens to data points, efficient and accurate but impersonal and non-democratic (Coglianese &amp; Lehr, 2017). 4.2.4.5. Predictive accuracy versus transparency and accountability versus gaming the system. Ensuring transparency with higher predictive accuracy presents tension in the design process. AI architectures such as neural networks are challenging to reverse engineer to determine factors and weights that produced model outputs (Young et al., 2019). Private sector firms that develop such models regard this as intellectual property and are reluctant to provide design specifications (Harrison &amp; Luna-Reyes, 2022;Mulligan &amp; Bamberger, 2019). This lack of transparency puts accountability and responsibility for AI-based decisions into question. Janssen et al., 2022's experiment shows transparency leads to more correct decisions when algorithmic options are used to support human decisions. However, a related tension ensues in the ability to game the system if such models were to become fully transparent.</p>
        <p>AI systems are commonly referred to as black-box designs transforming input variables into predictions or classifications. The correlational analysis of large amounts of data is characterised by opaqueness in how information is handled (Makasi et al., 2021;Zuiderwijk et al., 2021). It lacks casual intuition on the statistical significance of explanatory variables (Coglianese &amp; Lehr, 2017). Public decisions supported by AI that cannot be explained, and more importantly justified, constitute challenges to legal accountability (Janssen, Brous, et al., 2020;Sousa, Melo, Bermejo, Farias, &amp; Gomes, 2019;Veale &amp; Brass, 2019). There is a lack of a legal framework as to the liability of algorithmic public decisions (Henman, 2019;Wirtz et al., 2018). Should the responsibility lie with the public administration, the technology company, or the technology itself (Chen et al., 2019)? What is the role of public servants as mediators of algorithmic decisions (Janssen, Brous, et al., 2020)? Is there a need to develop a legal stature for technology similar to businesses so that they can be held liable?</p>
        <p>Transparency and explainability in AI-based decisions can garner higher trust both from public administration employees and citizens. However, the drawback of increased transparency is the ability to game the system for private motives (Janssen, Brous, et al., 2020;Ojo et al., 2019). A new industry might emerge in being able to manipulate public sector algorithmic decisions if the logic is transparent. Another concern is internal gaming by public administration employees towards opportunistic behaviours similar to performance measures being manipulated to meet specific targets for funding (Veale et al., 2018).</p>
        <p>Thus, public administration leaders and technology vendors need to ensure a balance between opaqueness to prevent gaming of the systems against ensuring decisions can be explained and justified in a legal setting.</p>
        <p>The theme of data governance emerged across AI tensions as a critical component of managing such tensions. Table 7 summarises the themes and codes and is discussed below.</p>
        <p>The data driving AI technologies in public administration, in particular machine learning, is Big, Open, and Linked Data (BOLD) consisting of structured and unstructured formats, generated in realtime, and dependent on multiple organisations or systems with different data management practices (Alexopoulos et al., 2019;Gong &amp; Janssen, 2021;Harrison &amp; Luna-Reyes, 2022;Janssen, Brous, et al., 2020). In addition, AI lacking contextual domain knowledge can exacerbate data quality and validity issues (Harrison &amp; Luna-Reyes, 2022). Data governance principles within public administration can ensure analogous management practices towards higher data quality and trustworthiness (Alshahrani et al., 2021;Janssen, Brous, et al., 2020). Another component of governance is increasing the data literacy of public administrators to be able to promote and maintain such practices and question data validity and reliability within their domain knowledge (Harrison &amp; Luna-Reyes, 2022).</p>
        <p>Adopting a processual view of innovation, the AI adoption stage consists of "activities that pertain to recognizing a need, searching for solutions, becoming aware of existing innovations, identifying suitable [AI] innovations and proposing some for adoption" (Damanpour &amp; Schneider, 2006, p. 217). Implementation of advanced computing technologies like AI needs to be first piloted and tested with low-risk applications (Desouza et al., 2020). The AI implementation stage is the post-adoption phase reflecting project initiation, resource allocations and funding, iterative implementation of AI solutions, and preparing the organisation for its use (Damanpour &amp; Schneider, 2006). Finally, AI diffusion represents the rollout of a full-scale product for wider operational use following several pilot applications when its use "becomes a routine feature of the organization" (Damanpour &amp; Schneider, 2006, p. 217). Using the results of the qualitative synthesis and the theoretical framework, a future research agenda is developed for the adoption, implementation, and diffusion of AI innovation. Furthermore, the decisions on AI tensions are made during the implementation stages while their effects materialise in the diffusion stage. These are discussed under diffusion given their embeddedness with public value creation. The research agenda is show in Table 8 and discussed below.</p>
        <p>The TOE framework provided a theoretical lens for categorising factors influencing AI adoption, as discussed in the literature, under technology, organisational, and environmental context as discussed in Section 4.2.1. The findings concur with Mikalef &amp; Gupta, 2021's construct of AI capabilities consisting of tangible and human (reflected in the technology context) and intangible (reflected in the organisational context) resources. The emergence of the absorptive capacity construct as a global theme suggests a strong path dependency on past technology implementations and existing infrastructure, knowledge management processes, and innovative culture. Lane, Koka, and Pathak (2006) describe two antecedents of absorptive capacityinternal and external. External factors relate to environmental conditions, knowledge characteristics, and learning relationships. Internal refers to mental models, structures, and organisational strategies. This concurs with technology and environmental contexts as external factors and organisational contexts as internal factors in the results of the review.</p>
        <p>The environmental pressures act as external triggers for public administration to respond to specific stimuli. The extent to which public managers can align their resource configurations to this external trigger is determined by their dynamic capabilities, organisational routines, and existing knowledge. Absorptive capacity enables the exploration and evaluation of AI technologies as solutions to these triggers. Thus, future qualitative and quantitative studies need to explore and test the effect of technology, organisation, environment contextual variables, and absorptive capacity on AI adoption.</p>
        <p>The results showcase the importance of a strong project management culture for the design and implementation of AI technologies within the public administration. Similar to prior technology implementations in public administration, AI implementation involves the coordination of several stakeholders, management of change related to both automation and augmentation, vendor management, and management of project costs. In addition, the unique aspects of AI implementation call for using agile methods and new innovative procurement methodologies. Thus, future research should explore AI implementations in public administration through in-depth case studies or ethnographic studies outlining the underlying mechanisms and dynamics of AI projects. Quantitative studies can test the applicability of established conceptual models of technology implementations within the AI context.</p>
        <p>As highlighted in the results, the three public value outcomes from AI diffusion are duty, service, and social. Public administration by its very nature has several competing interests and demands, the pursuit of this pluralism often leads to conflicts between these public values. In the context of AI diffusion, conflicts between public values are embodied in AI tensions. The decisions made on a wide spectrum of such apparent opposing poles during the design and implementation are deemed to emphasise certain values over others. Several pertinent research questions need to be explored related to each of the five AI tensions as outlined in Table 8. Future researchers can consider qualitative studies to explore each tension in-depth. In addition, scales can be developed and tested to measure each tension on a continuum between two opposing dimensions.</p>
        <p>AI tensions can also be viewed from a perceptual perspective in the way governments communicate management of these tensions impacting employees' and citizens' acceptance. Thus, future research will need to test the effect of decisions on AI tensions on citizen adoption.</p>
        <p>Strong governance policies relating to acquiring, preparing, and ongoing auditing of the data can help identify and eliminate biases (Medaglia et al., 2021). This can partially alleviate tensions between predictive accuracy and discrimination. Similarly, data governance principles on accessibility (see Table 1 in Janssen, Brous, et al., 2020) can help alleviate tensions related to privacy and security. Data stewardship and separation of control can become key aspects of the legal framework to define accountability of public decisions and enumerate delegation between humans and machines (Janssen, Brous, et al., 2020;Pencheva et al., 2020). Public administrators with advanced statistical knowledge and data management capabilities can provide domain expertise to software developers and evaluate the quality of AI outcomes improving the accuracy of these models towards the desired public value goals (Harrison &amp; Luna-Reyes, 2022). Hence, future research needs to explore the role of data governance in the management of AI tensions towards public value creation.</p>
        <p>This review aimed to synthesise current scholarship on the phenomenon of AI adoption and diffusion in public administration. We outline four theoretical contributions. First, adopting a multidisciplinary approach and a processual view of innovations, the full life cycle from AI adoption to diffusion was explored. The use of a critical realist perspective in a systematic literature review enabled us to propose underlying constructs at each stage of the process. We identify absorptive capacity and a comprehensive list of variables under technology, organisational, and environmental context as factors influencing AI adoption as discussed in the literature. Thus, we propose a TOE model within the specific context of AI and public administration for future testing contributing to the technology adoption and public administration literature. Second, this review addresses the calls for using a public value-based perspective when exploring the implementation and use of AI in public administration. AI outcomes are viewed from a vantage of public value creation leading to the identification of AI tensions. Third, to our knowledge, this is the first review that outlines five primary AI tensions that may be experienced as dilemmas or paradoxical tensions when implementing and using AI in public administration. Fourth, the suggested research questions highlight the current lack of understanding of the AI phenomenon within the public administration. This also lays out a future research agenda for developing and testing theory in this area.</p>
        <p>This review does come with limitations. First, this review synthesises both conceptual and empirical literature to provide a theoretical landscape of the current thought and empirical evidence. The findings are geared towards future theory development and testing and should be used within this context. Second, the review was limited to two specific AI technologies, ML and NLP, and the public administration context. Future literature reviews can expand the scope of technologies as well as include a broader public sector context including law enforcement, healthcare, city planning, etc. Third, following a systematic literature review, we intended to encompass extant literature within the defined research protocol. However, AI in public administration is an active area of research and this review might have missed important publications published following our search.</p>
        <p>The use of AI technologies in public administration is expeditiously accelerating with the prospect of efficient low-cost public service delivery and higher levels of citizen engagement. A long-awaited technocentric governance model is around the corner. However, similar to private sector applications, public leaders are grappling with the tensions AI introduces in service design and delivery. Notwithstanding several guidelines and frameworks that have been introduced by central governments and supra-national bodies, their application at the meso and micro level of public administration remains elusive. This review attempted to explore the phenomenon of AI in public administration with specific goals of understanding the factors influencing AI adoption and key tensions during AI diffusion as discussed in the literature, both towards achieving the goals of public value creation. We used a multi-disciplinary approach using theories from IS, management and public administration literature.</p>
        <p>Through a systematic literature review, we identify TOE variables as factors influencing AI adoption. The construct of absorptive capacity emerged as a new theme during our analysis. Using a public value framework, we adopted the perspective that public administration leaders and managers are not just passive executors of political direction but play an important role in building the potential absorptive capacity of their organisation sensing changes in the political environment and responding to customer needs and horizontal pressures from other agencies. Public managers strive to maximise public value through optimal use of resources. However, several tensions arise during the design and implementation of AI technologies. Trade-offs made by public managers impact aggregate public value that can be realised from AI and ultimately the citizen adoption of such technologies. Data governance maturity is further identified as an important component of managing some aspects of AI tensions.</p>
        <p>The suggested future research agenda lays the groundwork for addressing important research questions pertaining to understanding the AI phenomenon in public administration from a processual view. The novel theoretical contribution of this review is the identification of five AI tensions. Practitioners can also use the identified AI tensions to undertake a cost-benefit analysis before the design or acquisition of an AI solution for public administration needs.</p>
        <p>Annual International Conference on Digital Government Research International Conference on Theory and Practice of Electronic Governance International Conference on Electronic Participation, ePart Hawaii International Conference on System Sciences IFIP WG 6.11 Conference on e-Business, e-Services, and e-Society IFIP WG 5.5 Working Conference on Virtual Enterprises Iberian conference on information systems and technologies (CISTI) Conference on Fairness, Accountability, and Transparency Conference on Human Factors in Computing Systems European Conference on Cyber Warfare and Security NA International Conference on Industrial Engineering and Operations Management Annual conference of the Italian Chapter of AIS International Forum on Digital and Democracy. Towards A Sustainable Evolution, IFDaD International Conference on Digitization: Landscaping Artificial Intelligence, ICD International Conference on Electronic Government Year Fig. 2. Year of publications.</p>
        <p>Inertia • Bureaucracy and centralised decision-making • Status-quo bias • Lack of employee empowerment • Resistance to data sharing • Resource scarcity • Cost versus benefits for experimental projects • Resistance from unions</p>
        <p>(Alshahrani et al., 2021; Campion et al., 2020; Chen et al., 2019; Fatima et al., 2021; Mikalef et al., 2019; Pencheva et al., 2020; Schedler et al., 2019; van Noordt &amp; Misuraca, 2020b; Wirtz et al., 2018; Young et al., 2019; Zuiderwijk et al., 2021)</p>
        <p>Rohit Madan: Conceptualization, Formal analysis, Methodology, Writingoriginal draft, Writingreview &amp; editing. Mona Ashok: Conceptualization, Supervision, Writingreview &amp; editing.</p>
        <p>Future research agenda for AI adoption, implementation, and diffusion in the public administration.</p>
        <p>Research Questions</p>
        <p>• What is the effect of technology contextual constructs, such as IT assets, IT capabilities, and perceived benefits on AI adoption by public administration? • What is the effect of organisational contextual constructs, such as leadership, culture, and inertia on AI adoption by public administration?</p>
        <p>• What is the effect of environmental contextual constructs, such as horizontal and vertical pressures, on AI adoption by public administration?</p>
        <p>• What is the effect of absorptive capacity on AI adoption by public administration? AI Implementation</p>
        <p>• How are AI projects in public administration managed? What are the unique attributes compared to previous technology implementation projects? • What is the effect of the resolution of AI tensions as an aggregate on public value creation?</p>
        <p>• What is the effect of the resolution of AI tensions on citizen adoption of AI?</p>
        <p>The authors did not receive funding/support from any organisation for the submitted work. The authors have no relevant financial or nonfinancial interests to disclose.</p>
    </text>
</tei>
