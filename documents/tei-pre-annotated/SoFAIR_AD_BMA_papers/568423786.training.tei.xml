<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-13T13:31+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>A review of studies published in Industrial Marketing Management over the past two decades and more shows that these studies not only used partial least squares structural equation modeling (PLS-SEM) widely to estimate and empirically substantiate theoretically established models with constructs, but did so increasingly. In line with their study goals, researchers provided reasons for using PLS-SEM (e.g., model complexity, limited sample size, and prediction). These reasons are frequently not fully convincing, requiring further clarification. Additionally, our review reveals that researchers' assessment and reporting of their measurement and structural models are insufficient. Certain tests and thresholds that they use are also inappropriate. Finally, researchers seldom apply more advanced PLS-SEM analytic techniques, although these can support the results' robustness and may create new insights. This paper addresses the issues by reviewing business marketing studies to clarify PLS-SEM's appropriate use. Furthermore, the paper provides researchers and practitioners in the business marketing field with a best practice orientation and describes new opportunities for using PLS-SEM. To this end, the paper offers guidelines and checklists to support future PLS-SEM applications.A review of studies published in Industrial Marketing Management over the past two decades and more shows that these studies not only used partial least squares structural equation modeling (PLS-SEM) widely to estimate and empirically substantiate theoretically established models with constructs, but did so increasingly. In line with their study goals, researchers provided reasons for using PLS-SEM (e.g., model complexity, limited sample size, and prediction). These reasons are frequently not fully convincing, requiring further clarification. Additionally, our review reveals that researchers' assessment and reporting of their measurement and structural models are insufficient. Certain tests and thresholds that they use are also inappropriate. Finally, researchers seldom apply more advanced PLS-SEM analytic techniques, although these can support the results' robustness and may create new insights. This paper addresses the issues by reviewing business marketing studies to clarify PLS-SEM's appropriate use. Furthermore, the paper provides researchers and practitioners in the business marketing field with a best practice orientation and describes new opportunities for using PLS-SEM. To this end, the paper offers guidelines and checklists to support future PLS-SEM applications.</p>
        <p>Structural equation modeling (SEM) is firmly established in marketing research as a method to estimate (complex) models with relationships and chains of effects between theoretical constructs, which cannot be directly observed (Hair, Hult, Ringle, Sarstedt, &amp; Thiele, 2017;Martínez-López, Gázquez-Abad, &amp; Sousa, 2013). The composite-based 1 partial least squares structural equation modeling (PLS-SEM) method has become increasingly popular over the past two decades and more to analyze such models in marketing (e.g., Hair, Hult, et al., 2017;Sarstedt et al., 2022). This also applies to various other business disciplines such as accounting (e.g., Nitzl, 2016;Nitzl &amp; Chin, 2017), family business research (e.g., Hair et al., 2021;Sarstedt, Ringle, Smith, Reams, &amp; Hair, 2014), hospitality and tourism (e.g., Ali, Rasoolimanesh, Sarstedt, Ringle, &amp; Ryu, 2018;Usakli &amp; Kucukergin, 2018), human resource management (e.g., Legate, Hair, Chretien, &amp; Risher, 2022;Ringle, Sarstedt, Mitchell, &amp; Gudergan, 2020), information systems (e.g., Benitez, Henseler, Castillo, &amp; Schuberth, 2020;Hair, Hollingsworth, Randolph, &amp; Chong, 2017), operations management (e.g., Bayonne, Marin-Garcia, &amp; Alfalla-Luque, 2020; Peng &amp; Lai, 2012), and management with various specializations (e.g., Cepeda-Carrión, Cegarra-Navarro, &amp; Cillo, 2019;Hair et al., 2021;Kaufmann &amp; Gaeckler, 2015;Magno, Cassia, &amp; Ringle, 2022;Richter, Sinkovics, Ringle, &amp; Schlägel, 2016). These research fields often use the method to analyze the sources of competitive advantage and success factors regarding relevant target constructs (also see Albers, 2010). Business marketing researchers specifically emphasize certain method attributes, such as PLS-SEM helping researchers to estimate relatively complex models with minimal sample requirements (e.g., Siahtiri, Heirati, &amp; O'Cass, 2020;Statsenko &amp; Corral de Zubielqui, 2020;Yeniaras, Kaya, &amp; Dayan, 2020). The latter can be advantageous given that recruiting a large number of respondents is often challenging in business marketing research due to small populations and limited time of potential respondents (e.g., employees and managers).Structural equation modeling (SEM) is firmly established in marketing research as a method to estimate (complex) models with relationships and chains of effects between theoretical constructs, which cannot be directly observed (Hair, Hult, Ringle, Sarstedt, &amp; Thiele, 2017;Martínez-López, Gázquez-Abad, &amp; Sousa, 2013). The composite-based 1 partial least squares structural equation modeling (PLS-SEM) method has become increasingly popular over the past two decades and more to analyze such models in marketing (e.g., Hair, Hult, et al., 2017;Sarstedt et al., 2022). This also applies to various other business disciplines such as accounting (e.g., Nitzl, 2016;Nitzl &amp; Chin, 2017), family business research (e.g., Hair et al., 2021;Sarstedt, Ringle, Smith, Reams, &amp; Hair, 2014), hospitality and tourism (e.g., Ali, Rasoolimanesh, Sarstedt, Ringle, &amp; Ryu, 2018;Usakli &amp; Kucukergin, 2018), human resource management (e.g., Legate, Hair, Chretien, &amp; Risher, 2022;Ringle, Sarstedt, Mitchell, &amp; Gudergan, 2020), information systems (e.g., Benitez, Henseler, Castillo, &amp; Schuberth, 2020;Hair, Hollingsworth, Randolph, &amp; Chong, 2017), operations management (e.g., Bayonne, Marin-Garcia, &amp; Alfalla-Luque, 2020; Peng &amp; Lai, 2012), and management with various specializations (e.g., Cepeda-Carrión, Cegarra-Navarro, &amp; Cillo, 2019;Hair et al., 2021;Kaufmann &amp; Gaeckler, 2015;Magno, Cassia, &amp; Ringle, 2022;Richter, Sinkovics, Ringle, &amp; Schlägel, 2016). These research fields often use the method to analyze the sources of competitive advantage and success factors regarding relevant target constructs (also see Albers, 2010). Business marketing researchers specifically emphasize certain method attributes, such as PLS-SEM helping researchers to estimate relatively complex models with minimal sample requirements (e.g., Siahtiri, Heirati, &amp; O'Cass, 2020;Statsenko &amp; Corral de Zubielqui, 2020;Yeniaras, Kaya, &amp; Dayan, 2020). The latter can be advantageous given that recruiting a large number of respondents is often challenging in business marketing research due to small populations and limited time of potential respondents (e.g., employees and managers).</p>
        <p>While business marketing researchers increasingly use PLS-SEM (see the review results with regard to publications in Industrial Marketing Management in Fig. 1), they face several challenges in terms of using the method correctly, including in appropriate contexts. First, PLS-SEM is not the only available SEM method, as covariance-based SEM is an alternative (Davvetas, Diamantopoulos, Zaefarian, &amp; Sichtmann, 2020). Comprehensive formal explanations of the PLS-SEM method (Chin, 1998;Henseler, Ringle Christian, &amp; Sarstedt, 2012;Lohmöller, 1989, Chapters 2 and 3;Tenenhaus, Vinzi, Chatelin, &amp; Lauro, 2005;Wold, 1982) have helped business marketing researchers understand the technical distinctions between the SEM methods (also see, for instance, Rigdon, 2012;Rigdon, Sarstedt, &amp; Ringle, 2017): The primary statistical objective of PLS-SEM is prediction in that it minimizes the amount of unexplained variance in the structural model's dependent constructs and in the measurement model's indicators (Sarstedt, Ringle, &amp; Hair, 2022;Wold, 1982); in contrast, while prediction is possible, the primary statistical objective of covariance-based SEM is confirming theory by estimating a new (i.e., model-implied) covariance matrix with minimum difference to the original observed covariance matrix (Hair, Black, Babin, &amp; Anderson, 2018, Chapter 13). In the sense of Gregor's (2006) taxonomy, covariance-based SEM emphasizes explanation, whereas PLS-SEM focuses on prediction, but also facilitates explanation (Hair, 2021a;Sarstedt, Hair, Ringle, Thiele, &amp; Gudergan, 2016). Seminal work has referred to this dual emphasis as PLS-SEM's dual purpose or causalpredictive nature (Jöreskog &amp; Wold, 1982;Wold, 1982). While these technical distinctions offer important guidance, additional aspects also warrant attention when choosing the adequate SEM method for a specific research problem. However, researchers in the field of applied business marketing often seem unaware of these aspects. Similarly, in comparison to consumer marketing research, there are no flagship PLS-SEM applications in business marketing research that researchers could reference. Consumer marketing researchers (e.g., Guenther &amp; Guenther, 2021), for instance, can use the American Customer Satisfaction Index (ACSI) model as an example of a well-known application to determine the relevance of the drivers of consumers' satisfaction and loyalty (Fornell, Johnson, Anderson, Cha, &amp; Bryant, 1996;Fornell, Morgeson, Hult, &amp; VanAmburg, 2020, Chapter 5).While business marketing researchers increasingly use PLS-SEM (see the review results with regard to publications in Industrial Marketing Management in Fig. 1), they face several challenges in terms of using the method correctly, including in appropriate contexts. First, PLS-SEM is not the only available SEM method, as covariance-based SEM is an alternative (Davvetas, Diamantopoulos, Zaefarian, &amp; Sichtmann, 2020). Comprehensive formal explanations of the PLS-SEM method (Chin, 1998;Henseler, Ringle Christian, &amp; Sarstedt, 2012;Lohmöller, 1989, Chapters 2 and 3;Tenenhaus, Vinzi, Chatelin, &amp; Lauro, 2005;Wold, 1982) have helped business marketing researchers understand the technical distinctions between the SEM methods (also see, for instance, Rigdon, 2012;Rigdon, Sarstedt, &amp; Ringle, 2017): The primary statistical objective of PLS-SEM is prediction in that it minimizes the amount of unexplained variance in the structural model's dependent constructs and in the measurement model's indicators (Sarstedt, Ringle, &amp; Hair, 2022;Wold, 1982); in contrast, while prediction is possible, the primary statistical objective of covariance-based SEM is confirming theory by estimating a new (i.e., model-implied) covariance matrix with minimum difference to the original observed covariance matrix (Hair, Black, Babin, &amp; Anderson, 2018, Chapter 13). In the sense of Gregor's (2006) taxonomy, covariance-based SEM emphasizes explanation, whereas PLS-SEM focuses on prediction, but also facilitates explanation (Hair, 2021a;Sarstedt, Hair, Ringle, Thiele, &amp; Gudergan, 2016). Seminal work has referred to this dual emphasis as PLS-SEM's dual purpose or causalpredictive nature (Jöreskog &amp; Wold, 1982;Wold, 1982). While these technical distinctions offer important guidance, additional aspects also warrant attention when choosing the adequate SEM method for a specific research problem. However, researchers in the field of applied business marketing often seem unaware of these aspects. Similarly, in comparison to consumer marketing research, there are no flagship PLS-SEM applications in business marketing research that researchers could reference. Consumer marketing researchers (e.g., Guenther &amp; Guenther, 2021), for instance, can use the American Customer Satisfaction Index (ACSI) model as an example of a well-known application to determine the relevance of the drivers of consumers' satisfaction and loyalty (Fornell, Johnson, Anderson, Cha, &amp; Bryant, 1996;Fornell, Morgeson, Hult, &amp; VanAmburg, 2020, Chapter 5).</p>
        <p>Second, staying abreast of PLS-SEM method developments is a challenge for applied business marketing researchers. They often lack the time resources to review the latest methodological developments, as these compete with the time required to identify compelling research questions, theory, and frameworks, in addition to a usually very timeconsuming recruitment of respondents and data collection. However, PLS-SEM's methodological advances and usage recommendations evolve rapidly, requiring regular reflection and review (Hair, 2021b;Sarstedt, Hair, &amp; Ringle, 2022). An additional challenge is that relevant methodology articles are scattered across far more journals than those that business marketing researchers read regularly. Such journals include, for instance, the Information Systems Journal, the Journal of Family Business Strategy, MIS Quarterly, British Journal of Mathematical and Statistical Psychology, and Computations Statistics and Data Analysis. Against this backdrop, the purpose of this paper is to provide applied business marketing researchers with tailored, up-to-date guidance on when a PLS-SEM approach is appropriate, how to avoid the common errors in previous business marketing applications, and which advanced analytical techniques they should consider to validate their results and create deeper insights, thereby improving their projects' contribution level. Table 1 summarizes the paper's purpose, combining descriptive and prescriptive objectives to create value for business marketing researchers.Second, staying abreast of PLS-SEM method developments is a challenge for applied business marketing researchers. They often lack the time resources to review the latest methodological developments, as these compete with the time required to identify compelling research questions, theory, and frameworks, in addition to a usually very timeconsuming recruitment of respondents and data collection. However, PLS-SEM's methodological advances and usage recommendations evolve rapidly, requiring regular reflection and review (Hair, 2021b;Sarstedt, Hair, &amp; Ringle, 2022). An additional challenge is that relevant methodology articles are scattered across far more journals than those that business marketing researchers read regularly. Such journals include, for instance, the Information Systems Journal, the Journal of Family Business Strategy, MIS Quarterly, British Journal of Mathematical and Statistical Psychology, and Computations Statistics and Data Analysis. Against this backdrop, the purpose of this paper is to provide applied business marketing researchers with tailored, up-to-date guidance on when a PLS-SEM approach is appropriate, how to avoid the common errors in previous business marketing applications, and which advanced analytical techniques they should consider to validate their results and create deeper insights, thereby improving their projects' contribution level. Table 1 summarizes the paper's purpose, combining descriptive and prescriptive objectives to create value for business marketing researchers.</p>
        <p>We base our discussion on an extensive review of all PLS-SEM applications in business marketing studies published in Industrial Marketing Management (IMM) between 1998 and 2020 to ensure that we provide tailored guidance. 2 This review of actual applications is advantageous compared to a generic method review, as it allows us to focus on issues that mainly matter and are worth discussing in the business marketing research context. Consequently, we only briefly discuss aspects with which business marketing researchers are very familiar. We contrast the current state of PLS-SEM applications with up-to-date methodological PLS-SEM developments to identify issues such as common misconceptions, inappropriate analyses, and missed analytical opportunities. We specifically focused on IMM as the leading business marketing journal, as its content provides a good snapshot of PLS-SEM applications in quality studies investigating various business marketing research topics. Our review is based on 140 relevant research articles.We base our discussion on an extensive review of all PLS-SEM applications in business marketing studies published in Industrial Marketing Management (IMM) between 1998 and 2020 to ensure that we provide tailored guidance. 2 This review of actual applications is advantageous compared to a generic method review, as it allows us to focus on issues that mainly matter and are worth discussing in the business marketing research context. Consequently, we only briefly discuss aspects with which business marketing researchers are very familiar. We contrast the current state of PLS-SEM applications with up-to-date methodological PLS-SEM developments to identify issues such as common misconceptions, inappropriate analyses, and missed analytical opportunities. We specifically focused on IMM as the leading business marketing journal, as its content provides a good snapshot of PLS-SEM applications in quality studies investigating various business marketing research topics. Our review is based on 140 relevant research articles.</p>
        <p>In the next sections, we present our review and the discussion by chronologically viewing each PLS-SEM research project, examining the relevant issues in three decision areas: (1) when to use PLS-SEM, (2) which common analyses, thresholds, and tests to report, and (3) which advanced analyses to consider (Web Appendix A). To summarize our key points, we provide guidelines and checklists that researchers can use in future PLS-SEM projects. The Web Appendix also illustrates underutilized common PLS-SEM procedures using an example business marketing dataset (Web Appendix B). We conclude with a general discussion and recommendations for further PLS-SEM-related research.In the next sections, we present our review and the discussion by chronologically viewing each PLS-SEM research project, examining the relevant issues in three decision areas: (1) when to use PLS-SEM, (2) which common analyses, thresholds, and tests to report, and (3) which advanced analyses to consider (Web Appendix A). To summarize our key points, we provide guidelines and checklists that researchers can use in future PLS-SEM projects. The Web Appendix also illustrates underutilized common PLS-SEM procedures using an example business marketing dataset (Web Appendix B). We conclude with a general discussion and recommendations for further PLS-SEM-related research.</p>
        <p>Since there are different SEM approaches-most prominently PLS-SEM and covariance-based SEM (Hair, Hult, et al., 2017;Hoogland &amp; Boomsma, 1998)-business marketing researchers need to determine which approach to use. 3 Although both approaches allow researchers to estimate models with constructs that represent theoretical concepts in statistical models, either through common factors or composites, they differ fundamentally in the way they do so (e.g., Rigdon et al., 2017). A study's objectives and assumptions regarding the underlying theoretical constructs, as well as the data characteristics, determine the most appropriate approach (Jöreskog &amp; Wold, 1982;Sarstedt et al., 2016). Acknowledging that this discussion in the literature is ongoing (e.g., Petter, 2018;Rönkkö, McIntosh, Antonakis, &amp; Edwards, 2016;Sarstedt et al., 2016), we offer two preliminary guiding questions as well as two empirical considerations to help researchers substantiate their conceptual and empirical reasons for choosing PLS-SEM.Since there are different SEM approaches-most prominently PLS-SEM and covariance-based SEM (Hair, Hult, et al., 2017;Hoogland &amp; Boomsma, 1998)-business marketing researchers need to determine which approach to use. 3 Although both approaches allow researchers to estimate models with constructs that represent theoretical concepts in statistical models, either through common factors or composites, they differ fundamentally in the way they do so (e.g., Rigdon et al., 2017). A study's objectives and assumptions regarding the underlying theoretical constructs, as well as the data characteristics, determine the most appropriate approach (Jöreskog &amp; Wold, 1982;Sarstedt et al., 2016). Acknowledging that this discussion in the literature is ongoing (e.g., Petter, 2018;Rönkkö, McIntosh, Antonakis, &amp; Edwards, 2016;Sarstedt et al., 2016), we offer two preliminary guiding questions as well as two empirical considerations to help researchers substantiate their conceptual and empirical reasons for choosing PLS-SEM.</p>
        <p>Researchers mainly use an SEM approach to theoretically establish a model with constructs. They subsequently aim to estimate and assess the hypothesized relationships between the structural model's constructs. Because constructs are not directly observable, they are assumed to be determined and estimated by an observable set of indicators through the 2 To identify relevant papers for our review, we used IMM's own journal search function and the search functions of the three major research databases-EBSCO Business Source Complete, Thomson Reuters Web of Science, and ProQuest ABI/INFORM Global-to identify studies in which the authors used PLS-SEM for the empirical analysis. Two independent coders with expert knowledge of the PLS-SEM technique read each article (Cohen's κ = 0.83) to assess how the study applied PLS-SEM.Researchers mainly use an SEM approach to theoretically establish a model with constructs. They subsequently aim to estimate and assess the hypothesized relationships between the structural model's constructs. Because constructs are not directly observable, they are assumed to be determined and estimated by an observable set of indicators through the 2 To identify relevant papers for our review, we used IMM's own journal search function and the search functions of the three major research databases-EBSCO Business Source Complete, Thomson Reuters Web of Science, and ProQuest ABI/INFORM Global-to identify studies in which the authors used PLS-SEM for the empirical analysis. Two independent coders with expert knowledge of the PLS-SEM technique read each article (Cohen's κ = 0.83) to assess how the study applied PLS-SEM.</p>
        <p>3 This article focuses on the composite-based PLS-SEM method. However, researchers have presented various alternatives to PLS-SEM. For instance, consistent PLS-SEM (PLSc-SEM; Dijkstra, 2010Dijkstra, , 2014; see also Dijkstra &amp; Henseler, 2015b;Dijkstra &amp; Schermelleh-Engel, 2014), its PLSe1/PLS2e extensions (Bentler &amp; Huang, 2014;Huang, 2013), or Yuan, Wen, and Tang's (2020) approach based on Cronbach's α, adjust the parameter estimates to accommodate common factor models. Moreover, the generalized structured component analysis (GSCA; Hwang &amp; Takane, 2004;Hwang &amp; Takane, 2014) represents a component-based SEM alternative (also see, for example, Cho et al., 2020;Cho et al., 2022b;Cho, Lee, Hwang, Sarstedt and Ringle, 2022a;Hwang, Ringle, &amp; Sarstedt, 2021), which also allows to mimic common factor model results via the integrated GSCA approach (IGSCA; Cho et al., 2022c;Hwang et al., 2021, Hwang, Sarstedt, Cho, Choo, &amp; Ringle, 2023).3 This article focuses on the composite-based PLS-SEM method. However, researchers have presented various alternatives to PLS-SEM. For instance, consistent PLS-SEM (PLSc-SEM; Dijkstra, 2010Dijkstra, , 2014; see also Dijkstra &amp; Henseler, 2015b;Dijkstra &amp; Schermelleh-Engel, 2014), its PLSe1/PLS2e extensions (Bentler &amp; Huang, 2014;Huang, 2013), or Yuan, Wen, and Tang's (2020) approach based on Cronbach's α, adjust the parameter estimates to accommodate common factor models. Moreover, the generalized structured component analysis (GSCA; Hwang &amp; Takane, 2004;Hwang &amp; Takane, 2014) represents a component-based SEM alternative (also see, for example, Cho et al., 2020;Cho et al., 2022b;Cho, Lee, Hwang, Sarstedt and Ringle, 2022a;Hwang, Ringle, &amp; Sarstedt, 2021), which also allows to mimic common factor model results via the integrated GSCA approach (IGSCA; Cho et al., 2022c;Hwang et al., 2021, Hwang, Sarstedt, Cho, Choo, &amp; Ringle, 2023).</p>
        <p>P. Guenther et al. measurement model (Davvetas et al., 2020;Hair, Sarstedt, Ringle, &amp; Mena, 2012). Measurement theory determines the choice of indicators and the directionality between the indicators and the constructs in the measurement model from a conceptual perspective (Sarstedt et al., 2016). When estimating the model, regardless of the SEM technique used (e.g., PLS or covariance-based), this generates proxies of the constructs based on the available data of observed indicators in the measurement model and the method-specific mathematical operations (Rigdon, 2012). The proxies resemble, but do not perfectly represent and measure, the unobservable theoretical constructs, which means that a construct proxy cannot be equated with the underlying theoretical construct, as there is a validity gap between them (Rhemtulla et al., 2020;Rigdon, 2016).P. Guenther et al. measurement model (Davvetas et al., 2020;Hair, Sarstedt, Ringle, &amp; Mena, 2012). Measurement theory determines the choice of indicators and the directionality between the indicators and the constructs in the measurement model from a conceptual perspective (Sarstedt et al., 2016). When estimating the model, regardless of the SEM technique used (e.g., PLS or covariance-based), this generates proxies of the constructs based on the available data of observed indicators in the measurement model and the method-specific mathematical operations (Rigdon, 2012). The proxies resemble, but do not perfectly represent and measure, the unobservable theoretical constructs, which means that a construct proxy cannot be equated with the underlying theoretical construct, as there is a validity gap between them (Rhemtulla et al., 2020;Rigdon, 2016).</p>
        <p>In line with the above considerations, we follow the perspective suggested by Sarstedt et al. (2016), who broadly distinguish between the theoretical layer and the layer of statistical computations. On the theoretical layer, researchers determine the constructs, which then become part of their theory and model. They use measurement theory to identify a relevant set of observable indicators to determine the constructs and nature of the relationships between indicators and constructs (e.g., reflective or formative). On the statistical estimations layer, the available data and a method's mathematical operations provide proxies for the constructs. Consequently, we do not attribute terms such as reflective and formative to a specific method and its mathematical operations (e.g., common factor generation when using covariance-based SEM, and composite generation when using PLS-SEM), but to the layer of measurement-theoretical considerations. The layers are intertwined in that SEM methods rely on different entities (i.e., common factors or composites) to statistically approximate the constructs, as specified by the researchers. However, as the underlying data generation process is unknown, there is necessarily a validity gap between these two layers. For example, researchers may operationalize a construct reflectively, but the underlying data generation process, unknown to the researcher, could be well represented by a composite whose indicators covary strongly. Researchers can therefore use different methods (e.g., covariance-based SEM and PLS-SEM) to obtain proxies of theoretically established constructs, for example with a reflective or a formative measurement model.In line with the above considerations, we follow the perspective suggested by Sarstedt et al. (2016), who broadly distinguish between the theoretical layer and the layer of statistical computations. On the theoretical layer, researchers determine the constructs, which then become part of their theory and model. They use measurement theory to identify a relevant set of observable indicators to determine the constructs and nature of the relationships between indicators and constructs (e.g., reflective or formative). On the statistical estimations layer, the available data and a method's mathematical operations provide proxies for the constructs. Consequently, we do not attribute terms such as reflective and formative to a specific method and its mathematical operations (e.g., common factor generation when using covariance-based SEM, and composite generation when using PLS-SEM), but to the layer of measurement-theoretical considerations. The layers are intertwined in that SEM methods rely on different entities (i.e., common factors or composites) to statistically approximate the constructs, as specified by the researchers. However, as the underlying data generation process is unknown, there is necessarily a validity gap between these two layers. For example, researchers may operationalize a construct reflectively, but the underlying data generation process, unknown to the researcher, could be well represented by a composite whose indicators covary strongly. Researchers can therefore use different methods (e.g., covariance-based SEM and PLS-SEM) to obtain proxies of theoretically established constructs, for example with a reflective or a formative measurement model.</p>
        <p>PLS-SEM and covariance-based SEM applications usually differ regarding how they use the observed indicators to create construct proxies (Cho, Sarstedt, &amp; Hwang, 2022a;Rigdon et al., 2017;Sarstedt et al., 2016). Normally, PLS-SEM applications specify a construct's proxy as a composite, that is a weighted linear combination of its indicators. In contrast, covariance-based SEM normally splits the indicators' variance into variance that a proxy's indicators share and residual variance. The former is used to form the construct proxy via a common factor, while the latter is excluded from the model as measurement error (Sarstedt, This research guides current projects by synthesizing the recent literature on researchers' motivation for using the PLS-SEM approach. The choice of PLS-SEM should be based on conceptual considerations regarding the nature of the constructs under investigation and be related to the available data's characteristics (Rhemtulla, van Bork, &amp; Borsboom, 2020;Rigdon, 2016;Sarstedt et al., 2016). Given alternative SEM approaches, such as covariance-based SEM (e.g., Davvetas et al., 2020), sound motivation is important. We offer this guide as a preliminary orientation, recognizing that discussions of these points are still at an early stage.PLS-SEM and covariance-based SEM applications usually differ regarding how they use the observed indicators to create construct proxies (Cho, Sarstedt, &amp; Hwang, 2022a;Rigdon et al., 2017;Sarstedt et al., 2016). Normally, PLS-SEM applications specify a construct's proxy as a composite, that is a weighted linear combination of its indicators. In contrast, covariance-based SEM normally splits the indicators' variance into variance that a proxy's indicators share and residual variance. The former is used to form the construct proxy via a common factor, while the latter is excluded from the model as measurement error (Sarstedt, This research guides current projects by synthesizing the recent literature on researchers' motivation for using the PLS-SEM approach. The choice of PLS-SEM should be based on conceptual considerations regarding the nature of the constructs under investigation and be related to the available data's characteristics (Rhemtulla, van Bork, &amp; Borsboom, 2020;Rigdon, 2016;Sarstedt et al., 2016). Given alternative SEM approaches, such as covariance-based SEM (e.g., Davvetas et al., 2020), sound motivation is important. We offer this guide as a preliminary orientation, recognizing that discussions of these points are still at an early stage.</p>
        <p>We review prior applications in Industrial Marketing Management critically in terms of their implementation of common PLS-SEM estimation and evaluation procedures. We discuss relevant remedies (e.g., tests or appropriate thresholds) for the issues we identified. We also provide up-to-date checklists detailing recommended, optional, and nonrecommended tests and measures, in addition to relevant cut-off values and thresholds. 4. Guide contemporary research on advanced PLS-SEM procedures Many studies do not use advanced criteria and analytic methods. Consequently, many researchers miss the substantive opportunity to expand their analyses' quality and scope. We address the advanced methods' underutilization in business marketing research by offering our Web Appendix A, which provides extensive guidance: For each advanced method, it explains the method's purpose and procedure, as well as key application considerations. Ringle, &amp; Hair, 2022). Because a composite specification does not remove indicators' residual variance, some covariance-based SEM proponents who, for instance, assume common factor models to obtain results, criticized the PLS-SEM approach for being imprecise and biased. This criticism even led to simulation studies and journal editorials rejecting the approach (e.g., Rönkkö et al., 2016;Rönkkö &amp; Evermann, 2013). Nevertheless, several publications strongly countered this perspective and similar PLS-SEM-related criticism (e.g., Henseler et al., 2014;Petter, 2018;Petter &amp; Hadavi, 2021;Russo &amp; Stol, 2022;Sarstedt et al., 2016;Sharma, Liengaard, Sarstedt, Hair, &amp; Ringle, 2022). In essence, critics assume that reflectively-specified constructs can only be represented by common factors, without acknowledging that the underlying data generation process could better be represented by a composite model (Sarstedt et al., 2016).We review prior applications in Industrial Marketing Management critically in terms of their implementation of common PLS-SEM estimation and evaluation procedures. We discuss relevant remedies (e.g., tests or appropriate thresholds) for the issues we identified. We also provide up-to-date checklists detailing recommended, optional, and nonrecommended tests and measures, in addition to relevant cut-off values and thresholds. 4. Guide contemporary research on advanced PLS-SEM procedures Many studies do not use advanced criteria and analytic methods. Consequently, many researchers miss the substantive opportunity to expand their analyses' quality and scope. We address the advanced methods' underutilization in business marketing research by offering our Web Appendix A, which provides extensive guidance: For each advanced method, it explains the method's purpose and procedure, as well as key application considerations. Ringle, &amp; Hair, 2022). Because a composite specification does not remove indicators' residual variance, some covariance-based SEM proponents who, for instance, assume common factor models to obtain results, criticized the PLS-SEM approach for being imprecise and biased. This criticism even led to simulation studies and journal editorials rejecting the approach (e.g., Rönkkö et al., 2016;Rönkkö &amp; Evermann, 2013). Nevertheless, several publications strongly countered this perspective and similar PLS-SEM-related criticism (e.g., Henseler et al., 2014;Petter, 2018;Petter &amp; Hadavi, 2021;Russo &amp; Stol, 2022;Sarstedt et al., 2016;Sharma, Liengaard, Sarstedt, Hair, &amp; Ringle, 2022). In essence, critics assume that reflectively-specified constructs can only be represented by common factors, without acknowledging that the underlying data generation process could better be represented by a composite model (Sarstedt et al., 2016).</p>
        <p>In marketing and business applications, data might not strictly follow the common factor model logic on which covariance-based SEM is usually based (Rhemtulla et al., 2020;Rigdon, 2016;Sarstedt et al., 2016). For instance, if an indicator's residual variance has a certain meaning for the theoretical construct and is therefore not actually a measurement error, estimates based on a common factor model can be biased, while a composite model would provide more accurate results, even when the construct is specified reflectively (Rhemtulla et al., 2020;Sarstedt et al., 2016). Indicators' residual variance may have meaning if the theoretical construct is not strictly unidimensional, such as when an indicator captures an aspect of a construct (e.g., satisfaction with a provider's services as part of the satisfaction with the provider). Since the wording of survey items measuring the same construct inevitably varies, researchers can never completely rule out small violations of strict unidimensionality. Indicators' residual variance may also have meaning when indicators interact somewhat when forming the construct (e.g., satisfaction might be particularly high if satisfaction with the services as well as the staff is high). There are other scenarios that also lend meaning to indicators' residual variance (Rhemtulla et al., 2020). If this is the case, a composite model should provide more appropriate results because it fully accounts for the variance in indicators, meaning that the composite construct proxies, and therefore the broader model, capture the meaning of the indicators' residual variance. Keep in mind that the proxy is only an approximation, considering that a range of different proxy scores can be generated that are all consistent with the model (Hair &amp; Sarstedt, 2019;Rigdon, Becker, &amp; Sarstedt, 2019). This creates uncertainty regarding whether the construct proxy is equivalent to the theoretical construct (see Rigdon et al., 2019 andRigdon, Sarstedt, &amp;Moisescu, 2023 on this uncertainty concept derived from metrology research).In marketing and business applications, data might not strictly follow the common factor model logic on which covariance-based SEM is usually based (Rhemtulla et al., 2020;Rigdon, 2016;Sarstedt et al., 2016). For instance, if an indicator's residual variance has a certain meaning for the theoretical construct and is therefore not actually a measurement error, estimates based on a common factor model can be biased, while a composite model would provide more accurate results, even when the construct is specified reflectively (Rhemtulla et al., 2020;Sarstedt et al., 2016). Indicators' residual variance may have meaning if the theoretical construct is not strictly unidimensional, such as when an indicator captures an aspect of a construct (e.g., satisfaction with a provider's services as part of the satisfaction with the provider). Since the wording of survey items measuring the same construct inevitably varies, researchers can never completely rule out small violations of strict unidimensionality. Indicators' residual variance may also have meaning when indicators interact somewhat when forming the construct (e.g., satisfaction might be particularly high if satisfaction with the services as well as the staff is high). There are other scenarios that also lend meaning to indicators' residual variance (Rhemtulla et al., 2020). If this is the case, a composite model should provide more appropriate results because it fully accounts for the variance in indicators, meaning that the composite construct proxies, and therefore the broader model, capture the meaning of the indicators' residual variance. Keep in mind that the proxy is only an approximation, considering that a range of different proxy scores can be generated that are all consistent with the model (Hair &amp; Sarstedt, 2019;Rigdon, Becker, &amp; Sarstedt, 2019). This creates uncertainty regarding whether the construct proxy is equivalent to the theoretical construct (see Rigdon et al., 2019 andRigdon, Sarstedt, &amp;Moisescu, 2023 on this uncertainty concept derived from metrology research).</p>
        <p>Simulation studies (e.g., Cho, Sarstedt, &amp; Hwang, 2022b;Rhemtulla et al., 2020;Sarstedt et al., 2016) comparing the common factor model (typically used in covariance-based SEM) with the composite model (typically used in PLS-SEM) in respect of different data scenarios show that previous studies that dismissed PLS-SEM (e.g., Goodhue, Lewis, &amp; Thompson, 2012; see also Marcoulides, Chin, &amp; Saunders, 2012) underestimated the method's potential strengths. First, prior simulation studies (e.g., Hwang, Malhotra, Kim, Tomiuk, &amp; Hong, 2010;Reinartz, Haenlein, &amp; Henseler, 2009) usually used a population model in line with the common factor specifications to compare the common factor model estimations (that covariance-based SEM provided) with the composite model estimations (that PLS-SEM provided). Due to this study design, covariance-based SEM appeared comparatively advantageous, while the PLS-SEM estimation results showed a discrepancy that some researchers call a PLS-SEM bias (e.g., Goodhue et al., 2012). This discrepancy is however only an outcome of comparing apples with oranges (Marcoulides et al., 2012). Specifically, Cho, Sarstedt, and Hwang (2022b) and Sarstedt et al. (2016) demonstrated that common factor model estimations (e.g., by using covariance-based SEM) have advantages when used with common factor data in simulation studies, while composite model estimations (e.g., by using PLS-SEM) have advantages when used with simulated composite data. Second, covariance-based SEM estimates are relatively sensitive to changes in the data characteristics, while PLS-SEM estimates obtained by using data that deviates from composite requirements are comparably less variable and sensitive. Given these results, and because the true underlying data structure is only known in simulation studies and unknown in research applications, recent simulation studies indicate that a PLS-SEM-obtained composite model estimation is a sound choice to ensure the validity of applied researchers' results (Cho, Sarstedt, &amp; Hwang, 2022b;Sarstedt et al., 2016).Simulation studies (e.g., Cho, Sarstedt, &amp; Hwang, 2022b;Rhemtulla et al., 2020;Sarstedt et al., 2016) comparing the common factor model (typically used in covariance-based SEM) with the composite model (typically used in PLS-SEM) in respect of different data scenarios show that previous studies that dismissed PLS-SEM (e.g., Goodhue, Lewis, &amp; Thompson, 2012; see also Marcoulides, Chin, &amp; Saunders, 2012) underestimated the method's potential strengths. First, prior simulation studies (e.g., Hwang, Malhotra, Kim, Tomiuk, &amp; Hong, 2010;Reinartz, Haenlein, &amp; Henseler, 2009) usually used a population model in line with the common factor specifications to compare the common factor model estimations (that covariance-based SEM provided) with the composite model estimations (that PLS-SEM provided). Due to this study design, covariance-based SEM appeared comparatively advantageous, while the PLS-SEM estimation results showed a discrepancy that some researchers call a PLS-SEM bias (e.g., Goodhue et al., 2012). This discrepancy is however only an outcome of comparing apples with oranges (Marcoulides et al., 2012). Specifically, Cho, Sarstedt, and Hwang (2022b) and Sarstedt et al. (2016) demonstrated that common factor model estimations (e.g., by using covariance-based SEM) have advantages when used with common factor data in simulation studies, while composite model estimations (e.g., by using PLS-SEM) have advantages when used with simulated composite data. Second, covariance-based SEM estimates are relatively sensitive to changes in the data characteristics, while PLS-SEM estimates obtained by using data that deviates from composite requirements are comparably less variable and sensitive. Given these results, and because the true underlying data structure is only known in simulation studies and unknown in research applications, recent simulation studies indicate that a PLS-SEM-obtained composite model estimation is a sound choice to ensure the validity of applied researchers' results (Cho, Sarstedt, &amp; Hwang, 2022b;Sarstedt et al., 2016).</p>
        <p>Against this background, researchers can motivate a composite model estimation by using PLS-SEM to obtain proxies for the theoretically established constructs by considering the following two questions (also see Rigdon et al., 2017):Against this background, researchers can motivate a composite model estimation by using PLS-SEM to obtain proxies for the theoretically established constructs by considering the following two questions (also see Rigdon et al., 2017):</p>
        <p>• Could the indicator residual variances have meaning for the focal construct or the additional constructs in the model? If it cannot be ruled out that the residual variances might have a specific meaning, this could justify using a PLS-SEM approach with a standard composite model implementation, or using covariancebased SEM with composite variables (Grace &amp; Bollen, 2008), since common factor results are highly sensitive to residual variance that is not a measurement error (Rhemtulla et al., 2020;Sarstedt et al., 2016). In the light of the above discussion, meaningful residual variance may be present if the proxied construct is not strictly unidimensional, and if the indicators interact partially when forming the construct. Similarly, from an empirical perspective, researchers can motivate their use of PLS-SEM with a composite model based on moderate observed factor loadings. For instance, a 0.50 factor loading means that a common factor model would use only 25% of an indicator's variance to form the construct proxy. This raises the question whether there is sufficient certainty to assume that 75% of the indicator variance is a measurement error with no further meaning.• Could the indicator residual variances have meaning for the focal construct or the additional constructs in the model? If it cannot be ruled out that the residual variances might have a specific meaning, this could justify using a PLS-SEM approach with a standard composite model implementation, or using covariancebased SEM with composite variables (Grace &amp; Bollen, 2008), since common factor results are highly sensitive to residual variance that is not a measurement error (Rhemtulla et al., 2020;Sarstedt et al., 2016). In the light of the above discussion, meaningful residual variance may be present if the proxied construct is not strictly unidimensional, and if the indicators interact partially when forming the construct. Similarly, from an empirical perspective, researchers can motivate their use of PLS-SEM with a composite model based on moderate observed factor loadings. For instance, a 0.50 factor loading means that a common factor model would use only 25% of an indicator's variance to form the construct proxy. This raises the question whether there is sufficient certainty to assume that 75% of the indicator variance is a measurement error with no further meaning.</p>
        <p>• Is the measurement error unlikely to be large?• Is the measurement error unlikely to be large?</p>
        <p>In PLS-SEM estimates based on a composite model, bias is a function of the measurement error size, which might not be very large when researchers use established and refined construct measures (Sarstedt et al., 2016). In addition, PLS-SEM's weighting procedure, which is based on correlations, to some extent reduces the measurement error's impact. This is because by definition, an indicator's (orthogonal) measurement error limits the amount of correlation that this indicator can achieve with the other indicators. The resulting smaller weight of indicators with a larger measurement error attenuates the measurement error's impact on the construct proxy (Rigdon, 2016). Additionally, even without attenuation via weighting, the impact of indicators' measurement error on the construct proxy is mitigated from a statistical perspective. This is because the proxy's variance is the sum of its indicators' variances (which comprise measurement error), plus twice the indicators' covariances (which do not contain measurement error), all of which give substantially greater weight to that part of the indicators' variance that is free from measurement error (Rigdon, 2016).In PLS-SEM estimates based on a composite model, bias is a function of the measurement error size, which might not be very large when researchers use established and refined construct measures (Sarstedt et al., 2016). In addition, PLS-SEM's weighting procedure, which is based on correlations, to some extent reduces the measurement error's impact. This is because by definition, an indicator's (orthogonal) measurement error limits the amount of correlation that this indicator can achieve with the other indicators. The resulting smaller weight of indicators with a larger measurement error attenuates the measurement error's impact on the construct proxy (Rigdon, 2016). Additionally, even without attenuation via weighting, the impact of indicators' measurement error on the construct proxy is mitigated from a statistical perspective. This is because the proxy's variance is the sum of its indicators' variances (which comprise measurement error), plus twice the indicators' covariances (which do not contain measurement error), all of which give substantially greater weight to that part of the indicators' variance that is free from measurement error (Rigdon, 2016).</p>
        <p>In addition to these deliberations and according to the results of, for instance, Cho, Sarstedt, and Hwang (2022b) and Sarstedt et al. (2016), researchers can consider comparing the common factor model estimation results (e.g., by using covariance-based SEM) and composite model estimation results (e.g., by using PLS-SEM). While PLS-SEM estimates common factor models with data that stem from a common factor data population relatively precisely (e.g., Reinartz et al., 2009), covariancebased SEM tends to cause a large bias when estimating composite models with data that stem from a composite data population. Sarstedt et al. (2016) demonstrated that model estimation by means of PLS-SEM erroneously fitted to data following a common factor structure, causes a bias only one eleventh of that which a model estimation by means of covariance-based SEM erroneously fitted to data following a composite structure causes. 4 Furthermore, the covariance-based SEM approach's non-convergence might indicate that a covariance-based SEM with a common factor model is fitted to data that follows a composite structure. Specifically, in respect of a standard model estimation by means of covariance-based SEM, Sarstedt et al. (2016) reported a 50% or higher chance of non-convergence in 32 of the 40 assessed composite data scenarios (see their Table 3).In addition to these deliberations and according to the results of, for instance, Cho, Sarstedt, and Hwang (2022b) and Sarstedt et al. (2016), researchers can consider comparing the common factor model estimation results (e.g., by using covariance-based SEM) and composite model estimation results (e.g., by using PLS-SEM). While PLS-SEM estimates common factor models with data that stem from a common factor data population relatively precisely (e.g., Reinartz et al., 2009), covariancebased SEM tends to cause a large bias when estimating composite models with data that stem from a composite data population. Sarstedt et al. (2016) demonstrated that model estimation by means of PLS-SEM erroneously fitted to data following a common factor structure, causes a bias only one eleventh of that which a model estimation by means of covariance-based SEM erroneously fitted to data following a composite structure causes. 4 Furthermore, the covariance-based SEM approach's non-convergence might indicate that a covariance-based SEM with a common factor model is fitted to data that follows a composite structure. Specifically, in respect of a standard model estimation by means of covariance-based SEM, Sarstedt et al. (2016) reported a 50% or higher chance of non-convergence in 32 of the 40 assessed composite data scenarios (see their Table 3).</p>
        <p>Business marketing researchers should use the discussed guidance for their next PLS-SEM application, but should also pay attention to recent developments in this area. Specifically, the discussion of and research on how to obtain proxies (i.e., common factor versus composite model estimations) for the theoretical constructs under consideration (e. g., reflective or formative variables) and for a given dataset is an important subject of future research. This research will need to determine how to minimize the validity gap between the statistically obtained proxies and the theoretical constructs.Business marketing researchers should use the discussed guidance for their next PLS-SEM application, but should also pay attention to recent developments in this area. Specifically, the discussion of and research on how to obtain proxies (i.e., common factor versus composite model estimations) for the theoretical constructs under consideration (e. g., reflective or formative variables) and for a given dataset is an important subject of future research. This research will need to determine how to minimize the validity gap between the statistically obtained proxies and the theoretical constructs.</p>
        <p>Our review of PLS-SEM applications in IMM reveals that no study took the considerations discussed above into account when motivating their use of PLS-SEM or, more specifically, their composite model. 5Future PLS-SEM applications may take these considerations into account. Instead, authors provided the rationales that Table 2 lists as secondary motivators.Our review of PLS-SEM applications in IMM reveals that no study took the considerations discussed above into account when motivating their use of PLS-SEM or, more specifically, their composite model. 5Future PLS-SEM applications may take these considerations into account. Instead, authors provided the rationales that Table 2 lists as secondary motivators.</p>
        <p>The author-provided rationales for using PLS-SEM generally demonstrate the aspects that are particularly relevant for business marketing researchers (e.g., estimation with restricted samples) and are related to common modeling issues, such as determining the required minimum sample size, handling a non-normal data distribution, assessing formative and reflective measurement, and demonstrating predictive power. These modeling issues are linked to PLS-SEM analyses, thresholds, and tests, which are not always provided or are used improperly. The following sections discuss these modeling issues and summarize in comprehensive checklists the best-practice recommendations for each rationale as provided in recent key PLS-SEM literature. We discuss the author-provided rationales and related modeling issues in the order shown in Table 2 and also use recent literature to highlight certain shortcomings and limitations. 6 In respect of the discussions, we generally refer to the results of the entire sample of reviewed PLS-SEM applications. However, we split the overall sample into three distinct time periods in the overview tables, which reveals the trends over time (n before 2012 = 37, n 2012-2016 = 41, and n 2017-2020 = 62).The author-provided rationales for using PLS-SEM generally demonstrate the aspects that are particularly relevant for business marketing researchers (e.g., estimation with restricted samples) and are related to common modeling issues, such as determining the required minimum sample size, handling a non-normal data distribution, assessing formative and reflective measurement, and demonstrating predictive power. These modeling issues are linked to PLS-SEM analyses, thresholds, and tests, which are not always provided or are used improperly. The following sections discuss these modeling issues and summarize in comprehensive checklists the best-practice recommendations for each rationale as provided in recent key PLS-SEM literature. We discuss the author-provided rationales and related modeling issues in the order shown in Table 2 and also use recent literature to highlight certain shortcomings and limitations. 6 In respect of the discussions, we generally refer to the results of the entire sample of reviewed PLS-SEM applications. However, we split the overall sample into three distinct time periods in the overview tables, which reveals the trends over time (n before 2012 = 37, n 2012-2016 = 41, and n 2017-2020 = 62).</p>
        <p>Almost two-thirds of the reviewed studies motivate their use of PLS-SEM by arguing that the technique can handle relatively small sample sizes. This argument is popular in business marketing research contexts, because the underlying study populations used to research interesting phenomena, such as firms' new technology use, might be naturally limited, as only a few firms use the relevant technology. Similarly, compared to consumers, employee and manager informants are more difficult to recruit, as they are less numerous and have limited time available, while confidentiality and anonymity concerns as well as company rules and policies may constrain them (Greer, Chuchinprakarn, &amp; Seshadri, 2000). Although PLS-SEM's limited information estimator allows it to produce estimates for small samples for which covariance-based SEM fails to converge (Chin &amp; Newsted, 1999), the argument needs to be treated carefully. If a model is simply estimable, this does not mean that it produces good estimates. In PLS-SEM, the parameter estimates' precision is inversely related to the number of observations used for an estimation (Marcoulides &amp; Saunders, 2006). Consequently, a smaller sample tends to result in larger estimation errors and less statistical power to detect existing effects in the population (type II error). Our review of IMM studies reveals that sample sizes can be as small as 24 observations, which is problematic. Previous research showed that path coefficients with a strength of 0.20 require samples of 150-200 observations to be more or less precisely determined (Chin &amp; Newsted, 1999). Reinartz et al. (2009), however, demonstrated that PLS-SEM can achieve sufficient statistical power with only 100 observations.Almost two-thirds of the reviewed studies motivate their use of PLS-SEM by arguing that the technique can handle relatively small sample sizes. This argument is popular in business marketing research contexts, because the underlying study populations used to research interesting phenomena, such as firms' new technology use, might be naturally limited, as only a few firms use the relevant technology. Similarly, compared to consumers, employee and manager informants are more difficult to recruit, as they are less numerous and have limited time available, while confidentiality and anonymity concerns as well as company rules and policies may constrain them (Greer, Chuchinprakarn, &amp; Seshadri, 2000). Although PLS-SEM's limited information estimator allows it to produce estimates for small samples for which covariance-based SEM fails to converge (Chin &amp; Newsted, 1999), the argument needs to be treated carefully. If a model is simply estimable, this does not mean that it produces good estimates. In PLS-SEM, the parameter estimates' precision is inversely related to the number of observations used for an estimation (Marcoulides &amp; Saunders, 2006). Consequently, a smaller sample tends to result in larger estimation errors and less statistical power to detect existing effects in the population (type II error). Our review of IMM studies reveals that sample sizes can be as small as 24 observations, which is problematic. Previous research showed that path coefficients with a strength of 0.20 require samples of 150-200 observations to be more or less precisely determined (Chin &amp; Newsted, 1999). Reinartz et al. (2009), however, demonstrated that PLS-SEM can achieve sufficient statistical power with only 100 observations.</p>
        <p>Nevertheless, each individual research project should assess the number of observations required to avoid type II errors, as the eventually achieved statistical power depends on various factors. In this regard, a common rule of thumb suggests that the minimum required sample size should be ten times the maximum number of paths aiming at any one construct in the measurement and structural model (Barclay, Higgins, &amp; Thompson, 1995). However, estimates based on this rule are likely to be inaccurate, because researchers should consider additional aspects, such as the anticipated effect sizes, as well as the number of indicators and reliabilities (Aguirre-Urreta &amp; Rönkkö, 2015; Goodhue et al., 2012). To this end, more suitable approaches were developed to determine sample size, including the Monte Carlo-based power analysis for PLS-SEM, the inverse square root method, and the gammaexponential method (Aguirre-Urreta &amp; Rönkkö, 2015; Kock &amp; Hadaya, 2018). Our review reveals that business marketing research has been slow to adopt these suggestions, even in the most recent reviewed studies. Additionally, and more fundamentally, only a few studies (&lt; 13.9%) have determined the required sample size. In our application illustrations section in Web Appendix B, we address this significant gap by illustratively showing a recent approach, the inverse square root method, which is accurate and simple to use (Kock &amp; Hadaya, 2018). Moreover, for samples that are small but sufficiently large to estimate the PLS-SEM path model adequately, researchers could use a weighting variable to ensure the sample's representativeness based on relevant characteristics. In this scenario, the weighted PLS-SEM algorithm (Becker &amp; Ismail, 2016;Cheah, Nitzl, Roldán, Cepeda-Carrion, &amp; Gudergan, 2021) provides model estimation results that align the sample and population by means of the sample's weighting vector. However, our review of studies shows that business marketing researchers seem to be largely unaware of this possibility and therefore currently miss out on an appropriate approach to deal with small samples.Nevertheless, each individual research project should assess the number of observations required to avoid type II errors, as the eventually achieved statistical power depends on various factors. In this regard, a common rule of thumb suggests that the minimum required sample size should be ten times the maximum number of paths aiming at any one construct in the measurement and structural model (Barclay, Higgins, &amp; Thompson, 1995). However, estimates based on this rule are likely to be inaccurate, because researchers should consider additional aspects, such as the anticipated effect sizes, as well as the number of indicators and reliabilities (Aguirre-Urreta &amp; Rönkkö, 2015; Goodhue et al., 2012). To this end, more suitable approaches were developed to determine sample size, including the Monte Carlo-based power analysis for PLS-SEM, the inverse square root method, and the gammaexponential method (Aguirre-Urreta &amp; Rönkkö, 2015; Kock &amp; Hadaya, 2018). Our review reveals that business marketing research has been slow to adopt these suggestions, even in the most recent reviewed studies. Additionally, and more fundamentally, only a few studies (&lt; 13.9%) have determined the required sample size. In our application illustrations section in Web Appendix B, we address this significant gap by illustratively showing a recent approach, the inverse square root method, which is accurate and simple to use (Kock &amp; Hadaya, 2018). Moreover, for samples that are small but sufficiently large to estimate the PLS-SEM path model adequately, researchers could use a weighting variable to ensure the sample's representativeness based on relevant characteristics. In this scenario, the weighted PLS-SEM algorithm (Becker &amp; Ismail, 2016;Cheah, Nitzl, Roldán, Cepeda-Carrion, &amp; Gudergan, 2021) provides model estimation results that align the sample and population by means of the sample's weighting vector. However, our review of studies shows that business marketing researchers seem to be largely unaware of this possibility and therefore currently miss out on an appropriate approach to deal with small samples.</p>
        <p>As small sample sizes are a common problem, knowing how to treat missing values is both a critical issue and an opportunity. The papers we read (Table 3) frequently used listwise deletion (i.e., completely discarding a response with missing values). However, the broader SEM literature has noted increased standard errors and type II errors as possible problems associated with this approach due to a reduced number of observations (Allison, 2003). Similar issues arise regarding pairwise deletion, which carries the added risk of distorting parameters and standard errors (Allison, 2003;Kock, 2018). Nevertheless, there is as yet no research that specifically examines pairwise deletion's impact on PLS-SEM estimates. Further and importantly, our review reveals that imputation techniques, which could help preserve sample size, are underutilized (Cordeiro, Machás, &amp; Neves, 2010;Kock, 2018;Roth, 1994). A recent simulation study shows that imputation through multiple regression or mean replacement produces the least biased path coefficient estimates, while mean replacement and hierarchical regression imputation methods generate the least biased loading estimates (Kock, 2018). Although more work is needed that takes additional imputation techniques (e.g., median replacement and expectationmaximum algorithm) into account, preliminary findings suggest that research mainly concerned with the structural model outcomes (e.g., path coefficients' hypothesis tests) should use multiple regression imputation. In contrast, research mainly focused on the measurement model or on both the measurement and structural models should use mean replacement, while deletion approaches should be least preferred.As small sample sizes are a common problem, knowing how to treat missing values is both a critical issue and an opportunity. The papers we read (Table 3) frequently used listwise deletion (i.e., completely discarding a response with missing values). However, the broader SEM literature has noted increased standard errors and type II errors as possible problems associated with this approach due to a reduced number of observations (Allison, 2003). Similar issues arise regarding pairwise deletion, which carries the added risk of distorting parameters and standard errors (Allison, 2003;Kock, 2018). Nevertheless, there is as yet no research that specifically examines pairwise deletion's impact on PLS-SEM estimates. Further and importantly, our review reveals that imputation techniques, which could help preserve sample size, are underutilized (Cordeiro, Machás, &amp; Neves, 2010;Kock, 2018;Roth, 1994). A recent simulation study shows that imputation through multiple regression or mean replacement produces the least biased path coefficient estimates, while mean replacement and hierarchical regression imputation methods generate the least biased loading estimates (Kock, 2018). Although more work is needed that takes additional imputation techniques (e.g., median replacement and expectationmaximum algorithm) into account, preliminary findings suggest that research mainly concerned with the structural model outcomes (e.g., path coefficients' hypothesis tests) should use multiple regression imputation. In contrast, research mainly focused on the measurement model or on both the measurement and structural models should use mean replacement, while deletion approaches should be least preferred.</p>
        <p>The second most frequent rationale researchers mention for using a PLS-SEM approach is the non-normality of the data and, specifically, that the approach does not impose strong distributional assumptions on the data (Hair, Risher, Sarstedt, &amp; Ringle, 2019). For example, in the ACSI model (Fornell et al., 1996;Fornell et al., 2020, Chapter 5), selfreports of customer satisfaction are an indicator that usually has a negatively skewed distribution (Peterson &amp; Wilson, 1992). In business marketing research, commonly used variables (e.g., performance outcomes) might not follow a normal distribution, but can instead include many extreme values which result in fat tails (i.e., large skewness or kurtosis). Many industries, for instance, include a substantial number of firms that perform at the extreme ends compared to their peers (i.e., they overperform or underperform), exceeding the numbers expected in normally distributed data (Bottazzi &amp; Secchi, 2006). However, certain limits concerning the maximum amount of non-normality apply, which we discuss below.The second most frequent rationale researchers mention for using a PLS-SEM approach is the non-normality of the data and, specifically, that the approach does not impose strong distributional assumptions on the data (Hair, Risher, Sarstedt, &amp; Ringle, 2019). For example, in the ACSI model (Fornell et al., 1996;Fornell et al., 2020, Chapter 5), selfreports of customer satisfaction are an indicator that usually has a negatively skewed distribution (Peterson &amp; Wilson, 1992). In business marketing research, commonly used variables (e.g., performance outcomes) might not follow a normal distribution, but can instead include many extreme values which result in fat tails (i.e., large skewness or kurtosis). Many industries, for instance, include a substantial number of firms that perform at the extreme ends compared to their peers (i.e., they overperform or underperform), exceeding the numbers expected in normally distributed data (Bottazzi &amp; Secchi, 2006). However, certain limits concerning the maximum amount of non-normality apply, which we discuss below.</p>
        <p>Simulation studies generally confirm PLS-SEM's ability to suitably estimate models with non-normal data (Cassel, Hackl, &amp; Westlund, 1999;Sarstedt et al., 2016). Nevertheless, it is important to analyze nonnormality, including the data's skewness and kurtosis (&lt; 2% of the reviewed studies did this). In extreme cases, estimation results might be affected if the bootstrapping distributions are highly peaked or skewed. A bias-corrected and accelerated (BCa) bootstrapping routine could offer some improvement, although it is not a remedy (Efron, 1987). In general, percentile-based bootstrapping is preferred to bias-corrected bootstrapping, because the latter results in too narrow confidence intervals and overly liberal significance results, while the former tends to be overly conservative (Aguirre-Urreta &amp; Rönkkö, 2018). Outliers could be one reason for non-normality in the data; consequently, researchers should discuss their presence and treatment. In the reviewed studies, outliers were predominantly treated by deleting observations (Table 4), although this could introduce other problems (e.g., increased type II errors). Replacement (e.g., winsorizing) is a viable option (Beaumont &amp; Rivest, 2009), especially with a small sample size. Alternatively, researchers could consider using PLS-SEM's robust extension (e.g., Schamberger, Schuberth, Henseler, &amp; Dijkstra, 2020).Simulation studies generally confirm PLS-SEM's ability to suitably estimate models with non-normal data (Cassel, Hackl, &amp; Westlund, 1999;Sarstedt et al., 2016). Nevertheless, it is important to analyze nonnormality, including the data's skewness and kurtosis (&lt; 2% of the reviewed studies did this). In extreme cases, estimation results might be affected if the bootstrapping distributions are highly peaked or skewed. A bias-corrected and accelerated (BCa) bootstrapping routine could offer some improvement, although it is not a remedy (Efron, 1987). In general, percentile-based bootstrapping is preferred to bias-corrected bootstrapping, because the latter results in too narrow confidence intervals and overly liberal significance results, while the former tends to be overly conservative (Aguirre-Urreta &amp; Rönkkö, 2018). Outliers could be one reason for non-normality in the data; consequently, researchers should discuss their presence and treatment. In the reviewed studies, outliers were predominantly treated by deleting observations (Table 4), although this could introduce other problems (e.g., increased type II errors). Replacement (e.g., winsorizing) is a viable option (Beaumont &amp; Rivest, 2009), especially with a small sample size. Alternatively, researchers could consider using PLS-SEM's robust extension (e.g., Schamberger, Schuberth, Henseler, &amp; Dijkstra, 2020).</p>
        <p>Despite being the third most popular rationale regarding motivating the PLS-SEM approach, recent work suggests that it has a logic flaw (Rigdon, 2016). Earlier, we discussed the importance of motivating the use of a PLS-SEM approach on the basis of data characteristics. In a fully exploratory context, researchers would not know whether the assumed theoretical constructs exist and whether they could validly proxy them via observed indicators, which raise questions about the validity of using a PLS-SEM approach, or any other SEM approach for that matter (Rigdon, 2016). Recent work suggests a refined rationale: exploring established theories' complex theoretical extensions (Hair, Risher, et al., 2019).Despite being the third most popular rationale regarding motivating the PLS-SEM approach, recent work suggests that it has a logic flaw (Rigdon, 2016). Earlier, we discussed the importance of motivating the use of a PLS-SEM approach on the basis of data characteristics. In a fully exploratory context, researchers would not know whether the assumed theoretical constructs exist and whether they could validly proxy them via observed indicators, which raise questions about the validity of using a PLS-SEM approach, or any other SEM approach for that matter (Rigdon, 2016). Recent work suggests a refined rationale: exploring established theories' complex theoretical extensions (Hair, Risher, et al., 2019).</p>
        <p>PLS-SEM uses partial least squares estimation, which only estimates a subset of model parameters at a time. PLS-SEM can therefore handle much larger and complex models with many constructs and indicators (Chin, 1998). Using PLS-SEM to estimate complex models is therefore a perfectly reasonable justification, which Wold (1982) already pointed out when developing the PLS-SEM method. Nevertheless, as a (secondary) rationale for using PLS-SEM, a complex structural model is relatively underutilized, despite its merit for business marketing contexts that require complex models for in-depth studies. Specifically, research in this field often shows increased model complexity due to researchers' interest in the interactions between multiple organizations or functional units comprising several groups or individuals with diverse goals, motives, and behaviors (Möller, 2013). Our illustration of sample size requirements (Web Appendix B) and our discussion of advanced modeling issues (Web Appendix A) are particularly relevant in respect of complex models.PLS-SEM uses partial least squares estimation, which only estimates a subset of model parameters at a time. PLS-SEM can therefore handle much larger and complex models with many constructs and indicators (Chin, 1998). Using PLS-SEM to estimate complex models is therefore a perfectly reasonable justification, which Wold (1982) already pointed out when developing the PLS-SEM method. Nevertheless, as a (secondary) rationale for using PLS-SEM, a complex structural model is relatively underutilized, despite its merit for business marketing contexts that require complex models for in-depth studies. Specifically, research in this field often shows increased model complexity due to researchers' interest in the interactions between multiple organizations or functional units comprising several groups or individuals with diverse goals, motives, and behaviors (Möller, 2013). Our illustration of sample size requirements (Web Appendix B) and our discussion of advanced modeling issues (Web Appendix A) are particularly relevant in respect of complex models.</p>
        <p>Theoretically established models can include reflectively and formatively measured constructs (e.g., Sarstedt et al., 2016). In respect of reflectively measured constructs, researchers assume a relationship from the theoretical construct to the indicators in its measurement model (e.g., the indicators reflect their construct). In contrast, in respect of formatively measured constructs, researchers assume that the indicators in the measurement model have a relationship to their construct (e.g., the indicators form the construct). Researchers' decision regarding how to establish constructs and which items to use should be based on measurement-theoretical considerations. However, data and statistical methods only provide proxies of such theoretically assumed constructs. There is a validity gap between the theoretically established constructs and their estimated proxies. The validity gap results from estimating construct proxies using a specific dataset that is never perfect and a statistical method that is also never perfect due to its requirements and limitations (also see Rigdon, 2012Rigdon, , 2014;;Sarstedt et al., 2016;Sarstedt, Ringle, Henseler, &amp; Hair, 2014). In addition to theoretically conceptualizing and justifying a construct's measurement, researchers should decide how to estimate the construct proxies by means of the method and data used.Theoretically established models can include reflectively and formatively measured constructs (e.g., Sarstedt et al., 2016). In respect of reflectively measured constructs, researchers assume a relationship from the theoretical construct to the indicators in its measurement model (e.g., the indicators reflect their construct). In contrast, in respect of formatively measured constructs, researchers assume that the indicators in the measurement model have a relationship to their construct (e.g., the indicators form the construct). Researchers' decision regarding how to establish constructs and which items to use should be based on measurement-theoretical considerations. However, data and statistical methods only provide proxies of such theoretically assumed constructs. There is a validity gap between the theoretically established constructs and their estimated proxies. The validity gap results from estimating construct proxies using a specific dataset that is never perfect and a statistical method that is also never perfect due to its requirements and limitations (also see Rigdon, 2012Rigdon, , 2014;;Sarstedt et al., 2016;Sarstedt, Ringle, Henseler, &amp; Hair, 2014). In addition to theoretically conceptualizing and justifying a construct's measurement, researchers should decide how to estimate the construct proxies by means of the method and data used.</p>
        <p>Covariance-based SEM can accommodate constructs with formative measurement models by using causal-formative indicators (Bollen &amp; Diamantopoulos, 2017), although this requires setting specific model constraints for identification purposes (Bollen &amp; Davis, 2009;Diamantopoulos &amp; Riefler, 2011). Since PLS-SEM does not have comparable modeling requirements due to the use of composite indicators, the inclusion of constructs with a formative measurement in models might be a valid (secondary) reason for using the method. To statically obtain proxies of reflectively measured constructs, covariance-based SEM uses common factor model estimations while PLS-SEM employs composite model estimations. More specifically, in PLS-SEM, researchers usually use correlation weights (Mode A) to obtain proxies for reflectively measured constructs, and regression weights (Mode B) for formatively measured constructs (e.g., Chin, 1998;Tenenhaus et al., 2005) First, for formatively measured constructs, the literature recommends assessing convergent validity as well as indicator collinearity, relevance, and significance (Diamantopoulos &amp; Winklhofer, 2001;Hair, Risher, et al., 2019). Researchers establish the convergent validity by undertaking a redundancy analysis (i.e., by assessing how the construct's formative measurement correlates with an alternative measurement) for which they can use a single-item measure that captures the construct's essence, and which researchers must add proactively to their questionnaires (Cheah, Sarstedt, Ringle, Ramayah, &amp; Ting, 2018). To establish convergent validity, the correlation between the two constructs should have a value of at least 0.708 (Hair et al., 2022, Chapter 5). However, none of the reviewed studies assessed convergent validity, which illustrates a major omission in applied PLS-SEM work (Table 5). To assess collinearity, researchers should assess each indicator's variance inflation factor (VIF). Many of the studies we reviewed also lacked this test (Table 5). Collinearity is problematic, as it inflates standard errors, which inversely affects the significance levels, and it can reverse weights' directionality (sign) (Hair et al., 2022, Chapter 5). While a value of 5 is normally regarded as a critical cut-off value, multicollinearity issues might already be present in VIF values above 3 (Becker, Ringle, Sarstedt, &amp; Völckner, 2015). If there are collinearity problems in PLS-SEM, researchers should follow the guidance that Hair et al. (2022; Chapter 5) offer, and, for example, group problematic items together under a new item. To demonstrate indicator relevance, researchers should report the indictors' weights, which need to be sufficiently different from zero. Moreover, they need to establish the indicator weights' statistical significance by using the bootstrapping procedure (Aguirre-Urreta &amp; Rönkkö, 2018; Chin, 1998). In order to improve the measurement model, researchers should consider deleting indicators with non-significant weights if the indicator loading is nonsignificant or small (e.g., below 0.50), unless the indicator's inclusion is essential from a measurement theory perspective (Hair et al., 2022, Chapter 5;Hair, Risher, et al., 2019).Covariance-based SEM can accommodate constructs with formative measurement models by using causal-formative indicators (Bollen &amp; Diamantopoulos, 2017), although this requires setting specific model constraints for identification purposes (Bollen &amp; Davis, 2009;Diamantopoulos &amp; Riefler, 2011). Since PLS-SEM does not have comparable modeling requirements due to the use of composite indicators, the inclusion of constructs with a formative measurement in models might be a valid (secondary) reason for using the method. To statically obtain proxies of reflectively measured constructs, covariance-based SEM uses common factor model estimations while PLS-SEM employs composite model estimations. More specifically, in PLS-SEM, researchers usually use correlation weights (Mode A) to obtain proxies for reflectively measured constructs, and regression weights (Mode B) for formatively measured constructs (e.g., Chin, 1998;Tenenhaus et al., 2005) First, for formatively measured constructs, the literature recommends assessing convergent validity as well as indicator collinearity, relevance, and significance (Diamantopoulos &amp; Winklhofer, 2001;Hair, Risher, et al., 2019). Researchers establish the convergent validity by undertaking a redundancy analysis (i.e., by assessing how the construct's formative measurement correlates with an alternative measurement) for which they can use a single-item measure that captures the construct's essence, and which researchers must add proactively to their questionnaires (Cheah, Sarstedt, Ringle, Ramayah, &amp; Ting, 2018). To establish convergent validity, the correlation between the two constructs should have a value of at least 0.708 (Hair et al., 2022, Chapter 5). However, none of the reviewed studies assessed convergent validity, which illustrates a major omission in applied PLS-SEM work (Table 5). To assess collinearity, researchers should assess each indicator's variance inflation factor (VIF). Many of the studies we reviewed also lacked this test (Table 5). Collinearity is problematic, as it inflates standard errors, which inversely affects the significance levels, and it can reverse weights' directionality (sign) (Hair et al., 2022, Chapter 5). While a value of 5 is normally regarded as a critical cut-off value, multicollinearity issues might already be present in VIF values above 3 (Becker, Ringle, Sarstedt, &amp; Völckner, 2015). If there are collinearity problems in PLS-SEM, researchers should follow the guidance that Hair et al. (2022; Chapter 5) offer, and, for example, group problematic items together under a new item. To demonstrate indicator relevance, researchers should report the indictors' weights, which need to be sufficiently different from zero. Moreover, they need to establish the indicator weights' statistical significance by using the bootstrapping procedure (Aguirre-Urreta &amp; Rönkkö, 2018; Chin, 1998). In order to improve the measurement model, researchers should consider deleting indicators with non-significant weights if the indicator loading is nonsignificant or small (e.g., below 0.50), unless the indicator's inclusion is essential from a measurement theory perspective (Hair et al., 2022, Chapter 5;Hair, Risher, et al., 2019).</p>
        <p>Second, in respect of reflectively measured constructs, the literature recommends assessing the indicator loadings, internal consistency reliability, as well as the convergent and discriminant validity (Hair, Risher, Ringle, 2012). To assess internal consistency reliability (i.e., the extent to which the set of indicators consistently reflect the underlying construct), researchers should report composite reliability ρ A . Additional optional criteria are Cronbach's α and the composite reliability ρ C . Because Cronbach's α can be overly conservative and composite reliability ρ C too liberal (i.e., upward biased), researchers should perceive these criteria's results as the lower and upper bound of the actual composite reliability (Hair et al., 2022, Chapter 6). In contrast, the composite reliability ρ A represents an approximation of the true reliability (Dijkstra &amp; Henseler, 2015b), which is higher than Cronbach's α and lower than the composite reliability ρ C . These criteria for determining the internal consistency reliability should at least have a value of 0.7 to be considered satisfactory (Hair &amp; Sarstedt, 2019). However, outcomes larger than 0.95 indicate item redundancy and possible biased response patterns in the data, such as straight-line responses that deliver high inter-item correlations. In such cases, it is better to refine the items and/or sample. In terms of the validity checks, researchers should assess the convergent validity on the basis of the AVE (average variance extracted), and the discriminant validity on the basis of the heterotraitmonotrait (HTMT) ratio of correlations. The recommended threshold for the AVE is a minimum value of 0.50, meaning that a construct explains at least half of its items' variance. However, researchers should be aware that AVE is not useful when the number of a construct's indicators is as small as two, in which case AVEs larger than 0.50 would always be obtained in PLS-SEM. Importantly, although the literature recommends using the HTMT ratio instead of the Fornell-Larcker criterion to assess discriminant validity, most of the studies we reviewed only used the latter, despite its known weaknesses. According to Henseler, Ringle, and Sarstedt (2015), who established the HTMT ratio, the result needs to be smaller than the more conservative threshold of 0.85 or the more liberal one of 0.90. These thresholds indicate that the average indicator correlation across different constructs (the numerator) is substantially smaller than the average indicator correlation within the constructs (the denominator). As using static cut-off values for the HTMT ratio could deliver false positive results, researchers should use percentile-based bootstrap confidence intervals (i.e., inferential statistics) to assess the HTMT ratio (Franke &amp; Sarstedt, 2019). To ensure that the HTMT ratio is significantly below 0.85 (or 0.90), the upper bound of the (one-sided) percentile-based bootstrap confidence interval using 10,000 bootstrap samples must be smaller than 0.85 (or 0.90). This allows researchers to establish reflectively measured constructs' discriminant validity. 8 Roemer, Schuberth, and Henseler (2021) proposed a different version of the HTMT metric (i.e., HTMT2), which yields almost the same values as the original metric, except for extreme model constellations (i.e., with very heterogenous loadings patterns and very high construct correlations), for which the metrics are unlikely to be significantly different even in this case (see also Sarstedt, Hair, Pick, et al., 2022). However, the HTMT metrics' limitations in face of negative indicator correlation patterns, for which the metrics produce extreme values or are sometimes not even defined, can be handled by using the adjusted HTMT+ (and HTMT2+) versions, which employ absolute indicator correlations (Ringle, Sarstedt, Sinkovics, &amp; Sinkovics, 2023).Second, in respect of reflectively measured constructs, the literature recommends assessing the indicator loadings, internal consistency reliability, as well as the convergent and discriminant validity (Hair, Risher, Ringle, 2012). To assess internal consistency reliability (i.e., the extent to which the set of indicators consistently reflect the underlying construct), researchers should report composite reliability ρ A . Additional optional criteria are Cronbach's α and the composite reliability ρ C . Because Cronbach's α can be overly conservative and composite reliability ρ C too liberal (i.e., upward biased), researchers should perceive these criteria's results as the lower and upper bound of the actual composite reliability (Hair et al., 2022, Chapter 6). In contrast, the composite reliability ρ A represents an approximation of the true reliability (Dijkstra &amp; Henseler, 2015b), which is higher than Cronbach's α and lower than the composite reliability ρ C . These criteria for determining the internal consistency reliability should at least have a value of 0.7 to be considered satisfactory (Hair &amp; Sarstedt, 2019). However, outcomes larger than 0.95 indicate item redundancy and possible biased response patterns in the data, such as straight-line responses that deliver high inter-item correlations. In such cases, it is better to refine the items and/or sample. In terms of the validity checks, researchers should assess the convergent validity on the basis of the AVE (average variance extracted), and the discriminant validity on the basis of the heterotraitmonotrait (HTMT) ratio of correlations. The recommended threshold for the AVE is a minimum value of 0.50, meaning that a construct explains at least half of its items' variance. However, researchers should be aware that AVE is not useful when the number of a construct's indicators is as small as two, in which case AVEs larger than 0.50 would always be obtained in PLS-SEM. Importantly, although the literature recommends using the HTMT ratio instead of the Fornell-Larcker criterion to assess discriminant validity, most of the studies we reviewed only used the latter, despite its known weaknesses. According to Henseler, Ringle, and Sarstedt (2015), who established the HTMT ratio, the result needs to be smaller than the more conservative threshold of 0.85 or the more liberal one of 0.90. These thresholds indicate that the average indicator correlation across different constructs (the numerator) is substantially smaller than the average indicator correlation within the constructs (the denominator). As using static cut-off values for the HTMT ratio could deliver false positive results, researchers should use percentile-based bootstrap confidence intervals (i.e., inferential statistics) to assess the HTMT ratio (Franke &amp; Sarstedt, 2019). To ensure that the HTMT ratio is significantly below 0.85 (or 0.90), the upper bound of the (one-sided) percentile-based bootstrap confidence interval using 10,000 bootstrap samples must be smaller than 0.85 (or 0.90). This allows researchers to establish reflectively measured constructs' discriminant validity. 8 Roemer, Schuberth, and Henseler (2021) proposed a different version of the HTMT metric (i.e., HTMT2), which yields almost the same values as the original metric, except for extreme model constellations (i.e., with very heterogenous loadings patterns and very high construct correlations), for which the metrics are unlikely to be significantly different even in this case (see also Sarstedt, Hair, Pick, et al., 2022). However, the HTMT metrics' limitations in face of negative indicator correlation patterns, for which the metrics produce extreme values or are sometimes not even defined, can be handled by using the adjusted HTMT+ (and HTMT2+) versions, which employ absolute indicator correlations (Ringle, Sarstedt, Sinkovics, &amp; Sinkovics, 2023).</p>
        <p>Covariance-based SEM methods estimate the model so that its covariances are as similar as possible to the observed covariances in the data, which prioritizes explanation over prediction (Hair, Sarstedt, Ringle, &amp; Mena, 2012). In contrast, when estimating the relationships in a theoretically established model, the PLS-SEM algorithm minimizes the unexplained variance of both the indicators and the dependent constructs (e.g., Lohmöller, 1989, Chapter 2). As such, PLS-SEM is a causalpredictive method (Sarstedt, Ringle, &amp; Hair, 2022;Wold, 1982) that prioritizes prediction over explanation of theoretically established models (also see, for example, Gregor, 2006;Hofman, Sharma, &amp; Watts, 2017;Sarstedt &amp; Danks, 2022;Shmueli, 2010 on explanation and prediction). Even though PLS-SEM seeks to maximize the model's in-sample Notes: ☑ recommended; ✓ optional; ☒ not recommended; percentages show the share of studies that reported and met the respective thresholds/cut-off values. 8 We address the low use of inference-based HTMT ratio analyses (Table 5) by illustrating the process in Web Appendix B.Covariance-based SEM methods estimate the model so that its covariances are as similar as possible to the observed covariances in the data, which prioritizes explanation over prediction (Hair, Sarstedt, Ringle, &amp; Mena, 2012). In contrast, when estimating the relationships in a theoretically established model, the PLS-SEM algorithm minimizes the unexplained variance of both the indicators and the dependent constructs (e.g., Lohmöller, 1989, Chapter 2). As such, PLS-SEM is a causalpredictive method (Sarstedt, Ringle, &amp; Hair, 2022;Wold, 1982) that prioritizes prediction over explanation of theoretically established models (also see, for example, Gregor, 2006;Hofman, Sharma, &amp; Watts, 2017;Sarstedt &amp; Danks, 2022;Shmueli, 2010 on explanation and prediction). Even though PLS-SEM seeks to maximize the model's in-sample Notes: ☑ recommended; ✓ optional; ☒ not recommended; percentages show the share of studies that reported and met the respective thresholds/cut-off values. 8 We address the low use of inference-based HTMT ratio analyses (Table 5) by illustrating the process in Web Appendix B.</p>
        <p>P. Guenther et al. prediction, the model assessment should also consider the model's outof-sample predictive capabilities (Shmueli &amp; Koppius, 2011;Shmueli, Ray, Velasquez Estrada, &amp; Chatla, 2016). This is particularly important, because most managerial recommendations based on PLS-SEM results are predictive by nature (Hair, 2021a;Hair &amp; Sarstedt, 2021;Sarstedt and Danks, 2022). In this regard, researchers focus increasingly on impact and the relevance for practitioners; prediction is therefore likely to gain in importance (Hair, 2021a). For instance, managers and stakeholders seek research insights that enable them to optimize their activities' outcomes. The business marketing field is no exception and, consequently, various studies have used PLS-SEM to predict critical outcome variables, such as firm performance (e.g., Nguyen, Ngo, Bucic, &amp; Phong, 2018), transaction costs (e.g., Shahzad, Ali, Takala, Helo, &amp; Zaefarian, 2018), and customer monetary value (e.g., Streukens, van Hoesel, &amp; de Ruyter, 2011). Beside other important assessment criteria, we therefore revisit appropriate measures to assess a model's prediction and discuss the importance of establishing both the in-sample prediction and the out-of-sample prediction using relevant indicators (Hair, Risher, et al., 2019).P. Guenther et al. prediction, the model assessment should also consider the model's outof-sample predictive capabilities (Shmueli &amp; Koppius, 2011;Shmueli, Ray, Velasquez Estrada, &amp; Chatla, 2016). This is particularly important, because most managerial recommendations based on PLS-SEM results are predictive by nature (Hair, 2021a;Hair &amp; Sarstedt, 2021;Sarstedt and Danks, 2022). In this regard, researchers focus increasingly on impact and the relevance for practitioners; prediction is therefore likely to gain in importance (Hair, 2021a). For instance, managers and stakeholders seek research insights that enable them to optimize their activities' outcomes. The business marketing field is no exception and, consequently, various studies have used PLS-SEM to predict critical outcome variables, such as firm performance (e.g., Nguyen, Ngo, Bucic, &amp; Phong, 2018), transaction costs (e.g., Shahzad, Ali, Takala, Helo, &amp; Zaefarian, 2018), and customer monetary value (e.g., Streukens, van Hoesel, &amp; de Ruyter, 2011). Beside other important assessment criteria, we therefore revisit appropriate measures to assess a model's prediction and discuss the importance of establishing both the in-sample prediction and the out-of-sample prediction using relevant indicators (Hair, Risher, et al., 2019).</p>
        <p>Our review of PLS-SEM applications in business marketing studies shows that R 2 is a key criterion for assessing the structural model results (Table 6; e.g., Chin, 2010;Haenlein &amp; Kaplan, 2004;Roldán &amp; Sánchez-Franco, 2012). R 2 reveals the model's in-sample prediction capabilities and, from an econometric perspective, is an important indicator of model overfit that researchers should report. In this regard, focusing on the R 2 values when creating increasingly complex models may promote overfitting, as R 2 improves when more constructs explain a dependent construct in the structural model (Sharma, Sarstedt, Shmueli, Kim, &amp; Thiele, 2019). Although researchers can adjust the R 2 values to account for a model's complexity (i.e., by means of the adjusted R 2 ), the adjustment is not sufficient to satisfactorily address the measure's tendency to overfit. However, researchers should primarily use the adjusted R 2 value to compare model alternatives for a dependent construct when different numbers of explanators are used to explain it.Our review of PLS-SEM applications in business marketing studies shows that R 2 is a key criterion for assessing the structural model results (Table 6; e.g., Chin, 2010;Haenlein &amp; Kaplan, 2004;Roldán &amp; Sánchez-Franco, 2012). R 2 reveals the model's in-sample prediction capabilities and, from an econometric perspective, is an important indicator of model overfit that researchers should report. In this regard, focusing on the R 2 values when creating increasingly complex models may promote overfitting, as R 2 improves when more constructs explain a dependent construct in the structural model (Sharma, Sarstedt, Shmueli, Kim, &amp; Thiele, 2019). Although researchers can adjust the R 2 values to account for a model's complexity (i.e., by means of the adjusted R 2 ), the adjustment is not sufficient to satisfactorily address the measure's tendency to overfit. However, researchers should primarily use the adjusted R 2 value to compare model alternatives for a dependent construct when different numbers of explanators are used to explain it.</p>
        <p>To assess a model's predictive capabilities, PLS-SEM literature relatively early on suggested using Stone-Geisser's Q 2 criterion, which is based on the blindfolding procedure (Chin, 1998;Tenenhaus et al., 2005). The blindfolding procedure has the advantage that it does not require a holdout sample. However, this also means that it does not represent an out-of-sample predictive capabilities assessment procedure, which PLS-SEM requires (e.g., Cepeda Carrión, Henseler, Ringle, &amp; Roldán, 2016).To assess a model's predictive capabilities, PLS-SEM literature relatively early on suggested using Stone-Geisser's Q 2 criterion, which is based on the blindfolding procedure (Chin, 1998;Tenenhaus et al., 2005). The blindfolding procedure has the advantage that it does not require a holdout sample. However, this also means that it does not represent an out-of-sample predictive capabilities assessment procedure, which PLS-SEM requires (e.g., Cepeda Carrión, Henseler, Ringle, &amp; Roldán, 2016).</p>
        <p>To address this issue effectively, Shmueli et al. (2016) and Shmueli et al. (2019) presented the PLS predict procedure, which supports an outof-sample predictive capabilities assessment, although it consequently requires a moderately larger minimum sample size. According to this procedure, a k-fold cross-validation randomly divides the original sample into k equally sized folds (e.g., 10) and predicts the values of each fold (holdout sample) by using model estimates based on the remaining folds (training sample). When PLS predict uses a 10-fold crossvalidation, nine folds become the training sample used to estimate the model, while the remaining fold serves as a holdout sample, for which PLS predict computes the model's prediction errors. Researchers should note that the minimum sample size requirements apply to the total number of training sample observations in the nine folds used for the model estimation. In PLS predict , each of the ten folds becomes the holdout sample in turn. Consequently, each observation in the dataset is ultimately predicted. To ensure that a solution is not based on an extreme random assignment of the observations to the ten folds, PLS predict restarts several times (e.g., 10) and computes the average prediction error across all the solutions (Shmueli et al., 2019).To address this issue effectively, Shmueli et al. (2016) and Shmueli et al. (2019) presented the PLS predict procedure, which supports an outof-sample predictive capabilities assessment, although it consequently requires a moderately larger minimum sample size. According to this procedure, a k-fold cross-validation randomly divides the original sample into k equally sized folds (e.g., 10) and predicts the values of each fold (holdout sample) by using model estimates based on the remaining folds (training sample). When PLS predict uses a 10-fold crossvalidation, nine folds become the training sample used to estimate the model, while the remaining fold serves as a holdout sample, for which PLS predict computes the model's prediction errors. Researchers should note that the minimum sample size requirements apply to the total number of training sample observations in the nine folds used for the model estimation. In PLS predict , each of the ten folds becomes the holdout sample in turn. Consequently, each observation in the dataset is ultimately predicted. To ensure that a solution is not based on an extreme random assignment of the observations to the ten folds, PLS predict restarts several times (e.g., 10) and computes the average prediction error across all the solutions (Shmueli et al., 2019).</p>
        <p>Finally, PLS predict 's prediction errors need to be compared to a benchmark of naïve prediction alternatives. One of the most naïve benchmarks is a prediction using the average value of the training sample's variables to predict the holdout sample outcomes. If PLS-SEM has a smaller prediction error, in other words a Q 2 predict value larger than zero, it has superior predictive capabilities than the naïve mean value prediction benchmark (Shmueli et al., 2019). A more demanding linear model (LM) benchmark regresses each of the dependent constructs' indicators on all of the exogenous constructs' indicators (Danks &amp; Ray, 2018;Shmueli et al., 2016). PLS-SEM must once again show a lower prediction error than the LM benchmark to verify its higher predictive power. Shmueli et al. (2019) suggested that in order to assess the PLS predict results, the Q 2 predict value should be positive. Subsequently, researchers should compare, per construct indicator, the PLS-SEM and the LM benchmark results' root mean square error (RMSE) or mean absolute error (MAE). If the PLS-SEM results show a lower RMSE (or MAE) for all, the majority, the minority, or none of the construct indicators, the model has high, moderate, weak, or no predictive capabilities in respect of the specific construct (Shmueli et al., 2019). Researchers should carry out this predictive assessment for each of the key target constructs in the model (e.g., customer satisfaction and customer loyalty in the ACSI model; Fornell et al., 2020, Chapter 5). However, the PLS predict assessment is not a statistical test, but allows an assessment of high, moderate, weak, and lack of the model's predictive capabilities in respect of a certain target construct and the number of its indicators that favor the PLS-SEM solution.Finally, PLS predict 's prediction errors need to be compared to a benchmark of naïve prediction alternatives. One of the most naïve benchmarks is a prediction using the average value of the training sample's variables to predict the holdout sample outcomes. If PLS-SEM has a smaller prediction error, in other words a Q 2 predict value larger than zero, it has superior predictive capabilities than the naïve mean value prediction benchmark (Shmueli et al., 2019). A more demanding linear model (LM) benchmark regresses each of the dependent constructs' indicators on all of the exogenous constructs' indicators (Danks &amp; Ray, 2018;Shmueli et al., 2016). PLS-SEM must once again show a lower prediction error than the LM benchmark to verify its higher predictive power. Shmueli et al. (2019) suggested that in order to assess the PLS predict results, the Q 2 predict value should be positive. Subsequently, researchers should compare, per construct indicator, the PLS-SEM and the LM benchmark results' root mean square error (RMSE) or mean absolute error (MAE). If the PLS-SEM results show a lower RMSE (or MAE) for all, the majority, the minority, or none of the construct indicators, the model has high, moderate, weak, or no predictive capabilities in respect of the specific construct (Shmueli et al., 2019). Researchers should carry out this predictive assessment for each of the key target constructs in the model (e.g., customer satisfaction and customer loyalty in the ACSI model; Fornell et al., 2020, Chapter 5). However, the PLS predict assessment is not a statistical test, but allows an assessment of high, moderate, weak, and lack of the model's predictive capabilities in respect of a certain target construct and the number of its indicators that favor the PLS-SEM solution.</p>
        <p>As an improvement of the out-of-sample prediction assessment in PLS-SEM, Liengaard et al. (2021) presented the cross-validated predictive ability test (CVPAT) for predictive model comparison, which Sharma, Liengaard, Hair, Sarstedt, and Ringle (2022) further advanced to test a model's predictive capabilities. This approach allows researchers to statistically compare a model with a naïve mean value benchmark and a more demanding linear model benchmark. Researchers can use the test to assess one specific target construct in isolation or multiple relevant target constructs simultaneously. The approach then confirms whether the analyzed model has significantly better predictive capabilities than the prediction benchmarks. Since this test has advantages over PLS predict , we believe that researchers will use the CVPAT to confirm the predictive power of a model in future marketing applications. The demonstration of predictive capability is critical to support management recommendations and conclusions based on the results of a PLS-SEM study. However, because the CVPAT is relatively new, we have for now included it as an optional assessment of the structural model in Table 6.As an improvement of the out-of-sample prediction assessment in PLS-SEM, Liengaard et al. (2021) presented the cross-validated predictive ability test (CVPAT) for predictive model comparison, which Sharma, Liengaard, Hair, Sarstedt, and Ringle (2022) further advanced to test a model's predictive capabilities. This approach allows researchers to statistically compare a model with a naïve mean value benchmark and a more demanding linear model benchmark. Researchers can use the test to assess one specific target construct in isolation or multiple relevant target constructs simultaneously. The approach then confirms whether the analyzed model has significantly better predictive capabilities than the prediction benchmarks. Since this test has advantages over PLS predict , we believe that researchers will use the CVPAT to confirm the predictive power of a model in future marketing applications. The demonstration of predictive capability is critical to support management recommendations and conclusions based on the results of a PLS-SEM study. However, because the CVPAT is relatively new, we have for now included it as an optional assessment of the structural model in Table 6.</p>
        <p>The goodness-of-fit (GoF), which considers the average explained variance amount of indicators in reflective measurement models and of dependent constructs in the structural model, was an early criterion (Tenenhaus et al., 2005). However, Henseler and Sarstedt (2013) demonstrated that this criterion does not live up to its name's promise, because it fails to reliably distinguish between valid and invalid models. Nonetheless, a relatively large percentage of business marketing studies reported the GoF (Table 6).The goodness-of-fit (GoF), which considers the average explained variance amount of indicators in reflective measurement models and of dependent constructs in the structural model, was an early criterion (Tenenhaus et al., 2005). However, Henseler and Sarstedt (2013) demonstrated that this criterion does not live up to its name's promise, because it fails to reliably distinguish between valid and invalid models. Nonetheless, a relatively large percentage of business marketing studies reported the GoF (Table 6).</p>
        <p>Model fit criteria commonly compare the distance between the sample covariance matrix and a model's implied covariance matrix. The smaller the distance, the better the model's fit with the data (Henseler, Hubona, &amp; Ray, 2016). In this regard, researchers should consider model fit criteria such as the standardized root mean square residual (SRMR), which should be below 0.08 (e.g., Hair et al., 2022, Chapter 6). However, future research may establish PLS-SEM-specific cut-off values for the SRMR and other fit criteriasimilarly to other SEM methods (e.g., Cho, Hwang, Sarstedt, &amp; Ringle, 2020;Sharma, Mukherjee, Kumar, &amp; Dillon, 2005). Researchers could alternatively use a bootstrap-based test for the exact overall model fit in PLS-SEM (Dijkstra &amp; Henseler, 2015a;Schuberth, Rademaker, &amp; Henseler, 2022).Model fit criteria commonly compare the distance between the sample covariance matrix and a model's implied covariance matrix. The smaller the distance, the better the model's fit with the data (Henseler, Hubona, &amp; Ray, 2016). In this regard, researchers should consider model fit criteria such as the standardized root mean square residual (SRMR), which should be below 0.08 (e.g., Hair et al., 2022, Chapter 6). However, future research may establish PLS-SEM-specific cut-off values for the SRMR and other fit criteriasimilarly to other SEM methods (e.g., Cho, Hwang, Sarstedt, &amp; Ringle, 2020;Sharma, Mukherjee, Kumar, &amp; Dillon, 2005). Researchers could alternatively use a bootstrap-based test for the exact overall model fit in PLS-SEM (Dijkstra &amp; Henseler, 2015a;Schuberth, Rademaker, &amp; Henseler, 2022).</p>
        <p>Nevertheless, the question remains which fit criterion researchers should use, if they provide conflicting outcomes (e.g., the SRMR shows a relatively low value below 0.08, which indicates a model fit, while the bootstrap-based test for the exact overall model fit reveals that the model is wrong) and/or what they should do if a model fit has not been established in respect of a selected criterion. Moreover, in contrast to other SEM approaches, the variance-based PLS-SEM algorithm does not aim to minimize the covariance-related discrepancy and therefore the model fit (recall that its objective is to maximize the amount of explained variance in the measurement models and the structural model; also see Legate et al., 2022). Consequently, some researchers have questioned the usefulness of the model fit assessment in PLS-SEM (Hair, Sarstedt, &amp; Ringle, 2019) and show that the underlying assumptions (e.g., on the residual covariances of common factor models) are not considered in PLS-SEM, which can limit their appropriateness for fit assessment in PLS-SEM and hamper the comparison with covariancebased SEM fit results (Lohmöller, 1989, Chapter 2). In contrast, Schuberth et al. (2022) stress the relevance of model fit for results assessment and show the metrics' efficacy using (variations of) a simple composite model.Nevertheless, the question remains which fit criterion researchers should use, if they provide conflicting outcomes (e.g., the SRMR shows a relatively low value below 0.08, which indicates a model fit, while the bootstrap-based test for the exact overall model fit reveals that the model is wrong) and/or what they should do if a model fit has not been established in respect of a selected criterion. Moreover, in contrast to other SEM approaches, the variance-based PLS-SEM algorithm does not aim to minimize the covariance-related discrepancy and therefore the model fit (recall that its objective is to maximize the amount of explained variance in the measurement models and the structural model; also see Legate et al., 2022). Consequently, some researchers have questioned the usefulness of the model fit assessment in PLS-SEM (Hair, Sarstedt, &amp; Ringle, 2019) and show that the underlying assumptions (e.g., on the residual covariances of common factor models) are not considered in PLS-SEM, which can limit their appropriateness for fit assessment in PLS-SEM and hamper the comparison with covariancebased SEM fit results (Lohmöller, 1989, Chapter 2). In contrast, Schuberth et al. (2022) stress the relevance of model fit for results assessment and show the metrics' efficacy using (variations of) a simple composite model.</p>
        <p>Against this background and two streams of recommendations, business marketing researchers should consider the causal-predictive nature of the PLS-SEM method (Wold, 1982; also see Chin et al., 2020) and report both the predictive capability (e.g., by using PLS predict ) and the model fit (e.g., by using the SRMR criterion). Ideally, when using PLS-SEM, researchers show that the model fits the data and has predictive capabilities. In the reviewed business marketing applications, only a few studies reported the SRMR, while no study reported the bootstrap-based test for model fit (Table 6).Against this background and two streams of recommendations, business marketing researchers should consider the causal-predictive nature of the PLS-SEM method (Wold, 1982; also see Chin et al., 2020) and report both the predictive capability (e.g., by using PLS predict ) and the model fit (e.g., by using the SRMR criterion). Ideally, when using PLS-SEM, researchers show that the model fits the data and has predictive capabilities. In the reviewed business marketing applications, only a few studies reported the SRMR, while no study reported the bootstrap-based test for model fit (Table 6).</p>
        <p>However, since a well-fitting model is not necessarily a good predictive model and vice versa (e.g., Sarstedt &amp; Danks, 2022;Shmueli, 2010), researchers must decide what to do when the model assessment only supports either model fit or the predictive capabilities. In that case they may aim primarily to support the explanation of their theoretically established model, consider additional model fit assessments (e.g., the bootstrap-based test for the exact overall model fit), and apply model estimation approaches that maximize model fit (e.g., covariance-based SEM). However, researchers should keep in mind that other methods such as covariance-based SEM can achieve a somewhat more accurate representation of the underlying theory by focusing on maximizing model fit, but at the expense of lower predictive power (Evermann &amp; Tate, 2016;Hair, Sarstedt, &amp; Ringle, 2019). Alternatively, researchers may focus primarily on prediction and consider additional assessments of the model's predictive capabilities (e.g., by using CVPAT in addition to PLS predict ). The latter is particularly important for managerial recommendations based on the PLS-SEM results (e.g., Hair &amp; Sarstedt, 2021;Sarstedt &amp; Danks, 2022). Since such recommendations are predictive in nature (e.g., Becker, Cheah, Gholamzade, Ringle, &amp; Sarstedt, 2023;Magno et al., 2022), researchers should assess and not sacrifice predictive power to ensure that the model produces generalizable findings (e.g., Hair et al., 2022, Chapter 6;Shmueli, 2010). In addition, researchers may perform various robustness checks to provide additional assurance of the validity of the results. For instance, Hair, Sarstedt, Ringle, and Gudergan (2018), Sarstedt, Hair, Pick, et al. (2022), and Sarstedt et al. (2020) give examples of such analyses to ensure the robustness of results and their appropriate reporting.However, since a well-fitting model is not necessarily a good predictive model and vice versa (e.g., Sarstedt &amp; Danks, 2022;Shmueli, 2010), researchers must decide what to do when the model assessment only supports either model fit or the predictive capabilities. In that case they may aim primarily to support the explanation of their theoretically established model, consider additional model fit assessments (e.g., the bootstrap-based test for the exact overall model fit), and apply model estimation approaches that maximize model fit (e.g., covariance-based SEM). However, researchers should keep in mind that other methods such as covariance-based SEM can achieve a somewhat more accurate representation of the underlying theory by focusing on maximizing model fit, but at the expense of lower predictive power (Evermann &amp; Tate, 2016;Hair, Sarstedt, &amp; Ringle, 2019). Alternatively, researchers may focus primarily on prediction and consider additional assessments of the model's predictive capabilities (e.g., by using CVPAT in addition to PLS predict ). The latter is particularly important for managerial recommendations based on the PLS-SEM results (e.g., Hair &amp; Sarstedt, 2021;Sarstedt &amp; Danks, 2022). Since such recommendations are predictive in nature (e.g., Becker, Cheah, Gholamzade, Ringle, &amp; Sarstedt, 2023;Magno et al., 2022), researchers should assess and not sacrifice predictive power to ensure that the model produces generalizable findings (e.g., Hair et al., 2022, Chapter 6;Shmueli, 2010). In addition, researchers may perform various robustness checks to provide additional assurance of the validity of the results. For instance, Hair, Sarstedt, Ringle, and Gudergan (2018), Sarstedt, Hair, Pick, et al. (2022), and Sarstedt et al. (2020) give examples of such analyses to ensure the robustness of results and their appropriate reporting.</p>
        <p>At the predictor level, researchers should report path coefficients and the corresponding significance levels to demonstrate individual constructs' predictive ability. The resampling method for significance testing should be bootstrapping (and not jackknifing, see Hair, Sarstedt, Pieper, &amp; Ringle, 2012). The significance testing should be based on the percentile approach (Aguirre-Urreta &amp; Rönkkö, 2018) -or, in case of skewed distributions, the bias-corrected and accelerated (BCa) approach, which is based on the percentile approach (Hair et al., 2022, Chapters 5 and 6) -with a recommended minimum of 10,000 bootstrap samples (Streukens &amp; Leroi-Werelds, 2016). Based on the bootstrapping results, researchers should assess and report the (bias-corrected) confidence intervals of the coefficients for significance testing.At the predictor level, researchers should report path coefficients and the corresponding significance levels to demonstrate individual constructs' predictive ability. The resampling method for significance testing should be bootstrapping (and not jackknifing, see Hair, Sarstedt, Pieper, &amp; Ringle, 2012). The significance testing should be based on the percentile approach (Aguirre-Urreta &amp; Rönkkö, 2018) -or, in case of skewed distributions, the bias-corrected and accelerated (BCa) approach, which is based on the percentile approach (Hair et al., 2022, Chapters 5 and 6) -with a recommended minimum of 10,000 bootstrap samples (Streukens &amp; Leroi-Werelds, 2016). Based on the bootstrapping results, researchers should assess and report the (bias-corrected) confidence intervals of the coefficients for significance testing.</p>
        <p>The size of the standardized coefficients allows researcher to assess and rank their relevance. They could also report the effect size f 2 (Cohen, 1988) to capture a predictor's R 2 impact (i.e., the incremental variance explained), since f 2 is useful to rank predictors in the order of their explanatory importance. We regard this measure as suitable, although it often results in a rank order similar to the ranking based on the predictors' standardized coefficients (Hair, Risher, et al., 2019). Nevertheless, reporting f 2 can be useful to explain partial or full mediation, which different ranking orders indicate (Nitzl, Roldan, &amp; Cepeda Carrión, 2016). The recommended cut-off values for f 2 are 0.02, 0.15, and 0.35 for small, medium, and large effect sizes respectively.The size of the standardized coefficients allows researcher to assess and rank their relevance. They could also report the effect size f 2 (Cohen, 1988) to capture a predictor's R 2 impact (i.e., the incremental variance explained), since f 2 is useful to rank predictors in the order of their explanatory importance. We regard this measure as suitable, although it often results in a rank order similar to the ranking based on the predictors' standardized coefficients (Hair, Risher, et al., 2019). Nevertheless, reporting f 2 can be useful to explain partial or full mediation, which different ranking orders indicate (Nitzl, Roldan, &amp; Cepeda Carrión, 2016). The recommended cut-off values for f 2 are 0.02, 0.15, and 0.35 for small, medium, and large effect sizes respectively.</p>
        <p>PLS-SEM method development has introduced predictive model comparison approaches to assist researchers in choosing between theoretically established model alternatives. The Bayesian information criterion (BIC) and the Geweke-Meese criterion (GM), for instance, help researchers choose the most appropriate model (Danks, Sharma, &amp; Sarstedt, 2020;Sharma et al., 2019;Sharma, Shmueli, Sarstedt, Danks, &amp; Ray, 2021). Business marketing researchers can use the measures to demonstrate that an analyzed model has a smaller BIC or GM value and therefore a higher predictive power than an alternative theoretically plausible model (or the saturated model). We illustrate the BIC application in Web Appendix B. The BIC and GM criteria compare the results of alternative models. However, this approach does not indicate whether the most advantageous model with a lowest outcome for these criteria is significantly superior to alternative models. In this regard, the CVPAT approach to a predictive model comparison is an improvement (Liengaard et al., 2021), as it allows researchers to test a theoretically established alternative model against the theoretically established original model. The results then show whether the alternative model has significantly higher predictive power than the original model. As the predictive model comparison is relatively new to PLS-SEM, the approaches have not as yet been used in business marketing studies (Table 6). Researchers can also use the model fit criteria discussed above for model comparison. However, PLS-SEM research has not established model selection procedures based on model fit criteria that focus on the differences between the sample and model-implied covariance matrices.PLS-SEM method development has introduced predictive model comparison approaches to assist researchers in choosing between theoretically established model alternatives. The Bayesian information criterion (BIC) and the Geweke-Meese criterion (GM), for instance, help researchers choose the most appropriate model (Danks, Sharma, &amp; Sarstedt, 2020;Sharma et al., 2019;Sharma, Shmueli, Sarstedt, Danks, &amp; Ray, 2021). Business marketing researchers can use the measures to demonstrate that an analyzed model has a smaller BIC or GM value and therefore a higher predictive power than an alternative theoretically plausible model (or the saturated model). We illustrate the BIC application in Web Appendix B. The BIC and GM criteria compare the results of alternative models. However, this approach does not indicate whether the most advantageous model with a lowest outcome for these criteria is significantly superior to alternative models. In this regard, the CVPAT approach to a predictive model comparison is an improvement (Liengaard et al., 2021), as it allows researchers to test a theoretically established alternative model against the theoretically established original model. The results then show whether the alternative model has significantly higher predictive power than the original model. As the predictive model comparison is relatively new to PLS-SEM, the approaches have not as yet been used in business marketing studies (Table 6). Researchers can also use the model fit criteria discussed above for model comparison. However, PLS-SEM research has not established model selection procedures based on model fit criteria that focus on the differences between the sample and model-implied covariance matrices.</p>
        <p>A number of advanced modeling approaches are available for PLS-SEM, which give researchers as well as practitioners deeper insights into relationships in the data (e.g., necessary condition analysis, mediation, and nonlinear effects). Considering special types of relationships by means of more advanced modeling approaches could help researchers develop more comprehensive theoretical models and help practitioners make more informed predictions about how to achieve a desired outcome. In addition, advanced approaches such as addressing endogeneity help researchers establish that hypothesized relationships do exist in the underlying population, therefore ruling out that such relationships are simply spurious artifacts of unmeasured confounding effects. Advanced PLS-SEM approaches also deal with analyzing observed heterogeneity (e.g., by means of moderation and multigroup analyses) and uncovering unobserved heterogeneity (e.g., by means of finite mixture partial least squares and prediction-oriented segmentation) to ensure the results' validity. In sum, most of these approaches serve as PLS-SEM robustness checks to safeguard the results' quality (Sarstedt, Ringle, et al., 2020).A number of advanced modeling approaches are available for PLS-SEM, which give researchers as well as practitioners deeper insights into relationships in the data (e.g., necessary condition analysis, mediation, and nonlinear effects). Considering special types of relationships by means of more advanced modeling approaches could help researchers develop more comprehensive theoretical models and help practitioners make more informed predictions about how to achieve a desired outcome. In addition, advanced approaches such as addressing endogeneity help researchers establish that hypothesized relationships do exist in the underlying population, therefore ruling out that such relationships are simply spurious artifacts of unmeasured confounding effects. Advanced PLS-SEM approaches also deal with analyzing observed heterogeneity (e.g., by means of moderation and multigroup analyses) and uncovering unobserved heterogeneity (e.g., by means of finite mixture partial least squares and prediction-oriented segmentation) to ensure the results' validity. In sum, most of these approaches serve as PLS-SEM robustness checks to safeguard the results' quality (Sarstedt, Ringle, et al., 2020).</p>
        <p>In Web Appendix A, we briefly explain the following advanced approaches with particular relevance for PLS-SEM by outlining their purpose, procedure, and relevant considerations (Hair et al., 2022, Chapter 8;Hair, Sarstedt, et al., 2018;Sarstedt, Ringle, et al., 2020):In Web Appendix A, we briefly explain the following advanced approaches with particular relevance for PLS-SEM by outlining their purpose, procedure, and relevant considerations (Hair et al., 2022, Chapter 8;Hair, Sarstedt, et al., 2018;Sarstedt, Ringle, et al., 2020):</p>
        <p>• Higher-order constructs (e.g., Becker et al., 2023;Lohmöller, 1989, Chapter 3;Sarstedt, Hair, Cheah, Becker, &amp; Ringle, 2019), • mediation (e.g., Cheah, Roldán, Ciavolino, Ting, &amp; Ramayah, 2021;Nitzl et al., 2016;Sarstedt, Hair, Nitzl, Ringle, &amp; Howard, 2020) &amp; Schermelleh-Engel, 2014;Hair, Sarstedt, et al., 2018, Chapter 2), • endogeneity (e.g., Becker, Proksch, &amp; Ringle, 2022;Hult et al., 2018;Park &amp; Gupta, 2012), and • necessary condition analysis (NCA; e.g., Dul, 2016Dul, , 2020;;Richter, Schubring, Hauff, Ringle, &amp; Sarstedt, 2020;Richter et al., 2023).• Higher-order constructs (e.g., Becker et al., 2023;Lohmöller, 1989, Chapter 3;Sarstedt, Hair, Cheah, Becker, &amp; Ringle, 2019), • mediation (e.g., Cheah, Roldán, Ciavolino, Ting, &amp; Ramayah, 2021;Nitzl et al., 2016;Sarstedt, Hair, Nitzl, Ringle, &amp; Howard, 2020) &amp; Schermelleh-Engel, 2014;Hair, Sarstedt, et al., 2018, Chapter 2), • endogeneity (e.g., Becker, Proksch, &amp; Ringle, 2022;Hult et al., 2018;Park &amp; Gupta, 2012), and • necessary condition analysis (NCA; e.g., Dul, 2016Dul, , 2020;;Richter, Schubring, Hauff, Ringle, &amp; Sarstedt, 2020;Richter et al., 2023).</p>
        <p>Our review of PLS-SEM applications shows that even among the more recent studies, very few analyses employ more advanced approaches (Table 7). This could indicate a low awareness of the available techniques and their specific purposes. However, the few studies that do use advanced approaches often do not use suitable procedures. These findings suggest the significant value of giving applied business marketing researchers a concise overview of advanced approaches (Web Appendix A).Our review of PLS-SEM applications shows that even among the more recent studies, very few analyses employ more advanced approaches (Table 7). This could indicate a low awareness of the available techniques and their specific purposes. However, the few studies that do use advanced approaches often do not use suitable procedures. These findings suggest the significant value of giving applied business marketing researchers a concise overview of advanced approaches (Web Appendix A).</p>
        <p>The number of PLS-SEM applications in IMM studies has increased rapidly since 2005. This upturn is not surprising, since business marketing research's characteristics (e.g., dealing with complex phenomena) and challenges (e.g., requiring respondents who are difficult to recruit) make the method particularly relevant and attractive to the relevant researchers. Nonetheless, our review of &gt;100 PLS-SEM applications in IMM over the past two decades and more has revealed issues with the appropriate and full use of common application routines, namely tests, reporting, cut-off values, and thresholds, as well as with understanding them. The review has also shown the underuse of advanced modeling techniques despite their potential to generate more robust findings, a deeper understanding, and novel insights.The number of PLS-SEM applications in IMM studies has increased rapidly since 2005. This upturn is not surprising, since business marketing research's characteristics (e.g., dealing with complex phenomena) and challenges (e.g., requiring respondents who are difficult to recruit) make the method particularly relevant and attractive to the relevant researchers. Nonetheless, our review of &gt;100 PLS-SEM applications in IMM over the past two decades and more has revealed issues with the appropriate and full use of common application routines, namely tests, reporting, cut-off values, and thresholds, as well as with understanding them. The review has also shown the underuse of advanced modeling techniques despite their potential to generate more robust findings, a deeper understanding, and novel insights.</p>
        <p>We have found that many issues are relatively persistent over time, as they are equally present in older and more recent PLS-SEM applications, which underlines the need for concise guidance. We have therefore used our review to identify the most critical issues and to develop detailed checklists (Tables 3456) and application examples (Web Appendix B) to stimulate further purposive and adequate business marketing research using the PLS-SEM method. In addition, we provide researchers with a shortcut for their next PLS-SEM project by offering them a concise checklist (see Table 8) that captures the most important aspects, including the key conceptual considerations to motivate the PLS-SEM approach's use, common application routines, including the appropriate tests and cut-off values, and advanced application routines.We have found that many issues are relatively persistent over time, as they are equally present in older and more recent PLS-SEM applications, which underlines the need for concise guidance. We have therefore used our review to identify the most critical issues and to develop detailed checklists (Tables 3456) and application examples (Web Appendix B) to stimulate further purposive and adequate business marketing research using the PLS-SEM method. In addition, we provide researchers with a shortcut for their next PLS-SEM project by offering them a concise checklist (see Table 8) that captures the most important aspects, including the key conceptual considerations to motivate the PLS-SEM approach's use, common application routines, including the appropriate tests and cut-off values, and advanced application routines.</p>
        <p>In conclusion, given the increasing focus on research results' practical impact, we anticipate that researchers will continue to increasingly use composite based modeling and PLS-SEM's causal-predictive capabilities. This should close the gap between purely explanatory modeling, which prevails in the social sciences, and predictive modeling, which the natural sciences use predominantly (Shmueli &amp; Koppius, 2011). Against this backdrop, assessing a model's predictive capability properly is likely to become increasingly important in marketing and the social sciences disciplines (Hofman et al., 2017). In this paper, we explain the PLS predict and CVPAT procedures to assess a PLS path model's out-of-sample prediction (Web Appendix B). In addition, we encourage business marketing researchers to keep up to date, particularly with predictive capability assessment due to its importance for evaluating research findings' practical impact. The increasing focus on practical impact is likely to promote further improvement of out-of-sample prediction tests, such as Sharma et al.'s (2019) approach to use information criteria to compare models' predictive capabilities and Sharma, Liengaard, Hair, et al.'s (2022) predictive model assessment via an improved version of the CVPAT, which was originally developed by Liengaard et al. (2021) for the comparison of theoretically established model alternatives in PLS-SEM.In conclusion, given the increasing focus on research results' practical impact, we anticipate that researchers will continue to increasingly use composite based modeling and PLS-SEM's causal-predictive capabilities. This should close the gap between purely explanatory modeling, which prevails in the social sciences, and predictive modeling, which the natural sciences use predominantly (Shmueli &amp; Koppius, 2011). Against this backdrop, assessing a model's predictive capability properly is likely to become increasingly important in marketing and the social sciences disciplines (Hofman et al., 2017). In this paper, we explain the PLS predict and CVPAT procedures to assess a PLS path model's out-of-sample prediction (Web Appendix B). In addition, we encourage business marketing researchers to keep up to date, particularly with predictive capability assessment due to its importance for evaluating research findings' practical impact. The increasing focus on practical impact is likely to promote further improvement of out-of-sample prediction tests, such as Sharma et al.'s (2019) approach to use information criteria to compare models' predictive capabilities and Sharma, Liengaard, Hair, et al.'s (2022) predictive model assessment via an improved version of the CVPAT, which was originally developed by Liengaard et al. (2021) for the comparison of theoretically established model alternatives in PLS-SEM.</p>
        <p>Our review has revealed several areas for further PLS-SEM methodological research. First, research is needed on how to minimize the validity gap between the statistically obtained construct proxies and the theoretical constructs. Such research should consider the nature of the theoretical constructs (e.g., whether reflective or formative) and the data characteristics. Second, with regard to small-sample contexts, such as business marketing research, it is important to fully assess the imputation techniques (e.g., including median replacement, the expectation-maximum algorithm, and the winsorization of outliers) in order to optimally handle missing data or outliers. Third, researchers should develop concrete cut-off values for fit indices such as the SRMR. Fourth, additional research is needed to fully evaluate the Gaussian copula approach's appropriateness in order to detect and address endogeneity in PLS-SEM contexts. A recent study cautions that using the Gaussian copula approach in regression models that include an intercept could deliver biased results and low statistical power in small samples (Becker et al., 2022). While PLS-SEM does not include an intercept for data standardization reasons, standardization does not generally alleviate concerns regarding the copula approach's appropriateness (Becker et al., 2022). Further research should specifically evaluate the Gaussian copula approach in the PLS-SEM context and take recent findings into consideration. Fifth, researchers introduced the necessary condition analysis (Dul, 2016;Dul, 2020) to PLS-SEM (e.g., Richter et al., 2020;Sukhov, Olsson, &amp; Friman, 2022). Future research should consider recent developments in the method, including in the PLS-SEM context, and clarify additional technical issues (e.g., the use of theoretical or empirical scales or the use of standardized or unstandardized data).Our review has revealed several areas for further PLS-SEM methodological research. First, research is needed on how to minimize the validity gap between the statistically obtained construct proxies and the theoretical constructs. Such research should consider the nature of the theoretical constructs (e.g., whether reflective or formative) and the data characteristics. Second, with regard to small-sample contexts, such as business marketing research, it is important to fully assess the imputation techniques (e.g., including median replacement, the expectation-maximum algorithm, and the winsorization of outliers) in order to optimally handle missing data or outliers. Third, researchers should develop concrete cut-off values for fit indices such as the SRMR. Fourth, additional research is needed to fully evaluate the Gaussian copula approach's appropriateness in order to detect and address endogeneity in PLS-SEM contexts. A recent study cautions that using the Gaussian copula approach in regression models that include an intercept could deliver biased results and low statistical power in small samples (Becker et al., 2022). While PLS-SEM does not include an intercept for data standardization reasons, standardization does not generally alleviate concerns regarding the copula approach's appropriateness (Becker et al., 2022). Further research should specifically evaluate the Gaussian copula approach in the PLS-SEM context and take recent findings into consideration. Fifth, researchers introduced the necessary condition analysis (Dul, 2016;Dul, 2020) to PLS-SEM (e.g., Richter et al., 2020;Sukhov, Olsson, &amp; Friman, 2022). Future research should consider recent developments in the method, including in the PLS-SEM context, and clarify additional technical issues (e.g., the use of theoretical or empirical scales or the use of standardized or unstandardized data).</p>
        <p>Furthermore, regarding SEM in general and PLS-SEM specifically, there is sometimes a mismatch between researchers' articulated research goals and that what the methods can actually accomplish in terms ofFurthermore, regarding SEM in general and PLS-SEM specifically, there is sometimes a mismatch between researchers' articulated research goals and that what the methods can actually accomplish in terms of</p>
        <p>Shortcut: motivation, common application routines, and advanced application routines.Shortcut: motivation, common application routines, and advanced application routines.</p>
        <p>Panel A: motivating PLS-SEM use (based on its standard composite model) ☑ Is there a possibility that the indicator residual variances are not fully measurement errors, but that they have a meaning for the focal construct or the additional constructs in the model? ☑ Is the measurement error unlikely to be large? Panel B: Important common application routines Sample size ☑ Determine the minimum sample size by using the inverse square root method, the gamma-exponential method, or Monte Carlo-based power analysis. ☑ Address missing values by using imputation (mean or multiple regression). Non-normality ☑ Assess non-normality based on skewness and kurtosis. ☑ Address outliers by using replacement or robust PLS-SEM model estimation. Measurement of constructs ☑ Assess formative measurement: redundancy analysis, VIFs (&lt;3), weights' significance and relative relevance. ☑ Assess reflective measurement: loadings (&gt;0.708), internal consistency reliability (ρ A &gt; 0.70), AVE (&gt;0.50), 95% (one-sided) percentile bootstrap confidence interval of the HTMT ratio (upper bound &lt;0.85 or 0.90). Model ☑ Assess in-sample prediction: R 2 . ☑ Assess out-of-sample prediction: PLS predict (and CVPAT). ☑ Assess model fit: SRMR (and bootstrap-based test for model fit). ☑ Assess predictors: path coefficients significance and effect size f 2 . ☑ Compare models (optional): BIC or GM of the main model versus an alternative plausible model, CVPAT for a predictive model comparison.Panel A: motivating PLS-SEM use (based on its standard composite model) ☑ Is there a possibility that the indicator residual variances are not fully measurement errors, but that they have a meaning for the focal construct or the additional constructs in the model? ☑ Is the measurement error unlikely to be large? Panel B: Important common application routines Sample size ☑ Determine the minimum sample size by using the inverse square root method, the gamma-exponential method, or Monte Carlo-based power analysis. ☑ Address missing values by using imputation (mean or multiple regression). Non-normality ☑ Assess non-normality based on skewness and kurtosis. ☑ Address outliers by using replacement or robust PLS-SEM model estimation. Measurement of constructs ☑ Assess formative measurement: redundancy analysis, VIFs (&lt;3), weights' significance and relative relevance. ☑ Assess reflective measurement: loadings (&gt;0.708), internal consistency reliability (ρ A &gt; 0.70), AVE (&gt;0.50), 95% (one-sided) percentile bootstrap confidence interval of the HTMT ratio (upper bound &lt;0.85 or 0.90). Model ☑ Assess in-sample prediction: R 2 . ☑ Assess out-of-sample prediction: PLS predict (and CVPAT). ☑ Assess model fit: SRMR (and bootstrap-based test for model fit). ☑ Assess predictors: path coefficients significance and effect size f 2 . ☑ Compare models (optional): BIC or GM of the main model versus an alternative plausible model, CVPAT for a predictive model comparison.</p>
        <p>Panel C: Advanced application routines (Web Appendix A) Higher-order constructs ☑ Conceptually justify the measurements of the lower-and higher-order constructs. ☑ Use the repeated indicator approach or two-stage approach. ☑ Assess the reliability and validity of the lower-order and the higher-order constructs. ☑ Confirm that the model's predictive power is higher with than without modeling the higher-order construct by using the disjoint two-stage approach and BIC or CVPAT. Mediation ☑ Assess the mediating effects' significance via bootstrapping. ☑ In small samples, use the bias-corrected confidence intervals. ☑ Determine the mediation type (partial or full mediation), including by comparing the indirect effects' and total effects' variance accounted (VAF). Moderation ☑ Use the two-stage approach. ☑ Assess significance via bootstrapping. Multigroup analysis ☑ Assess measurement invariance between groups by using the MICOM procedure. ☑ Test the significance of effect differences across groups. ☑ If more than two groups are compared, correct the test statistic to keep the familywise error rate constant (e.g., by using a Bonferroni adjustment) Unobserved heterogeneity ☑ Identify and assess latent segments: finite mixture modeling, retention criteria (AIC 4 , BIC), segment size (&gt;min. required size), EN (&gt;0.5). ☑ Identify explanatory variables. ☑ Conduct a multigroup analysis. Nonlinear effects ☑ Use the two-stage approach. ☑ Assess significance of nonlinear effects via bootstrapping. Endogeneity ☑ Use the Anderson-Darling test or the Cramér-von Mises test to confirm that the suspected endogenous construct is sufficiently non-normally distributed. ☑ If it is, assess whether endogeneity is present, using the Gaussian copula; if present, address the endogeneity by adding the significant Gaussian copula term to the model. ☑ If it is not and a theoretically meaningful IV is available, use the IV approach to asses and address the potential endogeneity. ☑ If no IV is available, acknowledge the potential endogeneity as a limitation. Necessary condition analysis (NCA) ☑ Assess and address outliers. ☑ Perform NCA per construct pair (exogenous constructoutcome construct).Panel C: Advanced application routines (Web Appendix A) Higher-order constructs ☑ Conceptually justify the measurements of the lower-and higher-order constructs. ☑ Use the repeated indicator approach or two-stage approach. ☑ Assess the reliability and validity of the lower-order and the higher-order constructs. ☑ Confirm that the model's predictive power is higher with than without modeling the higher-order construct by using the disjoint two-stage approach and BIC or CVPAT. Mediation ☑ Assess the mediating effects' significance via bootstrapping. ☑ In small samples, use the bias-corrected confidence intervals. ☑ Determine the mediation type (partial or full mediation), including by comparing the indirect effects' and total effects' variance accounted (VAF). Moderation ☑ Use the two-stage approach. ☑ Assess significance via bootstrapping. Multigroup analysis ☑ Assess measurement invariance between groups by using the MICOM procedure. ☑ Test the significance of effect differences across groups. ☑ If more than two groups are compared, correct the test statistic to keep the familywise error rate constant (e.g., by using a Bonferroni adjustment) Unobserved heterogeneity ☑ Identify and assess latent segments: finite mixture modeling, retention criteria (AIC 4 , BIC), segment size (&gt;min. required size), EN (&gt;0.5). ☑ Identify explanatory variables. ☑ Conduct a multigroup analysis. Nonlinear effects ☑ Use the two-stage approach. ☑ Assess significance of nonlinear effects via bootstrapping. Endogeneity ☑ Use the Anderson-Darling test or the Cramér-von Mises test to confirm that the suspected endogenous construct is sufficiently non-normally distributed. ☑ If it is, assess whether endogeneity is present, using the Gaussian copula; if present, address the endogeneity by adding the significant Gaussian copula term to the model. ☑ If it is not and a theoretically meaningful IV is available, use the IV approach to asses and address the potential endogeneity. ☑ If no IV is available, acknowledge the potential endogeneity as a limitation. Necessary condition analysis (NCA) ☑ Assess and address outliers. ☑ Perform NCA per construct pair (exogenous constructoutcome construct).</p>
        <p>support for these goals. Future research should clearly map out the research goals that the methods do support, under which conditions they do so, and what their constraints are. In addition, developing specific examples to showcase the suitability of using common factors versus composites to estimate construct models would be desirable. Our study has emphasized that both statistical estimation techniques provide approximations of theoretically based constructs. By developing illustrative examples, future research could help further illustrate whether one or the other approach provides a better approximation. Future research may also consider advancements of confirmatory tetrad analysis (Bollen &amp; Ting, 1993;Gudergan, Ringle, Wende, &amp; Will, 2008) to guide researchers in their choice between a common factor or composite model.support for these goals. Future research should clearly map out the research goals that the methods do support, under which conditions they do so, and what their constraints are. In addition, developing specific examples to showcase the suitability of using common factors versus composites to estimate construct models would be desirable. Our study has emphasized that both statistical estimation techniques provide approximations of theoretically based constructs. By developing illustrative examples, future research could help further illustrate whether one or the other approach provides a better approximation. Future research may also consider advancements of confirmatory tetrad analysis (Bollen &amp; Ting, 1993;Gudergan, Ringle, Wende, &amp; Will, 2008) to guide researchers in their choice between a common factor or composite model.</p>
        <p>Moreover, there are opportunities available to extend the modeling capabilities, such as accommodating the relationships that multiple constructs have with a certain indicator, setting model constraints, and implementing circular and bidirectional relationships (i.e., not via a two-stage approach but a simultaneous model estimation). Additional improvements could focus on assessing the results and, especially, on extending the set of model evaluation criteria. The latter could include, for example, the further advances on bridging prediction and explanation via the joint application of related assessment criteria (e.g., PLS predict and the CVPAT as well as SRMR and the bootstrap-based test of exact overall model fit), and an evaluation of the impact that violating the PLS-SEM method's statistical assumptions (e.g., cross-loadings) has on the parameter bias and the predictive performance. Finally, multilevel modeling and longitudinal analysis are interesting candidates for methodologically extending PLS-SEM, as they are highly relevant for empirical research on marketing and management.Moreover, there are opportunities available to extend the modeling capabilities, such as accommodating the relationships that multiple constructs have with a certain indicator, setting model constraints, and implementing circular and bidirectional relationships (i.e., not via a two-stage approach but a simultaneous model estimation). Additional improvements could focus on assessing the results and, especially, on extending the set of model evaluation criteria. The latter could include, for example, the further advances on bridging prediction and explanation via the joint application of related assessment criteria (e.g., PLS predict and the CVPAT as well as SRMR and the bootstrap-based test of exact overall model fit), and an evaluation of the impact that violating the PLS-SEM method's statistical assumptions (e.g., cross-loadings) has on the parameter bias and the predictive performance. Finally, multilevel modeling and longitudinal analysis are interesting candidates for methodologically extending PLS-SEM, as they are highly relevant for empirical research on marketing and management.</p>
        <p>Notes: ☑ recommended; ✓ optional; ☒ not recommended.Notes: ☑ recommended; ✓ optional; ☒ not recommended.</p>
        <p>P.P.</p>
        <p>Guenther et al.Guenther et al.</p>
        <p>Notes: ☑ recommended; ✓ optional; ☒ not recommended.Notes: ☑ recommended; ✓ optional; ☒ not recommended.</p>
        <p>a During this period, no study detected outliers in the data; consequently, no treatment was required.a During this period, no study detected outliers in the data; consequently, no treatment was required.</p>
        <p>7 Note again that this discussion follows7 Note again that this discussion follows</p>
        <p>Sarstedt et al. (2016)Sarstedt et al. (2016)</p>
        <p>in that reflective measurement models can adequately be approximated by composites. However, if one assumes equivalence between reflective measurement models and common factors, consistent PLS-SEM (PLSc-SEM;in that reflective measurement models can adequately be approximated by composites. However, if one assumes equivalence between reflective measurement models and common factors, consistent PLS-SEM (PLSc-SEM;</p>
        <p>Dijkstra, 2010Dijkstra, , 2014Dijkstra, 2010Dijkstra, , 2014</p>
        <p>; see also; see also</p>
        <p>Dijkstra &amp; Henseler, 2015b;Dijkstra &amp; Schermelleh-Engel, 2014)Dijkstra &amp; Henseler, 2015b;Dijkstra &amp; Schermelleh-Engel, 2014)</p>
        <p>, its PLSe1/PLS2e extensions, its PLSe1/PLS2e extensions</p>
        <p>(Bentler &amp; Huang, 2014;Huang, 2013)(Bentler &amp; Huang, 2014;Huang, 2013)</p>
        <p>, or Yuan et al., or Yuan et al.</p>
        <p>(2020) approach based on Cronbach's α, adjust the parameter estimates to accommodate common factor models.(2020) approach based on Cronbach's α, adjust the parameter estimates to accommodate common factor models.</p>
        <p>P.P.</p>
        <p>Guenther et al. et al., 2019)Guenther et al. et al., 2019)</p>
        <p>. Regarding indicator loadings, each item (indicator) should have a loading of 0.708 or above to ensure that the construct proxy explains at least half of each item's variance. Regarding indicator loadings, each item (indicator) should have a loading of 0.708 or above to ensure that the construct proxy explains at least half of each item's variance</p>
        <p>(Hair, Sarstedt, Pieper, &amp;(Hair, Sarstedt, Pieper, &amp;</p>
        <p>Notes: ☑ recommended; ✓ optional; ☒ not recommended.Notes: ☑ recommended; ✓ optional; ☒ not recommended.</p>
        <p>a average number of bootstrap samples * not used in the reviewed studies, as the criterion/use recommendation is relatively new.a average number of bootstrap samples * not used in the reviewed studies, as the criterion/use recommendation is relatively new.</p>
        <p>, • moderation (e.g., Becker, Ringle, &amp; Sarstedt, 2018; Fassott, Henseler, &amp; Coelho, 2016; Memon et al., 2019),, • moderation (e.g., Becker, Ringle, &amp; Sarstedt, 2018; Fassott, Henseler, &amp; Coelho, 2016; Memon et al., 2019),</p>
        <p>Note that the distinction between common factor and composite model is not equivalent to reflective and formative measurementas sometimes suggested by PLS-SEM critics.Note that the distinction between common factor and composite model is not equivalent to reflective and formative measurementas sometimes suggested by PLS-SEM critics.</p>
        <p>To improve readability, we use 'PLS-SEM' in the following discussion instead of 'PLS-SEM based on a composite model,' as using this model together with the PLS-SEM algorithm is the dominant setup. However, readers should remember that PLS-SEM's composite model estimation results can also be combined with a common factor model(Dijkstra &amp; Henseler, 2015b).To improve readability, we use 'PLS-SEM' in the following discussion instead of 'PLS-SEM based on a composite model,' as using this model together with the PLS-SEM algorithm is the dominant setup. However, readers should remember that PLS-SEM's composite model estimation results can also be combined with a common factor model(Dijkstra &amp; Henseler, 2015b).</p>
        <p>The only exception is the argument that follow-up analyses require variable scores, which we do not address in more detail. In PLS-SEM, theoretical construct proxies' estimates are readily available, and can, for instance, be used in advanced follow-up analyses(Hair, Risher, et al., 2019). However, our reviews show that such follow-up analyses are rare. As these analyses could create incremental insights and are important ways of establishing results' validity, we revisit this issue in a dedicated section on advanced PLS-SEM issues.The only exception is the argument that follow-up analyses require variable scores, which we do not address in more detail. In PLS-SEM, theoretical construct proxies' estimates are readily available, and can, for instance, be used in advanced follow-up analyses(Hair, Risher, et al., 2019). However, our reviews show that such follow-up analyses are rare. As these analyses could create incremental insights and are important ways of establishing results' validity, we revisit this issue in a dedicated section on advanced PLS-SEM issues.</p>
        <p>In the Web Appendix B, this research uses the statistical software 
            <rs type="software">SmartPLS</rs> (
            <rs type="url">https://www.smartpls.com)</rs>. Christian M. Ringle acknowledges a financial interest in 
            <rs type="software">SmartPLS</rs>.
        </p>
        <p>Web Appendix A and Web Appendix B to this article can be found online at https://doi.org/10.1016/j.indmarman.2023.03.010.Web Appendix A and Web Appendix B to this article can be found online at https://doi.org/10.1016/j.indmarman.2023.03.010.</p>
    </text>
</tei>
