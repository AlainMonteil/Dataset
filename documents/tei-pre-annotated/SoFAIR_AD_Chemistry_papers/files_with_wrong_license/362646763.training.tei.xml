<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-13T15:11+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>Biomolecular force fields have been traditionally derived based on a mixture of reference quantum chemistry data and experimental information obtained on small fragments. However, the possibility to run extensive molecular dynamics simulations on larger systems achieving ergodic sampling is paving the way to directly using such simulations along with solution experiments obtained on macromolecular systems. Recently, a number of methods have been introduced to automatize this approach. Here, we review these methods, highlight their relationship with machine learning methods, and discuss the open challenges in the field.Biomolecular force fields have been traditionally derived based on a mixture of reference quantum chemistry data and experimental information obtained on small fragments. However, the possibility to run extensive molecular dynamics simulations on larger systems achieving ergodic sampling is paving the way to directly using such simulations along with solution experiments obtained on macromolecular systems. Recently, a number of methods have been introduced to automatize this approach. Here, we review these methods, highlight their relationship with machine learning methods, and discuss the open challenges in the field.</p>
        <p>Classical molecular dynamics (MD) simulations at the atomistic scale offer a unique opportunity to model the conformational dynamics of biomolecular systems. Being able to reveal mechanisms at spatial and temporal scales that are difficult to observe experimentally, MD simulations are often seen as a computational microscope. 1 In the past years, they have been applied to study problems ranging from protein folding 2 and aggregation 3 to RNA-protein interactions, 4,5 transmembrane proteins dynamics, 6 and full viruses, 7 bacteria, 8 or organelles. 9 The capability of MD simulations to reproduce and predict experimental results is limited by the statistical errors arising from the finite length of simulations and by the systematic errors resulting from the inaccuracies of the underlying models. Interactions are often modeled using empirically parameterized force fields that allow timescales of the order of the microsecond to be routinely simulated. Importantly, the two sources of error mentioned above are deeply intertwined because only systematic errors that are larger than statistical errors can be detected by comparison with the reference experimental results. Indeed, in the past 20 years, the use of special purpose hardware, 10 optimized software, 11,12 and enhanced sampling methods 13,14 has significantly reduced the statistical errors, thereby allowing force field inaccuracies to be detected and largely alleviated. In spite of this, empirical force fields are still far from perfect and, in some cases, are poorly predictive. For instance, it is not trivial to have force fields capable of simultaneously describing correctly folded, disordered, single-chain proteins or protein complexes, 15,16 to correctly predict the RNA structure from sequence-only information across a wide range of structural motifs, 17 or to reproduce experimental kinetics in ligand-receptor systems. 18 Solution experiments are optimally suited for validation of force fields since they provide information about transiently populated structures as well, and they have traditionally been used in this sense. Nevertheless, several approaches have enabled solution experiments to be used directly during force-field fitting, together with available quantum chemistry data. The aim of this perspective is to review these approaches, highlight their relationship with machine learning methods, and discuss the open challenges in the field.Classical molecular dynamics (MD) simulations at the atomistic scale offer a unique opportunity to model the conformational dynamics of biomolecular systems. Being able to reveal mechanisms at spatial and temporal scales that are difficult to observe experimentally, MD simulations are often seen as a computational microscope. 1 In the past years, they have been applied to study problems ranging from protein folding 2 and aggregation 3 to RNA-protein interactions, 4,5 transmembrane proteins dynamics, 6 and full viruses, 7 bacteria, 8 or organelles. 9 The capability of MD simulations to reproduce and predict experimental results is limited by the statistical errors arising from the finite length of simulations and by the systematic errors resulting from the inaccuracies of the underlying models. Interactions are often modeled using empirically parameterized force fields that allow timescales of the order of the microsecond to be routinely simulated. Importantly, the two sources of error mentioned above are deeply intertwined because only systematic errors that are larger than statistical errors can be detected by comparison with the reference experimental results. Indeed, in the past 20 years, the use of special purpose hardware, 10 optimized software, 11,12 and enhanced sampling methods 13,14 has significantly reduced the statistical errors, thereby allowing force field inaccuracies to be detected and largely alleviated. In spite of this, empirical force fields are still far from perfect and, in some cases, are poorly predictive. For instance, it is not trivial to have force fields capable of simultaneously describing correctly folded, disordered, single-chain proteins or protein complexes, 15,16 to correctly predict the RNA structure from sequence-only information across a wide range of structural motifs, 17 or to reproduce experimental kinetics in ligand-receptor systems. 18 Solution experiments are optimally suited for validation of force fields since they provide information about transiently populated structures as well, and they have traditionally been used in this sense. Nevertheless, several approaches have enabled solution experiments to be used directly during force-field fitting, together with available quantum chemistry data. The aim of this perspective is to review these approaches, highlight their relationship with machine learning methods, and discuss the open challenges in the field.</p>
        <p>We will use here as paradigmatic examples some of the force fields that are most used for simulating biomolecular systems, namely, 
            <rs type="software">AMBER</rs>, 19 CHARMM, 20 OPLS, 21 and GROMOS. 22 All the mentioned force fields share a common functional form, including bond stretching, angle potentials, torsional potentials, Lennard-Jones, and electrostatic interactions,
        </p>
        <p>The parameters (k b ; r 0 ; ka; a 0 ; Vn; δ; σ; ε; q) are derived from small fragments in advance and depend on the atom type and its chemical environment. Polarizable force fields (such as AMOEBA 23 and a variant of CHARMM 24 ), reactive force fields (such as ReaxFF 25 ), and semi-empirical methods (such as density-functional tight binding DFTB 26 ) have different functional forms, but similar considerations can be applied. The parameters in Eq. ( 1) are derived with a variety of different procedures that depend on the specific force field and are summarized in Table I. In particular, some of the parameters are typically derived from quantum chemistry calculations performed at a varying level of accuracy in a bottom up spirit. Other parameters are instead derived from experimental data, either using spectroscopy experiments, databases of crystallographic structures, or other gas-phase or solution-phase experiments, in a top down spirit.The parameters (k b ; r 0 ; ka; a 0 ; Vn; δ; σ; ε; q) are derived from small fragments in advance and depend on the atom type and its chemical environment. Polarizable force fields (such as AMOEBA 23 and a variant of CHARMM 24 ), reactive force fields (such as ReaxFF 25 ), and semi-empirical methods (such as density-functional tight binding DFTB 26 ) have different functional forms, but similar considerations can be applied. The parameters in Eq. ( 1) are derived with a variety of different procedures that depend on the specific force field and are summarized in Table I. In particular, some of the parameters are typically derived from quantum chemistry calculations performed at a varying level of accuracy in a bottom up spirit. Other parameters are instead derived from experimental data, either using spectroscopy experiments, databases of crystallographic structures, or other gas-phase or solution-phase experiments, in a top down spirit.</p>
        <p>One of the factors impacting the reliability of a force field is the accuracy of the employed reference data. For instance, a force field fitted purely on quantum chemistry data cannot provide results that are more accurate than the reference method. However, this limit can be surpassed if multiple sources of data are combined. As an additional and perhaps even more important source of error, one should take into account that the reference data used in force-field fitting, either computational or experimental ones, are obtained by studying systems that are necessarily not identical to those that one wants to simulate later (see Fig. 1). For instance, torsional parameters and partial charges in the AMBER force field are traditionally obtained using quantum chemistry calculations in small fragments of up to a few dozen atoms, typically including a couple of aminoacids, but are later used to simulate oligopeptides or full protein domains. Similarly, Lennard-Jones parameters in the OPLS force field are obtained from vaporization calorimetry of pure organic liquids such as tetrahydrofuran, pyridine, or benzene, but then applied to cases where the analyzed compounds are only portions of a sugar, nucleobase, or aminoacid, respectively. These parameters have not been changed in more recent OPLS versions. The reliability of a force field when used in a context different from the one in which it was parameterized depends on the transferability of the functional form in Eq. (1) (see Fig. 2). Given the very large gap between the size and complexity of the systems used for parameter fitting and the systems to which force fields are applied, it appears almost a miracle that current force fields are, for instance, capable of correctly identifying the folded state of a protein. 2 It is interesting to look at a few anecdotal examples to better understand how this is possible. The traditional 
            <rs type="software">AMBER</rs> force field for nucleic acids has been used for several years before it was realized that sufficiently long simulations could lead to a transition to experimentally unobserved rotamers in the α and γ torsions of the DNA backbone. 27,28 Following this empirical observation, a joint effort of several groups leads to the parmbsc0 reparameterization of the DNA backbone, 28 where the parameters corresponding to these two torsional angles were fitted against quantum chemistry calculations.
        </p>
        <p>A similar episode occurred later with the χOL3 corrections, derived to counteract the occurrence of ladder-like structures in the RNA. 29 In the CHARMM force field for proteins, one of the most important additions after its initial development has been the introduction of empirical corrections maps (CMAPs) 30 that deviate from the functional form of Eq. ( 1) by the presence of coupling terms between consecutive torsional angles. These corrections were fitted on quantum chemistry data but also required a heuristic adjustment to fix the typical values of torsional angles in α-helical and β-sheet regions. As a further example, empirical adjustments of the AMBER and CHARMM force fields were performed, respectively, in Ref. 31 and in Refs. 32 and 33, where solution data on short oligopeptides were used to optimize backbone dihedrals so as to reproduce helix-coil transitions.A similar episode occurred later with the χOL3 corrections, derived to counteract the occurrence of ladder-like structures in the RNA. 29 In the CHARMM force field for proteins, one of the most important additions after its initial development has been the introduction of empirical corrections maps (CMAPs) 30 that deviate from the functional form of Eq. ( 1) by the presence of coupling terms between consecutive torsional angles. These corrections were fitted on quantum chemistry data but also required a heuristic adjustment to fix the typical values of torsional angles in α-helical and β-sheet regions. As a further example, empirical adjustments of the AMBER and CHARMM force fields were performed, respectively, in Ref. 31 and in Refs. 32 and 33, where solution data on short oligopeptides were used to optimize backbone dihedrals so as to reproduce helix-coil transitions.</p>
        <p>A general trend that can be seen is that the experimental data on macromolecular systems (e.g., nucleic acids duplexes or protein domains) are typically used for validation, whereas the parameters are fitted on either theoretical or experimental information available for much smaller systems. Nonetheless, the observation of failures in macromolecular systems is the only way to detect which precise parameters should be corrected. The last three mentioned works, [31][32][33] instead, report direct fitting of parameters on simulations of short oligomers.A general trend that can be seen is that the experimental data on macromolecular systems (e.g., nucleic acids duplexes or protein domains) are typically used for validation, whereas the parameters are fitted on either theoretical or experimental information available for much smaller systems. Nonetheless, the observation of failures in macromolecular systems is the only way to detect which precise parameters should be corrected. The last three mentioned works, [31][32][33] instead, report direct fitting of parameters on simulations of short oligomers.</p>
        <p>A number of approaches have been introduced to allow fitting force fields directly on experimental data taken on macromolecular systems rather than on small fragments, all of them following a flowchart similar to the one illustrated in Fig. 3. Since solution experiments often report results that are averaged over an ensemble of copies of the same molecule, these methods are typically designed to enforce ensemble averages rather than instantaneous values. Norgaard et al. 34 introduced an approach where a force field is iteratively refined until agreement with the experiment is obtained. At each iteration, a simulation is performed, and the force-field parameters are optimized by assigning new weights to the visited conformations. Thus, through such a reweighting procedure, one can predict what result would be obtained using these slightly modified parameters. At some point, when the refined force field and the initial one become too different, it is necessary to iterate the procedure performing a new simulation. The method was applied to the refinement of a coarse-grained model of a protein and fitted against paramagnetic relaxation enhancement experiments. The same method was later used to choose the parameters of an implicit-solvent model against reference all-atom simulations. 35 FIG. 3. Schematic representation of a force-field fitting procedure using experimental data on macromolecular systems. Initial parameters are tuned based on both quantum chemistry data and experimental data on small systems (e.g., individual residues). Molecular dynamics simulations are then performed on macromolecular systems. Reweighting is used to optimize force-field parameters in order to maximize the agreement with a set of available data including experiments on macromolecular systems. In principle, this second stage might also include quantum chemistry data and experimental data on small systems. Even when not explicitly used at this stage, the initial set of quantum chemistry and experimental data is still playing a role for all the parameters that are not further adjusted. Even on the adjusted parameters, the information about the initial force field remains present if regularization terms are included.A number of approaches have been introduced to allow fitting force fields directly on experimental data taken on macromolecular systems rather than on small fragments, all of them following a flowchart similar to the one illustrated in Fig. 3. Since solution experiments often report results that are averaged over an ensemble of copies of the same molecule, these methods are typically designed to enforce ensemble averages rather than instantaneous values. Norgaard et al. 34 introduced an approach where a force field is iteratively refined until agreement with the experiment is obtained. At each iteration, a simulation is performed, and the force-field parameters are optimized by assigning new weights to the visited conformations. Thus, through such a reweighting procedure, one can predict what result would be obtained using these slightly modified parameters. At some point, when the refined force field and the initial one become too different, it is necessary to iterate the procedure performing a new simulation. The method was applied to the refinement of a coarse-grained model of a protein and fitted against paramagnetic relaxation enhancement experiments. The same method was later used to choose the parameters of an implicit-solvent model against reference all-atom simulations. 35 FIG. 3. Schematic representation of a force-field fitting procedure using experimental data on macromolecular systems. Initial parameters are tuned based on both quantum chemistry data and experimental data on small systems (e.g., individual residues). Molecular dynamics simulations are then performed on macromolecular systems. Reweighting is used to optimize force-field parameters in order to maximize the agreement with a set of available data including experiments on macromolecular systems. In principle, this second stage might also include quantum chemistry data and experimental data on small systems. Even when not explicitly used at this stage, the initial set of quantum chemistry and experimental data is still playing a role for all the parameters that are not further adjusted. Even on the adjusted parameters, the information about the initial force field remains present if regularization terms are included.</p>
        <p>Li and Brüschweiler 36 showed how to refine an all-atom protein force field using chemical shifts and full-length protein simulations.Li and Brüschweiler 36 showed how to refine an all-atom protein force field using chemical shifts and full-length protein simulations.</p>
        <p>A common trait of all these methods is that even small changes in force-field parameters can make the resulting ensemble very different from the original one, making the reweighting procedure less accurate. In Ref. 36, a local reweighting procedure was introduced to alleviate this issue. This procedure is based on the heuristic observation that the ensemble of conformations accessible to a residue is maximally affected by the parameters used for that residue and, to a lesser extent, by the parameters used for the other (possibly identical) residues. Since this is an approximation, a subsequent simulation performed with the corrected force field was necessary to validate the modification. References 37 and 38 used a similar automatic procedure to optimize water models. Interestingly, they realized that a straightforward fitting procedure might lead to overfitting and showed how a regularization term can be included in order to alleviate this issue. Finally, Cesari et al. 39 introduced a procedure to refine atomistic force fields where heterogeneous systems and types of experimental data are used to refine the AMBER RNA force field. Enhanced sampling techniques are employed by the authors to ergodically sample the conformational space for a number of RNA tetramers and hairpin loops, and a regularization term is used in the fitting scheme to maintain the refined force field close to the initial one. The weight of the regularization term is chosen with a crossvalidation procedure aimed at maximizing the transferability of the parameters.A common trait of all these methods is that even small changes in force-field parameters can make the resulting ensemble very different from the original one, making the reweighting procedure less accurate. In Ref. 36, a local reweighting procedure was introduced to alleviate this issue. This procedure is based on the heuristic observation that the ensemble of conformations accessible to a residue is maximally affected by the parameters used for that residue and, to a lesser extent, by the parameters used for the other (possibly identical) residues. Since this is an approximation, a subsequent simulation performed with the corrected force field was necessary to validate the modification. References 37 and 38 used a similar automatic procedure to optimize water models. Interestingly, they realized that a straightforward fitting procedure might lead to overfitting and showed how a regularization term can be included in order to alleviate this issue. Finally, Cesari et al. 39 introduced a procedure to refine atomistic force fields where heterogeneous systems and types of experimental data are used to refine the AMBER RNA force field. Enhanced sampling techniques are employed by the authors to ergodically sample the conformational space for a number of RNA tetramers and hairpin loops, and a regularization term is used in the fitting scheme to maintain the refined force field close to the initial one. The weight of the regularization term is chosen with a crossvalidation procedure aimed at maximizing the transferability of the parameters.</p>
        <p>It is important to recognize the difference between the mentioned approaches, which are meant to generate transferable forcefield parameters, and methods meant to improve the agreement with the experiment for a specific system for which data are available (Fig. 4). 40 This second class includes a variety of approaches such as Bayesian schemes 41,42 and methods based on the maximum entropy FIG. 4. Difference between maximum entropy and force-field fitting procedures. When using the maximum entropy principle to enforce agreement between simulation and experiment, one free parameter is used for each data point. As a consequence, different chemically equivalent units might be treated differently. This does not allow the corrections to be transferred to other molecules, for which new experimental data would be required. When using force-field fitting procedures, instead, all chemically equivalent units are treated in the same manner. This allows the derived parameters to be generalized to other molecules where the same units are used as building blocks.It is important to recognize the difference between the mentioned approaches, which are meant to generate transferable forcefield parameters, and methods meant to improve the agreement with the experiment for a specific system for which data are available (Fig. 4). 40 This second class includes a variety of approaches such as Bayesian schemes 41,42 and methods based on the maximum entropy FIG. 4. Difference between maximum entropy and force-field fitting procedures. When using the maximum entropy principle to enforce agreement between simulation and experiment, one free parameter is used for each data point. As a consequence, different chemically equivalent units might be treated differently. This does not allow the corrections to be transferred to other molecules, for which new experimental data would be required. When using force-field fitting procedures, instead, all chemically equivalent units are treated in the same manner. This allows the derived parameters to be generalized to other molecules where the same units are used as building blocks.</p>
        <p>principle. 43,44 In the maximum entropy formalism, the number of free parameters is equal to the number of experimental data points. For instance, in a homogeneous polymer, each of the monomers will feel a different correction that makes its structure as compatible as possible with experiments. Since the number of parameters is very high, regularization methods can be used and tuned with a crossvalidation procedure (see, e.g., Ref. 45). In addition, if a polymer of a different length needs to be simulated, new experimental data should be obtained. In force-field fitting procedures, the chemical structure of the investigated molecule is a priori used to reduce the number of parameters. For instance, in a homogeneous polymer, each of the monomers will feel the same correction (although perhaps terminal monomers might be treated differently 46 ). On the one hand, this allows us to encode a large amount of information in the specific choice of the functional form employed. This type of information is similar to the one that is included when atoms are classified in types in order to obtain their parameters. 47 On the other hand, it significantly reduces the number of parameters, potentially making the resulting force field transferable. Reference 48 used a hybrid approach where maximum entropy restraints were used but kept by construction constant across chemically equivalent parts of the system. For a recent comparison of approaches taken from both classes, see Ref. 49.principle. 43,44 In the maximum entropy formalism, the number of free parameters is equal to the number of experimental data points. For instance, in a homogeneous polymer, each of the monomers will feel a different correction that makes its structure as compatible as possible with experiments. Since the number of parameters is very high, regularization methods can be used and tuned with a crossvalidation procedure (see, e.g., Ref. 45). In addition, if a polymer of a different length needs to be simulated, new experimental data should be obtained. In force-field fitting procedures, the chemical structure of the investigated molecule is a priori used to reduce the number of parameters. For instance, in a homogeneous polymer, each of the monomers will feel the same correction (although perhaps terminal monomers might be treated differently 46 ). On the one hand, this allows us to encode a large amount of information in the specific choice of the functional form employed. This type of information is similar to the one that is included when atoms are classified in types in order to obtain their parameters. 47 On the other hand, it significantly reduces the number of parameters, potentially making the resulting force field transferable. Reference 48 used a hybrid approach where maximum entropy restraints were used but kept by construction constant across chemically equivalent parts of the system. For a recent comparison of approaches taken from both classes, see Ref. 49.</p>
        <p>Besides the discussed systematic approaches that report methodological improvements aimed at optimizing parameters based on the experimental data, a number of recently developed force fields include terms that were manually adjusted based on the result of MD simulations on systems of different complexity and their capability to reproduce experimental data. For instance, Refs. 15 and 31-33 reported optimizations of parameters based on the solution properties of oligopeptides. The atomic radii of the AMBER ff15ipq force field were chosen so as to provide correct salt-bridge interactions. 50 Finally, two recent variants of the AMBER RNA force field contain corrections on hydrogen bonds obtained by scanning a series of parameters and minimizing the discrepancy with the solution experiment for RNA oligomers. 46,51Besides the discussed systematic approaches that report methodological improvements aimed at optimizing parameters based on the experimental data, a number of recently developed force fields include terms that were manually adjusted based on the result of MD simulations on systems of different complexity and their capability to reproduce experimental data. For instance, Refs. 15 and 31-33 reported optimizations of parameters based on the solution properties of oligopeptides. The atomic radii of the AMBER ff15ipq force field were chosen so as to provide correct salt-bridge interactions. 50 Finally, two recent variants of the AMBER RNA force field contain corrections on hydrogen bonds obtained by scanning a series of parameters and minimizing the discrepancy with the solution experiment for RNA oligomers. 46,51</p>
        <p>Overfitting is a ubiquitous problem when fitting procedures are done in a blind manner. The prototypical cases are machine learning and related algorithms where functions of arbitrary complexity, supported by no or little physical understanding, are used to fit empirical data. The machine learning community has thus developed a number of tools that can be used to avoid or at least alleviate this issue.Overfitting is a ubiquitous problem when fitting procedures are done in a blind manner. The prototypical cases are machine learning and related algorithms where functions of arbitrary complexity, supported by no or little physical understanding, are used to fit empirical data. The machine learning community has thus developed a number of tools that can be used to avoid or at least alleviate this issue.</p>
        <p>Many different machine learning techniques exist and are typically based on a common framework. 52 The basic ingredient is a dataset made up of a set of independent variables (X, samples) and a set of dependent variables (Y, labels). Next, a set of models is proposed to map X into Y with best accuracy. A model is defined by a set of parameters plus a set of hyperparameters. This splitting is guided by computational convenience such that inference can be approached in a multi-level fashion: typically, model parameters are found by solving an optimization problem at fixed hyperparameters, which, on the other hand, are preferably scanned over a discreteMany different machine learning techniques exist and are typically based on a common framework. 52 The basic ingredient is a dataset made up of a set of independent variables (X, samples) and a set of dependent variables (Y, labels). Next, a set of models is proposed to map X into Y with best accuracy. A model is defined by a set of parameters plus a set of hyperparameters. This splitting is guided by computational convenience such that inference can be approached in a multi-level fashion: typically, model parameters are found by solving an optimization problem at fixed hyperparameters, which, on the other hand, are preferably scanned over a discrete</p>
        <p>The Journal of Chemical Physics PERSPECTIVE scitation.org/journal/jcp scale. This double approach is more easily understood when another basic ingredient of machine learning is introduced, that is, the cost function. The cost function is used to estimate the performance of a model, and while it is usually a continuous function of the model parameters, it can have a non-trivial dependence on the hyperparameters. For example, the set of hyperparameters can include the architecture of the model, the optimization algorithm used to find the optimal model parameters, the functional form of the cost function itself, etc. Similar choices also need to be taken in force-field fitting, as discussed in detail in Sec. V. Since the sets of parameters and hyperparameters defining models are fitted against a finite set of examples {X, Y}, overfitting can easily occur. In the limit of fitting on an infinite amount of data, the only limitation of a model wuld be determined by its complexity. In this limit, a too simple model would underfit the data, leading to a bias in the result. This bias can be decreased by increasing the model complexity. Since, in general, we deal with datasets of finite size, increasing the complexity of the model would result in a large contribution to the error (variance) due to the sampling. A too complex model would overfit the data, thus having a seriously low performance on new independent data.The Journal of Chemical Physics PERSPECTIVE scitation.org/journal/jcp scale. This double approach is more easily understood when another basic ingredient of machine learning is introduced, that is, the cost function. The cost function is used to estimate the performance of a model, and while it is usually a continuous function of the model parameters, it can have a non-trivial dependence on the hyperparameters. For example, the set of hyperparameters can include the architecture of the model, the optimization algorithm used to find the optimal model parameters, the functional form of the cost function itself, etc. Similar choices also need to be taken in force-field fitting, as discussed in detail in Sec. V. Since the sets of parameters and hyperparameters defining models are fitted against a finite set of examples {X, Y}, overfitting can easily occur. In the limit of fitting on an infinite amount of data, the only limitation of a model wuld be determined by its complexity. In this limit, a too simple model would underfit the data, leading to a bias in the result. This bias can be decreased by increasing the model complexity. Since, in general, we deal with datasets of finite size, increasing the complexity of the model would result in a large contribution to the error (variance) due to the sampling. A too complex model would overfit the data, thus having a seriously low performance on new independent data.</p>
        <p>The search for the model with the optimal tradeoff between bias and variance (i.e., between under-and over-fitting) follows two directions. One is to split the dataset into a training set and a cross-validation set, prior to analysis. Model parameters are fitted FIG. 5. Cross validation can be used to decrease overfitting and allow more generalizable force-field improvements. (a) In n-fold cross validation, the dataset is randomly split into n blocks of equal size. A single block of data is left out, and the parameters are trained on the remaining n -1 blocks. This is repeated once for each block, yielding multiple sets of trained parameters λ (1) , . . . , λ (n) . The error EThe search for the model with the optimal tradeoff between bias and variance (i.e., between under-and over-fitting) follows two directions. One is to split the dataset into a training set and a cross-validation set, prior to analysis. Model parameters are fitted FIG. 5. Cross validation can be used to decrease overfitting and allow more generalizable force-field improvements. (a) In n-fold cross validation, the dataset is randomly split into n blocks of equal size. A single block of data is left out, and the parameters are trained on the remaining n -1 blocks. This is repeated once for each block, yielding multiple sets of trained parameters λ (1) , . . . , λ (n) . The error E</p>
        <p>CV obtained with parameters λ (k) in reproducing the k-th block is then computed, and the average over the n results is the cross-validation error (ECV ). Leave-one-out cross validation is a special case where each block contains a single data point, whereas in leave-p-out cross validation, all possible subsets of p data are left out. (b) Hyperparameters controlling model complexity (such as regularization coefficients) are then chosen so as to minimize the cross-validation error.CV obtained with parameters λ (k) in reproducing the k-th block is then computed, and the average over the n results is the cross-validation error (ECV ). Leave-one-out cross validation is a special case where each block contains a single data point, whereas in leave-p-out cross validation, all possible subsets of p data are left out. (b) Hyperparameters controlling model complexity (such as regularization coefficients) are then chosen so as to minimize the cross-validation error.</p>
        <p>against data in the training set, and afterward, the optimized model is validated against the validation set data not included in the training procedure. This procedure is usually referred to as cross validation (Fig. 5), and depending on how the cross-validation set is built, it can be referred to as leave-one-out, leave-p-out, or n-fold cross validation. The other is to reduce the risk of overfitting by means of regularization techniques, the most common consisting in adding terms to the cost function that prevent the model parameters from reaching values extremely adapted to the dataset. This comes at the cost of increasing the number of hyperparameters (e.g., the relative size of training and cross-validation sets, their composition, coefficients of regularization terms, etc.) that continue to be affected by risk of overfitting. Even if a close solution to this problem is not established yet, overfitting should be taken into account for each level of inference (for both parameters and hyperparameters). The most straightforward way to deal with this multi-level risk of overfitting is to a priori split the dataset into three subsets: in addition to the standard training and cross-validation subsets, an independent test set is introduced. The training set is used to fit the optimal values of parameters at fixed hyperparameters; optimal hyperparameters are then fitted against the cross-validation set. Eventually, the performance of the model defined by the optimal parameters and hyperparameters is evaluated on the test set. A more robust approach consists in nested cross validation, 53 in which parameters and hyperparameters are optimized on a single dataset, but the criterion used to optimize model parameters (training) is different from the optimization criterion used for hyperparameters (model selection). Validation of the selected optimized model against new data that, importantly, has not been used to adjust neither parameters nor hyperparameters is a best practice in this case as well.against data in the training set, and afterward, the optimized model is validated against the validation set data not included in the training procedure. This procedure is usually referred to as cross validation (Fig. 5), and depending on how the cross-validation set is built, it can be referred to as leave-one-out, leave-p-out, or n-fold cross validation. The other is to reduce the risk of overfitting by means of regularization techniques, the most common consisting in adding terms to the cost function that prevent the model parameters from reaching values extremely adapted to the dataset. This comes at the cost of increasing the number of hyperparameters (e.g., the relative size of training and cross-validation sets, their composition, coefficients of regularization terms, etc.) that continue to be affected by risk of overfitting. Even if a close solution to this problem is not established yet, overfitting should be taken into account for each level of inference (for both parameters and hyperparameters). The most straightforward way to deal with this multi-level risk of overfitting is to a priori split the dataset into three subsets: in addition to the standard training and cross-validation subsets, an independent test set is introduced. The training set is used to fit the optimal values of parameters at fixed hyperparameters; optimal hyperparameters are then fitted against the cross-validation set. Eventually, the performance of the model defined by the optimal parameters and hyperparameters is evaluated on the test set. A more robust approach consists in nested cross validation, 53 in which parameters and hyperparameters are optimized on a single dataset, but the criterion used to optimize model parameters (training) is different from the optimization criterion used for hyperparameters (model selection). Validation of the selected optimized model against new data that, importantly, has not been used to adjust neither parameters nor hyperparameters is a best practice in this case as well.</p>
        <p>Force-field fitting procedures can be interpreted as machine learning methods where the parameters are the optimized coefficients and data and labels are a mixture of information obtained from both quantum chemistry calculations and various experimental techniques. One should thus pay attention to overfitting. Whenever overfitting occurs, transferability of the force field to a different case might be compromised. As already discussed, if parameters are only fitted on small systems, their transferability to larger systems might be limited. The other phenomenon that can be observed in reweighting methods is the subtle overfitting on the analyzed trajectory. In particular, if parameters are derived to match experimental data by reweighting a trajectory that is not sufficiently long, they might not work correctly on another trajectory obtained using the same force field but with different initial conditions. In addition, since reweighting schemes can only modulate the weight of states that have been explored but cannot predict the population of states that have not been observed (see, e.g., Ref. 54 for a comparison of restraining and reweighting when used to implement the maximum entropy principle), the only way to detect these problems is to keep the target force field as close as possible to the original one with some form of regularization and to then perform a new simulation once parameters have been optimized (see Fig. 6). The native state, compatible with experimental information, is in the middle (N). Two metastable non-native states that, based on experimental information, are supposed to have a low population are also shown (U1 and U2). In the original force field (panel a), the N state is sampled, but the most stable state is U1. During the reweighting procedure, the force field learns how to improve the agreement with experiments by disfavoring U1. However, since U2 was never observed in this simulation, there is nothing that prevents it to be stable when using the refined force field. Once a simulation is performed with the refined force field (panel b), state U2 appears with large population, leading to disagreement with the experiment. In principle, if a reweighting is performed using only the second simulation, state U1 might appear again with an incorrect population. Only a reweighting where both simulations are combined, and thus all the possible states can be observed, is capable of generating a force field that correctly sets N as the global free-energy minimum and U1 and U2 as metastable states with low population (panel c).Force-field fitting procedures can be interpreted as machine learning methods where the parameters are the optimized coefficients and data and labels are a mixture of information obtained from both quantum chemistry calculations and various experimental techniques. One should thus pay attention to overfitting. Whenever overfitting occurs, transferability of the force field to a different case might be compromised. As already discussed, if parameters are only fitted on small systems, their transferability to larger systems might be limited. The other phenomenon that can be observed in reweighting methods is the subtle overfitting on the analyzed trajectory. In particular, if parameters are derived to match experimental data by reweighting a trajectory that is not sufficiently long, they might not work correctly on another trajectory obtained using the same force field but with different initial conditions. In addition, since reweighting schemes can only modulate the weight of states that have been explored but cannot predict the population of states that have not been observed (see, e.g., Ref. 54 for a comparison of restraining and reweighting when used to implement the maximum entropy principle), the only way to detect these problems is to keep the target force field as close as possible to the original one with some form of regularization and to then perform a new simulation once parameters have been optimized (see Fig. 6). The native state, compatible with experimental information, is in the middle (N). Two metastable non-native states that, based on experimental information, are supposed to have a low population are also shown (U1 and U2). In the original force field (panel a), the N state is sampled, but the most stable state is U1. During the reweighting procedure, the force field learns how to improve the agreement with experiments by disfavoring U1. However, since U2 was never observed in this simulation, there is nothing that prevents it to be stable when using the refined force field. Once a simulation is performed with the refined force field (panel b), state U2 appears with large population, leading to disagreement with the experiment. In principle, if a reweighting is performed using only the second simulation, state U1 might appear again with an incorrect population. Only a reweighting where both simulations are combined, and thus all the possible states can be observed, is capable of generating a force field that correctly sets N as the global free-energy minimum and U1 and U2 as metastable states with low population (panel c).</p>
        <p>Every other decision taken in the path should be included in the list of hyperparameters. Coefficients controlling regularization terms used in the optimization, which control the relative weight of the initial force field and of experimental data, are naturally considered as hyperparameters. The functional form of the force field itself is a hyperparameter. The analogs of these hyperparameters in the training of the neural network are regularization terms or early stopping criteria and network architecture, respectively. 55 In forcefield fitting, a number of additional hyperparameters might be used whose control might be more or less explicit. For instance, the socalled forward models used to calculate experimental observables from MD trajectories contain a number of parameters. If the training is done to reproduce the energetics of quantum chemistry calculations, the set of structures used for fitting and their relative weights FIG. 7. Schematic representation of a training/final-validation procedure. Forcefield fitting can be based on a combination of quantum chemistry data, experimental data on small systems, and experimental data on macromolecular systems. All data can be used in parameter fitting, and cross validation (see Fig. 5) can be used to help the choice of hyperparameters. To this end, it is necessary that a separate set of data, either theoretical or experimental, is left out until the very end of the procedure to validate the transferability of the model. This separate data should not be used to take any decision during the fitting procedure, or the information leak might make the final validation not truly independent.Every other decision taken in the path should be included in the list of hyperparameters. Coefficients controlling regularization terms used in the optimization, which control the relative weight of the initial force field and of experimental data, are naturally considered as hyperparameters. The functional form of the force field itself is a hyperparameter. The analogs of these hyperparameters in the training of the neural network are regularization terms or early stopping criteria and network architecture, respectively. 55 In forcefield fitting, a number of additional hyperparameters might be used whose control might be more or less explicit. For instance, the socalled forward models used to calculate experimental observables from MD trajectories contain a number of parameters. If the training is done to reproduce the energetics of quantum chemistry calculations, the set of structures used for fitting and their relative weights FIG. 7. Schematic representation of a training/final-validation procedure. Forcefield fitting can be based on a combination of quantum chemistry data, experimental data on small systems, and experimental data on macromolecular systems. All data can be used in parameter fitting, and cross validation (see Fig. 5) can be used to help the choice of hyperparameters. To this end, it is necessary that a separate set of data, either theoretical or experimental, is left out until the very end of the procedure to validate the transferability of the model. This separate data should not be used to take any decision during the fitting procedure, or the information leak might make the final validation not truly independent.</p>
        <p>are to be considered as hyperparameters. Even the precise quantum methods used to compute the total energy might contain a number of hidden parameters (e.g., the possibility to use either the implicit or explicit solvent or the specific method used to solve the many-body Schrödinger equation).are to be considered as hyperparameters. Even the precise quantum methods used to compute the total energy might contain a number of hidden parameters (e.g., the possibility to use either the implicit or explicit solvent or the specific method used to solve the many-body Schrödinger equation).</p>
        <p>If hyperparameters are chosen a priori based on some independent intuition or information, for instance, the fact that a given quantum chemistry method is more accurate than another one, then this extra information will be encoded in the final result, improving the quality of the resulting model. However, if hyperparameters are optimized by monitoring the performance of the force field on a specific system, then this system will implicitly become part of the training set. Thus, the resulting model should be validated against a separate system (Fig. 7). A practical example would be if different variants of a force field are derived using three different quantum chemistry methods, then the best method is chosen checking the stability of the native structure of a specific system using all the derived variants. Unless there are other independent evidences that the selected quantum chemistry method is better than the other ones, this choice should be considered as fitted on the specific system and should be then validated on an independent one. Therefore, as a final remark, all the decisions taken in the process should be critically evaluated in this respect.If hyperparameters are chosen a priori based on some independent intuition or information, for instance, the fact that a given quantum chemistry method is more accurate than another one, then this extra information will be encoded in the final result, improving the quality of the resulting model. However, if hyperparameters are optimized by monitoring the performance of the force field on a specific system, then this system will implicitly become part of the training set. Thus, the resulting model should be validated against a separate system (Fig. 7). A practical example would be if different variants of a force field are derived using three different quantum chemistry methods, then the best method is chosen checking the stability of the native structure of a specific system using all the derived variants. Unless there are other independent evidences that the selected quantum chemistry method is better than the other ones, this choice should be considered as fitted on the specific system and should be then validated on an independent one. Therefore, as a final remark, all the decisions taken in the process should be critically evaluated in this respect.</p>
        <p>The recent works done in adjusting force-field parameters including experimental data suggest that this is a promising field that will lead to important improvements in the future. There are, however, a number of critical issues that one should carefully consider.The recent works done in adjusting force-field parameters including experimental data suggest that this is a promising field that will lead to important improvements in the future. There are, however, a number of critical issues that one should carefully consider.</p>
        <p>First, we suggest that all input data should be considered at the same time, irrespectively of being obtained from experiment or from quantum chemistry calculations. Both experimental and quantum chemistry data can indeed be equivalently used for training or for validation. Importantly, one should consider that different data have different relative errors and different information content. Data that provide limited information during fitting will also provide less stringent validations. Particularly valuable are data obtained on systems as close as possible to those that one is interested in simulating. Less weight instead should be given to the data obtained in very different conditions (e.g., without solvent) or on systems that are too simple to be considered as representative (e.g., individual aminoacids or nucleotides). As an exception to this general rule, one should consider that different types of data typically give access to the energetics in different portions of the conformational space. For instance, solution experiments on macromolecular systems are valuable in providing the relative stability of structures that can be distinguished using some probe. Quantum chemistry calculations are instead valuable when states are difficult to be distinguished in the experiment or when probing rarely visited states (such as transition states).First, we suggest that all input data should be considered at the same time, irrespectively of being obtained from experiment or from quantum chemistry calculations. Both experimental and quantum chemistry data can indeed be equivalently used for training or for validation. Importantly, one should consider that different data have different relative errors and different information content. Data that provide limited information during fitting will also provide less stringent validations. Particularly valuable are data obtained on systems as close as possible to those that one is interested in simulating. Less weight instead should be given to the data obtained in very different conditions (e.g., without solvent) or on systems that are too simple to be considered as representative (e.g., individual aminoacids or nucleotides). As an exception to this general rule, one should consider that different types of data typically give access to the energetics in different portions of the conformational space. For instance, solution experiments on macromolecular systems are valuable in providing the relative stability of structures that can be distinguished using some probe. Quantum chemistry calculations are instead valuable when states are difficult to be distinguished in the experiment or when probing rarely visited states (such as transition states).</p>
        <p>Reference data should be obtained in conditions as realistic as possible. One should carefully consider the conditions in which experiments are carried out and prefer experiments performed in conditions that can be reproduced in MD simulations. Ideally, specific experiments might be designed and performed in order to facilitate force field development, such as solution experiments on systems small enough to allow ergodic sampling but large enough to provide transferable information. When instead basing the fits on quantum chemistry calculations, one should consider the importance of the solvent. Additionally, errors in the experimental data should be taken into account. Very important are also errors in the forward models used to connect structures obtained in MD simulations with experiments since these errors are often larger than those of the raw data. Errors in the quantum chemistry calculations should be quantified as well.Reference data should be obtained in conditions as realistic as possible. One should carefully consider the conditions in which experiments are carried out and prefer experiments performed in conditions that can be reproduced in MD simulations. Ideally, specific experiments might be designed and performed in order to facilitate force field development, such as solution experiments on systems small enough to allow ergodic sampling but large enough to provide transferable information. When instead basing the fits on quantum chemistry calculations, one should consider the importance of the solvent. Additionally, errors in the experimental data should be taken into account. Very important are also errors in the forward models used to connect structures obtained in MD simulations with experiments since these errors are often larger than those of the raw data. Errors in the quantum chemistry calculations should be quantified as well.</p>
        <p>Taking inspiration from the machine learning community, it is fundamental to understand how to avoid overfitting. In particular, overfitting on specific systems should be avoided, and this can be achieved by including as heterogeneous as possible systems in the dataset. Similarly, overfitting should be avoided on specific trajectories. To this end, separate validation simulations can be run or robust estimates of the statistical errors can be pursued. Regularization terms can be used to tune model complexity, thus reducing the impact of overfitting. Validation should be made on data that are obtained in an as independent as possible manner.Taking inspiration from the machine learning community, it is fundamental to understand how to avoid overfitting. In particular, overfitting on specific systems should be avoided, and this can be achieved by including as heterogeneous as possible systems in the dataset. Similarly, overfitting should be avoided on specific trajectories. To this end, separate validation simulations can be run or robust estimates of the statistical errors can be pursued. Regularization terms can be used to tune model complexity, thus reducing the impact of overfitting. Validation should be made on data that are obtained in an as independent as possible manner.</p>
        <p>Finally, the current functional form [Eq. ( 1)] might be too limited to be usable on a wide range of cases. Increasing the complexity of the model might help in this respect. Complexity can be introduced by physical insight (e.g., explicitly polarizable force fields 23,24 or modified Lennard-Jones potentials 56 ) or by blind learning of nonlinear models (e.g., neural network potentials 57,58 ). Nonetheless, one should keep in mind that whenever complexity is increased, overfitting has more chance to appear. In this respect, for a fixed number of parameters, the more physical the functional form, the less it will tend to overfit. Interestingly, neural networks are now routinely used to fit bottom up potentials where the training data can be generated by computational methods and can then be easily made very abundant. [57][58][59][60] These approaches are however typically designed to be trained on very small systems or chemical groups, and their applicability to macromolecular systems has not been shown yet. It is thus still to be seen if neural network potentials can be used fruitfully when force fields are directly fitted on experimental data.Finally, the current functional form [Eq. ( 1)] might be too limited to be usable on a wide range of cases. Increasing the complexity of the model might help in this respect. Complexity can be introduced by physical insight (e.g., explicitly polarizable force fields 23,24 or modified Lennard-Jones potentials 56 ) or by blind learning of nonlinear models (e.g., neural network potentials 57,58 ). Nonetheless, one should keep in mind that whenever complexity is increased, overfitting has more chance to appear. In this respect, for a fixed number of parameters, the more physical the functional form, the less it will tend to overfit. Interestingly, neural networks are now routinely used to fit bottom up potentials where the training data can be generated by computational methods and can then be easily made very abundant. [57][58][59][60] These approaches are however typically designed to be trained on very small systems or chemical groups, and their applicability to macromolecular systems has not been shown yet. It is thus still to be seen if neural network potentials can be used fruitfully when force fields are directly fitted on experimental data.</p>
        <p>See the supplementary material for a table reporting more details about the methods used to obtain parameters in the most common biomolecular force field.See the supplementary material for a table reporting more details about the methods used to obtain parameters in the most common biomolecular force field.</p>
        <p>Published under license by AIP PublishingPublished under license by AIP Publishing</p>
        <p>Sandro Bottaro, Lillian Chong, and Andreas Larsen are acknowledged for carefully reading the manuscript and providing useful suggestions. Max Bonomi is greatly acknowledged for carefully reading the manuscript and reporting enlightening feedbacks.Sandro Bottaro, Lillian Chong, and Andreas Larsen are acknowledged for carefully reading the manuscript and providing useful suggestions. Max Bonomi is greatly acknowledged for carefully reading the manuscript and reporting enlightening feedbacks.</p>
        <p>Data sharing is not applicable to this article as no new data were created or analyzed in this study.Data sharing is not applicable to this article as no new data were created or analyzed in this study.</p>
        <p>The Journal of Chemical Physics PERSPECTIVE scitation.org/journal/jcpThe Journal of Chemical Physics PERSPECTIVE scitation.org/journal/jcp</p>
    </text>
</tei>
