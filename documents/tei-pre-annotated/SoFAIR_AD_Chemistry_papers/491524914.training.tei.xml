<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T10:12+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>Supplementary Fig. 1: The bootstrap DIA workflow. This sequence of algorithmic steps is applied to each DIA sample vs. the whole library. A matching step is usually followed by a step in which a calibration function (e.g. precursor m/z recalibration function) is determined from the matches found in the previous step. Then constraints (e.g. m/z deviation windows) are updated for the next round of matching. The DDA samples constituting the library are assumed to be retention time (and ion mobility if applicable) aligned to each other. a, The first matching from the library spectra to the DIA sample is performed with initial m/z windows for precursor and fragments of 20 p.p.m. by default and without restrictions on retention times or collision cross sections. b, Based on these matches, a linear recalibration is calculated to adjust for different total gradient lengths of library and DIA samples. c, After the linear retention time calibration has been calculated and applied, a time window is calculated from the data, which defines the allowed retention time difference for the next step. d, The second matching still uses the initial m/z windows and in addition uses the time window determined in the previous step. e, Based on the matches of the previous step a linear precursor m/z shift in p.p.m. between the DIA sample and calculated peptide masses is determined. f, Similarly, a fragment m/z shift is calculated from the data. g, Next, precursor and fragment m/z tolerances are calculated based on the distributions of m/z differences between DIA sample and theoretically calculated masses. h, The third matching uses adapted m/z and retention time windows which are applied to the linear calibrated data. i, The elimination of noise achieved by the adapted tolerances used in the matching in the previous step allows now to perform nonlinear retention tine calibration. j, A time dependent nonlinear allowed region is determined from the data. k, The fourth matching uses more stringent retention time constraints than the third matching, since it is applied to nonlinear calibrated data. l, Now a nonlinear calibration of precursor m/z values is determined from the data. This is done in a multivariate way, with a model for the mass error depending at least on m/z and retention time. For TOF data an intensitydependent component is added and for timsTOF data another component depending on 1/K0. This is similar to the 'software lock mass' calibration in the DDA MaxQuant workflow. m. Similarly, fragment m/z are nonlinear recalibrated. n, New, more stringent precursor and fragment m/z tolerances are calculated from the distributions of mass errors. o. Another matching step with updated constraints is performed. p, A linear function for the recalibration of CCS values is calculated from the data, in case of ion mobility spectrometry. q, A tolerance window for the acceptance of CCS value deviations is calculated. r, A matching round with constraints on the CCS values is performed. s, A nonlinear CCS calibration function is determined. t, CCS tolerance is adapted to the nonlinear calibrated data. u, The final round of matching is performed without constraints on retention time and CCS values. Instead, these deviations are used as features in the XGBoost-based machine learning. Precursor and fragment masses are still filtered with hard windows for the deviations. are stacked on top of each other. A single run of the HepG2 Orbitrap dataset (DIA_13.raw) was used. a, Score histogram after the first matching step. (Step a in Supplementary Fig. 1.) No constraints on the retention time are used. Initial tolerances of 20 p,p,m. are applied to precursor and fragment mass matches. The spikes at integer score values correspond to matches in which all matching fragments hit exactly the apex of the peak in retention time direction. The peaks from one to four matching fragments are dominated by false positives, since these bins have half or even more decoy hits. Score values of six or above indicate correctness of the match since decoy hits are strongly suppressed. b, Score histogram after the second matching step. (Step d in Supplementary Fig. 1.) Retention time is filtered after linear retention time calibration between library and DIA sample and after determining a tolerance from the distribution of retention time differences. c, Score histogram after the third matching step. (Step h in Supplementary Fig. 1.) Linear ppm shifts are applied to precursor and fragment masses and mass tolerances are adapted accordingly. Scores larger than four indicate few false positives, d, Score histogram after the fourth matching step. (Step k in Supplementary Fig. 1.) e, Score histogram after the fifth matching step. (Step o in Supplementary Fig. 1.) in which nonlinear mass recalibrations have been applied to the data. f, Each profile shows the rate of false positive matches after each of the five different matching steps. The numbers are derived from the bins at integer values in the histograms of the previous panels. g, After all recalibrations have been applied, the final matching is done without constraints on retention times, but the mass constraints are kept. (The corresponding score distribution is displayed.) Instead the deviation from the calibrated retention time is offered as a feature to the machine learning for calculating an enhanced score. This strategy (hard mass cutoffs and soft, machine learning based, retention time cutoff) resulted in the highest number of identifications. Similarly, a soft cutoff is used for collision cross sections in ion mobility spectrometry data. Supplementary Fig. 7: Scoring library spectra against DIA samples. a, Libraries are collections of DDA samples analyzed with MaxQuant. MS/MS spectra from the library are first sub-divided into unique peptide-charge-modification combinations. Each such combination that has assigned more than one MS/MS spectrum to it is then clustered into retention time clusters. Prerequisite for this is that all library samples are retention-time aligned to each other. The idea is that if a peptide is eluting at more than one place in a gradient, it will be stored as multiple instances in the library with different retention times. This is feasible, since from the MaxQunat DDA analysis it is known how the peptides elute from their MS1 features. For data with ion mobility spectrometry this kind of library feature clustering is done in the two-dimensional space consisting of retention times and collision cross sections. A resulting cluster may still contain more than one MS/MS spectrum. In that case, the one with the highest Andromeda score is chosen. This spectrum is then filtered to the top-N most intense fragment peaks. These are then scored against the DIA sample. By default, is N = 7. We visit each retention time in a DIA LC-MS run and calculate the score which is defined below. The matching position is defined as the retention time at which the highest score is achieved. This highest value of the score is also defined as the matching score of this library spectrum to the DIA sample. For ion mobility spectrometry, this score maximization takes place in the two-dimensional space of all retention time and ion mobility value pairs. b, For calculating the score of a library spectrum at a certain retention time (and CCS value) in the DIA sample, one first searches with a given mass tolerance for 3D/4D features that match the precursor and the N (typically = 7) top fragment peaks. For each spectrum mass that matches a feature in the DIA sample we calculate the apex fraction which is the ratio of the intensity at the current retention time to the maximum peak intensity. To obtain the score, we sum up the apex fractions for the precursor (in case one was matched) and the matching fragments. c, So far the scoring was done independently for each consolidated library spectrum. This can lead to multiple usages of a DIA feature in several library matches. d, To prohibit overinterpretation, we perform a second round of scoring. This time we put the library spectra in descending order according to the score they achieved in the first round of scoring. The same procedure is repeated, but now it is remembered which features in the DIA sample (precursors and fragments) have already been assigned and these will be prohibited from being assigned a second time. Note that an MS1 precursor match is not required but contributes the same way to the total score as each fragment does. before filtering for the top intense peaks. Feature 15 is explained in panel c. Feature 19 quantifies how close to its apex the precursor was hit. Feature 22 defines if the precursor was found in the MS1 data and feature 23 specifies whether an isotope pattern was seen. Features 24 and 25 quantify how close the peptide m/z is to the edges of the isolation window. b, Machine learning features derived from fragments. Feature 1 quantifies how close to its apex the fragment was hit. Feature 4 defines if the fragment was found and feature 5 specifies whether an isotope pattern was seen for it. By default, 7 top intense fragments are considered for identification which results in a 25 + 7 * 5 = 60 dimensional feature space in total. c, Explanation of the fragment overlap feature. The first peptide has a fragment overlap of 0 since the y and b ion series are not overlapping. The second peptide has overlapping y and b series and hence is its fragment overlap greater than 0. d, List of the top 10 features ranked by importance according to XGBoost 'gain'. Even more important than the score is whether the precursor had an isotope pattern or is a single feature. Interestingly, the absence or presence of the MS1 precursor did not make it into the top ten most relevant features. e, Log-log scatter plot of feature importance according to XGBoost 'gain' for library against discovery mode. To guide the eye, we drew a straight line from the cloud of non-important features in the lower left corner to the raw score, which is expected to be of high relevance for the classification. Whether the precursor feature has an isotope pattern became much less important in the discovery mode. Features that are correlated with peptide length and charge became more important in discovery mode, presumably since the length and charge distributions of predicted spectra in the in silico library are significantly different from these distributions for peptides that are detectable in the DIA samples. Supplementary Fig. 9: Comparison between different classification methods. We compared XGBoost, random forests, AdaBoost and fully connected multi-hidden layer neural networks to using the raw score. We tuned meta-parameters to its optimal value if applicable. a, ROC curves for the five classification methods. XGBoost has the highest area under the curve. b, Number of identified peptides when using each of the four classification Methods or the raw score in MaxDIA. XGBoost results in the highest number of peptide identifications. c, Number of identified protein groups when using each of the four classification Methods or the raw score in MaxDIA. XGBoost results in the highest number of peptide identifications. d, Optimal values of classification algorithm parameters found in grid searches. hybrid MS1-MS2.) c, Distributions of retention times of peptides identified by MaxDIA and Spectronaut. d, Distributions of precursor mass-to-charge ratios of peptides identified by MaxDIA and Spectronaut. e, Distributions of precursor mass errors in p.p.m. of peptides identified by MaxDIA and Spectronaut. f, Distributions of charges of peptides identified by MaxDIA and Spectronaut. g, Detailed comparison of identification results between MaxDIA, Spectronaut 13 and Spectronaut 14. For the latter we tested the impact of changing a set of parameters one by one from their default values on the result. In particular, we used the inverse database, we set profiling strategy to 'on' and we used 10 precursors and 10 peptides. None of these settings had a major impact on the results or changed the overall conclusions. Supplementary Fig. 12: MaxLFQ algorithm for DIA. The conventional MaxLFQ algorithm for DDA consists of two parts, feature intensity normalization and protein quantification. While in the adaptation to DIA the normalization part did not change, the quantification was adapted to accommodate signals contributing from precursor and fragment features. a, As an example we use the protein sequence of UniProt entry P07327. Three peptides were identified, Peptide 1, unmodified with charge 2 and 3, Peptide 2, unmodified and with an oxidation of methionine, and Peptide 3, only unmodified with charge 2. These five peptide, charge and modification combinations are treated as independent intensities in the protein quantification, as was already the case in the DDA version of MaxLFQ. In DIA, also the different types of ions, precursors and fragments, are treated as separate signals. Feeding these as independent 'channels' into MaxLFQ is a natural way of implementing hybrid precursor-fragment quantification. For every combination of peptide, charge and modifications, we take the top N intense fragment peaks over the whole dataset. These N annotations are then used in every spectrum of this type for quantification. In the example we chose N = 3 for simplicity, although N is a userdefinable parameter and much larger by default. (See Supplementary Fig. 13a for the influence of N on the quantification accuracy.) b, In the example from panel a with five peptide-charge-modification combinations and N = 3 we end up with 20 peptide-chargemodification-ion combinations. We assume that data for four samples was acquired. Then we have for this protein 20 intensity profiles over the four samples. Those intensities in this matrix which are zero we call missing, since they cannot be used for calculating ratios between samples. c, Next we calculate protein ratios between all pairs of samples to fill the lower triangular matrix indicated in the figure. 'Ratio 2,1' is the median of all ratios calculated from the intensities in the columns 'Sample 1' and 'Sample 2' in panel b. These are 20 if all values are present but can be less due to missing values. If the number of peptide-charge-modification combinations for which ratios can be calculated is less than the parameter 'LFQ min. ratio count' the corresponding ratio in the triangular matrix will be missing. d, For each ratio in panel c that is not missing we obtain one equation for the determination of the four LFQ intensities. (One for each sample.) This system of equations is usually over-determined and a least-squares best fit is obtained. e. Result of this operation is the profile of non-negative LFQ intensities over the four samples.</p>
        <p>to Entrez gene identifiers. For the Avant-garde results taken from the publication, the median was taken over all peptide-level logarithmic ratios that were mapped to a gene identifier. All ratios were globally normalized such that the median of all the human log ratios is at zero. All box plots indicate the median and the first and third quartile as box ends. Whiskers are positioned 1.5 box lengths away from the box ends. a, Gene level ratios derived from the peptide-level ratios provided in the Avant-garde publication as a function of log(Intensity). 18 sub-populations of proteins (genes) exist with a defined expected ratio. Several outlier ratios are present at large deviations and some of the sub-populations show systematic trends with Log(Intensity). b, Same as in panel a but for MaxLFQ ratios. c, Comparisons of performance measures between Avant-garde and MaxDIA results. For all 18 sub-populations. The population-wise standard deviations are about half as low in MaxQuant results for the H. sapiens ratios. For the S. cerevisiae ratios tend to have a lower standard deviation with Avant-garde while there is no clear trend in the standard deviations of the E. coli ratios.</p>
        <p>You can now start your analysis.</p>
        <p>Supplementary Fig. 2: Score distributions along the bootstrap DIA workflow. Histograms of score distributions, separately for target and decoy hits after the different matching steps in the bootstrap DIA workflow. Target (blue) and decoy (red) distributions Supplementary Fig. 3: Nonlinear m/z recalibration of precursors. One consequence of the bootstrap DIA is that masses of precursors and fragments are nonlinearly recalibrated against theoretically calculated molecule masses. This replaces the software lock mass strategy used in DDA 
            <rs type="software">MaxQuant</rs>, which is based on a 'first search' with the Andromeda search engine to produce the recalibration curves. We use the same data as in Supplementary Fig. 2 to compare mass errors before and after recalibration. In all panels, data points are color coded according to the conditional data density. For this, the bivariate density of data points is divided by the marginal distribution on the x-axis. Blue signifies the region of highest conditional density. In order to study the sensitivity of identification results in discovery mode towards the machine learning algorithm used for predicting the MS/MS spectra, we repeated all calculations using the predictions of two other state of the art prediction models, winner and PROSIT, both used with default settings. In PROSIT the optimal collision energy was determined and found to be 32. Instructions for preparing in-silico libraries with 
            <rs type="software">DeepMass</rs>:
            <rs type="software">Prism</rs>, winner and PROSIT can be found at https://github.com/cox-labs/DIAtools/blob/main/Misc/MLprediction/README.md#MLprediction. a, Comparison of results on gene level. For better comparability, we mapped the identified protein groups of the three approaches to Entrez gene identifiers. The vast majority of genes (protein groups) has been identified in all three approaches with a very slight lead in the collision energy-aware PROSIT identifications. b, Same as a but with comparison on the peptide level. Supplementary Fig. 13: Optimization of number of top fragments and peptides. a, Summed inter-quartile ranges for the four-species benchmark dataset by Bruderer et al. as a function of the number of top intense fragments used for quantification. The accuracy is increasing with rising number of fragments and plateauing around seven fragments after which no noticeable improvement happens. The default value of 0.3 was used for the transfer q-value. b, Same as in panel a but optimizing the number of top intense peptides used for quantification. The more peptides are taken, the higher is the quantification accuracy. c, Same as in panels a and b but filtering for top 3 intense peptides and top 3 intense fragments simultaneously. Supplementary Fig. 14: Comparison to Avant-garde filtered quantification. In order to judge how the accuracy of protein quantification with MaxLFQ for DIA compares to methods that explicitly filter the data for interfered transitions we use a dataset from Vaca Jacome et al. (Nature Methods, 2020) called 'Extended benchmarking DIA dataset' in the publication. There it was analyzed with the Skyline software and curated by Avant-garde. We analyzed the same data with MaxDIA and for comparison mapped MaxLFQ intensities Supplementary Fig. 15: Scanning through values for the transfer q.value. We analyzed the Bruker timsTOF pro three-species benchmark data using a range of values for the transfer q-value between 0.01 and 1. We provide summed inter-quartile ranges of speciesspecific ratio distributions as a measure of variability. Summed absolute errors are the deviations of the expected value for each species. The box plots are based on the numbers of data points given in the tables below the respective plot (Valid LFQ ratios). All box plots indicate the median and the first and third quartile as box ends. Whiskers are positioned 1.5 box lengths away from the box ends. Supplementary Fig. 16: Single-shot BoxCar samples. a, Venn diagram of protein identifications mapped to Entrez gene identifiers for the single shot BoxCar DIA samples using three different library approaches. In particular, comparing protein identifications between fractionated library and discovery approach shows good agreement of results. b, Same as in panel a but comparing peptide-level identifications. c, Venn diagram-like comparison of replicate-specific identifications in the fractionated BoxCar DIA samples analyzed in discovery mode. Only very few protein groups were not identified in all three replicates. Supplementary Fig. 17: Dependence of identifications on the number of fractions. a, DIA samples were fractionated into one, two, four and eight fractions and analyzed with single-shot, fractionated and discovery library, similarly as in Figure 6. The number of identified protein groups is indicated for each of these cases. While the number of protein groups is not increasing much with the fractions when using a single shot library, there is a linear increase with the discovery library. b, Same as a but showing the number of identified peptides.
        </p>
        <p>Summary: In order to enable MaxDIA for your DIA runs, after loading your mass spectrometry output data (raw data) into MaxQuant and setting your experiment design and the number of threads you'd like to utilize for your MaxQuant run, you can select either "Max DIA", "TIMS MaxDIA" or "BoxCar MaxDIA" from the "Type" menu within the "Group-specific parameters". Doing so will bring up a menu where you can specify your library files. These files include the peptide, evidence and msms text files from your DDA MaxQuant runs.</p>
        <p>Note: To be able to run 
            <rs type="software">MaxQuant</rs>, 
            <rs type="software">.NET</rs> Core 2.1 needs to be installed. Please visit https://dotnet.microsoft.com/download/dotnet-core/2.1 and install the SDK x64."
        </p>
        <p>Steps:</p>
        <p>1. Using your internet browser, navigate to https://maxquant.org/ 2. Click on the blue "Download" button to navigate to the download form.</p>
        <p>Summary: Running MaxDIA in discovery mode is identical to the library mode in every step except for the library files used (step 13 of library mode). Use in silico generated library files to run MaxDIA in discovery mode and the relevant FASTA files. Follow the steps below to download in silico libraries for most common species.</p>
        <p>Steps:</p>
        <p>1. Navigate to http://annotations.perseus-framework.org/.</p>
        <p>2. Click on "DiscoveryLibraries".</p>
        <p>Summary: The PRIDE database has two main types of submissions "Complete Submission" and "Partial Submission". The main different between both types of submissions is that in Complete Submissions the results (e.g. peptide and protein Summary: To make a complete Pride submission, you should download the submission tool from ProteomeXchange and follow the steps.</p>
        <p>Steps:</p>
        <p>1. Navigate to http://www.proteomexchange.org/submission/index.html.</p>
        <p>2. Download the submission tool and extract the contents of the zip file. Make sure to have java installed on your PC. The latest version of java can be downloaded and installed from https://www.java.com/en/download/.</p>
        <p>3. Double click on the jar file or refer to the README file for instruction on running the tool from the command line. Follow the steps accordingly. 4. After adding the title, sample and protocol description in the first two panels of the ProteomeXchange submission tool, the user will arrive to a panel where files should be provided:</p>
        <p>For MaxDIA Complete submissions the following files should be provided:</p>
    </text>
</tei>
