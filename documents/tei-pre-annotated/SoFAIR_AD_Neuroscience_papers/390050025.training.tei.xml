<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T16:29+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>Network meta-analysis (NMA) compares several interventions that are linked in a network of comparative studies and estimates the relative treatment effects between all treatments, using both direct and indirect evidence. NMA is increasingly used for decision making in health care, however, a user-friendly system to evaluate the confidence that can be placed in the results of NMA is currently lacking. This paper is a tutorial describing the Confidence In Network Meta-Analysis (CINeMA) web application, which is based on the framework developed by Salanti et al (2014, 
            <rs type="software">PLOS One</rs>, 
            <rs type="version">9</rs>, e99682) and refined by Nikolakopoulou et al (2019, 
            <rs type="software">bioRxiv</rs>). Six domains that affect the level of confidence in the NMA results are considered: (a) within-study bias, (b) reporting bias, (c) indirectness, (d) imprecision, (e) heterogeneity, and (f) incoherence. CINeMA is freely available and open-source and no login is required. In the configuration step users upload their data, produce network plots and define the analysis and effect measure. The dataset should include assessments of study-level risk of bias and judgments on indirectness. CINeMA calls
        </p>
        <p>the netmeta routine in R to estimate relative effects and heterogeneity. Users are then guided through a systematic evaluation of the six domains. In this way reviewers assess the level of concerns for each relative treatment effect from NMA as giving rise to "no concerns," "some concerns," or "major concerns" in each of the six domains, which are graphically summarized on the report page for all effect estimates. Finally, judgments across the domains are summarized into a single confidence rating ("high," "moderate," "low," or "very low"). In conclusion, the user-friendly web-based CINeMA platform provides a transparent framework to evaluate evidence from systematic reviews with multiple interventions.</p>
        <p>Network meta-analysis (NMA) is increasingly being used to make decisions about optimal interventions in health care (Kanters et al., 2016;Petropoulou et al., 2016). It combines direct evidence from studies that directly compare two or more interventions, and indirect evidence from studies that indirectly inform a comparison through intermediate comparators. To evaluate the confidence in the results of NMA, a framework has been developed (Salanti, Del Giovane, Chaimani, Caldwell, &amp; Higgins, 2014) and recently refined</p>
        <p>domains that affect the level of confidence in the NMA results: (a) within-study bias, (b) reporting bias, (c) indirectness, (d) imprecision, (e) heterogeneity, and (f) incoherence. Reviewers assess the level of concerns for each relative treatment effect from NMA as giving rise to "no concerns," "some concerns," or "major concerns" in each of the six domains. Then, judgments across the domains are summarized into a single confidence rating ("high," "moderate," "low," or "very low").</p>
        <p>The six domains include considerations pertaining to all stages of the systematic review, including literature search, data extraction, and statistical analysis. Within-study bias domain refers to limitations in the individual studies that may lead to a biased estimated relative treatment effect. Reporting bias results from the inclusion in the systematic review of a nonrepresentative set of the eligible studies, that may occur for example from an uncomplete literature search.</p>
        <p>Indirectness refers to the relevance of the included studies to the research question, which includes the definition of the population, interventions, and outcomes of interest. A core assumption in NMA is that of transitivity; that there is an underlying true relative treatment effect which applies to all studies regardless of the treatments being compared. Assessment of transitivity is challenging and is usually done by exploring the distribution of effect modifiers per comparison. CINeMA's approach for indirectness intends to also address the assumption of transitivity by indicating which comparisons may suffer from different definitions of the setting of interest. Assuming that transitivity holds implies that consistency-which refers to the agreement of the estimated treatment effects-also holds. This can be assessed under the incoherence domain in CINeMA. Finally, imprecision and heterogeneity domains refer to the certainty with which each effect is estimated and the variability in the results of studies contributing to each comparison respectively.</p>
        <p>The CINeMA framework has been implemented in a userfriendly web application (see 
            <rs type="url">https://cinema.ispm.unibe.ch/</rs>; CINe-MA, 2017). From a technical point of view, CINeMA is a single page application which communicates to an 
            <rs type="software">R</rs> back-end server; in particular, the packages meta and 
            <rs type="software">netmeta</rs> are used (Rücker, Schwarzer, Krahn, &amp; König, 2016;Schwarzer, 2019). It is developed as a custom functional reactive framework and written in JavaScript and PureScript. CINeMA does not permanently store the data, or any other information related to the uploaded projects; only temporary storage takes place for the sake of the calculations or network efficiency. The source code of CINeMA can be found in (Papakonstantinou).
        </p>
        <p>The methodology described in (Nikolakopoulou et al., 2019) has been implemented in CINeMA using "rules" that can automate derivation of domain-specific judgments. Three rules can be used to summarize the risk of within-study bias and of indirectness for each relative effect estimate and produce automated judgments. Two levels of judgment for reporting bias are suggested, based on completeness of the literature search, empirical studies, and statistical analyses. The rules for judging imprecision and heterogeneity are based on whether the confidence interval or prediction interval includes the line of no-effect and prespecified clinically important treatment effects. The use of rules is optional, and the outputs can be partially or fully overridden. However, the semiautomated process helps researchers to form judgments. Early applications of CINeMA have appeared in the literature (Cipriani et al., 2018;Schwingshackl et al., 2018).</p>
        <p>Here we provide a tutorial describing the functionality of CI-NeMA. We explain how the software works, the data formats and requirements, the default options implemented in the rules, and their rationale. We describe the functionality of CINeMA and illustrate its use with the example of a NMA that compared the incidence of diabetes in patients taking antihypertensive drugs or placebo. The network included 22 randomized trials which evaluated the differences between angiotensin-converting-enzyme inhibitors (ACE), angiotensin-receptor blockers (ARB), calcium-channel blocker (CCB), Beta Blocker, diuretics, and placebo. The NMA found that the risk of diabetes was lower with ARB, and higher with diuretics than with placebo (Elliott and Meyer, 2007). In this example, data on study- It might be that summary data are not available for each intervention group for each study. In this situation data can be imported in "inverse variance" format, where a comparison-specific estimate of the relative treatment effect (assumed to follow a normal distribution) and its standard error are reported (e.g., log odds ratios, standardized mean differences, etc., see Table 2). When the "inverse variance" format is used, CINeMA will prompt the user to define whether the outcome is binary or continuous. Users should choose one of the five data formats in Tables 1 and2. The names of variables can be as in Tables 1 or 2 (in which case CINeMA will automatically recognize which column refers to which variable) but custom field names are also allowed (e.g., "events" instead of "r" for number of events in Table 1a). If custom field names are used, CINeMA will prompt the user to specify which column represents which field after uploading the dataset. Once the procedure is done (or directly after uploading the data, if variable names are exactly as in Tables 1 or 2), information on the file format (long, wide), outcome type (binary, continuous), number of studies, number of interventions, and number of comparisons with direct evidence appears. Renaming the project's title is also possible under "Rename."</p>
        <p>Then, users can click on "Proceed" to go to "Configuration."</p>
        <p>Uploading the network of antihypertensive drugs, CINeMA recognizes the file format (long) and outcome type (binary) and provides summary of the dataset: it includes 22 studies, 6 interventions, and 14 comparisons with direct data.</p>
        <p>The "Configuration" tab is activated once the dataset has been uploaded and variable names have been successfully defined. In this tab the user needs to define the NMA analysis and is presented with a network plot. This page also allows users to evaluate only a subset of all possible intervention comparisons.</p>
        <p>The network plot corresponding to the uploaded dataset is automatically drawn with equally sized nodes and edges. Users can choose to weight nodes and/or edges according to the sample size or the number of studies (under "Node size by" and "Edge width by").</p>
        <p>T A B L E 1 Examples of four possible data formats that can be used as input to CINeMA Nodes can either be all blue or colored according to the proportion of studies with low (green), moderate (yellow), and high (red) RoB or indirectness (under "Node color by"). "Edge color by" dropdown menu allows coloring edges according to the most prevalent bias level within each comparison ("Majority RoB"), the average RoB of the included studies ("Average RoB"), or the maximum bias level within each comparison ("Highest RoB"); the respective categories for indirectness are also available ("Majority Indirectness," "Average Indirectness," "Highest Indirectness"). Different representations may be chosen according to users' interests: for example, "Highest RoB"</p>
        <p>or "Highest Indirectness" could be chosen when users are interested in viewing the worst pieces of evidence feeding into each compar-"Save Plot" button. The outcome data appear next to the network plot. By clicking on a specific edge or node, the respective outcome data corresponding to that edge or node appear on the data table.</p>
        <p>Here users are asked to choose whether to perform a fixed effect or a random effects NMA (under "Analysis model") and to define effect measure type (under "Effect measure"). For binary outcomes, the options "Odds Ratio," "Risk Ratio," and "Risk Difference" will appear, and for continuous outcomes the options "Mean Difference" and "Standardized Mean Difference."</p>
        <p>An NMA that compares several interventions produces estimates for all possible relative effects. However, it can be the case that not all of them are of interest (e.g., comparisons between placebo and older drugs that are no longer used). CINeMA offers the option to select A list of the comparisons to be evaluated then appears. Note that the analysis is performed using all studies irrespective of whether a subset or all comparisons are evaluated.</p>
        <p>After defining the comparisons for evaluation, the "Set up your evaluation" button appears. Clicking on this performs two actions.</p>
        <p>First, it calls 
            <rs type="software">netmeta</rs> in R to estimate all relative effects from the network and a common heterogeneity parameter. The relative effects are found in the league table, which can be downloaded and saved as a .csv file ("Download league table "). Second, it calls an R function that calculates the contribution matrix (Papakonstantinou).
        </p>
        <p>The contribution matrix shows the percentage contribution of information from each study and each direct comparison (shown in columns) to the estimation of each relative effect (shown in rows). It is calculated using the flow decomposition method described in (Papakonstantinou et al., 2018) and is used later in the evaluation of within-study bias and indirectness. Users can download the output in .csv format using options "Download per study contribution matrix" or "Download per comparison contribution matrix."</p>
        <p>During evaluation, the user can abort computations by pressing the "Cancel" button. Once calculations are done, the "Reset your evaluation" button deletes all previous choices and computations.</p>
        <p>"Proceed" saves the analysis (CINeMA will remember choices made so far in the case of refreshing or closing and revisiting the page) and takes users to the "Within-study bias" domain.</p>
        <p>The results of selecting different options for weighting the network plot are shown in Figure 1. In the "Define your analysis" section, we select a "Random effects" model and "Odds Ratio" as the effect measure to be analyzed. We select all interventions to be evaluated; note that in this case there is no difference between choosing "Containing any of the above interventions" and choosing "Between the above interventions." Table 3 shows the downloaded league table; per comparison and per study contribution matrices are given in Appendix Tables A1 andA2. and "Highest RoB." Choosing "Majority RoB" will lead to a level of concern according to the RoB with the greatest total percentage contribution (the greatest block between green, yellow, and red in each bar). The "Highest RoB" will assign a level of concern determined by the highest RoB in each bar. Summarizing RoB assessments using "Average RoB" uses a weighted average score for each relative effect estimate according to the percentage contribution of studies at each bias level. For example, if the contributions from low (arbitrarily assigned a score of 1), moderate (score 2), and high (score 3) RoB studies are 40%, 25%, and 35% respectively, the total RoB score will be × + × + × = 0.40 1 0.25 2 0.35 3 1.95 which rounds to 2 and leads to "Some concerns." In this example the judgment for "Majority RoB" would be "No concerns" and for "Highest RoB" would be "Major concerns."</p>
        <p>After selecting a rule, the boxes under the dropdown menu-which correspond to the each estimate of relative effects-are colored according to the level of concern, and judgments under each of the three rules are also given in the boxes. Manual change of judgments independently of the applied selection rule is possible; if a judgment is manually changed, the corresponding box is colored gray. "Reset" (the chosen rule) and "Proceed" (to "Reporting bias") buttons also appear.</p>
        <p>Figure 2 shows the bar chart for the worked example. Studies at low RoB contribute 53% in the estimation of ACE versus Beta Blockers, 43% of the contribution comes from studies at moderate RoB, and studies at high RoB contribute the remaining 4%. These RoB contributions resolve into "No concerns," "Some concerns," and "Major concerns" using the "Majority RoB," "Average RoB," and "Highest</p>
        <p>RoB" rules respectively. Figure 3 shows the boxes that appear in the software showing the judgments for all relative effects.</p>
        <p>The "Reporting bias" domain refers to biases that can occur due to To facilitate assessment of each effect separately, users can initially "Set all undetected" or "Set all suspected." They can then change the judgment manually for those estimates that do not fall into the category initially assigned. Note that a manual change from "Suspected" to "Undetected" and vice versa is not considered a deviation from the rule (and relevant boxes are not colored gray) as no rule for reporting bias is implemented. "Reset" and "Proceed" (to the "Indirectness" domain) buttons appear after initial population of judgments. We plan to develop the "Reporting bias" domain of CINeMA further in the months and years to come.</p>
        <p>For the indirectness domain, similar to "Within-study bias," the summary shows how many studies have been characterized as of low, moderate, and high indirectness at the top of the page. Subsequently, a bar graph shows the contribution of studies at each indirectness level to each NMA estimate. As for the "Within-study bias" domain, users can select between "Majority," "Average," and "Highest" rules to summarize indirectness for each relative effect estimate. Areas are colored accordingly, while judgments under each rule are shown in the boxes. Manual changes can be made, and "Reset" and "Proceed" (to the "Imprecision" domain) buttons appear.</p>
        <p>In that favored by the point estimate, "Major concerns" is assigned (Figure 4a). If only the null effect is included in the confidence intervals (and potentially also the clinically important value that favors the same intervention as the point estimate), "Some concerns" is assigned. Finally, "No concerns" is assigned to confidence intervals that only include the clinically important value that favors the same intervention as the point estimate. If the confidence interval lies entirely between the two clinically important values, "No concerns" is assigned (Figure 4a).</p>
        <p>After defining the clinically important size of effect, the boxes of the relative treatment effects appear colored according to the default rules described above. Boxes display the 95% (Wald-type) confidence intervals of the NMA effect, a description of its relation to the clinically important effects, and the judgment, which can be manually altered. Users can also reset the definition of the clinically important size of effect and/or the imprecision judgments with the relevant buttons. The "Proceed" button leads the user to the "Heterogeneity" domain.</p>
        <p>For illustration, we choose an odds ratio of 1.2 as clinically important and CINeMA informs us that "relative effect estimates below 0.83 and above 1.2 are considered clinically important." The confidence interval for the comparison between diuretics and placebo ranges from 1.12 to 1.57, which corresponds to case 3 Figure 4a. The automatically generated judgment is "No concerns" and the explanation reads "Confidence interval does not cross clinically important effect."</p>
        <p>The importance of heterogeneity depends on the variability of effects (beyond chance) in relation to the clinically important size of effect.</p>
        <p>The clinically important size of effect is the same as in "Imprecision";</p>
        <p>if already specified it will automatically appear on the top of "Heterogeneity." Otherwise, users need to specify it here; if this is the case, it will also be copied to the "Imprecision" domain. Users can press "Reset" to reset the clinically important effect size; note that this will affect the "Imprecision" domain too.</p>
        <p>CINeMA considers the agreement between confidence and prediction intervals to assign a judgment for "Heterogeneity" for each NMA effect. Prediction intervals provide a range within which the true effect of a new study is likely to lie (Riley, Higgins, &amp; Deeks, 2011) Boxes for each relative treatment effect are then updated to include between-study heterogeneity measures based on direct comparisons (I 2 and τ 2 ) and reference values for τ 2 (first quantile, median, and third quantile). The reference quantiles are taken from empirical studies and are specific to the type of outcome and comparison (Rhodes, Turner, &amp; Higgins, 2015;Turner, Davey, Clarke, Thompson, &amp; Higgins, 2012).</p>
        <p>Reference quantiles that are lower than the estimated direct τ 2 appear in black digits and reference values greater than the estimated τ 2 appear in gray digits. The comparison with the reference values does not affect judgments. However, their critical appraisal may lead to changing the automatically generated judgments manually. boxes are updated to include extra information on heterogeneity (Turner et al., 2012). Figure 5 shows the box that appears in the software referring to the comparison of beta blockers with placebo.</p>
        <p>The range of clinically important effects is also considered in the "Incoherence" domain; resetting it using the "Reset" button will et al., 2013;Dias, Welton, Caldwell, &amp; Ades, 2010;Higgins et al., 2012;White, Barrett, Jackson, &amp; Higgins, 2012). CINeMA performs and displays the results of two methods; the first is a global method to assess incoherence, the design-by-treatment interaction test (Higgins et al., 2012;White et al., 2012). Its results ( χ 2 , degrees of freedom, and p value) are shown on the top of the "Incoherence" page. In each box, the results of the second method, Separating Indirect from Direct Evidence (SIDE; Dias et al., 2010), are shown, including the relative effect estimate, the direct effect, the indirect effect, the measure of their agreement, and the respective p value. As SIDE approach refers to the disagreement measure between direct and indirect evidence as "inconsistency factors," we also use this terminology. Inconsistency factors measure the disagreement between direct estimates, estimated from studies directly comparing the particular comparison, and indirect estimates, estimated from a NMA including all but the direct studies. Inconsistency factors are given as the ratio of direct and indirect effects if a ratio measure is used, or as a difference otherwise.</p>
        <p>The rules used to produce automatic judgments are as follow:</p>
        <p>(1) Effect estimates based on both direct and indirect evidence and with a p value from SIDE greater than 0.10 are assigned "No concerns."</p>
        <p>(2) To assign judgments for effect estimates with both direct and indirect evidence and with a p value from SIDE &lt;0.10, areas a, b, and c are defined as illustrated in Figure 4a (below, within, and above the clinically important effects). The confidence intervals for the direct and indirect evidence are then compared with these areas and incoherence judged according to Table 5. As with other domains, judgments can be updated manually and a "Reset" and "Proceed" (to "Report") button appear if clinically important size of effect is set.</p>
        <p>As in case 5 of Figure 4c, "Some concerns" apply to the ACE inhibitor versus Beta Blockers comparison with respect to "Incoherence." Confidence intervals of both direct (0.68-1.03) and indirect (0.49-0.75) treatment effects extend below the clinically important effects zone, only the direct effect's confidence interval lies within the (0.83-1.2) interval and none extend above 1.2; thus, direct and indirect treatment effects do not have substantial, but only minor disagreement (Table 5). Figure 6 shows the boxes that appear in the software showing the judgments for all relative effects for "Incoherence."</p>
        <p>The "Report" page brings together all the judgments for the six domains across all evaluated treatment effects. Relative effects informed by only direct or both direct and indirect evidence are shown A thick gray left border line appears for judgments whose automatically generated judgments have been manually modified. Users can visit the "Report" page as soon as at least one domain has been assessed. If users wish to summarize judgments across domains, the "Confidence rating" dropdown menu can be used to manually assign an overall level of confidence to each relative effect. The default judgment is "High" confidence; downgrading by one, two, or three levels will lead to a confidence rating of "Moderate," "Low," or "Very low" respectively. We recommend considering judgments on different domains jointly rather than in isolation (Nikolakopoulou et al., 2019;Salanti et al., 2014). For example, "Indirectness" and "Incoherence" domains are closely related, as they both refer to considerations of similarity across included studies which could or</p>
        <p>We have outlined how 
            <rs type="software">CINeMA</rs> software can be used to facilitate evaluation of results of NMA. Such an evaluation is an important but challenging part of a systematic review with multiple interventions.
        </p>
        <p>CINeMA, with semiautomation of methods via a guided on-line process greatly simplifies this process, particularly for large networks. CINeMA is freely available and open-source and no login is required. It is largely based on the methodological framework described previously (Nikolakopoulou et al., 2019;Salanti et al., 2014).</p>
        <p>While the main guiding principles of the CINeMA framework have been established (Nikolakopoulou et al., 2019;Salanti et al., 2014), specific methods, recommendations, and implementation of automated rules in 
            <rs type="software">CINeMA</rs> software are evolving.
        </p>
        <p>Important platform updates will follow. These include users being able to upload multiple projects they are working on concurrently. With the addition of this feature, users will be able to also have multiple outcomes per project, something that is currently not supported by CINeMA. Note, however, that dependency between outcomes will not be assessed. Users will also be able to download a league table with studies of only low, or only low and moderate RoB (or indirectness). The "Report" page will be updated so that users can click on each comparison by domain judgment and decide whether they will downgrade their confidence or not, and if yes, for one or two levels.</p>
        <p>Subjectivity is inevitable in any process or system evaluating evidence, and CINeMA is no exception. Several aspects of the eva- Evidence synthesis is used by organizations to take decisions about whether to reimburse a medicinal product, by clinical guideline panels to recommend one drug over another, and by clinicians to prescribe an intervention or recommend a diagnostic procedure.</p>
        <p>CINeMA is a transparent framework to evaluate evidence from systematic reviews with multiple interventions, and we hope that the software presented here will facilitate its uptake.</p>
        <p>T</p>
        <p>treatment name, the events, the sample size, RoB and indirectness per study arm. Table</p>
        <p>1</p>
        <p>can be used as a guide on how outcome data of different possible formats can be used as input to CINeMA.</p>
        <p>Note: Columns refer to comparisons with direct data and rows refer to NMA relative treatment effects. Entries show how much each comparison contributes to the estimation of NMA relative treatment effects. The table can be downloaded as a .csv file by clicking on "Download per comparisons contribution matrix" in "Configuration."</p>
        <p>Abbreviations: ACE, angiotensin-converting-enzyme inhibitors; ARB, angiotensin-receptor blockers; BBlocker, Beta Blocker; CCB, calcium-channel blocker.</p>
        <p>Note:</p>
        <p>of 15 | PAPAKONSTANTINOU ET AL.</p>
        <p>of 15 | PAPAKONSTANTINOU ET AL.</p>
        <p>of 15 | PAPAKONSTANTINOU ET AL.</p>
        <p>The development of the software was supported by the Campbell Collaboration. TP, AN, and GS were supported by project funding (Grant No.: 179158) from the Swiss National Science Foundation. ME was supported by special project funding (Grant No.: 174281) from the Swiss National Science Foundation. Authors would like to thank Christopher Ritter of his valuable editorial assistance.</p>
    </text>
</tei>
