<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T16:34+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>The use of Artificial Intelligence (AI) in Digital technologies (DT) is proliferating a profound socio-technical transformation. Governments and AI scholarship have endorsed key AI principles but lack direction at the implementation level. Through a systematic literature review of 59 papers, this paper contributes to the critical debate on the ethical use of AI in DTs beyond high-level AI principles. To our knowledge, this is the first paper that identifies 14 digital ethics implications for the use of AI in seven DT archetypes using a novel ontological framework (physical, cognitive, information, and governance). The paper presents key findings of the review and a conceptual model with twelve propositions highlighting the impact of digital ethics implications on societal impact, as moderated by DT archetypes and mediated by organisational impact. The implications of intelligibility, accountability, fairness, and autonomy (under the cognitive domain), and privacy (under the information domain) are the most widely discussed in our sample. Furthermore, ethical implications related to the governance domain are shown to be generally applicable for most DT archetypes. Implications under the physical domain are less prominent when it comes to AI diffusion with one exception (safety). The key findings and resulting conceptual model have academic and professional implications.</p>
        <p>Processes, systems, and supply chains that drive our daily lives, from energy grids to healthcare, food distribution to online banking, are increasingly dependent on digital technologies (DT). The physical world is being digitised and the "second machine age" (Brynjolfsson &amp; McAfee, 2014, p. 7) characterised by the use of Artificial Intelligence (AI) in DTs has the potential to significantly change society. AI enables machines to execute cognitive tasks with minimal or no human interaction. At the same time, it has a profound impact on organisations by challenging the status quo but promising new value propositions and enhanced (digital) revenue streams (Ashok, 2018;Pathak et al., 2020). Such digital capabilities have been fundamental in weathering social and economic turbulences such as natural disasters, financial crises, pandemics, etc. However, the use of AI in DTs forces us to grapple with tensions between technological and societal advancement on one hand and the same technologies introducing ethical dilemmas on the other hand (Floridi, 2018). AI development has typically been the purview of a select group of engineers, scientists, programmers, and architects, who have failed to sufficiently represent the ethnic, cultural, gender, age, geographic, or economic diversity of human social life. As systems become fully autonomous, there is a risk humans will become dependent on these systems. When AI is biased by design, humans forfeit their agency to serve the needs of AI rather than its original purpose of serving humans (Applin, 2017). Some recent examples of digital ethical issues include the unjust acquisition of millions of Facebook users data by Cambridge Analytica (Venturini &amp; Rogers, 2019); use of social media and Twitter bots to influence votes outcome in Brexit and 2016 US presidential elections (Gorodnichenko et al., 2021); impact of misinformation and fake news, aggravated by the use of social media, on violence, lynching, riots in India (Khan et al., 2019); an explosion of cybercrime-related to data hacking and breaches, affecting millions of consumers (personal, payment, behavioural data) (Janakiraman et al., 2018); bias against certain groups of gender, ethnicity, race, etc. by facial analysis software and algorithms (Khalil et al., 2020); genderbased discrimination (by algorithms) in the online display of STEM career advertisements (Lambrecht &amp; Tucker, 2019); and, use of cryptocurrency in fraud and malware (Conti et al., 2018). Thus, we frame the research question as:</p>
        <p>What are the key digital ethics implications for the use of AI in digital technologies?</p>
        <p>Following the introduction, the paper outlines motivations for the paper and a fourdimensional ontological framework. This is followed by a theoretical discussion on digital ethics and DTs within the context of the ontological framework as an a priori template. Through a systematic literature review and qualitative synthesis, we inductively develop a typology of ethical implications with the use of AI in DTs. Finally, we develop a conceptual model with twelve propositions. Dwivedi et al. (2021a) outline a lack of agreement on the concept of artificial intelligence and suggest that researchers develop discipline-oriented typologies to enable boundary research in social sciences. Similarly, Stahl et al. (2016)'s review of computing ethics literature reveals ethics discussions are broad and generic and need to be focussed on particular technologies to have practical importance. To this effect, the last two years have seen several systematic reviews on AI literature within discipline-oriented streams such as business strategy, sustainability, decision making, digital marketing and social media, internet of things, blockchain, education, and learning (Borges et al., 2020;Duan et al., 2019;Dwivedi et al., 2021b;Kankanhalli et al., 2019;Nishant et al., 2020;Sarker et al., 2019). To the best of our knowledge, a systematic literature review on the ethical dimensions of the use of AI in DTs is lacking, despite the significant impact of misuse of AI in DTs. Floridi (2018, p. 2) argues that current AI scholarship lacks a "socio-political direction" and requires a collective vision on the future of AI to be ahead of the pace of technological development. Jobin et al. (2019)'s systematic review of 84 AI guidelines shows a convergence of high-level AI principles but divergence on interpretation and application of these principles.</p>
        <p>Similarly, Whittlestone et al. (2019, p. 11) state that AI guidelines "are not specific enough to be action-guiding." J. Morley et al. (2020) concurs that AI principles need to be translated to 'what' and 'how' of implementation. Adomavicius et al. (2007) argue that a single technology cannot be considered in isolation and it is essential to evaluate the diversity of different DTs when assessing their ethical impact and implications. There have been attempts to develop implementationoriented analytical tools, for example, Canada's Algorithmic Impact Assessment (Canada, 2020), World Economic Forum's AI Procurement in a Box (Forum, 2020), OECD's Framework on AI Strategies (Berryhill et al., 2019). However, these lack a common ontological basis risking ethical assessments and corresponding AI development diverging between actors driven by political and economic interpretations of high-level AI principles.</p>
        <p>We adopt Gruber (1993, p. 199)'s definition of ontology as "an explicit specification of a conceptualization." As opposed to the philosophical concept of ontology as the nature of reality, the use of ontology in information science is geared towards defining a "shared taxonomy of entities" (Smith &amp; Welty, 2001, p. vi).</p>
        <p>We build on several ontological frameworks (Ogden &amp; Richards, 1923;Popper, 1979;Project &amp; Peirce, 1998) and identify three domains to conceptually understand the ethical impact and interrelationships inherent in the use of AI in DTs as shown in (2009) and Rosenbloom (2012) refer to these triadic domains as physical, social, and life respectively. Building on Liu (2000)'s concept of organisational onion, we propose the fourth domain as governance capturing the in(formal) information system and contending technical information system is already captured by the other three domains.</p>
        <p>[Table 1: Ontological frameworks for information science]</p>
        <p>2.3 Key concepts 2.3.1 Digital Ethics Fieser (2000) discusses three main schools of thought on ethics: metaethics, normative ethics, and applied ethics. Applied ethics has emerged as a school of thought that combines consequential and nonconsequential approaches in specific contexts such as medical and business ethics (Breidbach &amp; Maglio, 2020;Fieser, 2000). Phillip (1985, p. 381) defines business ethics as "rules, standards, codes, or principles, which provide guidelines for morally right behaviour and truthfulness in specific situations." We expand on business ethics to define digital ethics as "the systems of values and moral principles for the conduct of electronic interactions" (Buytendijk, 2019). Within the context of AI use, these electronic interactions encapsulate both human-machine and machinemachine interactions.</p>
        <p>This study views digital ethics as being socially constructed by technological (Utilitarianism perspective) and societal moral values (Kantianism perspective), which act upon each other in a triadic recursive way. Furthermore, the digital ethics space covers both hard ethics, right and wrong actions based on regulations and compliance, and soft ethics, "what ought and ought not to be done over and above the existing regulation" (Floridi, 2018, pp. 4-5).</p>
        <p>The literature discusses several context-specific applied ethics research domains related to digital ethics as shown in Table 2. We map these ethical research domains to the four dimensions of our ontological framework and view digital ethics as the focal point of the four domains as shown in Figure 1.</p>
        <p>[Table 2: Research domains in applied ethics in digital technologies]</p>
        <p>[Figure 1: Digital ethics research domain]</p>
        <p>Bain (1937, p. 860)'s definition of technology is widely accepted among social scientists as "all tools, machines, utensils, weapons, instruments, housing, clothing, communicating and transporting devices and the skills by which we produce and use them." Arthur (2009) further extends the idea of technology as not only limited to tangible tools and espouses three perspectives:</p>
        <p>fulfilment of a human need, collection of practices and processes, and aggregation of available tools. Berger et al. (2018, p. 3), deriving from Arthur (2009), build a three-layer framework of technologies as "concept", "approach", and "physical components." The concept layer embodies numerous principles that accomplish a human need and is solution agnostic. The second layer, approach, is positioned within one specific principle and can have multiple implementation approaches. The third layer, physical components, is an assemblage of specific physical or virtual purpose-built solutions to achieve the approach technological layer.</p>
        <p>DTs as a subset of technology can be defined as "multiple principles … for the usage of digital resources … to effectively find, analyse, create, communicate, or use information in specific contexts" (Berger et al., 2018, p. 4). Berger et al. (2018) adopt the "approach" layer of technology and develop a taxonomy consisting of seven DT archetypes: platforms, connectivity, actor-based products, analytical insight generation, and augmented interaction. We build on Yoo et al.</p>
        <p>(2010)'s modular DT architecture mapping the four DT layers (service, content, network, and device) to our ontological framework as shown in Table 3.</p>
        <p>The physical domain consisting of the device layer can be divided into physical machinery layer (e.g., computer hardware) and a logical capability layer (e.g., operating system). The network layer is divided into a physical transport layer (cables, radio spectrum, transmitters) and a logical transmission layer (network standards such as TCP/IP or peer-to-peer protocols) providing interfaces between ontological domains. The service layer deals with application functionality that directly serves users as they create, manipulate, store, and consume content. The content layer includes data (texts, sounds, images, and videos) that are stored and shared and provides metadata and directory information about the origin, ownership, copyright, encoding methods, content tags, geo-time stamps, and so on (Benkler, 2006;Farrell &amp; Weiser, 2003).</p>
        <p>[Table 3: DT modular architecture mapped to the ontological framework]</p>
        <p>For this paper, AI is defined as machines or "assemblage of technological components" (Canhoto &amp; Clear, 2020, p. 184) that perform cognitive functions associated with human minds, operate autonomously without human intervention, and learn and identify patterns to make decisions (Raisch &amp; Krakowski, 2020;Sousa et al., 2019;von Krogh, 2018).</p>
        <p>Adopting Berger et al. (2018) and Arthur (2009) technology layers, AI can be conceptualised at the concept level encompassing multiple principles that serve the purpose of automating and augmenting cognitive tasks performed by humans (Raisch &amp; Krakowski, 2020).</p>
        <p>Thus, following one specific principle, 'use of AI in digital technologies', we evaluate the ethical implications of the use of AI at the approach level. The DT archetypes, also at the approach level, provide optimal conceptual clusters of digital technologies for our purposes. The ontological framework serves as a common taxonomy between ethical implications and DT architectural layers enabling mapping to DT archetype clusters.</p>
        <p>3 Research Methodology</p>
        <p>We followed the widely used 'Preferred Reporting Items for Systematic Reviews and Meta-Analyses' (PRISMA) (Moher et al., 2009) methodology to conduct a systematic literature review and qualitative synthesis. The objective of the review was to conduct a thematic analysis of academic literature to achieve theoretical saturation on digital ethics implications for the use of AI in DT archetypes. We extend the existing AI ethics landscape that is either focused on the grey literature synthesising policy documents (Floridi &amp; Cowls, 2019;Jobin et al., 2019) or academic debates on AI within the context of algorithms (Mittelstadt et al., 2016). The review in this paper focuses on digital ethics implications at the DT archetype level, thus, providing a second layer of granularity.</p>
        <p>A literature search was conducted in four phases following the PRISMA methodology.</p>
        <p>During identification, a scoping literature review was conducted to develop an understanding of the current state of the literature and test a range of keywords. A combination of two keywords, '"business ethics" AND (AI OR "artificial intelligence")' and '"digital ethics" AND (AI OR "artificial intelligence")', were used to conduct a literature search in three databases 2 shows the PRISMA flow.</p>
        <p>[Figure 2: PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) flow]</p>
        <p>Qualitative synthesis was conducted using template analysis. This enabled the development of conceptual themes, their clustering into constituent themes, and identification 1 The search on EBSCO Host and ISI Web of Knowledge was conducted on September 26, 2020. The search was rerun, and Scopus was added as a new database on November 9, 2020. 2 Conducted on November 9, 2020 across cases as global themes (King, 2004). Data analysis was conducted in three steps described below. The unit of analysis was the DT archetype.</p>
        <p>In step one, a priori template was developed adopting the AI principles outlined in the literature (Floridi &amp; Cowls, 2019;Jobin et al., 2019) as beneficence, non-maleficence, justice, autonomy, and explicability. In step 2, the DT archetype was identified using the modular architecture shown in Table 3 and the related digital ethical implications discussed in the literature were coded. As the ethical issues were coded, codes were grouped into organising and global themes (Attride-Stirling, 2001). The final template was produced after a few more rounds of reorganising themes and sub-themes and performing reflexivity checks. In step 3, a conceptual map was developed to summarise the results and interpret the findings.</p>
        <p>The systematic literature review included 59 papers from 43 different journals (Table 4). The comprehensive array of journals show the multi-disciplinary nature of ethical debates on AI in technology, computing, philosophy, law, nursing, medicine, management, finance, and accounting. Of the publications included in this review, over 91% were published since 2018 (Table 5) demonstrating the contemporaneous nature of the debate on ethics and AI. Figure 3 shows a wordle for all the papers included in the systematic literature review. The wordle shows data, ethics, technology, systems, researching, informs, socially, algorithms, human, and decisive as the top ten frequent stemmed words.</p>
        <p>[Table 4: Publications included in the literature review]</p>
        <p>[Table 5: Year of publications included in the systematic literature review]</p>
        <p>[Figure 3: Systematic literature review papers' wordle]</p>
        <p>All the seven DT archetypes were identified in the literature review as shown in Table 6.</p>
        <p>Analytical Insight Generation is the most prevalent archetype discussed in 76% of the papers. This is followed by Sensor-based Data Collection at 27%, Actor-based Product at 25%, Analytical Interaction at 22%, Platform at 20%, Connectivity at 12%, and Augmented Interaction clusters at 10%.</p>
        <p>[Table 6: DT Archetypes identified in literature review] Table 7 and Figure 4 show the digital ethics implications inductively derived from template analysis and clustered into a priori AI principles with the identification of a sixth principle as "governance" relevant for the current context of digital technologies. The digital ethics implications are inductively clustered around four global themes that comprise the dimensions of our ontological framework developed in Section 3. The results of template analysis are discussed below.</p>
        <p>[Table 7: Digital ethics themes identified from the qualitative synthesis]</p>
        <p>[Figure 4: Ethical implications mapped to the ontological framework and DT architecture]</p>
        <p>The physical domain refers to Popper (1979)'s World I encompassing the device layer of DTs and shows a prevalence of ethical implications related to new technology development. This domain includes implications for dignity and well-being, safety, and sustainability under the AI principle of beneficence stipulating "do no harm" (Floridi &amp; Cowls, 2019, p. 6).</p>
        <p>Dignity and well-being are defined as safeguarding human dignity and promoting the wellbeing of the people (Floridi &amp; Cowls, 2019;Malkiat et al., 2019). This is recognised as a key human rights principle in several policy guidelines on AI development and relates to a critical implication when balancing ethical implications of autonomy and privacy (Gregory &amp; Halff, 2020;Malkiat et al., 2019;Vesnic-Alujevic et al., 2020).</p>
        <p>Safety is defined as protection against physical harm from AI-enabled technologies (O'Sullivan et al., 2019;Rhim et al., 2020). This implication relates to ensuring human-machine interactions are physically safe and mitigate instances of fatalities of human actors.</p>
        <p>Sustainability is defined as promoting the well-being of the planet and a positive view of the future (Floridi &amp; Cowls, 2019;Neubert &amp; Montañez, 2020). This implication is concerned with the environmental impact of new digital technologies, sustainability of the planet, and respect for public goods. It espouses a positive future outlook and the capability of AI to better serve climate and environment sustainability challenges.</p>
        <p>The cognitive domain referring to Popper (1979)'s World II encompasses the digital technologies service layer and the dominant ethical implications are related to machine learning and algorithms.</p>
        <p>It includes ethical implications of intelligibility and accountability related to the AI principle of explicability, autonomy related to the same AI principle, and fairness, promoting prosperity, and solidarity related to the AI principle of justice (Floridi &amp; Cowls, 2019, pp. 7-8).</p>
        <p>Intelligibility is defined as "the epistemological sense of how the AI works and its accuracy" (Floridi &amp; Cowls, 2019, p. 8). Scholars associate this implication to building trust in AI outputs by ensuring that algorithms and digital/physical outputs are accurate and reliable, and machine learning is driven by causality rather than by correlations. In addition, the algorithms need to be scalable and generalisable to develop wide-ranging software applications. Furthermore, backbox AI design is extensively debated with the need for algorithms to be transparent, interpretable, and explainable to retain human agency and autonomy.</p>
        <p>Accountability is defined as "the ethical sense of who is responsible for the way AI works" (Floridi &amp; Cowls, 2019, p. 8). In tandem with intelligibility implication, there are extensive debates in the literature on who is ultimately responsible for algorithmic decisions, software engineers, organisations, or machines. In a similar context, liability and culpability resulting from autonomous operations of the DTs are widely discussed.</p>
        <p>Fairness is defined as all humans should be treated equally and the use of AI should not result in unfair discrimination against individuals, communities, or groups (Lodders &amp; Paterson, 2020;Vidgen et al., 2020). This implication is extensively discussed in the context of AI development and algorithms to ensure the outputs are not biased even though the data used for machine learning may reflect social biases. On a positive note, scholars (Floridi, 2018;Martin, 2019b;Neubert &amp; Montañez, 2020) discuss AI's emancipatory power to create a fair society by helping reduce societal asymmetries and racial and gender stereotypes.</p>
        <p>Promoting prosperity is defined as enhancing the common good, being socially beneficial, and considering all stakeholders (Metcalf et al., 2019;Neubert &amp; Montañez, 2020;Vidgen et al., 2020). This ethical implication is discussed from a utilitarian and common good argument (Vidgen et al., 2020) with the ultimate goal of AI development being beneficial for humanity (Sutton et al., 2018;Wright &amp; Schultz, 2018).</p>
        <p>Solidarity is defined as moral sensitivity, empathy, and appreciation for human rights (Siebecker, 2019). This ethical implication relates to fairness and prosperity focussing on the human rights principle and a call for developers to ensure empathy, social justice, and human rights for all stakeholders are considered.</p>
        <p>Autonomy is defined as the "development of AI should not hurt the power of humans to decide" (Floridi &amp; Cowls, 2019, p. 7). This is a key implication extensively discussed in AI development ensuring the preservation of human agency and freedom of choice to avoid humans becoming subservient to algorithmic design.</p>
        <p>The information domain refers to Popper (1979)'s World III concept encompassing the content layer of digital technologies. The key ethical implications in this domain relate to privacy and security under the non-maleficence AI principle (Floridi &amp; Cowls, 2019, p. 6).</p>
        <p>Privacy is defined as consent and safeguards against surveillance and big data collection (Frizzo-Barker et al., 2020;Schappert &amp; von Hauff, 2020). The primary implication revolves around access, consent, and rights to personal data in the age of big data and mass surveillance, and the use of such data in applications not disclosed during data consent. The related implication of security defined as data protection and managing information security (Stahl et al., 2016;Urquhart et al., 2019) is concerned with safeguards towards ensuring privacy and data protection.</p>
        <p>The AI principle of governance is defined as "the practice of establishing and implementing policies, procedures, and standards for the proper development, use, and management of the infosphere" (Floridi, 2018, p. 3). This domain encompasses the (in)formal rules and social moral values expressed in implications for regulatory, financial and economic, and individual and societal impact.</p>
        <p>Regulatory impact is defined as "relevant legislation, a system of laws elaborated and enforced through social or governmental institutions to regulate the behaviour of the relevant agents in the infosphere" (Floridi, 2018, p. 3). These impacts are discussed in terms of rules and regulations to ensure human rights, intellectual property rights, data governance, and lawful surveillance.</p>
        <p>The financial and economic impact is defined as impacts to organisations and nations as a result of AI diffusion (Grewal et al., 2020;Wang &amp; Siau, 2019). These are discussed in both negative and positive terms ranging from market dominance, additional revenues, and cost savings to concerns on data monetisation and antitrust.</p>
        <p>Individual and societal impact is defined as the "transformational changes in society and individual's agency as a result of AI" (Akter et al., 2020;Schappert &amp; von Hauff, 2020). In tandem with other implications, these impacts relate to transformational shifts in society with new technologies, labour displacement, and unemployment, and employee deskilling.</p>
        <p>The objective of this paper was to outline key digital ethics implications in the context of AI use in DTs. Through systematic literature review and qualitative synthesis, we identified 14 digital ethics implications associated with four ontological domains and mapped them to seven DT archetypes as shown in Tables 7 and8.</p>
        <p>Table 8 shows a conceptual mapping of 14 digital ethics implications mapped to the seven DT archetypes. Deriving from qualitative synthesis, the colour coding reflects the prominence of a given digital ethics implications for a DT archetype. Black cells reflect an ethical implication that is mentioned in more than 2/3 rd of the publications that discussed a particular archetype, grey cell indicates ethical implications in 1/3 rd to 2/3 rd of the publications, and light grey for less than 1/3 rd publications. The digital ethics implications of intelligibility, accountability, fairness, and autonomy under the cognitive domain (related to the DT service layer) and privacy under the information domain (related to the DT content layer) are the most widely discussed in our sample. DT archetypes through their inherent architectural requirements and design motives might need to prioritise one domain or ethical implication over another. Such prioritisation represents a "true dilemma", a conflict whereby ethical implication(s) are inherently conflicting, or a "dilemma in practice", a conflict arising from resource constraints, or a "false dilemma" involving failures in recognising true impacts (Whittlestone et al., 2019, p. 42). Literature suggests an enhanced form of cost-benefit analysis involving all stakeholder voices and public deliberations as a potential solution for resolution of "true" and "in practice" dilemmas (Ibid.). Considering AI as an "immaterial infrastructure" (Jaume-Palasi, 2019, p. 479) and incorporating cost-benefit analysis at the societal level, the fundamental reflection is to analyse identified digital ethics implications and their associated tensions in terms of the overall societal impact. We define societal impact in our context modifying the definition developed by Bornmann (2013, p. 217) ISO:26000 (2010, p. 3) defines social responsibility as "the responsibility of an organization for the impacts of its decisions and activities on society and the environment through transparent and ethical behavior." Stakeholder theory stipulates organisations need to be cognizant of the diverse and contradictory needs of all their stakeholder groups (Freeman, 1984). The new generation of stakeholders is increasingly conscious of social responsibility. Organisations that adopt socially responsible practices will have greater economic success with the use of AI (Du &amp; Xie, 2020) and improve their competitive position.</p>
        <p>The design characteristics of new technology are strongly influenced by the dominant market players in addition to the culture and technological capabilities of the implementing organisation. Crawford (2021, p. 8) states that AI in this sense is "a registry of power." This institutional environment affects how organisations situate their social responsibility efforts and organisational cultural norms for value realisation from the use of AI in DTs. Thus, we state our second proposition as:</p>
        <p>Proposition 2: The organisational impact mediates the effect of physical [P3A], cognitive [P3B],</p>
        <p>information [P3C], and governance [P3D] domains on the overall societal impact.</p>
        <p>The prevalence of the Analytical Insights Generation archetype in our review (Table 5)</p>
        <p>demonstrates the imperative discussions on algorithms and machine learning as the most critical within the context of digital ethics and AI applications. This is followed by the increasing use of Platform-oriented DT archetypes are characterised as infrastructure technologies acting as hubs transmitting data from a single source with a one-to-many design (Berger et al., 2018). Given data is a pivotal component of this archetype, our conceptual map highlights content being the key architecture layer when using AI in this DT archetype. Connectivity DT archetypes also characterised as infrastructure technologies add another dimension to data transmission with efficient throughput objectives (Berger et al., 2018). Thus, our conceptual map shows the use of AI in this archetype not only focuses on the content layer but also the service layer.</p>
        <p>Actor-based Product DT archetypes are characterised as application technologies with the primary function related to data execution from digital input to a physical output (Berger et al., 2018). Thus, our conceptual map shows the use of AI in this archetype focuses on both the device layer, with the ability to impact the physical environment, and the service layer, as the cognitive engine.</p>
        <p>Sensor-based Data Collection DT archetypes are characterised as application technologies with the primary function of data collection from physical input to digital output (Berger et al., 2018). Thus, our conceptual map shows the use of AI in this archetype is primarily focused on data and the content layer.</p>
        <p>Analytical Insight Generation DT archetypes are characterised as application technologies with logic and decision-making functions (Berger et al., 2018). Our conceptual map showcases the use of AI in this archetype, the highest percentage in our sample, leverages both big data and advanced machine learning capabilities to replicate human cognitive functions focussing on content and service layers.</p>
        <p>Analytical Interaction DT archetypes are characterised as application technologies associated with the transmission of digital input, analytical capabilities, and physical output (Berger et al., 2018). Our conceptual map shows the use of AI in this archetype focuses on the content layer with data transmission function and is often associated with replacement of service jobs leading to individual and societal impacts.</p>
        <p>Augmented Interaction DT archetypes are associated with data collection allowing for a physical input to a digital output and "embodies interaction capabilities without deeper analytical capabilities" (Berger et al., 2018, p. 11). Our conceptual map shows the use of AI in this archetype focuses on the content layer with data primacy functions, service layer with physical interaction capabilities, and its application leading to macro shifts in the industry.</p>
        <p>Thus, we argue the characteristics of DT archetypes moderate the effect of ontological domains on societal impact and state our third proposition as: The conceptual model derived from these propositions is shown in Figure 5. The constructs of physical, cognitive, information, and governance domains are suggested as reflective that may be measured through the corresponding ethical implications. The organisational impact can be measured in terms of measures associated with performance such as profits, throughput, customer satisfaction, etc. or a hybrid scale consisting of performance measures and social responsibility measures.</p>
        <p>[Figure 5: Conceptual Model for the digital ethical assessment of the use of AI in DTs]</p>
        <p>This paper extends the current systematic literature review in AI (Borges et al., 2020;Duan et al., 2019;Dwivedi et al., 2021b;Kankanhalli et al., 2019;Nishant et al., 2020;Sarker et al., 2019) and AI ethics (Floridi &amp; Cowls, 2019;Jobin et al., 2019;Mittelstadt et al., 2016) with five theoretical contributions. First, the paper develops a new typology embedded in an ontological framework to conceptualise the ethical impact of AI on seven DTs archetypes identified in the literature. Second, the ontological framework identifies an additional AI principle of governance missing from the current AI principles debates. The governance domain is critical within the context of DTs and exploration of the interrelations between regulations and soft and hard ethics (Floridi, 2018). Third, deriving from an applied ethics perspective, the paper identifies eight ethical research domains in DTs and positions digital ethics as the focal point when conceptualised through our ontological framework. Fourth, through systematic literature review and qualitative synthesis, we outline 14 digital ethics implications associated with the four ontological domains and mapped them to the seven DT archetypes (conceptual map). Fifth, the conceptual model and twelve propositions deducted from our analysis can be tested and used as an empirical instrument for analysing the ethical use of AI in different contexts.</p>
        <p>The intent of qualitative synthesis was theoretical saturation and hence Table 8 provides the breath of ethical implications that practitioners need to consider when conducting AI ethical impact analysis on a specific DT archetype. The colour coding provides a subjective guideline on the priorities based on our sample of reviewed studies. The associated conceptual map (Table 8)</p>
        <p>provides an additional instrument that can be used for prioritising tensions related to ethical conflicts. For example, a developer interested in applications related to Sensor-based Data</p>
        <p>Collection may start their analysis by focussing on the ethical implication pertinent to that DT archetype. The highest implication (cells in black followed by grey) for this archetype is related to privacy followed by intelligibility and fairness. These key implications should be explored and balanced with the impacts of technology under the governance domain related to regulatory and societal implications. An overall societal impact measure can assist with deciding on balancing negative outcomes related to compromising on the physical domain that may conflict with satisfying higher priority ethical implications under cognitive, governance, and information domain.</p>
        <p>This study does come with some limitations which can pave the path for future research avenues.</p>
        <p>First, the intent of this review was theoretical saturation and not an extant literature review. Hence, any conclusions concerning the count and priority should be considered cautiously and within the context of the DT archetypes being developed. Second, by limiting analysis at the "approach" level of technology we intended to capture the majority of DT clusters at an abstract level. However, with the exceedingly rapid progress in the technological sector, new DT clusters might arise and will need to be added to the model. Furthermore, the archetype levels do not guarantee mutually exclusive taxonomy and some DTs might fall into two archetypes. For example, the use of AI for natural language processing falls under both Sensor-based Data Collection (a wearable that can translate languages) and Analytical Insights Generation (for conducting sentiment and emotional analysis). Third, ethical impact analysis is a complex area that requires insights from several disciplines such as technology, medical ethics, policy, law, philosophy, etc. Not least, tensions between ethical implications are due to arise (Whittlestone et al., 2019) that will require extensive policy and academic debates. The conceptual model developed in this paper can be developed as an instrument through in-depth interviews and quantitative testing to conduct ethical AI analysis in different contexts.</p>
        <p>Technological progress in the use of AI in DTs has intensified since the start of this century.</p>
        <p>Applications driven by AI are now embedded in all areas of human existence and the concept of (Barlow, 2020;Breidbach &amp; Maglio, 2020;Cath et al., 2018;Dhagarra et al., 2020;Du &amp; Xie, 2020;Flick et al., 2020;Gerlick &amp; Liozu, 2020;Giddens, 2018;Neubert &amp; Montañez, 2020;Roberts et al., 2021;Savirimuthu, 2017;Shanmuganathan, 2020) Connectivity 12% Blockchain, electronic records management, electronic document sharing, cloud computing (Barlow, 2020;Dhagarra et al., 2020;Frizzo-Barker et al., 2020;Gerlick &amp; Liozu, 2020;Giddens, 2018;Yong et al., 2019) Actor-based Product 25% autonomous vehicles, smart house, robotics, autonomous weapon system, automated stock trading, adaptive architecture, autonomous robotic surgery (Breidbach &amp; Maglio, 2020;Du &amp; Xie, 2020;Flick et al., 2020;Guidotti et al., 2018;Headrick, 2014;Johnson, 2015;Neubert &amp; Montañez, 2020;Nicodemo &amp; Cardoso, 2019;O'Sullivan et al., 2019;Rhim et al., 2020;Roberts et al., 2021;Robles Carrillo, 2020;Urquhart et al., 2019;Wang &amp; Siau, 2019 (Breidbach &amp; Maglio, 2020;Dhagarra et al., 2020;Du &amp; Xie, 2020;Ebert, 2019;Flick et al., 2020;Gerlick &amp; Liozu, 2020;González-Rodríguez et al., 2020;Gregory &amp; Halff, 2020;Ioannou et al., 2020;Lodders &amp; Paterson, 2020;Jessica Morley et al., 2020;Nicodemo &amp; Cardoso, 2019;O'Leary, 2019;Roberts et al., 2021;Savirimuthu, 2017;Wright &amp; Schultz, 2018) DT Archetype % of papers ( 59 (Barlow, 2020;Breidbach &amp; Maglio, 2020;Burk, 2019;Cho et al., 2020;Dhagarra et al., 2020;Du &amp; Xie, 2020;Duan et al., 2019;Ebert, 2019;Flick et al., 2020;Gal et al., 2020;Geis et al., 2019;Gerlick &amp; Liozu, 2020;Giddens, 2018;González-Rodríguez et al., 2020;Gregory &amp; Halff, 2020;Guidotti et al., 2018;Ioannou et al., 2020;Lee &amp; Shin, 2020;Leicht-Deobald et al., 2019;Lodders &amp; Paterson, 2020;Malkiat et al., 2019;Martin, 2019aMartin, , 2019b;;Milano et al., 2020;Jessica Morley et al., 2020;Mraović, 2008;Mulligan &amp; Bamberger, 2019;Munoko et al., 2020;Neubert &amp; Montañez, 2020;Nicodemo &amp; Cardoso, 2019;O'Leary, 2019;Roberts et al., 2021;Robles Carrillo, 2020;Savirimuthu, 2017;Schniter et al., 2020;Shanmuganathan, 2020;Siebecker, 2019;Sutton et al., 2018;Vesnic-Alujevic et al., 2020;Vidgen et al., 2020;Wang &amp; Siau, 2019;Watson, 2019;Wright &amp; Schultz, 2018) Analytical Interaction</p>
        <p>human enhancement technology, anthropomorphism, interactive avatars (Cath et al., 2018;Chen et al., 2020;Du &amp; Xie, 2020;Grewal et al., 2020;Manfreda et al., 2021;Jessica Morley et al., 2020;Nicodemo &amp; Cardoso, 2019;Roberts et al., 2021;Schniter et al., 2020;Sipior, 2020;Subramanian, 2017;Sutton et al., 2018;Wang &amp; Siau, 2019;Wiesenberg &amp; Tench, 2020;Wright &amp; Schultz, 2018;Xie et al., 2020) Augmented Interaction</p>
        <p>human augmentation technology, adaptive architecture, robotics (Dwivedi et al., 2021b;Grewal et al., 2020;Nicodemo &amp; Cardoso, 2019;Roberts et al., 2021;Urquhart et al., 2019;Wang &amp; Siau, 2019) Carrillo, 2020;Shanmuganathan, 2020;Subramanian, 2017;Urquhart et al., 2019;Vesnic-Alujevic et al., 2020;Watson, 2019;Wiesenberg &amp; Tench, 2020;Yong et al., 2019) Justice the quality of being fair and eliminating discrimination ensuring equal access to the benefits of AI (Floridi &amp; Cowls, 2019) C3 -Fairness avoiding bias, fairness, justice, accessibility, discrimination, human rights, racial and gender stereotypes, information asymmetries, equality, freedom and justice, basic rights, equality, fair use, unfair outcomes (Breidbach &amp; Maglio, 2020;Burk, 2019;Cho et al., 2020;Du &amp; Xie, 2020;Dwivedi et al., 2021b;Flick et al., 2020;Frizzo-Barker et al., 2020;Geis et al., 2019;Gerlick &amp; Liozu, 2020;Giddens, 2018;Grewal et al., 2020;Guidotti et al., 2018;Lee &amp; Shin, 2020;Leicht-Deobald et al., 2019;Lodders &amp; Paterson, 2020;Martin, 2019aMartin, , 2019b;;Milano et al., 2020;Jessica Morley et al., 2020;Munoko et al., 2020;Neubert &amp; Montañez, 2020;Roberts et al., 2021;Robles Carrillo, 2020;Siebecker, 2019;Sipior, 2020;Vesnic-Alujevic et al., 2020;Vidgen et al., 2020;Wang &amp; Siau, 2019;Yong et al., 2019) Justice C4 -Promoting prosperity Socially beneficial, prudence, human values principle, common good, augment human capabilities than replacing them, the benefit of humanity, attention to context and culture (Malkiat et al., 2019;Mulligan &amp; Bamberger, 2019;Munoko et al., 2020;Neubert &amp; Montañez, 2020;Rhim et al., 2020;Roberts et al., 2021;Sutton et al., 2018;Vidgen et al., 2020;Wright &amp; Schultz, 2018) (Cath et al., 2018;Manfreda et al., 2021) Justice C5 -Solidarity solidarity, empathy, social inequality issues, social justice (Cath et al., 2018;Gerlick &amp; Liozu, 2020;Grewal et al., 2020;Leicht-Deobald et al., 2019;Mraović, 2008;Munoko et al., 2020 (Breidbach &amp; Maglio, 2020;Cath et al., 2018;Du &amp; Xie, 2020;Flick et al., 2020;Gal et al., 2020;Geis et al., 2019;Giddens, 2018;Gregory &amp; Halff, 2020;Leicht-Deobald et al., 2019;Lodders &amp; Paterson, 2020;Martin, 2019aMartin, , 2019b;;Milano et al., 2020;Mraović, 2008;Munoko et al., 2020;O'Leary, 2019;Rhim et al., 2020;Subramanian, Sutton et al., 2018;Vesnic-Alujevic et al., 2020;Vidgen et (Du &amp; Xie, 2020;Dwivedi et al., 2021b;Flick et al., 2020;Geis et al., 2019;Gregory &amp; Halff, 2020;Malkiat et al., 2019;Martin, 2019b;Munoko et al., 2020;Neubert &amp; Montañez, 2020;Rhim et al., 2020;Vesnic-Alujevic et al., 2020;Vidgen et (Floridi, 2018, p. 3) G1 -Regulatory impact avoid deception and coercion, policies to reduce social injustice, human rights and victim access to an effective remedy, intellectual property, data ownership, occupational rights, surveillance, consent (Cath et al., 2018;Chen et al., 2020;Du &amp; Xie, 2020;Duan et al., 2019;Dwivedi et al., 2021b;Gerlick &amp; Liozu, 2020;Headrick, 2014;Lodders &amp; Paterson, 2020;Malkiat et al., 2019;Manfreda et al., 2021;O'Leary, 2019;O'Sullivan et al., 2019;Roberts et al., 2021;Robles Carrillo, 2020;Savirimuthu, 2017;Sipior, 2020;Subramanian, 2017;Urquhart et al., 2019;Vesnic-Alujevic et al., 2020;Wang &amp; Siau, 2019;Wright &amp; Schultz, 2018;Yong et al., 2019) Governance G2 -Financial and economic impact positive benefits in the marketplace, reduce cost, data monetisation, additional revenues, antitrust factors, corporate digital responsibility, national and international economic impacts (Breidbach &amp; Maglio, 2020;Dwivedi et al., 2021b;Gerlick &amp; Liozu, 2020;Giddens, 2018;Grewal et al., 2020;Neubert &amp; Montañez, 2020;Roberts et al., 2021;Vidgen et al., 2020;Wang &amp; Siau, 2019;Wiesenberg &amp; Tench, 2020;Wright &amp; Schultz, 2018;Yong et al., 2019) Governance G3 -Individual and societal impact shifts in society with technological advancement, change in cultural and (Breidbach &amp; Maglio, 2020;Cath et al., 2018;Chen et al., 2020;Du &amp; Xie, 2020;Duan et al., 2019;Dwivedi et al., 2021b;Flick et al., 2020;Gal et al., 2020 et al., 2019;Lee &amp; Shin, 2020;Leicht-Deobald et al., 2019;Lodders &amp; Paterson, 2020;Martin, 2019aMartin, , 2019b;;Milano et al., 2020;Jessica Morley et al., 2020;Munoko et al., 2020;Neubert &amp; Montañez, 2020;O'Leary, 2019;Robles Carrillo, 2020;Subramanian, 2017;Sutton et al., 2018;Vesnic-Alujevic et al., 2020;Vidgen et al., 2020;Wang &amp; Siau, 2019;Wiesenberg &amp; Tench, 2020;Wright &amp; Schultz, 2018)</p>
    </text>
</tei>
