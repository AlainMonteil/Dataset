<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-14T14:09+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>Introduction: Wearable sensors have shown promise as a non-intrusive method for collecting biomarkers that may correlate with levels of elevated stress. Stressors cause a variety of biological responses, and these physiological reactions can be measured using biomarkers including Heart Rate Variability (HRV), Electrodermal Activity (EDA) and Heart Rate (HR) that represent the stress response from the Hypothalamic-Pituitary-Adrenal (HPA) axis, the Autonomic Nervous System (ANS), and the immune system. While Cortisol response magnitude remains the gold standard indicator for stress assessment [1], recent advances in wearable technologies have resulted in the availability of a number of consumer devices capable of recording HRV, EDA and HR sensor biomarkers, amongst other signals. At the same time, researchers have been applying machine learning techniques to the recorded biomarkers in order to build models that may be able to predict elevated levels of stress. Objective: The aim of this review is to provide an overview of machine learning techniques utilized in prior research with a specific focus on model generalization when using these public datasets as training data. We also shed light on the challenges and opportunities that machine learning-enabled stress monitoring and detection face. Methods: This study reviewed published works contributing and/or using public datasets designed for detecting stress and their associated machine learning methods. The electronic databases of 
            <rs type="software">Google Scholar</rs>, Crossref, DOAJ and PubMed were searched for relevant articles and a total of 33 articles were identified and included in the final analysis. The reviewed works were synthesized into three categories of publicly available stress datasets, machine learning techniques applied using those, and future research directions. For the machine learning studies reviewed, we provide an analysis of their approach to results validation and model generalization. The quality assessment of the included studies was conducted in accordance with the IJMEDI checklist [2]. Results: A number of public datasets were identified that are labeled for stress detection. These datasets were most commonly produced from sensor biomarker data recorded using the Empatica E4 device, a well-studied, medical-grade wrist-worn wearable that provides sensor biomarkers most notable to correlate with elevated levels of stress. Most of the reviewed datasets contain less than twenty-four hours of data, and the varied experimental conditions and labeling methodologies potentially limit their ability to generalize for unseen data. In addition, we discuss that previous works show shortcomings in areas such as their labeling protocols, lack of statistical power, validity of stress biomarkers, and model generalization ability. Conclusion: Health tracking and monitoring using wearable devices is growing in popularity, while the generalization of existing machine learning models still requires further study, and research in this area will continue to provide improvements as newer and more substantial datasets become available.
        </p>
        <p>Stress can be defined as the body's psychological and physiological response to physical, emotional or mental strain. Such change in environment. This is achieved through mobilization of energy and its appropriate redistribution to organs that most immediately serve the adaptational response. At present, a universally recognized standard for stress evaluation remains outstanding [4], further compounded with the need for a comprehensive framework for investigating how organisms function in and adapt to constantly changing environments [5]. In the context of this paper and its reviewed studies, stress is considered as a binary condition for prediction. The data in a number of these studies [6,7] was labeled with binary stressed or non-stressed time periods, and models trained on these datasets resulted in classifiers that would predict an observation as either stressed or not-stressed, while the other datasets [8] utilized a daily stress inventory score [9] and one dataset [10] was labeled through observer scoring (0 to 1, low to high). A single study by Siirtola et al. [11] investigated and compared models trained as classifiers to models trained as a regression, where a threshold was established by analyzing the obtained continuous prediction values study subject-wise to obtain a balanced accuracy rate is as high as possible. In the studies reviewed, no single thresholding method could be determined that can generalize well across models.Stress can be defined as the body's psychological and physiological response to physical, emotional or mental strain. Such change in environment. This is achieved through mobilization of energy and its appropriate redistribution to organs that most immediately serve the adaptational response. At present, a universally recognized standard for stress evaluation remains outstanding [4], further compounded with the need for a comprehensive framework for investigating how organisms function in and adapt to constantly changing environments [5]. In the context of this paper and its reviewed studies, stress is considered as a binary condition for prediction. The data in a number of these studies [6,7] was labeled with binary stressed or non-stressed time periods, and models trained on these datasets resulted in classifiers that would predict an observation as either stressed or not-stressed, while the other datasets [8] utilized a daily stress inventory score [9] and one dataset [10] was labeled through observer scoring (0 to 1, low to high). A single study by Siirtola et al. [11] investigated and compared models trained as classifiers to models trained as a regression, where a threshold was established by analyzing the obtained continuous prediction values study subject-wise to obtain a balanced accuracy rate is as high as possible. In the studies reviewed, no single thresholding method could be determined that can generalize well across models.</p>
        <p>Interestingly, a growing number of studies are examining the effects of training machine learning models on biomarker data collected in a study setting compared to daily life scenarios [12], with further studies examining the effect of context when both training and evaluating predictive power [13]. While the majority of studies in this review approached the training of machine learning models for stress detection as a single time-series dataset, more studies are evaluating the potential of person-specific models [14] compared to generic non-specific models, with person-specific models showing great promise as powerful predictors of stress.Interestingly, a growing number of studies are examining the effects of training machine learning models on biomarker data collected in a study setting compared to daily life scenarios [12], with further studies examining the effect of context when both training and evaluating predictive power [13]. While the majority of studies in this review approached the training of machine learning models for stress detection as a single time-series dataset, more studies are evaluating the potential of person-specific models [14] compared to generic non-specific models, with person-specific models showing great promise as powerful predictors of stress.</p>
        <p>Wearable devices for personal health monitoring and tracking have gained significant popularity and technical sophistication since the release of the first Fitbit [15] in 2009 and Empatica Embrace model in 2016 [16]. Recently, more advanced devices including Empatica's E4 [16] have been developed that are capable of measuring a wide variety of physiological signals. Peake et al. [17] performed a critical review of available wearable devices for providing bio-feedback, monitoring stress, and sleep with a critical review of their technical characteristics, reliability and validation. Continuous measurement of the physiological signals recorded using wearables enables researchers to extract useful information from these devices to potentially detect and monitor a variety of health-related events such as seizures [18][19][20], dehydration [21], cognitive load [22], physical activity [23], emotions [24] and specifically related to this review, stress [11,13,14,22,[25][26][27][28][29][30][31][32][33].Wearable devices for personal health monitoring and tracking have gained significant popularity and technical sophistication since the release of the first Fitbit [15] in 2009 and Empatica Embrace model in 2016 [16]. Recently, more advanced devices including Empatica's E4 [16] have been developed that are capable of measuring a wide variety of physiological signals. Peake et al. [17] performed a critical review of available wearable devices for providing bio-feedback, monitoring stress, and sleep with a critical review of their technical characteristics, reliability and validation. Continuous measurement of the physiological signals recorded using wearables enables researchers to extract useful information from these devices to potentially detect and monitor a variety of health-related events such as seizures [18][19][20], dehydration [21], cognitive load [22], physical activity [23], emotions [24] and specifically related to this review, stress [11,13,14,22,[25][26][27][28][29][30][31][32][33].</p>
        <p>A number of previous survey articles have studied the topics of stress detection using wearable devices [34] and machine learning [35]. In particular, in [34], Samson and Koh have surveyed various stress biomarkers and their measurement tools including wearables for salivary and electrochemical detection. However, they have not discussed how machine learning can be used to help with stress detection and measurements. In [35], Gedam and Paul have surveyed works that have performed stress detection using wearable sensors measuring Electrocardiogram (ECG), Electroencephalography (EEG), and Photoplethysmography (PPG) signals and surveyed machine learning techniques for that. However, in this paper, we systematically review studies that have mainly used biomarker data from medical-grade wearable devices available to the consumer, due to the growing popularity of personal health monitoring, different to those used in [35].A number of previous survey articles have studied the topics of stress detection using wearable devices [34] and machine learning [35]. In particular, in [34], Samson and Koh have surveyed various stress biomarkers and their measurement tools including wearables for salivary and electrochemical detection. However, they have not discussed how machine learning can be used to help with stress detection and measurements. In [35], Gedam and Paul have surveyed works that have performed stress detection using wearable sensors measuring Electrocardiogram (ECG), Electroencephalography (EEG), and Photoplethysmography (PPG) signals and surveyed machine learning techniques for that. However, in this paper, we systematically review studies that have mainly used biomarker data from medical-grade wearable devices available to the consumer, due to the growing popularity of personal health monitoring, different to those used in [35].</p>
        <p>In addition, the previous reviews have not addressed a number of important points such as the statistical power [36] of the training data used or their labeling protocols, and how it may affect machine learning model performance. Neither have they considered machine learning model generalization, where models built on any of the available public stress datasets are capable of accurately measuring stress when applied on a new dataset, or applied on datasets recorded under different conditions including experimental set-up, session duration, and labeling methodology.In addition, the previous reviews have not addressed a number of important points such as the statistical power [36] of the training data used or their labeling protocols, and how it may affect machine learning model performance. Neither have they considered machine learning model generalization, where models built on any of the available public stress datasets are capable of accurately measuring stress when applied on a new dataset, or applied on datasets recorded under different conditions including experimental set-up, session duration, and labeling methodology.</p>
        <p>Towards addressing these questions, we first explore the current state of stress detection and measurement using medical-grade wearable devices that are available to the consumer. We further explore the available public datasets built using sensor data recorded from these devices, and investigate the approaches utilized, and detection accuracy scores attained for machine learning models trained on these datasets. Finally, we discuss the generalization ability and limitations of these machine learning models, in order to understand the current state of using wearable devices for accurately measuring stress response and future directions.Towards addressing these questions, we first explore the current state of stress detection and measurement using medical-grade wearable devices that are available to the consumer. We further explore the available public datasets built using sensor data recorded from these devices, and investigate the approaches utilized, and detection accuracy scores attained for machine learning models trained on these datasets. Finally, we discuss the generalization ability and limitations of these machine learning models, in order to understand the current state of using wearable devices for accurately measuring stress response and future directions.</p>
        <p>The main aim of this work is to provide an overview of the current state of stress detection using machine learning techniques by using the IJMEDI checklist to assess the quality of the included literature, and specifically the generalization ability of models trained on public stress biomarker datasets and the potential reproducibility of their findings and results. Thus, our research questions can be formulated as follows:The main aim of this work is to provide an overview of the current state of stress detection using machine learning techniques by using the IJMEDI checklist to assess the quality of the included literature, and specifically the generalization ability of models trained on public stress biomarker datasets and the potential reproducibility of their findings and results. Thus, our research questions can be formulated as follows:</p>
        <p>• RQ1: Which machine learning algorithms and techniques are being utilized and trained on publicly available stress biomarker datasets? • RQ2: What accuracy metrics are reported and how are these findings being validated? Are the findings reproducible and does the methods utilized show promise towards model generalization?• RQ1: Which machine learning algorithms and techniques are being utilized and trained on publicly available stress biomarker datasets? • RQ2: What accuracy metrics are reported and how are these findings being validated? Are the findings reproducible and does the methods utilized show promise towards model generalization?</p>
        <p>Answering these questions will aid in getting a better understanding of the most current and accurate machine learning models available for predicting stress using wearable devices, and assist towards building a model capable of generalization on new, unseen data.Answering these questions will aid in getting a better understanding of the most current and accurate machine learning models available for predicting stress using wearable devices, and assist towards building a model capable of generalization on new, unseen data.</p>
        <p>We reviewed key published works (Fig. 1) between 2012 and 2022 on publicly available datasets related to stress, and more specifically, recorded using wearable devices; and measuring and predicting stress response using machine learning. The electronic databases of Google Scholar, Crossref, DOAJ and PubMed were searched for relevant articles using the keywords stress, machine learning and wearable in title or abstract, and a total of 973 papers were identified. Duplicates were identified, and 16 were found and removed, leaving the number of considered papers for the subsequent phases at 957. Abstracts were scanned and irrelevant papers were excluded, including papers where the full text was not available. A small number of papers, in which the focus was stress in animals or psychiatry, were excluded. Studies using devices that are generally considered as health-trackers, or lifestyle monitors were also excluded, as were studies performed solely using devices that would not generally be considered a wearable device, such as EEG or chest-worn monitors. We further limited this review to machine learning models trained on, and devices that are capable of, recording multiple biomarkers that are known to be robust indicators of elevated levels of stress, i.e. HRV, EDA, HR, Inter-beat Interval (IBI) [34]. Finally, papers where key machine learning techniques including feature-engineering and model validation techniques were not detailed, were also removed. As a result, a total of 33 papers were chosen for the systematic review process, grouped by the high-level topics of: Datasets, Machine Learning for Stress Detection and Future Research and Open Problems. Table 1 details the papers included in this review.We reviewed key published works (Fig. 1) between 2012 and 2022 on publicly available datasets related to stress, and more specifically, recorded using wearable devices; and measuring and predicting stress response using machine learning. The electronic databases of Google Scholar, Crossref, DOAJ and PubMed were searched for relevant articles using the keywords stress, machine learning and wearable in title or abstract, and a total of 973 papers were identified. Duplicates were identified, and 16 were found and removed, leaving the number of considered papers for the subsequent phases at 957. Abstracts were scanned and irrelevant papers were excluded, including papers where the full text was not available. A small number of papers, in which the focus was stress in animals or psychiatry, were excluded. Studies using devices that are generally considered as health-trackers, or lifestyle monitors were also excluded, as were studies performed solely using devices that would not generally be considered a wearable device, such as EEG or chest-worn monitors. We further limited this review to machine learning models trained on, and devices that are capable of, recording multiple biomarkers that are known to be robust indicators of elevated levels of stress, i.e. HRV, EDA, HR, Inter-beat Interval (IBI) [34]. Finally, papers where key machine learning techniques including feature-engineering and model validation techniques were not detailed, were also removed. As a result, a total of 33 papers were chosen for the systematic review process, grouped by the high-level topics of: Datasets, Machine Learning for Stress Detection and Future Research and Open Problems. Table 1 details the papers included in this review.</p>
        <p>Two reviewers (Vos and Azghadi) used the IJMEDI checklist [2] to evaluate the quality of the included studies independently. The IJMEDI checklist is a quality assessment tool for medical artificial intelligence studies proposed by the IJMEDI, which aims to distinguish high-quality machine learning studies from simple medical data-mining studies. Six dimensions are included as 30 questions in the checklist: problem and data understanding, data preparation, modeling, validation, and deployment. Each question can be answered as OK (adequately addressed), mR (sufficient but improvable), and MR (inadequately addressed). In high-priority items, OK, mR and MR were assigned the scores of 0, 1, and 2, respectively, whereas in low priority items, the scores were halved. The maximum possible score was 50 points, with study quality was divided into low (0-19.5), medium (20-34.5), and high (35)(36)(37)(38)(39)(40)(41)(42)(43)(44)(45)(46)(47)(48)(49)(50).Two reviewers (Vos and Azghadi) used the IJMEDI checklist [2] to evaluate the quality of the included studies independently. The IJMEDI checklist is a quality assessment tool for medical artificial intelligence studies proposed by the IJMEDI, which aims to distinguish high-quality machine learning studies from simple medical data-mining studies. Six dimensions are included as 30 questions in the checklist: problem and data understanding, data preparation, modeling, validation, and deployment. Each question can be answered as OK (adequately addressed), mR (sufficient but improvable), and MR (inadequately addressed). In high-priority items, OK, mR and MR were assigned the scores of 0, 1, and 2, respectively, whereas in low priority items, the scores were halved. The maximum possible score was 50 points, with study quality was divided into low (0-19.5), medium (20-34.5), and high (35)(36)(37)(38)(39)(40)(41)(42)(43)(44)(45)(46)(47)(48)(49)(50).</p>
        <p>Advances in hardware such as component miniaturization have enabled more technological features to be embedded into ever shrinking devices at lower cost. However, adoption is clearly a challenge that demands the collaborative attention of healthcare providers, hardware and software engineers, data scientists, policy-makers, cognitive neuroscientists, device engineers and materials scientists, among other specializations [52]. From the initial Fitbit device launched in 2009, through to the Empatica E4 and the latest Oura Ring 3, significant improvements have been realized in both base features, as well as capabilities specifically related to the monitoring of, and promise to assist in improving, the user's overall health.Advances in hardware such as component miniaturization have enabled more technological features to be embedded into ever shrinking devices at lower cost. However, adoption is clearly a challenge that demands the collaborative attention of healthcare providers, hardware and software engineers, data scientists, policy-makers, cognitive neuroscientists, device engineers and materials scientists, among other specializations [52]. From the initial Fitbit device launched in 2009, through to the Empatica E4 and the latest Oura Ring 3, significant improvements have been realized in both base features, as well as capabilities specifically related to the monitoring of, and promise to assist in improving, the user's overall health.</p>
        <p>There are a wide variety of wearable devices in the market [17] used for health monitoring, including both medical-grade devices (Empatica Embrace Plus, Empatica E4, NOWATCH, Oura Ring) and consumer-oriented devices (Apple iWatch, Fitbit, Garmin, Samsung Gear). Consumer-oriented devices generally provide web-based platforms and smartphone applications for reporting various health statistics and levels of stress, with no ability to extract raw biomarker sensor recordings for scientific study, in contrast to medical-grade devices, such as the Empatica range, that provides full biomarker data download and additional support for researchers to properly utilize the raw signals directly for study. However, in this review, our focus was limited to devices that are capable of stand-alone monitoring, without the need for an additional harness or pairing with a secondary device (worn on the wrist, finger or arm), as this would limit the usefulness for study outside of a stricter laboratory setting. Table 2 provides a non-exhaustive list of well-known wearable devices potentially capable of tracking and monitoring stress.There are a wide variety of wearable devices in the market [17] used for health monitoring, including both medical-grade devices (Empatica Embrace Plus, Empatica E4, NOWATCH, Oura Ring) and consumer-oriented devices (Apple iWatch, Fitbit, Garmin, Samsung Gear). Consumer-oriented devices generally provide web-based platforms and smartphone applications for reporting various health statistics and levels of stress, with no ability to extract raw biomarker sensor recordings for scientific study, in contrast to medical-grade devices, such as the Empatica range, that provides full biomarker data download and additional support for researchers to properly utilize the raw signals directly for study. However, in this review, our focus was limited to devices that are capable of stand-alone monitoring, without the need for an additional harness or pairing with a secondary device (worn on the wrist, finger or arm), as this would limit the usefulness for study outside of a stricter laboratory setting. Table 2 provides a non-exhaustive list of well-known wearable devices potentially capable of tracking and monitoring stress.</p>
        <p>Siirtola [53] performed a study on smart watches reporting stress using a single biomarker (HR) and concluded that to be sufficient for detecting stress. Farrow et al. [54] concluded that EDA is a robust, reliable, non-subjective psycho-physiological biomarker of psychological stress within subjects, but not always between. Greco et al. [32] concluded that using only the EDA biomarker is sufficient for accurately predicting stress. The validity of sensor biomarkers is an open research question, discussed in detail in Section 4.1. Devices reporting stress based on only a single biomarker (typically HR or HRV) were therefor excluded.Siirtola [53] performed a study on smart watches reporting stress using a single biomarker (HR) and concluded that to be sufficient for detecting stress. Farrow et al. [54] concluded that EDA is a robust, reliable, non-subjective psycho-physiological biomarker of psychological stress within subjects, but not always between. Greco et al. [32] concluded that using only the EDA biomarker is sufficient for accurately predicting stress. The validity of sensor biomarkers is an open research question, discussed in detail in Section 4.1. Devices reporting stress based on only a single biomarker (typically HR or HRV) were therefor excluded.</p>
        <p>The studies included in this review predominantly utilized datasets that are publicly available and therefor available to other researchers, and of these, the predominant wearable device utilized was the Empatica E4. Patient privacy when utilizing public health data for wearable research remains a concern, and Differential Privacy (DP) has emerged as a proficient technique to publish privacy sensitive data, including data from wearable devices. Saifuzzaman et al. [55] conducted a Systematic Literature Review to identify, select and critically appraise research in DP to understand the different techniques available in wearable data publishing, and proposed a number of solutions for protecting patient privacy. Of the public datasets reviewed and included in this study, all patient identifiable information were excluded from the datasets.The studies included in this review predominantly utilized datasets that are publicly available and therefor available to other researchers, and of these, the predominant wearable device utilized was the Empatica E4. Patient privacy when utilizing public health data for wearable research remains a concern, and Differential Privacy (DP) has emerged as a proficient technique to publish privacy sensitive data, including data from wearable devices. Saifuzzaman et al. [55] conducted a Systematic Literature Review to identify, select and critically appraise research in DP to understand the different techniques available in wearable data publishing, and proposed a number of solutions for protecting patient privacy. Of the public datasets reviewed and included in this study, all patient identifiable information were excluded from the datasets.</p>
        <p>Additionally, the measurement of stress in people with mental disorders or intellectual disabilities is of growing interest. Simons et al. [56] presented a specific protocol for studying patterns of physiological stress in patients with challenging behavior. However, in this review we found the vast majority of current studies were performed using data captured from predominantly healthy subjects, screened for a number of health conditions prior to inclusion. Table 3 lists the studies included in this review where health screening was explicitly noted in the study, or where a dataset was utilized that was built using biomarker data from subjects screened for inclusion based on reported health status.Additionally, the measurement of stress in people with mental disorders or intellectual disabilities is of growing interest. Simons et al. [56] presented a specific protocol for studying patterns of physiological stress in patients with challenging behavior. However, in this review we found the vast majority of current studies were performed using data captured from predominantly healthy subjects, screened for a number of health conditions prior to inclusion. Table 3 lists the studies included in this review where health screening was explicitly noted in the study, or where a dataset was utilized that was built using biomarker data from subjects screened for inclusion based on reported health status.</p>
        <p>A number of datasets are publicly available containing sensor data recorded using a variety of devices matching our inclusion criteria, as detailed in Table 4. The reviewed datasets contain the biomarkers predominantly utilized for stress detection, specifically EDA and HR signals. Apart from the Toadstool dataset, all recorded sessions exceed 60 minutes. The AffectiveROAD and Toadstool datasets contain biomarkers for a relatively small sample size of 10 subjects each, and small sample sizes of 25 subjects or less is a common feature of all public datasets reviewed. The largest public dataset included for review, Stress-Predict [39], contains biomarker data recorded using an Empatica E4 device for 35 test subjects.A number of datasets are publicly available containing sensor data recorded using a variety of devices matching our inclusion criteria, as detailed in Table 4. The reviewed datasets contain the biomarkers predominantly utilized for stress detection, specifically EDA and HR signals. Apart from the Toadstool dataset, all recorded sessions exceed 60 minutes. The AffectiveROAD and Toadstool datasets contain biomarkers for a relatively small sample size of 10 subjects each, and small sample sizes of 25 subjects or less is a common feature of all public datasets reviewed. The largest public dataset included for review, Stress-Predict [39], contains biomarker data recorded using an Empatica E4 device for 35 test subjects.</p>
        <p>Labeling of the included datasets were performed using one of two methods: (i) periodic, where specific time frames during the experiment were either labeled as stressed or non-stressed, while the test subject was placed under that perceived condition (a stressful test or action, or non-stressed, restful period), or (ii) scored as experiencing stress or no stress during a particular period, either by completing a self-scoring evaluation, or by an observer who perceived a level of stress by observing the emotional reaction of the subject during that period.Labeling of the included datasets were performed using one of two methods: (i) periodic, where specific time frames during the experiment were either labeled as stressed or non-stressed, while the test subject was placed under that perceived condition (a stressful test or action, or non-stressed, restful period), or (ii) scored as experiencing stress or no stress during a particular period, either by completing a self-scoring evaluation, or by an observer who perceived a level of stress by observing the emotional reaction of the subject during that period.</p>
        <p>The American Psychological Association defines three types of stress -Acute, Episodic Acute and Chronic, further divided into Absolute Stressors (stressors that everyone exposed to them would interpret as beingThe American Psychological Association defines three types of stress -Acute, Episodic Acute and Chronic, further divided into Absolute Stressors (stressors that everyone exposed to them would interpret as being</p>
        <p>stressful) and Relative Stressors (stressors that only some exposed to them would interpret as being stressful). Albrecht [57] further defined four common types of stress, namely Time Stress, Anticipatory Stress (concerns about future events), Situational Stress (situations that you have no control over) and Encounter Stress (worry about interacting with a certain person or group of people).stressful) and Relative Stressors (stressors that only some exposed to them would interpret as being stressful). Albrecht [57] further defined four common types of stress, namely Time Stress, Anticipatory Stress (concerns about future events), Situational Stress (situations that you have no control over) and Encounter Stress (worry about interacting with a certain person or group of people).</p>
        <p>Table 5 provides a summary of the types of stressors applied during each study reviewed in this paper, as defined by Albrecht [57], with a number of studies including all four types within their study setting and protocol. All studies involved cognitive or work-related tasks under pressure, and as noted in Table 3, study subjects were screened for known health conditions in virtually all studies. Of the studies reviewed, three collected stress biomarker data during normal life conditions. Jin et al. [42] provided Empatica E4 devices to study subjects after device use training, allowing subjects to utilize the device event marker to indicate periods during the day when they felt moderate to high levels of stress. Kaczor et al. [25] performed a similar study in an healthcare emergency department, while Can et al. [12] investigated the predictive performance of models trained under laboratory conditions when predicting on data collected in normal life conditions, and found that models trained on data recorded during laboratory sessions outperformed models trained on data collected during normal daily life conditions, when predicting for daily life conditions. This particular study [12] is of importance to researchers interested in building models from study data, for use on patient data collected during normal life conditions.Table 5 provides a summary of the types of stressors applied during each study reviewed in this paper, as defined by Albrecht [57], with a number of studies including all four types within their study setting and protocol. All studies involved cognitive or work-related tasks under pressure, and as noted in Table 3, study subjects were screened for known health conditions in virtually all studies. Of the studies reviewed, three collected stress biomarker data during normal life conditions. Jin et al. [42] provided Empatica E4 devices to study subjects after device use training, allowing subjects to utilize the device event marker to indicate periods during the day when they felt moderate to high levels of stress. Kaczor et al. [25] performed a similar study in an healthcare emergency department, while Can et al. [12] investigated the predictive performance of models trained under laboratory conditions when predicting on data collected in normal life conditions, and found that models trained on data recorded during laboratory sessions outperformed models trained on data collected during normal daily life conditions, when predicting for daily life conditions. This particular study [12] is of importance to researchers interested in building models from study data, for use on patient data collected during normal life conditions.</p>
        <p>Reviewing the literature, we found several machine learning techniques applied to detect elevated levels of stress using wearable devices. Table 6 lists the papers reviewed and the machine learning algorithms utilized. In the following subsections, we provide a discussion on the different steps of the machine learning pipelines utilized, and analyze how previous works have performed those steps, noting their strengths and limitations.Reviewing the literature, we found several machine learning techniques applied to detect elevated levels of stress using wearable devices. Table 6 lists the papers reviewed and the machine learning algorithms utilized. In the following subsections, we provide a discussion on the different steps of the machine learning pipelines utilized, and analyze how previous works have performed those steps, noting their strengths and limitations.</p>
        <p>Electronic sensors used in wearable devices for recording biomarkers differ widely, and subsequently operate and record on different sampling frequencies. For the Empatica E4, for instance, the EDA signal is sampled at 4 Hz, while the HR signal is sampled at 1 Hz. Recorded session data for both sensors will therefor differ in length, and researchers will have to pre-process the sensor data by down-sampling the EDA signal to 1 Hz to ensure a like for like timestamp match with the HR signal, and subsequently any stress metric label for the exact time period. In the studies reviewed, [14,22,30,42,48] specifically noted that down-sampling was applied on data used within their experiments.Electronic sensors used in wearable devices for recording biomarkers differ widely, and subsequently operate and record on different sampling frequencies. For the Empatica E4, for instance, the EDA signal is sampled at 4 Hz, while the HR signal is sampled at 1 Hz. Recorded session data for both sensors will therefor differ in length, and researchers will have to pre-process the sensor data by down-sampling the EDA signal to 1 Hz to ensure a like for like timestamp match with the HR signal, and subsequently any stress metric label for the exact time period. In the studies reviewed, [14,22,30,42,48] specifically noted that down-sampling was applied on data used within their experiments.</p>
        <p>Due to varying experimental protocols and the ease of collection of non-stress samples, data is likely to be unbalanced with more non-stress samples versus stressed samples present in any given dataset. Therefore, another usual pre-processing step performed on wearable stress data is class balancing that can be done in different ways. For instance, Nkurikiyeyezu et al. [14] balanced the recorded sensor data by randomly discarding some samples from the majority (non-stressed) class, and further applied logarithmic, square root, and Yeo-Johnson transformations to ensure a Gaussian distribution, as required by their use of a linear regression model. Can et al. [29] also performed class-balancing through random down-sampling of the majority class (non-stressed observations) to match the minority class (stressed observations).Due to varying experimental protocols and the ease of collection of non-stress samples, data is likely to be unbalanced with more non-stress samples versus stressed samples present in any given dataset. Therefore, another usual pre-processing step performed on wearable stress data is class balancing that can be done in different ways. For instance, Nkurikiyeyezu et al. [14] balanced the recorded sensor data by randomly discarding some samples from the majority (non-stressed) class, and further applied logarithmic, square root, and Yeo-Johnson transformations to ensure a Gaussian distribution, as required by their use of a linear regression model. Can et al. [29] also performed class-balancing through random down-sampling of the majority class (non-stressed observations) to match the minority class (stressed observations).</p>
        <p>As noted in Table 7, neither up-sampling nor down-sampling techniques showed a substantial difference or improvement in predictive power, and this may be due to the lack of a proven strategy employed when selecting which observations to discard, potentially causing information loss [58] of important biomarker data during the sampling process. Class balancing techniques all have varied benefits and risks, as noted in Table 7, and to this extent, a number of methods have been proposed to improve class-balancing re-sampling techniques. Deng et al. [59] proposed a unified approach for multivariate time series classification when data is imbalanced, while Lee et al. [60] used a semi-supervised technique known as Active Learning to mitigate the effect of imbalanced class labels. Jiang et al. [61] proposed a new oversampling method based on the classification contribution degree to deal with a number of shortcomings when using SMOTE (Synthetic Minority Oversampling Technique) [62], such as oversampling from noisy points. A notable drawback of reliance on class balancing when dealing with highly imbalanced datasets such as the stress biomarker datasets included in this study, where the stressed period is generally the minority class, is reproducibility and generalizability on new, unseen data that may contain significant outliers and a different class distribution, depending on the study setting and protocol used during biomarker recording. Further research is required to identify robust techniques for dealing with these class imbalances in physiological biomarker datasets.As noted in Table 7, neither up-sampling nor down-sampling techniques showed a substantial difference or improvement in predictive power, and this may be due to the lack of a proven strategy employed when selecting which observations to discard, potentially causing information loss [58] of important biomarker data during the sampling process. Class balancing techniques all have varied benefits and risks, as noted in Table 7, and to this extent, a number of methods have been proposed to improve class-balancing re-sampling techniques. Deng et al. [59] proposed a unified approach for multivariate time series classification when data is imbalanced, while Lee et al. [60] used a semi-supervised technique known as Active Learning to mitigate the effect of imbalanced class labels. Jiang et al. [61] proposed a new oversampling method based on the classification contribution degree to deal with a number of shortcomings when using SMOTE (Synthetic Minority Oversampling Technique) [62], such as oversampling from noisy points. A notable drawback of reliance on class balancing when dealing with highly imbalanced datasets such as the stress biomarker datasets included in this study, where the stressed period is generally the minority class, is reproducibility and generalizability on new, unseen data that may contain significant outliers and a different class distribution, depending on the study setting and protocol used during biomarker recording. Further research is required to identify robust techniques for dealing with these class imbalances in physiological biomarker datasets.</p>
        <p>Differences in data range, units and scale can be problematic for some machine learning algorithms and standardization is usually applied to scale the data to have a mean of 0 and a standard deviation of 1. Similarly, the goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values. In the context of stress detection, normaliza- tion and standardization were utilized by [14,22,28,33,46], with [22] experimenting on both raw and standardized data, and finding that standardization offered improved predictive performance across all 10 machine learning algorithms tested. Another usual pre-processing step on biomedical signals such as stress-related biomarkers collected by wearable devices is filtering. This is done to reduce outliers and any potential noise. For instance, [6] applied a 5 Hz low-pass filter on the raw EDA signal, [28] applied a high-pass filter on the raw EDA signal, while [14,27,31] applied a 4 Hz fourth-order Butterworth low-pass filter, followed by a moving average filter, to reduce outliers and remove noise from EDA sensor signals.Differences in data range, units and scale can be problematic for some machine learning algorithms and standardization is usually applied to scale the data to have a mean of 0 and a standard deviation of 1. Similarly, the goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values. In the context of stress detection, normaliza- tion and standardization were utilized by [14,22,28,33,46], with [22] experimenting on both raw and standardized data, and finding that standardization offered improved predictive performance across all 10 machine learning algorithms tested. Another usual pre-processing step on biomedical signals such as stress-related biomarkers collected by wearable devices is filtering. This is done to reduce outliers and any potential noise. For instance, [6] applied a 5 Hz low-pass filter on the raw EDA signal, [28] applied a high-pass filter on the raw EDA signal, while [14,27,31] applied a 4 Hz fourth-order Butterworth low-pass filter, followed by a moving average filter, to reduce outliers and remove noise from EDA sensor signals.</p>
        <p>A common technique for extracting useful features representing physiological time series data, is to summarize the changing features of the existing data using summary statistics. Guo et al. [68] performed a study to evaluate summary statistics as features for clinical prediction tasks, and found that commonly used combinations of summary statistics such as [min, max, mean] and [min, max, mean, standard deviation (std)] achieved good prediction results in most cases. However, they reported that skew and kurtosis, which reflect the shape of a distribution, performed poorly when used individually as features for prediction, but appeared frequently in the optimal combinations, indicating that they can play a role as supplemental information. The techniques noted by Guo et al. [68] were frequently applied in the stress detection studies reviewed. Fourteen of the reviewed approaches [6,[11][12][13][14]26,28,29,[31][32][33][44][45][46] utilized summary statistics of biomarkers using a sliding-window approach, ranging from 0.25 seconds in one experiment up to 20 minutes in others, with varying degrees of success. In [69], the author noted summary windows of 30 and 60 seconds are most often utilized, based on the hypothesis that this fac-tor correlates with physiological response. Can et al. [29] decomposed the phasic and tonic components of the EDA signal using a convex optimization approach, as the tonic component includes more long-term slow changes, whereas phasic components include faster (event-related) changes. Both [29] and [22] found that sliding windows ranging between 10 and 17.5 minutes produced better detection accuracy, with [29] further noting that different machine learning algorithms relied on different window sizes, an important factor to consider for future research.A common technique for extracting useful features representing physiological time series data, is to summarize the changing features of the existing data using summary statistics. Guo et al. [68] performed a study to evaluate summary statistics as features for clinical prediction tasks, and found that commonly used combinations of summary statistics such as [min, max, mean] and [min, max, mean, standard deviation (std)] achieved good prediction results in most cases. However, they reported that skew and kurtosis, which reflect the shape of a distribution, performed poorly when used individually as features for prediction, but appeared frequently in the optimal combinations, indicating that they can play a role as supplemental information. The techniques noted by Guo et al. [68] were frequently applied in the stress detection studies reviewed. Fourteen of the reviewed approaches [6,[11][12][13][14]26,28,29,[31][32][33][44][45][46] utilized summary statistics of biomarkers using a sliding-window approach, ranging from 0.25 seconds in one experiment up to 20 minutes in others, with varying degrees of success. In [69], the author noted summary windows of 30 and 60 seconds are most often utilized, based on the hypothesis that this fac-tor correlates with physiological response. Can et al. [29] decomposed the phasic and tonic components of the EDA signal using a convex optimization approach, as the tonic component includes more long-term slow changes, whereas phasic components include faster (event-related) changes. Both [29] and [22] found that sliding windows ranging between 10 and 17.5 minutes produced better detection accuracy, with [29] further noting that different machine learning algorithms relied on different window sizes, an important factor to consider for future research.</p>
        <p>Jin et al. [42] used the 
            <rs type="software">tsfresh</rs> Python 
            <rs type="software">library</rs> to automatically generate 4536 features off their existing data and applied a Random Forest model as machine learning approach. To evaluate the performance of such a large number of features, the results were grouped around the key biomarkers (i.e. HR, EDA, TEMP), from which the features were engineered. Gjoreski et al. [13] used greedy step-wise selection to identify the top features considered most useful for their specific machine learning model, and further noted that when sensor-specific features are used, PPG-based features achieved higher predictive accuracy results, followed by the IBI and HR-based features. Iqbal et al. [28] found features based on HR and respiratory rate to be the most important, while Dalmeida et al. [46] focused their research specifically on HRV as a viable biomarker, and found HRV features to constitute good markers for stress detection.
        </p>
        <p>Of the 23 machine learning based stress detection studies reviewed, we noted the use of 16 different algorithms, including combinations of Logistic Regression (LR), Support Vector Machines (SVM), Decision Trees (DT), Random Forests (RF), Bayesian Networks (BN), Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA), k-Nearest Neighbor (kNN), Multi-layer Perceptron (MLP), Multi-task Fig. 2. Accuracy based on labeling method included in study. learning (MTL), Adaboost, Naive Bayes (NB), Bagging, Gradient Boosting (GB) and Neural Networks (NN). Of these, SVM, RF and kNN were the most commonly used for stress detection, with tree-based models such as RF and GB generally delivering better predictive performance on supervised binary classification objectives.Of the 23 machine learning based stress detection studies reviewed, we noted the use of 16 different algorithms, including combinations of Logistic Regression (LR), Support Vector Machines (SVM), Decision Trees (DT), Random Forests (RF), Bayesian Networks (BN), Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA), k-Nearest Neighbor (kNN), Multi-layer Perceptron (MLP), Multi-task Fig. 2. Accuracy based on labeling method included in study. learning (MTL), Adaboost, Naive Bayes (NB), Bagging, Gradient Boosting (GB) and Neural Networks (NN). Of these, SVM, RF and kNN were the most commonly used for stress detection, with tree-based models such as RF and GB generally delivering better predictive performance on supervised binary classification objectives.</p>
        <p>A standard approach consists of selecting a small number of algorithms that may be suitable for the problem, train each and select the best performing model based on their final predictive accuracy. [14] experimented on a single method (Random Forest) while [53] used 13 different algorithms to test the predictive accuracy of classification based models versus regression type models for predicting elevated levels of stress, of which Bagged Trees performed the best. Similarly, [6,13,25,26,29,31] utilized 5 to 7 different algorithms and compared the stress prediction accuracy of each, with the highest performing models listed in Table 6. Iqbal et al. [49] compared the performance of 7 supervised methods to 7 unsupervised methods and concluded that a careful selection of classification models is required when aiming to develop an accurate stress detection system, with unsupervised machine learning classifiers showing good performance in terms of classification accuracy.A standard approach consists of selecting a small number of algorithms that may be suitable for the problem, train each and select the best performing model based on their final predictive accuracy. [14] experimented on a single method (Random Forest) while [53] used 13 different algorithms to test the predictive accuracy of classification based models versus regression type models for predicting elevated levels of stress, of which Bagged Trees performed the best. Similarly, [6,13,25,26,29,31] utilized 5 to 7 different algorithms and compared the stress prediction accuracy of each, with the highest performing models listed in Table 6. Iqbal et al. [49] compared the performance of 7 supervised methods to 7 unsupervised methods and concluded that a careful selection of classification models is required when aiming to develop an accurate stress detection system, with unsupervised machine learning classifiers showing good performance in terms of classification accuracy.</p>
        <p>Additionally, the predictions from a set of algorithms can be combined based on averaging, weighted-averaging or voting, to produce a final prediction (commonly known as model ensembling). This technique was specifically noted in experiments done by Gjoreski et al. [13], Kaczor et al. [25] and Elgendi et al. [44].Additionally, the predictions from a set of algorithms can be combined based on averaging, weighted-averaging or voting, to produce a final prediction (commonly known as model ensembling). This technique was specifically noted in experiments done by Gjoreski et al. [13], Kaczor et al. [25] and Elgendi et al. [44].</p>
        <p>Hyperparameters can be defined as the different parameter values used to control the learning process of a machine learning algorithm, and can have a significant effect on their performance. Hyperparameter optimization is the process of finding the right combination of algorithm parameter values to achieve maximum performance on the given dataset. Examples of hyperparameters are the number of estimators (trees) and maximum tree depth in the Random Forest algorithm. Due to the large number of parameters that require tuning in different algorithms, automated methods [70] have been developed to scan the full parameter search space in a reasonable amount of time to determine the optimal combination. Of the stress-related studies reviewed, we noted [26] restricted the hyperparameter of the estimators count used in their Random Forest model to 20, while [42] performed a grid search with estimators set at 500. In [14], the authors used 1,000 estimators while limiting the tree depth to 2, in order to limit the possibility of over-fitting. For the decision tree classification algorithms used by [6], information gain was used to measure the quality of splitting decision nodes, and the minimum number of samples required to split a node was set to 20. The number of base estimators was set to 100 for both of their utilized algorithms (Random Forest and AdaBoost). In another study, Han et al. [31] did not specifically optimize hyperparameters, but built several kNN models with different parameter values for k (1, 3, 5, 7, 9) and selected the best performing model from those. Sevil et al. [33] utilized Bayesian optimization techniques for feature-selection.Hyperparameters can be defined as the different parameter values used to control the learning process of a machine learning algorithm, and can have a significant effect on their performance. Hyperparameter optimization is the process of finding the right combination of algorithm parameter values to achieve maximum performance on the given dataset. Examples of hyperparameters are the number of estimators (trees) and maximum tree depth in the Random Forest algorithm. Due to the large number of parameters that require tuning in different algorithms, automated methods [70] have been developed to scan the full parameter search space in a reasonable amount of time to determine the optimal combination. Of the stress-related studies reviewed, we noted [26] restricted the hyperparameter of the estimators count used in their Random Forest model to 20, while [42] performed a grid search with estimators set at 500. In [14], the authors used 1,000 estimators while limiting the tree depth to 2, in order to limit the possibility of over-fitting. For the decision tree classification algorithms used by [6], information gain was used to measure the quality of splitting decision nodes, and the minimum number of samples required to split a node was set to 20. The number of base estimators was set to 100 for both of their utilized algorithms (Random Forest and AdaBoost). In another study, Han et al. [31] did not specifically optimize hyperparameters, but built several kNN models with different parameter values for k (1, 3, 5, 7, 9) and selected the best performing model from those. Sevil et al. [33] utilized Bayesian optimization techniques for feature-selection.</p>
        <p>Unlike the aforementioned works, Gjoreski et al. [22] tuned their model parameters by randomly sampling from distributions predefined by an expert. The models were then trained with the specific parameters and evaluated using cross-validation on the training data. The best performing model from the cross-validation was used to classify the test data. A systematic, well-defined hyperparameter optimization approach is crucial to improve the reproducibility of scientific studies and ensures that machine learning algorithms are tailored to the problem at hand. As noted by Can et al. [29], the performance of machine learning models may be dependent on an optimal selection of window size when generating summary statistics to engineer features, and this needs consideration when selecting hyperparameters for optimal predictive performance.Unlike the aforementioned works, Gjoreski et al. [22] tuned their model parameters by randomly sampling from distributions predefined by an expert. The models were then trained with the specific parameters and evaluated using cross-validation on the training data. The best performing model from the cross-validation was used to classify the test data. A systematic, well-defined hyperparameter optimization approach is crucial to improve the reproducibility of scientific studies and ensures that machine learning algorithms are tailored to the problem at hand. As noted by Can et al. [29], the performance of machine learning models may be dependent on an optimal selection of window size when generating summary statistics to engineer features, and this needs consideration when selecting hyperparameters for optimal predictive performance.</p>
        <p>An important requirement when developing supervised machine learning algorithms is to have valid labeled data. In the case of stress measurement, we found three main methods employed for labeling elevated levels of stress. These include (i) specific stress/no-stress periods marked during an experimental recording session [6,7,25,27,[29][30][31][32][33]38,39,[43][44][45][46][47][48][49]; (ii) self-reporting via questionnaires [8,12,13,22,26,28,37]; and (iii) labeling by a third-party observer, who observes subjects' response to a situation and numerically scores/grades the level of stress observed [10,11,37,42]. Fig. 2 details the studies reviewed for each year, with reported accuracy rates by labeling method. Periodic labeling was the most commonly used labeling technique and provided consistently higher accuracy rates as reported by each study, compared to self-scoring and scoring by a third-party.An important requirement when developing supervised machine learning algorithms is to have valid labeled data. In the case of stress measurement, we found three main methods employed for labeling elevated levels of stress. These include (i) specific stress/no-stress periods marked during an experimental recording session [6,7,25,27,[29][30][31][32][33]38,39,[43][44][45][46][47][48][49]; (ii) self-reporting via questionnaires [8,12,13,22,26,28,37]; and (iii) labeling by a third-party observer, who observes subjects' response to a situation and numerically scores/grades the level of stress observed [10,11,37,42]. Fig. 2 details the studies reviewed for each year, with reported accuracy rates by labeling method. Periodic labeling was the most commonly used labeling technique and provided consistently higher accuracy rates as reported by each study, compared to self-scoring and scoring by a third-party.</p>
        <p>As highlighted in Table 6, the best performing models from each experiment achieved at least 64.5% test accuracy, with [6,14,[30][31][32][33]47] reporting binary classification test accuracy rates of over 90%, using datasets labeled with specific, marked stress/no-stress periods. It should be noted that as stress is a physiological response, predictive accuracy in these experiments measures a predictive correlation between the included features (biomarkers) against a labeled metric at the same point in time (stressed versus non-stressed). Siirtola et al. [53] attempted to model how high this relationship is (using a regression algorithm instead of classification), while Umematsu et al. [71] focused on the problem of forecasting future episodes of stress, rather than measuring levels of stress on previously recorded data.As highlighted in Table 6, the best performing models from each experiment achieved at least 64.5% test accuracy, with [6,14,[30][31][32][33]47] reporting binary classification test accuracy rates of over 90%, using datasets labeled with specific, marked stress/no-stress periods. It should be noted that as stress is a physiological response, predictive accuracy in these experiments measures a predictive correlation between the included features (biomarkers) against a labeled metric at the same point in time (stressed versus non-stressed). Siirtola et al. [53] attempted to model how high this relationship is (using a regression algorithm instead of classification), while Umematsu et al. [71] focused on the problem of forecasting future episodes of stress, rather than measuring levels of stress on previously recorded data.</p>
        <p>Cross-validation is a re-sampling procedure used to evaluate machine learning models on a limited data sample. The purpose of crossvalidation is to test the ability of a machine learning model to predict with high accuracy on new, unseen data. It is also used to flag problems like over-fitting or selection bias, and gives insights on how well the model will generalize to an independent dataset. Among the studies reviewed, [6,11,13,22,26,27,32,45] utilized Leave One Subject Out (LOSO) cross-validation, while [12,14,25,28,29,31,33,42,43] utilized K-fold cross-validation with K=10. In addition, [22] utilized both LOSO and K-fold cross-validation, with K=5. All studies reviewed approached stress prediction as a binary classification problem apart from [53], where the problem type was defined as stress level measurement, rather than a binary stressed versus non-stressed problem. No definitive improvement in reported accuracy rates were noted when using LOSO cross-validation compared to K-fold cross-validation.Cross-validation is a re-sampling procedure used to evaluate machine learning models on a limited data sample. The purpose of crossvalidation is to test the ability of a machine learning model to predict with high accuracy on new, unseen data. It is also used to flag problems like over-fitting or selection bias, and gives insights on how well the model will generalize to an independent dataset. Among the studies reviewed, [6,11,13,22,26,27,32,45] utilized Leave One Subject Out (LOSO) cross-validation, while [12,14,25,28,29,31,33,42,43] utilized K-fold cross-validation with K=10. In addition, [22] utilized both LOSO and K-fold cross-validation, with K=5. All studies reviewed approached stress prediction as a binary classification problem apart from [53], where the problem type was defined as stress level measurement, rather than a binary stressed versus non-stressed problem. No definitive improvement in reported accuracy rates were noted when using LOSO cross-validation compared to K-fold cross-validation.</p>
        <p>A wide variety of metrics are available for measuring machine learning model performance, depending on the problem being solved, for example classification or regression type problems. The experiments reviewed utilized and reported a number of different evaluation metrics including F-score [6,22,29,45,48,49], classification accuracy [12,13,[25][26][27][28][29][30][31][32][33][43][44][45][46]48,49], Kappa [47], Area Under the Curve (AUC) [42,46] and Mean Absolute Error (MAE) [14]. For comparisons among the reviewed studies, here we only investigate their achieved classification accuracy, if reported. Classification accuracy simply measures how often the classifier correctly predicts, i.e. what is the ratio of the number of correct predictions to the total number of predictions.A wide variety of metrics are available for measuring machine learning model performance, depending on the problem being solved, for example classification or regression type problems. The experiments reviewed utilized and reported a number of different evaluation metrics including F-score [6,22,29,45,48,49], classification accuracy [12,13,[25][26][27][28][29][30][31][32][33][43][44][45][46]48,49], Kappa [47], Area Under the Curve (AUC) [42,46] and Mean Absolute Error (MAE) [14]. For comparisons among the reviewed studies, here we only investigate their achieved classification accuracy, if reported. Classification accuracy simply measures how often the classifier correctly predicts, i.e. what is the ratio of the number of correct predictions to the total number of predictions.</p>
        <p>To determine classification accuracy, Kaczor et al. [25] divided their dataset into 3 classes: a pre-stress event vs post-stress event, baseline vs pre-stress event, and baseline vs post-stress event, reporting a classifi-cation accuracy rate of 90.4%. Can et al. [29] reported a binary classification accuracy rate of 97.92% using a custom (non-public) dataset, and Gjoreski et al. [22] reported a binary classification accuracy rate of 68.2% when applied on the CogLoad dataset and 82.3% when applied on the Snake dataset. Han et al. reported a binary accuracy rate of 94.55%, while Nkurikiyeyezu et al. [14] and Schmidt et al. [6] reported binary classification accuracy rates of 93.9% and 93% respectively. Jin et al. [42] reported an AUC rate of 89.4% rather than an accuracy rate. AUC, unlike classification accuracy, is sensitive to class imbalance when there is a minority class. This implies that classification accuracy rates can be high even if the predictions for a minority class are mostly wrong. This could lead to samples marked as non-stressed being classified mostly correctly and stressed samples (the minority class) predicted inaccurately, while still reporting an overall high accuracy rate.To determine classification accuracy, Kaczor et al. [25] divided their dataset into 3 classes: a pre-stress event vs post-stress event, baseline vs pre-stress event, and baseline vs post-stress event, reporting a classifi-cation accuracy rate of 90.4%. Can et al. [29] reported a binary classification accuracy rate of 97.92% using a custom (non-public) dataset, and Gjoreski et al. [22] reported a binary classification accuracy rate of 68.2% when applied on the CogLoad dataset and 82.3% when applied on the Snake dataset. Han et al. reported a binary accuracy rate of 94.55%, while Nkurikiyeyezu et al. [14] and Schmidt et al. [6] reported binary classification accuracy rates of 93.9% and 93% respectively. Jin et al. [42] reported an AUC rate of 89.4% rather than an accuracy rate. AUC, unlike classification accuracy, is sensitive to class imbalance when there is a minority class. This implies that classification accuracy rates can be high even if the predictions for a minority class are mostly wrong. This could lead to samples marked as non-stressed being classified mostly correctly and stressed samples (the minority class) predicted inaccurately, while still reporting an overall high accuracy rate.</p>
        <p>Fig. 3 details the reported accuracy metrics achieved for the experiments reviewed in this paper, based on the size of the dataset used in terms of individual test subjects. The highest reported accuracy rate of 98.30% was achieved by Sevil et al. [33] when using Linear Discriminant Analysis (LDA) on a non-public dataset consisting of 24 test subjects, and validated using K-Fold cross-validation. Liapis et al. [47] trained a Neural Network on the public WESAD dataset (15 subjects), and evaluated on a user-annotated dataset consisting of skin conductivity (SC) segments for 30 study participants, reporting an accuracy rate of 97.40%.Fig. 3 details the reported accuracy metrics achieved for the experiments reviewed in this paper, based on the size of the dataset used in terms of individual test subjects. The highest reported accuracy rate of 98.30% was achieved by Sevil et al. [33] when using Linear Discriminant Analysis (LDA) on a non-public dataset consisting of 24 test subjects, and validated using K-Fold cross-validation. Liapis et al. [47] trained a Neural Network on the public WESAD dataset (15 subjects), and evaluated on a user-annotated dataset consisting of skin conductivity (SC) segments for 30 study participants, reporting an accuracy rate of 97.40%.</p>
        <p>The Supplementary File details the results of the IJMEDI quality assessment. Table 8 summarizes the scores of each dimension and the total score in each study. The average score of the included studies was 25.7 (range: . Most of the studies were of a medium quality, while one [72] were of a high quality. The majority of the studies had an obvious bias in the quality of problem understanding, data understanding and modeling dimensions. Fig. 4 shows the proportion of the different answers in the high and low priority items.The Supplementary File details the results of the IJMEDI quality assessment. Table 8 summarizes the scores of each dimension and the total score in each study. The average score of the included studies was 25.7 (range: . Most of the studies were of a medium quality, while one [72] were of a high quality. The majority of the studies had an obvious bias in the quality of problem understanding, data understanding and modeling dimensions. Fig. 4 shows the proportion of the different answers in the high and low priority items.</p>
        <p>In order to build a robust machine learning model capable of accurately detecting stress, we consider four important requirements. These include (i) Sensor biomarker data needs to be valid and sufficiently varied to capture a wide spectrum of potential physiological stress response; (ii) For supervised machine learning, this data needs to be accurately labeled where observations are marked as stressed or nonstressed or a stress score range is given, to allow the model to learn from the data; (iii) Where a specific hypothesis is being tested, a sufficient level of statistical power is required [36,39,[73][74][75], thereby ensuring results and findings can be considered statistically significant, and (iv) Model generalization occurs in order to apply the model on new, unseen data, with high accuracy. The discussion of this review is therefor focused on those four key requirements. Having scored the machine learning studies included in this review using the IJMEDI checklist, we found only one study [72] of high quality, with the remaining studies being of medium quality, and a single study being of low quality [45]. Most studies scored well in problem, data understanding and modeling domains. Data preparation and de-ployment scores were notably low, as were scores for high priority items in the validation domain. Interestingly, there were no notable improvement in study quality over time.In order to build a robust machine learning model capable of accurately detecting stress, we consider four important requirements. These include (i) Sensor biomarker data needs to be valid and sufficiently varied to capture a wide spectrum of potential physiological stress response; (ii) For supervised machine learning, this data needs to be accurately labeled where observations are marked as stressed or nonstressed or a stress score range is given, to allow the model to learn from the data; (iii) Where a specific hypothesis is being tested, a sufficient level of statistical power is required [36,39,[73][74][75], thereby ensuring results and findings can be considered statistically significant, and (iv) Model generalization occurs in order to apply the model on new, unseen data, with high accuracy. The discussion of this review is therefor focused on those four key requirements. Having scored the machine learning studies included in this review using the IJMEDI checklist, we found only one study [72] of high quality, with the remaining studies being of medium quality, and a single study being of low quality [45]. Most studies scored well in problem, data understanding and modeling domains. Data preparation and de-ployment scores were notably low, as were scores for high priority items in the validation domain. Interestingly, there were no notable improvement in study quality over time.</p>
        <p>Five studies [14,22,43,48,72] scored over 30, being of medium to higher quality. Focusing on the modeling, validation and deployment domain scores of these eight studies, we note an improvement in quality over time for only the validation domain, indicating a lack of progress in the modeling domain and little focus on the deployment of models in real-life scenarios, including factors pertaining to sustainability, model bias and ethics. See Fig. 5.Five studies [14,22,43,48,72] scored over 30, being of medium to higher quality. Focusing on the modeling, validation and deployment domain scores of these eight studies, we note an improvement in quality over time for only the validation domain, indicating a lack of progress in the modeling domain and little focus on the deployment of models in real-life scenarios, including factors pertaining to sustainability, model bias and ethics. See Fig. 5.</p>
        <p>The datasets included in this study contain a variety of sensor biomarker data potentially useful in detecting elevated levels of stress via HR, HRV and EDA signals, measured across a time interval. In addition, sweat sensing is at the forefront of wearable stress detection currently in development [34] and devices sensing sweat may hold great promise to quantify several biomarkers, namely Cortisol, to monitor the levels of stress that an individual is experiencing.The datasets included in this study contain a variety of sensor biomarker data potentially useful in detecting elevated levels of stress via HR, HRV and EDA signals, measured across a time interval. In addition, sweat sensing is at the forefront of wearable stress detection currently in development [34] and devices sensing sweat may hold great promise to quantify several biomarkers, namely Cortisol, to monitor the levels of stress that an individual is experiencing.</p>
        <p>However, [76] noted that at present, there is a lack of consensus on a standardized protocol or framework with which to test the validity of physiological signals measured by these devices and their derived parameters. It is also argued that sudden, short-lived stressors, such as being startled by the ringing of the phone, or possible habituation effects as a result of exposure to repeated information cannot be validly detected. Lier et al. [76] reported that physiological changes during a workday can be tracked by the Empatica E4 wearable against more major, sustained stressors.However, [76] noted that at present, there is a lack of consensus on a standardized protocol or framework with which to test the validity of physiological signals measured by these devices and their derived parameters. It is also argued that sudden, short-lived stressors, such as being startled by the ringing of the phone, or possible habituation effects as a result of exposure to repeated information cannot be validly detected. Lier et al. [76] reported that physiological changes during a workday can be tracked by the Empatica E4 wearable against more major, sustained stressors.</p>
        <p>In [77], the authors found the Empatica E4 to be suitable for psychotherapy research focused on Inter-Beat Interval (IBI) and specific HRV measures, but failed to produce reliable EDA data and produced missing IBI data, especially when a subject is being more dynamic. This is confirmed by Ryan et al. [78] and Sevil et al. [33] that found the Empatica E4 can be severely compromised by motion artifact. This can result in a high percentage of missing data across all conditions except seated and supine baselines, and questions the E4's efficacy as an HRV measurement tool in most in-vivo conditions. This is further confirmed by Georgiou et al. [79] that found wearable devices can only be used as a surrogate for HRV at resting or mild exercise conditions, as their accuracy fades out with increasing exercise load, and Schuurmans et al. [80] who noted the potential of the Empatica E4 as a practical and valid tool for research on HR and HRV under non-movement conditions. Seipaejaervi et al. [81] found that an HRV-based stress index mirrors responses of cortisol, and an HRV-based stress index may be used to quantify physiological responses to psychosocial stress across various health and age groups. In contrast, Greco et al. [32] found EDA to be a good marker of stress when features are engineered based on its phasic and tonic components.In [77], the authors found the Empatica E4 to be suitable for psychotherapy research focused on Inter-Beat Interval (IBI) and specific HRV measures, but failed to produce reliable EDA data and produced missing IBI data, especially when a subject is being more dynamic. This is confirmed by Ryan et al. [78] and Sevil et al. [33] that found the Empatica E4 can be severely compromised by motion artifact. This can result in a high percentage of missing data across all conditions except seated and supine baselines, and questions the E4's efficacy as an HRV measurement tool in most in-vivo conditions. This is further confirmed by Georgiou et al. [79] that found wearable devices can only be used as a surrogate for HRV at resting or mild exercise conditions, as their accuracy fades out with increasing exercise load, and Schuurmans et al. [80] who noted the potential of the Empatica E4 as a practical and valid tool for research on HR and HRV under non-movement conditions. Seipaejaervi et al. [81] found that an HRV-based stress index mirrors responses of cortisol, and an HRV-based stress index may be used to quantify physiological responses to psychosocial stress across various health and age groups. In contrast, Greco et al. [32] found EDA to be a good marker of stress when features are engineered based on its phasic and tonic components.</p>
        <p>In [11], the authors predominantly focused on comparing regression vs. classification models using the AffectiveROAD dataset [10]. This dataset contains sensor recordings for both left and right hands of the test subjects. To ensure consistent, comparable results, [11] utilized only data recorded from the right hand of each test subject, leaving the important question of sensor placement unanswered, and needing further study to confirm whether sensor placement on the dominant versus non-dominant hand of a test subject could potentially affect biomarker accuracy, and more importantly for this review, correlation with increased levels of stress. Empatica note on their website [16] that newer studies have shown substantial differences in the EDA signal between the dominant and non-dominant hand.In [11], the authors predominantly focused on comparing regression vs. classification models using the AffectiveROAD dataset [10]. This dataset contains sensor recordings for both left and right hands of the test subjects. To ensure consistent, comparable results, [11] utilized only data recorded from the right hand of each test subject, leaving the important question of sensor placement unanswered, and needing further study to confirm whether sensor placement on the dominant versus non-dominant hand of a test subject could potentially affect biomarker accuracy, and more importantly for this review, correlation with increased levels of stress. Empatica note on their website [16] that newer studies have shown substantial differences in the EDA signal between the dominant and non-dominant hand.</p>
        <p>In terms of labeling protocol and methodology, [11] questioned the accuracy of self-reporting of perceived levels of stress experienced, which was previously questioned by [82], who noted that study subjects are less likely to report on states less socially desired. Accurate labeling of stressed/non-stressed periods in the sensor data is crucial to building a reliable and robust machine learning model. To achieve this, in the datasets reviewed in Table 4, two major labeling methods were used. The SWELL, Toadstool and WESAD datasets were recorded with specific intervals to denote stressed/non-stressed periods for labeling. In the AffectiveROAD, MMASH and K-EmoCon datasets, on the other hand, labeling was performed using self or observed stress indicator scoring. An interesting observation is that where these datasets were utilized in reviewed machine learning models, the models trained on periodically-labeled data achieved significantly higher levels of detection accuracy compared to the models trained using self or observed stress scoring. This is likely due to false negative reporting in the questionnaires, as noted by [82].In terms of labeling protocol and methodology, [11] questioned the accuracy of self-reporting of perceived levels of stress experienced, which was previously questioned by [82], who noted that study subjects are less likely to report on states less socially desired. Accurate labeling of stressed/non-stressed periods in the sensor data is crucial to building a reliable and robust machine learning model. To achieve this, in the datasets reviewed in Table 4, two major labeling methods were used. The SWELL, Toadstool and WESAD datasets were recorded with specific intervals to denote stressed/non-stressed periods for labeling. In the AffectiveROAD, MMASH and K-EmoCon datasets, on the other hand, labeling was performed using self or observed stress indicator scoring. An interesting observation is that where these datasets were utilized in reviewed machine learning models, the models trained on periodically-labeled data achieved significantly higher levels of detection accuracy compared to the models trained using self or observed stress scoring. This is likely due to false negative reporting in the questionnaires, as noted by [82].</p>
        <p>Stress is not a binary condition, and none of the studies reviewed noted specific methods for establishing thresholds within biomarkers to utilize as indicators of periods of high stress (low, moderate, high). Any potential thresholds established by the machine learning algorithms, (specifically tree-based methods) during training were not examined in detail to determine any potential time-varying dynamics between the biomarkers. Ghiasi et al. [83] proposed combining HRV and EDA correlates as a single index, rather than treating each as separate indicators of ANS changes. They reported good results when validating this metric on two experimental protocols.Stress is not a binary condition, and none of the studies reviewed noted specific methods for establishing thresholds within biomarkers to utilize as indicators of periods of high stress (low, moderate, high). Any potential thresholds established by the machine learning algorithms, (specifically tree-based methods) during training were not examined in detail to determine any potential time-varying dynamics between the biomarkers. Ghiasi et al. [83] proposed combining HRV and EDA correlates as a single index, rather than treating each as separate indicators of ANS changes. They reported good results when validating this metric on two experimental protocols.</p>
        <p>Of the papers included in this review, six [14,26,28,43,44,46] specifically included a hypothesis statement in their experiments. However, no power analysis were noted in any of the machine learning papers reviewed, regardless of hypothesis statement. It is common to design behavioral science experiments with a statistical power of 80% or higher Fig. 6. Accuracy based on number of subjects included in study. [73], which reduces the probability of encountering a Type II error by up to 20% [84]. Statistical power has three parts: effect size (a statistical measure), sample size (number of observations or participants) and significance (typically 0.05 [73]). Power analysis assists researchers in determining the smallest sample size suitable to detect the effect of a given experiment at a desired level of significance, as collecting larger samples are likely costlier and much harder. The use of machine learning in behavioral science experiments does not automatically negate the need for sufficient statistical power [36,75].Of the papers included in this review, six [14,26,28,43,44,46] specifically included a hypothesis statement in their experiments. However, no power analysis were noted in any of the machine learning papers reviewed, regardless of hypothesis statement. It is common to design behavioral science experiments with a statistical power of 80% or higher Fig. 6. Accuracy based on number of subjects included in study. [73], which reduces the probability of encountering a Type II error by up to 20% [84]. Statistical power has three parts: effect size (a statistical measure), sample size (number of observations or participants) and significance (typically 0.05 [73]). Power analysis assists researchers in determining the smallest sample size suitable to detect the effect of a given experiment at a desired level of significance, as collecting larger samples are likely costlier and much harder. The use of machine learning in behavioral science experiments does not automatically negate the need for sufficient statistical power [36,75].</p>
        <p>One of the recurrent questions psychology researchers ask is: "What is the minimum number of participants I must test?" [74]. The high number of participants required for an 80% powered study often surprises cognitive psychologists, because in their experience, replicable research can be done with a smaller number. For a long time, samples of 20-24 participants were the norm in experimental psychology [74]. However, when applying a two-tailed power test with a correlation coefficient of 0.5 [73] and an assumed significance level of 𝛼 =0.05, we found that at least 34 test subjects would be required to achieve 80% power. Where correlation is notably less, for example stress biomarker correlation with a periodic stress label, substantially more subjects could be required to achieve at least 80% statistical power. Iqbal et al. [39] specifically performed a power analysis and similarly concluded that at least 34 test subjects would be required to achieve 80% statistical power, and built their Stress-Predict dataset using 35 test subjects.One of the recurrent questions psychology researchers ask is: "What is the minimum number of participants I must test?" [74]. The high number of participants required for an 80% powered study often surprises cognitive psychologists, because in their experience, replicable research can be done with a smaller number. For a long time, samples of 20-24 participants were the norm in experimental psychology [74]. However, when applying a two-tailed power test with a correlation coefficient of 0.5 [73] and an assumed significance level of 𝛼 =0.05, we found that at least 34 test subjects would be required to achieve 80% power. Where correlation is notably less, for example stress biomarker correlation with a periodic stress label, substantially more subjects could be required to achieve at least 80% statistical power. Iqbal et al. [39] specifically performed a power analysis and similarly concluded that at least 34 test subjects would be required to achieve 80% statistical power, and built their Stress-Predict dataset using 35 test subjects.</p>
        <p>Considering the small number of subjects contained in the datasets utilized in the experiments reviewed in this paper (Fig. 6), the statistical power of the experiments and subsequent conclusions reached on the accuracy achieved will be overshadowed, more so if these trained models were applied on new, unseen datasets (to confirm generalization). This holds true when the objective is to infer an unknown truth from the observed data, and hypothesis testing provides a specific framework whose inferential target is a binary truth (stressed vs. non-stressed). For example, whether an EDA biomarker from wearable device data provides a signal that correlates with an elevated level of stress. Li et al. [85] provides a detailed discussion and guidelines for choosing between the two strategies (hypothesis testing versus machine learning classification) when designing an experiment that can assist researchers in choosing a strategy and when required, validate whether their sample size contains sufficient power.Considering the small number of subjects contained in the datasets utilized in the experiments reviewed in this paper (Fig. 6), the statistical power of the experiments and subsequent conclusions reached on the accuracy achieved will be overshadowed, more so if these trained models were applied on new, unseen datasets (to confirm generalization). This holds true when the objective is to infer an unknown truth from the observed data, and hypothesis testing provides a specific framework whose inferential target is a binary truth (stressed vs. non-stressed). For example, whether an EDA biomarker from wearable device data provides a signal that correlates with an elevated level of stress. Li et al. [85] provides a detailed discussion and guidelines for choosing between the two strategies (hypothesis testing versus machine learning classification) when designing an experiment that can assist researchers in choosing a strategy and when required, validate whether their sample size contains sufficient power.</p>
        <p>Interestingly, as shown in Fig. 6, there appears to be no obvious correlation between the number of subjects included in the study with the reported accuracy rate. In virtually all the reviewed studies the number of subjects were less than 30. None of these studies apart from Mishra et al. [41] and Liapis et al. [47], tested generalization of the resulting models on a totally unseen, new dataset, to further validate the reported accuracy achieved in the experiments, when trained on a public dataset.Interestingly, as shown in Fig. 6, there appears to be no obvious correlation between the number of subjects included in the study with the reported accuracy rate. In virtually all the reviewed studies the number of subjects were less than 30. None of these studies apart from Mishra et al. [41] and Liapis et al. [47], tested generalization of the resulting models on a totally unseen, new dataset, to further validate the reported accuracy achieved in the experiments, when trained on a public dataset.</p>
        <p>Fig. 6 further shows the calculated statistical power given a twotailed power test with a correlation coefficient of 0.5 [73], and an assumed significance level of 𝛼 =0.05 for each of the studies reviewed, based on the number of unique test subjects contained within each dataset when used for training and validation. Of these, datasets utilized by Greco et al. [32] and Ehrhart et al. [48] achieved at least 80% power by using non-public datasets while the public WESAD [6,14,27,28,30,45,47] and SWELL [14,49] datasets achieve 45% and 70% power respectively, based on number of test subjects included.Fig. 6 further shows the calculated statistical power given a twotailed power test with a correlation coefficient of 0.5 [73], and an assumed significance level of 𝛼 =0.05 for each of the studies reviewed, based on the number of unique test subjects contained within each dataset when used for training and validation. Of these, datasets utilized by Greco et al. [32] and Ehrhart et al. [48] achieved at least 80% power by using non-public datasets while the public WESAD [6,14,27,28,30,45,47] and SWELL [14,49] datasets achieve 45% and 70% power respectively, based on number of test subjects included.</p>
        <p>The majority of studies in this review use a custom or public dataset to train their machine learning algorithms using time-series biomarker data within that dataset. These models are then evaluated using the test set of the same dataset, meaning the same experimental setup, and sometimes, different biomarker recordings of previously observed subjects during training. This cannot ensure generalizability of the developed model to other subjects or datasets. Recently some studies are evaluating the potential of person-specific models and their promise in improving generic stress detection models [14]. Of the studies reviews in this paper, and scored using the IJMEDI checklist [2], three studies [32,47,48] were found to likely achieve generalization (Table 8), based on model validation and the use of sufficiently large training datasets based on the number of individual study subjects included.The majority of studies in this review use a custom or public dataset to train their machine learning algorithms using time-series biomarker data within that dataset. These models are then evaluated using the test set of the same dataset, meaning the same experimental setup, and sometimes, different biomarker recordings of previously observed subjects during training. This cannot ensure generalizability of the developed model to other subjects or datasets. Recently some studies are evaluating the potential of person-specific models and their promise in improving generic stress detection models [14]. Of the studies reviews in this paper, and scored using the IJMEDI checklist [2], three studies [32,47,48] were found to likely achieve generalization (Table 8), based on model validation and the use of sufficiently large training datasets based on the number of individual study subjects included.</p>
        <p>Focusing specifically on results reported when models are trained and evaluated on the most commonly used WESAD dataset (Table 6), we note that of those experiments reporting accuracy rates higher than 90% [6,14,30,47], all included both EDA and HR (or HRV) biomarkers, while those excluding either the HR or EDA biomarkers [27,28,45] consistently reported accuracy rates below 86%, irrespective of featureengineering or cross-validation technique applied. This observation is in line with findings by Schmidt et al. [6] who noted their reported highest accuracy rate of 93% dropped to 88.33% when excluding the HR biomarker during model training and validation. This may indi- cate that both EDA and HR (or derivatives including HRV) biomarkers play an equally important role in correlation with perceived elevated levels of stress and require further examination, considering the small sample of experiments reviewed. Additionally, when considering the advancement of machine learning technologies over the last decade, there appears to be no consistent increase in model performance or reported accuracy over time (Fig. 7), indicating that model generalization with respect to stress detection and measurement using machine learning techniques remains a challenge.Focusing specifically on results reported when models are trained and evaluated on the most commonly used WESAD dataset (Table 6), we note that of those experiments reporting accuracy rates higher than 90% [6,14,30,47], all included both EDA and HR (or HRV) biomarkers, while those excluding either the HR or EDA biomarkers [27,28,45] consistently reported accuracy rates below 86%, irrespective of featureengineering or cross-validation technique applied. This observation is in line with findings by Schmidt et al. [6] who noted their reported highest accuracy rate of 93% dropped to 88.33% when excluding the HR biomarker during model training and validation. This may indi- cate that both EDA and HR (or derivatives including HRV) biomarkers play an equally important role in correlation with perceived elevated levels of stress and require further examination, considering the small sample of experiments reviewed. Additionally, when considering the advancement of machine learning technologies over the last decade, there appears to be no consistent increase in model performance or reported accuracy over time (Fig. 7), indicating that model generalization with respect to stress detection and measurement using machine learning techniques remains a challenge.</p>
        <p>The significant observations from this review are:The significant observations from this review are:</p>
        <p>• Technological improvements in wearable devices have seen a rapid improvement in complexity, ease of use and affordability. This has helped many studies to record and analyze various physiological signals that can be used as biomarkers. • Sensor biomarkers vary across the wearable devices reviewed, with questions remaining on whether all sensor data can be considered valid and accurate for use in stress detection and measurement, or which biomarkers are the best when measuring stress. • Existing work has predominantly used small datasets acquired in a single experimental setup with varying labeling protocols, bringing into question the statistical power of these small datasets when used for both training and validation. • In the studies reviewed, model validation was performed predominantly using LOSO or K-Fold cross-validation, with no further validation on a completely new, unseen dataset recorded in different experimental conditions using new study participants, leaving the question of model generalization unanswered.• Technological improvements in wearable devices have seen a rapid improvement in complexity, ease of use and affordability. This has helped many studies to record and analyze various physiological signals that can be used as biomarkers. • Sensor biomarkers vary across the wearable devices reviewed, with questions remaining on whether all sensor data can be considered valid and accurate for use in stress detection and measurement, or which biomarkers are the best when measuring stress. • Existing work has predominantly used small datasets acquired in a single experimental setup with varying labeling protocols, bringing into question the statistical power of these small datasets when used for both training and validation. • In the studies reviewed, model validation was performed predominantly using LOSO or K-Fold cross-validation, with no further validation on a completely new, unseen dataset recorded in different experimental conditions using new study participants, leaving the question of model generalization unanswered.</p>
        <p>To achieve reliable machine learning models suitable for real-world monitoring of stress, three formidable challenges should be addressed.To achieve reliable machine learning models suitable for real-world monitoring of stress, three formidable challenges should be addressed.</p>
        <p>• Varying experimental and labeling protocols influence stress measurement and detection accuracy. To address this challenge, there exists the need for a definitive set of test guidelines when using wearable devices to record biomarker data, including appraisal and scoring methodology. In [86], the authors concluded that, the appraisal process critically shapes an individual's response to acute stress, while [87] detected lower EDA biomarker activity in response to episodes of acute stress in caregivers of people with Autism Spectrum Disorder, a potential habituation to stress. These findings support the need for a proper understanding of when wearable devices can and should be used, and potential factors that could affect sensor accuracy. • Measurement accuracy is a major challenge that can significantly affect wearable device data and consequently any stress measurements. One of the main problems with current wearables is significant motion artifacts, which may be reduced by measures for better and more stable placement of the device, or through placing the device on other parts of the body. • Another significant challenge is the lack of large, diverse public datasets built from wearable sensor data that can be utilized to build machine learning models for predicting elevated levels of stress that generalize well to unseen data.• Varying experimental and labeling protocols influence stress measurement and detection accuracy. To address this challenge, there exists the need for a definitive set of test guidelines when using wearable devices to record biomarker data, including appraisal and scoring methodology. In [86], the authors concluded that, the appraisal process critically shapes an individual's response to acute stress, while [87] detected lower EDA biomarker activity in response to episodes of acute stress in caregivers of people with Autism Spectrum Disorder, a potential habituation to stress. These findings support the need for a proper understanding of when wearable devices can and should be used, and potential factors that could affect sensor accuracy. • Measurement accuracy is a major challenge that can significantly affect wearable device data and consequently any stress measurements. One of the main problems with current wearables is significant motion artifacts, which may be reduced by measures for better and more stable placement of the device, or through placing the device on other parts of the body. • Another significant challenge is the lack of large, diverse public datasets built from wearable sensor data that can be utilized to build machine learning models for predicting elevated levels of stress that generalize well to unseen data.</p>
        <p>The main objective in automated stress detection and measurement is to develop a robust, highly accurate machine learning model that can generalizing well on new, unseen data. The review presented here synthesized the literature and presented important information about the previous studies concerned with stress prediction using wearable devices. In particular, we reviewed and analyzed the publicly available stress biomarker datasets used in numerous studies, the machine learning techniques applied, their advantages, limitations and ability to generalize on new, unseen data. We also summarized our point of view on challenges and opportunities in this emerging domain. We believe this review will advance knowledge in the general area of machine learning for stress detection using wearable devices, helping the research efforts move one step closer to realizing effective stress detection and management technology.The main objective in automated stress detection and measurement is to develop a robust, highly accurate machine learning model that can generalizing well on new, unseen data. The review presented here synthesized the literature and presented important information about the previous studies concerned with stress prediction using wearable devices. In particular, we reviewed and analyzed the publicly available stress biomarker datasets used in numerous studies, the machine learning techniques applied, their advantages, limitations and ability to generalize on new, unseen data. We also summarized our point of view on challenges and opportunities in this emerging domain. We believe this review will advance knowledge in the general area of machine learning for stress detection using wearable devices, helping the research efforts move one step closer to realizing effective stress detection and management technology.</p>
        <p>G.G.</p>
        <p>Vos, K. Trinh, Z. Sarnyai et al.Vos, K. Trinh, Z. Sarnyai et al.</p>
        <p>G.Vos, K. Trinh, Z. Sarnyai et al.G.Vos, K. Trinh, Z. Sarnyai et al.</p>
        <p>The authors, Gideon Vos, Kelly Trinh, Zoltan Sarnyai, and Mostafa Rahimi Azghadi, declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.The authors, Gideon Vos, Kelly Trinh, Zoltan Sarnyai, and Mostafa Rahimi Azghadi, declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p>
        <p>Supplementary material related to this article can be found online at https://doi .org /10 .1016 /j .ijmedinf .2023 .105026.Supplementary material related to this article can be found online at https://doi .org /10 .1016 /j .ijmedinf .2023 .105026.</p>
    </text>
</tei>
