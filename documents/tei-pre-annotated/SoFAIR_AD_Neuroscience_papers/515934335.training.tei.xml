<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T16:32+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>For completeness, we provide a brief explanation of single-kernel ridge regression. The following section is adapted from our previous study (Kong et al., 2019). Suppose we have 𝑀 training participants. Let 𝑦 𝑖 be the behavioral measure (e.g., fluid intelligence) and 𝐹𝐶 𝑖 be the vectorized FC (considering only lower triangular matrix) of the 𝑖-th training participant. Given {𝑦 1 , 𝑦 2 , ⋯ , 𝑦 𝑀 } and {𝐹𝐶 1 , 𝐹𝐶 2 , ⋯ , 𝐹𝐶 𝑀 }, the kernel regression model is written as:</p>
        <p>where 𝛽 0 is the bias term and 𝐾(𝐹𝐶 𝑗 , 𝐹𝐶 𝑖 ) is the functional connectivity similarity between the 𝑖-th and 𝑗-th training participants. 𝐾(𝐹𝐶 𝑗 , 𝐹𝐶 𝑖 ) is defined by the correlation between the vectorized FC of the two participants. The choice of correlation is motivated by previous fingerprinting and behavioral prediction studies (Finn et al. 2015, Li et al. 2019, He et al. 2020).</p>
        <p>To estimate 𝛼 and 𝛽 0 from the training set, let 𝒚 = [𝑦 1 , 𝑦 2 , ⋯ , 𝑦 𝑀 ] 𝑇 , 𝜶 = [𝛼 1 , 𝛼 2 , ⋯ , 𝛼 𝑀 ] 𝑇 and 𝕂 be the 𝑀 × 𝑀 kernel similarity matrix, whose (𝑗, 𝑖)-th element is 𝐾(𝐹𝐶 𝑗 , 𝐹𝐶 𝑖 ). Note that we can rewrite Eq. ( 1) as 𝒚 = 𝕂𝜶 + 𝛽 0 . We can then estimate 𝜶 and 𝛽 0 by minimizing the following l2-regularized cost function:</p>
        <p>where 𝜆 controls the importance of the l2-regularization and is estimated within the inner-loop crossvalidation procedure. We emphasize that the test set was not used to estimate 𝜆. Once 𝜶 and 𝛽 0 have been estimated from the training set, the predicted behavior of test participant 𝑡 is given by:</p>
        <p>Single-kernel ridge regression uses data from a single fMRI brain state for prediction. (5)</p>
        <p>where 𝜆 𝑟 controls the importance of the l 2 -regularization for the 𝑟-th kernel. Here, 𝜆 𝑟 is estimated within the inner-loop cross-validation procedure using Gaussian-process optimization (Kawaguchi et al., 2015). We emphasize that the test set was not used to estimate 𝜆 𝑟 . Once 𝜶 𝒓 and 𝛽 0 have been estimated from the training set, the predicted behavior of test participant 𝑡 is given by</p>
        <p>Suppose 𝑁 is the number of test participants, 𝑦 𝑡 and 𝑦 ̂𝑡 are the groundtruth and predicted behavior measure of the 𝑡-th test participant respectively, and 𝑦 ̅ 𝑡𝑟𝑎𝑖𝑛 is the mean of the behavioral measure of all training participants. The coefficient of determination is defined as follows:</p>
        <p>Thus, a larger COD indicates more accurate prediction. A negative value implies that we are better off using the mean behavior of the training participants to predict the behavior of the test participant instead of using the FC data.</p>
        <p>To interpret which brain edges were important for the multi-kernel FC model, we utilized an elegant approach (Haufe et al. 2014) to invert the prediction model. Failure to invert the model leads to uninterpretable results (Haufe et al. 2014). Let us consider the functional connectivity between brain regions 𝑎 and 𝑏. We would like to compute the predictive-feature value of the functional connection 𝑝 𝑎𝑏 for the multi-kernel FC model. A positive value (or negative) predictive-feature value for an edge indicates that higher FC between brain regions 𝑎 and 𝑏 is associated with predicting greater (or lower) behavioral values.</p>
        <p>The FC of each participant was normalized to achieve zero mean and unit norm across all edges of the participant. This normalization arises from our choice of the correlation metric in the kernel ridge regression model. Not performing the normalization results in highly similar predictive network feature matrices (not shown). Let 𝐹𝐶 𝑎𝑏 be the normalized functional connectivity strength between brain regions 𝑎 and 𝑏 for all training participants, i.e., 𝐹𝐶 𝑎𝑏 is an 𝑁 × 1 vector where 𝑁 is the number of training participants. Let 𝑦 ̂ be the prediction of the training participants' behavioral measure based on the estimated kernel regression model. Therefore, 𝑦 ̂ is an 𝑁 × 1 vector where 𝑁 is the number of training participants. According to Haufe and colleagues (2014), 𝑝 𝑎𝑏 = 𝑐𝑜𝑣𝑎𝑟𝑖𝑎𝑛𝑐𝑒(𝐹𝐶 𝑎𝑏 , 𝑦 ̂).</p>
        <p>However, because we would like to compare across different behavioral measures, the scale of 𝑦 ̂ is very different across behavioral measures. Thus, we computed 𝑝 𝑎𝑏 = 𝑐𝑜𝑣𝑎𝑟𝑖𝑎𝑛𝑐𝑒(𝐹𝐶 𝑎𝑏 , 𝑦 ̂)/ 𝑣𝑎𝑟𝑖𝑎𝑛𝑐𝑒(𝑦 ̂), which does not change the relative predictive-feature values among edges, but allows for comparisons between behavioral measures. We note that the above formula is applied to the training set, because we want to interpret the trained model. However, recall that we performed leave-3-site-clusters-out nested cross-validation for each behavioral measure with 120 replications. Thus we computed the predictive-feature values for each replication and averaged across the 120 replications.</p>
        <p>Supplementary Table 3 Supplementary Table 9B. Continuation of Supplementary Table 9. Distribution of racial composition of included and excluded participants after matching. There is no significant difference in terms of racial composition between included and excluded participants after multiple comparisons correction with FDR q &lt; 0.05.</p>
        <p>For each participant, twenty minutes of resting-state fMRI data were acquired in four 5-minute runs. The task fMRI data consisted of three tasks (MID, N-back, SST) that were each acquired over two runs (for a total of six task fMRI runs). Each fMRI run was acquired in 2.4 mm isotropic resolution with a TR of 800 ms. The structural data consisted of one 1 mm isotropic scan for each participant. 10. List of statistical tests performed in the current study. There were four sets of FDR correction (q &lt; 0.05) corresponding to four different sets of analyses.</p>
        <p>Figure 2 Compare all prediction models against chance-level prediction (5 models * 3 behavioral domains = 15 tests) Compare prediction of resting-FC against each task-FC (3 tasks * 3 behavioral domains = 9 tests) Compare multi-kernel FC against the best single kernel (3 behavioral domains = 3 tests) Figure 3 Compare predictions against chance-level prediction (36 tests) Supplementary Figure 2 Compare predictions against chance-level prediction (36 tests) Supplementary Figure 18 Compare multi-kernel FC against mean-FC (3 behavioral domains = 3 tests) Compare mean-FC model against the best single-kernel model (3 behavioral domains = 3 tests)</p>
        <p>Figure 5 Compare within-and between-domain network overlap against chance-level overlap (6 tests) Compare within-domain overlap and between-domain overlap (6 tests) Compare within brain state network overlap against chance-level overlap (3 tests) Figure 7a Compare model-transfer accuracies against chance-level prediction (9 tests) Compare within-domain model-transfer against between-domain model transfer (6 tests) Figure 7c Compare feature-transfer accuracies against chance-level prediction (9 tests) Compare within-domain feature-transfer against between-domain feature transfer (6 tests) Figure 8 Compare 9 Compare distributions of age, sex, race, income, and behavior between included and excluded participants (5 variables matched * 36 behaviors = 180 tests) Supplementary Figure 1. Cross-validated prediction performance (coefficient of determination; COD) using kernel ridge regression for resting-state and task-states (MID, SST, N-Back). Multikernel FC utilized FC from all 4 brain states for prediction. Higher COD indicates greater variance predicted relative to the mean of the training data. No statistical test was performed here. Source data are provided as a Source Data file. For each pair of behavioral measures, we computed the proportion of network blocks for which the predictive network features exhibited consistent directionality (positive or negative) across the two behavioral measures. Green indicates consistency greater than 50%, while brown indicates consistency less than 50%. Within each behavioral domain, the proportion of consistent predictive network features was significantly better than chance: 74% for cognition (p=6e-45), 58% for personality (p=1e-10) and 67% for mental health (p=4e-14). Each within-domain proportion was also significantly greater than the corresponding between-domain proportions (p &lt; 0.015). The sole exception was the relatively high between-domain proportion for mental health and personality, consistent with Figure 4A. Source data are provided as a Source Data file.</p>
        <p>Supplementary Figure 8. Predictive-feature matrices for each brain state (Rest, MID, SST, N-Back) averaged across all behavioral measures within each data-driven behavioral cluster (cognition, personality, mental health). For visualization, the values within each matrix were divided by their standard deviations. Supplementary Figure 14. Bar plots showing average predictive-network feature values for the hypothesis-driven domains of (A) cognition, (B) personality and (C) personality behaviors. For each network, average predictive-network feature values were obtained by averaging the absolute predictive-network feature values of all brain regions within the network in Figures 8C and8D. Color in the bar plots corresponds to network color (Figure 1B). Supplementary Figure 15. Predictive-feature matrices showing significant network blocks for each data-driven behavioral cluster (cognitive, personality, mental health) and for each brain state (Rest, MID, SST, N-Back) after permutation testing. For visualization, the values within each matrix were divided by their standard deviations. 16. Predictive brain network features for predicting cognition, personality and mental health. This figure is the same as Figure 8 but using data-driven behavioral clusters, instead of hypothesis-driven behavioral domains. (A) Predictive-feature matrices averaged across brain states, considering only within-network and between-network blocks that were significant across all four brain states (Rest, MID, SST, N-Back). (B) Predictive network connections obtained by averaging the matrices in panel (A) within each between-network and within-network block. (C) Positive predictive features obtained by summing positive predictive-feature values across the rows of panel (A). A higher value for a brain region indicates that stronger connectivity yielded a higher prediction for the behavioral measure. (D) Negative predictive features obtained by summing negative predictive-feature values across the rows of panel (A). A higher value for a brain region indicates that weaker connectivity yielded a greater prediction for the behavioral measure. Conclusions were highly similar using hypothesis-driven behavioral domains (Figure 8). Runs with more than 50% frames censored, BBR cost &gt; 0.6 or max FD &gt; 5mm were removed. Note that the rest runs were from 10,277 participants, while the task runs were from 4,506 participants (Figure 1A). Supplementary Figure 21. Brain network features that support individual-level prediction of cognition, personality and mental health. This figure is the same as Figure 8 but using data processed with respiratory pseudo-motion filtering (N = 2262). (A) Predictive-feature matrices averaged across brain states, considering only within-network and between-network blocks that were significant across all four brain states (Rest, MID, SST, N-Back). (B) Predictive network connections obtained by averaging the matrices in panel (A) within each between-network and within-network block. (C) Positive predictive features obtained by summing positive predictive-feature values across the rows of panel (A). A higher value for a brain region indicates that stronger connectivity yielded a higher prediction for the behavioral measure. (D) Negative predictive features obtained by summing negative predictive-feature values across the rows of panel (A). A higher value for a brain region indicates that weaker connectivity yielded a greater prediction for the behavioral measure. In both panels C and D, the color of each parcel corresponds to the percentile of predictive-feature values among 400 parcels. For visualization, the values within each predictive-feature matrix in panel A were divided by their standard deviations across all entries in the predictive-feature matrix. Conclusions were highly similar using data from original processing pipeline (Figure 8). Supplementary Figure 22. Brain network features that support individual-level prediction of cognition, personality and mental health. This figure is the same as Figure 8 but using data processed with respiratory pseudo-motion filtering and more liberal quality control thresholds (N = 3744). (A) Predictive-feature matrices averaged across brain states, considering only within-network and between-network blocks that were significant across all four brain states (Rest, MID, SST, N-Back). (B) Predictive network connections obtained by averaging the matrices in panel (A) within each between-network and within-network block. (C) Positive predictive features obtained by summing positive predictive-feature values across the rows of panel (A). A higher value for a brain region indicates that stronger connectivity yielded a higher prediction for the behavioral measure. (D) Negative predictive features obtained by summing negative predictive-feature values across the rows of panel (A). A higher value for a brain region indicates that weaker connectivity yielded a greater prediction for the behavioral measure. In both panels C and D, the color of each parcel corresponds to the percentile of predictive-feature values among 400 parcels. For visualization, the values within each predictive-feature matrix in panel A were divided by their standard deviations across all entries in the predictive-feature matrix. Conclusions were highly similar using data from original processing pipeline (Figure 8). Supplementary Figure 23. Brain network features that support individual-level prediction of cognition, personality and mental health. This figure is the same as Figure 8 but using participants matched for age, sex, race, family income, and behavior with the overall population (Supplementary Table 9). (A) Predictive-feature matrices averaged across brain states, considering only withinnetwork and between-network blocks that were significant across all four brain states (Rest, MID, SST, N-Back). (B) Predictive network connections obtained by averaging the matrices in panel (A) within each between-network and within-network block. (C) Positive predictive features obtained by summing positive predictive-feature values across the rows of panel (A). A higher value for a brain region indicates that stronger connectivity yielded a higher prediction for the behavioral measure. (D) Negative predictive features obtained by summing negative predictive-feature values across the rows of panel (A). A higher value for a brain region indicates that weaker connectivity yielded a greater prediction for the behavioral measure. In both panels C and D, the color of each parcel corresponds to the percentile of predictive-feature values among 400 parcels. For visualization, the values within each predictive-feature matrix in panel A were divided by their standard deviations across all entries in the predictive-feature matrix. Conclusions were highly similar using data from original analysis (Figure 8). Supplementary Figure 24. Number of participants if we used quality control (QC) criteria from Chaarani and colleagues (Chaarani et al., 2021) excluding task activation QC criteria (e.g., beta weights outlier detection). Because we excluded the task activation QC criteria in this table, the resulting sample size for each modality (e.g., N = 6503 for SST task) was larger than Chaarani's study. Yet, after conjunction across resting and task states, we were left with 4187 participants, which was only 11% more than our control analysis (N = 3744). Furthermore, we note that the QC criteria in this Figure excluded typical functional connectivity QC used in the literature.</p>
    </text>
</tei>
