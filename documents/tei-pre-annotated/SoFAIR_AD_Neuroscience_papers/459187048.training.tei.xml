<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-14T14:08+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>P300-based brain-computer interfaces (BCIs) provide an additional communication channel for individuals with communication disabilities. In general, P300-based BCIs need to be trained, offline, for a considerable period of time, which causes users to become fatigued. This reduces the efficiency and performance of the system. In order to shorten calibration time and improve system performance, we introduce the concept of a generic model set. We used ERP data from 116 participants to train the generic model set. The resulting set consists of ten models, which are trained by weighted linear discriminant analysis (WLDA). Twelve new participants were then invited to test the validity of the generic model set. The results demonstrated that all new participants matched the best generic model. The resulting mean classification accuracy equaled 80% after online training, an accuracy that was broadly equivalent to the typical training model method. Moreover, the calibration time was shortened by 70.7% of the calibration time of the typical model method.P300-based brain-computer interfaces (BCIs) provide an additional communication channel for individuals with communication disabilities. In general, P300-based BCIs need to be trained, offline, for a considerable period of time, which causes users to become fatigued. This reduces the efficiency and performance of the system. In order to shorten calibration time and improve system performance, we introduce the concept of a generic model set. We used ERP data from 116 participants to train the generic model set. The resulting set consists of ten models, which are trained by weighted linear discriminant analysis (WLDA). Twelve new participants were then invited to test the validity of the generic model set. The results demonstrated that all new participants matched the best generic model. The resulting mean classification accuracy equaled 80% after online training, an accuracy that was broadly equivalent to the typical training model method. Moreover, the calibration time was shortened by 70.7% of the calibration time of the typical model method.</p>
        <p>In other words, the best matching model method only took 81s to calibrate, while the typical model method took 276s. There were also significant differences in both accuracy and raw bit rate between the best and the worst matching model methods. We conclude that the strategy of combining the generic models with online training is easily accepted and achieves higher levels of user satisfaction (as measured by subjective reports). Thus, we provide a valuable new strategy for improving the performance of P300-based BCI.In other words, the best matching model method only took 81s to calibrate, while the typical model method took 276s. There were also significant differences in both accuracy and raw bit rate between the best and the worst matching model methods. We conclude that the strategy of combining the generic models with online training is easily accepted and achieves higher levels of user satisfaction (as measured by subjective reports). Thus, we provide a valuable new strategy for improving the performance of P300-based BCI.</p>
        <p>A S A field of technology, brain computer interfacing (BCI) provides a way to communicate between the brain and an external devices without the involvement of muscles and peripheral nerves [1]- [3]. BCI technology translates electroencephalography (EEG) signals into control commands, which particularly benefits individuals who find it difficult or impossible to communicate, for example individuals with amyotrophic lateral sclerosis (ALS) or who are in the locked-in state (LIS) [4]- [6]. In this case, three type of signals are most widely used from the EEG: the event-related potential (ERP, typically, the P300 ERP is most frequently used), the steadystate visual evoked potential (SSVEP), and the event-related desynchronization (ERD), which is associated with motor imagery (MI). In the present study the P300-based BCI system is explored.A S A field of technology, brain computer interfacing (BCI) provides a way to communicate between the brain and an external devices without the involvement of muscles and peripheral nerves [1]- [3]. BCI technology translates electroencephalography (EEG) signals into control commands, which particularly benefits individuals who find it difficult or impossible to communicate, for example individuals with amyotrophic lateral sclerosis (ALS) or who are in the locked-in state (LIS) [4]- [6]. In this case, three type of signals are most widely used from the EEG: the event-related potential (ERP, typically, the P300 ERP is most frequently used), the steadystate visual evoked potential (SSVEP), and the event-related desynchronization (ERD), which is associated with motor imagery (MI). In the present study the P300-based BCI system is explored.</p>
        <p>In recent years, the P300-based BCI system, which was firstly demonstrated by Farewell and Donchin in 1988. Reference [7] has been widely investigated. The P300 component is the largest positive detection in the EEG after the stimulus onset, with a latency around 300ms [8]. In addition, P300 BCI systems can also evoke P100, N200, and N400 ERP components [9], [10]. In general, the performance of P300 BCIs can be assessed by classification accuracy and information transfer rate (ITR) [11]. In addition, researchers have designed numerous novel visual stimulus patterns and optimized classification algorithms to improve the performance of these systems [9], [11]- [13]. These studies have made significant progress in improving the performance of the P300 BCI. However, many of these approaches have not taken userfriendliness into account, which could cause user exhaustion. In an effort to reduce visual fatigue of users, Xu et al. [14] developed a new BCI speller based on miniature asymmetric visual evoked potentials (aVEPs), which demonstrated the feasibility of using very small lateral visual stimuli to implement an efficient BCI system. In addition, many previous research methods required long time training and offline calibration data. As an example, Townsend et al. [15] reported that participants experienced two sessions including a calibration phase and an online test phase on different days within the duration of a week, which required twelve minutes of calibration data to train their classifier, while Jin et al. [9] took an online and three offline runs on the same day, with each offline run four minutes. Therefore, reducing calibration time is a significant element in minimizing user exhaustion and maximizing the utility of BCI systems.In recent years, the P300-based BCI system, which was firstly demonstrated by Farewell and Donchin in 1988. Reference [7] has been widely investigated. The P300 component is the largest positive detection in the EEG after the stimulus onset, with a latency around 300ms [8]. In addition, P300 BCI systems can also evoke P100, N200, and N400 ERP components [9], [10]. In general, the performance of P300 BCIs can be assessed by classification accuracy and information transfer rate (ITR) [11]. In addition, researchers have designed numerous novel visual stimulus patterns and optimized classification algorithms to improve the performance of these systems [9], [11]- [13]. These studies have made significant progress in improving the performance of the P300 BCI. However, many of these approaches have not taken userfriendliness into account, which could cause user exhaustion. In an effort to reduce visual fatigue of users, Xu et al. [14] developed a new BCI speller based on miniature asymmetric visual evoked potentials (aVEPs), which demonstrated the feasibility of using very small lateral visual stimuli to implement an efficient BCI system. In addition, many previous research methods required long time training and offline calibration data. As an example, Townsend et al. [15] reported that participants experienced two sessions including a calibration phase and an online test phase on different days within the duration of a week, which required twelve minutes of calibration data to train their classifier, while Jin et al. [9] took an online and three offline runs on the same day, with each offline run four minutes. Therefore, reducing calibration time is a significant element in minimizing user exhaustion and maximizing the utility of BCI systems.</p>
        <p>Vo et al. [16] proposed that the subject-independent BCI system did not require new users to perform the training stage. Lu et al. [17] pointed out that the key to reducing calibration time is that making effective use of inter-participant information and building generic models. However, recent studies [18], [19] have suggested that large individual differences exist in the P300 across participants, especially in amplitude and latency. As a consequence, it is challenging to build a generic model to reduce calibration time.Vo et al. [16] proposed that the subject-independent BCI system did not require new users to perform the training stage. Lu et al. [17] pointed out that the key to reducing calibration time is that making effective use of inter-participant information and building generic models. However, recent studies [18], [19] have suggested that large individual differences exist in the P300 across participants, especially in amplitude and latency. As a consequence, it is challenging to build a generic model to reduce calibration time.</p>
        <p>Lu et al. [17] proposed an online model adaptation technique without any calibration for a new user to achieve excellent performance. This approach made use of inter-participant information to generate a generic model. Nevertheless, it required many training iterations to accurately update the model, which was time-consuming. Jin et al. [20] combined a generic model built from data recorded from ten participants with an online training strategy, which had considerable success in improving performance in generic model building. Waytowich et al. [21] combined trained classifiers with other individual data by a spectral-meta learning method. This approach was shown to reduce the feature dimension by using a spatial filter, requiring fewer samples to train the model. Xu et al. [22] investigated how the incorporation of other subject's data could improve the subject-specific classifier accuracy for P300-spellers by using a classifier calibration strategy, Weighted Ensemble Learning Generic Information (WELGI). Furthermore, Qi et al. [23] provided a novel method which applied the Riemannian distance measurement to select similar samples from others to train the model. This not only reduced calibration times, it also resulted in a better classification performance.Lu et al. [17] proposed an online model adaptation technique without any calibration for a new user to achieve excellent performance. This approach made use of inter-participant information to generate a generic model. Nevertheless, it required many training iterations to accurately update the model, which was time-consuming. Jin et al. [20] combined a generic model built from data recorded from ten participants with an online training strategy, which had considerable success in improving performance in generic model building. Waytowich et al. [21] combined trained classifiers with other individual data by a spectral-meta learning method. This approach was shown to reduce the feature dimension by using a spatial filter, requiring fewer samples to train the model. Xu et al. [22] investigated how the incorporation of other subject's data could improve the subject-specific classifier accuracy for P300-spellers by using a classifier calibration strategy, Weighted Ensemble Learning Generic Information (WELGI). Furthermore, Qi et al. [23] provided a novel method which applied the Riemannian distance measurement to select similar samples from others to train the model. This not only reduced calibration times, it also resulted in a better classification performance.</p>
        <p>Although the above studies have addressed the problem of training generic models in BCI to a certain degree, they were either based on a relatively small sample size or did not take individual differences into account. To data, designing an efficient calibration strategy is still a significant challenge in P300-based BCI systems.Although the above studies have addressed the problem of training generic models in BCI to a certain degree, they were either based on a relatively small sample size or did not take individual differences into account. To data, designing an efficient calibration strategy is still a significant challenge in P300-based BCI systems.</p>
        <p>In the current work, we propose the concept of a generic model set, and combined a model matching method with an online training strategy to decrease calibration time. The framework of the proposed strategy is shown in Fig. 1. First, we extracted the P300 feature from EEG recorded from 116 participants during offline processing of the dataset. Second, to account for the variations of the P300 across participants, the processed features were clustered by a k-means clustering algorithm before being used to build a generic model set by WLDA. Due to the large individual differences between participants, this allowed us to record enough information to identify the matching model. Therefore, some labeled data from new participants are acquired to calibrate the model. The labeled data were then used to calibrate a generic model set via a process of online-LDA training. In the end, new participants completed an online spelling task using two models. Specifically, the best and worst matching models were both evaluated to illustrate the advantage of our approach..In the current work, we propose the concept of a generic model set, and combined a model matching method with an online training strategy to decrease calibration time. The framework of the proposed strategy is shown in Fig. 1. First, we extracted the P300 feature from EEG recorded from 116 participants during offline processing of the dataset. Second, to account for the variations of the P300 across participants, the processed features were clustered by a k-means clustering algorithm before being used to build a generic model set by WLDA. Due to the large individual differences between participants, this allowed us to record enough information to identify the matching model. Therefore, some labeled data from new participants are acquired to calibrate the model. The labeled data were then used to calibrate a generic model set via a process of online-LDA training. In the end, new participants completed an online spelling task using two models. Specifically, the best and worst matching models were both evaluated to illustrate the advantage of our approach..</p>
        <p>The P300 dataset used in the current study is obtained from the 2018 World Robot Conference (WRC) BCI Contest. The dataset consists of 116 participants (72 males, 44 females) who were all undergraduate or postgraduate university students ranged in age from 17 to 23 years old at the time of data collection. This data was recorded with a 64-channel wireless EEG acquisition system at a sample rate of 1000Hz. The paradigm used to evoke P300 ERPs while recording the dataset consisted of a 6 × 6 matrix, sometimes referred to as a conventional oddball paradigm, which contained 26 characters and 10 numbers. The interface is shown in Fig. 2. A row or column was selected at random and intensified in brightness for 80ms every 160ms. Each participant was asked to undertake two runs of the experiment, including an offline run and an online run. The offline run included 36 epochs/characters (A-Z, 1-9, 0) with 4 trials per epoch. In our case, we only consider the EEG signals recorded during the offline training part of the experiment. The experimental flow diagram used to record the dataset is shown in Fig. 3.The P300 dataset used in the current study is obtained from the 2018 World Robot Conference (WRC) BCI Contest. The dataset consists of 116 participants (72 males, 44 females) who were all undergraduate or postgraduate university students ranged in age from 17 to 23 years old at the time of data collection. This data was recorded with a 64-channel wireless EEG acquisition system at a sample rate of 1000Hz. The paradigm used to evoke P300 ERPs while recording the dataset consisted of a 6 × 6 matrix, sometimes referred to as a conventional oddball paradigm, which contained 26 characters and 10 numbers. The interface is shown in Fig. 2. A row or column was selected at random and intensified in brightness for 80ms every 160ms. Each participant was asked to undertake two runs of the experiment, including an offline run and an online run. The offline run included 36 epochs/characters (A-Z, 1-9, 0) with 4 trials per epoch. In our case, we only consider the EEG signals recorded during the offline training part of the experiment. The experimental flow diagram used to record the dataset is shown in Fig. 3.</p>
        <p>Feature extraction is a key process to reduce dimensionality in the dataset to avoid overfitting and reduce computation time. In the P300-based BCI system, a band pass filter between 0.2Hz to 40Hz was applied to reduce high frequency noise. The filtering algorithm we applied was a 5th order Butterworth filter [24]. In order to eliminate the impact of electrical noise, a 5th order IIR comb notch filter at 50Hz was then applied. To decrease the dimensionality of the data and the complexity of model, the filtered EEG data was then down-sampled from 1000Hz to 50Hz (i.e. by a factor 20). Since the first 600ms of EEG after target stimulus presentation was extracted from each channel [25], the size of the feature vector is 10 × 30 where 10 is the number of channels we used in the whole experimental process, and 30 is the number of samples per channel.Feature extraction is a key process to reduce dimensionality in the dataset to avoid overfitting and reduce computation time. In the P300-based BCI system, a band pass filter between 0.2Hz to 40Hz was applied to reduce high frequency noise. The filtering algorithm we applied was a 5th order Butterworth filter [24]. In order to eliminate the impact of electrical noise, a 5th order IIR comb notch filter at 50Hz was then applied. To decrease the dimensionality of the data and the complexity of model, the filtered EEG data was then down-sampled from 1000Hz to 50Hz (i.e. by a factor 20). Since the first 600ms of EEG after target stimulus presentation was extracted from each channel [25], the size of the feature vector is 10 × 30 where 10 is the number of channels we used in the whole experimental process, and 30 is the number of samples per channel.</p>
        <p>We built a generic model set derived from 116 participants' data and explored the differences across participants. Then, to evaluate the efficacy of this generic model set in training a BCI, 12 new participants were invited to test the performance of the model. In the following section, we describe the experimental process and present the generic model set building method and matching technique.We built a generic model set derived from 116 participants' data and explored the differences across participants. Then, to evaluate the efficacy of this generic model set in training a BCI, 12 new participants were invited to test the performance of the model. In the following section, we describe the experimental process and present the generic model set building method and matching technique.</p>
        <p>Twelve healthy participants (S1-S12), eight of whom were male and four female, aged 22-25 years, with a mean age of 24, and with normal or corrected to normal vision participated in this experiment. Before the experiment began, all participants were asked to sign a consent form, which the local ethics committee approved. After completion of the study, they were given 100 RMB as a reward. All participants' native language was Mandarin Chinese, and all participants were familiar with the Western characters used in the display. Seven of the twelve participants had participated in a BCI experiment previously.Twelve healthy participants (S1-S12), eight of whom were male and four female, aged 22-25 years, with a mean age of 24, and with normal or corrected to normal vision participated in this experiment. Before the experiment began, all participants were asked to sign a consent form, which the local ethics committee approved. After completion of the study, they were given 100 RMB as a reward. All participants' native language was Mandarin Chinese, and all participants were familiar with the Western characters used in the display. Seven of the twelve participants had participated in a BCI experiment previously.</p>
        <p>In the experiment, we instructed participants to sit approximately 105 cm in front of an LCD computer monitor, 23.6-in. Dell VG2401 series. And the computer processor (CPU) is an Intel Xeno(R) E5-2603 v3, processor running at 1.6GHz with 16GB of RAM. Participants were instructed to relax themselves and to avoid unnecessary movement when we were recoding their EEG.In the experiment, we instructed participants to sit approximately 105 cm in front of an LCD computer monitor, 23.6-in. Dell VG2401 series. And the computer processor (CPU) is an Intel Xeno(R) E5-2603 v3, processor running at 1.6GHz with 16GB of RAM. Participants were instructed to relax themselves and to avoid unnecessary movement when we were recoding their EEG.</p>
        <p>The EEG acquisition system included an EEG cap, wireless EEG amplifier, and wireless router. The 64-channel wireless amplifier connected to the electrode cap was used to record EEG at a sample rate of 1000Hz. The amplifier was connected to the amplifier control router via the WIFI. In this paper, EEG signals were recorded via ten electrodes placed at positions Fz, Cz, Pz, P3, P4, P7, P8, O1, Oz, and O2 based on the international 10-20 system. These electrodes were chosen as they lie over areas of the brain which are associated with vision [26]. The ground electrode was placed at AFz, while the reference electrodes were placed at locations CPz, T7 and T8 [27], [28]. That is, data from each channel was referenced online to channel CPz and re-referenced offline to the mean of channel T7 and T8. The impedance was kept below 10k in the experiments [29]. Fig. 4 illustrates the configuration of the selected electrode positions.The EEG acquisition system included an EEG cap, wireless EEG amplifier, and wireless router. The 64-channel wireless amplifier connected to the electrode cap was used to record EEG at a sample rate of 1000Hz. The amplifier was connected to the amplifier control router via the WIFI. In this paper, EEG signals were recorded via ten electrodes placed at positions Fz, Cz, Pz, P3, P4, P7, P8, O1, Oz, and O2 based on the international 10-20 system. These electrodes were chosen as they lie over areas of the brain which are associated with vision [26]. The ground electrode was placed at AFz, while the reference electrodes were placed at locations CPz, T7 and T8 [27], [28]. That is, data from each channel was referenced online to channel CPz and re-referenced offline to the mean of channel T7 and T8. The impedance was kept below 10k in the experiments [29]. Fig. 4 illustrates the configuration of the selected electrode positions.</p>
        <p>In this study, three cases were considered.In this study, three cases were considered.</p>
        <p>Case 1 (Typical Model): Participants were asked to complete two runs, an offline run and an online run. The offline run covers 36 target spelling tasks with 4 trials per target. The model was trained using a linear discriminant analysis (LDA) approach and used to spell 20 characters online. Offline calibration time was 276 s.Case 1 (Typical Model): Participants were asked to complete two runs, an offline run and an online run. The offline run covers 36 target spelling tasks with 4 trials per target. The model was trained using a linear discriminant analysis (LDA) approach and used to spell 20 characters online. Offline calibration time was 276 s.</p>
        <p>Case 2 (The Best Matching Model): In this case, in order to record enough information to identify the matching model, participants first need to spell 7 characters (i.e, 1, J, X, H, D, G, and 7; see Fig. 2.) to calibrate or train the generic model online. Each character has 6 trials and it takes 81s to train the model. Participants were then instructed to complete an online spelling run of 20 characters using the best matching generic model.Case 2 (The Best Matching Model): In this case, in order to record enough information to identify the matching model, participants first need to spell 7 characters (i.e, 1, J, X, H, D, G, and 7; see Fig. 2.) to calibrate or train the generic model online. Each character has 6 trials and it takes 81s to train the model. Participants were then instructed to complete an online spelling run of 20 characters using the best matching generic model.</p>
        <p>In order to compare the differences between generic models and illustrate the validity of the matching rule, we also applied the worst calibrated generic model in an online spelling system.In order to compare the differences between generic models and illustrate the validity of the matching rule, we also applied the worst calibrated generic model in an online spelling system.</p>
        <p>In order to ensure consistency, we used 20 characters for spelling in the online experiment, and the online spelling order of the 20 characters remained the same in all three cases, i.e. regardless of in which case a given participant was asked to attempt the letters they were asked to spell remained the same. After each run, the participants were given a rest for 4-5 minutes.In order to ensure consistency, we used 20 characters for spelling in the online experiment, and the online spelling order of the 20 characters remained the same in all three cases, i.e. regardless of in which case a given participant was asked to attempt the letters they were asked to spell remained the same. After each run, the participants were given a rest for 4-5 minutes.</p>
        <p>1) Feature Clustering: Since there are obvious temporal domain characteristics in the P300 potential, we took the filtered EEG data from 116 participants as features. Due to the high dimensionality of the EEG [30], we decided to use the PCA dimensionality reduction algorithm to decrease the feature set, to save computation, and to reduce preprocessing time. After reducing feature dimension, a clustering algorithm was used for feature processing of the EEG to account for individual differences. Notably, a k-means clustering algorithm was used due to its good convergence rate [31].1) Feature Clustering: Since there are obvious temporal domain characteristics in the P300 potential, we took the filtered EEG data from 116 participants as features. Due to the high dimensionality of the EEG [30], we decided to use the PCA dimensionality reduction algorithm to decrease the feature set, to save computation, and to reduce preprocessing time. After reducing feature dimension, a clustering algorithm was used for feature processing of the EEG to account for individual differences. Notably, a k-means clustering algorithm was used due to its good convergence rate [31].</p>
        <p>a) PCA: The principal component analysis (PCA) [32] is an unsupervised dimensionality reduction method, which is widely applied in many field. In this work, we use PCA to reduce the dimensionality of the EEG feature set.a) PCA: The principal component analysis (PCA) [32] is an unsupervised dimensionality reduction method, which is widely applied in many field. In this work, we use PCA to reduce the dimensionality of the EEG feature set.</p>
        <p>The original data is comprised of the sample vectors of all participants and is represented by X = {x 1 , . . . , x N } where x i is the row vector of the i th participant and N is the number of participants, that is, 116. There were 518400 (36 * 4 * 12 * 10 * 30) eigenvalues for each participant, where 36 is the number of characters, 4 is the number of trials, 12 is the number of flashes, 10 is the number of channels, and 30 is the number of samples. The covariance matrix is given as,The original data is comprised of the sample vectors of all participants and is represented by X = {x 1 , . . . , x N } where x i is the row vector of the i th participant and N is the number of participants, that is, 116. There were 518400 (36 * 4 * 12 * 10 * 30) eigenvalues for each participant, where 36 is the number of characters, 4 is the number of trials, 12 is the number of flashes, 10 is the number of channels, and 30 is the number of samples. The covariance matrix is given as,</p>
        <p>Let A = x i -x, then s = A A T , and implement singular value decomposition to get the eigenvalue λ i (i = 1, . . . , N) and the correspond eigenvector v i (i = 1, . . . , N) of the matrix s. Suppose that λ i (i = 1, . . . , r ) are the eigenvalues, which are not zero. The normalized orthogonal eigenvector u i is:Let A = x i -x, then s = A A T , and implement singular value decomposition to get the eigenvalue λ i (i = 1, . . . , N) and the correspond eigenvector v i (i = 1, . . . , N) of the matrix s. Suppose that λ i (i = 1, . . . , r ) are the eigenvalues, which are not zero. The normalized orthogonal eigenvector u i is:</p>
        <p>We re-order i (i = 1, . . . , r ) in descending order of the magnitude of the eigenvalues, and adjust the order of u i accordingly. In this work, the orthonormal eigenvector is U = {u 1 , . . . , u d }. We used the PCA function with 'econ' parameter in 
            <rs type="software">Matlab</rs> in which, if the number of samples N is smaller than the number of eigenvalues, the N -1 principle component is acquired. This can be significantly faster when the number of eigenvalues is larger than N [32], [33]. Consequently, we selected the u i corresponding to the 115 largest eigenvalues for each participant, that is d = 115, and the contribution rate is greater than 95%. It is enough to represent the whole data with fewer features. The transformed data is defined by Z = X T U ∈ R N×d , Where each column of Z (i.e. z j ∈ R N , j ∈ {1, . . . , d}) is a principal component. It can be found that each principal component is a linear combination of all the original features [34].
        </p>
        <p>b) K-means Clustering Algorithm: The k-means algorithm, is one of the most popular and the simplest clustering algorithms [31]. It works by minimizing the cluster variance. Let Z = {z 1 , . . . , z 115 } be the set of 116 d-dimensional points, and take K as the input to cluster 116 samples into K clusters, C = {c k , k = 1, . . . , K }. Let μ k = x i ∈C k x i /n k be the centroid of cluster C k , where n k denotes the number of points in C k . Cluster similarity is measured according to the dissimilarity between a data point and the centroid of the cluster. The squared error between μ k and the points in cluster C k is defined asb) K-means Clustering Algorithm: The k-means algorithm, is one of the most popular and the simplest clustering algorithms [31]. It works by minimizing the cluster variance. Let Z = {z 1 , . . . , z 115 } be the set of 116 d-dimensional points, and take K as the input to cluster 116 samples into K clusters, C = {c k , k = 1, . . . , K }. Let μ k = x i ∈C k x i /n k be the centroid of cluster C k , where n k denotes the number of points in C k . Cluster similarity is measured according to the dissimilarity between a data point and the centroid of the cluster. The squared error between μ k and the points in cluster C k is defined as</p>
        <p>K-means is determined by minimizing the sum of squared errors over all K clusters,K-means is determined by minimizing the sum of squared errors over all K clusters,</p>
        <p>Different initializations can lead to different final clustering because k-means only converges to a local minima [35]. One way to overcome the local minima is to run the k-means algorithm, for a given K , with multiple different initial partitions and choose the partition with the smallest squared error. In this paper, we applied k-means with K = 10 [36], [37] to cluster sample data with the minimization of the sum of squared errors among multiple clusters.Different initializations can lead to different final clustering because k-means only converges to a local minima [35]. One way to overcome the local minima is to run the k-means algorithm, for a given K , with multiple different initial partitions and choose the partition with the smallest squared error. In this paper, we applied k-means with K = 10 [36], [37] to cluster sample data with the minimization of the sum of squared errors among multiple clusters.</p>
        <p>2) Model Online Update and Classification: In this section, we developed a weighted linear discriminant analysis method (WLDA) to obtain offline classification models of every cluster which belongs to the generic model set. In addition, we also applied Online Linear Discriminant Classifiers (OLDA) to enable updates to accommodate changing environments during online training [13].2) Model Online Update and Classification: In this section, we developed a weighted linear discriminant analysis method (WLDA) to obtain offline classification models of every cluster which belongs to the generic model set. In addition, we also applied Online Linear Discriminant Classifiers (OLDA) to enable updates to accommodate changing environments during online training [13].</p>
        <p>a) Weighted Linear Discriminant Analysis (WLDA): The WLDA is an extension of LDA, that is, a weighted LDA. The objective of WLDA (the same as Fisher's LDA) is to use hyper-planes to separate the data representing the different classes. Compared with other complex classifiers, LDA has very low computational requirements and processing time, which makes it suitable for online spelling [38], [39]. Moreover, this classifier is simple to use and generally obtains better classification performance and acceptable accuracy [22], [40]. Some improved algorithms have been developed based on LDA, for instance the stepwise LDA (SWLDA) [41], Bayesian LDA (BLDA) [42], and spatial temporal discriminant analysis (STDA) [43]. LDA can achieve better performance in some situations, for example, Syan and Harnarinesingh [44] indicated that the LDA classifier achieved the best performance in classifying unseen P300 spatiotemporal features in both the single-trial (74.19%) and multi-trial case (100%). Raudys and Jain [45] proposed that, if there is a small training set, simple techniques with few parameters should be used, such as LDA, which is why we use LDA in our work.a) Weighted Linear Discriminant Analysis (WLDA): The WLDA is an extension of LDA, that is, a weighted LDA. The objective of WLDA (the same as Fisher's LDA) is to use hyper-planes to separate the data representing the different classes. Compared with other complex classifiers, LDA has very low computational requirements and processing time, which makes it suitable for online spelling [38], [39]. Moreover, this classifier is simple to use and generally obtains better classification performance and acceptable accuracy [22], [40]. Some improved algorithms have been developed based on LDA, for instance the stepwise LDA (SWLDA) [41], Bayesian LDA (BLDA) [42], and spatial temporal discriminant analysis (STDA) [43]. LDA can achieve better performance in some situations, for example, Syan and Harnarinesingh [44] indicated that the LDA classifier achieved the best performance in classifying unseen P300 spatiotemporal features in both the single-trial (74.19%) and multi-trial case (100%). Raudys and Jain [45] proposed that, if there is a small training set, simple techniques with few parameters should be used, such as LDA, which is why we use LDA in our work.</p>
        <p>In the current work, WLDA we proposed is used to classify the P300 feature of multiple participants. We assigned a weight for each feature of each participant according to the contributions of each participant to the result. In this system, we only take the two-class circumstance to train offline data. Let x i ∈ R D be the input vectors of the classifier, and y i ∈{-1, 1} be the label vector, which represents class 1 G 1 and class 2 G 2 respectively. Finally, the LDA weight vector we require can be defined by,In the current work, WLDA we proposed is used to classify the P300 feature of multiple participants. We assigned a weight for each feature of each participant according to the contributions of each participant to the result. In this system, we only take the two-class circumstance to train offline data. Let x i ∈ R D be the input vectors of the classifier, and y i ∈{-1, 1} be the label vector, which represents class 1 G 1 and class 2 G 2 respectively. Finally, the LDA weight vector we require can be defined by,</p>
        <p>where N k denotes the number of classes k, and S -1 w is the inversion of the within-scatter matrix.where N k denotes the number of classes k, and S -1 w is the inversion of the within-scatter matrix.</p>
        <p>During the model construction for each cluster the input vectors is taken from multiple participants who are grouped into the same cluster. Given this, we decided to assign different weights according to the contribution rate of the participants to the results of the offline classification. In this section of the work, we considered only the between-class scatter matrix.During the model construction for each cluster the input vectors is taken from multiple participants who are grouped into the same cluster. Given this, we decided to assign different weights according to the contribution rate of the participants to the results of the offline classification. In this section of the work, we considered only the between-class scatter matrix.</p>
        <p>First, we used feature of ten clusters to compute corresponding discriminant vector w k (k = 1, . . . , 10). Clustered participants are defined by c k = {x i , i = 1, . . . , n k }, where n k is the number k th cluster.First, we used feature of ten clusters to compute corresponding discriminant vector w k (k = 1, . . . , 10). Clustered participants are defined by c k = {x i , i = 1, . . . , n k }, where n k is the number k th cluster.</p>
        <p>Second, we used the trained vector w k to classify x i , (i = 1, . . . , n k ) and the offline accuracy acc i was used to get a feature weight e i for every participant, as shown in equation (9).Second, we used the trained vector w k to classify x i , (i = 1, . . . , n k ) and the offline accuracy acc i was used to get a feature weight e i for every participant, as shown in equation (9).</p>
        <p>Finally, we used a weighted feature vector c k = {x i e i , i = 1, . . . , n k } to re-train the discriminant vector w k (k = 1, . . . , 10). The WLDA weighted vector can be described by equation (10).Finally, we used a weighted feature vector c k = {x i e i , i = 1, . . . , n k } to re-train the discriminant vector w k (k = 1, . . . , 10). The WLDA weighted vector can be described by equation (10).</p>
        <p>wherewhere</p>
        <p>b) Online Linear Discriminant Analysis: Online Linear Discriminant Analysis (OLDA) was proposed by Kuncheva and Plumpton [13]. The online training strategy is based on the inverse of the common covariance matrix, updated with the Sherman-Morrison-Woodbury formula. Moreover, it is simple and can reduce the amount of calculation, which makes it suitable for online BCI systems.b) Online Linear Discriminant Analysis: Online Linear Discriminant Analysis (OLDA) was proposed by Kuncheva and Plumpton [13]. The online training strategy is based on the inverse of the common covariance matrix, updated with the Sherman-Morrison-Woodbury formula. Moreover, it is simple and can reduce the amount of calculation, which makes it suitable for online BCI systems.</p>
        <p>In this work, we applied two methods of measuring bit rate, practical bit rate (PBR) and raw bit rate (RBR), to describe the speed and the number of online spellings made by the ERP-BCI system [10]. The practical bit rate was used to estimate the speed of the system in a real-world setting. Though both methods were shown in TABLE I, in general, we only analyzed the RBR in this work. The practical bit rate is defined asIn this work, we applied two methods of measuring bit rate, practical bit rate (PBR) and raw bit rate (RBR), to describe the speed and the number of online spellings made by the ERP-BCI system [10]. The practical bit rate was used to estimate the speed of the system in a real-world setting. Though both methods were shown in TABLE I, in general, we only analyzed the RBR in this work. The practical bit rate is defined as</p>
        <p>where RBR is the raw bit rate and P is the error rate of online spelling in the system. Both PBR and RBR include the time to make a selection. The raw bit rate, which also includes selection time, represents the online transfer rate of the P300-based online spelling system.where RBR is the raw bit rate and P is the error rate of online spelling in the system. Both PBR and RBR include the time to make a selection. The raw bit rate, which also includes selection time, represents the online transfer rate of the P300-based online spelling system.</p>
        <p>In order to improve the performance of the system, an adaptive strategy was added into the online spelling system [42]. Specifically, the number of trials required to select eachIn order to improve the performance of the system, an adaptive strategy was added into the online spelling system [42]. Specifically, the number of trials required to select each</p>
        <p>Step 2: Reduce the dimensionality of the filtered data X = {x 1 ,…,x 116 } by PCA. Then, cluster the data of the 116 training participants into 10 clusters by the k-means algorithm.Step 2: Reduce the dimensionality of the filtered data X = {x 1 ,…,x 116 } by PCA. Then, cluster the data of the 116 training participants into 10 clusters by the k-means algorithm.</p>
        <p>Step 3: Construct ten WLDA classifiers from the feature vector from the ten clusters of participants.Step 3: Construct ten WLDA classifiers from the feature vector from the ten clusters of participants.</p>
        <p>Input Ten classifiers and EEG signal of twelve novel test participants are observed. Output The feedback of online spelling for 20 characters from the best and worst matching model.Input Ten classifiers and EEG signal of twelve novel test participants are observed. Output The feedback of online spelling for 20 characters from the best and worst matching model.</p>
        <p>Step 1: Ask the test participants to attempt to spell 7 characters online and, at the same time, use the OLDA to calibrate the model, then match the model which corresponds to maximal and minimal accuracy.Step 1: Ask the test participants to attempt to spell 7 characters online and, at the same time, use the OLDA to calibrate the model, then match the model which corresponds to maximal and minimal accuracy.</p>
        <p>Step 2: Use the best and the worst matching model after online training to complete online adaptive spelling for 20 characters respectively. character is related with the classifier output, and the classifier output can be got after each trial when using the online system. In particular, when the classifier recognized the same character after two subsequent trials, there are no new flashes and the recognized character is be presented on the screen as feedback. If the number of trials for a given character reaches 10 with no consensus reached, the classifier will automatically choose the target recognized on the final trial. Note that the score of each trial is the sum of the previous one. For example, suppose that '1' is the target character, which the classifier recognized in the first trial. If the character '1' was recognized again in the second trial, the final output will be '1'. We can describe with the formal as cha (n) = cha(n -1)(1 &lt; n ≤ 10).Step 2: Use the best and the worst matching model after online training to complete online adaptive spelling for 20 characters respectively. character is related with the classifier output, and the classifier output can be got after each trial when using the online system. In particular, when the classifier recognized the same character after two subsequent trials, there are no new flashes and the recognized character is be presented on the screen as feedback. If the number of trials for a given character reaches 10 with no consensus reached, the classifier will automatically choose the target recognized on the final trial. Note that the score of each trial is the sum of the previous one. For example, suppose that '1' is the target character, which the classifier recognized in the first trial. If the character '1' was recognized again in the second trial, the final output will be '1'. We can describe with the formal as cha (n) = cha(n -1)(1 &lt; n ≤ 10).</p>
        <p>At the end of each test, each participant was asked two questions. Each question was given a rating in the range 1-5, with a score of 1 indicating the lowest agreement and a score of 5 indicating the highest level of agreement. The two questions were:At the end of each test, each participant was asked two questions. Each question was given a rating in the range 1-5, with a score of 1 indicating the lowest agreement and a score of 5 indicating the highest level of agreement. The two questions were:</p>
        <p>Q1: Did you feel tired in the three cases? Please give a score respectively.Q1: Did you feel tired in the three cases? Please give a score respectively.</p>
        <p>Q2: Did you feel annoyed in the three cases? Please give a score respectively.Q2: Did you feel annoyed in the three cases? Please give a score respectively.</p>
        <p>The questions were asked in Mandarin Chinese.The questions were asked in Mandarin Chinese.</p>
        <p>In this system, the generic model set was updated by the labeled data of 7 characters from each participant, and then the updated generic model was used to classify EEG related to 7 characters respectively. In this case, the matching strategy used was that the classification result of each model was regarded as the matching result. In order to explore the individual differences in time domain across participants, especially in amplitude and latency, Fig. 5 illustrates the P300 waveform variations at channel Cz for twelve healthy participants calculated through averaging 288 EEG flashes of the targets (36 characters * 4 trials * 2 flashes). Fig. 6 shows matching accuracy of the generic model set for the test set of 12 new participants. The green bar corresponds to the best matching model and the red bar corresponds to the worst matching model. Due to individual variations, we can find that some participants matched the different best matching model, while some participants shared the same best matching model.In this system, the generic model set was updated by the labeled data of 7 characters from each participant, and then the updated generic model was used to classify EEG related to 7 characters respectively. In this case, the matching strategy used was that the classification result of each model was regarded as the matching result. In order to explore the individual differences in time domain across participants, especially in amplitude and latency, Fig. 5 illustrates the P300 waveform variations at channel Cz for twelve healthy participants calculated through averaging 288 EEG flashes of the targets (36 characters * 4 trials * 2 flashes). Fig. 6 shows matching accuracy of the generic model set for the test set of 12 new participants. The green bar corresponds to the best matching model and the red bar corresponds to the worst matching model. Due to individual variations, we can find that some participants matched the different best matching model, while some participants shared the same best matching model.</p>
        <p>Fig. 6. The matching result of the model set for participants. numerals (I -X) on the horizontal axis indicate which matching model is used. The green bar corresponds to the best matching model and red bar corresponds to the worst matching model. (Note: the accuracy was 66.66% (2/3) when all labels were wrong, so we set the minimum value of the vertical axis to 60%).Fig. 6. The matching result of the model set for participants. numerals (I -X) on the horizontal axis indicate which matching model is used. The green bar corresponds to the best matching model and red bar corresponds to the worst matching model. (Note: the accuracy was 66.66% (2/3) when all labels were wrong, so we set the minimum value of the vertical axis to 60%).</p>
        <p>TABLE I describes the online classification accuracy, raw bit rate, practical bit rate, calibration time, online spelling time and the average number of trials in three cases (typical model, the and the matching model). In terms of accuracy, we can see that, when using the best matching model, the accuracy of twelve participants can reach a mean accuracy of 80%. As for the online spelling time of a run, we use 'S-time' of three cases in TABLE I to describe, where a 3.2s interval between characters was included. Although participant S2 showed superior performance in all three cases, this participant reported that the generic model was "a good fit" and that the spelling task was easy to complete.TABLE I describes the online classification accuracy, raw bit rate, practical bit rate, calibration time, online spelling time and the average number of trials in three cases (typical model, the and the matching model). In terms of accuracy, we can see that, when using the best matching model, the accuracy of twelve participants can reach a mean accuracy of 80%. As for the online spelling time of a run, we use 'S-time' of three cases in TABLE I to describe, where a 3.2s interval between characters was included. Although participant S2 showed superior performance in all three cases, this participant reported that the generic model was "a good fit" and that the spelling task was easy to complete.</p>
        <p>Participants S10 and S11, can achieve outstanding results in case 1, while using our proposed best matching model they obtained a mean accuracy of 60%. At the same time, their matching results were lower than other participants. This may be a result of relatively low matching result. In other words, their ERP data does not match well with the data from the training dataset. In addition, participant S12 displayed poor performance using the typical model, while the online classification result reached an accuracy of 90% using the best matching generic model. In summary, most participants using the best matching method can obtain the same performance level as the typical model method. From the perspective of the calibration time in the three cases we proposed, it is obvious that using the best matching model method we proposed has results in a reduction in calibration time of 70.7% compared to the typical model method.Participants S10 and S11, can achieve outstanding results in case 1, while using our proposed best matching model they obtained a mean accuracy of 60%. At the same time, their matching results were lower than other participants. This may be a result of relatively low matching result. In other words, their ERP data does not match well with the data from the training dataset. In addition, participant S12 displayed poor performance using the typical model, while the online classification result reached an accuracy of 90% using the best matching generic model. In summary, most participants using the best matching method can obtain the same performance level as the typical model method. From the perspective of the calibration time in the three cases we proposed, it is obvious that using the best matching model method we proposed has results in a reduction in calibration time of 70.7% compared to the typical model method.</p>
        <p>In order to make sure that the classification accuracy and raw bit rate can be analyzed, data was statistically tested via a One-Sample Ryan-Joiner test for normal distributions. A repeated-measures ANOVA (RM-ANOVA) was chosen to evaluate the effect of stimuli paradigm on the results. Mauchly's test of sphericity was executed before the analysis. If the assumption was broken, Greenhouse-Geisser correction was performed to adjust the degrees of freedom. In the end, we applied Bonferroni correction in a post hoc test. The alpha level reached 0.05 after Bonferroni correction [10].In order to make sure that the classification accuracy and raw bit rate can be analyzed, data was statistically tested via a One-Sample Ryan-Joiner test for normal distributions. A repeated-measures ANOVA (RM-ANOVA) was chosen to evaluate the effect of stimuli paradigm on the results. Mauchly's test of sphericity was executed before the analysis. If the assumption was broken, Greenhouse-Geisser correction was performed to adjust the degrees of freedom. In the end, we applied Bonferroni correction in a post hoc test. The alpha level reached 0.05 after Bonferroni correction [10].</p>
        <p>We explore the P300 variability by using three models. Typical models of the twelve test participants were built from their offline run. In addition, the best and the worst matching models built from the dataset were matched and trained online respectively. A one-way repeated measures ANOVA was applied to show the classification accuracy I, there are no statistically significant differences in classification accuracy ( p &gt; 0.05) and raw bit rate ( p &gt; 0.05) between the typical model method and the best matching model method, which demonstrates that using the best matching model could obtain the same online accuracy and raw bit rate as the typical model. TABLE II gives a description of the p values of the significance of the difference under pairwise comparison in the three cases. Bonferroni correction for multiple comparisons was applied.We explore the P300 variability by using three models. Typical models of the twelve test participants were built from their offline run. In addition, the best and the worst matching models built from the dataset were matched and trained online respectively. A one-way repeated measures ANOVA was applied to show the classification accuracy I, there are no statistically significant differences in classification accuracy ( p &gt; 0.05) and raw bit rate ( p &gt; 0.05) between the typical model method and the best matching model method, which demonstrates that using the best matching model could obtain the same online accuracy and raw bit rate as the typical model. TABLE II gives a description of the p values of the significance of the difference under pairwise comparison in the three cases. Bonferroni correction for multiple comparisons was applied.</p>
        <p>Furthermore, the typical model takes approximately seven minutes to train, while the matching model took less than one and a half minutes, which spent less than 70.7% of the calibration time it previously took. In other words, it significantly calibration time ( p &lt; 0.05). Fig. 7 shows the online accuracy using three kinds of models. The blue bar indicates results obtained with the typical model, the green indicates the best matching model, and red bar indicates the worst matching model. Fig. 8 shows the practical bit rates achieved using three kinds of models. The blue line indicates the typical model, the green the best matching model, and the red the worst matching model.Furthermore, the typical model takes approximately seven minutes to train, while the matching model took less than one and a half minutes, which spent less than 70.7% of the calibration time it previously took. In other words, it significantly calibration time ( p &lt; 0.05). Fig. 7 shows the online accuracy using three kinds of models. The blue bar indicates results obtained with the typical model, the green indicates the best matching model, and red bar indicates the worst matching model. Fig. 8 shows the practical bit rates achieved using three kinds of models. The blue line indicates the typical model, the green the best matching model, and the red the worst matching model.</p>
        <p>As Fig. 7 and Fig. 8 show, it is easily noted that the accuracy ( p &lt; 0.05) and raw bit rate ( p &lt; 0.05) of the best matching model method is significantly higher than the worst matching TABLE III displays the feedback answers of the 12 participants who attempted the three cases. For the sake of distinguishing the differences, a Friedman nonparametric test was applied to explore the differences in feedback. According to users' feedback, we find that there are significant trends (χ 2 = 7.091, p &lt; 0.05) toward tiredness of all participants in the experiment. In addition, in terms of the annoyance, there was no significant trend (χ 2 = 4.389, p &gt; 0.05) in the experiment. According to the study of Möckel, long time in a cognitive task causes mental fatigue [46]. This means that our proposed method which shortened the calibration time may decrease mental fatigue of participants and improve practicability of the system [43].As Fig. 7 and Fig. 8 show, it is easily noted that the accuracy ( p &lt; 0.05) and raw bit rate ( p &lt; 0.05) of the best matching model method is significantly higher than the worst matching TABLE III displays the feedback answers of the 12 participants who attempted the three cases. For the sake of distinguishing the differences, a Friedman nonparametric test was applied to explore the differences in feedback. According to users' feedback, we find that there are significant trends (χ 2 = 7.091, p &lt; 0.05) toward tiredness of all participants in the experiment. In addition, in terms of the annoyance, there was no significant trend (χ 2 = 4.389, p &gt; 0.05) in the experiment. According to the study of Möckel, long time in a cognitive task causes mental fatigue [46]. This means that our proposed method which shortened the calibration time may decrease mental fatigue of participants and improve practicability of the system [43].</p>
        <p>V. DISCUSSION P300-based BCI systems have been widely investigated in over recent years and are beginning to be used in clinical applications [4], [5]. However, despite significant progress in the operation of the P300 BCI, many BCIs still spend considerable time on offline training/calibration. As a consequence, developing an efficient calibration strategy is an important challenge to solve in P300-based BCI development.V. DISCUSSION P300-based BCI systems have been widely investigated in over recent years and are beginning to be used in clinical applications [4], [5]. However, despite significant progress in the operation of the P300 BCI, many BCIs still spend considerable time on offline training/calibration. As a consequence, developing an efficient calibration strategy is an important challenge to solve in P300-based BCI development.</p>
        <p>In general, a calibration strategy should take the classification accuracy and calibration time into consideration simultaneously. Previous studies have shown that using interparticipant information to build a model can waste time. A better approach is to strategically update the model [10], [21], [47]. These studies attempted to train an initial classifier in advance and update it using an appropriate updating strategy. Given the aim of reducing the system calibration time, we adopted the concept of a generic model set and matched the samples of new participants with those of participants in the training set with the same ERP characteristics.In general, a calibration strategy should take the classification accuracy and calibration time into consideration simultaneously. Previous studies have shown that using interparticipant information to build a model can waste time. A better approach is to strategically update the model [10], [21], [47]. These studies attempted to train an initial classifier in advance and update it using an appropriate updating strategy. Given the aim of reducing the system calibration time, we adopted the concept of a generic model set and matched the samples of new participants with those of participants in the training set with the same ERP characteristics.</p>
        <p>In the data processing stage, the EEG data of 116 training participants was used to ensure that we had enough samples to build a model set that improved the generalization of the system. During online testing, participants were required to complete a seven characters spelling task. This allowed us to record enough information to identify the matching model. As a whole, the system works very well. However, according to feedback from our participants, the system still has shortcomings. Specifically, there is a short stimulus onset asynchrony (SOA) and unobvious stimulus flash. In this system, the SOA is set to be 160ms, which is too short for many participants to count accurately. In work reported by Allison and Pineda [48] faster SOAs were shown to result in a considerable number of errors. Participant S7 reported that he did not see each individual flash. In this case, the amplitude of the P300 recorded from participant S7 was reduced since the P300 occurs only in response to detected targets. This also resulted in lower accuracy.In the data processing stage, the EEG data of 116 training participants was used to ensure that we had enough samples to build a model set that improved the generalization of the system. During online testing, participants were required to complete a seven characters spelling task. This allowed us to record enough information to identify the matching model. As a whole, the system works very well. However, according to feedback from our participants, the system still has shortcomings. Specifically, there is a short stimulus onset asynchrony (SOA) and unobvious stimulus flash. In this system, the SOA is set to be 160ms, which is too short for many participants to count accurately. In work reported by Allison and Pineda [48] faster SOAs were shown to result in a considerable number of errors. Participant S7 reported that he did not see each individual flash. In this case, the amplitude of the P300 recorded from participant S7 was reduced since the P300 occurs only in response to detected targets. This also resulted in lower accuracy.</p>
        <p>In terms of stimuli, this system used a white/gray flicker matrix as a visual stimulus, which induced discomfort [49]. In addition, Martens et al. [50] showed that traditional row/column flashes can cause overlap and refractory effects and negatively impact on the performance of the system. We can see this negative effect from the online spelling results. Dias et al. [51] proposed that there are differences in the amplitude and latency of the P300 signal for different age groups. Thus, in order to the usage of the system, the age of the participants should be considered in the experiment design. Note, the age group of our participants in the dataset was consistent with the test participants.In terms of stimuli, this system used a white/gray flicker matrix as a visual stimulus, which induced discomfort [49]. In addition, Martens et al. [50] showed that traditional row/column flashes can cause overlap and refractory effects and negatively impact on the performance of the system. We can see this negative effect from the online spelling results. Dias et al. [51] proposed that there are differences in the amplitude and latency of the P300 signal for different age groups. Thus, in order to the usage of the system, the age of the participants should be considered in the experiment design. Note, the age group of our participants in the dataset was consistent with the test participants.</p>
        <p>In the current study, we proposed the concept of a generic model set and introduced an online training strategy combined with a model matching method. The generic model set including ten models trained by a weighted linear discriminant analysis (WLDA) method. The results prove that most participants using the best matching model achieved the same classification performance as the typical model, which reduced the calibration time by approximately 70.7% and proved the the In addition, the results of the worst matching model indicated that not all generic models are suitable for every participant to achieve good performance. In other words, differences exist across generic models.In the current study, we proposed the concept of a generic model set and introduced an online training strategy combined with a model matching method. The generic model set including ten models trained by a weighted linear discriminant analysis (WLDA) method. The results prove that most participants using the best matching model achieved the same classification performance as the typical model, which reduced the calibration time by approximately 70.7% and proved the the In addition, the results of the worst matching model indicated that not all generic models are suitable for every participant to achieve good performance. In other words, differences exist across generic models.</p>
        <p>In future work, we plan to identify optimal parameters and paradigms to build a generic model set. In addition, in order to improve the generality of the model set, we plan to build generic models for specific participant age groups, particularly for older participants and for participants who live with amyotrophic lateral sclerosis (ALS) and are in the lockedin state (LIS).In future work, we plan to identify optimal parameters and paradigms to build a generic model set. In addition, in order to improve the generality of the model set, we plan to build generic models for specific participant age groups, particularly for older participants and for participants who live with amyotrophic lateral sclerosis (ALS) and are in the lockedin state (LIS).</p>
        <p>On the other hand, some participants may have poor performance using BCI systems and may be unfamiliar with how to use it. Thus, we should adopt new ways to improve BCI systems. We will continue to train our generic model set, for example by using neural networks as proposed by Hiraiwa et al. [52], to increase the applicability of the system.On the other hand, some participants may have poor performance using BCI systems and may be unfamiliar with how to use it. Thus, we should adopt new ways to improve BCI systems. We will continue to train our generic model set, for example by using neural networks as proposed by Hiraiwa et al. [52], to increase the applicability of the system.</p>
        <p>This work was supported in part by the National Key Research and Development Program under Grant 2017YFB13003002, in part by the Grant National Natural Science Foundation of China under Grant 61573142, Grant 61773164, and Grant 91420302, in part by the Programme of Introducing Talents of Discipline to Universities through the 111 Project under Grant B17017, and in part by the ShuGuang Project by Shanghai Municipal Education Commission and Shanghai Education Development Foundation under Grant 19SG25.This work was supported in part by the National Key Research and Development Program under Grant 2017YFB13003002, in part by the Grant National Natural Science Foundation of China under Grant 61573142, Grant 61773164, and Grant 91420302, in part by the Programme of Introducing Talents of Discipline to Universities through the 111 Project under Grant B17017, and in part by the ShuGuang Project by Shanghai Municipal Education Commission and Shanghai Education Development Foundation under Grant 19SG25.</p>
    </text>
</tei>
