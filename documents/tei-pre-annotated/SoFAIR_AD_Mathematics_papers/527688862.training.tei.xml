<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-14T12:40+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>Although the hidden Markov models (HMM) are very popular in many applied areas their use in reliability engineering is limited. Problems such as the selection of the HMM model by choosing the appropriate number of states, or problems of prediction of failures have not been widely covered in the literature. This paper is concerned with the use of HMMs where the state of the system is not directly observable and instead certain indicators of the true situation are provided via a control system. A hidden model can provide key information about the system dependability such as the failed component of the system, the reliability of the system and related measures. A maximum-likelihood estimator of the system reliability is obtained and its asymptotic properties are studied. Finally, the maintenance of the system is considered in this context and new preventive maintenance strategies are defined and their efficiency is measured in terms of expected cost. To prove the finite sample performance of the methodology, an extensive simulation study is developed.Although the hidden Markov models (HMM) are very popular in many applied areas their use in reliability engineering is limited. Problems such as the selection of the HMM model by choosing the appropriate number of states, or problems of prediction of failures have not been widely covered in the literature. This paper is concerned with the use of HMMs where the state of the system is not directly observable and instead certain indicators of the true situation are provided via a control system. A hidden model can provide key information about the system dependability such as the failed component of the system, the reliability of the system and related measures. A maximum-likelihood estimator of the system reliability is obtained and its asymptotic properties are studied. Finally, the maintenance of the system is considered in this context and new preventive maintenance strategies are defined and their efficiency is measured in terms of expected cost. To prove the finite sample performance of the methodology, an extensive simulation study is developed.</p>
        <p>A stochastic model can describe the evolution-in-time of a stochastic system. The estimation of its local characteristics is derived from observation data of its evolution in a given interval of time, based on one or several trajectories. In general, data can be provided by sensors that can be interpreted in order to predict the real state of the system. All modern systems include sensors aimed to describe internal or environmental changes of the system functional conditions that influence to their performance level. For example, a car has sensors of pressure, temperature, etc., in order to describe the functional conditions of its engine, brakes, etc. The important challenge for engineers is to provide methods and devices to define the state of the engine, for example, of the car given the values of these indicators. This is a typical inverse problem where several methods can be applied. Some of these methods are the so called hidden Markov models (HMM), which are based on a coupled process (e.g. Markov chain), say (X, Y ) , where X is an unobserved random sequence, describing the state of the system (i.e., engine), and Y is an observable random sequence, giving the values of the parameters of some indicators (i.e., pressure, temper-ature, etc.), whose law depends on the value of the corresponding unobserved sequence X. In order to be able to handle the above coupled process, we have to assume some particular probabilistic structure. For example, for X we can suppose that it is an i.i.d sequence or a Markov or semi-Markov chain; while for Y it can be thought as conditionally independent on X sequence, with its law depending on the corresponding value of X.A stochastic model can describe the evolution-in-time of a stochastic system. The estimation of its local characteristics is derived from observation data of its evolution in a given interval of time, based on one or several trajectories. In general, data can be provided by sensors that can be interpreted in order to predict the real state of the system. All modern systems include sensors aimed to describe internal or environmental changes of the system functional conditions that influence to their performance level. For example, a car has sensors of pressure, temperature, etc., in order to describe the functional conditions of its engine, brakes, etc. The important challenge for engineers is to provide methods and devices to define the state of the engine, for example, of the car given the values of these indicators. This is a typical inverse problem where several methods can be applied. Some of these methods are the so called hidden Markov models (HMM), which are based on a coupled process (e.g. Markov chain), say (X, Y ) , where X is an unobserved random sequence, describing the state of the system (i.e., engine), and Y is an observable random sequence, giving the values of the parameters of some indicators (i.e., pressure, temper-ature, etc.), whose law depends on the value of the corresponding unobserved sequence X. In order to be able to handle the above coupled process, we have to assume some particular probabilistic structure. For example, for X we can suppose that it is an i.i.d sequence or a Markov or semi-Markov chain; while for Y it can be thought as conditionally independent on X sequence, with its law depending on the corresponding value of X.</p>
        <p>We have a number of different situations where this model can be used in the real data case. For example in Rex data (field data), where we have a system (a device) with lifetime data and maintenance data matching together. If for example, in this case we have several identical systems and we estimate their lifetime distributions, they are not the same. That means we have some additional random factor. This random factor could be a Markov chain as a random media of our main system. The situation of experimental data is the same. This is the case of the Virkler's data that we present here (see Section 6 ). The same idea is possible considering expert's opinion to describe the lifetime of the device. The random factor here could be the different experience of each expert. A different situation is when we describe a system, i.e, our car etc.We have a number of different situations where this model can be used in the real data case. For example in Rex data (field data), where we have a system (a device) with lifetime data and maintenance data matching together. If for example, in this case we have several identical systems and we estimate their lifetime distributions, they are not the same. That means we have some additional random factor. This random factor could be a Markov chain as a random media of our main system. The situation of experimental data is the same. This is the case of the Virkler's data that we present here (see Section 6 ). The same idea is possible considering expert's opinion to describe the lifetime of the device. The random factor here could be the different experience of each expert. A different situation is when we describe a system, i.e, our car etc.</p>
        <p>It is a common practice in Statistics, in order to be able to control the results, to produce simulated data. For example, we produce trajectories (data) for Markov chain, from a given transition probability matrix, and then we use these trajectories as data entries to our estimator of the transition probability matrix without any reference to the given matrix. Finally, we can compare the given matrix with the estimated one. Nevertheless, as the ultimate goal is to estimate parameters and functions using real data, we have also to try using real data, even if these data is a little difficult to obtain (see Section 6 ).It is a common practice in Statistics, in order to be able to control the results, to produce simulated data. For example, we produce trajectories (data) for Markov chain, from a given transition probability matrix, and then we use these trajectories as data entries to our estimator of the transition probability matrix without any reference to the given matrix. Finally, we can compare the given matrix with the estimated one. Nevertheless, as the ultimate goal is to estimate parameters and functions using real data, we have also to try using real data, even if these data is a little difficult to obtain (see Section 6 ).</p>
        <p>Another important aspect for engineers is keeping the system in an appropriate working state. This is achieved by implementing good maintenance strategies for each particular system. Maintenance involves planned (preventive) and unplanned (corrective) actions carried out to retain a system in or restore it to an acceptable operating condition ( Pham &amp; Wang, 1996 ). Preventive maintenance (PM) actions attempt to retain the system in an acceptable operating condition preventing its failure. Corrective maintenance refers to all the actions that occur when the system has already failed. PM is essential to reduce operating costs and the risk of a catastrophic failure ( Shey-Huei, Chin-Chih, Yen-Luan, &amp; Zhe, 2015 ).Another important aspect for engineers is keeping the system in an appropriate working state. This is achieved by implementing good maintenance strategies for each particular system. Maintenance involves planned (preventive) and unplanned (corrective) actions carried out to retain a system in or restore it to an acceptable operating condition ( Pham &amp; Wang, 1996 ). Preventive maintenance (PM) actions attempt to retain the system in an acceptable operating condition preventing its failure. Corrective maintenance refers to all the actions that occur when the system has already failed. PM is essential to reduce operating costs and the risk of a catastrophic failure ( Shey-Huei, Chin-Chih, Yen-Luan, &amp; Zhe, 2015 ).</p>
        <p>After a maintenance action takes place the system is in a new state, that depends not only on the performed maintenance action but also how well it was performed. Maintenance actions can be perfect, restoring the system to an as good as new condition (AGAN), minimal, keeping the system in the same state as before the maintenance action took place, or something in between ( Labeau &amp; Segovia, 2011 ). In most situations the system is not back to an AGAN condition, but rather to a state previous to the moment the maintenance action took place. This is known as Imperfect Maintenance. Estimating this state has been widely considered in the literature. For example, Kijima I and Kijima II ( Kijima, 1989 ) are two well-known classical models. The first model considers that maintenance actions can only remove damage on the system since previous maintenance intervention, the second model assumes that maintenance can remove part of the cumulated damage up to the moment the intervention takes place. Other well established models are Arithmetic Reduction of the Intensity (ARI) and Arithmetic Reduction of the Age (ARA) models ( Doyen &amp; Gaudoin, 2004 ). ARI models consider that the failure intensity of the system is reduced after maintenance. ARA models focuses on reducing the age of the system after the intervention. These are just some examples but there are many others.After a maintenance action takes place the system is in a new state, that depends not only on the performed maintenance action but also how well it was performed. Maintenance actions can be perfect, restoring the system to an as good as new condition (AGAN), minimal, keeping the system in the same state as before the maintenance action took place, or something in between ( Labeau &amp; Segovia, 2011 ). In most situations the system is not back to an AGAN condition, but rather to a state previous to the moment the maintenance action took place. This is known as Imperfect Maintenance. Estimating this state has been widely considered in the literature. For example, Kijima I and Kijima II ( Kijima, 1989 ) are two well-known classical models. The first model considers that maintenance actions can only remove damage on the system since previous maintenance intervention, the second model assumes that maintenance can remove part of the cumulated damage up to the moment the intervention takes place. Other well established models are Arithmetic Reduction of the Intensity (ARI) and Arithmetic Reduction of the Age (ARA) models ( Doyen &amp; Gaudoin, 2004 ). ARI models consider that the failure intensity of the system is reduced after maintenance. ARA models focuses on reducing the age of the system after the intervention. These are just some examples but there are many others.</p>
        <p>In this paper we will suppose that X = { X n ; n ≥ 0 } is a Markov chain taking values in a set E = { e 1 , e 2 , . . . , e d } where transitions between states are given by an unknown matrix P ; and, thatIn this paper we will suppose that X = { X n ; n ≥ 0 } is a Markov chain taking values in a set E = { e 1 , e 2 , . . . , e d } where transitions between states are given by an unknown matrix P ; and, that</p>
        <p>general, and M is an unknown function. We consider the case where Y takes values in a finite set A = { a 1 , a 2 , . . . , a s } . The d × s -matrix M with (i, j) element M(e i , a j ) is called the emission matrix. This model is described as HMM M1-M0, that is, a Markov chain of order one for X, and a Markov chain of order zero for Y . They are dynamical stochastic models and this is the main reason of their usefulness to model real systems.general, and M is an unknown function. We consider the case where Y takes values in a finite set A = { a 1 , a 2 , . . . , a s } . The d × s -matrix M with (i, j) element M(e i , a j ) is called the emission matrix. This model is described as HMM M1-M0, that is, a Markov chain of order one for X, and a Markov chain of order zero for Y . They are dynamical stochastic models and this is the main reason of their usefulness to model real systems.</p>
        <p>The problem here is to estimate the transition matrix of the Markov chain X and the emission probability for Y as above. As it is always the case for missed data, we cannot obtain a closed form solution for the maximum likelihood estimator (MLE), but we have to use approximation numerical methods as the EM-algorithm. The main application of the proposed model concerns reliability and maintenance of complex systems, see Landon, Ozekici, &amp; Soyer (2013) , or Vrignat, Avila, Duculty, &amp; Kratz (2015) , among others, and also Wang (2002) , and Jonge &amp; Scarf (2020) for an up to date review on maintenance theory and applications.The problem here is to estimate the transition matrix of the Markov chain X and the emission probability for Y as above. As it is always the case for missed data, we cannot obtain a closed form solution for the maximum likelihood estimator (MLE), but we have to use approximation numerical methods as the EM-algorithm. The main application of the proposed model concerns reliability and maintenance of complex systems, see Landon, Ozekici, &amp; Soyer (2013) , or Vrignat, Avila, Duculty, &amp; Kratz (2015) , among others, and also Wang (2002) , and Jonge &amp; Scarf (2020) for an up to date review on maintenance theory and applications.</p>
        <p>Several studies in the literature concern this kind of models from theoretical point of view ( Baum &amp; Petrie, 1966;Trevezas &amp; Limnios, 2009 ) and practical applications in modelling and analysing biological sequences, as DNA ( Barbu &amp; Limnios, 2008 ), in environmental sustainability problems analysis ( Jiang &amp; Liu, 2015 ), and recently in reliability analysis ( Durand &amp; Gaudoin, 2005;Fort, Mugnaini, &amp; Vignoli, 2015;Simoes, Viegas, Torres Farinha, &amp; Fonseca, 2017;Votsi, Limnios, Tsaklidis, &amp; Papadimitriou, 2013;Zhou, Hu, Xu, Chen, &amp; Zhou, 2010 ).Several studies in the literature concern this kind of models from theoretical point of view ( Baum &amp; Petrie, 1966;Trevezas &amp; Limnios, 2009 ) and practical applications in modelling and analysing biological sequences, as DNA ( Barbu &amp; Limnios, 2008 ), in environmental sustainability problems analysis ( Jiang &amp; Liu, 2015 ), and recently in reliability analysis ( Durand &amp; Gaudoin, 2005;Fort, Mugnaini, &amp; Vignoli, 2015;Simoes, Viegas, Torres Farinha, &amp; Fonseca, 2017;Votsi, Limnios, Tsaklidis, &amp; Papadimitriou, 2013;Zhou, Hu, Xu, Chen, &amp; Zhou, 2010 ).</p>
        <p>The present paper is organized as follows. In Section 2 general considerations about hidden Markov models are treated. In Section 3 a new approach of reliability analysis based on HMM is presented. Section 4 is devoted to maintenance issues. Numerical applications are developed in Section 5 and Section 6 where we discuss simulated data as well as a real dataset. Finally, Section 7 gives the conclusions and suggests future research lines.The present paper is organized as follows. In Section 2 general considerations about hidden Markov models are treated. In Section 3 a new approach of reliability analysis based on HMM is presented. Section 4 is devoted to maintenance issues. Numerical applications are developed in Section 5 and Section 6 where we discuss simulated data as well as a real dataset. Finally, Section 7 gives the conclusions and suggests future research lines.</p>
        <p>In a hidden modelling context, there are three basic problems that must be solved for the model to be useful in real-world applications ( Rabiner, 1989 ). The most difficult one is the training problem, which consists of optimally estimate the parameters of the model from observed data. We usually call the available observations the training dataset . Once the model is constructed (trained), we need to evaluate the model, that is we address the evaluation problem. This involves the calculation of several probabilities associated to the model estimated parameters. Among others we want to score how well the estimated model fit the data, which is useful to choose between competing candidate models. Finally, we are mostly interested in uncovering the hidden part of the model, then we have a decoding problem. In short it means that we want to determine the "optimal" sequence of hidden states that originated the output sequence we actually observed. To do it, we first need to decide which optimality criterion best fits our purposes. In the particular case of reliability applications, solving these problems allow us to get key information about the system performance.In a hidden modelling context, there are three basic problems that must be solved for the model to be useful in real-world applications ( Rabiner, 1989 ). The most difficult one is the training problem, which consists of optimally estimate the parameters of the model from observed data. We usually call the available observations the training dataset . Once the model is constructed (trained), we need to evaluate the model, that is we address the evaluation problem. This involves the calculation of several probabilities associated to the model estimated parameters. Among others we want to score how well the estimated model fit the data, which is useful to choose between competing candidate models. Finally, we are mostly interested in uncovering the hidden part of the model, then we have a decoding problem. In short it means that we want to determine the "optimal" sequence of hidden states that originated the output sequence we actually observed. To do it, we first need to decide which optimality criterion best fits our purposes. In the particular case of reliability applications, solving these problems allow us to get key information about the system performance.</p>
        <p>More specifically: knowing an estimator θ of θ we can estimate by the usual plug in estimation procedure the reliability, availability, mean times, etc. ( evaluation ) and find the way the system fails ( decoding ), e.g. via a Viterbi algorithm.More specifically: knowing an estimator θ of θ we can estimate by the usual plug in estimation procedure the reliability, availability, mean times, etc. ( evaluation ) and find the way the system fails ( decoding ), e.g. via a Viterbi algorithm.</p>
        <p>Let us consider two finite sets, say E = { e 1 , . . . , e d } and A = { a 1 , . . . , a s } , and a sequence of coupled r.v. (X n , Y n ) n ≥0 , where (X n ) is a Markov chain of order 1 (CM1), with values in E, and transition matrix P , and initial law α, and (Y n ) a sequence of r.v. with values in A whose law depends on values of (X n ) , in the following way:Let us consider two finite sets, say E = { e 1 , . . . , e d } and A = { a 1 , . . . , a s } , and a sequence of coupled r.v. (X n , Y n ) n ≥0 , where (X n ) is a Markov chain of order 1 (CM1), with values in E, and transition matrix P , and initial law α, and (Y n ) a sequence of r.v. with values in A whose law depends on values of (X n ) , in the following way:</p>
        <p>(1) for all n ∈ N . The matrix M is called an emission matrix. As usual we call the elements of E the states of the system while the elements of A are referred to as signals .(1) for all n ∈ N . The matrix M is called an emission matrix. As usual we call the elements of E the states of the system while the elements of A are referred to as signals .</p>
        <p>We can write thenWe can write then</p>
        <p>This model is denoted by M1 -M0 , where M1 is referred to the Markov chain of order 1, X, and M0 to the chain Y of order zero with respect to itself. A more general case is the model M1 -Mk with k ≥ 1 . In the last case, the conditional law of Y isThis model is denoted by M1 -M0 , where M1 is referred to the Markov chain of order 1, X, and M0 to the chain Y of order zero with respect to itself. A more general case is the model M1 -Mk with k ≥ 1 . In the last case, the conditional law of Y is</p>
        <p>It is obvious that the Markov chain X can be considered of order m , which is the model Mm -Mk .It is obvious that the Markov chain X can be considered of order m , which is the model Mm -Mk .</p>
        <p>In this paper we limit ourselves to the case HMM (M1-M0) . The problem here is to estimate the parameters of P and M .In this paper we limit ourselves to the case HMM (M1-M0) . The problem here is to estimate the parameters of P and M .</p>
        <p>Let us denote the independent parameters of the model by θ = (P (i, j)Let us denote the independent parameters of the model by θ = (P (i, j)</p>
        <p>The log-likelihood can be written, by neglecting the term log P (X 0 ) , asThe log-likelihood can be written, by neglecting the term log P (X 0 ) , as</p>
        <p>where Y = (Y 0 , . . . , Y n ) and X = (X 0 , . . . , X n ) and it is included inwhere Y = (Y 0 , . . . , Y n ) and X = (X 0 , . . . , X n ) and it is included in</p>
        <p>(3)(3)</p>
        <p>In order to estimate θ we will apply E-M algorithm as follows. The function Q (θ | θ (m ) ) will give us by successive iterations an approximation of the estimate of θ .In order to estimate θ we will apply E-M algorithm as follows. The function Q (θ | θ (m ) ) will give us by successive iterations an approximation of the estimate of θ .</p>
        <p>The calculus of this expectation needs the calculus of the probabil-The calculus of this expectation needs the calculus of the probabil-</p>
        <p>In order to pass from θ (m ) to θ (m +1) ,In order to pass from θ (m ) to θ (m +1) ,</p>
        <p>the following two-steps algorithm is used. This is the well known EM algorithm.the following two-steps algorithm is used. This is the well known EM algorithm.</p>
        <p>Step E (Expectation):Step E (Expectation):</p>
        <p>For given θ (m ) , compute the probabilities:For given θ (m ) , compute the probabilities:</p>
        <p>Step M (Maximization):Step M (Maximization):</p>
        <p>Update θ (m ) to θ (m +1) via (5)Update θ (m ) to θ (m +1) via (5)</p>
        <p>The maximization step M, is realized directly by the following formulas:The maximization step M, is realized directly by the following formulas:</p>
        <p>ˆˆ</p>
        <p>The probabilities that need to be computed in the E-step can be obtained by means of the "forward-backward" procedure as explained in the following.The probabilities that need to be computed in the E-step can be obtained by means of the "forward-backward" procedure as explained in the following.</p>
        <p>For given θ (m ) , compute the probabilities:For given θ (m ) , compute the probabilities:</p>
        <p>To do it a "forward-backward" procedure is used.To do it a "forward-backward" procedure is used.</p>
        <p>Define the forward probability function F k (i ) , for k = 1 , . . . , n and i ∈ E asDefine the forward probability function F k (i ) , for k = 1 , . . . , n and i ∈ E as</p>
        <p>and the backward probability function B k (i ) , asand the backward probability function B k (i ) , as</p>
        <p>for k = 1 , . . . , n and i ∈ E. These functions meet, respectively, the following recurrence equationsfor k = 1 , . . . , n and i ∈ E. These functions meet, respectively, the following recurrence equations</p>
        <p>Then it can be written thatThen it can be written that</p>
        <p>We suppose here that the system structure is described by the hidden Markov chain X and that the state-space is split into two subsets U := { 1 , . . . , r} , the working states, and D := { r + 1 , . . . , d} , the down states. For simplicity, and without loss of generality, this notation is used for the states of the system. Additionally, the system up states can be defined not only by U ⊂ E but also by some subset of A . In some situations, the information we get about the system functioning can be categorized into two groups of signals. On the one hand, we have a group of signals indicating a good performance, the subset A 1 ⊂ A ; and, on the other hand, there is a group of s 1 &lt; s signals for warning of some serious problem in the system A 2 that involves the operation interruption thus causing the system failure, that is, the subset A 2 ⊂ A . Then we have also the partition A = A 1 ∪ A 2 .We suppose here that the system structure is described by the hidden Markov chain X and that the state-space is split into two subsets U := { 1 , . . . , r} , the working states, and D := { r + 1 , . . . , d} , the down states. For simplicity, and without loss of generality, this notation is used for the states of the system. Additionally, the system up states can be defined not only by U ⊂ E but also by some subset of A . In some situations, the information we get about the system functioning can be categorized into two groups of signals. On the one hand, we have a group of signals indicating a good performance, the subset A 1 ⊂ A ; and, on the other hand, there is a group of s 1 &lt; s signals for warning of some serious problem in the system A 2 that involves the operation interruption thus causing the system failure, that is, the subset A 2 ⊂ A . Then we have also the partition A = A 1 ∪ A 2 .</p>
        <p>Let us denote T the first time the system visits the set of down states D , i.e. the hitting time of set D . Let us consider U =Let us denote T the first time the system visits the set of down states D , i.e. the hitting time of set D . Let us consider U =</p>
        <p>Therefore the reliability of the system can be defined as R (n [m5G;May 26, 2022;10:41 ] ×M (i,Therefore the reliability of the system can be defined as R (n [m5G;May 26, 2022;10:41 ] ×M (i,</p>
        <p>where we use the notation i nwhere we use the notation i n</p>
        <p>where α i = P (X 0 = i ) , for i ∈ U, denotes the initial law.where α i = P (X 0 = i ) , for i ∈ U, denotes the initial law.</p>
        <p>As we know, the two-dimensional processAs we know, the two-dimensional process</p>
        <p>is a two-dimensional Markov chain of order 1 (CM1) with statespace E of size d • s and transition probability matrix P , with elementsis a two-dimensional Markov chain of order 1 (CM1) with statespace E of size d • s and transition probability matrix P , with elements</p>
        <p>As can be seen, the matrixAs can be seen, the matrix</p>
        <p>For convenience in the calculations, the states are organized in lexicographical order as follows (d,For convenience in the calculations, the states are organized in lexicographical order as follows (d,</p>
        <p>where it is denoted (i, l) n 0 = { (i 0 , l 0 ) , . . . , (i n , l n ) } . That is, the system fails whenever the subset D is reached or a signal of subset A 2 is emitted. The summation in Eq. ( 12) is expanded for all the elements in U = U × A 1 , then, using matrix notation, it can be writtenwhere it is denoted (i, l) n 0 = { (i 0 , l 0 ) , . . . , (i n , l n ) } . That is, the system fails whenever the subset D is reached or a signal of subset A 2 is emitted. The summation in Eq. ( 12) is expanded for all the elements in U = U × A 1 , then, using matrix notation, it can be written</p>
        <p>for n ≥ 1 , with 1 r a unitary vector of size r = r • s 1 , being r the total number of up states and s 1 the size of the set A 1 .for n ≥ 1 , with 1 r a unitary vector of size r = r • s 1 , being r the total number of up states and s 1 the size of the set A 1 .</p>
        <p>We define the following estimator of the reliability asWe define the following estimator of the reliability as</p>
        <p>for n ≥ 0 and N the sample size.for n ≥ 0 and N the sample size.</p>
        <p>Let us derive the consistency and asymptotic normality of the reliability estimator defined above.Let us derive the consistency and asymptotic normality of the reliability estimator defined above.</p>
        <p>For { Y 0 , ..., Y N } a sample path of observations, the loglikelihood function for an observation of the hidden Markov chain log f (X, Y | θ) , is given in Eq. (3) . The vector of parameters of the model θ, can be written after removing the independent parameters as θ = θ 1 , θ 2 , withFor { Y 0 , ..., Y N } a sample path of observations, the loglikelihood function for an observation of the hidden Markov chain log f (X, Y | θ) , is given in Eq. (3) . The vector of parameters of the model θ, can be written after removing the independent parameters as θ = θ 1 , θ 2 , with</p>
        <p>that is, the elements of the matrix P taken column-wise without the diagonal. The number of parameters to be estimated in thisthat is, the elements of the matrix P taken column-wise without the diagonal. The number of parameters to be estimated in this</p>
        <p>) . On the other hand,) . On the other hand,</p>
        <p>that is the elements of the matrix M taken column-wise. The size of the sub-vector θ 2 is b 2 = d • (s -1) . Then, the total number of independent parameters to be estimated is bthat is the elements of the matrix M taken column-wise. The size of the sub-vector θ 2 is b 2 = d • (s -1) . Then, the total number of independent parameters to be estimated is b</p>
        <p>We need the following assumptions.We need the following assumptions.</p>
        <p>Assumptions Barbu &amp; Limnios (2008) :Assumptions Barbu &amp; Limnios (2008) :</p>
        <p>A1 The Markov chain X is ergodic, i.e., irreducible and aperiodic; and stationary; A2 There exists an integer n ∈ N such that the Fisher informa-A1 The Markov chain X is ergodic, i.e., irreducible and aperiodic; and stationary; A2 There exists an integer n ∈ N such that the Fisher informa-</p>
        <p>is nonsingular, where log p θ (Y n 0 ) is the log-likelihood function defined in Eq. ( 2) .is nonsingular, where log p θ (Y n 0 ) is the log-likelihood function defined in Eq. ( 2) .</p>
        <p>Let us denote θ 0 = θ 0 1 , θ 0 2 the true value of the parameter.Let us denote θ 0 = θ 0 1 , θ 0 2 the true value of the parameter.</p>
        <p>The following theorem is deduced as a particular case of Theorem 6.1 and Theorem 6.4 in Barbu &amp; Limnios (2008) . See also Baum &amp; Petrie (1966) and Bickel, Ritov, &amp; Rydén (1998) .The following theorem is deduced as a particular case of Theorem 6.1 and Theorem 6.4 in Barbu &amp; Limnios (2008) . See also Baum &amp; Petrie (1966) and Bickel, Ritov, &amp; Rydén (1998) .</p>
        <p>is asymptotically Normal, as N → + ∞ , with zero mean and covariance matrix the inverse of the asymptotic Fisher information matrixis asymptotically Normal, as N → + ∞ , with zero mean and covariance matrix the inverse of the asymptotic Fisher information matrix</p>
        <p>The asymptotic Fisher information matrix is given byThe asymptotic Fisher information matrix is given by</p>
        <p>, see Baum &amp; Petrie (1966) , and in Douc (2005) it is shown that, see Baum &amp; Petrie (1966) , and in Douc (2005) it is shown that</p>
        <p>From Theorem 1 we immediately obtain the consistency and the asymptotic normality of the reliability estimator R . Previously we need the following lemmas. First we consider the following partition of the matrix P P = P UU P UD P DU P DD and denote θ U = θ 1 ,U , θ 2 , 1 where in the sub-vector denoted θ 1 ,UFrom Theorem 1 we immediately obtain the consistency and the asymptotic normality of the reliability estimator R . Previously we need the following lemmas. First we consider the following partition of the matrix P P = P UU P UD P DU P DD and denote θ U = θ 1 ,U , θ 2 , 1 where in the sub-vector denoted θ 1 ,U</p>
        <p>we keep only the elements of sub-matrix P UU , which contains all transitions between the up-states; and, in the sub-vector denoted θ 2 , 1 we keep only the elements of sub-matrix M UA 1 , which contains all emission probabilities from up-states to good signals.we keep only the elements of sub-matrix P UU , which contains all transitions between the up-states; and, in the sub-vector denoted θ 2 , 1 we keep only the elements of sub-matrix M UA 1 , which contains all emission probabilities from up-states to good signals.</p>
        <p>Accordingly, we can write matrix P by blocks as followsAccordingly, we can write matrix P by blocks as follows</p>
        <p>where we have considered a similar partition of the state spacewhere we have considered a similar partition of the state space</p>
        <p>, is strongly consistent as N tends to infinity., is strongly consistent as N tends to infinity.</p>
        <p>Proof. The transition probabilities for the two-dimensional process (X, Y ) are obtained as P ((i, l) , ( j, h )) = P (i, j) M( j, h ) for all i, j ∈ E and l, h ∈ A . Considering the vector of parameters θ = θ 1 , θ 2 we define the following functionProof. The transition probabilities for the two-dimensional process (X, Y ) are obtained as P ((i, l) , ( j, h )) = P (i, j) M( j, h ) for all i, j ∈ E and l, h ∈ A . Considering the vector of parameters θ = θ 1 , θ 2 we define the following function</p>
        <p>and, for i = 1 , 2 , . . . , r, consider two cases:and, for i = 1 , 2 , . . . , r, consider two cases:</p>
        <p>This function returns a vector whose components are the elements of matrix P U U taken column-wise. Then, using the consistency of the estimator θ, which is deduced from Theorem 6.1 in Barbu &amp; Limnios (2008) , recalled by Theorem 1 above, and applying the continuous mapping theorem to the function defined in ( 13) -( 14) , we obtain the desired result.This function returns a vector whose components are the elements of matrix P U U taken column-wise. Then, using the consistency of the estimator θ, which is deduced from Theorem 6.1 in Barbu &amp; Limnios (2008) , recalled by Theorem 1 above, and applying the continuous mapping theorem to the function defined in ( 13) -( 14) , we obtain the desired result.</p>
        <p>Lemma 2. We have thatLemma 2. We have that</p>
        <p>Proof. The proof is easily obtained from Lemma 1 given above that gives the proof for n = 1 , then, mathematical induction similarly to Lemma 1 of Sadek &amp; Limnios (2002) can be applied to get the result for all n ≥ 2 .Proof. The proof is easily obtained from Lemma 1 given above that gives the proof for n = 1 , then, mathematical induction similarly to Lemma 1 of Sadek &amp; Limnios (2002) can be applied to get the result for all n ≥ 2 .</p>
        <p>Proof. The proof is similar to Theorem 3 in Sadek &amp; Limnios (2002) and can be deduced straightforwardly from Lemma 1 and Lemma 2 above.Proof. The proof is similar to Theorem 3 in Sadek &amp; Limnios (2002) and can be deduced straightforwardly from Lemma 1 and Lemma 2 above.</p>
        <p>Lemma 3. Under the Assumptions A 1 -A 2 , given a sample of observations Y N 0 , the random vectorLemma 3. Under the Assumptions A 1 -A 2 , given a sample of observations Y N 0 , the random vector</p>
        <p>is asymptotically Normal, as N → + ∞ with 0 mean and covariance matrix P = • θ • , where θ is the covariance matrix of the random vector θ = θ 1 , θ 2 and is the function defined in ( 13) -( 14) whose partial derivative matrix has elements given in ( 15) -( 18) .is asymptotically Normal, as N → + ∞ with 0 mean and covariance matrix P = • θ • , where θ is the covariance matrix of the random vector θ = θ 1 , θ 2 and is the function defined in ( 13) -( 14) whose partial derivative matrix has elements given in ( 15) -( 18) .</p>
        <p>Proof. Theorem 6.4 in Barbu &amp; Limnios (2008) gives the asymptotic normality of the maximum likelihood estimator θ = ( θ 1 , θ 2 ) , then we can apply the Delta method considering the function defined in ( 13) -( 14) and the derivative matrix is detailed as follows:Proof. Theorem 6.4 in Barbu &amp; Limnios (2008) gives the asymptotic normality of the maximum likelihood estimator θ = ( θ 1 , θ 2 ) , then we can apply the Delta method considering the function defined in ( 13) -( 14) and the derivative matrix is detailed as follows:</p>
        <p>• For each k = 1 , 2 , . . . , s 1 , each j = 1 , 2 , . . . , r, and i = j. For all i , j ∈ { 1 , 2 , . . . , d} , we have that• For each k = 1 , 2 , . . . , s 1 , each j = 1 , 2 , . . . , r, and i = j. For all i , j ∈ { 1 , 2 , . . . , d} , we have that</p>
        <p>For all j ∈ { 1 , . . . , d} and all k ∈ { 1 , . . . , s } ,For all j ∈ { 1 , . . . , d} and all k ∈ { 1 , . . . , s } ,</p>
        <p>Finally, for all k ∈ { 1 , . . . , s } , and all j ∈ { 1 , . . . , d} ,Finally, for all k ∈ { 1 , . . . , s } , and all j ∈ { 1 , . . . , d} ,</p>
        <p>)) , for all n ≥ 1 and (i, l) , ( j, h ) ∈ E . Then, the random vector F n N = (F n (i,l) , ( j,h ) ) converges, as N → + ∞ , to a Normal distribution with mean 0, and covariance matrix F n = n F n , where n is a constant matrix and F is the covariance matrix of F N .)) , for all n ≥ 1 and (i, l) , ( j, h ) ∈ E . Then, the random vector F n N = (F n (i,l) , ( j,h ) ) converges, as N → + ∞ , to a Normal distribution with mean 0, and covariance matrix F n = n F n , where n is a constant matrix and F is the covariance matrix of F N .</p>
        <p>Proof. This result is directly deduced from the result in Lemma 3 given above which shows the result for n = 1 . Then we can follow similar steps as in Theorem 4 of Sadek &amp; Limnios (2002) and apply mathematical induction to get the result for all n ≥ 2 . Specifically, for n = 2 we haveProof. This result is directly deduced from the result in Lemma 3 given above which shows the result for n = 1 . Then we can follow similar steps as in Theorem 4 of Sadek &amp; Limnios (2002) and apply mathematical induction to get the result for all n ≥ 2 . Specifically, for n = 2 we have</p>
        <p>P ((i, l) , (i 1 , l 1 )) P ((i 1 , l 1 ) , ( j, h ))P ((i, l) , (i 1 , l 1 )) P ((i 1 , l 1 ) , ( j, h ))</p>
        <p>-P ((i 1 , l 1 ) , ( j, h )) + + P ((i, l) , (i 1 , l 1 )) -P ((i, l) , (i 1 , l 1 )) P ((i 1 , l 1 ) , ( j, h )) , which can also be written as-P ((i 1 , l 1 ) , ( j, h )) + + P ((i, l) , (i 1 , l 1 )) -P ((i, l) , (i 1 , l 1 )) P ((i 1 , l 1 ) , ( j, h )) , which can also be written as</p>
        <p>P ((i,l) , (i 1 ,l 1 )) P ((i 1 , l 1 ) , ( j, h ))P ((i,l) , (i 1 ,l 1 )) P ((i 1 , l 1 ) , ( j, h ))</p>
        <p>-P ((i 1 , l 1 ) , ( j, h ))-P ((i 1 , l 1 ) , ( j, h ))</p>
        <p>P ((i, l) , (i 1 , l 1 )) -P ((i, l) , (i 1 , l 1 ))P ((i, l) , (i 1 , l 1 )) -P ((i, l) , (i 1 , l 1 ))</p>
        <p>Following similar arguments as in Sadek &amp; Limnios (2002) , by Slutsky's theorem, the first term of the sum in 19 is of lower order so it can be ignored for the limit expression. Then, we haveFollowing similar arguments as in Sadek &amp; Limnios (2002) , by Slutsky's theorem, the first term of the sum in 19 is of lower order so it can be ignored for the limit expression. Then, we have</p>
        <p>So we can express F 2 (i,l) , ( j,h ) as a linear transformation of the vectorSo we can express F 2 (i,l) , ( j,h ) as a linear transformation of the vector</p>
        <p>Using Lemma 3 , the vectorUsing Lemma 3 , the vector</p>
        <p>centered Normal distribution. Moreover the covariance matrix can be obtained from the following Cov F 2 ((i 1 ,l 1 ) , ( j 1 ,h 1 )) , F 2centered Normal distribution. Moreover the covariance matrix can be obtained from the following Cov F 2 ((i 1 ,l 1 ) , ( j 1 ,h 1 )) , F 2</p>
        <p>+ (i,l) , ( j,h ) ∈ E P (i,l) , ( j 1 ,h 1 ) P ( j,h ) , ( j 2 ,h 2 ) Cov (F (i 1 ,l 1 ) , (i,l) ,+ (i,l) , ( j,h ) ∈ E P (i,l) , ( j 1 ,h 1 ) P ( j,h ) , ( j 2 ,h 2 ) Cov (F (i 1 ,l 1 ) , (i,l) ,</p>
        <p>which can be written, after conveniently defining the matrix 2 , aswhich can be written, after conveniently defining the matrix 2 , as</p>
        <p>By the same reasoning as in Eq. ( 19) , for any n ≥ 2 , the expression F n +1 (i,l) , ( j,h ) has the same limit as the expression that followsBy the same reasoning as in Eq. ( 19) , for any n ≥ 2 , the expression F n +1 (i,l) , ( j,h ) has the same limit as the expression that follows</p>
        <p>Then, using mathematical induction, the following recurrence relation can be shown, for any n ≥ 2 ,Then, using mathematical induction, the following recurrence relation can be shown, for any n ≥ 2 ,</p>
        <p>where ≡ means equivalence in distribution. Then, we get that vectorwhere ≡ means equivalence in distribution. Then, we get that vector</p>
        <p>(i,l) , ( j,h ) ; (i, l) , ( j, h ) ∈ E is a linear transformation of vector F N and then it has Normal distribution with mean 0. Reasoning similar to the case n = 2 we can write the covariance matrix conveniently defining the transformation matrix n +1 .(i,l) , ( j,h ) ; (i, l) , ( j, h ) ∈ E is a linear transformation of vector F N and then it has Normal distribution with mean 0. Reasoning similar to the case n = 2 we can write the covariance matrix conveniently defining the transformation matrix n +1 .</p>
        <p>Proposition 2. The estimator R (n ; N) is asymptotically Normal, asProposition 2. The estimator R (n ; N) is asymptotically Normal, as</p>
        <p>Proof. The proof is similar to Theorem 6 in Sadek &amp; Limnios (2002) and can be deduced straightforwardly from Lemma 3 and Lemma 4 above.Proof. The proof is similar to Theorem 6 in Sadek &amp; Limnios (2002) and can be deduced straightforwardly from Lemma 3 and Lemma 4 above.</p>
        <p>When the Markov chain X is stationary the initial distribution α coincides with the stationary distribution π, then we have that R (0) &lt; 1 because in general π(DWhen the Markov chain X is stationary the initial distribution α coincides with the stationary distribution π, then we have that R (0) &lt; 1 because in general π(D</p>
        <p>being U the subset of up-states U, and D the subset of down-states.being U the subset of up-states U, and D the subset of down-states.</p>
        <p>To overcome this issue we introduce the concept of conditional reliability R C , defined asTo overcome this issue we introduce the concept of conditional reliability R C , defined as</p>
        <p>for all n ≥ 0 , where π(U 10) we can define the corresponding estimator and deduce its properties.for all n ≥ 0 , where π(U 10) we can define the corresponding estimator and deduce its properties.</p>
        <p>In this paper, we propose a maintenance policy for our HMM where the system states represent degradation levels. The policy restores the system to a previous, not necessarily AGAN, condition with certain probability. Similarly, Boussemart, Bickard, &amp; Limnios (2001) considered a Markov chain that governs the system degradation, maintenance actions bring the system to a new state with certain probability, the new system state depends on the performed action. More details in this subject can be read in Section 1 .In this paper, we propose a maintenance policy for our HMM where the system states represent degradation levels. The policy restores the system to a previous, not necessarily AGAN, condition with certain probability. Similarly, Boussemart, Bickard, &amp; Limnios (2001) considered a Markov chain that governs the system degradation, maintenance actions bring the system to a new state with certain probability, the new system state depends on the performed action. More details in this subject can be read in Section 1 .</p>
        <p>Let us consider a system that degrades with time. Every state of the system represents a degradation level, E = { 1 , . . . , d} . State 1 indicates that the system is new and state d indicates the failure of the system. The system can only progress to a higher degradation level, not necessarily the following one.Let us consider a system that degrades with time. Every state of the system represents a degradation level, E = { 1 , . . . , d} . State 1 indicates that the system is new and state d indicates the failure of the system. The system can only progress to a higher degradation level, not necessarily the following one.</p>
        <p>The system is inspected at regular intervals to detect any problem and intervene if necessary. Two different maintenance policies are proposed for this system: the first one is based on the estimated probability that the system is visiting a certain subset of states at the n th inspection. The second one considers the observed signals assuming that when the signals associated to failure are observed, the system has failed.The system is inspected at regular intervals to detect any problem and intervene if necessary. Two different maintenance policies are proposed for this system: the first one is based on the estimated probability that the system is visiting a certain subset of states at the n th inspection. The second one considers the observed signals assuming that when the signals associated to failure are observed, the system has failed.</p>
        <p>The cost of the intervention depends on the degradation level reached by the system, being the corrective maintenance the most expensive one.The cost of the intervention depends on the degradation level reached by the system, being the corrective maintenance the most expensive one.</p>
        <p>In our first approach we consider preventive maintenance criteria based on critical states probability criterion (CSPC). Roughly speaking, a preventive maintenance action is carried out once the system enters a subset of operational states that are considered critical in some sense. To get a better picture of the situation let us illustrate it with the following example.In our first approach we consider preventive maintenance criteria based on critical states probability criterion (CSPC). Roughly speaking, a preventive maintenance action is carried out once the system enters a subset of operational states that are considered critical in some sense. To get a better picture of the situation let us illustrate it with the following example.</p>
        <p>Consider a system with two units that is working as long as at least one unit is operative (i.e. parallel structure). Let us assume that the two units are identical and the system evolution is modelled by a Markov chain with state space defined in terms of the number of down units, E = { 0 , 1 , 2 } ; the set of up states is U = { 0 , 1 } and the down-state set is then D = { 2 } . State 1 can be seen as critical in comparison with state 0. In general, we denote U = { 1 , 2 , . . . , r} , the set of up states and let us assume that U = U 1 ∪ U 2 where the set of up states can be split into two subsets such states in U 2 are critical to the system performance. Let us assume that card(U 2 ) = c, for a c &lt; r.Consider a system with two units that is working as long as at least one unit is operative (i.e. parallel structure). Let us assume that the two units are identical and the system evolution is modelled by a Markov chain with state space defined in terms of the number of down units, E = { 0 , 1 , 2 } ; the set of up states is U = { 0 , 1 } and the down-state set is then D = { 2 } . State 1 can be seen as critical in comparison with state 0. In general, we denote U = { 1 , 2 , . . . , r} , the set of up states and let us assume that U = U 1 ∪ U 2 where the set of up states can be split into two subsets such states in U 2 are critical to the system performance. Let us assume that card(U 2 ) = c, for a c &lt; r.</p>
        <p>JID: EOR [m5G;May 26, 2022;10:41 ] The preventive maintenance action is undertaken as soon as the subset U 2 is reached with pre-specified probability. More specifically, let us denote T c the first time the system hits subset U 2 directly from subset U 1 , that is, without visiting any state of subset D . The probability distribution of this time isJID: EOR [m5G;May 26, 2022;10:41 ] The preventive maintenance action is undertaken as soon as the subset U 2 is reached with pre-specified probability. More specifically, let us denote T c the first time the system hits subset U 2 directly from subset U 1 , that is, without visiting any state of subset D . The probability distribution of this time is</p>
        <p>for n ≥ 1 . As long as transitions from U 1 to D are allowed there are non-zero elements in sub-matrix P U 1 ,D , and then k ) , for all n = 1 , 2 . . . and letfor n ≥ 1 . As long as transitions from U 1 to D are allowed there are non-zero elements in sub-matrix P U 1 ,D , and then k ) , for all n = 1 , 2 . . . and let</p>
        <p>denote the corresponding distribution function. A preventive maintenance action is carried out at timedenote the corresponding distribution function. A preventive maintenance action is carried out at time</p>
        <p>with q a critical probability value, 0 &lt; q &lt; 1 ; that is, the quantile of order q of the distribution F * c . Once the action is finished, the system is restored to a noncritical state. Then, by the memoryless property, a new preventive maintenance action will be scheduled following the rule just defined. Note that with this rule we decide when to do the preventive action, but it is still to be decided how the system is maintained.with q a critical probability value, 0 &lt; q &lt; 1 ; that is, the quantile of order q of the distribution F * c . Once the action is finished, the system is restored to a noncritical state. Then, by the memoryless property, a new preventive maintenance action will be scheduled following the rule just defined. Note that with this rule we decide when to do the preventive action, but it is still to be decided how the system is maintained.</p>
        <p>As explained in Section 3 , the system performance is described not only in terms of the states of the set E, but also in terms of the set of observed signals, i.e. A = A 1 ∪ A 2 , where we distinguish between good signals A 1 , and bad signals A 2 . Then we can decide to undertake a preventive action as soon as a warning signal is observed. Notice that when a signal in the subset A 2 is emitted the system is in a failed state with probability 1.As explained in Section 3 , the system performance is described not only in terms of the states of the set E, but also in terms of the set of observed signals, i.e. A = A 1 ∪ A 2 , where we distinguish between good signals A 1 , and bad signals A 2 . Then we can decide to undertake a preventive action as soon as a warning signal is observed. Notice that when a signal in the subset A 2 is emitted the system is in a failed state with probability 1.</p>
        <p>Let as assume that the subset of good signals A 1 can in turn be split into two subsets such that A 1 = A 11 ∪ A 12 , being a w ∈ A 12 a signal that alerts of some non desirable behaviour in the system, that is, a w is a warning signal. Let us also define τ w the first time a warning signal is observed without having previously received a signal indicating the system failure, that is a signal of subset A 2 .Let as assume that the subset of good signals A 1 can in turn be split into two subsets such that A 1 = A 11 ∪ A 12 , being a w ∈ A 12 a signal that alerts of some non desirable behaviour in the system, that is, a w is a warning signal. Let us also define τ w the first time a warning signal is observed without having previously received a signal indicating the system failure, that is a signal of subset A 2 .</p>
        <p>In other words, τ w = n if and only if Y n ∈ A 12 and Y k ∈ A 11 for all k = 1 , 2 , . . . , n -1 . The system has only emitted good signals until time n , when an alert is detected for the first time. To obtain the distribution probability of τ w we can consider two different situations.In other words, τ w = n if and only if Y n ∈ A 12 and Y k ∈ A 11 for all k = 1 , 2 , . . . , n -1 . The system has only emitted good signals until time n , when an alert is detected for the first time. To obtain the distribution probability of τ w we can consider two different situations.</p>
        <p>Let A 1 l , for l = 1 , 2 the corresponding subset of signals, then it can be writtenLet A 1 l , for l = 1 , 2 the corresponding subset of signals, then it can be written</p>
        <p>Then, for a pre-specified probability q , we can decide to undertake preventive maintenance actions at timesThen, for a pre-specified probability q , we can decide to undertake preventive maintenance actions at times</p>
        <p>for n = 1 , 2 , . . . , and 0 &lt; q &lt; 1 , a critical probability value, and G * w represents the distribution function of the corresponding normalized distribution.for n = 1 , 2 , . . . , and 0 &lt; q &lt; 1 , a critical probability value, and G * w represents the distribution function of the corresponding normalized distribution.</p>
        <p>Let us consider again the state space E = { 1 , . . . , d} as a set of degradation states of the system in the sense that 1 indicates the system is new and d the failure of the system. As above, let us assume that U = U 1 ∪ U 2 , that is r = r 1 + r 2 &lt; d, with U 2 the subset of size r 2 containing the critical states of the system. D is the subset of failed states.Let us consider again the state space E = { 1 , . . . , d} as a set of degradation states of the system in the sense that 1 indicates the system is new and d the failure of the system. As above, let us assume that U = U 1 ∪ U 2 , that is r = r 1 + r 2 &lt; d, with U 2 the subset of size r 2 containing the critical states of the system. D is the subset of failed states.</p>
        <p>Here a maintenance cost depending on the state of the system as well as the observed signal is considered. A system failure is followed by a corrective maintenance action which involves a cost vector of C CM , of dimension dr. On the other hand, a preventive maintenance action is done at times N c (q ) given in ( 20) when the maintenance is carried out following rule CSPC (see Case 1 above), and at times N w (q ) given in ( 22) , when the maintenance is carried out following rule WSPC (as described in Case 2). The associated cost depends on the hidden state that is being visited at the moment of the inspection. We then define a vector of costs as follows. The cost is 0 for the states 1 to r 1 , and, on the other hand, for the critical states there is an associated PM cost given by c j with j = r 1 + 1 , . . . , r 1 + r 2 = r where c j 1 ≤ c j 2 , for j 1 &lt; j 2 . Let C PM = (0 r 1 , c r 1 +1 , . . . , c r ) be a column vector of dimension r with 0 r 1 , the first r 1 components equal to 0. Additionally, it is supposed that min C CM ≥ c r . For a probability q , a PM inspection is carried out at a particular time n only if N (q ) = n . Let C q, (n ) , the total cost associated with a potential maintenance action at a time n , with N = N c for PM based on CSPC; or N = N w in case PM is adopted according to WSPC. The expected cost at time n can be obtained asHere a maintenance cost depending on the state of the system as well as the observed signal is considered. A system failure is followed by a corrective maintenance action which involves a cost vector of C CM , of dimension dr. On the other hand, a preventive maintenance action is done at times N c (q ) given in ( 20) when the maintenance is carried out following rule CSPC (see Case 1 above), and at times N w (q ) given in ( 22) , when the maintenance is carried out following rule WSPC (as described in Case 2). The associated cost depends on the hidden state that is being visited at the moment of the inspection. We then define a vector of costs as follows. The cost is 0 for the states 1 to r 1 , and, on the other hand, for the critical states there is an associated PM cost given by c j with j = r 1 + 1 , . . . , r 1 + r 2 = r where c j 1 ≤ c j 2 , for j 1 &lt; j 2 . Let C PM = (0 r 1 , c r 1 +1 , . . . , c r ) be a column vector of dimension r with 0 r 1 , the first r 1 components equal to 0. Additionally, it is supposed that min C CM ≥ c r . For a probability q , a PM inspection is carried out at a particular time n only if N (q ) = n . Let C q, (n ) , the total cost associated with a potential maintenance action at a time n , with N = N c for PM based on CSPC; or N = N w in case PM is adopted according to WSPC. The expected cost at time n can be obtained as</p>
        <p>Let us assume that the system is allowed to operate for a prespecified period of time, that is N 0 . Each time a PM action is carried out, the system is returned to a functioning state in the subset U 1 chosen with a probability given by the vector α 1 , that is the initial law restricted to the elements of U 1 . After that, the conditions of the system are the same as they were at time 0, which means that the following state after PM is chosen according to the initial law, α and the following transitions are governed by the matrix P .Let us assume that the system is allowed to operate for a prespecified period of time, that is N 0 . Each time a PM action is carried out, the system is returned to a functioning state in the subset U 1 chosen with a probability given by the vector α 1 , that is the initial law restricted to the elements of U 1 . After that, the conditions of the system are the same as they were at time 0, which means that the following state after PM is chosen according to the initial law, α and the following transitions are governed by the matrix P .</p>
        <p>From that moment, new PM action will be carried out N times later. This behaviour continues until time N 0 is reached. The total number of PM actions developed is equal to n 0 , , where it can be written N 0 = n 0 , N + r 0 , . The total expected cost involved in the interval (0 , N 0 ] is thenFrom that moment, new PM action will be carried out N times later. This behaviour continues until time N 0 is reached. The total number of PM actions developed is equal to n 0 , , where it can be written N 0 = n 0 , N + r 0 , . The total expected cost involved in the interval (0 , N 0 ] is then</p>
        <p>JID: EOR [m5G;May 26, 2022;10:41 ] = n 0 ,JID: EOR [m5G;May 26, 2022;10:41 ] = n 0 ,</p>
        <p>where as before, the subscript indicates the type of PM maintenance, based on critical states or critical signals.where as before, the subscript indicates the type of PM maintenance, based on critical states or critical signals.</p>
        <p>Maintenance strategy based on observed signals can lead to assess the state of the system wrongly, and consequently an unnecessary maintenance cost will be involved. If an alarm signal is observed the system will be sent for repair. Maintenance crew will then assess the true system state that might not agree with the estimated one. There is a cost associated to it that should be minimized. This aspect of maintenance will be treated in a future research.Maintenance strategy based on observed signals can lead to assess the state of the system wrongly, and consequently an unnecessary maintenance cost will be involved. If an alarm signal is observed the system will be sent for repair. Maintenance crew will then assess the true system state that might not agree with the estimated one. There is a cost associated to it that should be minimized. This aspect of maintenance will be treated in a future research.</p>
        <p>Let us consider a system with d 0 identical units that operate independently. The system is operative while at least one unit is operative and fails as soon as all units are down. The state of the system (wear out level) is measured in terms of the number of units failed. After failure, the units are not repaired, and when there are no operative units, the system is replaced by a new identical one.Let us consider a system with d 0 identical units that operate independently. The system is operative while at least one unit is operative and fails as soon as all units are down. The state of the system (wear out level) is measured in terms of the number of units failed. After failure, the units are not repaired, and when there are no operative units, the system is replaced by a new identical one.</p>
        <p>Let us assume that the units are exponentially distributed with equal failure rate λ.Let us assume that the units are exponentially distributed with equal failure rate λ.</p>
        <p>Model description. Information on the system performance is collected periodically in such a way that only partial information is obtained regarding the system deterioration. More specifically, at regular instants of time one has access to some parameters or indicators ( signals ) related somehow to the level of wear out of the system. For simplicity, let us denote A = { 1 , 2 , . . . , s } , and consider that when signal a = 1 is emitted, it means that the system is operating in optimal conditions. On the opposite, an observation a = s indicates that a fatal failure has occurred in the system.Model description. Information on the system performance is collected periodically in such a way that only partial information is obtained regarding the system deterioration. More specifically, at regular instants of time one has access to some parameters or indicators ( signals ) related somehow to the level of wear out of the system. For simplicity, let us denote A = { 1 , 2 , . . . , s } , and consider that when signal a = 1 is emitted, it means that the system is operating in optimal conditions. On the opposite, an observation a = s indicates that a fatal failure has occurred in the system.</p>
        <p>At any moment, the true state of the systems is unobservable.At any moment, the true state of the systems is unobservable.</p>
        <p>The state space is represented by E = { 1 , 2 , . . . , d} , where i = 1 is the optimal functioning state, that is, the system is new with no unit failed. On the other hand, i = d means that all units are down and then the system is in the failure state, with d = d 0 + 1 . Let us denote X 0 , X 1 , . . . , X n the successive (unobserved) states of the system, taking values in the set E; and, Y 0 , Y 1 , . . . , Y n the successive observed indicators, which are assumed to range in the set A . We consider that inspections are carried out at times k = 0 , , 2 • , . . . . . . , for simplicity we take = 1 . At time k = 0 we assume that the system is new so that the initial state is X 0 = 1 and the transition probabilitiesThe state space is represented by E = { 1 , 2 , . . . , d} , where i = 1 is the optimal functioning state, that is, the system is new with no unit failed. On the other hand, i = d means that all units are down and then the system is in the failure state, with d = d 0 + 1 . Let us denote X 0 , X 1 , . . . , X n the successive (unobserved) states of the system, taking values in the set E; and, Y 0 , Y 1 , . . . , Y n the successive observed indicators, which are assumed to range in the set A . We consider that inspections are carried out at times k = 0 , , 2 • , . . . . . . , for simplicity we take = 1 . At time k = 0 we assume that the system is new so that the initial state is X 0 = 1 and the transition probabilities</p>
        <p>for and i ≤ j, and p i j = 0 for i &gt; j. Finally, p d, 1 = 1 . Successively, an output symbol is produced according to a probability distribution, which depends on the current state. This probability distribution is held fixed for the state regardless of when and how the state is entered. Specifically, for a given state of the system, i ∈ E, we denotefor and i ≤ j, and p i j = 0 for i &gt; j. Finally, p d, 1 = 1 . Successively, an output symbol is produced according to a probability distribution, which depends on the current state. This probability distribution is held fixed for the state regardless of when and how the state is entered. Specifically, for a given state of the system, i ∈ E, we denote</p>
        <p>We have that a ∈ A M(i, a ) = 1 , for all i ∈ E. Let M denote the matrix of dimension d × s , whose (i, a ) element is M(i, a ) , for all i ∈ E, and a ∈ A . In particular we have that M(1 , 1) = 1 , and M(d, s ) = 1 . In addition, it is quite realistic assumption that M(i, 1) = M(i, s ) = 0 for 1 &lt; i &lt; s . Rows 2 to d -1 of matrix M are taken as the corresponding probability distribution of a Binomial law with size s -2 and probability p i which is assumed to decrease with the value of i . Then we have that the signal emitted stochastically increases as the system deteriorates.We have that a ∈ A M(i, a ) = 1 , for all i ∈ E. Let M denote the matrix of dimension d × s , whose (i, a ) element is M(i, a ) , for all i ∈ E, and a ∈ A . In particular we have that M(1 , 1) = 1 , and M(d, s ) = 1 . In addition, it is quite realistic assumption that M(i, 1) = M(i, s ) = 0 for 1 &lt; i &lt; s . Rows 2 to d -1 of matrix M are taken as the corresponding probability distribution of a Binomial law with size s -2 and probability p i which is assumed to decrease with the value of i . Then we have that the signal emitted stochastically increases as the system deteriorates.</p>
        <p>Then the parameters to be estimated are θ := ( θ 1 , θ 2 ) , with θ 1 = λ and θ 2 = (M(i, a ) ; i = 2 , . . . , d -1 ; a = 1 , . . . , s -1) .Then the parameters to be estimated are θ := ( θ 1 , θ 2 ) , with θ 1 = λ and θ 2 = (M(i, a ) ; i = 2 , . . . , d -1 ; a = 1 , . . . , s -1) .</p>
        <p>Eq. ( 4) can be approximated asEq. ( 4) can be approximated as</p>
        <p>where all terms that do not depend on the unknown parameters have been omitted.where all terms that do not depend on the unknown parameters have been omitted.</p>
        <p>Using the EM algorithm, the maximization step M leads us to the followingUsing the EM algorithm, the maximization step M leads us to the following</p>
        <p>Changing the order of summation we getChanging the order of summation we get</p>
        <p>, where we have used that, where we have used that</p>
        <p>. On the other hand, M (m +1) (i, a ) as in Eq. ( 7) .. On the other hand, M (m +1) (i, a ) as in Eq. ( 7) .</p>
        <p>Using the forward-backward probabilities in Eq. ( 8) and the backward probabilities given in (9) , we calculate,Using the forward-backward probabilities in Eq. ( 8) and the backward probabilities given in (9) , we calculate,</p>
        <p>and,and,</p>
        <p>Numerical results . In this example we are specially interested in evaluating the role of the system size. Then we consider different specifications for the number of units included in the system, specifically we take d 0 = 3 , 5 , 10 . Besides, we consider λ = 0 . 1 .Numerical results . In this example we are specially interested in evaluating the role of the system size. Then we consider different specifications for the number of units included in the system, specifically we take d 0 = 3 , 5 , 10 . Besides, we consider λ = 0 . 1 .</p>
        <p>Figure 1 displays the true reliability functions corresponding to 3 systems with size: 3 ( solid line ), 5 ( dashed line ), 10 ( dotted line ), respectively.Figure 1 displays the true reliability functions corresponding to 3 systems with size: 3 ( solid line ), 5 ( dashed line ), 10 ( dotted line ), respectively.</p>
        <p>For each system we have simulated markovian sample paths of size n = 150 using the corresponding true model (α, P ) . Then, from the theoretical emission matrix M , a sample of simulated outputs has been obtained. To avoid wrong conclusions due to the randomness in the simulation process the experiment has been repeated a total of 500 times for each system. The estimation results are represented in Fig. 2 . The true reliability is given by the black curve.For each system we have simulated markovian sample paths of size n = 150 using the corresponding true model (α, P ) . Then, from the theoretical emission matrix M , a sample of simulated outputs has been obtained. To avoid wrong conclusions due to the randomness in the simulation process the experiment has been repeated a total of 500 times for each system. The estimation results are represented in Fig. 2 . The true reliability is given by the black curve.</p>
        <p>For averaging. That is, we consider the followingFor averaging. That is, we consider the following</p>
        <p>where R (r) is the estimated reliability function based on the rth sample, for r = 1 , . . . , 500 .where R (r) is the estimated reliability function based on the rth sample, for r = 1 , . . . , 500 .</p>
        <p>The red curve represents the average of the estimated curves along the 500 replications for each case d 0 = 3 , 5 , 10 (from left to right). As expected, the accuracy of the estimator decreases with the complexity of the system. The bias increases with the number of components. It is worth noticing that in an acceptable reliability level, i.e. [ 0 , 20 ] time interval, for all figures we have a good accuracy.The red curve represents the average of the estimated curves along the 500 replications for each case d 0 = 3 , 5 , 10 (from left to right). As expected, the accuracy of the estimator decreases with the complexity of the system. The bias increases with the number of components. It is worth noticing that in an acceptable reliability level, i.e. [ 0 , 20 ] time interval, for all figures we have a good accuracy.</p>
        <p>Let us consider a system that receives shocks with time. The state of the system varies in the set E = { 1 , 2 , . . . , d} , from perfect functioning represented by state 1 to complete failure represented by state d. Each time a shock occurs, the state of the system changes from the current state i to i + 1 with probability p or the system remains in the same state i with probability 1p, for i = 1 , 2 , . . . , d -1 . It is assumed that the system is designed such that it can only stand a maximum number of shocks after which it is replaced by a new and identical one. Equivalently when the system reaches level d it is restored to state 1 of perfect functioning. That is, the system is designed to stand a maximum number of chocks, i.e. d. In this case the hidden Markov chain is given by a random walk with state space E, with a reflecting barrier at d, whose probability transition matrix is given byLet us consider a system that receives shocks with time. The state of the system varies in the set E = { 1 , 2 , . . . , d} , from perfect functioning represented by state 1 to complete failure represented by state d. Each time a shock occurs, the state of the system changes from the current state i to i + 1 with probability p or the system remains in the same state i with probability 1p, for i = 1 , 2 , . . . , d -1 . It is assumed that the system is designed such that it can only stand a maximum number of shocks after which it is replaced by a new and identical one. Equivalently when the system reaches level d it is restored to state 1 of perfect functioning. That is, the system is designed to stand a maximum number of chocks, i.e. d. In this case the hidden Markov chain is given by a random walk with state space E, with a reflecting barrier at d, whose probability transition matrix is given by</p>
        <p>As in the previous case, we do not observe the true state of the system but an output symbol wich is produced depending on the current state with a particular probability distribution. Again, for a given state of the system, i ∈ E, we denoteAs in the previous case, we do not observe the true state of the system but an output symbol wich is produced depending on the current state with a particular probability distribution. Again, for a given state of the system, i ∈ E, we denote</p>
        <p>) , for any a ∈ A . Let M be a d × s -matrix whose (i, a ) element is M(i, a ) , for all i ∈ E, and a ∈ A . In this case we only assume that M(d, s ) = 1 and for rows 1 to d -1 we consider the corresponding probability distribution of a Binomial law with size s -1 and probability p i which is assumed to decrease with the value of i .) , for any a ∈ A . Let M be a d × s -matrix whose (i, a ) element is M(i, a ) , for all i ∈ E, and a ∈ A . In this case we only assume that M(d, s ) = 1 and for rows 1 to d -1 we consider the corresponding probability distribution of a Binomial law with size s -1 and probability p i which is assumed to decrease with the value of i .</p>
        <p>The parameters to be estimated are θ := ( θ 1 , θ 2 ) , with θ 1 = p and θ 2 = (M(i, a ) ; i = 2 , . . . , d -1 ; a = 1 , . . . , s -1) . Eq. ( 4) , can be written asThe parameters to be estimated are θ := ( θ 1 , θ 2 ) , with θ 1 = p and θ 2 = (M(i, a ) ; i = 2 , . . . , d -1 ; a = 1 , . . . , s -1) . Eq. ( 4) , can be written as</p>
        <p>Using the EM, the maximization step M leads us to the following expressionUsing the EM, the maximization step M leads us to the following expression</p>
        <p>Let us consider the following particular model: d = 10 ; s = 20 ; p = 0 . 6 . From this model we generate a total of 500 samples of size n = 150 and, as in the previous example, estimate for each case the reliability function. The estimation results are presented in Fig. 3 . The true reliability is given by the black curve. For each sample we have estimated the reliability function based on the HMM model. The solid red curve represents the average of the estimated curves along the 500 replications, the two dotted red lines represent the corresponding bootstrap confidence intervals at a confidence level of 95%, calculated at each estimation point, that is, n = 1 , 2 , . . . .Let us consider the following particular model: d = 10 ; s = 20 ; p = 0 . 6 . From this model we generate a total of 500 samples of size n = 150 and, as in the previous example, estimate for each case the reliability function. The estimation results are presented in Fig. 3 . The true reliability is given by the black curve. For each sample we have estimated the reliability function based on the HMM model. The solid red curve represents the average of the estimated curves along the 500 replications, the two dotted red lines represent the corresponding bootstrap confidence intervals at a confidence level of 95%, calculated at each estimation point, that is, n = 1 , 2 , . . . .</p>
        <p>Let us consider now a system with four possible levels of performance, that isLet us consider now a system with four possible levels of performance, that is</p>
        <p>..</p>
        <p>The consistency properties of the estimators can be numerically evaluated by noticing the significant reduction of the errors (increasing accuracy) as N increases.The consistency properties of the estimators can be numerically evaluated by noticing the significant reduction of the errors (increasing accuracy) as N increases.</p>
        <p>A graphical inspection element-by-element of the two matrices is given in Figs. 6 and 7 that display, respectively, summary statistics for the estimations of the matrices P and M . We have considered in each case samples of sizes N = 10 0 , 50 0 , 10 0 0 , 50 0 0 . Each boxplot on the graphs gives the results for each element of matrix P in Fig. 6 and matrix M in Fig. 7 . The red symbols inside the boxplots represent the true values. The blue symbols represent, for each probability value, the average of the estimated values. These averages have been obtained by considering 500 samples for each sample size. As expected the accuracy of the estimators increases with the sample size. The distance between the red and blue points inside the plots provides a graphical impression of the bias of the estimator for each element of the corresponding matrix, P and M . As can be seen even for small samples the bias is reasonable and it almost vanishes for the biggest samples. On the other hand, the number of parameters to be estimated is large in this case, 24 unknown parameters in total, and then the estimators show high variability for the smallest samples ( N = 100 ) especially in the case of the emission matrix. However, this variability shows a remarkable descending trend as the sample size increases, as it can be appreciated on the plots.A graphical inspection element-by-element of the two matrices is given in Figs. 6 and 7 that display, respectively, summary statistics for the estimations of the matrices P and M . We have considered in each case samples of sizes N = 10 0 , 50 0 , 10 0 0 , 50 0 0 . Each boxplot on the graphs gives the results for each element of matrix P in Fig. 6 and matrix M in Fig. 7 . The red symbols inside the boxplots represent the true values. The blue symbols represent, for each probability value, the average of the estimated values. These averages have been obtained by considering 500 samples for each sample size. As expected the accuracy of the estimators increases with the sample size. The distance between the red and blue points inside the plots provides a graphical impression of the bias of the estimator for each element of the corresponding matrix, P and M . As can be seen even for small samples the bias is reasonable and it almost vanishes for the biggest samples. On the other hand, the number of parameters to be estimated is large in this case, 24 unknown parameters in total, and then the estimators show high variability for the smallest samples ( N = 100 ) especially in the case of the emission matrix. However, this variability shows a remarkable descending trend as the sample size increases, as it can be appreciated on the plots.</p>
        <p>In this section we discuss the maintenance problem for the system in Example 1, that is, the deteriorating system. We consider in particular that d 0 = 5 , so the hidden chain has d = 6 states of which r = 5 are operative states. The subset of critical states is U 2 = { 4 , 5 } , so r 2 = 2 . With respect to the observations (signals), we consider that s = 7 is the total number of possible signals emitted by the system, with A 2 = { 4 , 5 , 6 } the set of warning signals among the set of good signals, that is, A = { 1 , 2 , 3 , 4 , 5 , 6 } . We assume that the system is allowed to be in operation for a maximum of N 0 = 50 transitions. Our aim is to calculate the expected cost considering two different PM strategies as explained in Section 4 . The vector of cost is defined as follows. C CM = 1 is the cost associated to a CM action. The vector of cost associated to PM maintenance is C PM = (0 , 0 , 0 , 0 . 5 , 0 . 75) . In Fig. 8 the solid line reports the results of the total cost that entails the operation of the system until time N 0 = 50 under CM and PM based on critical states for a range of values of the threshold probability q . The dashed line give the results of the cost generated by the system operating until N 0 = 50 under CM and PM based on critical signals. We can see that when the critical probability increases, the PM based on states get smaller values, while the opposite is true for the PM strategy based on signals.In this section we discuss the maintenance problem for the system in Example 1, that is, the deteriorating system. We consider in particular that d 0 = 5 , so the hidden chain has d = 6 states of which r = 5 are operative states. The subset of critical states is U 2 = { 4 , 5 } , so r 2 = 2 . With respect to the observations (signals), we consider that s = 7 is the total number of possible signals emitted by the system, with A 2 = { 4 , 5 , 6 } the set of warning signals among the set of good signals, that is, A = { 1 , 2 , 3 , 4 , 5 , 6 } . We assume that the system is allowed to be in operation for a maximum of N 0 = 50 transitions. Our aim is to calculate the expected cost considering two different PM strategies as explained in Section 4 . The vector of cost is defined as follows. C CM = 1 is the cost associated to a CM action. The vector of cost associated to PM maintenance is C PM = (0 , 0 , 0 , 0 . 5 , 0 . 75) . In Fig. 8 the solid line reports the results of the total cost that entails the operation of the system until time N 0 = 50 under CM and PM based on critical states for a range of values of the threshold probability q . The dashed line give the results of the cost generated by the system operating until N 0 = 50 under CM and PM based on critical signals. We can see that when the critical probability increases, the PM based on states get smaller values, while the opposite is true for the PM strategy based on signals.</p>
        <p>As illustrative example we consider the fatigue crack growth problem in a degradation mechanism analyzed in Chiquet, Limnios, &amp; Eid (2009) , where a piecewise deterministic Markov process is proposed for the degradation modelling. The data consist of an aluminum alloy specimen that was tested to investigate fatigue crack propagation. 1Starting from an initial crack of length 9 mm for a particular item in test, the number of cycles for the size of the crack to reach a predetermined value was recorded successively. That is, it is registered the number of cycles every time an increment of size 0 . 2 mm in length occurs. The experiment finishes once a critical size of the crack is reached, meaning the failure of the item. The data were first published in Virkler, Hillberry, &amp; Goel (1979) . The random factor here is the inhomogeneity in the material.As illustrative example we consider the fatigue crack growth problem in a degradation mechanism analyzed in Chiquet, Limnios, &amp; Eid (2009) , where a piecewise deterministic Markov process is proposed for the degradation modelling. The data consist of an aluminum alloy specimen that was tested to investigate fatigue crack propagation. 1Starting from an initial crack of length 9 mm for a particular item in test, the number of cycles for the size of the crack to reach a predetermined value was recorded successively. That is, it is registered the number of cycles every time an increment of size 0 . 2 mm in length occurs. The experiment finishes once a critical size of the crack is reached, meaning the failure of the item. The data were first published in Virkler, Hillberry, &amp; Goel (1979) . The random factor here is the inhomogeneity in the material.</p>
        <p>Fatigue crack growth in materials may exhibit high variability due to among other causes material inhomogeneity or environmental conditions and thus an HMM is a good model to explain such variability. Certain information on the state of the piece is recorded regularly in terms of the size of the crack, however full understanding of the real degradation also needs to account for random factors that are involved in the underlying process. So, the fatigue crack growth is assumed to fit into different regimes with different crack propagation rates. One can consider that these regimes are in a one-to-one correspondence with the actual deterioration states of the piece, so that a state transition of the hidden model means a regime-switching. The transition between regimes (states) may happen at an arbitrary random time.Fatigue crack growth in materials may exhibit high variability due to among other causes material inhomogeneity or environmental conditions and thus an HMM is a good model to explain such variability. Certain information on the state of the piece is recorded regularly in terms of the size of the crack, however full understanding of the real degradation also needs to account for random factors that are involved in the underlying process. So, the fatigue crack growth is assumed to fit into different regimes with different crack propagation rates. One can consider that these regimes are in a one-to-one correspondence with the actual deterioration states of the piece, so that a state transition of the hidden model means a regime-switching. The transition between regimes (states) may happen at an arbitrary random time.</p>
        <p>One item is followed until the size of the crack exceeds 49 . 8 mm , which occurs at time τ = 247251 (cycles of functioning) for the selected item. Assume that the piece is observed every 20 0 0 cycles and that the increment of the crack size between two consecutive inspections is recorded while the true state of the piece remains unobserved. Let us denote Y 1 , Y 2 , . . . , Y N the sequence of the crack increments observed in the item and X 1 , X 2 , . . . , X N , the corresponding sequence of hidden states. For simplicity the observation space is divided into four categories using the k -means clustering method. In Table 2 it is detailed the estimated 4-dimensional signal-space as well as the frequency corresponding to each value (see Chiquet et al., 2009 for a similar discussion).One item is followed until the size of the crack exceeds 49 . 8 mm , which occurs at time τ = 247251 (cycles of functioning) for the selected item. Assume that the piece is observed every 20 0 0 cycles and that the increment of the crack size between two consecutive inspections is recorded while the true state of the piece remains unobserved. Let us denote Y 1 , Y 2 , . . . , Y N the sequence of the crack increments observed in the item and X 1 , X 2 , . . . , X N , the corresponding sequence of hidden states. For simplicity the observation space is divided into four categories using the k -means clustering method. In Table 2 it is detailed the estimated 4-dimensional signal-space as well as the frequency corresponding to each value (see Chiquet et al., 2009 for a similar discussion).</p>
        <p>In an attempt to reveal the number of the actual degradations levels underlying the observations we study two possibilities. First, we distinguish only two internal (hidden) states, that is E = { 1 , 2 } .In an attempt to reveal the number of the actual degradations levels underlying the observations we study two possibilities. First, we distinguish only two internal (hidden) states, that is E = { 1 , 2 } .</p>
        <p>It is reasonable that initially the item is occupying its less degraded state, that is X 0 = 1 . The estimated transition matrix P 2 and emission matrix M 2 are given According to matrix M , the probability distribution of signals emitted from state 2 is the same as from state 3. In other words, actually the model with three states does not allow to distinguish different behaviours between these two latent states. Finally, to compare the fitted HMMs on the basis of the number of states, we use the Akaike's information criterion as done in Votsi et al. (2013) . The best model will be selected by means of the AIC, defined by AIC = -2 log L + 2(d(d -1) + d(m -1)) , where log L is the estimated maximum log-likelihood function. The results are presented in Table 3 , where it is shown that the 2-states HMM model fits better the data. This conclusion agrees with previous analyses of this dataset where it is argued that fatigue crack growth of this kind of material can be divided into two regimes with different crack propagation rates, see Abdessalema et al. (2012) .It is reasonable that initially the item is occupying its less degraded state, that is X 0 = 1 . The estimated transition matrix P 2 and emission matrix M 2 are given According to matrix M , the probability distribution of signals emitted from state 2 is the same as from state 3. In other words, actually the model with three states does not allow to distinguish different behaviours between these two latent states. Finally, to compare the fitted HMMs on the basis of the number of states, we use the Akaike's information criterion as done in Votsi et al. (2013) . The best model will be selected by means of the AIC, defined by AIC = -2 log L + 2(d(d -1) + d(m -1)) , where log L is the estimated maximum log-likelihood function. The results are presented in Table 3 , where it is shown that the 2-states HMM model fits better the data. This conclusion agrees with previous analyses of this dataset where it is argued that fatigue crack growth of this kind of material can be divided into two regimes with different crack propagation rates, see Abdessalema et al. (2012) .</p>
        <p>Using the fitted 2-dimensional HMM model we can define the reliability of the item in terms of up and down states as well as good and bad signals as explained in Section 3 . In our case the hidden state space is E = { 1 , 2 } and we can consider that 1 is denoting a good performance in the system while 2 refers to a bad functioning regime. Then, according to the previous notation we consider U = { 1 } and D = { 2 } . In the same way, the observed signals can be split into two categories. If a crack size growth is detected near 0 . 606 mm or more during a single interval of 20 0 0 cycles, then a danger situation is considered. So, we have A 1 = { 1 , 2 } and A 2 = { 3 , 4 } , using the notation of Section 3 . Then, we define the reliability of the piece in this terms as R (t) = P (X n t = 1 ; Y n t ∈ A 2 ) , for t &gt; 0 and n t = sup { n ∈ N : n ≤ t 20 0 0 } . The results are displayed in Fig. 9 .Using the fitted 2-dimensional HMM model we can define the reliability of the item in terms of up and down states as well as good and bad signals as explained in Section 3 . In our case the hidden state space is E = { 1 , 2 } and we can consider that 1 is denoting a good performance in the system while 2 refers to a bad functioning regime. Then, according to the previous notation we consider U = { 1 } and D = { 2 } . In the same way, the observed signals can be split into two categories. If a crack size growth is detected near 0 . 606 mm or more during a single interval of 20 0 0 cycles, then a danger situation is considered. So, we have A 1 = { 1 , 2 } and A 2 = { 3 , 4 } , using the notation of Section 3 . Then, we define the reliability of the piece in this terms as R (t) = P (X n t = 1 ; Y n t ∈ A 2 ) , for t &gt; 0 and n t = sup { n ∈ N : n ≤ t 20 0 0 } . The results are displayed in Fig. 9 .</p>
        <p>During the lifetime of most real complex systems, the real state of the system is unobservable most of the time, while indicators of this state, such as temperature, pressure, etc., are available via a control system. So, the real problem here is to be able to estimate the state of the system by considering those indicators.During the lifetime of most real complex systems, the real state of the system is unobservable most of the time, while indicators of this state, such as temperature, pressure, etc., are available via a control system. So, the real problem here is to be able to estimate the state of the system by considering those indicators.</p>
        <p>This paper aims to validate the approach of the HMM models in reliability engineering. As we have seen in this paper, a hidden model can provide the key information about the system dependability such as the failed component of the system, the reliability of the system and related measures. Our approach focuses on the introduction of a new concept of the system reliability function when the true system degradation is not directly observed. The reliability function is expressed not only in terms of the internal (unobserved) states of the system but also in terms of the observed signal that is recorded and is treated as an indicator of the degradation level of the system. We have constructed a maximumlikelihood estimator of the reliability function based on a sample of observations of signals and have derived its theoretical (asymptotic) properties.This paper aims to validate the approach of the HMM models in reliability engineering. As we have seen in this paper, a hidden model can provide the key information about the system dependability such as the failed component of the system, the reliability of the system and related measures. Our approach focuses on the introduction of a new concept of the system reliability function when the true system degradation is not directly observed. The reliability function is expressed not only in terms of the internal (unobserved) states of the system but also in terms of the observed signal that is recorded and is treated as an indicator of the degradation level of the system. We have constructed a maximumlikelihood estimator of the reliability function based on a sample of observations of signals and have derived its theoretical (asymptotic) properties.</p>
        <p>Maintenance is an important issue of system dependability. In this respect we have proposed for the first time in this context of missing information, two criteria for preventive maintenance. One is based on critical states probability criterion (CSPC) and the other in warning signals probability criterion (WSPC). We have studied the efficiency of these two criteria in terms of cost and we have illustrated our methodology through a simulation study where three systems of different nature have been analyzed.Maintenance is an important issue of system dependability. In this respect we have proposed for the first time in this context of missing information, two criteria for preventive maintenance. One is based on critical states probability criterion (CSPC) and the other in warning signals probability criterion (WSPC). We have studied the efficiency of these two criteria in terms of cost and we have illustrated our methodology through a simulation study where three systems of different nature have been analyzed.</p>
        <p>The present work can be extended to:The present work can be extended to:</p>
        <p>• Hidden Semi-Markov reliability models;• Hidden Semi-Markov reliability models;</p>
        <p>• Define and develop other approaches of maintenance;• Define and develop other approaches of maintenance;</p>
        <p>• Extend our study to the case of a continuous time follow-up of the system; • Extend our model to the semi-Markov case via Phase-type distributions.• Extend our study to the case of a continuous time follow-up of the system; • Extend our model to the semi-Markov case via Phase-type distributions.</p>
        <p>, (d, a, (d, a</p>
        <p>2 ) , . . . , (1 , a s ) , . . . , (d, a s ) } .2 ) , . . . , (1 , a s ) , . . . , (d, a s ) } .</p>
        <p>The matrix P consists then of s blocks of sub-matrices B 1 , . . . , B s , with dimension d × s d each. All blocks are identical, B j = B , for all j = 1 , . . . , s , and can be expressed asThe matrix P consists then of s blocks of sub-matrices B 1 , . . . , B s , with dimension d × s d each. All blocks are identical, B j = B , for all j = 1 , . . . , s , and can be expressed as</p>
        <p>European Journal of Operational Research xxx (xxxx) xxxEuropean Journal of Operational Research xxx (xxxx) xxx</p>
        <p>Although the original dataset contains a total of 68 trajectories, we have considered only one of them to develop this application example. There is no particular preference for the one utilized here and similar results would have been obtained had it been selected a different case of the dataset.Although the original dataset contains a total of 68 trajectories, we have considered only one of them to develop this application example. There is no particular preference for the one utilized here and similar results would have been obtained had it been selected a different case of the dataset.</p>
        <p>The authors are grateful to two anonymous reviewers and the Editor for many valuable comments and suggestions, which have helped to improve the quality of the article. The authors gratefully acknowledge support from the Spanish Ministry of Science and Innovation -State Research Agency through grant number PID2020-120217RB-I00. This work is supported in part by the IMAG Maria de Maeztu grant CEX2020-001105-M/AEI/10.13039/50110 0 011033. Funding for open access charge: Universidad de Granada / CBUA.The authors are grateful to two anonymous reviewers and the Editor for many valuable comments and suggestions, which have helped to improve the quality of the article. The authors gratefully acknowledge support from the Spanish Ministry of Science and Innovation -State Research Agency through grant number PID2020-120217RB-I00. This work is supported in part by the IMAG Maria de Maeztu grant CEX2020-001105-M/AEI/10.13039/50110 0 011033. Funding for open access charge: Universidad de Granada / CBUA.</p>
        <p>In this case we have simulated a total of 500 samples of size n = 150 each. The results are illustrated in Fig. 4 where also bootstrap confidence intervals have been added based on the empirical quantiles.In this case we have simulated a total of 500 samples of size n = 150 each. The results are illustrated in Fig. 4 where also bootstrap confidence intervals have been added based on the empirical quantiles.</p>
        <p>We use this example to check the asymptotic properties of the estimator of the reliability function. We have simulated samples of size N = 10 0 , 50 0 , 10 0 0 , 50 0 0 respectively. The plot in Fig. 5 shows [m5G;May 26, 2022;10:41 ]We use this example to check the asymptotic properties of the estimator of the reliability function. We have simulated samples of size N = 10 0 , 50 0 , 10 0 0 , 50 0 0 respectively. The plot in Fig. 5 shows [m5G;May 26, 2022;10:41 ]</p>
    </text>
</tei>
