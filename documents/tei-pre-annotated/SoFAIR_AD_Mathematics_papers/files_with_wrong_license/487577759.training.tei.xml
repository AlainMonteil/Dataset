<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T15:45+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>Deviations from Brownian motion leading to anomalous diffusion are ubiquitously found in transport dynamics, playing a crucial role in phenomena from quantum physics to life sciences. The detection and characterization of anomalous diffusion from the measurement of an individual trajectory are challenging tasks, which traditionally rely on calculating the mean squared displacement of the trajectory. However, this approach breaks down for cases of important practical interest, e.g., short or noisy trajectories, ensembles of heterogeneous trajectories, or non-ergodic processes. Recently, several new approaches have been proposed, mostly building on the ongoing machine-learning revolution. Aiming to perform an objective comparison of methods, we gathered the community and organized an open competition, the Anomalous Diffusion challenge (AnDi). Participating teams independently applied their own algorithms to a commonly-defined dataset including diverse conditions. Although no single method performed best across all scenarios, the results revealed clear differences between the various approaches, providing practical advice for users and a benchmark for developers.</p>
        <p>The random walk [1] is a mathematical model ubiquitously employed at all scales in a variety of scientific fields, including physics, chemistry, biology, ecology, * carlo.manzo@uvic.cat psychology, economics, sociology, and computer science (Fig. 1a) [2,3]. Random walks are characterized by an erratic change of an observable over time (e.g., position, temperature, or stock price, Fig. 1b). The archetypal example of a random walk is Brownian motion, which describes the movement of a microscopic particle in a fluid as a consequence of thermal forces [4].</p>
        <p>The space explored by random walkers over time is arXiv:2105.06766v1 [physics.data-an] 14 May 2021 commonly measured by the mean squared displacement (MSD), which grows linearly in time for Brownian walkers (MSD ∝ t) [4]. Deviations from such a linear behavior displaying an asymptotic power-law dependence (MSD ∝ t α ) have been observed in several fields and are generally referred to as anomalous diffusion [4]: subdiffusion for 0 &lt; α &lt; 1, and superdiffusion for α &gt; 1 (as particular cases, α = 0 corresponds to immobile trajectories, α = 1 to Brownian motion, and α = 2 to ballistic motion). The left panel in Fig. 1c shows some examples of MSDs for Brownian (black line), subdiffusive (blue line), and superdiffusive (red line) motion together with the corresponding trajectories in 2D. For example, anomalous diffusion occurs in the diffusion of lipids and receptors in the cell membrane [5], in the transport of molecules within the cytosol [6] and the nucleus [7], in the foraging and mating strategies of animals [8], in sleepwake transitions during sleep [9], and in the fluctuations of the stock market [10].</p>
        <p>The recurrent observation of anomalous diffusion has driven an important theoretical effort to understand and mathematically describe its underlying mechanisms. This effort has provided a palette of microscopic models characterized by different spatial (step length) and temporal (step duration) random distributions, both with and without long-range correlations [4]. Important models for the interpretation of experimental results are continuous-time random walk (CTRW) [11], fractional Brownian motion (FBM) [12], Lévy walk (LW) [13], annealed transient time motion (ATTM) [14], and scaled Brownian motion (SBM) [15] (some sample trajectories are shown in the central panel of Fig. 1c, see Methods, "Theoretical models").</p>
        <p>In typical experiments aimed at understanding diffusion, the available data consists of trajectories of a tracer, such as a molecule in a cell, a stock price in the stock market, a foraging animal in its environment. The aim is to extract from these trajectories information about properties of the tracer and of the medium where its motion takes place, namely to infer the anomalous diffusion exponent α, to determine the underlying diffusion model and, finally, to determine whether these properties change over time and space.</p>
        <p>The first crucial step to characterize the tracer's motion is the determination of the anomalous diffusion exponent α (Task 1, Fig. 1c). It is typically estimated by fitting the MSD to a power law [16]. Traditionally, the MSD is defined as the ensemble average over a group of tracers (EA-MSD, Methods, Eq. ( 1)), in analogy to the solution to Fick's second law for the spreading of a bunch of particles in a homogeneous medium [4]. When long tracks are available, the MSD can be instead obtained as a time average from the trajectory of a single tracer (TA-MSD, Methods, Eq. ( 2)). While seemingly a straightforward procedure, determining α from the MSD can introduce significant errors and biases: i) the accuracy of the estimation depends on fluctuations, which can only be reduced by increasing the number of trac-ers (for EA-MSD) or the length of the trajectory (for TA-MSD), which is often not possible because of practical constraints; ii) the value of α is biased by noise, such as the localization precision of experimental trajectories [17], which needs to be estimated independently to introduce a proper correction [16,18]; iii) while for a stationary motion in a homogeneous medium, EA-MSD and TA-MSD have the same α, several systems are intrinsically heterogeneous and non-stationary [19,20], which can lead to non-ergodicity (i.e., the non-equivalence of time and ensemble averages) and thus invalidate the use of TA-MSD to determine the exponent.</p>
        <p>The second critical issue is to determine the underlying diffusion model (Task 2, Fig. 1c), which is related to its driving physical mechanism. Here, difficulties arise because the calculation of the MSD is not very informative, since different models provide curves with the same scaling exponent. Other statistical parameters have been proposed for this task and algorithms based on the combination of several estimators allow to distinguish between pairs of models [21-24], but there is no general consensus on how to unambiguously determine the underlying diffusion model from a trajectory.</p>
        <p>The third issue is to determine whether the properties of the motion of a given tracer change over time [6,20,25, 26] (Task 3, Fig. 1c). This can be both the result of heterogeneity in the environment (e.g., patches with different viscosity on a cellular membrane) or of timevarying properties of the tracer (e.g., different activation states of a molecular motor). In these cases, the determination of α and of the underlying diffusion model must be combined with a segmentation of the trajectory to identify fragments with homogeneous characteristics. Several methods have been proposed for the segmentation of time traces [27], mostly based on changes in diffusion constant, velocity, or diffusion mode (e.g., immobile, random, directed) [28][29][30][31]. Only recently, attempts have been made to determine changepoints with respect to a switch in α [25, 32,33] and diffusion model [34]. Until now, a systematic assessment of changepoint detection methods for anomalous diffusion has not been performed.</p>
        <p>In recent years, advances in fluorescence techniques have greatly increased the availability of high-precision trajectories of single molecules in living systems [35], producing an increasing drive to develop methods for quantifying anomalous diffusion [16,25,32,[36][37][38][39]. Furthermore, the recent blossoming of machine learning has promoted the accessibility of new powerful tools for data analysis [40] and further widened the palette of available methods [33,[41][42][43]. Some of the novel approaches have already delivered new insights into anomalous diffusion in different scenarios [44][45][46].</p>
        <p>This recent increase of available methods performing similar tasks requires an objective assessment on a common reference dataset to define the state of the art and guide end users in the optimal choice of characterization tools for each specific application. To assess the performance in quantifying anomalous diffusion, we have therefore run an open competition, the Anomalous Diffusion (AnDi) Challenge, divided in three different tasks: anomalous exponent inference, model classification, and trajectory segmentation, each for 1D, 2D, and 3D trajectories. The performance of submitted methods (Supplementary Note 1) was assessed with common metrics on simulated datasets with trajectory length and signal-tonoise level reproducing realistic experimental conditions (Methods, "Structure of the datasets"). The submitted methods were also compared on the blind analysis of experimental trajectories (Supplementary Note 2).</p>
        <p>The challenge consisted of three tasks: Task 1 (T1)inference of the anomalous diffusion exponent α; Task 2 (T2) -classification of the underlying diffusion model; Task 3 (T3) -trajectory segmentation (Fig. 1c and Methods, "Organization of the challenge"). The aim of the last task was to identify the changepoint within a trajectory switching α and diffusion model, as well as to determine the exponent and model for the identified segments. Each task was further divided into three subtasks corresponding to the trajectory dimensions (1D, 2D, and 3D, Fig. 1b), totaling 9 independent subtasks. Participants could choose to submit predictions for any combination of subtasks. We received submissions from 13 teams for T1, 14 teams for T2, and 4 teams for T3. Information about methods used by participating teams can be found in Supplementary Note 1.</p>
        <p>Details of the datasets generation are provided in Methods ("Structure of the datasets" and "Theoretical models"). The challenge datasets contained 10 4 trajectories of variable length simulated according to five anomalous diffusion models, both ergodic and nonergodic (Fig. 1c): ATTM (weakly non-ergodic), a motion with random changes of diffusion coefficient in time [14]; CTRW (weakly non-ergodic), a motion undergoing local trapping with a wide distribution of waiting times [11]; FBM (ergodic), a motion with longrange correlated steps, often used to describe viscoelastic effects [12]; LW (ultra-weakly non-ergodic), a motion displaying irregular jumps with constant velocity, often associated with animal foraging strategies [13]; and SBM (weakly non-ergodic), a motion whose diffusion coefficient features deterministic time-dependent changes [15]. Trajectories were simulated with random anomalous diffusion exponents corresponding to subdiffusive (0 &lt; α &lt; 1, all models except LW), Brownian (α = 1, all models), or superdiffusive behavior (1 &lt; α ≤ 2, all models except CTRW and ATTM). To mimic the localization precision of experiments, trajectories were corrupted with Gaussian noise corresponding to three different levels of signal-to-noise-ratio (SNR). An open-source Python 
            <rs type="software">package</rs> (
            <rs type="url">https://github.com/ AnDiChallenge/ANDI_datasets</rs>) was developed to generate the data. Examples of trajectories for various exponents and models are presented in Fig. 1c.
        </p>
        <p>We primarily assessed method performance using these key metrics:</p>
        <p>• Mean absolute error (MAE) between predicted α p and the ground truth exponent α GT for T1 and T3.</p>
        <p>• F 1 -score (micro-averaged) to measure the classification performance among the diffusion models for T2 and T3.</p>
        <p>• Root mean-squared localization error (RMSE) between predicted changepoint position and the ground truth for T3.</p>
        <p>The mean reciprocal rank was used to combine the metrics for T3 into a unique value. Other metrics, such as recall, RMSE in true positive position pairs (RMSE TP ), receiver operating characteristic (ROC) curve, and area under the curve (AUC) were used to obtain further insight. Details are provided in Methods, "Metrics". We further built an interactive tool (http: //andi-challenge.org/interactive-tool/) for comparing method performance (Fig. S1). This application also provides a useful tool for developers to benchmark new methods.</p>
        <p>We could distinguish fifteen substantially different approaches (Table I and Supplementary Note 1). A large majority of them are based on machine-learning architectures, such as recurrent neural networks (RNN), convolutional neural networks (CNN), gradient boosting machines, graph neural networks, extreme learning machine (ELM), or sequence learners. Other methods are based on statistical approaches, such as Bayesian inference, temporal scaling, and random interval spectral ensemble (RISE). Some methods employed feature engineering using classical statistics as an input for machine learning. We thus grouped the approaches in three classes: 1) machine learning over raw trajectories; 2) machine learning over statistical features; 3) classical statistics. Furthermore, methods that required a specific training or model for different (ranges of) trajectory lengths were classified as length-specific. Several methods could be directly used or easily adapted to run multiple tasks.</p>
        <p>We investigated the performance of the methods submitted for each task separately. A summary of rankings for all tasks and methods is presented in Fig. S2. Full rankings for T1 and T2 in all dimensions are presented in Fig. 2a-c and Fig. 3a-c, respectively, together with representative information for the best-in-class methods for the 1D case (Fig. 2d-g and Fig. 3d-g, respectively). The same analysis is presented in Figs. S3 and S4 for higher dimensions. Results for T3 in 1D are shown in Fig. 4a-c, together with representative information for the best-inclass methods (Fig. 4e-f). Results for all dimensions are presented in Fig. 4d and Fig. S5.</p>
        <p>The inference of the exponent α is the most popular way to quantify anomalous diffusion and 13 teams participated in T1 of the AnDi Challenge (Fig. 2a-c). We observed a rather large spread of performances, but for each dimension we could identify a cluster of four top methods with comparable performance, scoring better than the rest. Three methods (E, G, and L) were consistently part of the top group in all dimensions. All top teams used machine-learning approaches: teams E, G, J, and M applied them to raw or simply pre-processed trajectories; teams F and L used statistical features as inputs. All these methods, except L and J, were based on a length-specific training.</p>
        <p>Besides the overall MAE, Fig. 2a-c also shows the performance obtained for specific diffusion models (colors within bars) by all participating teams. In Fig. 2d-g, the methods are compared with the simple fitting of the TA-MSD, used as a baseline method (Methods, "Alternative and baseline estimators"). Most methods perform better than TA-MSD. As expected, the fit of the TA-MSD shows better performance on ergodic (FBM) and ultraweakly non-ergodic (LW) rather than on (weakly) nonergodic models (CTRW, ATTM, and SBM), for which TA-MSD and EA-MSD have different exponents (Fig. 2d and Fig. S6). Interestingly, the top performing methods do not suffer from this limitation and provide similar MAE for all the models, with exception of the ATTM (short ATTM trajectories might not undergo any change of diffusion coefficient and, therefore, result indistinguishable from pure Brownian motion, impacting the final performance). As an example, in Fig. 2e, we show a 2D histogram of the predicted exponent vs the ground truth for the best-in-class method (team M) and the TA-MSD (upper inset) in 1D. As most of the top-scoring methods (Fig. S7, Fig. S8, and Fig. S9), the best-in-class method achieves similar performance over the whole range of α, whereas TA-MSD has a lower accuracy for α 0.5 to 1. In addition, the method of team M (similarly to other top methods, (Figs. S14, S15, and S16)) does not show any bias, whereas the TA-MSD systematically underes-timates the value of α as a consequence of localization error [16,18] (Fig. 2e, lower inset).</p>
        <p>In Fig. 2f, we explore the effect of the trajectory length on the exponent prediction. As the trajectory length increases, the MAE rapidly decreases toward a value ∼ 0.1 for the best performing methods. Thus, the MAE of machine-learning approaches features a striking improvement with respect to the nearly constant MAE of the TA-MSD, demonstrating the capability of machine learning to take advantage of the information contained in longer trajectories.</p>
        <p>Last, we investigated the effect of the level of noise (Fig. 2g). Even for SNR= 1, i.e., when the standard deviation of the noise has the same amplitude as the displacement standard deviation, the top-performing methods show a greater than 2-fold improvement in predicting α with respect to TA-MSD. Thus, while localization noise delays convergence of TA-MSD to its asymptotic behavior [16], the top methods seem able to determine patterns associated to the correct exponent even from short-time behaviors, which is an ability particularly useful for many potential applications to the analysis of experimental data.</p>
        <p>We present the performance of the submitted methods to classify trajectories between the 5 diffusion models in Figs. 3 andS4. For this task, method performance varied more smoothly making it harder to identify a cluster of best-performing teams (Fig. 3a-c). For each dimension, we identified 2 top teams that achieved rather similar scores. These top positions were occupied by three teams with machine-learning methods operating on raw trajectories (teams E and M) or features (team L). In general, the use of features as input to machine learning models seems to provide better results as the trajectory dimension increases.</p>
        <p>We also dissected the results as a function of the exponent α, as shown in Fig. 3a-c (colors within the bars), and in more detail in Fig. 3d for 1D, and in Fig. S10 for all dimensions. For all methods, the worst performance is achieved for α 1. This is expected because in this regime all models converge to pure Brownian motion and thus feature large similarity in their long-time statistical properties, even though their microscopic generative dynamics are different. A similar situation occurs for α → 0, a regime in which, independently of the underlying model, trajectories are nearly immobile and dominated by localization noise. Still, most of the methods show good predictive capability (F 1 0.7) even in these two regimes, since they probably learn to recognize details or patterns of the microscopic dynamics. The confusion matrix of the best-in-class method (team E) for the 1D subtask (Fig. 3e) provides a representative view of the classification capabilities of these methods. Results obtained by other methods are shown in Fig. S11, Fig. S12, and Fig. S13. The best accuracy is obtained for CTRW and LW, for which the method of team E is able to identify their markedly different features. However, it shows a higher level of error when discriminating between Gaussian processes, such as FBM and SBM [39]. The worst performance is obtained for ATTM, whose trajectories display a large heterogeneity in diffusion coefficients and lack a characteristic timescale. Rather long trajectories (including at least a switch of diffusivity) are thus necessary to distinguish ATTM from the other models.</p>
        <p>Similarly to what we observed for T1, the trajectory length and the presence of localization noise affect the performance of the methods, as shown in Figs. 3f and3g, respectively. Nevertheless, even for very short and noisy trajectories, the results obtained by the top methods display excellent accuracy (F 1 ∼ 0.6 to 0.8), taking into account that the largest noise level severely hides the actual diffusive dynamics. Recently, several experimental studies have evidenced the occurrence of switching of diffusion model and α within individual trajectories [6,25]. However, methods to determine and analyze such changes are not established and widely employed yet. Probably for this reason, the participation to T3 was reduced as compared to T1 and T2, with two teams proposing machine-learning methods (RNNs for team E and CNN for team J), and team B using Bayesian inference.</p>
        <p>The main objective of T3 is the precise assessment of the changepoint between two diffusive regimes, characterized by different diffusion models and anomalous diffusion exponents. As shown in Fig. 4a, participants to this task achieved RMSE well below the one obtained from random predictions. The RMSE is heavily affected by the position of the changepoint, being minimum for changepoints located near the center of the trajectory. As described earlier, the performance for predictions of α and the diffusion model strongly depends on the trajectory length. In this task, they are thus correlated to the changepoint position, which sets the segment length. Therefore, the larger (smaller) the distance of the changepoint from the origin, the better (worse) the prediction for the first segment is and the worse (better) that for the second segment (Fig. 4b-c).</p>
        <p>Fig. 4a-c show that it is challenging to estimate the changepoint when it is located very close to the trajectory start/end points. To gain further insight into methods' performance, we analyzed predictions when considering trajectories with a changepoint within 10 points from the start/end as not having a changepoint. The plot of the recall vs the RMSE TP (Fig. 4d) shows that all submitted methods detect more than the 95% of the inner changepoints with a higher precision with respect to the average of Fig. 4a.</p>
        <p>The difference between α-exponents (Fig. 4e) and the combination of diffusion models (Fig. 4f) of the two segments also affect the changepoint localization precision. Unsurprisingly, the RMSE is minimal when there is a change between directed or ballistic motion (α 1.5) and a nearly immobile motion (α 0.5) (Fig 4e). The worst case scenario is instead observed when near-Brownian diffusion (0.5 α 1.5) switches to subdiffusion (0.5 α 1.0) (Fig 4e). Besides these observations, no clear pattern emerges. This dependence is related in a nontrivial fashion to the change in RMSE observed as a function of diffusion models (Fig. 4f). In fact, while FBM and SBM allow Brownian, sub-and superdiffusion, CTRW and ATTM do not allow superdiffusion, and LW does not allow subdiffusion. The smallest RMSE is observed when LW switches to CTRW or FBM, but even in this case it is difficult to pinpoint a clear pattern.</p>
        <p>The datasets provided to the participants for the scoring of the methods participating in T1 and T2 also included experimental trajectories of mRNA molecules in bacterial cells, telomeres in the cell nucleus, proteins in the cell membrane and cytoplasm, single atoms in an optical trap, and tracer particles in cell cytoplasm and stirring liquid, from previously published works. For these trajectories, no objective ground truth is available besides the interpretation given in the literature. Therefore, it is not possible to assess their absolute errors and they were not included in the scoring. However, we found it interesting to carry out a comparative analysis of the predictions blindly provided by the 5 top-scoring challenge participants in each task. Out of the whole dataset, we discuss the results for 4 representative experiments [20,38,[47][48][49] for the inference of α (Fig. 5a-d) and the classification of the underlying model (Fig. 5e-h). The results obtained by all methods are shown in Figs. S21 -S28.</p>
        <p>The first dataset includes trajectories of mRNA molecules inside live E. coli cells from the work by Golding and Cox [47] (Fig. 5a). Together with Ref. [50], these data provide one of the first evidences of subdiffusion in cellular systems. These experiments have generated a lively discussion about their underlying diffusion model (mainly between FBM and CTRW) and ergodicity [21, [51][52][53]. All top-ranking methods provided distributions of exponents centered (median between 0.75 and 0.81) around the value estimated in the original publication (α = 0.77) with variable width (st. dev. between 0.04 and 0.18) (Fig. 5e). However, the methods agreed in classifying the large majority (between 74% and 100%) of trajectories as ATTM (Fig. 5i). This classification confirms the occurrence of ergodicity breaking, since both CTRW and ATTM are compatible with non-ergodic behavior and both have power-law waiting-time distribution. The preference toward ATTM might arise because of its varying diffusivity that better accounts for heterogeneity due to the biological environment or to variable noise.</p>
        <p>The second dataset of experiments includes trajectories of telomeres in the nucleus of mammalian cells [38,48] (Fig. 5b). It was previously shown that their TA-MSD features a FBM-like subdiffusive scaling for short and intermediate times with a mean exponent α ∼ 0.5, approaching a linear behavior (α ∼ 1.0) at longer timescales [48]. Also in this case, the classification methods largely agree and associate most of the trajectories to FBM (between 65% and 85%) (Fig. 5j). However, the determination of the exponent often produces a bimodal distribution with median values between 0.61 and 0.75 (Fig. 5f). Likely, the methods are not able to pick up the crossovers between diffusion regimes and rather assign an average exponent to each trajectory. The analysis of these experiments deserves further methodological effort, since heterogeneous diffusion is emerging as a key feature of random motion in the biological environment [54].</p>
        <p>The third dataset consists of trajectories recorded for receptors diffusing in the plasma membrane of mammalian cells (Fig. 5c). In the original work [20], the TA-MSD was found to scale roughly linearly, whereas the EA-MSD showed subdiffusion with α ∼ 0.84; this nonergodicity was attributed to a temporal change of diffusivity and associated to ATTM. Once more, the classification methods largely confirmed previous results. A large percent of trajectories were attributed to the two models with time-dependent diffusion coefficient, namely the ATTM (between 57% and 71%) and the SBM (between 22% and 33%) (Fig. 5k). Moreover, inference methods consistently detected a large heterogeneity in α, including both sub-and superdiffusion, with a slightly subdiffusive overall value, median between 0.86 and 0.95 (Fig. 5g), in agreement to the original study [20].</p>
        <p>To demonstrate the applicability of these methods beyond biological systems and at different spatio-temporal scales, we included a dataset with trajectories obtained for single atoms moving in a 1D periodic potential and interacting with a near-resonant light field that acts as a thermal bath [49] (Fig. 5d). These data were originally [49] interpreted as evidence of CTRW with α = 1. Because of the intrinsic complexity of this experiment, the trajectories were extremely short (∼ 10 datapoints), a regime where all the methods showed rather large uncertainties. The top regression methods for such short trajectories in 1D provided distributions spread over a wide range of α with medians between 0.8 and 0.91 (Fig. 5h). The results of model classification were also more balanced with respect to the previous cases, likely a consequence of having short trajectories with α 1, a regime where detectable differences among models are reduced. Still, the CTRW was the most-likely model for 4 of the 5 top-scoring methods (between 28% and 48%, Fig. 5l), thanks to the capability of these methods to extract information from the microscopic dynamics of the generative models and not only from the long-term properties of the trajectory and its MSD.</p>
        <p>The results of the 
            <rs type="software">AnDi Challenge</rs> (T1) show that the choice of the analysis method strongly affects the accuracy in the determination of the anomalous diffusion exponent α, in particular for more challenging conditions. Most of the methods outperform the conventional TA-MSD, even for long trajectories. For each dimension, we could identify a group of methods with comparable performance that greatly improve the precision of the anomalous diffusion exponent with respect to the baseline provided by the classical estimation of the MSD. Two aspects seem to contribute the most to boost the overall performance: the ability to provide precise and unbiased prediction for short and noisy trajectories; and the ability to extract the anomalous diffusion exponent (an intrinsic ensemble property) from single trajectories for non-ergodic models. The former represents a major improvement for trajectory analysis, since it enables collecting information from short and noisy tracks (e.g., those obtained by SPT PALM [55]) and from time segments of trajectories exhibiting heterogeneous behavior, without further averaging. The latter aspect suggests that the top-performing methods are capable of determining model properties usually obtained from ensemble averages or feature distributions from patterns present in single trajectories. It is quite remarkable that this is possible even in the presence of noise that is known to hide nonergodic behavior in some classical estimators [56] or with short trajectories that limit obtaining sufficient statistics for features such as the waiting-time distribution. This is a major limitation for approaches based on classical statistics (e.g., Bayesian inference) with models having several hidden variables that need to be systematically integrated. The availability of reliable methods to infer α will encourage researchers to further investigate the deviations from Brownian behavior that emerge in many experiments of interest, e.g., for biology and physics.
        </p>
        <p>The AnDi challenge (T2) has led to the first concerted effort to develop methods able to classify individual trajectories among several mathematical models of diffusion. Machine-learning methods ranked top in the leader board and achieved an overall accuracy greater than 80% at detecting the ground-truth diffusion models. The comparison of F 1 -score and AUC/ROC (Figs. S17, S18, S19, and S20) shows that most of the methods are quite confident at providing the correct classification. However, a limitation of all these classification approaches is that they can only choose among the diffusion models provided in the training. To robustly extend model classification to actual experiments, it can be useful to include a noneof-the-above class and/or to include some metric of the confidence of the estimation (e.g., by using an entropy measure calculated on the predictions of an ensemble of machine-learning models).</p>
        <p>Trajectory segmentation (T3 of the AnDi challenge) has been widely investigated when changes occur with respect to an estimator of the observable such as the mean or the variance [27]. Determining changes of anomalous diffusion is a rather novel problem, triggered by recent experimental findings [6,25]. We kept the challenge design rather simple, with trajectories of fixed length featuring exactly one changepoint. Even in this simple condition, the wide parameter space made the problem rather challenging, limiting the participation to T3 to only 4 teams. Yet, the submitted results showed an interesting asymmetry between performance obtained for the two segments (Fig. 4a-c). We believe that this is at least partly a consequence of the inaccurate detection of the changepoint and the non-stationarity of some models. The inexact localization of the changepoint produces two spurious segments, altering the tail of the first segment and the initial point of the second by removing or adding spurious points. For non-stationary models, the initial point encloses information about the initiation of the physical process, thus improper segmentation impacts more severely the evaluation of the second segment [57].</p>
        <p>From the blind analysis of various experimental datasets, we observed that the top methods, although based on different principles, lead to very similar results. This is encouraging as it points to an objective underlying reality of the anomalous diffusion phenomena and its mechanisms, which can be measured experimentally and has now been underpinned by the results of the AnDi challenge. Importantly, the results provided by the challenge methods were also in line with the conclusions of previous studies [20,38,[47][48][49], further reinforcing their reliability. Interestingly, while the original works required a combination of several estimators, including ensemble averages, the challenge methods were able to provide compatible predictions in a one-shot analysis and with no prior knowledge about the experimental conditions. This is a particularly remarkable result, since the methods were not specifically trained to work with parameters used in experiments. In fact, experimental trajectories often show broad distributions of diffusion coefficients. In spite of a fixed localization error, this produces a non-uniform SNR with respect to our simulations. Also, experiments have different sampling rates with respect to the characteristic diffusion timescale. Accounting for the variability introduced by these effects during the training might improve the methods' prediction capability, further boosting their performance.</p>
        <p>The number of experiments producing individual random trajectories is steadily increasing, accompanied by the production of ad hoc analysis tools. The AnDi challenge gave the opportunity to obtain a first assessment of some of these tools, oriented at detecting anomalous diffusion. In particular, we focused on methods quantifying deviation from pure Brownian behavior in terms of anomalous diffusion exponent and the underlying mathematical model. However, similar experiments are often analyzed following a more phenomenological approach, e.g., the classification of motion as diffusive, immobile, confined, or directed. Although the latter classification offers a more intuitive interpretation of random motion occurring in some systems, the models included in the challenge are strictly connected to these diffusion modalities. In fact, they allow a generalization of anomalous diffusion beyond the life sciences and include macroscopic natural and human processes, ranging from the foraging of animals to the spread of diseases, to trends in financial markets and climate records.</p>
        <p>Building on these considerations, we believe it is necessary to establish clear and unified guidelines to identify and report anomalous diffusion, in particular from experiments, where the ground truth is not known. Possibilities in this sense might involve a list of key parameters to be quantified together with their respective confidence interval, e.g., based on the comparative use of multiple methods, involving both machine learning and classical statistics. The joint approach will allow to combine advantages from both worlds: while machine learning methods are becoming more available and powerful, they often operate as a black box; estimators based on classical statistics can thus help to provide deep insight on anomalous diffusion phenomena.</p>
        <p>The AnDi challenge gathered a large part of the community to trigger this discussion and collaborate on this unifying task. We hope this effort might be extended in the future to reach a larger consensus. To this aim, we have built an interactive tool (http://andi-challenge. org/interactive-tool/) where datasets and results of the challenge are stored; new methods can undergo an automated benchmarking according to the challenge rules and compare their scores with those of other participants. Therefore, the challenge is permanently open and performance improvements are continuously updated. d). e-h, Histograms of the estimation of the anomalous diffusion exponent αp predicted by top teams for trajectories from experimental datasets. Gray areas correspond to the results of baseline method TA-MSD. Dashed lines indicate the original estimations of α provided by Refs. [47] (e), [38,48] (f ), [20] (g), and [49] (h). i-l, Histograms of the diffusion model predicted by top teams for trajectories from experimental datasets. Dashed boxes indicate the original classifications provided by Refs. [47] (i), [38,48] (j), [20] (k), and [49] (l). We show predictions obtained by the top 5 teams for the corresponding subtask. For the last dataset, we further selected the teams based on their performance on short (L ∼ 10) trajectories. All results for the analysis of the experimental data are presented in Suppl. Figs. S21-S28.</p>
        <p>We ran the Anomalous Diffusion (AnDi) challenge as a time-limited competition from March 1, 2020, to November 1, 2020. The competition was hosted on the Codalab platform (https://competitions.codalab. org/competitions/23601) and divided in three phases (Development, Validation, and Challenge). The competition has later been converted to an open challenge, continuously accepting new submissions. Datasets, methods, list of participants, and results of the AnDi Challenge are available at 
            <rs type="url">http://andi-challenge.org</rs>. Software for simulation and analysis is hosted on the competition GitHub repository 
            <rs type="url">https://github.com/AnDiChallenge</rs>.
        </p>
        <p>Simulated datasets were composed of synthetic trajectories generated according to five different mathematical models: annealed transient time motion (ATTM) [14], continuous-time random walk (CTRW) [11], fractional Brownian motion (FBM) [12], Lévy walk (LW) [13], and scaled Brownian motion (SBM) [15]. We considered trajectories with anomalous diffusion exponents in the range α ∈ [0.05, 2]. Exponents were restricted to α &gt; 0.05 because smaller exponents produce practically immobile trajectories. Note that CTRW and ATTM are strictly subdiffusive (α ≤ 1), LW is superdiffusive (α ≥ 1), FBM cannot have ballistic behavior (α &lt; 2), whereas SBM covers the whole exponent range.</p>
        <p>Each dataset contained 10 4 trajectories. All trajectories were first generated with a length L = 1000. For theoretical models providing trajectory sampling at irregular times (CTRW and LW), oversampling was used to obtain tracer coordinates at uniform times. The trajectories were then standardized to have a unitary standard deviation σ D of the distribution of displacements. To mimic experimental data, trajectories were corrupted with a finite localization precision. For this, a random number from a normal distribution N (0, σ noise ) was added to each trajectory coordinate. Last, the displacements' standard deviation was scaled by a random number sampled from a normal distribution N (0, 1) to include the effect of an effective diffusion coefficient (see Fig. 1a-c for exemplary trajectories in each dimension). Trajectories were thus cut to the desired length. For T1 and T2, trajectories were cut to lengths L ∈ [10, 1000], whereas for T3 all trajectories had length L = 200. A different dataset was generated for each task to ensure the proper balance of the feature to be determined. Therefore, the dataset for T1 had a balanced distribution of anomalous exponents but not of diffusion models, whereas the dataset for T2 was balanced with respect to the diffusion models. For T3, trajectories were obtained by concatenating trajectories simulated for all models and exponents. Each tra-jectory had a random changepoint at a discrete index t GT ∈ [1,199] corresponding to a change at least in one of the two features (α and diffusion model). An example of such kind of trajectories is presented in Fig. 1d.</p>
        <p>Three levels of noise were used to corrupt trajectories, corresponding to σ noise = 0.1, 0.5, 1. The SNR was calculated as SNR = σ D /σ noise . Due to the previous standardization, the SNR levels thus were SNR = 1, 2, 10. Trajectories in 2D and 3D were allowed to have different noise levels along different directions. The overall noise was calculated as the square root of the squared sum of σ noise along independent directions.</p>
        <p>We developed the andi-datasets Python package to allow participants to generate their own dataset (e.g., for training). Details about available functions can be found in the hosting repository https://github.com/ AnDiChallenge/ANDI_datasets.</p>
        <p>In this section, we present a brief introduction to the concepts of anomalous diffusion and ergodicity breaking. We provide theoretical insights about the anomalous diffusion models considered in the AnDi challenge, as well as the description of the pseudocode used for simulations. Finally, we describe how to extend the algorithms to simulate the diffusion models in two and three dimensions. The Python implementation of all the algorithms described below is available at https: //github.com/AnDiChallenge/ANDI_datasets.</p>
        <p>When analyzing trajectories, diffusion is typically quantified through the calculation of the mean squared displacement (MSD). The MSD grows linearly in time for Brownian walkers, MSD ∼ t, while it shows a powerlaw scaling for anomalous diffusion, MSD ∼ t α , where α is the anomalous diffusion exponent. In practice, the MSD can be calculated either by performing an ensemble average of the positions of a set of N tracers,</p>
        <p>or, for the trajectory of a single tracer, sampled at L discrete times t i = i∆t, as a time-average:</p>
        <p>2 .</p>
        <p>(2) In its most general definition, a process is considered ergodic if any single realization is able to explore all the possible configurations of the system. The impossibility of performing such an exploration is usually referred to as ergodicity breaking. For a (strong) non-ergodic process, the space of configurations is separated into mutually inaccessible domains, hence preventing its full exploration. If those domains are indeed accessible, but a single tracer is unable to visit them in a finite time, the process is instead defined as weakly non-ergodic [62]. In this case, a sufficiently large ensemble of tracers may indeed explore all possible configurations, hence producing a difference between ensemble and time averages.</p>
        <p>In the context of anomalous diffusion, a system is said to show weak ergodicity breaking if the EA-MSD does not converge to TA-MSD in the infinite time limit [4]. Generally, while the EA-MSD still shows the expected power-law scaling, the TA-MSD scales linearly with time. Moreover, the amplitude of the TA-MSD for different trajectories is a random variable, whose distribution can be analytically calculated for some diffusion models [63]. One can then define the time and ensemble averaged TEA-MSD over a set of N trajectories as</p>
        <p>where TA-MSD(∆) i is the TA-MSD for the i-th trajectory. The so-called ergodicity breaking parameter (EB) [51] can be calculated as</p>
        <p>where ζ = TA-MSD(∆)/TEA-MSD(∆). The EB parameter, in the limit ∆/T → 0, is a widely used tool to quantify ergodicity breaking (here T = L∆t represents the trajectory length). For ergodic diffusion, then EB → 0, while any other value showcases a non-ergodic behavior. Processes like CTRW, ATTM and SBM show weak ergodicity breaking [14,64,65], whereas Brownian motion and FBM are ergodic, though convergence of the EA-MSD to the TA-MSD may be slow for certain values of the anomalous exponent α [66]. Indeed, as discussed in [24], the ergodicity of FBM requires a careful analysis as a function of α, and often other statistical measures are necessary to study ergodicity breaking. To find a technique to study short trajectories, it is important to note that, for CTRW and ATTM, the TA-MSD shows a short-time linear behavior TA-MSD∝ ∆ even for anomalous trajectories. This showcases one of the limitations of the fitting of the TA-MSD to determine the anomalous diffusion exponent. A mention apart requires the concept of ultraweak ergodicity breaking, which has been identified for LW, where time and ensemble averages only differ by a constant factor [67, 68].</p>
        <p>The continuous time random walk (CTRW) defines a large family of random walks with arbitrary displacement density for which the waiting time, i.e., the time between subsequent steps, is a stochastic variable [11]. Here, we consider a specific case of CTRW for which waiting times are sampled from a power-law distribution ψ(t) ∼ t -σ and displacements are sampled from a Gaussian distribution with variance D and zero mean. In such case, the anomalous diffusion exponent is α = σ -1 (the EA-MSD = x(t) 2 ∝ t α ). Since the waiting times are generated from a power law distribution, for σ = 2 the EA-MSD features Brownian diffusion with logarithmic corrections [2]. For α = 1 one should instead use a Poisson density, or a fixed waiting time (i.e., the limit of a one-sided Lévy stable density in the limit α = 1).</p>
        <p>The algorithm used to simulate CTRW trajectories is described in Algorithm 1. Notice that the variable τ stands for the total time at i-th iteration. Also notice that the output vector x corresponds to the position of the particle at the irregular times given by t.</p>
        <p>length of the trajectory T anomalous exponent α diffusion coefficient D Define:</p>
        <p>x → empty vector t → empty vector N (µ, s) → Gaussian random number generator with mean µ and standard deviation s i = 0; τ = 0 while τ &lt; T do ti ← sample randomly from</p>
        <p>In fractional Brownian motion (FBM), x(t) is a Gaussian process with stationary increments. This process is symmetric, x(t) = 0, and importantly its EA-MSD scales as x(t) 2 = 2K H t 2H . Here, H is the Hurst exponent, which is related to the anomalous diffusion exponent as H = α/2 [12,69]. Also, the two-time correlation is</p>
        <p>). FBM can also be introduced as a process arising from a generalized Langevin equation where the noise is nonwhite (aka fractional Gaussian noise, fGn). The fGn has a standard normal distribution with zero mean and power-law correlations:</p>
        <p>The FBM features two regimes: one where the noise is positively correlated (1/2 &lt; H &lt; 1, i.e., 1 &lt; α &lt; 2, superdiffusive) and one where the noise is negatively correlated (0 &lt; H &lt; 1/2, i.e., 0 &lt; α &lt; 1, subdiffusive). For H = 1/2 (α = 1) the noise is uncorrelated, hence the FBM converges to Brownian motion.</p>
        <p>For a d-dimensional FBM, the corresponding position vector has zero mean, x(t) = 0, the EA-MSD is</p>
        <p>), and the fGN reads</p>
        <p>where i, j in the subindex of the fGN denotes a different cartesian coordinate.</p>
        <p>Various numerical approaches have been proposed to solve the FBM generalized Langevin equation exactly.</p>
        <p>Here, we use the Davies-Harte method [70] and the Hosking method [71] via the 
            <rs type="software">FBM Python package</rs>(
            <rs type="url">https: //pypi.org/project/fbm/)</rs>. Details about the numerical implementations can be found in the associated references.
        </p>
        <p>The Lévy walk (LW) is a particular case of CTRW. The time between steps is irregular [13], but, in contrast to the CTRW considered here, the distribution of displacements for a LW is not Gaussian. We considered the case in which the flight times (i.e., the times between steps) are retrieved from the distribution ψ(t) ∼ t -σ-1 . In one dimension, the displacements are ∆x and the step length is |∆x|. The displacements are correlated with the flight times such that the probability to move a step ∆x at time t and stop at the new position to wait for a new random event to happen is Ψ(∆x, t) = 1 2 δ(|∆x|-vt)ψ(t), where v is the velocity. From here, one can show that the anomalous exponent is given by</p>
        <p>The details of the numerical implementation for the LW are given in Algorithm 2. Notice that we use a random number r, which can take values 0 or 1, to decide in which sense the step is performed. Also note that, as for the CTRWs, the output vectors x, t represent irregularly sampled positions and times.</p>
        <p>Input: length of the trajectory T anomalous exponent α Define:</p>
        <p>x → empty vector t → empty vector v → random number ∈ (0, 10] i = 0 while τ &lt; T do ti ← sample randomly from ψ(t) ∼ t -σ-1 xi ← (-1) r vti, where random r is 0 or 1 with equal probability. τ ← τ + ti i ← i + 1 end while Return: x, t</p>
        <p>The annealed transient time motion (ATTM) implements the motion of a Brownian particle whose diffusion coefficient varies in time [14]. The tracer performs Brownian motion for a random time t 1 with a random diffusion coefficient D 1 , then for t 2 with D 2 , etc. The diffusion coefficients are sampled from a distribution such that P (D) ∼ D σ-1 with σ &gt; 0 as D → 0 and that decays rapidly for large D. If the random times t are sampled from a distribution with expected value E[t|D] = D -γ , with σ &lt; γ &lt; σ + 1, the anomalous diffusion exponent is α = σ/γ (corresponding to the subdiffusive regime I of the model described in Ref. [14]). Here, we consider that the distribution is a delta function, P t (t|D) ∼ δ(t-D -γ ). Hence, the period of time t i in which the particle performs Brownian motion with a random diffusion coefficient D i is t i = D -γ i , with D i extracted from the distribution described above. The numerical implementation of the ATTM model is given in Algorithm 3. Note that, in contrast to CTRW and LW, now the only output is x because the trajectory is already produced at regular time intervals of duration ∆t. The scaled Brownian motion (SBM) is a process described by the Langevin equation with a time-dependent diffusivity K(t)</p>
        <p>where ξ(t) is white Gaussian noise [15]. For the case in which K(t) has a power-law dependence with respect to t such that K(t) = αK α t α-1 , the EA-MSD follows x 2 (t) N ≈ K α t α with K α = Γ(1+α)K α . The numerical implementation of SBM is presented in Algorithm 4.</p>
        <p>Input: length of the trajectory T anomalous exponent α Define:</p>
        <p>The algorithms presented above provide examples for the simulation of 1D trajectories. In order to maintain the properties of each anomalous diffusion model, extension to 2D and 3D was performed differently depending on the considered model. For ATTM, CTRW, FBM, and SBM in 2D, trajectories were obtained by the simple composition of (independent) motion performed over orthogonal axes. The same was done for FBM and SBM in 3D. For ATTM and CTRW (3D), and for LW (2D and 3D), waiting times and displacement lengths were sampled according to the recipe provided by each particular model in 1D. However, the displacement length was used to sets the radius of the circle (2D) or the sphere (3D) over which the tracer step ended up. The direction was randomly chosen to ensure the uniform sampling of the circle or the sphere, and coordinates along orthogonal axes were calculated accordingly.</p>
        <p>We calculated several metrics to quantify the performance of the submitted methods with respect to the ground truth in the various tasks. Although only the most representative metrics were used to build the competition leaderboard, others were used to gain further insight about the methods.</p>
        <p>• Mean absolute error (MAE). Methods were required to provide an accurate prediction for the anomalous diffusion exponent α for a single trajectory (T1) or for a part of a trajectory after segmentation (T3). Method performance was thus quantified by the MAE between the predicted value and the ground truth:</p>
        <p>where N is the number of trajectories in the dataset, and α i,p and α i,GT represent the predicted and ground truth values of the anomalous exponent of the i-th trajectory, respectively.</p>
        <p>• F 1 -score. For T2 and T3, the methods have to provide the probability for a trajectory (or a segment) to be assigned to one of the five diffusion models. Predictions for which the highest probability value corresponded to the the ground truth model were identified as true positives (TP). As a summary statistics for model classification, we used the F 1 -score. In the case of a balanced dataset (as the one considered in the challenge, for which each class is equally represented), the F 1 -score with micro-average can be calculated as</p>
        <p>where N is the total number of trajectories in the dataset.</p>
        <p>• Root mean square error (RMSE). The trajectory segmentation problem in T3 requires the location of the point where a trajectory undergoes a change in anomalous diffusion. The most important consideration for a changepoint method is how accurately it localizes the changepoint itself. The quantification of this accuracy was performed through the RMSE between the predicted and ground truth position:</p>
        <p>where t i,p and t i,GT represent the predicted and ground truth values of the changepoint position, respectively.</p>
        <p>• Mean reciprocal rank (MRR). For ranking purposes of T3, the precision in determining the changepoint position, the anomalous diffusion exponent α, and the diffusion model were summarized into a single statistics for the overall method evaluation, given by the MRR:</p>
        <p>For this task, MAE and F 1 -score were calculated by treating each segment (before and after the predicted changepoint) as an individual trajectory and averaging the metrics obtained over the two segments.</p>
        <p>Further statistics were used for the comparative analysis of the performance of the methods.</p>
        <p>• Anomalous exponent bias. For the determination of the anomalous diffusion exponent in T1 and T3, besides the accuracy, we further assessed whether the predicted value systematically differed from the ground truth. For this reason, we calculated the distribution of the difference between predicted and ground truth exponent (Figs. S14,S15, and S16), and estimated the bias θ as its expectation value:</p>
        <p>As shown in Fig. 2, the estimation of the anomalous diffusion exponent from the fit of the TA-MSD shows a negative bias (i.e., the predicted exponent α p is systematically smaller than the ground truth exponent α GT ). Such effect is particularly important close to α GT = 1 and is associated to the presence of localization error [18]. However, as shown in Figs. S14, S15, and S16, the top performing methods show little or no bias in their predictions.</p>
        <p>• Receiver operating characteristic (ROC) curve and area under the curve (AUC). The calculation of the F 1 -score assumes that a method outputs a discrete classifier (i.e., a unique choice for the diffusion model). However, many methods output continuous numbers associated to the probability of the input to belong to each class. Thus, these probability values assigned to each model contain more information about the performance of the classifier. This information can be summarized by the ROC curve and the corresponding AUC. The ROC curve reports the true positive rate (or sensitivity) versus the false negative (one minus the specificity) for different levels of probability thresholds: if an input has a certain class probability above the threshold, it is considered to belong of such class. The AUC is given by the integral of the ROC curve and is equal to the probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one. It thus provides a useful tool to compare the sensitivity and specificity of a given classifier. In particular, being based on probability instead of class labels, ROC/AUC report how "doubtful" a method is about its choice of the model. ROC curves for each class versus the others are shown in Figs. S17, S18, and S19 for all teams. Micro-(i.e., considering each class as a binary prediction) and macro-averaged (i.e., considering an equal weight for the classification of each label) ROC curves are also reported. The ROC/AUC analysis confirms that ATTM is the most problematic model to classify, whereas the best results are obtained for CTRW and LW. The scatter plot of values of F 1 -score vs. micro-averaged AUC show a rather good correlation (Fig. S20), with the exception of a few models (teams L, D and N) that perform considerably better in terms of F 1 -score.</p>
        <p>• Recall and RMSE TP . For the assessment of changepoint localization error in T3, we followed two different evaluation approaches. For the challenge evaluation, we simply quantified the RMSE. Trajectories showing no changepoint were considered as having a dummy changepoint either at index 1 or 199. However, to get a better understanding of methods' performance, we also considered an alternative analysis. For this, ground truth and predicted changepoints within a distance = 10 from the start/end points were removed and the associated trajectories were considered as not having a changepoint. Matching changepoints were identified as true positives and used to calculate the recall and the RMSE in true positive position pairs RMSE TP (Fig. 4d). Predicted changepoints not matching any ground truth changepoint were identified as false positives. Similarly, ground truth changepoints not having any prediction were counted as missed events.</p>
        <p>Several classical statistical methods have been employed to characterize anomalous diffusion from single trajectories and quantify the anomalous diffusion exponent. Many of them rely on the analysis of the EA-MSD or TA-MSD presented in Eqs. ( 1) and (2).</p>
        <p>We developed a simple tool to perform the estimation of the anomalous exponent to establish a performance baseline for Task 1 of the challenge. The code calculates the TA-MSD and performs a linear fit of its logarithm with respect to the logarithm of the timelag for the first k datapoints, where k is the maximum between 10 and the 10% of the trajectory length. The anomalous diffusion exponent is thus obtained as the slope of the straight line. This criterion has been shown to provide reliable results for the fitting of TA-MSD for Brownian diffusion [72]. Although the choice of a different timescale or the use of an independently calculated localization precision can produce better results [16], we intentionally limited the code to a simple fitting algorithm with a straightforward criterion for the choice of the number of data points to fit. As shown in Fig. 2, such a simple fit produces results comparable with the best methods for ergodic models with high SNR and long trajectories. The code is available at 
            <rs type="url">https://github.com/AnDiChallenge/ANDI_datasets</rs>.
        </p>
        <p>Besides the MSD, another popular methodology for the quantification of the anomalous diffusion exponent is the moment scaling spectrum MSS [73,74]. MSS considers several high-order moments of the displacement distribution to obtain their scaling exponents and use them to calculate the slope of the exponent curve versus the moment order, which is found proportional to α.</p>
        <p>The anomalous diffusion exponent is strictly linked to specific characteristics of the diffusion model, thus can also be obtained by means of their quantification [4]. However, this approach require the knowledge (or an educated guess) of the diffusion model. If, in addition, distributions of the associated quantities can be obtained, then anomalous diffusion exponent can be estimated through their fitting. For instance, for CTRW, the anomalous diffusion exponent can be extracted by fitting the waiting time distribution ψ(t) [19]; for the ATTM, by fitting the distribution of diffusion coefficients or transit times [20]; or, for a Lèvy walk from the flight time or step length distribution [75].</p>
        <p>Even though the problem of associating a trajectory to an underlying diffusion model has been long investigated, there is still no clear general consensus on how to unambiguously determine the underlying physical mechanism from a trajectory. To the best of our knowledge, model classification is generally performed using a com-bination of multiple estimators and further corroborated by a comparison with the corresponding analysis of simulated data. Several statistical parameters have been proposed in this sense. Algorithms based on multiple estimators can allow to distinguish between pairs of models [21][22][23]. Some of the proposed approaches are based on estimating trajectory statistical features to determine ergodicity [21,51] and Gaussianity [76], and thus restrict the number of possible models. Lastly, the velocity autocorrelation function [77] and the power spectral density [38] have been shown to have model-dependent fingerprints for some diffusion models. However, none of these method can be directly used to classify the trajectories as required for T2. First attempts to provide a direct and generalized classification have been proposed only recently [36,41,43] and the developing teams have participated in the challenge. Therefore, we decided not to provide any baseline estimation for this task.</p>
        <p>Although a few methods have been recently developed for the detection of trajectory changepoints with respect to a switch in α [25, 32,33] and diffusion model [34], there is no consensus on a well-established method that can be used as a baseline for T3. Limited to the the changepoint detection part, we thus decided to compare methods' performance with the results of a random prediction, as shown in dashed lines in Fig. 4a and Fig. S5. For this, we simply calculate the RMSE for selecting a random point on a trajectory having a changepoint at t GT . The error associated to such a random prediction is not uniform, since it depends on the changepoint position t GT along the trajectory, as well as on the trajectory length L. The random predictor RMSE random can thus be calculated as:</p>
        <p>for L = 200 as in trajectories simulated for T3.</p>
        <p>All 
            <rs type="software">software</rs> used for the Challenge is available at 
            <rs type="url">https://github.com/AnDiChallenge</rs>. The 
            <rs type="software">code</rs> of the andi-datasets package used to generate the competition datasets is available at https://github.com/ AnDiChallenge/ANDI_datasets. Simulated datasets used for the competition are available for download at http://andi-challenge.org. Groundtruth for datasets used in the first phase of the competition for training are also available. Empirical probability distributions of the difference between the predicted (αp) and the ground-truth exponent (αGT ) for every method participating in T1.3D. The expectation value of the bias θ is reported in the plot. A dashed line representing the zero value is included as a guide-to-the-eye. Teams are ordered according to to their ranking in the leaderboard. Team K: TSA Contact: Erez Aghion Max-Planck institute for the physics of complex systems Dresden, Gemany Reference:
        </p>
        <p>[15] Method:</p>
        <p>Scaling analysis, and feature engineering (for T2) Platform: Python Open-access: https://github.com/ErezAgh/ANDI-challange-codes- https://github.com/AnDiChallenge/AnDi2020_TeamK_TSA Description:</p>
        <p>This approach is based on theory, as opposed to pure data-driven methods. Anomalous diffusion can be described via more than just the Hurst exponent. The assumptions of the central limit theorem, which leads to standard diffusion, can be violated in three distinct ways: Increment correlations (like in FBM), fat-tailed increment distribution (like in CTRW), and nonstationarity of the increments' distribution, like in SBM. Each of these three paths can be characterized by its own scaling exponent, and can be measured directly in data, using methods of time-series analysis. The exponent J, describing the first violation, can be measured, e.g., using detrended fluctuations analysis. The exponent L, for the second violation, is measured from the temporal scaling of the time-average of the squared increments of the process. Finally, The exponent M is measured from the scaling of the time-average of the increments' absolute value. These exponents can be measured in any number of dimensions.</p>
        <p>Their sum leads to the Hurst exponent: H = M + L + J -1 [15][16][17].</p>
        <p>To estimate the Hurst exponent for T1, we evaluate J, L and M using methods which were specifically adapted for noise filtering. Importantly, this approach is not model-dependent, and our algorithm can be applied also to other types of data, not generated by one of the five models in the AnDi challenge.</p>
        <p>For T2, we construct a small set of educated questions, targeted to characterize different properties of the paths in the data set, via precise analysis of the increments of the process. When comparing between various models outside of the AnDi challenge, here we would need to construct a new set of questions for the new models. Some of the questions are aimed for various general relations between the three exponents described above, others, to more specific properties of the individual types of paths involved in the challenge. The answers of each question can be "yes" (= 1) or "no" (= 0) (or "maybe" (= 2)). An example for a question about the exponents: Is (J -0.5) &gt; (M -0.5) + (L -0.5)? Namely, is the effect of autocorrelations on the Hurst exponent stronger than the combined effect of the increment distribution? This question separates between FBM and LW on the one side, and ATTM and SBM on the other. An example for a question beyond the exponents, is given by the comparison of the autocorrelations of the increments of the process, versus that of their absolute value. This question is highly selective for distinguishing Lévy walk from all the others. For each trajectory in the competition data set: we generate a set of answers using the same algorithm, and then generate an array of probabilities for this set to be either ATTM, CTRW, FBM, LW, or SBM. This is done by counting how many times a similar line of answers appeared in the training set for each type of process, divided by the total number of occurrences. The answer is, e.g.: [0.125; 0.025; 0.85; 0.0; ...]. The larger the training set, the more accurate is the evaluation of the probabilities. If a new set of answers is not found in the training file, a reduced number of selected questions are asked again, making the choice less selective. The selectivity of the questions, and the time-series analysis techniques used, also affect the quality of the final results. This method is similar in one and higher dimensions. Tasks: T1, T2.1D</p>
        <p>D. S. Martin, M. B. Forstner, and J. A. Käs, "Apparent subdiffusion inherent to single particle tracking", Biophysical journal 83, 2109-2117 (2002).</p>
        <p>A. V. Weigel, B. Simon, M. M. Tamkun, and D. Krapf, "Ergodic and nonergodic processes coexist in the plasma membrane as observed by single-molecule tracking", Proceedings of the National Academy of Sciences 108, 6438-6443 (2011).</p>
        <p>C. Manzo, J. A. Torreno-Pina, P. Massignan, G. J. Lapeyre Jr, M. Lewenstein, and M. F. G. Parajo, "Weak ergodicity breaking of receptor motion in living cells stemming from random diffusivity", Physical Review X 5, 011021 (2015).</p>
        <p>M. Magdziarz, A. Weron, K. Burnecki, and J. Klafter, "Fractional brownian motion versus the continuoustime random walk: a simple test for subdiffusive dynamics", Physical review letters 103, 180602 (2009).</p>
        <p>Y. Meroz, I. M. Sokolov, and J. Klafter, "Test for determining a subdiffusive model in ergodic systems from single trajectories", Physical review letters 110, 090601 (2013).</p>
        <p>L. Chen, K. E. Bassler, J. L. McCauley, and G. H. Gunaratne, "Anomalous scaling of stochastic processes and the moses effect", Physical Review E 95, 042141 (2017).</p>
        <p>M. Schwarzl, A. Godec, and R. Metzler, "Quantifying non-ergodicity of anomalous diffusion with higher order moments", Scientific reports 7, 1-18 (2017).</p>
        <p>A. Weron, K. Burnecki, E. J. Akin, L. Solé, M. Balcerek, M. M. Tamkun, and D. Krapf, "Ergodicity breaking on the neuronal surface emerges from random switching between diffusive states", Scientific reports 7, 1-10 (2017).</p>
        <p>E. Yamamoto, T. Akimoto, A. Mitsutake, and R. Metzler, "Universal relation between instantaneous diffusivity and radius of gyration of proteins in aqueous solution", Physical review letters 126, 128101 (2021).</p>
        <p>C. Truong, L. Oudre, and N. Vayatis, "Selective review of offline change point detection methods", Signal Processing 167, 107299 (2020).</p>
        <p>The authors would like to thank: Paula Kowalek for the graphical illustrations; Matthias Weiss and Maria Garcia-Parajo for sharing experimental data; Daniel Adam for help with compiling the data of singleatom trajectories. G.M.-G., B.R., and M.L. acknowledge support from ERC AdG NOQIA, Agencia Estatal de Investigación "Severo Ochoa" Center of Excellence CEX2019-000910-S, Plan National FIDEUA PID2019-106901GB-I00/10.13039 / 501100011033, FPI), Fundació Privada Cellex, Fundació Mir-Puig, and from Generalitat de Catalunya (AGAUR Grant No. 2017 SGR 1341, CERCA program, QuantumCAT U16-011424 , co-funded by ERDF Operational Program of Catalonia 2014-2020), MINECO-EU QUANTERA MAQS (funded by State Research Agency (AEI) PCI2019-111828-2 / 10.13039/501100011033), EU Horizon 2020 FET-OPEN OPTOLogic (Grant No 899794), and the National Science Centre, Poland-Symfonia Grant No. 2016/20/W/ST4/00314. Giov.V. and A.A. acknowledge funding from ERC StG ComplexSwimmers. M.A.G.-M. acknowledges funding from the Spanish Ministry of Education and Vocational Training (MEFP) through the Beatriz Galindo program 2018 (BEAGAL18/00203). R.M. acknowledges DFG grant ME 1535/12-1. Gior.V. and A.G. acknowledge sponsorship for this work by the U.S. Office of Naval Research Global (Award No. N62909-18-1-2170). Z.H. acknowledges funding from the Fundamental Research Funds for the Central Universities. T.B. acknowledges support by the Francis Crick Institute, which receives its core funding from Cancer Research UK (FC001086), the UK Medical Research Council (FC001086), and the Wellcome Trust (FC001086), and thanks Nate Goehring for supervision and acquisition of funding. P.K, H.L.-O. and J.S. were funded by the Polish National Science Centre (NCN-DFG Beethoven Grant No. 2016/23/G/ST1/04083) and acknowledge the support by the Wroclaw Centre for Networking and Supercomputing (calculations were performed using their BEM computing cluster). S.T. acknowledges the Deutscher Akademischer Austauschdienst for PhD Scholarship (DAAD Program ID 57214224). H.K. and I.S. acknowledge funding from the Dutch Research Council (NWO) through the GENOMETRACK project of the Building Blocks of Life research program (Project No. 737.016.014). C.M. acknowledges funding from FEDER/Ministerio de Ciencia, Innovación y Universidades -Agencia Estatal de Investigación through the "Ramón y Cajal" program 2015 (Grant No. RYC-2015-17896), and the "Programa Estatal de I+D+i Orientada a los Retos de la Sociedad" (Grant No. BFU2017-85693-R); from the Generalitat de Catalunya (AGAUR Grant No. 2017SGR940). C.M. also acknowledges the support of NVIDIA Corporation with the donation of the Titan Xp GPU and funding from the PO FEDER of Catalonia 2014-2020 (project PECT Osona Transformació Social, Ref. 001-P-000382).</p>
        <p>Screenshots of the interactive tool for performance comparison. a, Summary of the results obtained for T1 and T2 according to corresponding challenge metrics. Hovering on each symbol reveals team name and scores. b-d, Plots of the metrics and estimators used to assess methods' performance for T1 (b), for T2 (c), and for T3 (d). For each task, plots can be displayed for user-selected subsets of the datasets. Sliders and buttons allow data selection based on task dimension, team, trajectory length, noise, α, diffusion model, or changepoint position. The interactive tool is available at 
            <rs type="url">http://andi-challenge.org/interactive-tool/</rs>.
        </p>
        <p>SUPPLEMENTARY NOTE 1: LIST OF TEAMS PARTICIPATING TO THE CHALLENGE Team A: Anomalous Unicorns Contact:</p>
        <p>Borja Requena ICFO-The Institute of Photonic Sciences Castelldefels (Barcelona), Spain Method:</p>
        <p>HYDRAS (RNN + CNN) Platform: Python Open-access: https://github.com/BorjaRequena/AnDi-unicorns https://github.com/AnDiChallenge/AnDi2020_TeamA_AnomalousUnicorns Description:</p>
        <p>Hydras are architectures that have a set of independent feature extractors (heads) that process the input trajectories. These all converge into a final set of fully connected layers (body) that process the output of the heads to perform inference. The feature extractors can be anything capable of processing trajectories of arbitrary lengths, such as RNNs, CNNs or, even, other hydras. For T2, we have taken an ensemble of ten bi-headed hydras built with an RNN and a CNN as feature extractors.</p>
        <p>For T1, the resulting model is another ensemble of hydras that builds upon the result from T2. The resulting hydras have six heads: a hydra from T1 and five expert bi-headed hydras (RNN+CNN) that are trained to predict the anomalous exponent of a single diffusion model exclusively. This way, the body receives the output from all the model-specific feature extractors together with the opinion of the classifier. Each head is trained independently and then, in order to build the hydra, their weights are frozen while the body is trained. Finally, after a few epochs of body training, the head weights are unfrozen, and the entire hydra is trained with discriminative learning rates: heads are trained with a much lower learning rate than the body. The entire source code can be found in the GitHub repository together with some examples. Tasks:</p>
        <p>T1.1D, T2.1D Bayesian inference using annealed importance sampling to sample from the posterior distribution. We attempted to use Bayes theorem to calculate the posterior probability distributions for the models and parameters. The likelihood functions, and to a large extent also the priors, could be derived from the descriptions and codes provided by the organizers. Effective Bayesian inference could be achieved for the SBM and FBM models. However, the need to integrate out hidden waiting times impaired effective inference for ATTM, CTRW and LW. For ATTM and CTRW, we attempted to integrate out the waiting times together with the model parameters using Monte Carlo techniques. For LW, in 1D we used the forward algorithm on a hidden Markov model (but without including measurement noise), while in 2D and 3D we used a goodness-of-fit test after inference with the other four models to exclude them, followed by a fit to the TA-MSD to obtain the anomalous diffusion exponent of the LW. First, each trajectory is turned into a graph, where nodes are the positions and edges connect positions following a pattern based on their time difference. Then, features computed from normalized positions are attached to nodes (e.g., cumulative distance covered since origin, distance to origin, maximal step size since origin). These graphs are then passed as input to a graph convolution module (graph neural network), which outputs, for each trajectory, a latent representation in a high-dimensional space. This fixed-size latent vector is then passed as input to task-specific modules, which can predict the anomalous exponent or the random walk type. Several output modules can be trained at the same time, using the same graph convolution module, by summing task-specific losses. The model can receive trajectories of any size as inputs. The high-dimensional latent representation of trajectories can be projected down to a 2D space for visualisation and provides interesting insights regarding the information extracted by the model (see details in Ref. [6]). Tasks:</p>
        <p>T1.1D, T2.1D We build our machine in the context of ensembles and hybrid structures. The applied preprocessing consists of three steps: 1) the noise is reduced by a 3-points moving average, 2) length of input trajectories are re-scaled to 100 points by a spline interpolation, and 3) the trajectories are normalized to the range[0, 1]. First, we prepare each normalized trajectory and extract user-defined features from the trajectory as an input for the ensemble modules. Then, we construct an ensemble of ten identical ResNet-MLP modules. The ResNet input is the normalized trajectory and the following multi-layer perceptron (MLP) receives both an output of the ResNet and the prepared features. Finally, the ten outputs from the ResNet-MLP module are analyzed by 
            <rs type="software">XGBoost</rs>. Tasks: T1.1D, T2.1D The method is based on recurrent neural networks (RNN). The RNN used in all tasks share the same basic architecture and differ only in the last layer or two. All the RNN have two LSTM layers (of dimension 250 and 50, respectively). For inference tasks (T1 and T3) the last output of the second LSTM layer is directly connected to the output layer. For classification tasks (T2 and T3), the last output of the second LSTM layer is followed by a dense layer including 20 nodes, which is then connected to the five dimensional output layer (representing each model with softmax activation).
        </p>
        <p>We train multiple RNN that specialize in analyzing trajectories of a certain length. When presented with a trajectory of length l, we use the predictions of the two RNN trained on the nearest lengths (one on longer trajectories of length L+ and one on shorter ones of length L-) and weigh them according to their distance from l. For T1, we train 14 RNN for different lengths in 1D and 9 RNN for different lengths in 2D. For T2, we train 6 RNN for different lengths in 1D and 4 RNN for different lengths in 2D. In T3 all trajectories have the same length; we train 4 RNN: the first RNN to classify the model of the first segment, the second RNN to classify the model of the second segment, and two inference RNN; each inference RNN predicts the switching time, first exponent and the second exponent and their predictions are then averaged. We follow the same approach in 2D (but there we use a single RNN for the inference). We do not train RNN on 3D trajectories. For 3D data, we take projections on lower dimensions and use RNN trained on 2D and 1D data and average their outputs.</p>
        <p>All RNN are trained using 3×10 6 trajectories that are generated using 
            <rs type="software">andi-datasets package</rs> (
            <rs type="url">https: //github.com/AnDiChallenge/ANDI_datasets)</rs>. To avoid overtraining, we split these trajectories in 30 datasets (each containing 10 5 trajectories) which are successively presented to the RNN. We use the first dataset to train for 5 epochs splitting it in batches of size 32. We then switch to another dataset, split it in batches of size 128 and train for 4 epochs. We repeat this procedure for 3 other datasets. We iterate the procedure using 5 datasets split into batches of size 512 each considered for 3 epochs and finally use 20 datasets split into batches of size 2048 for 2 epochs each. For memory reasons, we did not use the batches of size 2048 for trajectories containing large amounts of measurement, such as long or high-dimensional trajectories. We use recurrent dropout (20%) in both LSTM layers. We preprocess the input data as follows: 1) We take the increment values of the trajectory. 2) We normalize the increments in a way that they have zero mean and unitary standard deviation for each trajectory. 3) To optimize the training, we re-shape the input trajectories into shorter trajectories of higher dimensions. For example, for the inference of 1D trajectories of length 225, the 224 increments are split into 56 blocks of dimension 4, bj = [∆x4j, ∆x4j+1, ∆x4j+2, ∆x4j+3] with j = 0, . . . 55. The chosen block size varies according to the trajectory length and dimension. The FEST method was used to solve T1 and T2 and was applied to one-, two-and three-dimensional trajectory data. This method is divided in two parts: i) measurement of features at each point along the trajectories, and ii) training of a neural network consisting of a stack of bidirectional Long Short-Term Memory (LSTM) and fully connected ("Dense") layers [8].
        </p>
        <p>The following features were computed: the displacements ∆rn(t) = (∆xn(t), ∆y n (t), ∆zn(t)) of a particle between time t and t + n (which is the difference between two particle positions rt and rt+n, where rt = (xt, yt, zt) and n ≥ 1) and the distances dn(t) = ∆xn(t) 2 + ∆y n (t) 2 + ∆zn(t) 2 . The features for 1D and 2D cases were similarly defined. Subsequently, a mean of distances between time t -p and t + p, dn,p(t), was calculated as dn,p(t) = 1 2p+1 t+p k=t-p dn(k), where p ≥ 1. All the mentioned features characterize how fast particles move. To gain information on the direction of motion, for 2D and 3D cases, the angles θn(t) between two displacement vectors ∆rn(t) and ∆rn(t-n) were computed. The number of features that were used as input to the neural network depended greatly on the number of dimensions. For 1D case, only displacements could be computed, therefor we used ∆xn, n = {1, 2}. Larger values of n led to smaller sizes of feature vectors. For 2D case, we computed six features: ∆x1, ∆y 1 , d1, d1,1, d2,1 and θ1. For 3D case, 6 other features were used: ∆x1, ∆y 1 , ∆z1, d1, d1,1, d2,1. We built two similar neural network architectures for T1 and T2. Using the above-mentioned features, the output for T1 was a predicted value of α, and the outputs for T2 were probabilities of input track belonging to one of 5 diffusive models. The architectures of both neural network were built using functions from the 
            <rs type="software">Keras</rs> library [9]. In both cases, we used 3 bidirectional LSTM layers (with 2 6 , 2 5 and 2 4 hidden nodes, respectively), followed by 4 Dense layers (with 2 5 , 2 4 , 2 3 and 1 (or 5) hidden nodes) with Dropout layers in between (with a dropout rate of 0.2 or 0.1). For T1, ReLu activation function was applied on each Dense layer, while for T2 tanh was applied with a softmax at the output layer. During the training, the models were optimized using the Adam optimizer and, as loss functions, we used the mean squared error (MSE) for T1 and categorical cross-entropy for T2. The described networks had to be trained using trajectories with a fixed number of time points. For that, new datasets were created with the tool provided by the organizers (https://github.com/ AnDiChallenge/ANDI_datasets). To cover the variety of lengths that can be encountered in the challenge data, 4 different datasets were generated for each task, each consisting of different trajectory lengths: 50, 200, 400 or 600 time points. Thereby, each network was trained 4 times in order to create 4 distinct models. For each case (1D, 2D and 3D), we created 30000 tracks of length 50 for training and 6000 for validation (denoted 30000/6000) to keep a ratio 8:2, 7500/1500 trajectories of length 200, 3750/750 of length 400 and 2500/500 of length 600. Training and validation datasets were generated separately to ensure that all combined cases of α and diffusive models were present in both dataset. The training have been carried out on a Linux system with a GPU GeForce GTX 1650 and a processor 2.60GHz Intel 12 cores i7. An early stopping criterion was used to monitor the validation loss and prevent over-fitting. Finally, during the prediction phase and depending on the trajectory length, a combination of the different models was used to predict the outcome. Any track with a length below 100 was predicted with the model trained with 50 time points (denoted model50), any length falling between 100 and 300 with model200, between 300 and 500 with model400 and above 500 with model600. This approach would increase the accuracy of the prediction when the variety of trajectory length would be very diverse in a dataset. Tasks:
        </p>
        <p>T1, T2</p>
        <p>To further improve the model performance, 5-Fold cross validation is utilized. However, due to the time limit of this competition, we only use a 3-fold average. On the other hand, by analyzing an external validation dataset containing 100000 1D trajectories, the predicted results for challenge data are multiplied by 1.011 and finally clipped to ensure reasonable predictions. The methods for 2D and 3D tasks are both based on the solution for 1D trajectories. We separate the dimensions of the trajectories and treat the data of each dimension as 1D trajectories. Thus, we get predicted exponents αx, αy, and αz for x, y, and z dimensions, respectively. The final results are α2D = (αx + αy)/2 for 2D trajectories, and α3D = (αx + αy + αz)/3 for 3D trajectories. Tasks: T1</p>
        <p>Team Our model (convLSTM) consists of a convolutional block (ConvBlock), a bidirectional LSTM, and a linear block (LinearOuts). The ConvBlock consists primarily of two one-dimensional convolutions with a filter size of two, each is followed by a ReLU. The first convolutional layer is more coarse and outputs 20 features, while the second layer takes the output of the first and outputs 64 features. At the end of the convolutional block, we have a dropout with dropout probability p = 0.2, to avoid overfitting, and a one-dimensional MaxPooling layer, which cuts the output size in half by selecting the larger of two adjacent entries. The bidirectional LSTM has three layers, each layer is followed by a dropout with probability of dropout p = 0.2. The final Block (LinearOuts) takes the flattened (2D tensor to 1D) output of the LSTM as its input and passes it to a fully connected linear layer, which has five output units that correspond to the five models used to produce the trajectories. The first two linear layers are followed by a ReLU activation and the final layer is not, as non-linearity is handled by an instance of 
            <rs type="software">nn.</rs>
            <rs type="software">CrossEntropyLoss</rs>, during training, called the "criterion". Training of our method for the AnDi challenge was done using a hidden size of 32 and a learn rate of 0.001. However, later testing has shown that our model accuracy can be improved by increasing the hidden size to 128, while beyond that point we see a drop in accuracy. Training was performed by merging two data sets, which were generated with the andi-datasets package, the first of length 189810 and the second of length 150000. The resulting combined dataset was split into 75% training data and 25% test data. From the training data an additional 20% was reserved for validation data to be used by our early stopping algorithm. Our early stopping method saves the parameter state if there is an improvement in the mean validation loss, which is computed at the end of each epoch. We used 100 epochs and 10 patience for our early stopping. Tasks:
        </p>
        <p>T1.1D for k = 1, 2. In addition, the correlation of absolute displacements obtained for t lag = 1 was also included, for a total of 15 features per trajectory. Features were standardized using the z-score over the training dataset. The mean and standard deviation obtained for each feature of the training dataset was saved and later used to standardize the validation and test datasets. For a training dataset of n trajectories and f features with target values T, the n × f feature matrix X is fed into an 
            <rs type="software">Extreme</rs> learning Machine composed by single hidden layer feedforward network (SLFN) with m = 1000 hidden nodes [11,12]. A matrix of initial weights W of size f × m and a bias vector b of size 1 × m are randomly initialized to connect observations to targets through:
        </p>
        <p>where f (•) represents the sigmoid activation function, u is a unitary vector of size n × 1, and B is the matrix of output weight. The training of the SFLN is converted into solving an over-determined linear problem, whose least squares solution corresponds to the Moore-Penrose pseudoinverse of the hidden layer matrix H [11,12] B = H † T.</p>
        <p>The SFLN was trained either as a regressor or as a classifier to provide predictions for T1 and T2 for 1D trajectories. Training was performed using only the dataset provided by the organizers (10000 trajectories per subtask) during the Development phase of the challenge. Training took typically 5 seconds on a MacBookPro with a 8-Core Intel Core i9 processor with 2.4GHz speed. Tasks: T1.1D, T2.1D We use a convolutional neural network structure adapted from the models used in Refs. [13,14]. For T1 and T2, this consists of a series of convolutional blocks, followed by a global max-pooling layer over the temporal dimension, which feeds into a dense network. For T1, the model outputs a single number representing the predicted anomalous exponent. For T2, the model outputs 5 numbers, representing a probability (from 0-1) for each diffusion type. For T3, convolutional blocks are followed by a 1 × 1 convolutional network, which outputs an array of size (1, n), where n is the number of steps in the trajectory, representing the probability of a switch at each position in the trajectory. The same network architectures can be used in 1D and higher dimensions, varying only the number of input features. Models were built using 
            <rs type="software">TensorFlow</rs> in Python, and 
            <rs type="software">code</rs> is available on Github.
        </p>
        <p>Training data were generated using the 
            <rs type="software">andi-</rs>datasets package. Trajectories were first preprocessed by taking the difference between successive positions, and normalized by dividing by the mean step size. For T1 and T2, a single model was simultaneously trained on trajectories of all lengths (ranging from 5-1000 steps). To permit mini-batch gradient descent with tracks of variable length, shorter tracks within each batch were padded with zeros to ensure a consistent input size (Note: padding is only necessary during training, and inference can be carried out with or without padding). For T3, training data consisted of trajectories 200-steps in length with a single changepoint, as per the challenge, but the method could be adapted to variable trajectory lengths and multiple changepoints. For all models, training was carried out with a batch size of 32 and an Adam optimizer with a learning rate of 0.001, until a performance plateau was reached (up to a maximum of 1.28 million trajectories, with each trajectory seen by the networks only once). Tasks:
        </p>
        <p>T1.1D, T1.2D, T2.1D, T2.2D, T3.1D, T3.2D Our method relies on at first analyzing the trajectories to extract features (and their statistics) such as the trajectory length, velocity (with sign and absolute value, different sampling rates), rate of variation, Fourier Transform, Power Spectral Density, autocorrelation function, time-averaged MSD, and wavelet transform, among others. This analysis is performed on each dimension separately. T2: These features are the inputs for a deep feed-forward neural network (5 categories, 2 hidden layers, 20 neurons per layer, trained with a 10 5 trajectory dataset) which classifies the model. The classification is then reprocessed in order by two similar neural networks (3 categories and 2 categories, instead of 5) that improve the precision on distinguishing among ATTM, FBM and SBM or between ATTM and CTRW, respectively. The combination of these three networks is our predictor for T2. T1: To estimate α, we use the arithmetic average of the outputs of two different methods based on neural networks. Briefly, in a first method, the result of the classification (T2) is added as an input to the list of features above. These new features become the inputs for a 1 × 4 tree of networks (2 hidden layers, 20 neurons, trained with 3e5 trajectory datasets), where the parent network has 4 equally spaced α categories (in the range 0.05 to 2). Each of these categories is then branched into a different network with 5 equally spaced α categories in the corresponding α range. The (overestimated) predicted value of α is the average value in that category. In a second method, the result of the classification is not used as an input but is used to split the data into 5 categories each one analyzed by a different network (architecture and training as above). In particular, the networks for ATTM and CTRW have 5 α categories in the range 0.05 to 1. The network for LW has 5 α categories in the range 1 to 2. Finally, the prediction for FBM and SBM is based on a 1 × 2 tree of networks with the parent network having 2 equally spaced categories in the range 0.05 to 2, each then refined by a 5-category network in the corresponding range. The (underestimated) predicted value of α is the average value of the corresponding α range. Tasks: T1, T2 Our approach is related to the feature-based methods described in Refs. [19][20][21], with an extended list of features used for extraction of the trajectories' characteristics. We used the gradient boosting algorithm in XGBoost (T1) and Gradient Boosting (T2) architectures. Such procedures allow us to examine trajectories with different lengths by extracting characteristics such as diffusion coefficient, anomalous diffusion exponent, fractal dimension, or gaussianity. The full set of features is listed in the Github repository. Each task and dimension gets a different set of features, depending on the problem behind the task. Both algorithms (Gradient Boosting, XGBoost) belong to the class of ensemble learning, i.e., methods that generate many base classifiers/regressors (decision trees in this case) and aggregate their results. We decided to use these classifiers as the idea behind the classifiers is easy to understand and interpret. The training was performed on 70000 trajectories generated using andi-datasets package (for each task and subtask). Each set was balanced with respect to the anomalous exponent value (T1) or the model (T2 The atoms are radially confined by a running wave optical trap. Axially the atoms are trapped within the sites of the lattice formed by two counterpropagating laser beams. During the experimental sequence, only the lattice potential is lowered, while the radial confinement is held constant at all times. This allows one to limit the diffusion of the atoms along the lattice axis, justifying an effective one-dimensional description.</p>
    </text>
</tei>
