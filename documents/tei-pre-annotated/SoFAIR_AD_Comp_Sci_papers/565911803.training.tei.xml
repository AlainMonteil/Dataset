<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T11:35+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>The advent of generative artificial intelligence (AI) offers transformative potential in the field of education. The study explores three main areas: (1) How did ChatGPT answer questions related to science education? (2) What are some ways educators could utilise ChatGPT in their science pedagogy? and (3) How has ChatGPT been utilised in this study, and what are my reflections about its use as a research tool? This exploratory research applies a self-study methodology to investigate the technology. Impressively, ChatGPT's output often aligned with key themes in the research. However, as it currently stands, ChatGPT runs the risk of positioning itself as the ultimate epistemic authority, where a single truth is assumed without a proper grounding in evidence or presented with sufficient qualifications. Key ethical concerns associated with AI include its potential environmental impact, issues related to content moderation, and the risk of copyright infringement. It is important for educators to model responsible use of ChatGPT, prioritise critical thinking, and be clear about expectations. ChatGPT is likely to be a useful tool for educators designing science units, rubrics, and quizzes. Educators should critically evaluate any AI-generated resource and adapt it to their specific teaching contexts. ChatGPT was used as a research tool for assistance with editing and to experiment with making the research narrative clearer. The intention of the paper is to act as a catalyst for a broader conversation about the use of generative AI in science education.</p>
        <p>Artificial intelligence (AI) is playing a crucial role in the ever-increasing digitisation of society. AI's capability to automate tasks, process large quantities of data, and provide predictive insights will increasingly revolutionise various aspects of our daily lives (Yang, 2022). Previously, AI has been described as technology that has the capacity to mimic human-like responses, such as reasoning, exercising judgement, and exhibiting intentionality (Shubhendu &amp; Vijay, 2013). Technological advancements such as machine learning and neural networks have sparked further discussion about how to define AI (Wang, 2019). The challenge … "is to specify the parameters of artificiality, or the ways in which computers are unlike human intelligence. They are much less than human intelligence-they can only calculate. And they are much more-they can calculate larger numbers and faster than humans. We have cause to be in awe at the super-human brilliance of their feats of calculation" (Cope et al., 2021(Cope et al., , p. 1230). Discourse about the potential societal impact of AI has recently been attracting significant attention. For instance, there have been increasing concerns about significant job losses and debates about classifying AI output as art (e.g. WALL-E 2, Midjourney) (Pavlik, 2023). Discussions around the use of AI, like in other fields, are mostly in the early stages. Celik (2023) claims that educators have not maximised the potential of AI in teaching and learning contexts. It has even been described as the "Cinderella of the AI story", alluding to its underdeveloped and often ignored status in education (Lameras &amp; Arnab, 2021). Despite calls for further uptake, some educators are resistant to using software that collects large amounts of student data and, moreover, sceptical of companies that present technology as a panacea for all educational issues (Stockman &amp; Nottingham et al., 2022). This research focuses on an AI platform called ChatGPT. It has garnered worldwide attention and captured the public zeitgeist.</p>
        <p>Large language models are a form of generative AI that produces human-like language (OpenAI, 2023a). OpenAI trains its text-generating models using machine learning algorithms on large amounts of text, including books, news articles, websites, and Wikipedia (Scharth, 2022). By processing terabytes of data, models acquire the patterns and structure of language, enabling them to provide users with relevant and meaningful content in response to their requests. When I asked 
            <rs type="software">ChatGPT</rs> to describe itself (prompt-Describe Chat-GPT), it generated the following italicised text:
        </p>
        <p>
            <rs type="software">ChatGPT</rs> is a language model developed by 
            <rs type="creator">OpenAI</rs>. It is a variant of the GPT (Generative Pre-training Transformer) model, which is trained on a massive amount of text data to generate human-like text. It can be used for a variety of natural language processing tasks, such as language translation, text summarization, question answering, and also for chatbot applications. It can understand and respond to human inputs in a conversational way, making it well suited for interactive applications. 
            <rs type="software">ChatGPT</rs> can be fine-tuned on specific data sets and task, which means it can be customized to perform specific task and generate outputs that are more accurate and useful.
        </p>
        <p>ChatGPT can… "write stories, give life advice, even compose poems and code computer programs" (Scharth, 2022, para. 2). There have been reports however that it… "produces fake citations and reproduces biases that exist in the literature" (Gleason, 2022, para. 7). According to cited ChatGPT output, "AI systems can perpetuate biases that are present in the data they are trained on. This can lead to unequal and unfair outcomes for students, particularly if the bias is related to factors such as race, gender, or socio-economic status" (Zhai, 2022, p. 7). OpenAI (2023b) acknowledge in their advice to educators that… "ChatGPT may produce content that perpetuates harmful biases and stereotypes, sometimes in subtle ways… the model is generally skewed towards content that reflects Western perspectives and people" (para. 18).</p>
        <p>
            <rs type="software">ChatGPT</rs> has gone viral on social media, and anecdotal evidence suggests that students are already familiar with it. It is safe to assume that undergraduate students are using 
            <rs type="software">ChatGPT</rs> or a similar software. Given 
            <rs type="software">ChatGPT</rs>'s apparent usage and stakeholder concerns, it is crucial to evaluate its output about science education. As far as I am aware, there has been no prior research that has examined the text generated by 
            <rs type="software">ChatGPT</rs> in relation to science education topics or its potential applications to create science teaching resources. Also, there is little written about its utilisation as a research tool, especially in STEM education contexts. This presents as a significant and timely research gap to address.
        </p>
        <p>Inspired by Pavlik's (2023) Research question 2 of this study asks: What are some ways educators could utilise ChatGPT in their science pedagogy? For example, how might it design a science unit using the 5Es model, or how could it design a rubric to use in my science classroom? How might it generate a multiple-choice quiz with an answer key?</p>
        <p>Research question 3 of this study asks: How has ChatGPT been utilised in this study, and what are my reflections about its use as a research tool? "All tools do more than human minds and bodies can achieve unaided, which is why we create and use them" (Cope et al., 2021(Cope et al., , p. 1230)). Positioning the AI as a research tool, I will reflect on its use in the present study. This is exploratory research; the intention is to document my experiences with ChatGPT and to reflect on its possible implications. This exploratory study applies a self-study methodology to investigate the technology (Hamilton et al., 2009). Through this study, I acknowledge that aspects of my educator and researcher identities have influenced the kinds of AI prompts I am interested in posing. As part of my exploration, I critically analyse ChatGPT output about science education, comparing it to key themes in the research. Moreover, I am eager to investigate the practical applications of using it for the classroom. Anecdotally, educators are already utilising ChatGPT to teach science. As discussed earlier, I am also interested in the application of ChatGPT as a tool for researchers.</p>
        <p>The text italicised below has been directly copied from ChatGPT. It is important to remember that the following results are a moment-in-time response, meaning the same questions could be entered into ChatGPT and you may get a different response. The responses below were collected in January 2023. Let us compare ChatGPT's response above to seminal research discussing characteristics of effective science teaching. Hackling and Prain (2005) report six elements including:</p>
        <p>1. Students experience a curriculum that is relevant to their lives and interests. 2. Classroom science is linked with the broader community. 3. Students are actively engaged with inquiry, ideas, and evidence. 4. Students are challenged to develop and extend meaningful conceptual understandings. 5. Assessment facilitates learning and focuses on outcomes that contribute to scientific literacy. 6. Information and communication technologies are exploited to enhance the learning of science with opportunities to interpret and construct multimodal representations (p. 19).</p>
        <p>Both lists stress the importance of inquiry-based learning, real-world connections, differentiation of instruction, the use of technology to enhance science learning, the importance of effective assessments, and student-led, collaborative science learning. The first list by ChatGPT mentions the importance of professional development while the second list by Hackling et al. makes no explicit mention of this. It does however stress the importance of connecting science learning with the broader community, which is less obvious in the ChatGPT response (e.g. real world connection). Overall, there seems strong alignment between the two lists.</p>
        <p>[ChatGPT Prompt 2]: Should I Use Chalk and Talk to Teach Science or Embrace More Student-Centred Pedagogies?</p>
        <p>Both "chalk and talk" teaching, where the teacher primarily lectures and writes on the board, and student-centred pedagogies, which put the focus on the student's own learning and discovery, have their own advantages and disadvantages.</p>
        <p>"Chalk and talk" teaching can be effective for introducing new concepts and providing a clear structure for the material. However, it can also be less engaging for students and may not allow for enough student interaction and active learning.</p>
        <p>On the other hand, student-centred pedagogies such as inquiry-based learning, project-based learning and problembased learning, allow students to take an active role in their own learning, encouraging them to ask questions, explore, and discover new concepts on their own. This type of teaching has been shown to be more engaging for students and can lead to better retention of the material.</p>
        <p>It is important to note that a good science teaching should aim to be a balance between the teacher-centred and studentcentred pedagogies.</p>
        <p>It can be beneficial to use a variety of teaching methods in the classroom, such as incorporating hands-on activities, group work, and discussions to supplement traditional lectures. This can help to keep students engaged and promote active learning. Additionally, allowing for student choice and incorporating real-world connections can help to make the material more relevant and interesting to students.</p>
        <p>The response balances the different pedagogical approaches to teaching science. Its output defines "chalk and talk" as a process whereby the teacher primarily lectures and writes on the board… 'chalk and talk' teaching can be effective for introducing new concepts. The former is more closely aligned with a teaching model that emphasises direct instruction (Kirschner et al., 2006). The output also details the benefits of inquiry-based, student-centred models of science education (Rannikmäe et al., 2020), stating that this type of teaching has been shown to be more engaging for students and can lead to better retention of the material. Later, ChatGPT discusses the importance of aiming for a balance between teacher-centred and studentcentred pedagogies. Where is the evidence base to support a balance? I also wonder about the importance of context? (e.g. individual student needs, school profile/priorities). We will elaborate on these points later.</p>
        <p>Failing in Science, Should I Care?</p>
        <p>Yes, as a teacher it's important to care if a student is failing in science because it can have a significant impact on their academic and future career opportunities. Failing in science can indicate that a student may be struggling with the material and may need additional support or different teaching methods.</p>
        <p>It's important to identify the reasons why the student is failing and address the underlying issues. This could include providing additional support such as tutoring, adjusting teaching methods to better suit the student's learning style, or providing opportunities for hands-on, inquiry-based learning.</p>
        <p>It's also important to communicate with the student's parents or guardians and work together to develop a plan to support the student's success in science. Additionally, creating a positive and encouraging classroom environment can help to motivate the student to improve their performance in science.</p>
        <p>In addition, it's important to recognize that students may fail for a variety of reasons, such as lack of interest, lack of prior knowledge or skills, or other personal issues. Therefore, it's important to be understanding and supportive and not to blame the student for their failure but instead, help them to overcome the obstacles and achieve their goals.</p>
        <p>There are several helpful suggestions in the ChatGPT response that align with the research literature. For instance, ensuring more opportunities for student-centred learning (Kang &amp; Keinonen, 2017), working with guardians or caregivers to support student learning (Archer et al., 2013;Gorard &amp; See, 2009), and fostering a supportive learning environment (Du &amp; Wong, 2019). • Begin the unit by posing a real-world problem related to energy sources such as "How can we ensure a sustainable future for our community?"</p>
        <p>• Show a video or pictures of a community facing energy challenges, such as a power outage during a heatwave, or an oil spill • Encourage students to brainstorm and share their prior knowledge about energy sources Explore:</p>
        <p>• Divide the class into small groups and assign each group a different renewable or non-renewable energy source to research. Explain:</p>
        <p>• Have each group present their findings to the class, using visual aids and hands-on activities to help explain the concepts • Encourage class discussion and questions • Provide additional support and resources for students who are struggling with the material, such as providing a graphic organiser or a template for the presentation Elaborate:</p>
        <p>• Students will work in groups again to create a proposal for a sustainable energy plan for their community.</p>
        <p>• Provide a list of criteria that their plan must meet such as cost-effectiveness, environmental impact, and reliability. • Provide additional support and resources for students who are struggling with the material, such as providing a sample proposal or a step-by-step guide to creating the plan.</p>
        <p>Evaluate:</p>
        <p>• Have students self-assess their understanding and participation in the unit using a rubric</p>
        <p>• Have students peer-assess the presentations and plans of other groups • Have the teacher provide feedback and grades on the final plan.</p>
        <p>This teaching unit allows students to actively engage in the learning process, explore and research the subject, explain their findings, elaborate a plan, evaluate their understanding and participation and debate about the best energy source for the community. The unit provides support and scaffolding for students who are struggling with the material, while also challenging students who have a strong understanding of the topic to think critically and apply their knowledge to real-world scenarios.</p>
        <p>The 5Es model (Bybee, 2002) is a popular teaching model used by schools and influential in pre-service teacher courses globally. One might imagine how it could be used by an educator as a catalyst for ideas, to move beyond a blank page, when designing a science unit. Example learning experiences in the output above seem mostly underpinned by a social-constructivist pedagogy (e.g. students sharing prior knowledge, working in groups to create a proposal, classroom debates, and opportunities for students to assess their own and peer presentations). As discussed, context is crucial. I can see it as a helpful tool for teachers as a starting point who then should consider their own teaching contexts (e.g. student needs, school profile, curriculum, access to resources). It is important that educators are critical about the ChatGPT output, deleting parts that are not helpful and building on elements that are. While the unit certainly needs refining, I suspect many educators will find this feature in ChatGPT helpful. Early career teachers and pre-service teachers may find the use of ChatGPT especially helpful for teaching resources because they are less likely to have an extensive bank of trusted resources.</p>
        <p>This rubric can be used by students to self-assess their learning about renewable and non-renewable energy sources, it can be used to evaluate their understanding of the concepts, research, critical thinking, and participation. Each criteria will have a scale of four levels: exemplary, proficient, developing and emerging. The students can check the level that they think they have reached on each criteria and then have a teacher or peer review and feedback on their self-assessment.</p>
        <p>I see some potential for the use of ChatGPT to help with rubric design (Table 1). As you can see from the question I asked ChatGPT, it self-identified rubric criteria (e.g. understanding, research, participation). The rubric categories make a distinction between levels (e.g. exemplary, proficient) but are too vague to identify specific indicators in each category. This might suit some educators. Others might add further detail and use the ChatGPT response as a starting point, in a similar way to the unit design discussed earlier.</p>
        <p>What is a renewable energy source? (a) An energy source that can never be depleted (b) An energy source that is not replenished by natural processes (c) An energy source that can be replenished by natural processes (d) An energy source that is not produced by natural processes What are the three main types of renewable energy sources? What is a non-renewable energy source?</p>
        <p>(a) An energy source that can be replenished by natural processes (b) An energy source that is not replenished by natural processes (c) An energy source that is not produced by natural processes This quiz assesses the student's understanding of the concept of Renewable and Non-Renewable Energy Sources, it includes multiple-choice questions that test their knowledge of the definition of Renewable and Non-renewable energy sources.</p>
        <p>I asked ChatGPT a series of questions broadly related to science education. It is worth acknowledging that its capacity to emulate human-like responses is nothing short of extraordinary. Broadly speaking, the ChatGPT response commonly aligned with key research themes in the literature. As discussed, the AI output in both prompts 1 and 3 highlighted strong synergies between the ChatGPT response and key themes in the research. Despite this, a major criticism of its current design is the absence of evidence to support its output. As it currently stands, ChatGPT runs the risk of positioning itself as the ultimate epistemic authority, where a single truth is assumed, without a proper grounding in evidence or presented with sufficient qualifications. The response to prompt 2 highlights the problematic absence of evidence, where the AI stated it was important to aim for a balance between teacher-centred and student-centred pedagogies. As stated earlier, where is the recognition of context? Where is the evidence base? Even when ChatGPT is prompted to provide references, it has been reported that… "it continually provides false and misleading references. To make matters worse, it will often provide correct references to papers that do exist and mix these in with incorrect references and references to non-existent papers… The question is, when does it give good answers and when does it give garbage answers?" (Buchanan, 2023, para. 1-3). Science educators, who prioritise evidence-based explanations in their own teaching, may find the current design of ChatGPT problematic.</p>
        <p>Beyond its narrow framing of truth, its output is based on… "argumentum ad populum-it considers to be true what is repeated the most" (Darics &amp; Poppel, 2023, para. 4). As discussed, the model is generally skewed towards content that reflects Western perspectives and people. Whose voices are silenced by the algorithm? Who is the author, and what is their bias? These are critical questions for educators, as well as students, to think carefully about.</p>
        <p>Although this paper does not extensively probe the ethical implications related to ChatGPT, it may be valuable to discuss the matters listed below with students who are exploring its use or AI in general. One consideration is the potential environmental impact of AI platforms. Although the information is not readily available on ChatGPT, machine learning models require substantial processing power, and data centres hosting cloud networks must be effectively cooled (Boudreau, 2023;Wu et al, 2022). It was also reported that Kenyan workers were paid about $2 per hour to work as content moderators for systems associated with the creation of ChatGPT, sifting through disturbing content like sexual abuse, hate speech, and violence (Perrigo, 2023). The use of large language models such as ChatGPT also raises questions about the potential for copyright infringement when generated text resembles or copies existing content (Karim, 2023). Apart from these broader concerns, there are other considerations for how students use AI. For instance, is it okay for students to reference ChatGPT verbatim in an assessment? Given my previous discussion about its lack of evidence, I have instructed students in my classes not to. Students may first generate essay text in ChatGPT and subsequently insert key references mentioned in class. I do not know how I feel about this, it does not quite sit well with me. Instead of allowing research to drive the argument, it seems more like an essay hack. Matching an AI-generated narrative with research to legitimise it.</p>
        <p>I am interested in the potential of ChatGPT to be used as (1) a learning scaffold for learning new concepts (before supporting students to engage with more traditional stimuli, such as an academic journal or textbook) and its potential to (2) help students who are not strong writers. For instance, I have modelled prompts students can enter to get a broad overview of a concept (e.g. ChatGPT prompt-Imagine I am an undergrad student, make some bullet points about [phenomena]). I suspect that for students who find it difficult to write, it will be helpful in overcoming writer's block. To demonstrate to students the advantages of using ChatGPT to improve their writing, again, I have modelled prompts (e.g. ChatGPT prompt-rewrite: [paste your text here]). It is important for stakeholders to carefully consider how AI impacts the design of, and completion of, assessments and pre-service teacher programmes more broadly. Prioritising student's critical thinking, critiquing ethical issues related to the use of AI systems, modelling its responsible use, and being clear about expectations for its use in assessments seems like a good place to start a broader conversation. Beyond large language models, educators need to consider generative AI more broadly (e.g. image, audio, video etc.). The ability to think critically as an educator is now more important than ever, an essential element of a science teacher's toolkit. In an age of social media echo chambers, climate change scepticism, and uncertainty about sources of evidence and "truth(s)", the emergence of generative AI introduces further complexity.</p>
        <p>In this part of the study, I was interested in exploring how educators might draw on its use of ChatGPT. Its output to prompts 4, 5, and 6 illustrates ways ChatGPT can be helpful to generate ideas when designing science units, rubrics, and quizzes. I was particularly impressed by its capacity to generate a science unit underpinned by the 5Es model, even if some of the output seemed a little generic and in need of further refinement. The output embedded the science topic (renewable and non-renewable energy sources) within a pedagogical framework (the 5Es). Again, however, educators need to critically evaluate any resources and adapt it to their specific context. Teacher's expertise, experience, and understanding of their students remain key to making sound pedagogical decisions. AI does not replace the expertise of the science teacher (yet).</p>
        <p>As part of my research exploration, I was interested in using 
            <rs type="software">ChatGPT</rs> as a research tool in the present study. It has been reported that some scientists are already…. "using chatbots as research assistants-to help organize their thinking, generate feedback on their work, assist with writing code and summarize research literature" (Nature, 2023, p. 612). The large bulk of its use in this research was assistance with editing. There were sentences that I asked 
            <rs type="software">ChatGPT</rs> to rewrite (
            <rs type="software">ChatGPT</rs> prompt-rewrite: [paste sentence]) at different stages of the paper to help with phrasing, flow, and word choice. Researchers who tend to write excessively long or complicated sentences could use ChatGPT to clarify their message. Certain sentences, however, had better phrasing prior to being entered into 
            <rs type="software">ChatGPT</rs>, while others were improved after a rewrite by the AI. When composing this paper, I kept a browser window open, experimenting with the possibilities of making my research narrative clearer.
        </p>
        <p>There is presently a debate among journal editors, researchers, and publishers regarding the role of such AI tools in published literature and whether it is acceptable to attribute authorship to the bot (Stokel-Walker, 2023). Nature, along with all Springer Nature journals, has formulated two key principles to their existing guidelines for authors in response to the rise of ChatGPT. The first principle is that no large language model will be recognised as an accredited author because attribution carries accountability for the work, which AI tools cannot take such responsibility (Nature, 2023). "If ChatGPT deserves authorship, Microsoft Word deserves it, too, for providing us with the platform to organise and write documents more efficiently…. Excel, R, or Python deserve to be co-authors for calculating statistics or analysing data for a quantitative scientific publication" (Karim, 2023, para. 5). The second principle added to Nature's author guidelines is that researchers need to disclose their use of large language models in the methods or acknowledgements sections (Nature, 2023). Similar to how journals require statements about data availability or ethical research, authors may soon have the option to disclose their use of large language models or AI during the journal submission process. I suspect formatting guidelines about the use of ChatGPT input and output will become clearer soon as well. The addition of AI to the research process commonly means new rules and processes for investigators. Ultimately, transparency and clearer guidelines about the use of AI platforms in research are essential for advancing scientific knowledge.</p>
        <p>The emergence of generative AI is already having far-reaching implications for science educators. It seems like we are in the early stages of a seismic shift. This article is in no way intended to be a comprehensive discussion of its use, merely an exploratory study that hopefully acts as a catalyst for a broader conversation-how do generative AI tools, such as ChatGPT, fit into our research and teaching pedagogy? How do we feel about them? What feels right, what does not? How will generative AI platforms evolve? And what are the potential future implications for science educators? At this stage, I have more questions than answers.</p>
        <p>6. Assessment: Effective science teaching uses a variety of assessment methods to measure student understanding and provide feedback to guide instruction. This includes formative and summative assessments, as well as performancebased assessments. 7. Professional development: Effective science teaching requires ongoing professional development for teachers to stay current with the latest research, best practices and new technologies in the field of science education.</p>
        <p>• Students can use a variety of resources such as books, articles, videos, and websites to research their topic. • Provide additional support and resources for students who are struggling with the material, such as providing a more simplified version of the guiding questions or offering extra time for research.</p>
        <p>Funding Open Access funding enabled and organized by CAUL and its Member Institutions.</p>
        <p>All raw data published in the paper.</p>
        <p>Ethical Approval Not applicable.</p>
        <p>Consent to Participate Informed consent was obtained from all individual participants included in the study.</p>
        <p>The participant has consented to the submission of the case report to the journal.</p>
        <p>The author declares no competing interests.</p>
        <p>Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.</p>
        <p>Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </text>
</tei>
