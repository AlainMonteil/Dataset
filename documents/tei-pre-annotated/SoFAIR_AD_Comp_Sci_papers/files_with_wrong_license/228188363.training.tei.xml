<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-13T15:20+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>Dynamic interval multi-objective optimization problems (DI-MOPs) are very common in real-world applications. However, there are few evolutionary algorithms that are suitable for tackling DI-MOPs up to date. A framework of dynamic interval multi-objective cooperative co-evolutionary optimization based on the interval similarity is presented in this paper to handle DI-MOPs. In the framework, a strategy for decomposing decision variables is first proposed, through which all the decision variables are divided into two groups according to the interval similarity between each decision variable and interval parameters. Following that, two sub-populations are utilized to cooperatively optimize decision variables in the two groups. Furthermore, two response strategies, i.e., a strategy based on the change intensity and a random mutation strategy, are employed to rapidly track the changing Pareto front of the optimization problem. The proposed algorithm is applied to eight benchmark optimization instances as well as a multi-period portfolio selection problem and compared with five state-of-the-art evolutionary algorithms. The experimental results reveal that the proposed algorithm is very competitive on most optimization instances.Dynamic interval multi-objective optimization problems (DI-MOPs) are very common in real-world applications. However, there are few evolutionary algorithms that are suitable for tackling DI-MOPs up to date. A framework of dynamic interval multi-objective cooperative co-evolutionary optimization based on the interval similarity is presented in this paper to handle DI-MOPs. In the framework, a strategy for decomposing decision variables is first proposed, through which all the decision variables are divided into two groups according to the interval similarity between each decision variable and interval parameters. Following that, two sub-populations are utilized to cooperatively optimize decision variables in the two groups. Furthermore, two response strategies, i.e., a strategy based on the change intensity and a random mutation strategy, are employed to rapidly track the changing Pareto front of the optimization problem. The proposed algorithm is applied to eight benchmark optimization instances as well as a multi-period portfolio selection problem and compared with five state-of-the-art evolutionary algorithms. The experimental results reveal that the proposed algorithm is very competitive on most optimization instances.</p>
        <p>T HERE are various multi-objective optimization problems (MOPs) with the interval characteristic in real-word applications. Each of these optimization problems generally contains more than one objective conflicting with each other, and has the interval characteristic in at least one objective and (or) constraint. One representative instance is production planning in a steel-making continuous casting-hot rolling (SCC-HR) process [1]. The process can be formulated as an MOP with the interval characteristic. For this problem, there are various uncertainties in the production process, e.g., the processing time, the production leading time, to name a few, which are contained in such objectives as the throughput, the hot charge ratio, the utilization rate, and the additional cost, and embodied with intervals. Another typical instance is robot path planning. When planning the path of a robot, the workspace of the robot often involves various danger sources, such as fire, landmines and enemies. Given the fact that it is too expensive or even impossible to get the precise positions of these danger sources, decision-makers only know their ranges in most cases. Along this line, taking two performance metrics, i.e. the risk and the path distance, into consideration, the problem of robot path planning in the environment with uncertain danger sources can be formulated as a bi-objective optimization problem with interval parameters [2]. To illustrate the popularity of MOPs with the interval characteristic, let us investigate the reliability redundancy allocation problem. For this problem, the reliability of an individual component may be imprecise, and is generally represented with an interval, which results in an interval MOP where the reliability of the whole system and its cost are simultaneously optimized [3].T HERE are various multi-objective optimization problems (MOPs) with the interval characteristic in real-word applications. Each of these optimization problems generally contains more than one objective conflicting with each other, and has the interval characteristic in at least one objective and (or) constraint. One representative instance is production planning in a steel-making continuous casting-hot rolling (SCC-HR) process [1]. The process can be formulated as an MOP with the interval characteristic. For this problem, there are various uncertainties in the production process, e.g., the processing time, the production leading time, to name a few, which are contained in such objectives as the throughput, the hot charge ratio, the utilization rate, and the additional cost, and embodied with intervals. Another typical instance is robot path planning. When planning the path of a robot, the workspace of the robot often involves various danger sources, such as fire, landmines and enemies. Given the fact that it is too expensive or even impossible to get the precise positions of these danger sources, decision-makers only know their ranges in most cases. Along this line, taking two performance metrics, i.e. the risk and the path distance, into consideration, the problem of robot path planning in the environment with uncertain danger sources can be formulated as a bi-objective optimization problem with interval parameters [2]. To illustrate the popularity of MOPs with the interval characteristic, let us investigate the reliability redundancy allocation problem. For this problem, the reliability of an individual component may be imprecise, and is generally represented with an interval, which results in an interval MOP where the reliability of the whole system and its cost are simultaneously optimized [3].</p>
        <p>In practice, an uncertain optimization problem can also be modeled as stochastic programming [4], [5], [6] or fuzzy programming [7], [8], [9], [10] instead of interval programming. However, additional functions or information are required when formulating the problem, such as probability distribution in stochastic programming and membership functions in fuzzy programming. On the one hand, additional functions or information generally result in a complex model. On the other hand, much history information is required for describing probability distribution and membership functions, which is often hard to obtain. Furthermore, probability distribution and membership functions can be converted to intervals using the confidence level and cut set, respectively. On this circumstance, stochastic and fuzzy optimization problems can be transformed into interval optimization problems.In practice, an uncertain optimization problem can also be modeled as stochastic programming [4], [5], [6] or fuzzy programming [7], [8], [9], [10] instead of interval programming. However, additional functions or information are required when formulating the problem, such as probability distribution in stochastic programming and membership functions in fuzzy programming. On the one hand, additional functions or information generally result in a complex model. On the other hand, much history information is required for describing probability distribution and membership functions, which is often hard to obtain. Furthermore, probability distribution and membership functions can be converted to intervals using the confidence level and cut set, respectively. On this circumstance, stochastic and fuzzy optimization problems can be transformed into interval optimization problems.</p>
        <p>Interval programming is employed to tackle problems with the interval characteristic. These optimization problems generally contain a number of parameters represented with intervals [11], [12], [13], [14], and the left and right endpoints or the midpoints and radius of these intervals are known a priori. It is relatively easier to obtain an interval than a probability distribution or membership function. When tackling an interval MOP, previous studies generally convert it to a deterministic single-or multi-objective optimization problem [11], [15], [16], [17]. The converted problem, however, is largely different from the original one. In addition, for the same interval MOP, different transformation approaches generally bring about dif-ferent deterministic optimization problems. As a consequence, optimal solutions to these deterministic problems may be too diverse, which raises a big problem when selecting optimal solutions from a number of solution sets. Compared with the conversion approach, the direct approach can avoid losing valuable information and adding redundant information, thus obtaining more precise solutions.Interval programming is employed to tackle problems with the interval characteristic. These optimization problems generally contain a number of parameters represented with intervals [11], [12], [13], [14], and the left and right endpoints or the midpoints and radius of these intervals are known a priori. It is relatively easier to obtain an interval than a probability distribution or membership function. When tackling an interval MOP, previous studies generally convert it to a deterministic single-or multi-objective optimization problem [11], [15], [16], [17]. The converted problem, however, is largely different from the original one. In addition, for the same interval MOP, different transformation approaches generally bring about dif-ferent deterministic optimization problems. As a consequence, optimal solutions to these deterministic problems may be too diverse, which raises a big problem when selecting optimal solutions from a number of solution sets. Compared with the conversion approach, the direct approach can avoid losing valuable information and adding redundant information, thus obtaining more precise solutions.</p>
        <p>An MOP with changing ranges of interval parameters in at least one objective and (or) constraint over time is called as a dynamic interval multi-objective optimization problem (DI-MOP). Taking the problem of robot path planning as an example, the ranges of interval parameters will change when the positions of danger sources change over time. At this point, decision-makers should rapidly adjust the robot path so as to successfully fulfill a mission.An MOP with changing ranges of interval parameters in at least one objective and (or) constraint over time is called as a dynamic interval multi-objective optimization problem (DI-MOP). Taking the problem of robot path planning as an example, the ranges of interval parameters will change when the positions of danger sources change over time. At this point, decision-makers should rapidly adjust the robot path so as to successfully fulfill a mission.</p>
        <p>Different from traditional dynamic MOPs (DMOPs) with precise objectives, a DI-MOP generally has objectives with interval values, which makes previous approaches, e.g., selecting non-dominated solutions, detecting whether an optimization problem changes or not, and responding the change, unsuitable for this problem. In addition, an algorithm is required to have the capability of obtaining a set of solutions with good performance in convergence and distribution when the problem changes. As a result, it is meaningful and greatly needed to develop efficient approaches to solving DI-MOPs.Different from traditional dynamic MOPs (DMOPs) with precise objectives, a DI-MOP generally has objectives with interval values, which makes previous approaches, e.g., selecting non-dominated solutions, detecting whether an optimization problem changes or not, and responding the change, unsuitable for this problem. In addition, an algorithm is required to have the capability of obtaining a set of solutions with good performance in convergence and distribution when the problem changes. As a result, it is meaningful and greatly needed to develop efficient approaches to solving DI-MOPs.</p>
        <p>Various studies have shown that the co-evolutionary mechanism is beneficial to increasing the efficiency of an optimization process [18], [19]. A cooperative co-evolutionary algorithm (CCEA) generally decomposes an optimization problem with a large number of decision variables into a number of sub-problems with a small number of decision variables, with each being optimized by a sub-population. Each subpopulation seeks the optimal solutions for a sub-problem in the corresponding search space. A complete solution, i.e., the candidate to the original optimization problem, for a subpopulation is constructed by combining a best solution of the current sub-population with the best solutions of other subpopulations at each generation. Since CCEAs can significantly reduce the search space of a sub-population which is utilized to optimize a small number of decision variables, they are efficient when solving traditional DMOPs. For example, Goh and Tan presented a dynamic competitive-cooperative coevolutionary algorithm (dCOEA) to solve both static and dynamic MOPs, where all the decision variables are adaptively divided into a number of groups, and stochastic competitors are employed to track changing optimal solutions [20]. Two approaches to large-scale multi-objective optimization were proposed in [21] and [22]. One is to solve an MOP with many decision variables, called an evolutionary algorithm for largescale many-objective optimization (LMEA), which divides the decision variables into distance-and diversity-related groups using a clustering approach [21]. The other is an MOEA based on decision variable analyses (MOEA/DVAs) for large-scale MOPs [22], which groups the decision variables according to the contribution of a decision variable to convergence (i.e., the distance to the PF), diversity, or both. But a large number of function evaluations are consumed before the optimization, especially for an optimization problem with a large number of decision variables. It is not suitable for a dynamic problem, which requires an algorithm with the capability in rapidly responding to environmental changes. The proposed decomposition strategy, however, does not take the influence of changing parameters on the decision variables into consideration. Following the influence of the time scale on the decision variables, we divided all the decision variables into two groups [23], among which one contains decision variables interrelated with the time scale, and the other does not. When cooperatively optimizing the decision variables of the two groups using two sub-populations, we employed different prediction strategies to generate the initial population for different sub-populations, with the purpose of rapidly responding to the change of the optimization problem. The above methods focus mainly on real value problems and do not take interval objectives into account, hence incapable to tackle DI-MOPs. Further analyses can be found in Subsections III.C and III.D.Various studies have shown that the co-evolutionary mechanism is beneficial to increasing the efficiency of an optimization process [18], [19]. A cooperative co-evolutionary algorithm (CCEA) generally decomposes an optimization problem with a large number of decision variables into a number of sub-problems with a small number of decision variables, with each being optimized by a sub-population. Each subpopulation seeks the optimal solutions for a sub-problem in the corresponding search space. A complete solution, i.e., the candidate to the original optimization problem, for a subpopulation is constructed by combining a best solution of the current sub-population with the best solutions of other subpopulations at each generation. Since CCEAs can significantly reduce the search space of a sub-population which is utilized to optimize a small number of decision variables, they are efficient when solving traditional DMOPs. For example, Goh and Tan presented a dynamic competitive-cooperative coevolutionary algorithm (dCOEA) to solve both static and dynamic MOPs, where all the decision variables are adaptively divided into a number of groups, and stochastic competitors are employed to track changing optimal solutions [20]. Two approaches to large-scale multi-objective optimization were proposed in [21] and [22]. One is to solve an MOP with many decision variables, called an evolutionary algorithm for largescale many-objective optimization (LMEA), which divides the decision variables into distance-and diversity-related groups using a clustering approach [21]. The other is an MOEA based on decision variable analyses (MOEA/DVAs) for large-scale MOPs [22], which groups the decision variables according to the contribution of a decision variable to convergence (i.e., the distance to the PF), diversity, or both. But a large number of function evaluations are consumed before the optimization, especially for an optimization problem with a large number of decision variables. It is not suitable for a dynamic problem, which requires an algorithm with the capability in rapidly responding to environmental changes. The proposed decomposition strategy, however, does not take the influence of changing parameters on the decision variables into consideration. Following the influence of the time scale on the decision variables, we divided all the decision variables into two groups [23], among which one contains decision variables interrelated with the time scale, and the other does not. When cooperatively optimizing the decision variables of the two groups using two sub-populations, we employed different prediction strategies to generate the initial population for different sub-populations, with the purpose of rapidly responding to the change of the optimization problem. The above methods focus mainly on real value problems and do not take interval objectives into account, hence incapable to tackle DI-MOPs. Further analyses can be found in Subsections III.C and III.D.</p>
        <p>In addition, a non-dominated solution to an interval MOP may not be non-dominated in the scenario of a DI-MOP due to the changing ranges of interval parameters. Consequently, issues are expected to address when solving a DI-MOP, including accurately detecting the change of the optimization problem, rapidly tracking the changing Pareto front (PF), and timely providing candidates with good performance in diversity and approximation.In addition, a non-dominated solution to an interval MOP may not be non-dominated in the scenario of a DI-MOP due to the changing ranges of interval parameters. Consequently, issues are expected to address when solving a DI-MOP, including accurately detecting the change of the optimization problem, rapidly tracking the changing Pareto front (PF), and timely providing candidates with good performance in diversity and approximation.</p>
        <p>In this study, we focus on DI-MOPs, and a framework of dynamic interval multi-objective cooperative co-evolutionary optimization based on the interval similarity is presented to handle them. In the framework, a strategy for decomposing decision variables is first proposed, through which all the decision variables are divided into two groups according to the interval similarity between each decision variable and interval parameters. Following that, two sub-populations are utilized to cooperatively optimize decision variables in the two groups. Furthermore, two response strategies, i.e., a strategy based on the change intensity and a random mutation strategy, are employed to rapidly track the changing Pareto front of the optimization problem.In this study, we focus on DI-MOPs, and a framework of dynamic interval multi-objective cooperative co-evolutionary optimization based on the interval similarity is presented to handle them. In the framework, a strategy for decomposing decision variables is first proposed, through which all the decision variables are divided into two groups according to the interval similarity between each decision variable and interval parameters. Following that, two sub-populations are utilized to cooperatively optimize decision variables in the two groups. Furthermore, two response strategies, i.e., a strategy based on the change intensity and a random mutation strategy, are employed to rapidly track the changing Pareto front of the optimization problem.</p>
        <p>More specifically, this paper has the following four-fold contributions:More specifically, this paper has the following four-fold contributions:</p>
        <p>(1) Providing a cooperative co-evolutionary optimization framework for tackling DI-MOPs; (2) Presenting strategies for grouping decision variables of a DI-MOP and detecting its change according to the interval similarity; (3) Defining the change intensity of an optimization problem and proposing a response strategy based on it, and (4) Experimentally investigating the performance of the proposed algorithm based on a set of benchmark problems and applying the proposed algorithm to a multi-period portfolio selection problem. The rest of this paper is structured as follows. Section II provides a comprehensive review on the related work. The proposed framework of dynamic interval multi-objective cooperative co-evolutionary optimization based on the interval similarity is detailed in Section III. The experimental setting and results are reported and analyzed in Section IV. Finally, Section V concludes the whole paper and points out several topics for future study.(1) Providing a cooperative co-evolutionary optimization framework for tackling DI-MOPs; (2) Presenting strategies for grouping decision variables of a DI-MOP and detecting its change according to the interval similarity; (3) Defining the change intensity of an optimization problem and proposing a response strategy based on it, and (4) Experimentally investigating the performance of the proposed algorithm based on a set of benchmark problems and applying the proposed algorithm to a multi-period portfolio selection problem. The rest of this paper is structured as follows. Section II provides a comprehensive review on the related work. The proposed framework of dynamic interval multi-objective cooperative co-evolutionary optimization based on the interval similarity is detailed in Section III. The experimental setting and results are reported and analyzed in Section IV. Finally, Section V concludes the whole paper and points out several topics for future study.</p>
        <p>Without loss of generality, a DI-MOP can be formulated as follows.Without loss of generality, a DI-MOP can be formulated as follows.</p>
        <p>where x -an n-dimensional decision vector; c(t)where x -an n-dimensional decision vector; c(t)</p>
        <p>-an m-dimensional interval parameter vector; F (x, c(t))-an m-dimensional interval parameter vector; F (x, c(t))</p>
        <p>-an objective vector;-an objective vector;</p>
        <p>-the i-th component of c(t) , which is a vector with l components;-the i-th component of c(t) , which is a vector with l components;</p>
        <p>-the right endpoint of c ik (t).-the right endpoint of c ik (t).</p>
        <p>Given the fact that c i (t) is an interval vector, f i (x, c i (t)) is an objective with its value being within an interval, denoted asGiven the fact that c i (t) is an interval vector, f i (x, c i (t)) is an objective with its value being within an interval, denoted as</p>
        <p>generally changes over the time scale. Specially, if c i (t) remains unchanged over time for any i, Eq. (1) will be degraded as a traditional interval MOP [24]. In addition, if c ik (t) = c ik (t) is held for any i and k, Eq. (1) will be degraded as a traditional DMOP [25]. From this viewpoint, the optimization problem formulated with Eq. ( 1) is an extension of previous optimization problems. As a result, studying approaches suitable for Eq. ( 1) is of considerable significance.generally changes over the time scale. Specially, if c i (t) remains unchanged over time for any i, Eq. (1) will be degraded as a traditional interval MOP [24]. In addition, if c ik (t) = c ik (t) is held for any i and k, Eq. (1) will be degraded as a traditional DMOP [25]. From this viewpoint, the optimization problem formulated with Eq. ( 1) is an extension of previous optimization problems. As a result, studying approaches suitable for Eq. ( 1) is of considerable significance.</p>
        <p>For two solutions,For two solutions,</p>
        <p>Limbourg and Aponte [24] defined the following order and dominance relations based on intervals.Limbourg and Aponte [24] defined the following order and dominance relations based on intervals.</p>
        <p>Definition 1: Order relation. The order relation betweenDefinition 1: Order relation. The order relation between</p>
        <p>The order relation, &lt; IN , is antisymmetric, reflexive, and transitive. As a result, it defines a partial order relation between intervals.The order relation, &lt; IN , is antisymmetric, reflexive, and transitive. As a result, it defines a partial order relation between intervals.</p>
        <p>Definition 2: Dominance relation based on intervals. x 1 is said to dominate x 2 based on intervals, denoted asDefinition 2: Dominance relation based on intervals. x 1 is said to dominate x 2 based on intervals, denoted as</p>
        <p>If neither x 1 dominates x 2 , nor x 1 is dominated by x 2 , x 1 and x 2 are non-dominated based on intervals, denoted as x 1 ||x 2 .If neither x 1 dominates x 2 , nor x 1 is dominated by x 2 , x 1 and x 2 are non-dominated based on intervals, denoted as x 1 ||x 2 .</p>
        <p>To obtain a diverse Pareto front, Limbourg and Aponte provided the definitions of the hyper-volume and crowding distance based on intervals [24]. Following the dominance relation and the crowding distance based on intervals, they proposed the following strategy for sorting solutions to (1). The dominance relation is first utilized to assign each solution with a unique rank. Then, for solutions with the same rank, the order relation is adopted to sort them according to their crowding distances. Finally, a random strategy is employed to sort solutions which cannot be distinguished by the above approach.To obtain a diverse Pareto front, Limbourg and Aponte provided the definitions of the hyper-volume and crowding distance based on intervals [24]. Following the dominance relation and the crowding distance based on intervals, they proposed the following strategy for sorting solutions to (1). The dominance relation is first utilized to assign each solution with a unique rank. Then, for solutions with the same rank, the order relation is adopted to sort them according to their crowding distances. Finally, a random strategy is employed to sort solutions which cannot be distinguished by the above approach.</p>
        <p>Various real-world applications can be formulated as interval optimization problems, such as optimal dispatch of a virtual power plant [26], aircraft wing and automobile design [27], [28], and household load scheduling [29]. As a result, seeking approaches suitable for addressing interval optimization problems is of great significance in theory and applications, and among which interval analysis is one of representative tools [30].Various real-world applications can be formulated as interval optimization problems, such as optimal dispatch of a virtual power plant [26], aircraft wing and automobile design [27], [28], and household load scheduling [29]. As a result, seeking approaches suitable for addressing interval optimization problems is of great significance in theory and applications, and among which interval analysis is one of representative tools [30].</p>
        <p>In recent years, utilizing evolutionary algorithms (EAs) to address interval MOPs has become a rapidly growing field, and a plenty of achievements have been obtained. Roughly, there are the following two ways to handle interval MOPs with EAs. One is converting an interval MOP to a deterministic single-or multi-objective optimization problem, followed by solving the converted one using EAs. Along this line, Cheng et al. first transformed an interval MOP into a mini-max optimization problem [31]. Then, they adopted a hierarchical algorithm composed of a genetic algorithm and a nonlinear programming approach to tackle the converted problem. Jiang et al. converted an interval MOP to a deterministic MOP based on the middle point and the width of an interval [32], and further converted it to a single-objective optimization without constraints which is tackled by an EA. We converted an interval MOP with hybrid indices to a deterministic MOP using such information as the middle point and the width of an interval [15], and employed NSGA-II [33] to address the converted problem. Sahoo et al. first formulated an MOP with interval parameters, followed by converting the model to a single-objective optimization problem and solving it using an improved EA [17]. In addition, Bhunia et al. first defined the interval ordering relation between solutions to an interval MOP. Then, they transformed the interval MOP into a deterministic single-objective optimization problem and tackled the converted problem using a hybrid EA [16]. Recently, focusing on an interval many-objective optimization problem, we first transformed it into a deterministic bi-objective problem, where new objectives are hyper-volume and imprecision. And then, a set-based genetic algorithm was proposed to tackle it [11].In recent years, utilizing evolutionary algorithms (EAs) to address interval MOPs has become a rapidly growing field, and a plenty of achievements have been obtained. Roughly, there are the following two ways to handle interval MOPs with EAs. One is converting an interval MOP to a deterministic single-or multi-objective optimization problem, followed by solving the converted one using EAs. Along this line, Cheng et al. first transformed an interval MOP into a mini-max optimization problem [31]. Then, they adopted a hierarchical algorithm composed of a genetic algorithm and a nonlinear programming approach to tackle the converted problem. Jiang et al. converted an interval MOP to a deterministic MOP based on the middle point and the width of an interval [32], and further converted it to a single-objective optimization without constraints which is tackled by an EA. We converted an interval MOP with hybrid indices to a deterministic MOP using such information as the middle point and the width of an interval [15], and employed NSGA-II [33] to address the converted problem. Sahoo et al. first formulated an MOP with interval parameters, followed by converting the model to a single-objective optimization problem and solving it using an improved EA [17]. In addition, Bhunia et al. first defined the interval ordering relation between solutions to an interval MOP. Then, they transformed the interval MOP into a deterministic single-objective optimization problem and tackled the converted problem using a hybrid EA [16]. Recently, focusing on an interval many-objective optimization problem, we first transformed it into a deterministic bi-objective problem, where new objectives are hyper-volume and imprecision. And then, a set-based genetic algorithm was proposed to tackle it [11].</p>
        <p>The other is tackling interval MOPs directly by EAs based on the interval dominance relation. Keeping this line in mind, Limbourg et al. defined an interval Pareto dominance relation based on the interval order relation when tackling an interval MOP [24]. In addition, they proposed an imprecision-propagating multi-objective evolutionary algorithm (IP-MOEA) to address the interval MOP. We proposed a Pareto dominance relation based on the interval possibility and interval crowding distance [34], [35]. Using them, we selected the optimal solutions to an interval MOP. Sun et al. presented an interval Pareto dominance relation based on the lower limit of a possibility, and employed it to modify NSGA-II to cope with interval MOPs [36]. Zhang et al. evaluated solutions using a probability dominance relation [37]. Goh and Tan calculated the probability with which a solution dominates another, and compared solutions based on the probability [38]. Karshenas et al. presented an α-degree Pareto dominance to discriminate solutions to an interval MOP [39]. In addition, Dou et al. presented the scheme of the interval hesitation dominance to distinguish solutions [40]. However, different dominance relations will derive different optimal solution sets for the same interval programming problem even though the identical algorithm is adopted. It is difficult to choose a favorable solution set for users. Bearing this characteristic in mind, Sun et al. integrated previous interval dominance rules in a framework through investigating the correlations of interval dominance rules, developing a strategy to reducing a rule set and assembling the reduced rules. As a result, users can utilize the proposed ensemble dominance to handle their interval programming models. Moreover, they will free themselves from choosing an appropriate approach to assess solutions [41], [42].The other is tackling interval MOPs directly by EAs based on the interval dominance relation. Keeping this line in mind, Limbourg et al. defined an interval Pareto dominance relation based on the interval order relation when tackling an interval MOP [24]. In addition, they proposed an imprecision-propagating multi-objective evolutionary algorithm (IP-MOEA) to address the interval MOP. We proposed a Pareto dominance relation based on the interval possibility and interval crowding distance [34], [35]. Using them, we selected the optimal solutions to an interval MOP. Sun et al. presented an interval Pareto dominance relation based on the lower limit of a possibility, and employed it to modify NSGA-II to cope with interval MOPs [36]. Zhang et al. evaluated solutions using a probability dominance relation [37]. Goh and Tan calculated the probability with which a solution dominates another, and compared solutions based on the probability [38]. Karshenas et al. presented an α-degree Pareto dominance to discriminate solutions to an interval MOP [39]. In addition, Dou et al. presented the scheme of the interval hesitation dominance to distinguish solutions [40]. However, different dominance relations will derive different optimal solution sets for the same interval programming problem even though the identical algorithm is adopted. It is difficult to choose a favorable solution set for users. Bearing this characteristic in mind, Sun et al. integrated previous interval dominance rules in a framework through investigating the correlations of interval dominance rules, developing a strategy to reducing a rule set and assembling the reduced rules. As a result, users can utilize the proposed ensemble dominance to handle their interval programming models. Moreover, they will free themselves from choosing an appropriate approach to assess solutions [41], [42].</p>
        <p>For a DMOP, an ideal optimization algorithm is expected to rapidly seek Pareto-optimal solutions before the problem changes, and a well-designed dynamic multi-objective optimization algorithm generally has good performance in convergence and diversity.For a DMOP, an ideal optimization algorithm is expected to rapidly seek Pareto-optimal solutions before the problem changes, and a well-designed dynamic multi-objective optimization algorithm generally has good performance in convergence and diversity.</p>
        <p>Various studies have focused on speeding up the convergence and maintaining a good diversity of EAs from the following two aspects. One is developing memory-based methods, which save relevant information of the current solutions, and employ it in the subsequent stages. Along this line, Goh et al. selected a number of non-dominated solutions from an archive, and re-evaluated them to obtain information for guiding the subsequent evolution [20]. In the immune clonal algorithm (ICA) for a DMOP [43], Shang et al. saved representative individuals as the initial population when the optimization problem changes, so as to accelerate the convergence. They also proposed an improved decompositionbased memetic algorithm in [44], and employed an archive to store the currently best solution in each decomposition direction during the search. The helpful information offered by the archive can assist in handling neighbor sub-problems by cooperation. Azzouz et al. proposed an adaptive strategy for managing hybrid populations with memory, local search and random strategies, to effectively tackle DMOPs, which guarantees a rapid convergence and good diversity [45]. Koo et al. proposed a selective memory technique, which selects a partial retrieval based on the diversity in the decision space to maintain effective memories [46]. Recently, Chen et al. focused on DMOPs with a time-variable number of objectives in [47], and proposed a dynamic two-archive EA, denoted as DTAEA, to address them. DTAEA simultaneously maintains two co-evolutionary populations, i.e., CA and DA, during the evolution, and CA and DA will be reconstructed as the environment changes. By a restricted mating selection mechanism, DTAEA takes full advantages of complementary influences of CA and DA, with the purpose of striking the balance between convergence and diversity. Additionally, they utilized a truncation operator to retrieve the most diverse subset of memories.Various studies have focused on speeding up the convergence and maintaining a good diversity of EAs from the following two aspects. One is developing memory-based methods, which save relevant information of the current solutions, and employ it in the subsequent stages. Along this line, Goh et al. selected a number of non-dominated solutions from an archive, and re-evaluated them to obtain information for guiding the subsequent evolution [20]. In the immune clonal algorithm (ICA) for a DMOP [43], Shang et al. saved representative individuals as the initial population when the optimization problem changes, so as to accelerate the convergence. They also proposed an improved decompositionbased memetic algorithm in [44], and employed an archive to store the currently best solution in each decomposition direction during the search. The helpful information offered by the archive can assist in handling neighbor sub-problems by cooperation. Azzouz et al. proposed an adaptive strategy for managing hybrid populations with memory, local search and random strategies, to effectively tackle DMOPs, which guarantees a rapid convergence and good diversity [45]. Koo et al. proposed a selective memory technique, which selects a partial retrieval based on the diversity in the decision space to maintain effective memories [46]. Recently, Chen et al. focused on DMOPs with a time-variable number of objectives in [47], and proposed a dynamic two-archive EA, denoted as DTAEA, to address them. DTAEA simultaneously maintains two co-evolutionary populations, i.e., CA and DA, during the evolution, and CA and DA will be reconstructed as the environment changes. By a restricted mating selection mechanism, DTAEA takes full advantages of complementary influences of CA and DA, with the purpose of striking the balance between convergence and diversity. Additionally, they utilized a truncation operator to retrieve the most diverse subset of memories.</p>
        <p>The other is designing prediction-based approaches, which predict optimal solutions based on historical information when the optimization problem changes. Zhou et al. proposed a method of re-initializing a population based on prediction [48]. The method first predicts the new positions of individuals based on information collected during previous searches, and the current population is then partially or completely replaced by the predicted individuals. This method has, however, deteriorative performance when the PS of an optimization problem changes nonlinearly over time. To improve the prediction accuracy, a method of hybrid diversity maintenance was proposed in [49], which firstly relocates a number of solutions close to the new Pareto front by prediction based on the moving direction of each center. Following that, it employs a gradual search to generate a number of well-distributed solutions in the decision space, so as to compensate for possible inaccuracies. To maintain the diversity of a population, the rest solutions are randomly generated. Moreover, Liu et al. proposed an improved prediction model to overcome this drawback [50]. In the proposed model, two individuals are selected to guide the newly predicted individuals, which is beneficial to preventing them from moving toward wrong directions [48]. In addition, Muruganantham et al. presented a dynamic MOEA by utilizing a Kalman filter (KF) to predict the new PF [51], which uses less information than the strategy proposed by Zhou. Furthermore, Rong et al. proposed a multidirectional prediction (MDP) strategy to enhance the performance of EAs in addressing a DMOP. They construct multiple time series models based on historical information to predict a number of evolutionary directions. Once an environmental change occurs, a part of the population is re-initialized by the prediction model, and the rest will be randomly generated [52].The other is designing prediction-based approaches, which predict optimal solutions based on historical information when the optimization problem changes. Zhou et al. proposed a method of re-initializing a population based on prediction [48]. The method first predicts the new positions of individuals based on information collected during previous searches, and the current population is then partially or completely replaced by the predicted individuals. This method has, however, deteriorative performance when the PS of an optimization problem changes nonlinearly over time. To improve the prediction accuracy, a method of hybrid diversity maintenance was proposed in [49], which firstly relocates a number of solutions close to the new Pareto front by prediction based on the moving direction of each center. Following that, it employs a gradual search to generate a number of well-distributed solutions in the decision space, so as to compensate for possible inaccuracies. To maintain the diversity of a population, the rest solutions are randomly generated. Moreover, Liu et al. proposed an improved prediction model to overcome this drawback [50]. In the proposed model, two individuals are selected to guide the newly predicted individuals, which is beneficial to preventing them from moving toward wrong directions [48]. In addition, Muruganantham et al. presented a dynamic MOEA by utilizing a Kalman filter (KF) to predict the new PF [51], which uses less information than the strategy proposed by Zhou. Furthermore, Rong et al. proposed a multidirectional prediction (MDP) strategy to enhance the performance of EAs in addressing a DMOP. They construct multiple time series models based on historical information to predict a number of evolutionary directions. Once an environmental change occurs, a part of the population is re-initialized by the prediction model, and the rest will be randomly generated [52].</p>
        <p>In addition to the aforementioned methods, Shang et al. combined a co-evolutionary competitive and cooperative operation in the immune clonal algorithm (ICA) for DMOPs to have good performance of solutions in uniformity and diversity [53], [54]. Qu differential evolution algorithms to cope with dynamic economic emission dispatch (DEED) problems [55], [56], and the experimental results demonstrated that the proposed algorithm is capable in speeding up convergence and effective in handling DEED problems.In addition to the aforementioned methods, Shang et al. combined a co-evolutionary competitive and cooperative operation in the immune clonal algorithm (ICA) for DMOPs to have good performance of solutions in uniformity and diversity [53], [54]. Qu differential evolution algorithms to cope with dynamic economic emission dispatch (DEED) problems [55], [56], and the experimental results demonstrated that the proposed algorithm is capable in speeding up convergence and effective in handling DEED problems.</p>
        <p>A. The general framework DI-MOPs have the following twofold characteristics: one is that each objective of a DI-MOP is an interval, and the other is that interval parameters in the objectives change over time. Aiming at these two characteristics, we propose a framework of dynamic interval multi-objective cooperative co-evolutionary optimization based on the interval similarity to handle DI-MOPs.A. The general framework DI-MOPs have the following twofold characteristics: one is that each objective of a DI-MOP is an interval, and the other is that interval parameters in the objectives change over time. Aiming at these two characteristics, we propose a framework of dynamic interval multi-objective cooperative co-evolutionary optimization based on the interval similarity to handle DI-MOPs.</p>
        <p>In the proposed framework, all the decision variables of an optimization problem are first decomposed according to the strategy proposed in Subsection III.C. Next, sub-populations cooperatively co-evolve with each sub-population evolving the decision variables in one group, and a complete solution is formed as described in Subsection III.F with its objective being the fitness of an individual to be evaluated. Following that, non-dominated solutions are selected, and saved in an archive. In addition, a strategy based on the interval similarity is employed to check whether the optimization problem changes or not, as described in Subsection III.D. If yes, the sub-populations will be re-initialized using the proposed response and perturbation strategies, respectively, as described in Subsection III.E. The above process will be repeated until a termination condition is met. The complete non-dominated solutions in the archive are finally output as the optimal solutions to the DI-MOP. Algorithm 1 provides the pseudo code of the framework.In the proposed framework, all the decision variables of an optimization problem are first decomposed according to the strategy proposed in Subsection III.C. Next, sub-populations cooperatively co-evolve with each sub-population evolving the decision variables in one group, and a complete solution is formed as described in Subsection III.F with its objective being the fitness of an individual to be evaluated. Following that, non-dominated solutions are selected, and saved in an archive. In addition, a strategy based on the interval similarity is employed to check whether the optimization problem changes or not, as described in Subsection III.D. If yes, the sub-populations will be re-initialized using the proposed response and perturbation strategies, respectively, as described in Subsection III.E. The above process will be repeated until a termination condition is met. The complete non-dominated solutions in the archive are finally output as the optimal solutions to the DI-MOP. Algorithm 1 provides the pseudo code of the framework.</p>
        <p>To fulfill this task, we first define the interval similarity as follows.To fulfill this task, we first define the interval similarity as follows.</p>
        <p>In [57], the authors provide a definition of interval similarity and its properties. The definition, however, is useless when an interval degrades as a real value. Therefore, we extend the definition and make it also suitable for real values.In [57], the authors provide a definition of interval similarity and its properties. The definition, however, is useless when an interval degrades as a real value. Therefore, we extend the definition and make it also suitable for real values.</p>
        <p>Definition 3: Interval similarity. For two intervals a = [a, a] and b = [b, b], their similarity, denoted as s(a, b), is defined as follows. In addition, we have the following observations. ( 1)Definition 3: Interval similarity. For two intervals a = [a, a] and b = [b, b], their similarity, denoted as s(a, b), is defined as follows. In addition, we have the following observations. ( 1)</p>
        <p>which is called transitive. Please refer to Subsection I.A in the supplementary material for the proofs of these observations.which is called transitive. Please refer to Subsection I.A in the supplementary material for the proofs of these observations.</p>
        <p>For a DI-MOP, a well-designed algorithm is generally expected to have good performance in convergence and diversity before the problem changes. For a solution to a DI-MOP, some of its components change over dynamic parameters, and the others remain unchanged. If we divide all the decision variables of a DI-MOP into two groups, and optimize decision variables in each group individually, the efficiency of solving the optimization problem will be improved to some degree. In [58], a differential grouping strategy is employed to discover the underlying interaction structure of the decision variables. However, the strategy cannot be directly utilized to detect the interaction between a decision variable and a parameter in a DI-MOP, especially when the parameter is an interval, due to its different characteristics with a real value. For example,For a DI-MOP, a well-designed algorithm is generally expected to have good performance in convergence and diversity before the problem changes. For a solution to a DI-MOP, some of its components change over dynamic parameters, and the others remain unchanged. If we divide all the decision variables of a DI-MOP into two groups, and optimize decision variables in each group individually, the efficiency of solving the optimization problem will be improved to some degree. In [58], a differential grouping strategy is employed to discover the underlying interaction structure of the decision variables. However, the strategy cannot be directly utilized to detect the interaction between a decision variable and a parameter in a DI-MOP, especially when the parameter is an interval, due to its different characteristics with a real value. For example,</p>
        <p>Inspired by the study in [58], we propose a variant of the above method based on the interval similarity in this study, with the purpose of efficiently tackling a DI-MOP.Inspired by the study in [58], we propose a variant of the above method based on the interval similarity in this study, with the purpose of efficiently tackling a DI-MOP.</p>
        <p>Definition 4: separable function. A function, f (x, c), is partially additively separable, if it has the following form:Definition 4: separable function. A function, f (x, c), is partially additively separable, if it has the following form:</p>
        <p>where f j (x j , c j ) is a function associated with x j and c j ,where f j (x j , c j ) is a function associated with x j and c j ,</p>
        <p>Please refer to Subsection I.B in the supplementary material for the detailed proof.Please refer to Subsection I.B in the supplementary material for the detailed proof.</p>
        <p>The grouping theory in [23] is a particular case as the parameter, c, is a real vector in the above theory.The grouping theory in [23] is a particular case as the parameter, c, is a real vector in the above theory.</p>
        <p>In [23] and [58], only one point is utilized to group the decision variables. However, the interval is characterized by two points, the left and the right endpoints. For interval optimization problems, if only one point is employed, information provided by the other endpoint will be lost, which results in inaccuracy. Taking a function, f (x, c(t)) = c(t)x, as an example, assume that c(t)= [1, 1+t] and δ=0.5. On this circumstance,In [23] and [58], only one point is utilized to group the decision variables. However, the interval is characterized by two points, the left and the right endpoints. For interval optimization problems, if only one point is employed, information provided by the other endpoint will be lost, which results in inaccuracy. Taking a function, f (x, c(t)) = c(t)x, as an example, assume that c(t)= [1, 1+t] and δ=0.5. On this circumstance,</p>
        <p>If only the left endpoints are utilized to measure the difference between ∆ 1 and ∆ 2 , we will conclude that there is no difference according to the results of [23] and [58]. In fact, their right endpoints have a large difference. Nonetheless, based on the method proposed in this paper, their interval similarity is s(∆ 1 , ∆ 2 )=0.5, suggesting that ∆ 1 and ∆ 2 are clearly different. As a consequence, the method proposed in this paper can easily distinguish ∆ 1 and ∆ 2 , and is more suitable for handling interval optimization problems.If only the left endpoints are utilized to measure the difference between ∆ 1 and ∆ 2 , we will conclude that there is no difference according to the results of [23] and [58]. In fact, their right endpoints have a large difference. Nonetheless, based on the method proposed in this paper, their interval similarity is s(∆ 1 , ∆ 2 )=0.5, suggesting that ∆ 1 and ∆ 2 are clearly different. As a consequence, the method proposed in this paper can easily distinguish ∆ 1 and ∆ 2 , and is more suitable for handling interval optimization problems.</p>
        <p>In this study, due to uncertainties and noises generally existing in the objectives, we regard x k and c p inseparable ifIn this study, due to uncertainties and noises generally existing in the objectives, we regard x k and c p inseparable if</p>
        <p>, where θ 1 is a threshold set in advance in the range of (0,1)., where θ 1 is a threshold set in advance in the range of (0,1).</p>
        <p>According to the above theorem, we propose the following approach of dividing all the decision variables in (1). For x k and c p (t), we first calculate ∆f (x, c(t))According to the above theorem, we propose the following approach of dividing all the decision variables in (1). For x k and c p (t), we first calculate ∆f (x, c(t))</p>
        <p>according to (6).according to (6).</p>
        <p>Following that, we obtain the similarity between the two intervals by (4), and if it is smaller than θ 1 , x k is inseparable with c p (t). On this circumstance, we delete x k from the set of decision variables, and put it into the first group. The above process is repeated until all the interval parameters are detected. In this way, we can obtain decision variables in the first group. θ 1 is set according to noises and uncertainties existing in a problem, and the larger the noises or uncertainties, the smaller the value of θ 1 should be set. For a problem, θ 1 is generally set to 1. In fact, assigning its appropriate value is difficult. Algorithm 2 provides the pseudo code of the proposed method of dividing all the decision variables.Following that, we obtain the similarity between the two intervals by (4), and if it is smaller than θ 1 , x k is inseparable with c p (t). On this circumstance, we delete x k from the set of decision variables, and put it into the first group. The above process is repeated until all the interval parameters are detected. In this way, we can obtain decision variables in the first group. θ 1 is set according to noises and uncertainties existing in a problem, and the larger the noises or uncertainties, the smaller the value of θ 1 should be set. For a problem, θ 1 is generally set to 1. In fact, assigning its appropriate value is difficult. Algorithm 2 provides the pseudo code of the proposed method of dividing all the decision variables.</p>
        <p>Input: the time scale, t; upper and lower bounds of decision variables, upb and lowb; the number of objectives, decision variables and interval parameters, m, n and P, respectively; Output: the groups of decision variables, g1 and g2; 1 g1 ← ∅ % g1 saves decision variables inseparable with c(t); 2 g2 ← ∅ % g2 saves decision variables separable with c(t); 3 for i = 1 to m do Using the proposed strategy, all the decision variables can be divided into the following two groups: one isInput: the time scale, t; upper and lower bounds of decision variables, upb and lowb; the number of objectives, decision variables and interval parameters, m, n and P, respectively; Output: the groups of decision variables, g1 and g2; 1 g1 ← ∅ % g1 saves decision variables inseparable with c(t); 2 g2 ← ∅ % g2 saves decision variables separable with c(t); 3 for i = 1 to m do Using the proposed strategy, all the decision variables can be divided into the following two groups: one is</p>
        <p>, which is inseparable with interval parameters, and the other is, which is inseparable with interval parameters, and the other is</p>
        <p>), which is separable with interval parameters.), which is separable with interval parameters.</p>
        <p>For a DI-MOP, if traditional approaches [25], [59], [60] are employed to detect the problem change, a predefined value associated with an objective interval, such as the left endpoint, the right endpoint, and the midpoint, is selected. However, the predefined value may not be changed as the problem varies. Let us consider the following three functions:For a DI-MOP, if traditional approaches [25], [59], [60] are employed to detect the problem change, a predefined value associated with an objective interval, such as the left endpoint, the right endpoint, and the midpoint, is selected. However, the predefined value may not be changed as the problem varies. Let us consider the following three functions:</p>
        <p>When the parameter, t, varies, the left endpoint of f 1 (x, t), the right endpoint of f 2 (x, t), and the midpoint of f 3 (x, t) remain unchanged for the same value of x. Under this circumstance, traditional approaches have a difficulty in tackling a DI-MOP.When the parameter, t, varies, the left endpoint of f 1 (x, t), the right endpoint of f 2 (x, t), and the midpoint of f 3 (x, t) remain unchanged for the same value of x. Under this circumstance, traditional approaches have a difficulty in tackling a DI-MOP.</p>
        <p>For a solution to a DI-MOP, at least one of its objective intervals will generally vary when the optimization problem changes, and the larger the change intensity of the optimization problem, the smaller the similarity between objective intervals of the previous and current optimization problems. In this way, we can detect whether the optimization problem change or not. To fulfill the task, we first form a detection population at the end of each generation, which is composed of a number of individuals chosen from the current optimal solutions. Then, we calculate the similarity between objective intervals of each individual in the detection population based on the previous and current optimization problems, and obtain the average interval similarity of these individuals. Finally, we compare the average interval similarity with a threshold, θ 2 (0 &lt; θ 2 &lt; 1), set in advance. If it is smaller than θ 2 , the Algorithm 3: Environment detection Input: the archive, A; the number of objectives, m; Output: the results of environment detection, flag; 1 Choose u individuals from the current optimal solutions to form the detection population, optimization problem is detected to have changed. θ 2 is set by a decision-maker according to his/her preference. The more sensitive the decision-maker to the environmental change, the larger the value of θ 2 should be set. On this circumstance, the decision-maker will frequently change his/her plan once the environment changes, and has a high requirement to the algorithm so as to rapidly seeking optimal solutions. The pseudo code of the proposed method of detecting the problem change is supplied in Algorithm 3.For a solution to a DI-MOP, at least one of its objective intervals will generally vary when the optimization problem changes, and the larger the change intensity of the optimization problem, the smaller the similarity between objective intervals of the previous and current optimization problems. In this way, we can detect whether the optimization problem change or not. To fulfill the task, we first form a detection population at the end of each generation, which is composed of a number of individuals chosen from the current optimal solutions. Then, we calculate the similarity between objective intervals of each individual in the detection population based on the previous and current optimization problems, and obtain the average interval similarity of these individuals. Finally, we compare the average interval similarity with a threshold, θ 2 (0 &lt; θ 2 &lt; 1), set in advance. If it is smaller than θ 2 , the Algorithm 3: Environment detection Input: the archive, A; the number of objectives, m; Output: the results of environment detection, flag; 1 Choose u individuals from the current optimal solutions to form the detection population, optimization problem is detected to have changed. θ 2 is set by a decision-maker according to his/her preference. The more sensitive the decision-maker to the environmental change, the larger the value of θ 2 should be set. On this circumstance, the decision-maker will frequently change his/her plan once the environment changes, and has a high requirement to the algorithm so as to rapidly seeking optimal solutions. The pseudo code of the proposed method of detecting the problem change is supplied in Algorithm 3.</p>
        <p>To compare the traditional and the proposed detection strategies, three functions, f 1 (x, t) = (1, 1 + t)x, f 2 (x, t) = (1 + 0.1t, 1 + t)x, and f 3 (x, t) = (1 + t)x, are taken into account. Among them, the first two are intervals, and the third one is a real value. Assume that only the left endpoints are employed in the traditional detection strategy. Table I lists the comparison results when the two strategies are employed to detect the environmental change. From this table, we can see:To compare the traditional and the proposed detection strategies, three functions, f 1 (x, t) = (1, 1 + t)x, f 2 (x, t) = (1 + 0.1t, 1 + t)x, and f 3 (x, t) = (1 + t)x, are taken into account. Among them, the first two are intervals, and the third one is a real value. Assume that only the left endpoints are employed in the traditional detection strategy. Table I lists the comparison results when the two strategies are employed to detect the environmental change. From this table, we can see:</p>
        <p>(1) for interval functions, f 1 (x, t) and f 2 (x, t), rows 2 and 3 demonstrate that the traditional method is low-efficient, or even useless to detect the environmental change, due to its focus on only one point and neglect of the other one. However, the proposed method detects the environment change on the interval similarity, and hence successfully detect the changes with high-efficiency.(1) for interval functions, f 1 (x, t) and f 2 (x, t), rows 2 and 3 demonstrate that the traditional method is low-efficient, or even useless to detect the environmental change, due to its focus on only one point and neglect of the other one. However, the proposed method detects the environment change on the interval similarity, and hence successfully detect the changes with high-efficiency.</p>
        <p>(2) for real function, f 3 (x, t), both methods have a capability in detecting the environmental change. However, the proposed method is less impacted by the decision variable, suggesting its robustness. Therefore, the proposed method is also suitable for real functions.(2) for real function, f 3 (x, t), both methods have a capability in detecting the environmental change. However, the proposed method is less impacted by the decision variable, suggesting its robustness. Therefore, the proposed method is also suitable for real functions.</p>
        <p>Once a change of the optimization problem is detected, appropriate strategies should be employed to respond to the change. Multi-population co-evolutionary optimization can efficiently search for the feasible decision space in multiple directions and interact with each other, which makes it suitable for addressing DMOPs. Compared with traditional single population evolutionary optimization, the multi-population counterpart generally has good performance in convergence and diversity. If all the populations respond to the change in the same way, the characteristics of different populations will be ignored, which deteriorates the performance of multipopulation co-evolutionary optimization. A well-designed responding strategy is generally expected to have good performance in convergence and diversity. On the one hand, abandoning historical optimal solutions and randomly initializing a population is beneficial to the population diversity but may be time-consuming for an algorithm to converge. On the other hand, utilizing all the historical optimal solutions is helpful to converge, but may mislead the evolutionary direction when the change is severe. Furthermore, it generally results in the loss of the population diversity and falls into local optima. Therefore, seeking appropriate strategies for responding to the change is of considerable necessity.Once a change of the optimization problem is detected, appropriate strategies should be employed to respond to the change. Multi-population co-evolutionary optimization can efficiently search for the feasible decision space in multiple directions and interact with each other, which makes it suitable for addressing DMOPs. Compared with traditional single population evolutionary optimization, the multi-population counterpart generally has good performance in convergence and diversity. If all the populations respond to the change in the same way, the characteristics of different populations will be ignored, which deteriorates the performance of multipopulation co-evolutionary optimization. A well-designed responding strategy is generally expected to have good performance in convergence and diversity. On the one hand, abandoning historical optimal solutions and randomly initializing a population is beneficial to the population diversity but may be time-consuming for an algorithm to converge. On the other hand, utilizing all the historical optimal solutions is helpful to converge, but may mislead the evolutionary direction when the change is severe. Furthermore, it generally results in the loss of the population diversity and falls into local optima. Therefore, seeking appropriate strategies for responding to the change is of considerable necessity.</p>
        <p>To fulfill this task, we present a strategy for responding to changes of the optimization problem. In the proposed strategy, we initialize sub-populations corresponding to different groups using different methods. For decision variables in groups x 1 and x 2 , they are optimized by two populations P 1 and P 2 , respectively. For P 1 , it is composed of two parts: one contains individuals which are randomly initialized in the feasible decision space to promote the diversity of P 1 , and the other contains those which are initialized by a prediction strategy based on the change intensity to rapidly tracking the optimal solutions to the changed optimization problem. In the following, we will detail the prediction strategy.To fulfill this task, we present a strategy for responding to changes of the optimization problem. In the proposed strategy, we initialize sub-populations corresponding to different groups using different methods. For decision variables in groups x 1 and x 2 , they are optimized by two populations P 1 and P 2 , respectively. For P 1 , it is composed of two parts: one contains individuals which are randomly initialized in the feasible decision space to promote the diversity of P 1 , and the other contains those which are initialized by a prediction strategy based on the change intensity to rapidly tracking the optimal solutions to the changed optimization problem. In the following, we will detail the prediction strategy.</p>
        <p>1) Predicting the change direction of optimal solutions : To fulfill this task, we re-evaluate solutions in A(t), the archive of complete solutions at the time scale t, and store non-dominated solutions in A 0 (t + 1). Then, the change direction can be obtained as follows.1) Predicting the change direction of optimal solutions : To fulfill this task, we re-evaluate solutions in A(t), the archive of complete solutions at the time scale t, and store non-dominated solutions in A 0 (t + 1). Then, the change direction can be obtained as follows.</p>
        <p>where C A0(t+1) and C A(t) are the centroids of A 0 (t+1) and A(t) in the decision space, respectively.where C A0(t+1) and C A(t) are the centroids of A 0 (t+1) and A(t) in the decision space, respectively.</p>
        <p>2) Estimating the step size of the change of optimal solutions: We define the change intensity of the optimization problem as follows.2) Estimating the step size of the change of optimal solutions: We define the change intensity of the optimization problem as follows.</p>
        <p>where |A 0 (t+1)| is the size of A 0 (t+1), s ij refers to the similarity between the i-th objective of the j-th individual for the previous and current optimization problems, ds(t+1) is the average dissimilarity of each objective of all the individuals. ds(t+1) reflects the change intensity of the optimization problem, and a larger value of ds(t+1) indicates a more violent change.where |A 0 (t+1)| is the size of A 0 (t+1), s ij refers to the similarity between the i-th objective of the j-th individual for the previous and current optimization problems, ds(t+1) is the average dissimilarity of each objective of all the individuals. ds(t+1) reflects the change intensity of the optimization problem, and a larger value of ds(t+1) indicates a more violent change.</p>
        <p>Using historical information of optimal solutions, the step size of the change of optimal solutions is estimated as follows.Using historical information of optimal solutions, the step size of the change of optimal solutions is estimated as follows.</p>
        <p>where ds(t+1) ds(t) means the ratio of the change intensity from time scale t to t+1, and a larger value of ds(t+1) ds(t) suggests that the change intensity at the time scale t+1 is stronger than that at time t. As a result, the step size of optimal solutions, S(t+1), will be larger.where ds(t+1) ds(t) means the ratio of the change intensity from time scale t to t+1, and a larger value of ds(t+1) ds(t) suggests that the change intensity at the time scale t+1 is stronger than that at time t. As a result, the step size of optimal solutions, S(t+1), will be larger.</p>
        <p>3) Generating new individuals: For any p(t) ∈ P 1 (t), its location for the changed optimization problem is predicted as follows.3) Generating new individuals: For any p(t) ∈ P 1 (t), its location for the changed optimization problem is predicted as follows.</p>
        <p>p(t + 1) = p(t) + rS(t+1)D(t+1) + ε(t) (10) where r refers to a random value obeying the uniform distribution inp(t + 1) = p(t) + rS(t+1)D(t+1) + ε(t) (10) where r refers to a random value obeying the uniform distribution in</p>
        <p>is a Gaussian noise which is added to increase the probability of the re-initialized population to cover the PS of the changed optimization problem, I is an identity matrix, and σ(t) is the standard deviation of the Gaussian distribution with its expression being σ(t) = S(t+1) 2 √ n . P 1 is heavily affected by interval parameters when the optimization problem changes. According to this characteristic, the proposed response method utilizes the interval similarity of individuals fitness before and after the change to generate the initial solutions. Due to taking full advantage of information associated with the change, the generated initial solutions can well reflect the change trend of optimal solutions, leading to a rapid convergence.is a Gaussian noise which is added to increase the probability of the re-initialized population to cover the PS of the changed optimization problem, I is an identity matrix, and σ(t) is the standard deviation of the Gaussian distribution with its expression being σ(t) = S(t+1) 2 √ n . P 1 is heavily affected by interval parameters when the optimization problem changes. According to this characteristic, the proposed response method utilizes the interval similarity of individuals fitness before and after the change to generate the initial solutions. Due to taking full advantage of information associated with the change, the generated initial solutions can well reflect the change trend of optimal solutions, leading to a rapid convergence.</p>
        <p>With respect to P 2 , interval parameters have no influences on x 2 . As a result, a half of individuals in P 2 are randomly initialized, and the rest are initialized with the Gaussian mutation, shown in (11), when the optimization problem changes.With respect to P 2 , interval parameters have no influences on x 2 . As a result, a half of individuals in P 2 are randomly initialized, and the rest are initialized with the Gaussian mutation, shown in (11), when the optimization problem changes.</p>
        <p>When evaluating an individual of the current population, forming a complete solution by selecting a representative individual from the other population together with the current individual is of necessity. To fulfill this task, the method in [23] is adopted to construct and evaluate a complete solution. For more details, please refer to [23].When evaluating an individual of the current population, forming a complete solution by selecting a representative individual from the other population together with the current individual is of necessity. To fulfill this task, the method in [23] is adopted to construct and evaluate a complete solution. For more details, please refer to [23].</p>
        <p>In each generation, the main difference between the proposed CC-IP-MOEA-IS, which is achieved by combining the proposed cooperative co-evolutionary optimization and the response strategies based on the interval similarity with IP-MOEA, and IP-MOEA lies in grouping the decision variables, detecting the environmental change, responding the change, cooperatively co-evolving each sub-population, and forming the archive. Assume that there are two sub-populations with their size of N/2 to cooperative co-evolve when tackling an optimization problem with m(≥ 2) objectives, n decision variables, and p interval parameters. In additional, we assume that there are k non-separable variables for each interval parameter, and let n co be the number of representatives from the other sub-populations during the evolution, and N be the sizes of the archive. The computational complexity associated with each of the above strategies is given as follows:In each generation, the main difference between the proposed CC-IP-MOEA-IS, which is achieved by combining the proposed cooperative co-evolutionary optimization and the response strategies based on the interval similarity with IP-MOEA, and IP-MOEA lies in grouping the decision variables, detecting the environmental change, responding the change, cooperatively co-evolving each sub-population, and forming the archive. Assume that there are two sub-populations with their size of N/2 to cooperative co-evolve when tackling an optimization problem with m(≥ 2) objectives, n decision variables, and p interval parameters. In additional, we assume that there are k non-separable variables for each interval parameter, and let n co be the number of representatives from the other sub-populations during the evolution, and N be the sizes of the archive. The computational complexity associated with each of the above strategies is given as follows:</p>
        <p>(1) grouping the decision variables is O(mp(n + k)) [58],(1) grouping the decision variables is O(mp(n + k)) [58],</p>
        <p>(2) detecting the environmental change is O(mN ) in the worst case, (3) responding to the change is O(mN ), (4) cooperatively co-evolving all the sub-populations is O(m(n co) 2 N ), and ( 5) forming the archive is O((2N ) m ) [24], [61].(2) detecting the environmental change is O(mN ) in the worst case, (3) responding to the change is O(mN ), (4) cooperatively co-evolving all the sub-populations is O(m(n co) 2 N ), and ( 5) forming the archive is O((2N ) m ) [24], [61].</p>
        <p>The number of representatives, n co, is generally a small constant and irrelevant to the size of a sub-population. Therefore, the overall complexity of the proposed algorithm is O((2N ) m ), which is the same as that of the state-of-theart IP-MOEA [61]. From this viewpoint, CC-IP-MOEA-IS is computationally efficient. However, if n co is set to a large value, and relevant to the size of a sub-population, CC-IP-MOEA-IS will have a high computational complexity when m = 2.The number of representatives, n co, is generally a small constant and irrelevant to the size of a sub-population. Therefore, the overall complexity of the proposed algorithm is O((2N ) m ), which is the same as that of the state-of-theart IP-MOEA [61]. From this viewpoint, CC-IP-MOEA-IS is computationally efficient. However, if n co is set to a large value, and relevant to the size of a sub-population, CC-IP-MOEA-IS will have a high computational complexity when m = 2.</p>
        <p>To evaluate the proposed algorithm, we conduct the following three groups of experiments. The first group investigates the influences of different response strategies by comparing the response strategy proposed in Section III. E with strategies A and B proposed in [25]. For the second group, its aim is to demonstrate the influences of cooperative co-evolution on an optimization algorithm. To fulfill this task, we compare 
            <rs type="software">IP-MOEA</rs> [24] with and without this paradigm when solving benchmark optimization instances. With the last group, we attempt to conduct a comprehensive comparison between the proposed algorithm and other five state-of-the-art ones. The implementation environment is provided as follows: Intel(R) Xeon(R) E5-2660 V3 CPU, 2.60GHz, 48GB RAM, 
            <rs type="software">Windows 10</rs>, 
            <rs type="software">MATLAB</rs>
            <rs type="version">R2012a</rs>.
        </p>
        <p>To evaluate the proposed algorithm, eight new optimization problems, ZDT3 DI , FDA1 DI , FDA2 DI , FDA4 DI , FDA5 DI , and DSW1 DI -DSW3 DI , are constructed by modifying previous deterministic counterparts, ZDT3, FDA1, FDA2, FDA4, FDA5 [62] , and DSW1-DSW3 [63]. These problems can be scaled to any number of decision variables, and have concave, disconnected, scalable, and changeable Pareto fronts/sets. The first decision variable of each deterministic optimization problem is multiplied by an interval, c 1 = [0.9, 1], and the rest are multiplied by intervals associated with the time In this way, the deterministic optimization problems can be converted into their interval counterparts. c i (t) changes over time, and different decision variables have different interval coefficients, which poses a difficulty to an algorithm when tackling these optimization problems. Therefore, these optimization problems are qualified to test the capacity of an algorithm in tracking changing optimal solutions.To evaluate the proposed algorithm, eight new optimization problems, ZDT3 DI , FDA1 DI , FDA2 DI , FDA4 DI , FDA5 DI , and DSW1 DI -DSW3 DI , are constructed by modifying previous deterministic counterparts, ZDT3, FDA1, FDA2, FDA4, FDA5 [62] , and DSW1-DSW3 [63]. These problems can be scaled to any number of decision variables, and have concave, disconnected, scalable, and changeable Pareto fronts/sets. The first decision variable of each deterministic optimization problem is multiplied by an interval, c 1 = [0.9, 1], and the rest are multiplied by intervals associated with the time In this way, the deterministic optimization problems can be converted into their interval counterparts. c i (t) changes over time, and different decision variables have different interval coefficients, which poses a difficulty to an algorithm when tackling these optimization problems. Therefore, these optimization problems are qualified to test the capacity of an algorithm in tracking changing optimal solutions.</p>
        <p>Please refer to Section II in the supplementary material for the detailed descriptions of them.Please refer to Section II in the supplementary material for the detailed descriptions of them.</p>
        <p>1) Compared algorithms and strategies: Since each subpopulation in the proposed algorithm evolves using operators in IP-MOEA, it is necessary to take IP-MOEA as a compared algorithm. To investigate the efficiency of the response strategy proposed in this study, we take two state-of-the-art strategies, A and B, proposed by Deb et al. [25], into consideration for a comparative study. The three corresponding dynamic evolutionary optimization algorithms, CC-IP-MOEA-A, and CC-IP-MOEA-B, are achieved by combining the proposed cooperative co-evolutionary optimization, and the response strategies, A and B, respectively, with IP-MOEA. In addition, the other two algorithms, D-IP-MOEA-A and D-IP-MOEA-B, are obtained by incorporating the response strategies, A and B, respectively, with IP-MOEA. Finally, these two algorithms are compared with CC-IP-MOEA-A and CC-IP-MOEA-B to evaluate the performance of the proposed cooperative coevolutionary strategy.1) Compared algorithms and strategies: Since each subpopulation in the proposed algorithm evolves using operators in IP-MOEA, it is necessary to take IP-MOEA as a compared algorithm. To investigate the efficiency of the response strategy proposed in this study, we take two state-of-the-art strategies, A and B, proposed by Deb et al. [25], into consideration for a comparative study. The three corresponding dynamic evolutionary optimization algorithms, CC-IP-MOEA-A, and CC-IP-MOEA-B, are achieved by combining the proposed cooperative co-evolutionary optimization, and the response strategies, A and B, respectively, with IP-MOEA. In addition, the other two algorithms, D-IP-MOEA-A and D-IP-MOEA-B, are obtained by incorporating the response strategies, A and B, respectively, with IP-MOEA. Finally, these two algorithms are compared with CC-IP-MOEA-A and CC-IP-MOEA-B to evaluate the performance of the proposed cooperative coevolutionary strategy.</p>
        <p>2) Parameter settings: In the experiments, the simulated binary crossover (SBX) and polynomial mutation are utilized with their distribution indexes of 20 to generate new offspring during the evolution. The crossover and mutation probabilities are 0.9 and 1/n, respectively, where n is the number of decision variables. For each benchmark optimization problem,2) Parameter settings: In the experiments, the simulated binary crossover (SBX) and polynomial mutation are utilized with their distribution indexes of 20 to generate new offspring during the evolution. The crossover and mutation probabilities are 0.9 and 1/n, respectively, where n is the number of decision variables. For each benchmark optimization problem,</p>
        <p>, where n t , τ t and τ are the change severity and frequency, as well as the maximal number of iterations, respectively. For problems ZDT3 DI , FDA1 DI , FDA2 DI , FDA4 DI , and FDA5 DI , n t = 10, τ t = 50, τ = 2500, indicating that there are fifty changes in total for each optimization problem. Each function is evaluated 10,000 times after the optimization problem changes. For problems DSW1 DI -DSW3 DI , n t = 2, τ t = 100, τ = 2000, i.e. twenty changes are tackled for each algorithm. Each function is evaluated 20,000 times after the change occurs., where n t , τ t and τ are the change severity and frequency, as well as the maximal number of iterations, respectively. For problems ZDT3 DI , FDA1 DI , FDA2 DI , FDA4 DI , and FDA5 DI , n t = 10, τ t = 50, τ = 2500, indicating that there are fifty changes in total for each optimization problem. Each function is evaluated 10,000 times after the optimization problem changes. For problems DSW1 DI -DSW3 DI , n t = 2, τ t = 100, τ = 2000, i.e. twenty changes are tackled for each algorithm. Each function is evaluated 20,000 times after the change occurs.</p>
        <p>At each generation, cooperative co-evolutionary algorithms, i.e., CC-IP-MOEA-A, CC-IP-MOEA-B, and CC-IP-MOEA-IS, have more evaluations than IP-MOEA. Therefore, the population size is set to 50 for these cooperative co-evolutionary algorithms and 200 for IP-MOEA, D-IP-MOEA-A, and D-IP-MOEA-B, to balance their total budget in evaluation. The archive size is set to 100, and the cooperative individual rate is set to 2. Besides, the values of θ 1 and θ 2 are set according to the tolerability of a decision-maker to the problem change and the robustness of obtained optimal solutions. In this study, they are both set to 0.9. For problems with their decision variables being inseparable with interval parameters, such as ZDT3 DI , FDA1 DI , and FDA2 DI , the decision variables are equally divided into two groups.At each generation, cooperative co-evolutionary algorithms, i.e., CC-IP-MOEA-A, CC-IP-MOEA-B, and CC-IP-MOEA-IS, have more evaluations than IP-MOEA. Therefore, the population size is set to 50 for these cooperative co-evolutionary algorithms and 200 for IP-MOEA, D-IP-MOEA-A, and D-IP-MOEA-B, to balance their total budget in evaluation. The archive size is set to 100, and the cooperative individual rate is set to 2. Besides, the values of θ 1 and θ 2 are set according to the tolerability of a decision-maker to the problem change and the robustness of obtained optimal solutions. In this study, they are both set to 0.9. For problems with their decision variables being inseparable with interval parameters, such as ZDT3 DI , FDA1 DI , and FDA2 DI , the decision variables are equally divided into two groups.</p>
        <p>We run each algorithm 30 times for each optimization problem independently, and calculate the mean and standard deviation of the two performance indicators which will be formulated with (12) and (13). Besides, Mann-Whitney U test is adopted to show the difference of different algorithms in terms of each performance metric at the significant level of 5%.We run each algorithm 30 times for each optimization problem independently, and calculate the mean and standard deviation of the two performance indicators which will be formulated with (12) and (13). Besides, Mann-Whitney U test is adopted to show the difference of different algorithms in terms of each performance metric at the significant level of 5%.</p>
        <p>When evaluating a solution set obtained by an algorithm in convergence, diversity, and uncertainty, Limbourg and Aponte et al. [24] introduced such indicators as hyper-volume (H) and imprecision (I). To adapt the H and I indicators to DI-MOPs, the average value of each indicator in a period of time scales is calculated.When evaluating a solution set obtained by an algorithm in convergence, diversity, and uncertainty, Limbourg and Aponte et al. [24] introduced such indicators as hyper-volume (H) and imprecision (I). To adapt the H and I indicators to DI-MOPs, the average value of each indicator in a period of time scales is calculated.</p>
        <p>Definition 5: Average hyper-volume (AH). The value of the AH metric assists in assessing the tracking ability of a Pareto optimal set obtained by an algorithm before the optimization problem changes, with its expression as follows.Definition 5: Average hyper-volume (AH). The value of the AH metric assists in assessing the tracking ability of a Pareto optimal set obtained by an algorithm before the optimization problem changes, with its expression as follows.</p>
        <p>where T is a set of time scales with its cardinality being |T |, X * (t) means the obtained PS(t) at the time scale, t. The larger the value of AH of the final Pareto front is, the closer the final front is to the true one, and the better the distribution of solutions along the front is. In the experiments, the reference point is set to (where T is a set of time scales with its cardinality being |T |, X * (t) means the obtained PS(t) at the time scale, t. The larger the value of AH of the final Pareto front is, the closer the final front is to the true one, and the better the distribution of solutions along the front is. In the experiments, the reference point is set to (</p>
        <p>) for DSW3 DI and (5, 5) for the rest problems, where f max 1 and f max 2 are the maximal objectives of f 1 and f 2 , respectively.) for DSW3 DI and (5, 5) for the rest problems, where f max 1 and f max 2 are the maximal objectives of f 1 and f 2 , respectively.</p>
        <p>Definition 6: Average imprecision (AI). For X * (t), its imprecision is calculated as follows.Definition 6: Average imprecision (AI). For X * (t), its imprecision is calculated as follows.</p>
        <p>The average imprecision of X * (t) is then calculated as follows.The average imprecision of X * (t) is then calculated as follows.</p>
        <p>AI reflects the uncertainty of a Pareto optimal set in the objective space, and the smaller the value of AI of a Pareto optimal set, the more exact the true PF(t) corresponding to the Pareto optimal set.AI reflects the uncertainty of a Pareto optimal set in the objective space, and the smaller the value of AI of a Pareto optimal set, the more exact the true PF(t) corresponding to the Pareto optimal set.</p>
        <p>In this subsection, the proposed algorithm, CC-IP-MOEA-IS, is compared with five algorithms, IP-MOEA, D-IP-MOEA-A, D-IP-MOEA-B, CC-IP-MOEA-A, and CC-IP-MOEA-B.In this subsection, the proposed algorithm, CC-IP-MOEA-IS, is compared with five algorithms, IP-MOEA, D-IP-MOEA-A, D-IP-MOEA-B, CC-IP-MOEA-A, and CC-IP-MOEA-B.</p>
        <p>We first compare the two algorithms, D-IP-MOEA-A and D-IP-MOEA-B, on the eight benchmark problems to show the performance of incorporating response strategies A and B with IP-MOEA. Fig. 1 demonstrates that D-IP-MOEA-A and D-IP-MOEA-B are not better than IP-MOEA in terms of H. Especially, the H values of the former are slightly smaller than that of the latter on FDA4 DI , DSW1 DI , and DSW2 DI , indicating that there is no significant improvement in convergence and diversity after incorporating response strategies A and B into IP-MOEA. In addition, there is no significant difference in terms of AI among the three algorithms, suggesting that response strategies A and B have slightly influence on the performance of an improved algorithm. We therefore conclude the unsuitability of response strategies A and B for DI-MOPs.We first compare the two algorithms, D-IP-MOEA-A and D-IP-MOEA-B, on the eight benchmark problems to show the performance of incorporating response strategies A and B with IP-MOEA. Fig. 1 demonstrates that D-IP-MOEA-A and D-IP-MOEA-B are not better than IP-MOEA in terms of H. Especially, the H values of the former are slightly smaller than that of the latter on FDA4 DI , DSW1 DI , and DSW2 DI , indicating that there is no significant improvement in convergence and diversity after incorporating response strategies A and B into IP-MOEA. In addition, there is no significant difference in terms of AI among the three algorithms, suggesting that response strategies A and B have slightly influence on the performance of an improved algorithm. We therefore conclude the unsuitability of response strategies A and B for DI-MOPs.</p>
        <p>Then, we compare the algorithms, CC-IP-MOEA-A and CC-IP-MOEA-B with CC-IP-MOEA-IS, which have the same cooperative co-evolution paradigm and different response strategies, A, B, and interval similarity-based, to demonstrate the performance of the three response strategies. For ZDT3 DI , FDA1 DI , and FDA4 DI , CC-IP-MOEA-IS is significantly superior to CC-IP-MOEA-A and CC-IP-MOEA-B in terms of H. When tackling problems DSW1 DI and DSW2 DI , CC-IP-MOEA-IS achieves larger values of H than CC-IP-MOEA-A. Although CC-IP-MOEA-IS and CC-IP-MOEA-B have no significant difference in terms of the medium of H, CC-IP-MOEA-IS has the H values with a smaller fluctuation than CC-IP-MOEA-B, which highlights its strong robustness. Moreover, on DSW3 DI , there is no significant difference in terms of H among CC-IP-MOEA-IS, CC-IP-MOEA-A, and CC-IP-MOEA-B. To sum up, the proposed response strategy achieves a larger H value and a smaller fluctuation on the other problems except FDA2 DI . The AH value in Table II also confirms the above observation, suggesting that the proposed response strategy has a better capability to be combined with the cooperative co-evolution paradigm to promote the performance in convergence and diversity of an algorithm.Then, we compare the algorithms, CC-IP-MOEA-A and CC-IP-MOEA-B with CC-IP-MOEA-IS, which have the same cooperative co-evolution paradigm and different response strategies, A, B, and interval similarity-based, to demonstrate the performance of the three response strategies. For ZDT3 DI , FDA1 DI , and FDA4 DI , CC-IP-MOEA-IS is significantly superior to CC-IP-MOEA-A and CC-IP-MOEA-B in terms of H. When tackling problems DSW1 DI and DSW2 DI , CC-IP-MOEA-IS achieves larger values of H than CC-IP-MOEA-A. Although CC-IP-MOEA-IS and CC-IP-MOEA-B have no significant difference in terms of the medium of H, CC-IP-MOEA-IS has the H values with a smaller fluctuation than CC-IP-MOEA-B, which highlights its strong robustness. Moreover, on DSW3 DI , there is no significant difference in terms of H among CC-IP-MOEA-IS, CC-IP-MOEA-A, and CC-IP-MOEA-B. To sum up, the proposed response strategy achieves a larger H value and a smaller fluctuation on the other problems except FDA2 DI . The AH value in Table II also confirms the above observation, suggesting that the proposed response strategy has a better capability to be combined with the cooperative co-evolution paradigm to promote the performance in convergence and diversity of an algorithm.</p>
        <p>Additionally, CC-IP-MOEA-IS has not only smaller I values and stronger robustness than CC-IP-MOEA-A and CC-IP-MOEA-B in terms of I on ZDT3 DI , FDA1 DI , FDA2 DI , FDA4 DI , and FDA5 DI , but also its imprecise is as small as CC-IP-MOEA-A and CC-IP-MOEA-B on DSW1 DI -DSW3 DI .Additionally, CC-IP-MOEA-IS has not only smaller I values and stronger robustness than CC-IP-MOEA-A and CC-IP-MOEA-B in terms of I on ZDT3 DI , FDA1 DI , FDA2 DI , FDA4 DI , and FDA5 DI , but also its imprecise is as small as CC-IP-MOEA-A and CC-IP-MOEA-B on DSW1 DI -DSW3 DI .</p>
        <p>From the above experimental results and analysis, we can conclude that the proposed response strategy has effectively improved in convergence and diversity of an algorithm. In addition, it significantly reduces the imprecise of the obtained optimal solution set. Hence, the proposed response strategy is more suitable for DI-MOPs.From the above experimental results and analysis, we can conclude that the proposed response strategy has effectively improved in convergence and diversity of an algorithm. In addition, it significantly reduces the imprecise of the obtained optimal solution set. Hence, the proposed response strategy is more suitable for DI-MOPs.</p>
        <p>2) The performance of the cooperative co-evolutionary paradigm: We compare the following pairs of algorithms, D-IP-MOEA-A and CC-IP-MOEA-A, D-IP-MOEA-B and CC-IP-MOEA-B, with each pair having the same response strategy, but different evolutionary paradigm. Fig. 1 demonstrates that, CC-IP-MOEA-A and CC-IP-MOEA-B are worse than their counterparts in terms of H on ZDT3 DI and FDA4 DI . In addition, there is a slight difference among them on FDA5 DI . However, CC-IP-MOEA-A and CC-IP-MOEA-B have significantly larger H values than their counterparts on the rest five test instances, suggesting that the cooperative co-evolutionary paradigm can achieve good performance in convergence and diversity on most test cases.2) The performance of the cooperative co-evolutionary paradigm: We compare the following pairs of algorithms, D-IP-MOEA-A and CC-IP-MOEA-A, D-IP-MOEA-B and CC-IP-MOEA-B, with each pair having the same response strategy, but different evolutionary paradigm. Fig. 1 demonstrates that, CC-IP-MOEA-A and CC-IP-MOEA-B are worse than their counterparts in terms of H on ZDT3 DI and FDA4 DI . In addition, there is a slight difference among them on FDA5 DI . However, CC-IP-MOEA-A and CC-IP-MOEA-B have significantly larger H values than their counterparts on the rest five test instances, suggesting that the cooperative co-evolutionary paradigm can achieve good performance in convergence and diversity on most test cases.</p>
        <p>We have the following observations from Fig. 2: CC-IP-MOEA-A and CC-IP-MOEA-B have larger I values than their counterparts on ZDT3 DI , FDA4 DI , and FDA5 DI , but their I values are generally smaller than their counterparts on the rest five problems, indicating that the cooperative co-evolutionary paradigm can also improve the imprecise of an algorithm.We have the following observations from Fig. 2: CC-IP-MOEA-A and CC-IP-MOEA-B have larger I values than their counterparts on ZDT3 DI , FDA4 DI , and FDA5 DI , but their I values are generally smaller than their counterparts on the rest five problems, indicating that the cooperative co-evolutionary paradigm can also improve the imprecise of an algorithm.</p>
        <p>The curves of H (i.e. the upper endpoint of H) and I over 30 runs versus the time instances on the eight benchmark problems are depicted in Fig. 3. From this figure, we can obtain:The curves of H (i.e. the upper endpoint of H) and I over 30 runs versus the time instances on the eight benchmark problems are depicted in Fig. 3. From this figure, we can obtain:</p>
        <p>(1) For ZDT3 DI , FDA4 DI , and FDA5 DI , two CCEAs, i.e. CC-IP-MOEA-A and CC-IP-MOEA-B, show no better performance in both convergence and diversity than the three non-CCEAs. Nevertheless, the proposed algorithm, CC-IP-MOEA-IS, obtains the competitive H and I values along with the change of an optimization problem, indicating its excellence in tracking time-dependent Pareto fronts. Furthermore, the proposed algorithm has the H and I values with a slighter fluctuation than the others, which highlights its strong robustness.(1) For ZDT3 DI , FDA4 DI , and FDA5 DI , two CCEAs, i.e. CC-IP-MOEA-A and CC-IP-MOEA-B, show no better performance in both convergence and diversity than the three non-CCEAs. Nevertheless, the proposed algorithm, CC-IP-MOEA-IS, obtains the competitive H and I values along with the change of an optimization problem, indicating its excellence in tracking time-dependent Pareto fronts. Furthermore, the proposed algorithm has the H and I values with a slighter fluctuation than the others, which highlights its strong robustness.</p>
        <p>(2) For FDA1 DI and FDA2 DI , three CCEAs are superior to the others no matter how an optimization problem changes, with good performance in robustness. In addition, CC-IP-MOEA-IS, which incorporates with the proposed response strategy, achieves the best performance in terms of H and I all the time. These results reveal that CC-IP-MOEA-IS is more suitable for handling dynamic interval problems.(2) For FDA1 DI and FDA2 DI , three CCEAs are superior to the others no matter how an optimization problem changes, with good performance in robustness. In addition, CC-IP-MOEA-IS, which incorporates with the proposed response strategy, achieves the best performance in terms of H and I all the time. These results reveal that CC-IP-MOEA-IS is more suitable for handling dynamic interval problems.</p>
        <p>(3) For DSW1 DI , DSW2 DI and DSW3 DI , which have large feasible regions, CC-IP-MOEA-IS achieves the competitive H values, and is significant better than the non-CCEAs, except the first two time instances. Moreover, there is no significant difference in terms of the I values among the three CCEAs.(3) For DSW1 DI , DSW2 DI and DSW3 DI , which have large feasible regions, CC-IP-MOEA-IS achieves the competitive H values, and is significant better than the non-CCEAs, except the first two time instances. Moreover, there is no significant difference in terms of the I values among the three CCEAs.</p>
        <p>From the above results, we can conclude that the proposed algorithm is capable of rapidly tracking time-variant Pareto fronts as well as achieving a Pareto optimal set with good performance in convergence, diversity, and imprecision.From the above results, we can conclude that the proposed algorithm is capable of rapidly tracking time-variant Pareto fronts as well as achieving a Pareto optimal set with good performance in convergence, diversity, and imprecision.</p>
        <p>Tables II and III list the averages and standard deviations of AH and AI obtained by different algorithms on the above eight test instances. We have the following observations in terms of AH from Table II. (2) For FDA2 DI , it is Type II, and its PS(t) and PF(t) vary as the optimization problem changes. As a result, it is difficult to be tracked when the optimization problem changes. The proposed algorithm, CC-IP-MOEA-IS, is clearly superior to IP-MOEA, D-IP-MOEA-A, and D-IP-MOEA-B. Although the AH value of CC-IP-MOEA-IS (24.8329) is slightly smaller than those of CC-IP-MOEA-A (24.8358) and CC-IP-MOEA-B (24.8406), there is no significant difference between CC-IP-MOEA-IS and each of CC-IP-MOEA-A and CC-IP-MOEA-B.Tables II and III list the averages and standard deviations of AH and AI obtained by different algorithms on the above eight test instances. We have the following observations in terms of AH from Table II. (2) For FDA2 DI , it is Type II, and its PS(t) and PF(t) vary as the optimization problem changes. As a result, it is difficult to be tracked when the optimization problem changes. The proposed algorithm, CC-IP-MOEA-IS, is clearly superior to IP-MOEA, D-IP-MOEA-A, and D-IP-MOEA-B. Although the AH value of CC-IP-MOEA-IS (24.8329) is slightly smaller than those of CC-IP-MOEA-A (24.8358) and CC-IP-MOEA-B (24.8406), there is no significant difference between CC-IP-MOEA-IS and each of CC-IP-MOEA-A and CC-IP-MOEA-B.</p>
        <p>(3) For FDA4 DI , CC-IP-MOEA-IS performs the best in terms of AH, and is significantly better than the other four except IP-MOEA. For FDA5 DI , its PS(t) and PF(t) change over time, and its convexity varies, suggesting that it is difficult for an algorithm to rapidly tracking the changing PF(t). On this test case, although there is no significant difference in terms of AH between the proposed algorithm and the rest, CC-IP-MOEA-IS obtains the best AH value.(3) For FDA4 DI , CC-IP-MOEA-IS performs the best in terms of AH, and is significantly better than the other four except IP-MOEA. For FDA5 DI , its PS(t) and PF(t) change over time, and its convexity varies, suggesting that it is difficult for an algorithm to rapidly tracking the changing PF(t). On this test case, although there is no significant difference in terms of AH between the proposed algorithm and the rest, CC-IP-MOEA-IS obtains the best AH value.</p>
        <p>(4) For DSW1 DI -DSW3 DI , there is no significant difference between CC-IP-MOEA-IS and CC-IP-MOEA-B in terms of AH. However, CC-IP-MOEA-IS is clearly superior to the other four and achieves the largest value of AH among all the comparative algorithms. Therefore, the proposed algorithm has a strong capacity in tracking the optimal solutions to DSW1 DI -DSW3 DI .(4) For DSW1 DI -DSW3 DI , there is no significant difference between CC-IP-MOEA-IS and CC-IP-MOEA-B in terms of AH. However, CC-IP-MOEA-IS is clearly superior to the other four and achieves the largest value of AH among all the comparative algorithms. Therefore, the proposed algorithm has a strong capacity in tracking the optimal solutions to DSW1 DI -DSW3 DI .</p>
        <p>Furthermore, we have the following observations in terms of AI from Table III.Furthermore, we have the following observations in terms of AI from Table III.</p>
        <p>(1) Although CC-IP-MOEA-IS does not achieve the minimal AI value on ZDT3 DI and FDA5 DI , there is no significant difference between CC-IP-MOEA-IS and each of IP-MOEA, D-IP-MOEA-A, and D-IP-MOEA-B. In addition, CC-IP-MOEA-IS outperforms CC-IP-MOEA-A and CC-IP-MOEA-B in terms of the AI indicator. Taking FDA DI 5 as an example, although the AI value of the proposed algorithm, 0.1359, is slightly bigger than those of IP-MOEA (0.1308), D-IP-MOEA-A (0.1334), and D-IP-MOEA-B (0.1313), there is no significant difference. Furthermore, it is clearly smaller than those of. CC-IP-MOEA-A (0.1568) and CC-IP-MOEA-B (0.1581).(1) Although CC-IP-MOEA-IS does not achieve the minimal AI value on ZDT3 DI and FDA5 DI , there is no significant difference between CC-IP-MOEA-IS and each of IP-MOEA, D-IP-MOEA-A, and D-IP-MOEA-B. In addition, CC-IP-MOEA-IS outperforms CC-IP-MOEA-A and CC-IP-MOEA-B in terms of the AI indicator. Taking FDA DI 5 as an example, although the AI value of the proposed algorithm, 0.1359, is slightly bigger than those of IP-MOEA (0.1308), D-IP-MOEA-A (0.1334), and D-IP-MOEA-B (0.1313), there is no significant difference. Furthermore, it is clearly smaller than those of. CC-IP-MOEA-A (0.1568) and CC-IP-MOEA-B (0.1581).</p>
        <p>(2) For FDA2 DI , CC-IP-MOEA-IS is clearly better than the others but CC-IP-MOEA-B. Moreover, CC-IP-MOEA-IS has also achieved the smallest AI value in the six compared algorithm on FDA4 DI .(2) For FDA2 DI , CC-IP-MOEA-IS is clearly better than the others but CC-IP-MOEA-B. Moreover, CC-IP-MOEA-IS has also achieved the smallest AI value in the six compared algorithm on FDA4 DI .</p>
        <p>(3) CC-IP-MOEA-A, CC-IP-MOEA-B, and CC-IP-MOEA-IS have no significant difference in terms of AI on FDA1 DI , DSW1 DI -DSW3 DI . They have smaller AI values than the other three algorithms, suggesting that the algorithms incorporating with the cooperative co-evolutionary paradigm gain the smallest imprecision.(3) CC-IP-MOEA-A, CC-IP-MOEA-B, and CC-IP-MOEA-IS have no significant difference in terms of AI on FDA1 DI , DSW1 DI -DSW3 DI . They have smaller AI values than the other three algorithms, suggesting that the algorithms incorporating with the cooperative co-evolutionary paradigm gain the smallest imprecision.</p>
        <p>Based on the above experimental results and analyses, we have the following conclusions..Based on the above experimental results and analyses, we have the following conclusions..</p>
        <p>(1) Using an appropriate response strategy is beneficial to improving the performance of EAs for DI-MOPs. For example, D-IP-MOEA-A and D-IP-MOEA-B are not significantly better than IP-MOEA in terms of AH and AI on most test cases.(1) Using an appropriate response strategy is beneficial to improving the performance of EAs for DI-MOPs. For example, D-IP-MOEA-A and D-IP-MOEA-B are not significantly better than IP-MOEA in terms of AH and AI on most test cases.</p>
        <p>However, CC-IP-MOEA-IS is superior to CC-IP-MOEA-A and CC-IP-MOEA-B, indicating that the proposed response strategy is more suitable for DI-MOPs than response strategies A and B. The main reason is that the proposed response strategy can rapidly respond to the change of an optimization problem by accurately predicting the new location of the evolutionary population.However, CC-IP-MOEA-IS is superior to CC-IP-MOEA-A and CC-IP-MOEA-B, indicating that the proposed response strategy is more suitable for DI-MOPs than response strategies A and B. The main reason is that the proposed response strategy can rapidly respond to the change of an optimization problem by accurately predicting the new location of the evolutionary population.</p>
        <p>(2) The cooperative co-evolutionary paradigm is not always effective. Although CC-IP-MOEA-A and CC-IP-MOEA-B are good at addressing FDA1 DI , FDA2 DI , DSW1 DI -DSW3 DI , they do not work on ZDT3 DI and FDA5 DI .(2) The cooperative co-evolutionary paradigm is not always effective. Although CC-IP-MOEA-A and CC-IP-MOEA-B are good at addressing FDA1 DI , FDA2 DI , DSW1 DI -DSW3 DI , they do not work on ZDT3 DI and FDA5 DI .</p>
        <p>(3) Appropriately combining the strategies proposed in this paper can improve the performance of an EA. CC-IP-MOEA-IS, which is generated by incorporating the proposed response strategy and CC into IP-MOEA, has the best performance among all the six algorithms. The reason is that the proposed response strategy has the capability in rapidly responding to the change of an optimization, and cooperative co-evolutionary paradigm is good at speeding up convergence. Therefore, the algorithm proposed in this paper is competitive when solving DI-MOPs.(3) Appropriately combining the strategies proposed in this paper can improve the performance of an EA. CC-IP-MOEA-IS, which is generated by incorporating the proposed response strategy and CC into IP-MOEA, has the best performance among all the six algorithms. The reason is that the proposed response strategy has the capability in rapidly responding to the change of an optimization, and cooperative co-evolutionary paradigm is good at speeding up convergence. Therefore, the algorithm proposed in this paper is competitive when solving DI-MOPs.</p>
        <p>In addition, experiments about time consumption for each comparative algorithm and the effectiveness of the archive set are conducted in Section III of Supplementary Material. From the experimental results, we can conclude that each IP-MOEA with cooperative co-evolution has significantly longer time consumption than the others. Additionally, the proposed algorithm obtains the largest H value when the archive size is 100 and 150. For more details, please refer to Section III of Supplementary Material.In addition, experiments about time consumption for each comparative algorithm and the effectiveness of the archive set are conducted in Section III of Supplementary Material. From the experimental results, we can conclude that each IP-MOEA with cooperative co-evolution has significantly longer time consumption than the others. Additionally, the proposed algorithm obtains the largest H value when the archive size is 100 and 150. For more details, please refer to Section III of Supplementary Material.</p>
        <p>In this section, we investigate a multi-period portfolio selection problem in emerging markets [64], [65]. To provide investors with more choices, we formulate the problem with uncertainties as a bi-objective optimization model with interval coefficients in the objectives. In the formulated model, the expected return rate and risk loss rate at the tth period are represented as follows: R(x, r(t))In this section, we investigate a multi-period portfolio selection problem in emerging markets [64], [65]. To provide investors with more choices, we formulate the problem with uncertainties as a bi-objective optimization model with interval coefficients in the objectives. In the formulated model, the expected return rate and risk loss rate at the tth period are represented as follows: R(x, r(t))</p>
        <p>[q t,i , q t,i ] + 1 2(rt,i-rt,i) (r t,i -r t,i )[q t,i , q t,i ] + 1 2(rt,i-rt,i) (r t,i -r t,i )</p>
        <p>22</p>
        <p>x t,i .x t,i .</p>
        <p>Therefore, the interval bi-objective optimization model can be formulated as min (-R(x, r(t)), Q(x, r(t), q(t)))Therefore, the interval bi-objective optimization model can be formulated as min (-R(x, r(t)), Q(x, r(t), q(t)))</p>
        <p>x i,t = 1, x i,t ≥ 0, t = 1, 2, ..., T. (14) where r(t), q(t), a t,i are parameters, with their meaning and setting being found in [64], [65]. In addition, r(t), q(t) are intervals.x i,t = 1, x i,t ≥ 0, t = 1, 2, ..., T. (14) where r(t), q(t), a t,i are parameters, with their meaning and setting being found in [64], [65]. In addition, r(t), q(t) are intervals.</p>
        <p>According to 1, x t,0 is one separable variable and the others are inseparable with interval parameters, r(t) and/or q(t), in model (14). The proposed algorithm, CC-IP-MOEA-IS, and the comparative ones are employed to tackle the optimization problem.According to 1, x t,0 is one separable variable and the others are inseparable with interval parameters, r(t) and/or q(t), in model (14). The proposed algorithm, CC-IP-MOEA-IS, and the comparative ones are employed to tackle the optimization problem.</p>
        <p>Each algorithm runs 20 times independently. We save these results and calculate their means. The reference point is set to (0, 0.2) when computing hyper-volume. The values of the best hyper-volume and time consumption are listed in Table IV. In addition, we depict the best result obtained by CC-IP-MOEA-IS, IP-MOEA, and CC-IP-MOEA-B, with t=2 and t=3 in Fig. 4, respectively, to intuitively demonstrate the advantages of the proposed algorithm. Table IV reports that although the proposed algorithm, CC-IP-MOEA-IS, does not achieve the maximal H value at t=1, there is no significant difference between CC-IP-MOEA-IS and each comparative algorithm. Furthermore, CC-IP-MOEA-IS reaches the best H values among all the algorithms at t=2 and t=3, despite its time consumption is the longest, indicating that CC-IP-MOEA-IS has the best performance in convergence and distribution. From Fig. 4, we can conclude that the proposed algorithm can archive more and better solutions than IP-MOEA and CC-IP-MOEA-B. Taking Fig. 4a as an example, on the one hand, CC-IP-MOEA-IS offers investors a larger return rate with the same risk loss rate than IP-MOEA. On the other hand, CC-IP-MOEA-IS provides investors more choices with different preferences.Each algorithm runs 20 times independently. We save these results and calculate their means. The reference point is set to (0, 0.2) when computing hyper-volume. The values of the best hyper-volume and time consumption are listed in Table IV. In addition, we depict the best result obtained by CC-IP-MOEA-IS, IP-MOEA, and CC-IP-MOEA-B, with t=2 and t=3 in Fig. 4, respectively, to intuitively demonstrate the advantages of the proposed algorithm. Table IV reports that although the proposed algorithm, CC-IP-MOEA-IS, does not achieve the maximal H value at t=1, there is no significant difference between CC-IP-MOEA-IS and each comparative algorithm. Furthermore, CC-IP-MOEA-IS reaches the best H values among all the algorithms at t=2 and t=3, despite its time consumption is the longest, indicating that CC-IP-MOEA-IS has the best performance in convergence and distribution. From Fig. 4, we can conclude that the proposed algorithm can archive more and better solutions than IP-MOEA and CC-IP-MOEA-B. Taking Fig. 4a as an example, on the one hand, CC-IP-MOEA-IS offers investors a larger return rate with the same risk loss rate than IP-MOEA. On the other hand, CC-IP-MOEA-IS provides investors more choices with different preferences.</p>
        <p>Focusing on DI-MOPs with time-varying interval parameters, we have proposed a cooperative co-evolutionary algorithm, termed CC-IP-MOEA-IS, by incorporating the interval similarity-based grouping strategy and response strategy into IP-MOEA. In CC-IP-MOEA-IS, all the decision variables are first divided into two groups, interrelated with/without interval parameters, according to the interval similarity-based grouping strategy. Then, two sub-populations are utilized to evolve those groups, with the search space of each sub-population being shrunk, and the capability in tracking the optimal solutions being prompted. At the end of each generation, the interval similarity of objectives is adopted to detect whether the optimization problem changes or not. Once a change is detected, the two groups are re-initialized according to the proposed response strategy. To evaluate CC-IP-MOEA-IS, we have employed it to address eight benchmark optimization cases provided in Table II in comparison with five algorithms and two response strategies. The experimental results demonstrate that CC-IP-MOEA-IS, the interval similarity-based grouping and the proposed response strategies are very competitive among the comparative algorithms and strategies on most optimization instances whose decision variables are separable with interval parameters. In addition, the proposed algorithm and strategies have better performance on optimization instances whose decision variables are inseparable with interval parameters, such as ZDT3 DI , FDA1 DI , and FDA2 DI .Focusing on DI-MOPs with time-varying interval parameters, we have proposed a cooperative co-evolutionary algorithm, termed CC-IP-MOEA-IS, by incorporating the interval similarity-based grouping strategy and response strategy into IP-MOEA. In CC-IP-MOEA-IS, all the decision variables are first divided into two groups, interrelated with/without interval parameters, according to the interval similarity-based grouping strategy. Then, two sub-populations are utilized to evolve those groups, with the search space of each sub-population being shrunk, and the capability in tracking the optimal solutions being prompted. At the end of each generation, the interval similarity of objectives is adopted to detect whether the optimization problem changes or not. Once a change is detected, the two groups are re-initialized according to the proposed response strategy. To evaluate CC-IP-MOEA-IS, we have employed it to address eight benchmark optimization cases provided in Table II in comparison with five algorithms and two response strategies. The experimental results demonstrate that CC-IP-MOEA-IS, the interval similarity-based grouping and the proposed response strategies are very competitive among the comparative algorithms and strategies on most optimization instances whose decision variables are separable with interval parameters. In addition, the proposed algorithm and strategies have better performance on optimization instances whose decision variables are inseparable with interval parameters, such as ZDT3 DI , FDA1 DI , and FDA2 DI .</p>
        <p>It is worth noting that we have evaluated the proposed algorithm only on a few benchmark optimization instances, and investigated its scalability by applying it to a practical optimization problem. In addition, the two sub-populations utilized to optimize the two groups have the same size, which consumes many computing resources in searching for optimal solutions of a group which is weakly impacted by the changing interval parameters. For these problems, new efficient methods are required to explore, which will be the focus of our future work.It is worth noting that we have evaluated the proposed algorithm only on a few benchmark optimization instances, and investigated its scalability by applying it to a practical optimization problem. In addition, the two sub-populations utilized to optimize the two groups have the same size, which consumes many computing resources in searching for optimal solutions of a group which is weakly impacted by the changing interval parameters. For these problems, new efficient methods are required to explore, which will be the focus of our future work.</p>
        <p>et al. proposed an ensemble of multi-objective Algorithm 1: 5 Change detection (Algorithm 3); 6 if the change occurs thenet al. proposed an ensemble of multi-objective Algorithm 1: 5 Change detection (Algorithm 3); 6 if the change occurs then</p>
        <p>77</p>
        <p>This work was jointly supported by National Natural Science Foundation of ChinaThis work was jointly supported by National Natural Science Foundation of China</p>
        <p>* )'$ ', ,302($ ',302($$ ',302($% &amp;&amp;,302($$ &amp;&amp;,302($% &amp;&amp;,302($,6 (a) * )'$ ', (QYLURQPHQW * )'$ ', ,302($ ',302($$ ',302($% &amp;&amp;,302($$ &amp;&amp;,302($% &amp;&amp;,302($,6 * )'$ ', (QYLURQPHQW * '6: ', ,302($ ',302($$ ',302($% &amp;&amp;,302($$ &amp;&amp;,302($% &amp;&amp;,302($,6 (c) * '6: ', (QYLURQPHQW * '6: ', ,302($ ',302($$ ',302($% &amp;&amp;,302($$ &amp;&amp;,302($% &amp;&amp;,302($,6 (d) , ='7 ', (QYLURQPHQW , )'$ ', ,302($ ',302($$ ',302($% &amp;&amp;,302($$ &amp;&amp;,302($% &amp;&amp;,302($,6 (e) , )'$ ', (QYLURQPHQW , )'$ ', ,302($ ',302($$ ',302($% &amp;&amp;,302($$ &amp;&amp;,302($% &amp;&amp;,302($,6 (f) , )'$ ', (QYLURQPHQW , '6: ', ,302($ ',302($$ ',302($% &amp;&amp;,302($$ &amp;&amp;,302($% &amp;&amp;,302($,6 (g) , '6: ', (QYLURQPHQW , '6: ', ,302($ ',302($$ ',302($% &amp;&amp;,302($$ &amp;&amp;,302($% &amp;&amp;,302($,6* )'$ ', ,302($ ',302($$ ',302($% &amp;&amp;,302($$ &amp;&amp;,302($% &amp;&amp;,302($,6 (a) * )'$ ', (QYLURQPHQW * )'$ ', ,302($ ',302($$ ',302($% &amp;&amp;,302($$ &amp;&amp;,302($% &amp;&amp;,302($,6 * )'$ ', (QYLURQPHQW * '6: ', ,302($ ',302($$ ',302($% &amp;&amp;,302($$ &amp;&amp;,302($% &amp;&amp;,302($,6 (c) * '6: ', (QYLURQPHQW * '6: ', ,302($ ',302($$ ',302($% &amp;&amp;,302($$ &amp;&amp;,302($% &amp;&amp;,302($,6 (d) , ='7 ', (QYLURQPHQW , )'$ ', ,302($ ',302($$ ',302($% &amp;&amp;,302($$ &amp;&amp;,302($% &amp;&amp;,302($,6 (e) , )'$ ', (QYLURQPHQW , )'$ ', ,302($ ',302($$ ',302($% &amp;&amp;,302($$ &amp;&amp;,302($% &amp;&amp;,302($,6 (f) , )'$ ', (QYLURQPHQW , '6: ', ,302($ ',302($$ ',302($% &amp;&amp;,302($$ &amp;&amp;,302($% &amp;&amp;,302($,6 (g) , '6: ', (QYLURQPHQW , '6: ', ,302($ ',302($$ ',302($% &amp;&amp;,302($$ &amp;&amp;,302($% &amp;&amp;,302($,6</p>
    </text>
</tei>
