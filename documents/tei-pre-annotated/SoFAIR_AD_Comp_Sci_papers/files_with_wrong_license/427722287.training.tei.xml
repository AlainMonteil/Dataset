<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-13T15:20+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>Time series feature extraction is one of the preliminary steps of conventional machine learning pipelines. Quite often, this process ends being a time consuming and complex task as data scientists must consider a combination between a multitude of domain knowledge factors and coding implementation. We present in this paper a Python package entitled 
            <rs type="software">Time Series Feature Extraction Library (TSFEL)</rs>, which computes over 60 different features extracted across temporal, statistical and spectral domains. User customisation is achieved using either an online interface or a conventional Python 
            <rs type="software">package</rs> for more flexibility and integration into real deployment scenarios. 
            <rs type="software">TSFEL</rs> is designed to support the process of fast exploratory data analysis and feature extraction on time series with computational cost evaluation.
        </p>
        <p>Over the last years, the technological breakthroughs motivated by the rise of Internet-of-Things led to the proliferation of sensors to measure a plethora of physical processes. Those observations often result in the creation of large quantities of data in the form of time series, which are described as sequences of numerical observations ordered in time. The process of time series feature extraction is one of the preliminary steps in conventional machine learning pipelines and aims to extract a set of properties to characterise time series. The feature extraction is a timeconsuming and complex task, which poses challenges on such a significant and important step of the machine learning stack: ''At the end of the day, some machine learning projects succeed and some fail. What makes the difference? Easily the most important factor is the features used'' [1].Over the last years, the technological breakthroughs motivated by the rise of Internet-of-Things led to the proliferation of sensors to measure a plethora of physical processes. Those observations often result in the creation of large quantities of data in the form of time series, which are described as sequences of numerical observations ordered in time. The process of time series feature extraction is one of the preliminary steps in conventional machine learning pipelines and aims to extract a set of properties to characterise time series. The feature extraction is a timeconsuming and complex task, which poses challenges on such a significant and important step of the machine learning stack: ''At the end of the day, some machine learning projects succeed and some fail. What makes the difference? Easily the most important factor is the features used'' [1].</p>
        <p>We present in this paper a Python package named Time Series Feature Extraction Library (TSFEL), which provides support for fast exploratory analysis supported by an automated process of feature extraction on multidimensional time series.We present in this paper a Python package named Time Series Feature Extraction Library (TSFEL), which provides support for fast exploratory analysis supported by an automated process of feature extraction on multidimensional time series.</p>
        <p>In literature, there exist related packages dedicated to feature extraction, such as FATS [2], CESIUM [3], TSFRESH [4] and HCTSA [5]. Those packages inspired the creation of TSFEL and in the future they may be combined. TSFEL extends their scope by integrating a more thorough analysis of the temporal complexity of the features. This fact is relevant in scenarios where feature extraction is computed in embedded devices such as wearables, with limited computational resources. TSFEL is being used to support feature extraction on inertial data acquired by smartphones and wearables in the contexts of Human Activity Recognition (HAR) [6][7][8][9], rehabilitation [10][11][12] and anomaly detection [13].In literature, there exist related packages dedicated to feature extraction, such as FATS [2], CESIUM [3], TSFRESH [4] and HCTSA [5]. Those packages inspired the creation of TSFEL and in the future they may be combined. TSFEL extends their scope by integrating a more thorough analysis of the temporal complexity of the features. This fact is relevant in scenarios where feature extraction is computed in embedded devices such as wearables, with limited computational resources. TSFEL is being used to support feature extraction on inertial data acquired by smartphones and wearables in the contexts of Human Activity Recognition (HAR) [6][7][8][9], rehabilitation [10][11][12] and anomaly detection [13].</p>
        <p>Users can interact with TSFEL in two forms: a backend built upon a Python package aimed for advance users; a frontend displayed in online spreadsheets aimed for beginners. For both cases, TSFEL also provides a crucial aspect for the deployment of machine learning algorithms in real scenarios -a comprehensive evaluation of the computational complexity of each feature. Fig. 1 summarises the TSFEL processing pipeline. Time series are passed as inputs for the main TSFEL extraction method either as arrays previously loaded in memory or stored in files on a dataset. Since TSFEL can handle multidimensional time series, a set of preprocessing methods is afterwards applied to ensure that not only the signal quality is adequate, but also, time series synchronisation, so that the window calculation process is properly achieved. After the feature extraction, the result is saved using a standard schema ready to be digested by most of the classification and data mining platforms. Each line corresponds to a window with the results of the feature extraction methods stored along the corresponding columns.Users can interact with TSFEL in two forms: a backend built upon a Python package aimed for advance users; a frontend displayed in online spreadsheets aimed for beginners. For both cases, TSFEL also provides a crucial aspect for the deployment of machine learning algorithms in real scenarios -a comprehensive evaluation of the computational complexity of each feature. Fig. 1 summarises the TSFEL processing pipeline. Time series are passed as inputs for the main TSFEL extraction method either as arrays previously loaded in memory or stored in files on a dataset. Since TSFEL can handle multidimensional time series, a set of preprocessing methods is afterwards applied to ensure that not only the signal quality is adequate, but also, time series synchronisation, so that the window calculation process is properly achieved. After the feature extraction, the result is saved using a standard schema ready to be digested by most of the classification and data mining platforms. Each line corresponds to a window with the results of the feature extraction methods stored along the corresponding columns.</p>
        <p>2 https://github.com/fraunhoferportugal/tsfel.2 https://github.com/fraunhoferportugal/tsfel.</p>
        <p>When deploying machine learning applications, a proper set of features can improve the performance of the algorithms and reduce the computational complexity. In the signal windowing step, time series are divided into user-defined fixed length time windows (which can optionally have some overlap), from which features are extracted.When deploying machine learning applications, a proper set of features can improve the performance of the algorithms and reduce the computational complexity. In the signal windowing step, time series are divided into user-defined fixed length time windows (which can optionally have some overlap), from which features are extracted.</p>
        <p>Before the feature extraction step, it is essential to ensure adequate data quality. The time series can be passed to the feature extraction method using two methods:Before the feature extraction step, it is essential to ensure adequate data quality. The time series can be passed to the feature extraction method using two methods:</p>
        <p>• dataset_features_extractor: receives a string containing the dataset root_directory and the configuration feature dictionary feat_dict. To ensure that unequal length time series become synchronised, time-based parameters must be defined, namely the sampling frequency in Hertz and the time_unit defining the temporal scale of the dataset. This method might optionally receive as input the output_directory where the extracted features will be saved in a delimited text file format and the search_criteria, which will be used to match and filter the files which are the ones more relevant to the user.• dataset_features_extractor: receives a string containing the dataset root_directory and the configuration feature dictionary feat_dict. To ensure that unequal length time series become synchronised, time-based parameters must be defined, namely the sampling frequency in Hertz and the time_unit defining the temporal scale of the dataset. This method might optionally receive as input the output_directory where the extracted features will be saved in a delimited text file format and the search_criteria, which will be used to match and filter the files which are the ones more relevant to the user.</p>
        <p>• time_series_features_extractor: receives a multidimensional structure with time series stored as variables in memory, the configuration feature dictionary feat_dict and the sampling frequency in Hertz.• time_series_features_extractor: receives a multidimensional structure with time series stored as variables in memory, the configuration feature dictionary feat_dict and the sampling frequency in Hertz.</p>
        <p>Both methods receive additional parameters related to window metadata, defining the window parameters used for the feature extraction, such as window size in the number of samples and the overlap between windows, defined as a percentage value.Both methods receive additional parameters related to window metadata, defining the window parameters used for the feature extraction, such as window size in the number of samples and the overlap between windows, defined as a percentage value.</p>
        <p>The TSFEL features can be grouped into three categories according to the domain where they are calculated: temporal, statistical and spectral domain. The listing of the available features and detailed implementation containing mathematical formulation, pseudo-code and references are available at Appendix.The TSFEL features can be grouped into three categories according to the domain where they are calculated: temporal, statistical and spectral domain. The listing of the available features and detailed implementation containing mathematical formulation, pseudo-code and references are available at Appendix.</p>
        <p>All features implemented are classified by their time complexity according to the following known models: 1). Firstly, a set of time series with incremental length are synthetically generated from a sinusoidal model. Secondly, the feature extraction runtime is calculated for each incremental length time series. This process allows creating a curve displaying the relationship between time series length and execution time for each feature. Thirdly, we use a non-linear least squares to fit the runtime results to the known models. For each feature, we assign the time complexity which minimises the χ 2 among all the time complexity models.All features implemented are classified by their time complexity according to the following known models: 1). Firstly, a set of time series with incremental length are synthetically generated from a sinusoidal model. Secondly, the feature extraction runtime is calculated for each incremental length time series. This process allows creating a curve displaying the relationship between time series length and execution time for each feature. Thirdly, we use a non-linear least squares to fit the runtime results to the known models. For each feature, we assign the time complexity which minimises the χ 2 among all the time complexity models.</p>
        <p>In order to properly maintain a significant number of different feature extraction methods, it is necessary to systematically verify the feature extraction implementation. A set of unit tests were created for each feature. Those tests compare the values obtained from TSFEL against a set of synthetic time series with a known distribution. Different time series synthesis parameters are used to cover a variety of properties (e.g. constant values, modulation of amplitude offsets, periodicity and noise addition). The contribution guidelines to incorporate new features in TSFEL require the introduction of at least one unit test for the new feature.In order to properly maintain a significant number of different feature extraction methods, it is necessary to systematically verify the feature extraction implementation. A set of unit tests were created for each feature. Those tests compare the values obtained from TSFEL against a set of synthetic time series with a known distribution. Different time series synthesis parameters are used to cover a variety of properties (e.g. constant values, modulation of amplitude offsets, periodicity and noise addition). The contribution guidelines to incorporate new features in TSFEL require the introduction of at least one unit test for the new feature.</p>
        <p>TSFEL provides flexibility for users to add their personal features to those already available on the library. Users are require to write the feature extraction method and declare its domain.TSFEL provides flexibility for users to add their personal features to those already available on the library. Users are require to write the feature extraction method and declare its domain.</p>
        <p>We now provide an illustrative example with a typical pipeline to extract features in the context of HAR. We used a subset from the dataset collected by [12], composed of time series retrieved by accelerometer, gyroscope and goniometer sensors from two subjects performing four activities: stand, sit, stand-to-sit and sitto-stand. Developers can accomplish the feature extraction using two distinct methods: conduct the feature extraction on a time series already loaded in memory or conduct the feature extraction across an entire time series database organised in directories. At line 4 of Fig. 2 the user loads a configuration setting which is available as a template. The get_all_features() template enables all the implemented features to be extracted. In line 7 a dataset composed of univariate time series from 3 different sensors is loaded. At line 8 the feature extraction process is accomplished. The method receives as inputs the configuration settings, the time series passed as a pandas' dataframe df, the sampling frequency in Hertz, the window size defined as number of samples and no overlap percentage between consecutive windows. Fig. 3 summarises the interaction required to use TSFEL to extract features from a dataset stored in files across system directories. In line 4 we define the root directory of the dataset. The configuration file is defined on line 5. The main method is present on lines 7 to 13. The method receives as inputs the root dataset directory, the configuration file, the search criteria defined by keywords that will match the designated files for feature extraction, the resample parameters (which will configure the resampling methods to ensure the multivariate time series are synchronised prior dividing data into windows), and the parameters which define the window size and overlap.We now provide an illustrative example with a typical pipeline to extract features in the context of HAR. We used a subset from the dataset collected by [12], composed of time series retrieved by accelerometer, gyroscope and goniometer sensors from two subjects performing four activities: stand, sit, stand-to-sit and sitto-stand. Developers can accomplish the feature extraction using two distinct methods: conduct the feature extraction on a time series already loaded in memory or conduct the feature extraction across an entire time series database organised in directories. At line 4 of Fig. 2 the user loads a configuration setting which is available as a template. The get_all_features() template enables all the implemented features to be extracted. In line 7 a dataset composed of univariate time series from 3 different sensors is loaded. At line 8 the feature extraction process is accomplished. The method receives as inputs the configuration settings, the time series passed as a pandas' dataframe df, the sampling frequency in Hertz, the window size defined as number of samples and no overlap percentage between consecutive windows. Fig. 3 summarises the interaction required to use TSFEL to extract features from a dataset stored in files across system directories. In line 4 we define the root directory of the dataset. The configuration file is defined on line 5. The main method is present on lines 7 to 13. The method receives as inputs the root dataset directory, the configuration file, the search criteria defined by keywords that will match the designated files for feature extraction, the resample parameters (which will configure the resampling methods to ensure the multivariate time series are synchronised prior dividing data into windows), and the parameters which define the window size and overlap.</p>
        <p>Fig. 4 represents a set of the extracted features in the form of a horizon plot. The x-axis contains three repetitions of the following sequence of activities: sit, sit-to-stand, stand, standto-sit. The y-axis corresponds to the extracted features, and the range of y-axis to a third of the maximum value of each feature, represented by the darkest values. The blue and red colours correspond to positive and negative values, respectively. The goniometer and gyroscope sensors allow to discriminate between static activities (sit and stand) and transitions (sit-to-stand and stand-to-sit). The acc_x_Upper_Min and acc_z_Upper_Min clearly distinguish between sit and stand. Finally, the goniometer_y_Slope is an adequate feature to discriminate between sit-to-stand and stand-to-sit.Fig. 4 represents a set of the extracted features in the form of a horizon plot. The x-axis contains three repetitions of the following sequence of activities: sit, sit-to-stand, stand, standto-sit. The y-axis corresponds to the extracted features, and the range of y-axis to a third of the maximum value of each feature, represented by the darkest values. The blue and red colours correspond to positive and negative values, respectively. The goniometer and gyroscope sensors allow to discriminate between static activities (sit and stand) and transitions (sit-to-stand and stand-to-sit). The acc_x_Upper_Min and acc_z_Upper_Min clearly distinguish between sit and stand. Finally, the goniometer_y_Slope is an adequate feature to discriminate between sit-to-stand and stand-to-sit.</p>
        <p>While working with the analysis of heterogeneous time series data from multiple sources, the process of feature engineering (i.e. transforming raw data into features to enter as inputs for machine learning models) is a time-consuming and complex task.While working with the analysis of heterogeneous time series data from multiple sources, the process of feature engineering (i.e. transforming raw data into features to enter as inputs for machine learning models) is a time-consuming and complex task.</p>
        <p>TSFEL helps data scientists by creating an abstraction layer composed of a comprehensive list of time series feature extraction techniques. Those methods were aggregated from several scientific domains and previously validated on the context of HAR. The output of the TSFEL is a standardised file format ready to be digested by most of time series classification libraries like Orange, Weka or scikit-learn. TSFEL also provides a systematic methodology to record the inputs, the dataset metadata and the parameters of feature extraction experiments, promoting openness and reproducibility of the scientific method among researchers. TSFEL relies on a master configuration file which stores the metadata and can be easily edited thorough a spreadsheet configuration manager.TSFEL helps data scientists by creating an abstraction layer composed of a comprehensive list of time series feature extraction techniques. Those methods were aggregated from several scientific domains and previously validated on the context of HAR. The output of the TSFEL is a standardised file format ready to be digested by most of time series classification libraries like Orange, Weka or scikit-learn. TSFEL also provides a systematic methodology to record the inputs, the dataset metadata and the parameters of feature extraction experiments, promoting openness and reproducibility of the scientific method among researchers. TSFEL relies on a master configuration file which stores the metadata and can be easily edited thorough a spreadsheet configuration manager.</p>
        <p>With the proliferation of Cyber-Physical Systems, more data and processes are being digitised across several sectors. Whilst machine learning holds the promise to uncover hidden patterns of big data to gain new insights on data-driven business, the deployment of such systems might still be limited by scalability concerns. For example, in the context of large manufacturing plants, the anomaly detection on their products based on sensors producing high data volume, requires a compromise between high accuracy and low latency. Therefore, the complete pipeline should be designed with a mindset of being able to run the inference step in near real-time. The successful implementation of this approach should be accomplished bottom-up, meaning to have design concerns on the initial stages of the machine learning stack. TSFEL helps mitigate these technology adoption risks by providing the user with a comprehensive list of feature extraction methods on time series with an associated estimate of computational complexity, enabling to have an idea of the computational cost of the feature extraction on the early stages of the machine learning stack.With the proliferation of Cyber-Physical Systems, more data and processes are being digitised across several sectors. Whilst machine learning holds the promise to uncover hidden patterns of big data to gain new insights on data-driven business, the deployment of such systems might still be limited by scalability concerns. For example, in the context of large manufacturing plants, the anomaly detection on their products based on sensors producing high data volume, requires a compromise between high accuracy and low latency. Therefore, the complete pipeline should be designed with a mindset of being able to run the inference step in near real-time. The successful implementation of this approach should be accomplished bottom-up, meaning to have design concerns on the initial stages of the machine learning stack. TSFEL helps mitigate these technology adoption risks by providing the user with a comprehensive list of feature extraction methods on time series with an associated estimate of computational complexity, enabling to have an idea of the computational cost of the feature extraction on the early stages of the machine learning stack.</p>
        <p>We have developed a Python package entitled Time Series Feature Extraction Library, which provides a comprehensive list of feature extraction methods for time series. Over 60 different features are extracted across temporal, statistical and spectral domains. TSFEL includes unit tests for every implemented feature extraction method and proper code documentation. Besides these strongly oriented coding guidelines, this project has three main broad contributions to the scientific community: TSFEL can be used through a user interface built upon 
            <rs type="software">Google Sheets</rs>, requiring no installation whatsoever, allowing rapid prototyping and exploratory time series analysis, with reduced coding effort. More expert users can delve directly into TSFEL backend for more flexibility and integration with Python projects.
        </p>
        <p>A master configuration file is used to record the experiment parameters, emphasising traceability and reproducibility.A master configuration file is used to record the experiment parameters, emphasising traceability and reproducibility.</p>
        <p>The feature extraction process is performed either on time series already stored in the memory environment or using a list of directories containing time series data files. The latter is achieved using a search criteria which filters the files relevant to the user. This process aims to reduce the time spent by the user in preparing data aggregation code for every application. This design of TSFEL is oriented to have from the early stage of the machine learning pipeline an estimate regarding the computational complexity of the features being extracted, aligned with the ''Edge artificial intelligence'' strategy to empower the deployment of machine learning applications in large scale environments.The feature extraction process is performed either on time series already stored in the memory environment or using a list of directories containing time series data files. The latter is achieved using a search criteria which filters the files relevant to the user. This process aims to reduce the time spent by the user in preparing data aggregation code for every application. This design of TSFEL is oriented to have from the early stage of the machine learning pipeline an estimate regarding the computational complexity of the features being extracted, aligned with the ''Edge artificial intelligence'' strategy to empower the deployment of machine learning applications in large scale environments.</p>
        <p>Although multiple features are extracted across three different domains, there is still room for improvement. Thus, as future work, features regarding new domains such as nonlinear features will be introduced.Although multiple features are extracted across three different domains, there is still room for improvement. Thus, as future work, features regarding new domains such as nonlinear features will be introduced.</p>
        <p>TSFEL is open for contributions and invites users to extend the library with new time series feature extraction methods across different scientific disciplines.TSFEL is open for contributions and invites users to extend the library with new time series feature extraction methods across different scientific disciplines.</p>
        <p>The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p>
        <p>Let s represent the time series signal vector, ∆s the discrete derivative of s, t the correspondent time vector, fs signal's sampling frequency, and N the length of s. Additionally, P(x) states probability.Let s represent the time series signal vector, ∆s the discrete derivative of s, t the correspondent time vector, fs signal's sampling frequency, and N the length of s. Additionally, P(x) states probability.</p>
        <p>Absolute energy:Absolute energy:</p>
        <p>Maximum peaks: The following features are implemented according to the following references: Kurtosis [14], Skewness [14], Maximum [15],Maximum peaks: The following features are implemented according to the following references: Kurtosis [14], Skewness [14], Maximum [15],</p>
        <p>Minimum [15], Mean [15], Median [15] and ECDF [16], ECDF Percentile [16].Minimum [15], Mean [15], Median [15] and ECDF [16], ECDF Percentile [16].</p>
        <p>Wavelet absolute mean: |mean(wavelet(s))| The following features are implemented according to the following references: Maximum Power Spectrum [17], Spectral Centroid [18], Decrease [18], Kurtosis [18], Skewness [18], Spread [18], Slope [18], Variation [18], Spectral Roll-off [7], Roll-on [7], Human Range Energy, [19], MFCC [20], LPCC [20], Power Bandwidth [21], Spectral Entropy [22], Wavelet Entropy [23] and Wavelet Energy [24].Wavelet absolute mean: |mean(wavelet(s))| The following features are implemented according to the following references: Maximum Power Spectrum [17], Spectral Centroid [18], Decrease [18], Kurtosis [18], Skewness [18], Spread [18], Slope [18], Variation [18], Spectral Roll-off [7], Roll-on [7], Human Range Energy, [19], MFCC [20], LPCC [20], Power Bandwidth [21], Spectral Entropy [22], Wavelet Entropy [23] and Wavelet Energy [24].</p>
        <p>1: INPUT: s, t ← s is the signal and t the time 2: OUTPUT: frequency, magnitude 31: INPUT: s, t ← s is the signal and t the time 2: OUTPUT: frequency, magnitude 3</p>
        <p>if N Median absolute deviation: median(|s -median(s)|) Variance: mean(|s -mean(s)|) 2 ECDF percentile count: 1: INPUT: s, percentile value (p) 2: OUTPUT: Cumulative sum of samples that are less than the percentile. 3: x = sorted s 4: y = ECDF values 5: percentilecount = length of x, where y &lt; p ECDF slope: 1: INPUT: s, two percentile values (p init , p end ) 2: OUTPUT: Slope of the ECDF between the two percentiles 3: x init , x end = the s values for the given percentiles 4: slope = p end -p init x end -x initif N Median absolute deviation: median(|s -median(s)|) Variance: mean(|s -mean(s)|) 2 ECDF percentile count: 1: INPUT: s, percentile value (p) 2: OUTPUT: Cumulative sum of samples that are less than the percentile. 3: x = sorted s 4: y = ECDF values 5: percentilecount = length of x, where y &lt; p ECDF slope: 1: INPUT: s, two percentile values (p init , p end ) 2: OUTPUT: Slope of the ECDF between the two percentiles 3: x init , x end = the s values for the given percentiles 4: slope = p end -p init x end -x init</p>
        <p>1: INPUT: s, t 2: OUTPUT: Fundamental Frequency (ff ) 3: Computes the Fast Fourier Transform: freq, fmag = fft(t, s) 4: Finds the lowest frequency of vibration (ff ) Maximum frequency: 1: INPUT: s, fs 2: OUTPUT: Maximum Frequency (mf ) 3: Computes the Fast Fourier Transform: freq, fmag = fft(t, s)1: INPUT: s, t 2: OUTPUT: Fundamental Frequency (ff ) 3: Computes the Fast Fourier Transform: freq, fmag = fft(t, s) 4: Finds the lowest frequency of vibration (ff ) Maximum frequency: 1: INPUT: s, fs 2: OUTPUT: Maximum Frequency (mf ) 3: Computes the Fast Fourier Transform: freq, fmag = fft(t, s)</p>
        <p>4: Cumulative sum of the magnitude (cumsum fmag ) 5: Returns the frequency with 95% of the cumsum fmag (mf ) Median frequency: 1: INPUT: s, fs 2: OUTPUT: Median Frequency (medf ) 3: Computes the Fast Fourier Transform: freq, fmag = fft(t, s) 4: Cumulative sum of the magnitude (cumsum fmag ) 5: Returns the frequency with 50% of the cumsum fmag (medf ) Spectral maximum peaks: 1: INPUT: s, fs 2: OUTPUT: 4: Returns the maximum number of peaks of fmag4: Cumulative sum of the magnitude (cumsum fmag ) 5: Returns the frequency with 95% of the cumsum fmag (mf ) Median frequency: 1: INPUT: s, fs 2: OUTPUT: Median Frequency (medf ) 3: Computes the Fast Fourier Transform: freq, fmag = fft(t, s) 4: Cumulative sum of the magnitude (cumsum fmag ) 5: Returns the frequency with 50% of the cumsum fmag (medf ) Spectral maximum peaks: 1: INPUT: s, fs 2: OUTPUT: 4: Returns the maximum number of peaks of fmag</p>
        <p>We would like to acknowledge the financial support obtained from the project Total Integrated and Predictive Manufacturing System Platform for Industry 4.0, co-funded by Portugal 2020, framed under the COMPETE 2020 (Operational Programme Competitiveness and Internationalisation) and European Regional Development Fund (ERDF) from European Union (EU), with operation code POCI-01-0247-FEDER-038436.We would like to acknowledge the financial support obtained from the project Total Integrated and Predictive Manufacturing System Platform for Industry 4.0, co-funded by Portugal 2020, framed under the COMPETE 2020 (Operational Programme Competitiveness and Internationalisation) and European Regional Development Fund (ERDF) from European Union (EU), with operation code POCI-01-0247-FEDER-038436.</p>
    </text>
</tei>
