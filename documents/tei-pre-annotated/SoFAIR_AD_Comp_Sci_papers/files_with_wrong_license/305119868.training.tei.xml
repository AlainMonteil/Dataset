<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-13T15:19+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>Please refer to published version for the most recent bibliographic citation information. If a published version is known of, the repository item page linked to above, will contain details on accessing it.Please refer to published version for the most recent bibliographic citation information. If a published version is known of, the repository item page linked to above, will contain details on accessing it.</p>
        <p>Tumor microenvironment (TME) plays a crucial role in the development of intra-tumor heterogeneity (ITH) (Marusyk et al. (2012)). It is, therefore, vital that we develop ways to systematically profile spatial characteristics of the TME in order to better understand tumor heterogeneity and consequently exploit it for therapeutic gain (Alizadeh et al. (2015)). Computational pathology is a rapidly emerging discipline (van der Laak et al. (2018)), spurred by the recent revolution in digital pathology (DP) imaging which has been shown to be non-inferior to glass slide based visual assessment by pathologists for routine diagnostic purposes (Snead et al. (2016)), concerned with the development of computational algorithms for the processing and analysis of DP images. Automatic tissue phenotyping, identifi- Because of the importance of this problem in computational pathology, a number of approaches have been proposed for the automatic identification of tissue phenotypes (Kather et al. (2016(Kather et al. ( , 2019)); Nalisnik et al. (2017); Sirinukunwattana et al. (2018); Bianconi et al. (2015); Huang et al. (2017b); Lazebnik et al. (2006);Linder et al. (2012); Sarkar and Acton (2018); Srinivas et al. (2014); Tamura et al. (1978); Vu et al. (2016); Wright et al. (2009); Xu et al. (2016Xu et al. ( , 2017))). Texture analysis is a commonly used approach for tissue phenotyping (Kather et al. (2016); Bianconi et al. (2015); Linder et al. (2012); Tamura et al. (1978)), whereby texture features such as local binary patterns and Gabor features of different histology images are computed to train classifiers which are then used to predict distinct tissue types. For instance, Sarkar and Acton (2018) recently proposed a saliency guided dictionary approach where Gabor features were extracted for histology image classification. Bianconi et al. (2015) proposed five different kinds of perception-based texture features, while Linder et al. (2012) reported a simple SVM classifier trained on a set of local binary patterns and contrast measure features. Although texturebased methods may be attractive due to their simplicity, texture features do not fully capture the biological significance of tissue types resulting in performance degradation (Kather et al. (2016)).Tumor microenvironment (TME) plays a crucial role in the development of intra-tumor heterogeneity (ITH) (Marusyk et al. (2012)). It is, therefore, vital that we develop ways to systematically profile spatial characteristics of the TME in order to better understand tumor heterogeneity and consequently exploit it for therapeutic gain (Alizadeh et al. (2015)). Computational pathology is a rapidly emerging discipline (van der Laak et al. (2018)), spurred by the recent revolution in digital pathology (DP) imaging which has been shown to be non-inferior to glass slide based visual assessment by pathologists for routine diagnostic purposes (Snead et al. (2016)), concerned with the development of computational algorithms for the processing and analysis of DP images. Automatic tissue phenotyping, identifi- Because of the importance of this problem in computational pathology, a number of approaches have been proposed for the automatic identification of tissue phenotypes (Kather et al. (2016(Kather et al. ( , 2019)); Nalisnik et al. (2017); Sirinukunwattana et al. (2018); Bianconi et al. (2015); Huang et al. (2017b); Lazebnik et al. (2006);Linder et al. (2012); Sarkar and Acton (2018); Srinivas et al. (2014); Tamura et al. (1978); Vu et al. (2016); Wright et al. (2009); Xu et al. (2016Xu et al. ( , 2017))). Texture analysis is a commonly used approach for tissue phenotyping (Kather et al. (2016); Bianconi et al. (2015); Linder et al. (2012); Tamura et al. (1978)), whereby texture features such as local binary patterns and Gabor features of different histology images are computed to train classifiers which are then used to predict distinct tissue types. For instance, Sarkar and Acton (2018) recently proposed a saliency guided dictionary approach where Gabor features were extracted for histology image classification. Bianconi et al. (2015) proposed five different kinds of perception-based texture features, while Linder et al. (2012) reported a simple SVM classifier trained on a set of local binary patterns and contrast measure features. Although texturebased methods may be attractive due to their simplicity, texture features do not fully capture the biological significance of tissue types resulting in performance degradation (Kather et al. (2016)).</p>
        <p>In recent years, a growing number of deep learning methods have also been proposed to classify WSIs into distinct tissue types (Nalisnik et al. (2017); Huang et al. (2017b); Xu et al. (2016Xu et al. ( , 2017)); Janowczyk and Madabhushi (2016)). Xu et al. (2016) proposed a fully supervised deep CNN model for segmentation and classification of epithelial and stromal regions in histology images. Huang et al. (2017b) proposed an unsupervised domain adaptation deep network for segmenting histology images into meaningful regions. Most deep learning methods for tissue phenotyping share a common denominator which is their need for large amount of annotated histology data for training which may be tedious to obtain (Huang et al. (2017b); Janowczyk and Madabhushi (2016)). Another shortcoming of most existing literature is that although encouraging results were reported in these studies, most of the current methods are limited to the discrimination of tumor epithelium and stroma only (Bianconi et al. (2015), Huang et al. (2017b), Linder et al. (2012), Xu et al. (2016)). Like most solid tumors, colorectal cancer (CRC) tissue does not consist of only tumor and stroma components (Kather et al. (2016)). It also contains a complex rich mix of several other tissue phenotypes including smooth muscle, inflammatory, necrotic, complex stroma, and benign tissue, as shown in Fig. 1.In recent years, a growing number of deep learning methods have also been proposed to classify WSIs into distinct tissue types (Nalisnik et al. (2017); Huang et al. (2017b); Xu et al. (2016Xu et al. ( , 2017)); Janowczyk and Madabhushi (2016)). Xu et al. (2016) proposed a fully supervised deep CNN model for segmentation and classification of epithelial and stromal regions in histology images. Huang et al. (2017b) proposed an unsupervised domain adaptation deep network for segmenting histology images into meaningful regions. Most deep learning methods for tissue phenotyping share a common denominator which is their need for large amount of annotated histology data for training which may be tedious to obtain (Huang et al. (2017b); Janowczyk and Madabhushi (2016)). Another shortcoming of most existing literature is that although encouraging results were reported in these studies, most of the current methods are limited to the discrimination of tumor epithelium and stroma only (Bianconi et al. (2015), Huang et al. (2017b), Linder et al. (2012), Xu et al. (2016)). Like most solid tumors, colorectal cancer (CRC) tissue does not consist of only tumor and stroma components (Kather et al. (2016)). It also contains a complex rich mix of several other tissue phenotypes including smooth muscle, inflammatory, necrotic, complex stroma, and benign tissue, as shown in Fig. 1.</p>
        <p>In this paper, we propose the concept of cellular communities comprising of different types of cells and pose the problem of tissue phenotyping as a cellular community detection problem. The premise is that spatially adjacent cells are more likely to receive intercellular signals from each other than from cells that are further away. It is also well established that the intercellular signalling between various types of cells in the microenvironment can lead to the progression of cancer (Alberts et al. (2015)). In clinical practice, pathologists consider the spatial distributions of different cellular components while identifying complex tissue phenotypes, such as the complex stroma.In this paper, we propose the concept of cellular communities comprising of different types of cells and pose the problem of tissue phenotyping as a cellular community detection problem. The premise is that spatially adjacent cells are more likely to receive intercellular signals from each other than from cells that are further away. It is also well established that the intercellular signalling between various types of cells in the microenvironment can lead to the progression of cancer (Alberts et al. (2015)). In clinical practice, pathologists consider the spatial distributions of different cellular components while identifying complex tissue phenotypes, such as the complex stroma.</p>
        <p>Community detection methods have attracted a good deal of attention in the literature for understanding real-world complex networks in recent years, see for instance (Fortunato (2010); Harenberg et al. (2014); Mahmood et al. (2017)). The edges and nodes in a network are often inhomogeneous, resulting in groups of nodes with higher concentration of edges known as communities that share many common attributes and similar behaviour. Different tissue types such as stroma, tumor, and necrotic etc., also form local cellular communities which can play an important role in the interpretation of WSIs as shown in Fig. 1. We propose a novel semi-supervised community detection algorithm for automatic recognition of distinct tissue phenotypes in a colon cancer WSI. We first construct local cell-cell networks using potential cell-cell connection between cells as features and whereby adjacent cells are connected with each other while distant cells are not, taking into account the various ranges of cell signalling. Dividing a WSI into several thousand patches, we then construct a patch-level graph for the WSI using the cell-cell connection frequencies as features. Finally, we identify tissue phenotypes by mining in the patch-level graph for cellular communities that are biologically meaningful and clinically relevant.Community detection methods have attracted a good deal of attention in the literature for understanding real-world complex networks in recent years, see for instance (Fortunato (2010); Harenberg et al. (2014); Mahmood et al. (2017)). The edges and nodes in a network are often inhomogeneous, resulting in groups of nodes with higher concentration of edges known as communities that share many common attributes and similar behaviour. Different tissue types such as stroma, tumor, and necrotic etc., also form local cellular communities which can play an important role in the interpretation of WSIs as shown in Fig. 1. We propose a novel semi-supervised community detection algorithm for automatic recognition of distinct tissue phenotypes in a colon cancer WSI. We first construct local cell-cell networks using potential cell-cell connection between cells as features and whereby adjacent cells are connected with each other while distant cells are not, taking into account the various ranges of cell signalling. Dividing a WSI into several thousand patches, we then construct a patch-level graph for the WSI using the cell-cell connection frequencies as features. Finally, we identify tissue phenotypes by mining in the patch-level graph for cellular communities that are biologically meaningful and clinically relevant.</p>
        <p>A major limitation of most community detection methods is the presence of a relatively high number of inter-community edges which makes the detection of communities difficult (For-tunato (2010)). To address this problem, we propose to map the patch-level network nodes to the geometric space by representing each node as a vector of geodesic distances from other nodes in the network. The geodesic density gradient is then computed in the geodesic space and nodes are drifted towards maximum density regions (Mahmood et al. (2017)). After the convergence of the network in the geometric space, simple Kmeans clustering algorithm is used to assign community labels to each patch (see Fig. 1). The nodes in each community represent biologically meaningful tissue components which are distinct from the other communities. An earlier version of this work was presented at the MICCAI Computational Pathology workshop (Javed et al. (2018)). The main contributions of this work are as follows:A major limitation of most community detection methods is the presence of a relatively high number of inter-community edges which makes the detection of communities difficult (For-tunato (2010)). To address this problem, we propose to map the patch-level network nodes to the geometric space by representing each node as a vector of geodesic distances from other nodes in the network. The geodesic density gradient is then computed in the geodesic space and nodes are drifted towards maximum density regions (Mahmood et al. (2017)). After the convergence of the network in the geometric space, simple Kmeans clustering algorithm is used to assign community labels to each patch (see Fig. 1). The nodes in each community represent biologically meaningful tissue components which are distinct from the other communities. An earlier version of this work was presented at the MICCAI Computational Pathology workshop (Javed et al. (2018)). The main contributions of this work are as follows:</p>
        <p>1. Instead of using texture features to represent a patch of WSI, we consider the potential cell-cell connections between various types of cells as representative features of a patch. These features are biologically more meaningful and better capture the distribution of different types of cells in the histology patch.1. Instead of using texture features to represent a patch of WSI, we consider the potential cell-cell connections between various types of cells as representative features of a patch. These features are biologically more meaningful and better capture the distribution of different types of cells in the histology patch.</p>
        <p>2. We pose the problem of identifying tissue phenotypes as a community detection problem in histological landscape where each community represents a distinct tissue phenotype, for example tumor, benign, stroma, inflammatory, complex stroma, and smooth muscle. To the best of our knowledge, the formulation of tissue phenotyping as community detection has not been done before. The use of geodesic density gradients for tissue phenotyping is also novel and has resulted in significant performance improvement.2. We pose the problem of identifying tissue phenotypes as a community detection problem in histological landscape where each community represents a distinct tissue phenotype, for example tumor, benign, stroma, inflammatory, complex stroma, and smooth muscle. To the best of our knowledge, the formulation of tissue phenotyping as community detection has not been done before. The use of geodesic density gradients for tissue phenotyping is also novel and has resulted in significant performance improvement.</p>
        <p>3. We propose a new large-scale dataset for tissue phenotyping which consists of 280K patches extracted from 20 WSIs of CRC slides stained with H&amp;E. Each slide is taken from a different patient. Each WSI contains exhaustive region-level annotation of seven distinct tissue phenotypes labelled by experienced pathologists (KB and KH).3. We propose a new large-scale dataset for tissue phenotyping which consists of 280K patches extracted from 20 WSIs of CRC slides stained with H&amp;E. Each slide is taken from a different patient. Each WSI contains exhaustive region-level annotation of seven distinct tissue phenotypes labelled by experienced pathologists (KB and KH).</p>
        <p>The dataset has two different testing and training settings including patch-level separation and patient-level separation. This CRC Tissue Phenotyping (CRC-TP) dataset will soon be publicly released.The dataset has two different testing and training settings including patch-level separation and patient-level separation. This CRC Tissue Phenotyping (CRC-TP) dataset will soon be publicly released.</p>
        <p>4. An existing dataset known as CRCHistoPhenotypes 1 (Sirinukunwattana et al. (2016)) for Cell Detection and Classification (CDC) has been extended to include five distinct cell types: tumor epithelial, normal epithelial, necrotic, spindle-shaped, and inflammatory cells. This dataset also contains patch-level and patient-level separations between training and testing splits. The extended dataset named as CRC-CDC will soon be made publicly available.4. An existing dataset known as CRCHistoPhenotypes 1 (Sirinukunwattana et al. (2016)) for Cell Detection and Classification (CDC) has been extended to include five distinct cell types: tumor epithelial, normal epithelial, necrotic, spindle-shaped, and inflammatory cells. This dataset also contains patch-level and patient-level separations between training and testing splits. The extended dataset named as CRC-CDC will soon be made publicly available.</p>
        <p>The proposed algorithm is evaluated on two independent datasets including colon cancer tissue dataset (Kather et al. 1 https://warwick.ac.uk/TIAlab/data/crchistolabelednucleihe/ (2016)) and our proposed CRC-TP dataset and compared with 27 recent state-of-the-art methods. The results demonstrate the superiority of the proposed algorithm over the existing methods by a significant margin.The proposed algorithm is evaluated on two independent datasets including colon cancer tissue dataset (Kather et al. 1 https://warwick.ac.uk/TIAlab/data/crchistolabelednucleihe/ (2016)) and our proposed CRC-TP dataset and compared with 27 recent state-of-the-art methods. The results demonstrate the superiority of the proposed algorithm over the existing methods by a significant margin.</p>
        <p>The rest of this paper is organized as follows. Recent literature on tissue phenotyping is given in Section 2. Section 3 describes the proposed algorithm in detail. Experiments and results are discussed in Section 4, and finally conclusions and future directions are given in Section 5.The rest of this paper is organized as follows. Recent literature on tissue phenotyping is given in Section 2. Section 3 describes the proposed algorithm in detail. Experiments and results are discussed in Section 4, and finally conclusions and future directions are given in Section 5.</p>
        <p>In the past few years, many studies have investigated histology image classification problem (Bianconi et al. (2015); Huang et al. (2017b); Kather et al. (2016); Lazebnik et al. (2006);Linder et al. (2012);Nalisnik et al. (2017); Sarkar and Acton (2018); Sirinukunwattana et al. (2018); Srinivas et al. (2014); Tamura et al. (1978);Vu et al. (2016);Wright et al. (2009);Xu et al. (2016Xu et al. ( , 2017))). Many excellent surveys have also been contributed in this direction (Irshad et al. (2014); Janowczyk and Madabhushi (2016); Komura and Ishikawa (2018); Madabhushi and Lee (2016);Qaiser et al. (2018); Veta et al. (2014)). Existing tissue phenotyping approaches can be broadly categorized into texture-based methods (Bianconi et al. (2015); Kather et al. (2016); Kothari et al. (2013);Linder et al. (2012); Tamura et al. (1978)), sparse representation methods (Sarkar and Acton (2018) Texture-based methods estimate the local texture around a pixel of the histology image to alleviate the effect of heterogeneity (Bianconi et al. (2015); Kather et al. (2016); Kothari et al. (2013);Linder et al. (2012); Tamura et al. (1978)). These features consist of Local Binary Patterns (LPB), Gabor features, lower and higher order histogram features, gray level cooccurrence matrix at different directions, and perception-based features. Texture features of different histology images are first estimated, and then they are used to train SVM classifiers for predicting tissue phenotypes. Tamura et al. (1978) proposed five different perception-based features including coarseness, contrast, directionality, line-likeness, and roughness. Bianconi et al. (2015) exploited these perception features for tissue phenotyping. Kothari et al. (2013) proposed Fourier shape-based descriptor for the identification of retinal tumor in images. Linder et al. (2012) proposed to use LBP with contrast measure features. Encouraging results were reported in these studies. However, the studies presented in (Bianconi et al. (2015)) and (Linder et al. (2012)) were limited for the identification of tumor epithelium and stromal tissue phenotypes. To address this deficiency, Kather et al. (2016) recently proposed to use six different types of texture-based descriptors for the classification of eight different tissue phenotypes in colon cancer histology images. Although, the discrimination performance improved, the texture descriptors do not fully capture the biological significance of the tissue components, hence this method is not very accurate in identifying tumors with complex stroma and mucosa (Kather et al. (2016)). Sparse representation approaches encode a histology image as a sparse linear combination of basis functions or dictionary atoms (Lazebnik et al. (2006); Sarkar and Acton (2018); Srinivas et al. (2014);Vu et al. (2016);Wright et al. (2009)). For each tissue phenotype, a different dictionary is learned and based on the representation error, tissue phenotypes of test images are identified. Srinivas et al. (2014) proposed a multichannel dictionary using the RGB tissue features. Vu et al.In the past few years, many studies have investigated histology image classification problem (Bianconi et al. (2015); Huang et al. (2017b); Kather et al. (2016); Lazebnik et al. (2006);Linder et al. (2012);Nalisnik et al. (2017); Sarkar and Acton (2018); Sirinukunwattana et al. (2018); Srinivas et al. (2014); Tamura et al. (1978);Vu et al. (2016);Wright et al. (2009);Xu et al. (2016Xu et al. ( , 2017))). Many excellent surveys have also been contributed in this direction (Irshad et al. (2014); Janowczyk and Madabhushi (2016); Komura and Ishikawa (2018); Madabhushi and Lee (2016);Qaiser et al. (2018); Veta et al. (2014)). Existing tissue phenotyping approaches can be broadly categorized into texture-based methods (Bianconi et al. (2015); Kather et al. (2016); Kothari et al. (2013);Linder et al. (2012); Tamura et al. (1978)), sparse representation methods (Sarkar and Acton (2018) Texture-based methods estimate the local texture around a pixel of the histology image to alleviate the effect of heterogeneity (Bianconi et al. (2015); Kather et al. (2016); Kothari et al. (2013);Linder et al. (2012); Tamura et al. (1978)). These features consist of Local Binary Patterns (LPB), Gabor features, lower and higher order histogram features, gray level cooccurrence matrix at different directions, and perception-based features. Texture features of different histology images are first estimated, and then they are used to train SVM classifiers for predicting tissue phenotypes. Tamura et al. (1978) proposed five different perception-based features including coarseness, contrast, directionality, line-likeness, and roughness. Bianconi et al. (2015) exploited these perception features for tissue phenotyping. Kothari et al. (2013) proposed Fourier shape-based descriptor for the identification of retinal tumor in images. Linder et al. (2012) proposed to use LBP with contrast measure features. Encouraging results were reported in these studies. However, the studies presented in (Bianconi et al. (2015)) and (Linder et al. (2012)) were limited for the identification of tumor epithelium and stromal tissue phenotypes. To address this deficiency, Kather et al. (2016) recently proposed to use six different types of texture-based descriptors for the classification of eight different tissue phenotypes in colon cancer histology images. Although, the discrimination performance improved, the texture descriptors do not fully capture the biological significance of the tissue components, hence this method is not very accurate in identifying tumors with complex stroma and mucosa (Kather et al. (2016)). Sparse representation approaches encode a histology image as a sparse linear combination of basis functions or dictionary atoms (Lazebnik et al. (2006); Sarkar and Acton (2018); Srinivas et al. (2014);Vu et al. (2016);Wright et al. (2009)). For each tissue phenotype, a different dictionary is learned and based on the representation error, tissue phenotypes of test images are identified. Srinivas et al. (2014) proposed a multichannel dictionary using the RGB tissue features. Vu et al.</p>
        <p>(2016) proposed a dictionary learning technique trained on increasing the inter-class and decreasing the intra-class variability. Sarkar and Acton (2018) recently proposed a saliencyguided sparse representation approach for multi-class tissue phenotypes. Results reported in these studies are promising however, the dictionaries are trained by using the color and texture features resulting in the performance degradation similar to the texture-based approaches.(2016) proposed a dictionary learning technique trained on increasing the inter-class and decreasing the intra-class variability. Sarkar and Acton (2018) recently proposed a saliencyguided sparse representation approach for multi-class tissue phenotypes. Results reported in these studies are promising however, the dictionaries are trained by using the color and texture features resulting in the performance degradation similar to the texture-based approaches.</p>
        <p>Recently, Deep CNN (DCNN) based methods have also been proposed for tissue phenotyping (Bejnordi et al. (2018); Du et al. (2018); Huang et al. (2017b);Nalisnik et al. (2017);Xu et al. (2016Xu et al. ( , 2017))). DCNN models learn the rich hierarchy of convolutional features for each class and then predict the tissue type. Xu et al. (2016) proposed a DCNN model for classifying breast cancer histology images. Their network comprised of two convolutional layers, two max-pooling layers, and two fully connected layers followed by a soft-max layer. Du et al. (2018) and Huang et al. (2017b) proposed DCNN models incorporating the notion of domain adaptation in the AlexNet and 
            <rs type="software">GoogleNet</rs>. Xu et al. (2017) improved the AlexNet model for the segmentation and classification of histology images. Bejnordi et al. (2018) proposed three DCNN models for classifying breast cancer WSIs. The first network was trained to classify WSI into fat, stroma, and epithelium tissues. The second DCNN processed the stromal regions and predicted the complex stroma regions. The third DCNN was trained to classify invasive cancer in the WSIs. These studies produced better results in many complex situations however, these methods are limited to binary classification including tumor epithelium and stroma. Moreover, these methods require large amounts of labelled training histology data, which may not always be available. In contrast, we propose a semi-supervised algorithm which does not require any labelled training data for the classification of tissue phenotypes.
        </p>
        <p>Most of the existing approaches consider binary classification only and rely on texture features. In contrast, we observe that if the potential cell-cell connections between cellular components can be exploited as a discriminator, the performance of tissue phenotyping can be significantly improved in the presence of complex tissue structure. Moreover, we propose the tissue classification problem as identifying network communities. To the best of our knowledge, no similar method has previously been reported for tissue classification.Most of the existing approaches consider binary classification only and rely on texture features. In contrast, we observe that if the potential cell-cell connections between cellular components can be exploited as a discriminator, the performance of tissue phenotyping can be significantly improved in the presence of complex tissue structure. Moreover, we propose the tissue classification problem as identifying network communities. To the best of our knowledge, no similar method has previously been reported for tissue classification.</p>
        <p>In the proposed tissue phenotyping algorithm, a given WSI is divided into non-overlapping patches, and in each patch, we classify cells using a deep neural network. In this study, we have used a patch size of 150 × 150 pixels at 20× resolution from each WSI. Based on the cell-cell connections and distribution of different cellular components in each patch, we compute patch-level feature vectors which are then used to compute a patch-level graph. In this graph, each node represents a locality contained by a patch. Based on the connections between different nodes, the patch-level graph is divided into seven histology communities. A schematic diagram of the overall proposed algorithm is shown in Fig. 2. The proposed approach consists of four main steps including cell detection and classification, cell graph construction and computation of cell-cell connections features, construction of patch-level graph, and computation of tissue phenotype communities using a community detection algorithm. In the following subsections, each of these steps are explained in more detail.In the proposed tissue phenotyping algorithm, a given WSI is divided into non-overlapping patches, and in each patch, we classify cells using a deep neural network. In this study, we have used a patch size of 150 × 150 pixels at 20× resolution from each WSI. Based on the cell-cell connections and distribution of different cellular components in each patch, we compute patch-level feature vectors which are then used to compute a patch-level graph. In this graph, each node represents a locality contained by a patch. Based on the connections between different nodes, the patch-level graph is divided into seven histology communities. A schematic diagram of the overall proposed algorithm is shown in Fig. 2. The proposed approach consists of four main steps including cell detection and classification, cell graph construction and computation of cell-cell connections features, construction of patch-level graph, and computation of tissue phenotype communities using a community detection algorithm. In the following subsections, each of these steps are explained in more detail.</p>
        <p>In this work, potential cell-cell connections between different cellular components has been used as features which are then used for identifying tissue communities. In order to compute potential cell-cell connections, we first identify different types of cells in each histology patch referred to as locality. For this purpose, we use Spatially Constrained Convolutional Neural Network (SC-CNN) proposed by Sirinukunwattana et al. (2016) and pre-trained Tunable Shape Priors CNN (TSP-CNN) proposed by Tofighi et al. (2019) for cell detection. For the training of SC-CNN for cell detection, nuclei centres were manually marked. A probability map was generated such that maximum probability was assigned to the centroid pixels. For the other pixels, the probability decreases as the distance from the centroid increases. Using this probability map, the detection network is trained to assign an appropriate probability to each pixel in the test patch for being a nuclei centroid.In this work, potential cell-cell connections between different cellular components has been used as features which are then used for identifying tissue communities. In order to compute potential cell-cell connections, we first identify different types of cells in each histology patch referred to as locality. For this purpose, we use Spatially Constrained Convolutional Neural Network (SC-CNN) proposed by Sirinukunwattana et al. (2016) and pre-trained Tunable Shape Priors CNN (TSP-CNN) proposed by Tofighi et al. (2019) for cell detection. For the training of SC-CNN for cell detection, nuclei centres were manually marked. A probability map was generated such that maximum probability was assigned to the centroid pixels. For the other pixels, the probability decreases as the distance from the centroid increases. Using this probability map, the detection network is trained to assign an appropriate probability to each pixel in the test patch for being a nuclei centroid.</p>
        <p>The classification SC-CNN network proposed by Sirinukunwattana et al. ( 2016) was able to classify only four classes including Epithelial, Miscellaneous, Inflammatory, and Fibroblast. In the current work, we extended the classification network to predict five distinct classes including Tumor epithelial (T), Spindle-shaped (S), Debris or necrotic (D), Normal epithelial (N), and Inflammatory (I) cells. Multiple shifted patches are extracted around each detected nuclei location which are used for the training of the classification network. The classification network comprises of two convolution layers and two max-pooling layers with a stride of 2 × 2, two fully connected layers followed by the classification layer and the probability for each label is predicted using soft-max layer. For a test nuclei, multiple shifted patches are extracted and classified using the network and the class label of the test nuclei is computed from a weighted sum of all the probability maps of the shifted patches. A patch having a larger distance from the detected nuclei is assigned smaller weight compare to a patch closer to the nuclei. The output of the network is a set of five different types of cell nuclei shown in Fig. 2 (c).The classification SC-CNN network proposed by Sirinukunwattana et al. ( 2016) was able to classify only four classes including Epithelial, Miscellaneous, Inflammatory, and Fibroblast. In the current work, we extended the classification network to predict five distinct classes including Tumor epithelial (T), Spindle-shaped (S), Debris or necrotic (D), Normal epithelial (N), and Inflammatory (I) cells. Multiple shifted patches are extracted around each detected nuclei location which are used for the training of the classification network. The classification network comprises of two convolution layers and two max-pooling layers with a stride of 2 × 2, two fully connected layers followed by the classification layer and the probability for each label is predicted using soft-max layer. For a test nuclei, multiple shifted patches are extracted and classified using the network and the class label of the test nuclei is computed from a weighted sum of all the probability maps of the shifted patches. A patch having a larger distance from the detected nuclei is assigned smaller weight compare to a patch closer to the nuclei. The output of the network is a set of five different types of cell nuclei shown in Fig. 2 (c).</p>
        <p>For each patch X i ∈ R p×p (patch size is 150×150 at 20× magnification level),), we construct a cellular graph such that the vertices correspond to the spatial locations of cells and the edges are assigned using Delaunay triangulation (Fig. 2 (d)). The Delaunay triangulation estimates a triangle for each cell by finding two nearest cells and inserts edges among the three cells. We observe that cells on the opposite sides of tissue constituent white space also known as lumen and endothelium known as micro-vessels do not communicate to each other. To avoid these edges, we use a distance threshold between the cells. The edges between cells which are at a distance larger than a threshold are discarded as shown in Fig. 2 (e). By removing these edges, the problem of heterogeneity within the edges is also reduced.For each patch X i ∈ R p×p (patch size is 150×150 at 20× magnification level),), we construct a cellular graph such that the vertices correspond to the spatial locations of cells and the edges are assigned using Delaunay triangulation (Fig. 2 (d)). The Delaunay triangulation estimates a triangle for each cell by finding two nearest cells and inserts edges among the three cells. We observe that cells on the opposite sides of tissue constituent white space also known as lumen and endothelium known as micro-vessels do not communicate to each other. To avoid these edges, we use a distance threshold between the cells. The edges between cells which are at a distance larger than a threshold are discarded as shown in Fig. 2 (e). By removing these edges, the problem of heterogeneity within the edges is also reduced.</p>
        <p>For each patch, we compute a feature vector by computing 15 potential cell-cell connections between cellular components including T to T (red), T to I (red and green), T to S (red and yellow), T to D (red and blue), T to N (red and black), I to I (green), I to S (green and yellow), I to D (green and blue), I to N (green and black), S to S (yellow), S to D (yellow and blue), S to N (yellow and black), D to D (blue), D to N (blue and black), and N to N (black) as shown in Fig. 2 (f). The cellcell connection features are computed as the frequency of each cell-cell connection in a given cell graph:For each patch, we compute a feature vector by computing 15 potential cell-cell connections between cellular components including T to T (red), T to I (red and green), T to S (red and yellow), T to D (red and blue), T to N (red and black), I to I (green), I to S (green and yellow), I to D (green and blue), I to N (green and black), S to S (yellow), S to D (yellow and blue), S to N (yellow and black), D to D (blue), D to N (blue and black), and N to N (black) as shown in Fig. 2 (f). The cellcell connection features are computed as the frequency of each cell-cell connection in a given cell graph:</p>
        <p>where A cg i is the adjacency matrix of cell graph of i th patch and l cg i is the cell labels for each node in the same cell graph, and h i ∈ R m represents distribution of cellular components in the cell-graph, where m = 15. We create an input data matrix for each WSI aswhere A cg i is the adjacency matrix of cell graph of i th patch and l cg i is the cell labels for each node in the same cell graph, and h i ∈ R m represents distribution of cellular components in the cell-graph, where m = 15. We create an input data matrix for each WSI as</p>
        <p>where n denotes the number of patches in the WSI.where n denotes the number of patches in the WSI.</p>
        <p>Using the cell graph feature vectors, we construct an undirected graph G p = (V, A) such that each vertex v i corresponds to h i in the feature matrix H. The adjacency matrix A ∈ R n×n is computed by employing chi-squared distance as:Using the cell graph feature vectors, we construct an undirected graph G p = (V, A) such that each vertex v i corresponds to h i in the feature matrix H. The adjacency matrix A ∈ R n×n is computed by employing chi-squared distance as:</p>
        <p>where h i ∈ R m and h j ∈ R m are two feature vectors, and σ is a weight decay control parameter. The adjacency matrix A represents a weighted graph whereby the weight between two vertices quantifies the closeness or the similarity between the corresponding cell graphs. Using the adjacency matrix A, we compute a geodesic distance matrix G.where h i ∈ R m and h j ∈ R m are two feature vectors, and σ is a weight decay control parameter. The adjacency matrix A represents a weighted graph whereby the weight between two vertices quantifies the closeness or the similarity between the corresponding cell graphs. Using the adjacency matrix A, we compute a geodesic distance matrix G.</p>
        <p>The geodesic distance is more meaningful in case the data is distributed on a nonlinear manifold. In such cases, the chisquared distance between two features may be small but corresponding geodesic distance may be large. We assume that the network represented by the adjacency matrix A in Eq. ( 3) is fully connected. We represent each network node h i ∈ R m using its shortest distances from all other nodes in the network g i ∈ R n also known as geodesic distances using Eq. ( 4). Note that the geodesic distance computation acts as a kernel projecting the feature vector to a higher dimensional space. This projection results in better separation between different clusters in the tissue phenotype network. The distance between two geodesic vectors g i andThe geodesic distance is more meaningful in case the data is distributed on a nonlinear manifold. In such cases, the chisquared distance between two features may be small but corresponding geodesic distance may be large. We assume that the network represented by the adjacency matrix A in Eq. ( 3) is fully connected. We represent each network node h i ∈ R m using its shortest distances from all other nodes in the network g i ∈ R n also known as geodesic distances using Eq. ( 4). Note that the geodesic distance computation acts as a kernel projecting the feature vector to a higher dimensional space. This projection results in better separation between different clusters in the tissue phenotype network. The distance between two geodesic vectors g i and</p>
        <p>where W ∈ R n×n is a diagonal matrix containing weights for each dimension of the geodesic distance vector. These weights are adjusted such that the local and global structure of the network becomes equally important (Mahmood et al. ( 2017)).where W ∈ R n×n is a diagonal matrix containing weights for each dimension of the geodesic distance vector. These weights are adjusted such that the local and global structure of the network becomes equally important (Mahmood et al. ( 2017)).</p>
        <p>Thus, the weight of the shortest distances corresponding to p = q = {i, j} becomes 1.00 and the weight of the remaining shortest distances, which are n -2, also collectively becomes 1.00. So, we ensure a balance between direct distances and indirect distances. Using this definition of distances in the geodesic space, we compute cellular communities in the patchlevel graph as described below.Thus, the weight of the shortest distances corresponding to p = q = {i, j} becomes 1.00 and the weight of the remaining shortest distances, which are n -2, also collectively becomes 1.00. So, we ensure a balance between direct distances and indirect distances. Using this definition of distances in the geodesic space, we compute cellular communities in the patchlevel graph as described below.</p>
        <p>In the patch level graph, instead of considering each network node as a discrete point in the geodesic space, we consider it yielding a continuous density function. As an example, a density at a point s induced by a node g i is given byIn the patch level graph, instead of considering each network node as a discrete point in the geodesic space, we consider it yielding a continuous density function. As an example, a density at a point s induced by a node g i is given by</p>
        <p>The parameter σ g is the bandwidth of the kernel function in geodesic space. By varying σ g , we can vary the probability density induced by a node at a particular distance from that node. Each network node is assumed to induce its density in the whole geodesic space. The probability density at point s induced by all network nodes gets superimposed. The resulting density is given byThe parameter σ g is the bandwidth of the kernel function in geodesic space. By varying σ g , we can vary the probability density induced by a node at a particular distance from that node. Each network node is assumed to induce its density in the whole geodesic space. The probability density at point s induced by all network nodes gets superimposed. The resulting density is given by</p>
        <p>The cumulative density function as defined by Eq. ( 8) varies across the space. We intend to drift the network nodes towards the higher density regions. Each density region corresponds to a particular tissue phenotype in the WSI. For this purpose, we compute the gradient of the cumulative density function as followsThe cumulative density function as defined by Eq. ( 8) varies across the space. We intend to drift the network nodes towards the higher density regions. Each density region corresponds to a particular tissue phenotype in the WSI. For this purpose, we compute the gradient of the cumulative density function as follows</p>
        <p>where ∇ is a gradient operator with respect to each of the dimensions of the space. Using the values of K from Eq. ( 7) and differentiating it with respect to g as:where ∇ is a gradient operator with respect to each of the dimensions of the space. Using the values of K from Eq. ( 7) and differentiating it with respect to g as:</p>
        <p>where ∇ f (s) is the estimate of the average density gradient pointing in the direction of the maximum increase in density. If each network node is drifted towards positive density gradient, then nodes will converge towards maximum density regions. In these regions, the density gradient will approach to zero. It is because density will be the same in all directions. Assuming s to be the current estimate of a node, setting ∇ f (s) = 0, we get the new estimate as follow:where ∇ f (s) is the estimate of the average density gradient pointing in the direction of the maximum increase in density. If each network node is drifted towards positive density gradient, then nodes will converge towards maximum density regions. In these regions, the density gradient will approach to zero. It is because density will be the same in all directions. Assuming s to be the current estimate of a node, setting ∇ f (s) = 0, we get the new estimate as follow:</p>
        <p>Eq. ( 11) is repeatedly applied to each node of the network to get updated node position g k+1 i = g k i + ∆s, where g k i is the current position of the node in k th iteration and g k+1 i is the updated position k + 1 iteration. It results in each node iteratively drifting towards local density maximum. The nodes are assumed to converge to the final positions when the cumulative drift r k+1 becomes less than a threshold.Eq. ( 11) is repeatedly applied to each node of the network to get updated node position g k+1 i = g k i + ∆s, where g k i is the current position of the node in k th iteration and g k+1 i is the updated position k + 1 iteration. It results in each node iteratively drifting towards local density maximum. The nodes are assumed to converge to the final positions when the cumulative drift r k+1 becomes less than a threshold.</p>
        <p>In maximum density regions, gradients become very small therefore most of the nodes may not converge to a single point in space, instead, most of the nodes stop at different close-by positions. Therefore, in order to obtain a discrete community labels, we apply K-means algorithm on the final positions g k+1 i of nodes.In maximum density regions, gradients become very small therefore most of the nodes may not converge to a single point in space, instead, most of the nodes stop at different close-by positions. Therefore, in order to obtain a discrete community labels, we apply K-means algorithm on the final positions g k+1 i of nodes.</p>
        <p>where c l is the number of tissue communities, and ∈ R n is the community label vector. Each cluster indicates a discrete community corresponding to a particular tissue phenotype. Us-ing the community labels found by Eq. ( 13), we compute the geometric centres for each tissue community for the cell connectivity features given by Eq. ( 2). These geometric centres c j are considered as representative samples of each tissue phenotype. Figs. 3 (a)-(h) show these representative samples obtained from each cluster centre. The tissue patches belonging to each cluster are presented to the experienced pathologists. The computed clusters are biologically meaningful and the pathologists assigned a distinct tissue phenotype to each cluster including tumor, stroma, complex stroma, smooth muscle, debris, benign, and inflammatory. Algorithm 1 describes each step of the proposed method. The predicted community labels are compared with the ground truth labels of each patch using three different clustering quality measures including normalized mutual information, adjusted rank index, and purity as discussed in Section 4.4 below.where c l is the number of tissue communities, and ∈ R n is the community label vector. Each cluster indicates a discrete community corresponding to a particular tissue phenotype. Us-ing the community labels found by Eq. ( 13), we compute the geometric centres for each tissue community for the cell connectivity features given by Eq. ( 2). These geometric centres c j are considered as representative samples of each tissue phenotype. Figs. 3 (a)-(h) show these representative samples obtained from each cluster centre. The tissue patches belonging to each cluster are presented to the experienced pathologists. The computed clusters are biologically meaningful and the pathologists assigned a distinct tissue phenotype to each cluster including tumor, stroma, complex stroma, smooth muscle, debris, benign, and inflammatory. Algorithm 1 describes each step of the proposed method. The predicted community labels are compared with the ground truth labels of each patch using three different clustering quality measures including normalized mutual information, adjusted rank index, and purity as discussed in Section 4.4 below.</p>
        <p>The proposed Tissue Phenotyping using Community Detection (TPCD) algorithm is evaluated both quantitatively and qualitatively on two different CRC datasets including Colon Cancer Tissue (CCT) dataset (Kather et al. (2016)) and our newly proposed CRC-TP dataset which has two versions. The first version has patch-level separation between testing and training data while the second version has patient-level separation as specified below. The results of tissue phenotyping algorithm are compared with 27 state-of-the-art methods including 12 published methods, 4 deep neural networks-based methods, 5 Graph CNN-based (GCN) methods, and 7 variants of the proposed algorithm. Since, the cell detection and classification are Algorithm 1: Proposed Tissue Phenotyping Algorithm.The proposed Tissue Phenotyping using Community Detection (TPCD) algorithm is evaluated both quantitatively and qualitatively on two different CRC datasets including Colon Cancer Tissue (CCT) dataset (Kather et al. (2016)) and our newly proposed CRC-TP dataset which has two versions. The first version has patch-level separation between testing and training data while the second version has patient-level separation as specified below. The results of tissue phenotyping algorithm are compared with 27 state-of-the-art methods including 12 published methods, 4 deep neural networks-based methods, 5 Graph CNN-based (GCN) methods, and 7 variants of the proposed algorithm. Since, the cell detection and classification are Algorithm 1: Proposed Tissue Phenotyping Algorithm.</p>
        <p>Input:Input:</p>
        <p>Step 1: Cell detection and classification on eachStep 1: Cell detection and classification on each</p>
        <p>Step 2: Construct cell-level graph.Step 2: Construct cell-level graph.</p>
        <p>Step 2: Compute h i using Eq. (1).Step 2: Compute h i using Eq. (1).</p>
        <p>Step 3: Compute H using Eq. ( 2).Step 3: Compute H using Eq. ( 2).</p>
        <p>Step 4: Compute A ∈ R n×n using Eq. (3).Step 4: Compute A ∈ R n×n using Eq. (3).</p>
        <p>Step 5: Compute G ∈ R n×n using Eq. ( 4).Step 5: Compute G ∈ R n×n using Eq. ( 4).</p>
        <p>while not converged do 1. Compute drift for each node using Eq. ( 11).while not converged do 1. Compute drift for each node using Eq. ( 11).</p>
        <p>2. Check convergence according to Eq. ( 12) end Step 6: Compute community labels using Eq. ( 13).2. Check convergence according to Eq. ( 12) end Step 6: Compute community labels using Eq. ( 13).</p>
        <p>pre-processing steps for our proposed tissue phenotyping algorithm, therefore, we also discuss the performance of different existing methods on our newly proposed CRC-CDC dataset. 2017)). All implementations are obtained from the original authors and we used the default parameters as proposed by the original authors. We implemented SVM-CNN method for multi-class tissue classification (Xu et al. (2017)). We extracted deep features from the fully connected layer 2 (fc-2) of AlexNet (Krizhevsky et al. (2012)) and then we trained linear SVM classifier for tissue phenotyping.pre-processing steps for our proposed tissue phenotyping algorithm, therefore, we also discuss the performance of different existing methods on our newly proposed CRC-CDC dataset. 2017)). All implementations are obtained from the original authors and we used the default parameters as proposed by the original authors. We implemented SVM-CNN method for multi-class tissue classification (Xu et al. (2017)). We extracted deep features from the fully connected layer 2 (fc-2) of AlexNet (Krizhevsky et al. (2012)) and then we trained linear SVM classifier for tissue phenotyping.</p>
        <p>We compared our methods with the four deep neural networks including Mobile DCNN (MobileNet) (Howard et ResNet101 (He et al. (2016)), and DenseNet (Huang et al. (2017a)). These networks were pertained on the ImageNet database (Deng et al. (2009)). We replaced the classification layer and fine-tuned these networks with stochastic gradient descent with a momentum of 0.8. To gauge the performance of these network architectures, we randomly divided the tissue phenotyping datasets into 70% training set and 30% testing set. We trained all networks on a desktop workstation with two NVidia Titan Xp GPUs with a mini-batch size of 256 and a learning rate of 3 × 10 -4 for 130 epochs. In all cases, rotational invariance was achieved through data augmentation with random horizontal and vertical flips of the training images. Images were re-sized to the neural network input size if necessary.We compared our methods with the four deep neural networks including Mobile DCNN (MobileNet) (Howard et ResNet101 (He et al. (2016)), and DenseNet (Huang et al. (2017a)). These networks were pertained on the ImageNet database (Deng et al. (2009)). We replaced the classification layer and fine-tuned these networks with stochastic gradient descent with a momentum of 0.8. To gauge the performance of these network architectures, we randomly divided the tissue phenotyping datasets into 70% training set and 30% testing set. We trained all networks on a desktop workstation with two NVidia Titan Xp GPUs with a mini-batch size of 256 and a learning rate of 3 × 10 -4 for 130 epochs. In all cases, rotational invariance was achieved through data augmentation with random horizontal and vertical flips of the training images. Images were re-sized to the neural network input size if necessary.</p>
        <p>The Graph CNN (GCN) methods compute the node embedding of the graph which are then used for node classification in transductive as well as inductive learning manners. The labels of the training nodes, feature vectors, and input graph are fed to GCN methods. We compared our proposed algorithm with five GCN methods including GCN with fast localized Spectral Filtering (GCN-SF) (Defferrard et al. (2016)), Semi-Supervised classification with GCN (SSC-GCN) (Kipf and Welling (2017)), GCN for web-scale Recommender Systems (GCN-RS) (Ying et al. ( 2018)), Deep Graph Infomax (DGI) (Veličković et al. (2019)), and GCN with Arma filters (GCN-AF) (Bianchi et al. (2019)). These methods are compared with Euclidean distance-based graph as well as our proposed cell features-based patch-level graph given by Eq. (3). For Euclidean distance-based graph construction, the deep features are extracted using the VGG-16 model. The features are compressed using PCA and the resulting feature vector of dimension 128 is obtained for each patch, which is then used for the distance computation as suggested by (Li et al. (2018)). The implementations of compared GCN methods are taken from the original authors2 and training is performed by using the recommended parameters in the relevant publications.The Graph CNN (GCN) methods compute the node embedding of the graph which are then used for node classification in transductive as well as inductive learning manners. The labels of the training nodes, feature vectors, and input graph are fed to GCN methods. We compared our proposed algorithm with five GCN methods including GCN with fast localized Spectral Filtering (GCN-SF) (Defferrard et al. (2016)), Semi-Supervised classification with GCN (SSC-GCN) (Kipf and Welling (2017)), GCN for web-scale Recommender Systems (GCN-RS) (Ying et al. ( 2018)), Deep Graph Infomax (DGI) (Veličković et al. (2019)), and GCN with Arma filters (GCN-AF) (Bianchi et al. (2019)). These methods are compared with Euclidean distance-based graph as well as our proposed cell features-based patch-level graph given by Eq. (3). For Euclidean distance-based graph construction, the deep features are extracted using the VGG-16 model. The features are compressed using PCA and the resulting feature vector of dimension 128 is obtained for each patch, which is then used for the distance computation as suggested by (Li et al. (2018)). The implementations of compared GCN methods are taken from the original authors2 and training is performed by using the recommended parameters in the relevant publications.</p>
        <p>Different steps of the proposed algorithm are evaluated by designing six variants including TPCD-1, our previous study referred as TPCD-2 (Javed et al. (2018)), TPCD-3, TPCD-Hist, SVM-Cellfeatures, TPCD-4, and TPCD-CG. In TPCD-1 algorithm, geodesic distance computation is skipped and the network as given by Eq. ( 3) is directly used for further processing. TPCD-2 and TPCD-3 algorithms are similar with the only difference that cells at a relatively larger distance also communicate in TPCD-2 which results in increased heterogeneity. In TPCD-3 algorithm, these cell-cell connections are removed using a threshold on the physical distance between different cellular components as previously described in Sec. 3.2. In TPCD-Hist, the histogram of cell types is used as a feature vector while the remaining processing is similar to TPCD-3. TPCD-4 is similar to TPCD-3 except for the cell detection component instead of using SC-CNN method proposed by Sirinukuwattana et al. (Sirinukunwattana et al. ( 2016)), we have employed a recently proposed cell detection method known as TSP-CNN proposed by (Tofighi et al. (2019)). SVM-Cellfeatures consists of SVM classifier using cell-cell connections features. In SVM-CellFeatures, SVM-CNN, B5F-SVM, and B6F-SVM methods, we train the SVM classifier and we used 10-fold cross validation. Both datasets were randomly divided in 10 parts, and 10 rounds of training and testing were performed. For each subdivision a different 10% subset of the dataset was used for testing while the other 90% was used for training.Different steps of the proposed algorithm are evaluated by designing six variants including TPCD-1, our previous study referred as TPCD-2 (Javed et al. (2018)), TPCD-3, TPCD-Hist, SVM-Cellfeatures, TPCD-4, and TPCD-CG. In TPCD-1 algorithm, geodesic distance computation is skipped and the network as given by Eq. ( 3) is directly used for further processing. TPCD-2 and TPCD-3 algorithms are similar with the only difference that cells at a relatively larger distance also communicate in TPCD-2 which results in increased heterogeneity. In TPCD-3 algorithm, these cell-cell connections are removed using a threshold on the physical distance between different cellular components as previously described in Sec. 3.2. In TPCD-Hist, the histogram of cell types is used as a feature vector while the remaining processing is similar to TPCD-3. TPCD-4 is similar to TPCD-3 except for the cell detection component instead of using SC-CNN method proposed by Sirinukuwattana et al. (Sirinukunwattana et al. ( 2016)), we have employed a recently proposed cell detection method known as TSP-CNN proposed by (Tofighi et al. (2019)). SVM-Cellfeatures consists of SVM classifier using cell-cell connections features. In SVM-CellFeatures, SVM-CNN, B5F-SVM, and B6F-SVM methods, we train the SVM classifier and we used 10-fold cross validation. Both datasets were randomly divided in 10 parts, and 10 rounds of training and testing were performed. For each subdivision a different 10% subset of the dataset was used for testing while the other 90% was used for training.</p>
        <p>In addition, we also implemented TPCD algorithm on each Cell-level Graph (TPCD-CG) without exploiting cell classification information. From each patch, we constructed cell-level graph using Delaunay triangulation and then the feature vector corresponding to three structural properties including average degree, average clustering coefficient, and diameter (Dorogovtsev and Mendes ( 2002)) of the cell-level graph is computed. TPCD algorithm is then used to compute the distinct tissue phenotypes.In addition, we also implemented TPCD algorithm on each Cell-level Graph (TPCD-CG) without exploiting cell classification information. From each patch, we constructed cell-level graph using Delaunay triangulation and then the feature vector corresponding to three structural properties including average degree, average clustering coefficient, and diameter (Dorogovtsev and Mendes ( 2002)) of the cell-level graph is computed. TPCD algorithm is then used to compute the distinct tissue phenotypes.</p>
        <p>In our experiments, we used a threshold of 45-pixel distance to remove the distant edges in TPCD-3 algorithm. Performance variation is investigated by varying this threshold from 10 to 60 in steps of 5 as shown in Fig. 4. The best performance is observed for a threshold of 45. In Eq. 12, the cumulative drift r k+1 is bounded to be more than 0.003. For r k+1 &lt; 0.003, further iterations are stopped. 2016)). This dataset had four cell classes including epithelial, inflammatory, miscellaneous, and fibroblast. The epithelial class contained both normal epithelial and tumor-epithelial cells. Therefore, tissue phenotyping based on these classes resulted in the same community label for the tumor and the benign phenotypes which is an undesired result. In order to differentiate tumor from benign tissue phenotype, we have to re-label normal epithelial cells and tumor epithelial cells separately. In the current study, we extend the CRCHistoPhenotypes dataset to 256 H &amp; E stained images of CRC obtained from 20 different patients and containing five distinct cell classes including tumor epithelial, normal epithelial, spindleshaped, inflammatory cells, and necrotic. The extended version is named as CRC-CDC dataset in which each visual field contains 500 × 500 pixels extracted at 20x magnification level. For the annotations purpose, the same protocol was used as reported by the previous study (Sirinukunwattana et al. (2016)). Manual annotations of cell nuclei are made by experienced pathologists (YT and KH) and partly by a research fellow under the supervision of the same pathologists. After full annotations, each annotated nuclei was reviewed by both of the pathologists; therefore refining their own and each others annotations. Annotating the data in this way ensured that minimal nuclei were missed in the annotation process. However, we cannot avoid inevitable few pixel difference between the annotation and the true nuclei centre. A total of 38,984 nuclei are marked at the centre for detection purposes. Out of these, 30, 531 nuclei have associated class labels. In total, there are 7, 231 tumor epithelial cells, 6, 545 normal epithelial cells, 5, 712 spindle-shaped cells, 6, 971 inflammatory cells, and 4, 072 necrotic cells.In our experiments, we used a threshold of 45-pixel distance to remove the distant edges in TPCD-3 algorithm. Performance variation is investigated by varying this threshold from 10 to 60 in steps of 5 as shown in Fig. 4. The best performance is observed for a threshold of 45. In Eq. 12, the cumulative drift r k+1 is bounded to be more than 0.003. For r k+1 &lt; 0.003, further iterations are stopped. 2016)). This dataset had four cell classes including epithelial, inflammatory, miscellaneous, and fibroblast. The epithelial class contained both normal epithelial and tumor-epithelial cells. Therefore, tissue phenotyping based on these classes resulted in the same community label for the tumor and the benign phenotypes which is an undesired result. In order to differentiate tumor from benign tissue phenotype, we have to re-label normal epithelial cells and tumor epithelial cells separately. In the current study, we extend the CRCHistoPhenotypes dataset to 256 H &amp; E stained images of CRC obtained from 20 different patients and containing five distinct cell classes including tumor epithelial, normal epithelial, spindleshaped, inflammatory cells, and necrotic. The extended version is named as CRC-CDC dataset in which each visual field contains 500 × 500 pixels extracted at 20x magnification level. For the annotations purpose, the same protocol was used as reported by the previous study (Sirinukunwattana et al. (2016)). Manual annotations of cell nuclei are made by experienced pathologists (YT and KH) and partly by a research fellow under the supervision of the same pathologists. After full annotations, each annotated nuclei was reviewed by both of the pathologists; therefore refining their own and each others annotations. Annotating the data in this way ensured that minimal nuclei were missed in the annotation process. However, we cannot avoid inevitable few pixel difference between the annotation and the true nuclei centre. A total of 38,984 nuclei are marked at the centre for detection purposes. Out of these, 30, 531 nuclei have associated class labels. In total, there are 7, 231 tumor epithelial cells, 6, 545 normal epithelial cells, 5, 712 spindle-shaped cells, 6, 971 inflammatory cells, and 4, 072 necrotic cells.</p>
        <p>To test the generalization of the cell detection and classification network SC-CNN (Sirinukunwattana et al. (2016)), two experimental settings are used. In the first experiment, 70% nuclei are randomly selected for training and the remaining 30% nuclei are used for testing. In the second experiment, patientlevel separation is maintained by keeping the images from 14 patients as training data while the images of the remaining 6 patients are used for testing data.To test the generalization of the cell detection and classification network SC-CNN (Sirinukunwattana et al. (2016)), two experimental settings are used. In the first experiment, 70% nuclei are randomly selected for training and the remaining 30% nuclei are used for testing. In the second experiment, patientlevel separation is maintained by keeping the images from 14 patients as training data while the images of the remaining 6 patients are used for testing data.</p>
        <p>The CCT dataset contains eight different types in human CRC histology obtained from H&amp;E stained slides of CRC samples (Kather et al. (2016)). The tissue categories are manually annotated and overlapping patches of size 150 × 150 extracted from these samples. The 8 categories are: tumor, stroma, complex structured stroma, lymphocytes, debris, mucosa, adipose, and background. Due to a lack of cellular structure, the background and adipose classes are not considered in our experiments. Sample images from the remaining 6 tissue classes are shown in Fig. 5. There are a total of 3,750 images in these 6 classes, with 625 images per class.The CCT dataset contains eight different types in human CRC histology obtained from H&amp;E stained slides of CRC samples (Kather et al. (2016)). The tissue categories are manually annotated and overlapping patches of size 150 × 150 extracted from these samples. The 8 categories are: tumor, stroma, complex structured stroma, lymphocytes, debris, mucosa, adipose, and background. Due to a lack of cellular structure, the background and adipose classes are not considered in our experiments. Sample images from the remaining 6 tissue classes are shown in Fig. 5. There are a total of 3,750 images in these 6 classes, with 625 images per class.</p>
        <p>This dataset consists of 280K patches extracted from 20 WSIs of CRC stained with H &amp; E taken from our local University Hospitals Coventry and Warwickshire (UHCW) for tissue phenotyping. The 20 WSIs are obtained from 20 different patients. Each WSI is manually region-level annotated by ex- extracted and each patch was assigned a unique label based on majority of its content. Each patch and its label were then inspected by the same pathologists and verified correctness of the patch and its label. Patches containing significant pixels from more than one phenotype were discarded. Therefore, in the resulting dataset, patch of a particular phenotype mostly contains one tissue phenotype however, we cannot avoid the presence of small percentage of other phenotypes in addition to the identified label. Overal, the dataset consists of 50K patches each for Tumor (Tu), Stroma (St), Complex Stroma (CS), and Smooth Muscle (SM) phenotypes. Each of the Benign (Be) and Inflammatory (In) phenotypes consist of 30K patches while the Debris (De) class consists of 20K patches. Following the Kather et al. (2016), the patch size is fixed to 150 × 150 pixels extracted at 20× magnification level and the patches are non-overlapping. Fig. 5 shows some sample tissue images from the proposed dataset.This dataset consists of 280K patches extracted from 20 WSIs of CRC stained with H &amp; E taken from our local University Hospitals Coventry and Warwickshire (UHCW) for tissue phenotyping. The 20 WSIs are obtained from 20 different patients. Each WSI is manually region-level annotated by ex- extracted and each patch was assigned a unique label based on majority of its content. Each patch and its label were then inspected by the same pathologists and verified correctness of the patch and its label. Patches containing significant pixels from more than one phenotype were discarded. Therefore, in the resulting dataset, patch of a particular phenotype mostly contains one tissue phenotype however, we cannot avoid the presence of small percentage of other phenotypes in addition to the identified label. Overal, the dataset consists of 50K patches each for Tumor (Tu), Stroma (St), Complex Stroma (CS), and Smooth Muscle (SM) phenotypes. Each of the Benign (Be) and Inflammatory (In) phenotypes consist of 30K patches while the Debris (De) class consists of 20K patches. Following the Kather et al. (2016), the patch size is fixed to 150 × 150 pixels extracted at 20× magnification level and the patches are non-overlapping. Fig. 5 shows some sample tissue images from the proposed dataset.</p>
        <p>To test the generalization of the proposed tissue phenotyping algorithm and compared methods, two experimental settings are used. In the first experiment, 70% patches of each tissue phenotype are randomly selected for training and remaining 30% are used for testing. In the second experiment, patientlevel separation is maintained by keeping 14 patients data for training and remaining 6 patients data for testing. The number of patches are kept same in both experiments.To test the generalization of the proposed tissue phenotyping algorithm and compared methods, two experimental settings are used. In the first experiment, 70% patches of each tissue phenotype are randomly selected for training and remaining 30% are used for testing. In the second experiment, patientlevel separation is maintained by keeping 14 patients data for training and remaining 6 patients data for testing. The number of patches are kept same in both experiments.</p>
        <p>For cell detection and classification, we compare the performance of the SC-CNN and TSP-CNN methods on CRCHistoPhenotypes dataset and on our proposed CRC-CDC dataset with nuclei-level separation and with patient-level separation. The SC-CNN has two different networks one for nuclei detection and one for nuclei classification as discussed in Sec. 3.1 while, TSP-CNN has only detection network therefore, we also combined SC-CNN classification network with TSP-CNN to get the combined detection and classification performance. In addition to SC-CNN cell classification network, we also evaluated the performance of ResNet50 and DenseNet for cell classification. The SC-CNN detection network is retrained on CRC-CDC dataset while TSP-CNN 4 was pre-trained on CRCHistoPhenotypes dataset. The classification networks including SC-CNN, ResNet50, and DenseNet are trained on CRC-CDC dataset for five distinct nuclei classes.For cell detection and classification, we compare the performance of the SC-CNN and TSP-CNN methods on CRCHistoPhenotypes dataset and on our proposed CRC-CDC dataset with nuclei-level separation and with patient-level separation. The SC-CNN has two different networks one for nuclei detection and one for nuclei classification as discussed in Sec. 3.1 while, TSP-CNN has only detection network therefore, we also combined SC-CNN classification network with TSP-CNN to get the combined detection and classification performance. In addition to SC-CNN cell classification network, we also evaluated the performance of ResNet50 and DenseNet for cell classification. The SC-CNN detection network is retrained on CRC-CDC dataset while TSP-CNN 4 was pre-trained on CRCHistoPhenotypes dataset. The classification networks including SC-CNN, ResNet50, and DenseNet are trained on CRC-CDC dataset for five distinct nuclei classes.</p>
        <p>For SC-CNN networks, we use input patch size of 27×27 pixels containing a single cell, cropped by keeping the nuclei at the centre position. We also use data augmentations in which we rotate patches (0 0 , 90 0 , 180 0 , and 270 0 ) and flip along vertical and horizontal axis to make the networks orientation independent. We also extracted multiple patches for the same nuclei at shifted locations to make the networks shift invariant and to improve the cell localization. For network training, we used cross entropy loss function with stochastic gradient descent with momentum of 0.9, 120 epochs, and learning rate was set as 10 -3 . 4 http://php.scripts.psu.edu/mqt5352/SP-CNN/SP-CNN.php For ResNet50 and DenseNet, the input patch size is enlarged as required by the respective network.For SC-CNN networks, we use input patch size of 27×27 pixels containing a single cell, cropped by keeping the nuclei at the centre position. We also use data augmentations in which we rotate patches (0 0 , 90 0 , 180 0 , and 270 0 ) and flip along vertical and horizontal axis to make the networks orientation independent. We also extracted multiple patches for the same nuclei at shifted locations to make the networks shift invariant and to improve the cell localization. For network training, we used cross entropy loss function with stochastic gradient descent with momentum of 0.9, 120 epochs, and learning rate was set as 10 -3 . 4 http://php.scripts.psu.edu/mqt5352/SP-CNN/SP-CNN.php For ResNet50 and DenseNet, the input patch size is enlarged as required by the respective network.</p>
        <p>We followed the same two-fold cross validation procedure for performance evaluation as suggested by (Sirinukunwattana et al. (2016)). The nuclei detected within 6-pixel distance from the ground truth locations are considered as True Positives (TP). The nuclei detection performance is evaluated using F 1 measure score as:We followed the same two-fold cross validation procedure for performance evaluation as suggested by (Sirinukunwattana et al. (2016)). The nuclei detected within 6-pixel distance from the ground truth locations are considered as True Positives (TP). The nuclei detection performance is evaluated using F 1 measure score as:</p>
        <p>and False Positives (FP) are incorrectly detected nuclei, while False Negatives (FN) are miss-detected nuclei. The aim is to maximize F 1 measure so that its value is close to one.and False Positives (FP) are incorrectly detected nuclei, while False Negatives (FN) are miss-detected nuclei. The aim is to maximize F 1 measure so that its value is close to one.</p>
        <p>Table 1 shows the performance of nuclei detection in terms of F 1 score averaged over all test images. For CRCHistoPhenotypes dataset, TSP-CNN has obtained the highest F 1 score of 0.85 while SC-SNN has obtained 0.80 F 1 score. On CRC-CDC dataset with nuclei-level separation experiment, TSP-CNN has obtained 0.87 while SC-CNN has obtained 0.83 average F 1 score. For the CRC-CDC dataset with patient-level separation, TSP-CNN has obtained 0.86 while SC-CNN has obtained 0.82 average F 1 score. As compared to nuclei-level separation CRC-CDC, the performance is 1% less for both methods which demonstrates that the patient-level separation has posed an equal challenge for both methods.Table 1 shows the performance of nuclei detection in terms of F 1 score averaged over all test images. For CRCHistoPhenotypes dataset, TSP-CNN has obtained the highest F 1 score of 0.85 while SC-SNN has obtained 0.80 F 1 score. On CRC-CDC dataset with nuclei-level separation experiment, TSP-CNN has obtained 0.87 while SC-CNN has obtained 0.83 average F 1 score. For the CRC-CDC dataset with patient-level separation, TSP-CNN has obtained 0.86 while SC-CNN has obtained 0.82 average F 1 score. As compared to nuclei-level separation CRC-CDC, the performance is 1% less for both methods which demonstrates that the patient-level separation has posed an equal challenge for both methods.</p>
        <p>To evaluate the cell classification performance, the weighted average F score is used as follows:To evaluate the cell classification performance, the weighted average F score is used as follows:</p>
        <p>where c l is the number of cell classes, n i is the number of test samples in i-th class, and n is the total number of test samples.where c l is the number of cell classes, n i is the number of test samples in i-th class, and n is the total number of test samples.</p>
        <p>Table 1 shows the comparison of cell classification performance using ground truth cell detection as well as combined detection and classification performed by compared methods. On CRCHistoPhenotypes dataset for 4 nuclei classes, SC-CNN has obtained 0.78 while ResNet50 has obtained 0.74 weighted average F score using ground truth nuclei annotations. The combined performance of TSP-CNN+SC-CNN is 0.73 while SC-CNN has obtained 0.69 weighted average F score. The combined performance is reduced because the nuclei detection by respective networks is performed instead of using ground truth annotations.Table 1 shows the comparison of cell classification performance using ground truth cell detection as well as combined detection and classification performed by compared methods. On CRCHistoPhenotypes dataset for 4 nuclei classes, SC-CNN has obtained 0.78 while ResNet50 has obtained 0.74 weighted average F score using ground truth nuclei annotations. The combined performance of TSP-CNN+SC-CNN is 0.73 while SC-CNN has obtained 0.69 weighted average F score. The combined performance is reduced because the nuclei detection by respective networks is performed instead of using ground truth annotations.</p>
        <p>On CRC-CDC dataset with nuclei-level separation for five nuclei classes including Tumor epithelial (T), Normal epithelial (N), Inflammatory (I), Spindle-shaped (S), and Debris (D), the SC-CNN has obtained 0.86 and ResNet50 has obtained 0.77 weighted average F score using ground truth nuclei annotations. However, the combined performance of TSP-CNN+SC-CNN has remained 0.80 while the second best performing method is SC-CNN by obtaining weighted average F score of 0.78.On CRC-CDC dataset with nuclei-level separation for five nuclei classes including Tumor epithelial (T), Normal epithelial (N), Inflammatory (I), Spindle-shaped (S), and Debris (D), the SC-CNN has obtained 0.86 and ResNet50 has obtained 0.77 weighted average F score using ground truth nuclei annotations. However, the combined performance of TSP-CNN+SC-CNN has remained 0.80 while the second best performing method is SC-CNN by obtaining weighted average F score of 0.78.</p>
        <p>For the CRC-CDC dataset with patient-level separation, SC-CNN has obtained 0.83 and ResNet50 has obtained 0.71 weighted average F score using ground truth nuclei annotations. In case of combined performance, TSP-CNN+SC-CNN has obtained 0.79 while SC-CNN has obtained 0.75 weighted average F score. For patient-level separation, the performance of SC-CNN has reduced by 3% while TSP-CNN+SC-CNN is reduced by 1% compared to nuclei-level separation combined performance results.For the CRC-CDC dataset with patient-level separation, SC-CNN has obtained 0.83 and ResNet50 has obtained 0.71 weighted average F score using ground truth nuclei annotations. In case of combined performance, TSP-CNN+SC-CNN has obtained 0.79 while SC-CNN has obtained 0.75 weighted average F score. For patient-level separation, the performance of SC-CNN has reduced by 3% while TSP-CNN+SC-CNN is reduced by 1% compared to nuclei-level separation combined performance results.</p>
        <p>The combined performance of cell detection and classification has remained best for TSP-CNN+SC-CNN while SC-CNN has remained the second best performing method. Both of these methods are used as a pre-processing steps for the proposed tissue phenotyping algorithm.The combined performance of cell detection and classification has remained best for TSP-CNN+SC-CNN while SC-CNN has remained the second best performing method. Both of these methods are used as a pre-processing steps for the proposed tissue phenotyping algorithm.</p>
        <p>The clustering performance of the proposed algorithm is evaluated using three different clustering measures including Normalized Mutual Information (NMI) Schütze et al. (2008), Adjust Rand Index (ARI) Zhao and Karypis ( 2004), and Purity Zhao and Karypis ( 2004) on CCT and CRC-TP with patch-level separation datasets. The NMI is computed as follows:The clustering performance of the proposed algorithm is evaluated using three different clustering measures including Normalized Mutual Information (NMI) Schütze et al. (2008), Adjust Rand Index (ARI) Zhao and Karypis ( 2004), and Purity Zhao and Karypis ( 2004) on CCT and CRC-TP with patch-level separation datasets. The NMI is computed as follows:</p>
        <p>where c l are the number of classes in the ground truth, c f are the number of found classes, m i, j is the two dimensional joint probability of ground truth and the found classes, m i is the marginal probability of ground truth, and m j is the marginal probability of found classes. A higher value of NMI shows better clustering performance of an algorithm. The ARI represents the percentage of TP and True Negative (TN) decisions over testing samples as defined below:where c l are the number of classes in the ground truth, c f are the number of found classes, m i, j is the two dimensional joint probability of ground truth and the found classes, m i is the marginal probability of ground truth, and m j is the marginal probability of found classes. A higher value of NMI shows better clustering performance of an algorithm. The ARI represents the percentage of TP and True Negative (TN) decisions over testing samples as defined below:</p>
        <p>The ARI value is in the range of [0,1] and higher values represent better clustering performance. Similarly, the Purity measure represents the percentage of the total number of nodes clustered correctly. Let Ω = {w 1 , • • •, w k } be the computed clustered labels and C = {c 1 , •••, c k } be ground truth class labels, the purity is defined as below:The ARI value is in the range of [0,1] and higher values represent better clustering performance. Similarly, the Purity measure represents the percentage of the total number of nodes clustered correctly. Let Ω = {w 1 , • • •, w k } be the computed clustered labels and C = {c 1 , •••, c k } be ground truth class labels, the purity is defined as below:</p>
        <p>where |w k ∩c j | represents the number of nodes in the intersection of w k and c j .where |w k ∩c j | represents the number of nodes in the intersection of w k and c j .</p>
        <p>Table 2 shows the performance comparison of our proposed tissue phenotyping algorithms with other state-of-the-art methods on CCT dataset having six tissue phenotypes. On the average, TPCD-4 has remained the best performer for all the three clustering measures NMI, ARI, and Purity, while TPCD-3 has remained the second best performer. It is because of the better performance of TSP-CNN for cell detection in TPCD-4 algorithm compared to SC-CNN in TPCD-3. By considering the tissue phenotype-wise performance, TPCD-4 has remained the best performer for the Tumor, Stroma, and Debris tissue components on all three measures. For the complex stroma tissue phenotype, TPCD-4 obtained the best performance for NMI and ARI while for Purity measure SPM has remained the best performer. For Mucosa, TPCD-4 performed best for ARI and Purity measures while for NMI, B6F-SVM has remained the best performer. For the Lymphocytes tissue phenotype, TPCD-3 and TPCD-4 both remained the best performers for ARI and Purity while for NMI, B6F-SVM performed best.Table 2 shows the performance comparison of our proposed tissue phenotyping algorithms with other state-of-the-art methods on CCT dataset having six tissue phenotypes. On the average, TPCD-4 has remained the best performer for all the three clustering measures NMI, ARI, and Purity, while TPCD-3 has remained the second best performer. It is because of the better performance of TSP-CNN for cell detection in TPCD-4 algorithm compared to SC-CNN in TPCD-3. By considering the tissue phenotype-wise performance, TPCD-4 has remained the best performer for the Tumor, Stroma, and Debris tissue components on all three measures. For the complex stroma tissue phenotype, TPCD-4 obtained the best performance for NMI and ARI while for Purity measure SPM has remained the best performer. For Mucosa, TPCD-4 performed best for ARI and Purity measures while for NMI, B6F-SVM has remained the best performer. For the Lymphocytes tissue phenotype, TPCD-3 and TPCD-4 both remained the best performers for ARI and Purity while for NMI, B6F-SVM performed best.</p>
        <p>Table 3 shows the performance comparison of different clustering methods on CRC-TP dataset having seven distinct tissue phenotypes. On the average, TPCD-4 obtained the best performance while TPCD-3 remained the second best performer on all three measures. In terms of tissue phenotype-wise performance, TPCD-4 has remained best performer for Tumor and Complex Stroma phenotypes for all three measures. For Stroma tissue phenotype, TPCD-4 has remained best for NMI and ARI measures while for Purity, ResNet achieved the best performance. For the Benign class, TPCD-4 performed best for NMI and ARI, while TPCD-2 performed best in terms of Purity. For Debris class, TPCD-4 remained best for NMI and ARI while for Purity the TPCD-2 remained the best performer. For inflammatory class, the TPCD-4 performed best in terms of NMI while TPCD-2 remained best in terms of ARI and Purity. For the Smooth Muscle tissue phenotype, TPCD-4 performed best in terms of NMI and Purity while TPCD-2 performed best in terms of ARI and Purity.Table 3 shows the performance comparison of different clustering methods on CRC-TP dataset having seven distinct tissue phenotypes. On the average, TPCD-4 obtained the best performance while TPCD-3 remained the second best performer on all three measures. In terms of tissue phenotype-wise performance, TPCD-4 has remained best performer for Tumor and Complex Stroma phenotypes for all three measures. For Stroma tissue phenotype, TPCD-4 has remained best for NMI and ARI measures while for Purity, ResNet achieved the best performance. For the Benign class, TPCD-4 performed best for NMI and ARI, while TPCD-2 performed best in terms of Purity. For Debris class, TPCD-4 remained best for NMI and ARI while for Purity the TPCD-2 remained the best performer. For inflammatory class, the TPCD-4 performed best in terms of NMI while TPCD-2 remained best in terms of ARI and Purity. For the Smooth Muscle tissue phenotype, TPCD-4 performed best in terms of NMI and Purity while TPCD-2 performed best in terms of ARI and Purity.</p>
        <p>We compare the performance of the proposed algorithms with the current state-of-the-art methods in terms of F 1 score for tissue phenotyping. In CCT dataset, all tissue classes have an equal number of instances therefore, the average F 1 and weighted average F scores remain the same. Since, this dataset has only tissue phenotype labels at patch-level therefore, the cell detection and classification is performed by using SC-CNN network trained on CRC-CDC dataset. In order to remove the stain differences between CRC-CDC and CCT datasets, we have used the Macenko method for stain normalization as a preprocessing step Macenko et al. (2009).We compare the performance of the proposed algorithms with the current state-of-the-art methods in terms of F 1 score for tissue phenotyping. In CCT dataset, all tissue classes have an equal number of instances therefore, the average F 1 and weighted average F scores remain the same. Since, this dataset has only tissue phenotype labels at patch-level therefore, the cell detection and classification is performed by using SC-CNN network trained on CRC-CDC dataset. In order to remove the stain differences between CRC-CDC and CCT datasets, we have used the Macenko method for stain normalization as a preprocessing step Macenko et al. (2009).</p>
        <p>Table 4 shows the comparative performance in terms of average F 1 score of six tissue phenotypes on CCT dataset. The proposed algorithms TPCD-4 and TPCD-3 have remained the best performers by achieving 94.5% and 94.0% average F 1 score. The TPCD-2 has obtained average F 1 score of 92.5% while the nearest competitors are DenseNet and B6F-SVM which obtained 89.5% and 89.7%. For tumor phenotype, the GCN method, GCN-AF, has obtained 0.86 F 1 score using deep features-based Euclidean distance graph and using our proposed cell features-based graph (Eq. 3), the GCN-AF has obtained 0.88 F 1 score. All the compared methods have obtained less than 0.90 F 1 score except for DenseNet and ResNet101 both obtaining 0.91 F 1 score. The proposed variants TPCD-2, TPCD-3, and TPCD-4 have obtained 0.92, 0.95, and 0.95 F 1 score, respectively.Table 4 shows the comparative performance in terms of average F 1 score of six tissue phenotypes on CCT dataset. The proposed algorithms TPCD-4 and TPCD-3 have remained the best performers by achieving 94.5% and 94.0% average F 1 score. The TPCD-2 has obtained average F 1 score of 92.5% while the nearest competitors are DenseNet and B6F-SVM which obtained 89.5% and 89.7%. For tumor phenotype, the GCN method, GCN-AF, has obtained 0.86 F 1 score using deep features-based Euclidean distance graph and using our proposed cell features-based graph (Eq. 3), the GCN-AF has obtained 0.88 F 1 score. All the compared methods have obtained less than 0.90 F 1 score except for DenseNet and ResNet101 both obtaining 0.91 F 1 score. The proposed variants TPCD-2, TPCD-3, and TPCD-4 have obtained 0.92, 0.95, and 0.95 F 1 score, respectively.</p>
        <p>For Stroma phenotype, majority of the compared methods have obtained less than 0.90 F 1 score except KM-CD (0.92). The proposed algorithms TPCD-1, TPCD-2, TPCD-3, and TPCD-4 have obtained 0.92, 0.94, 0.95, and 0.96 F 1 score, respectively. The Complex Stroma is one of the difficult tissue phenotypes for discriminating it from the tumor class. The DenseNet has produced the best F 1 score of 0.89 while our proposed algorithm variants SVM-CellFeatures, TPCD-3, and TPCD-4 have obtained 0.87, 0.87, and 0.88 F 1 score, respectively. The proposed algorithms TPCD-3 and TPCD-4 are successful in obtaining comparative performance by leveraging the potential cell-cell connections between cellular components while most existing methods are suffered from performance degradation due to texture features which are not able to handle rich tissue heterogeneity.For Stroma phenotype, majority of the compared methods have obtained less than 0.90 F 1 score except KM-CD (0.92). The proposed algorithms TPCD-1, TPCD-2, TPCD-3, and TPCD-4 have obtained 0.92, 0.94, 0.95, and 0.96 F 1 score, respectively. The Complex Stroma is one of the difficult tissue phenotypes for discriminating it from the tumor class. The DenseNet has produced the best F 1 score of 0.89 while our proposed algorithm variants SVM-CellFeatures, TPCD-3, and TPCD-4 have obtained 0.87, 0.87, and 0.88 F 1 score, respectively. The proposed algorithms TPCD-3 and TPCD-4 are successful in obtaining comparative performance by leveraging the potential cell-cell connections between cellular components while most existing methods are suffered from performance degradation due to texture features which are not able to handle rich tissue heterogeneity.</p>
        <p>In the case of Mucosa tissue, B6F-SVM has obtained the best performance of 0.94 while our proposed algorithms TPCD-2, TPCD-3, and TPCD-4 have obtained 0.90, 0.92, and 0.93 F 1 sore, respectively. Most of the existing methods have achieved less than 0.90 F 1 score for Mucosa tissue which shows that Mucosa tissue pose a significant challenge to all the compared methods. The Debris and Lymphocytes are well differentiated phenotypes therefore; these classes do not pose a significant challenge for the majority of the compared methods. The TPCD-2, TPCD-3, and TPCD-4 algorithms have obtained the best F 1 scores of 0.96, 0.97, and 0.97, respectively, for Debris and 0.97, 0.98, and 0.98, respectively, for Lymphocytes. In Debris, the nearest competitor is ResNet101 obtaining 0.92 while in case of Lymphocytes KM-CD obtained 0.95 compared to 0.98 obtained by TPCD-3 and TPCD-4.In the case of Mucosa tissue, B6F-SVM has obtained the best performance of 0.94 while our proposed algorithms TPCD-2, TPCD-3, and TPCD-4 have obtained 0.90, 0.92, and 0.93 F 1 sore, respectively. Most of the existing methods have achieved less than 0.90 F 1 score for Mucosa tissue which shows that Mucosa tissue pose a significant challenge to all the compared methods. The Debris and Lymphocytes are well differentiated phenotypes therefore; these classes do not pose a significant challenge for the majority of the compared methods. The TPCD-2, TPCD-3, and TPCD-4 algorithms have obtained the best F 1 scores of 0.96, 0.97, and 0.97, respectively, for Debris and 0.97, 0.98, and 0.98, respectively, for Lymphocytes. In Debris, the nearest competitor is ResNet101 obtaining 0.92 while in case of Lymphocytes KM-CD obtained 0.95 compared to 0.98 obtained by TPCD-3 and TPCD-4.</p>
        <p>The proposed variant TPCD-Hist which uses number of celltypes as a feature vector is also not able to obtain the comparative performance. The better performance achieved by our proposed algorithm variants is mainly leveraged by proposed cellcell connections features.The proposed variant TPCD-Hist which uses number of celltypes as a feature vector is also not able to obtain the comparative performance. The better performance achieved by our proposed algorithm variants is mainly leveraged by proposed cellcell connections features.</p>
        <p>The evaluations on this dataset are performed in two different settings including patch-level separation and patient-level separation as discussed in section 4.2.3.The evaluations on this dataset are performed in two different settings including patch-level separation and patient-level separation as discussed in section 4.2.3.</p>
        <p>Table 5 shows the performance comparison in terms of F 1score (F 1 ) for seven distinct tissue phenotypes and weighted average F-score ( F) over all classes with other state-of-theart methods. The proposed algorithms TPCD-3 and TPCD-4 have performed best on CRC-TP dataset with F of 0.91 and 0.89. The removal of distant cell-cell connections in TPCD-3 has reduced heterogeneity and therefore improved the accuracy by 1.0% as compared to TPCD-2. TPCD-1 has obtained 0.84 F which is still competitive with compared methods. The inclusion of Geodesic distance in TPCD-4 algorithm has caused upto 7.0% increase in accuracy as compared to TPCD-1, therefore Geodesic distance is an important step in our proposed algorithm. Among the compared methods, ResNet101 and DenseNet have achieved an F of 0.87 and 0.86 F close to TPCD-2.Table 5 shows the performance comparison in terms of F 1score (F 1 ) for seven distinct tissue phenotypes and weighted average F-score ( F) over all classes with other state-of-theart methods. The proposed algorithms TPCD-3 and TPCD-4 have performed best on CRC-TP dataset with F of 0.91 and 0.89. The removal of distant cell-cell connections in TPCD-3 has reduced heterogeneity and therefore improved the accuracy by 1.0% as compared to TPCD-2. TPCD-1 has obtained 0.84 F which is still competitive with compared methods. The inclusion of Geodesic distance in TPCD-4 algorithm has caused upto 7.0% increase in accuracy as compared to TPCD-1, therefore Geodesic distance is an important step in our proposed algorithm. Among the compared methods, ResNet101 and DenseNet have achieved an F of 0.87 and 0.86 F close to TPCD-2.</p>
        <p>In tumor phenotype, our proposed algorithm TPCD-4 has obtained 0.96 and TPCD-3 has obtained 0.95 which are significantly larger than the compared methods. The nearest competitors are TPCD-2 and ResNet101 both obtaining 0.93 F. In stroma phenotype, TPCD-4 and TPCD-3 are the best performing algorithms obtaining a F of 0.94 and 0.93 while our proposed TPCD-2 has obtained 0.90 F. The nearest competitor is TPCD-1 which has obtained 0.89 F while among the compared methods ResNet101 obtained 0.87 F. In complex stroma phenotype, both TPCD-4 and TPCD-3 algorithms have obtained 0.87 F. It is because of the cell detection performance of SC-CNN in TPCD-3 algorithm approached to the performance of (Kather et al. (2016)). Performance is presented in terms of F 1 score for each tissue phenotype and average F 1 score in (%) for all tissue components. The two best results are shown in red and blue fonts respectively.In tumor phenotype, our proposed algorithm TPCD-4 has obtained 0.96 and TPCD-3 has obtained 0.95 which are significantly larger than the compared methods. The nearest competitors are TPCD-2 and ResNet101 both obtaining 0.93 F. In stroma phenotype, TPCD-4 and TPCD-3 are the best performing algorithms obtaining a F of 0.94 and 0.93 while our proposed TPCD-2 has obtained 0.90 F. The nearest competitor is TPCD-1 which has obtained 0.89 F while among the compared methods ResNet101 obtained 0.87 F. In complex stroma phenotype, both TPCD-4 and TPCD-3 algorithms have obtained 0.87 F. It is because of the cell detection performance of SC-CNN in TPCD-3 algorithm approached to the performance of (Kather et al. (2016)). Performance is presented in terms of F 1 score for each tissue phenotype and average F 1 score in (%) for all tissue components. The two best results are shown in red and blue fonts respectively.</p>
        <p>Tumor Stroma Complex Mucosa Debris Lympho F 1 KM-CD (Sirinukunwattana et al. (2018) In Benign tissue phenotype, TPCD-4 and TPCD-3 algorithms have obtained 0.90 and 0.89 F while TPCD-2 has obtained 0.86 F. In this case, normal epithelial to normal epithelial cell-cell connections are observed quite higher on the micro-vessels, therefore the removal of distant edges was not helpful in this case. The nearest competitor is ResNet101 which obtained 0.86 F. In Debris tissue, the DenseNet and B5F-SVM have achieved the best performance of 0.91 F, while TPCD-4 has obtained 0.90 F. The nearest competitors are TPCD-2 and ResNet50 both obtaining 0.88 F. In Inflammatory tissue type, ResNet101 obtained the best performance of 0.95 F, while DenseNet and B5F-SVM methods obtained 0.92 F. Our proposed algorithm TPCD-4 obtained F of 0.88 for inflammatory tissue. In the case of Smooth Muscle phenotype, TPCD-4 and TPCD-2 obtained 0.88 and 0.87 F while TPCD-3 obtained 0.86 F. The removal of distant cellular edges has shown performance degradation in this tissue component. An improved cell detection performance with TPCD-2 would have resulted in further performance improvement like TPCD-4. Table 6 shows the tissue phenotyping performance comparison on CRC-TP dataset with patient-level separation. Overall, TPCD-4 and TPCD-3 obtained 0.84 and 0.83 F. Compared to patch-level separation results on Table 5, the performance of all the compared methods is significantly reduced. It is because the testing dataset is completely unseen by the cell detection and classification networks in the proposed TPCD algorithms which caused accuracy degradation of 6.0% for TPCD-2, TPCD-3, and TPCD-4. Compared to ResNet101, DenseNet, and GCN-AF with cell features-based graph construction, the accuracies are reduced by 6.0%, 7.0%, and 4.0%, respectively which are also in the same range as compared to proposed algorithms. Moreover, the TPCD-3 and TPCD-4 algorithms have performed better than the other compared methods on Tu, St, CS, Be, and De tissue phenotypes, respectively. Overall, the patient-level separation is more challenging compared to the patch-level separation across training and testing data.Tumor Stroma Complex Mucosa Debris Lympho F 1 KM-CD (Sirinukunwattana et al. (2018) In Benign tissue phenotype, TPCD-4 and TPCD-3 algorithms have obtained 0.90 and 0.89 F while TPCD-2 has obtained 0.86 F. In this case, normal epithelial to normal epithelial cell-cell connections are observed quite higher on the micro-vessels, therefore the removal of distant edges was not helpful in this case. The nearest competitor is ResNet101 which obtained 0.86 F. In Debris tissue, the DenseNet and B5F-SVM have achieved the best performance of 0.91 F, while TPCD-4 has obtained 0.90 F. The nearest competitors are TPCD-2 and ResNet50 both obtaining 0.88 F. In Inflammatory tissue type, ResNet101 obtained the best performance of 0.95 F, while DenseNet and B5F-SVM methods obtained 0.92 F. Our proposed algorithm TPCD-4 obtained F of 0.88 for inflammatory tissue. In the case of Smooth Muscle phenotype, TPCD-4 and TPCD-2 obtained 0.88 and 0.87 F while TPCD-3 obtained 0.86 F. The removal of distant cellular edges has shown performance degradation in this tissue component. An improved cell detection performance with TPCD-2 would have resulted in further performance improvement like TPCD-4. Table 6 shows the tissue phenotyping performance comparison on CRC-TP dataset with patient-level separation. Overall, TPCD-4 and TPCD-3 obtained 0.84 and 0.83 F. Compared to patch-level separation results on Table 5, the performance of all the compared methods is significantly reduced. It is because the testing dataset is completely unseen by the cell detection and classification networks in the proposed TPCD algorithms which caused accuracy degradation of 6.0% for TPCD-2, TPCD-3, and TPCD-4. Compared to ResNet101, DenseNet, and GCN-AF with cell features-based graph construction, the accuracies are reduced by 6.0%, 7.0%, and 4.0%, respectively which are also in the same range as compared to proposed algorithms. Moreover, the TPCD-3 and TPCD-4 algorithms have performed better than the other compared methods on Tu, St, CS, Be, and De tissue phenotypes, respectively. Overall, the patient-level separation is more challenging compared to the patch-level separation across training and testing data.</p>
        <p>The qualitative classification results are thoroughly examined by experienced pathologist (KB) and found to match with manual assessment. The results of the proposed algorithm are overlaid on the WSI taken from CRC-TP dataset as shown in Figs.The qualitative classification results are thoroughly examined by experienced pathologist (KB) and found to match with manual assessment. The results of the proposed algorithm are overlaid on the WSI taken from CRC-TP dataset as shown in Figs.</p>
        <p>Execution times are compared on a machine with Intel core i9 processor and 128GB RAM. The average cell detection time is 0.21 sec for 150×150 patch and classification time is 0.08 sec. On a same patch size, the Delaunay triangulation takes 0.2 sec while the feature vector extraction takes 0.04 seconds. Complexity of 2-D Delaunay triangulation is O(clog(c)), where c is the number of cells detected in a patch. Complexity of graph construction is O(mn 2 ), where n is the number of patches and m is the size of feature vector. Since the chi-square distance is symmetric, each patch pair distance computation is required only once reducing the overall computation to half. An all pair shortest distance algorithm proposed by Pettie and Ramachandran (2005) has time complexity of O(mnlog(α(n, s))), where s is the number of edges in the patch graph and α(n, s) is a slowly growing function. Jiang et al. (2011) have proposed a relatively faster algorithm which takes O(µ(n)loglog(n)) time on a random scale free network with n vertices. Our implementation of the algorithm used in this step takes O(mtn 2 ) where t is the number of iterations. We observe that the algorithm converges in less than 5 iterations.Execution times are compared on a machine with Intel core i9 processor and 128GB RAM. The average cell detection time is 0.21 sec for 150×150 patch and classification time is 0.08 sec. On a same patch size, the Delaunay triangulation takes 0.2 sec while the feature vector extraction takes 0.04 seconds. Complexity of 2-D Delaunay triangulation is O(clog(c)), where c is the number of cells detected in a patch. Complexity of graph construction is O(mn 2 ), where n is the number of patches and m is the size of feature vector. Since the chi-square distance is symmetric, each patch pair distance computation is required only once reducing the overall computation to half. An all pair shortest distance algorithm proposed by Pettie and Ramachandran (2005) has time complexity of O(mnlog(α(n, s))), where s is the number of edges in the patch graph and α(n, s) is a slowly growing function. Jiang et al. (2011) have proposed a relatively faster algorithm which takes O(µ(n)loglog(n)) time on a random scale free network with n vertices. Our implementation of the algorithm used in this step takes O(mtn 2 ) where t is the number of iterations. We observe that the algorithm converges in less than 5 iterations.</p>
        <p>In this work, a novel semi-supervised cellular community detection algorithm is proposed for tissue phenotyping based on cell detection and classification, and clustering of image patches into biologically meaningful communities. First deep neural networks are used for cell detection and classification and then based on potential cell-cell connections between these cells, feature vectors are computed at the patch level. These feature vectors are then used to construct a patch level network using chi-square distance such that each node is a patch in WSI and edges have weights inversely proportional to the distance between the feature vectors. In this network, geodesic distances are computed which are then used to compute node clusters such that each cluster corresponds to a particular tissue phenotype. The proposed algorithm has exhibited better performance than end-to-end deep learning methods as well as several existing algorithms based on handcrafted features.In this work, a novel semi-supervised cellular community detection algorithm is proposed for tissue phenotyping based on cell detection and classification, and clustering of image patches into biologically meaningful communities. First deep neural networks are used for cell detection and classification and then based on potential cell-cell connections between these cells, feature vectors are computed at the patch level. These feature vectors are then used to construct a patch level network using chi-square distance such that each node is a patch in WSI and edges have weights inversely proportional to the distance between the feature vectors. In this network, geodesic distances are computed which are then used to compute node clusters such that each cluster corresponds to a particular tissue phenotype. The proposed algorithm has exhibited better performance than end-to-end deep learning methods as well as several existing algorithms based on handcrafted features.</p>
        <p>We showed that the proposed approach was able to achieve better performance mainly because it uses both deep learning and handcrafted features which complement each other. Also the proposed potential cell-cell connections features are biologically more meaningful than the texture-based features used in most existing methods. The concept of constructing a graph and then using geodesic distance for community detection has also significantly contributed to the performance. It is because the graph based approaches work well even if the underlying classes are not linearly separable. The geodesic distance has also performed similar to kernels projecting data to higher dimensional spaces such that the classes become linearly separable. Owing to all these novel steps, the proposed algorithm was able to achieve superior classification accuracy on an existing as well as newly proposed large scale tissue phenotyping dataset.We showed that the proposed approach was able to achieve better performance mainly because it uses both deep learning and handcrafted features which complement each other. Also the proposed potential cell-cell connections features are biologically more meaningful than the texture-based features used in most existing methods. The concept of constructing a graph and then using geodesic distance for community detection has also significantly contributed to the performance. It is because the graph based approaches work well even if the underlying classes are not linearly separable. The geodesic distance has also performed similar to kernels projecting data to higher dimensional spaces such that the classes become linearly separable. Owing to all these novel steps, the proposed algorithm was able to achieve superior classification accuracy on an existing as well as newly proposed large scale tissue phenotyping dataset.</p>
        <p>This new dataset will soon be made publicly available with two experimental settings including patch-level separation and patient-level separation between training and testing splits. Currently, we have used five distinct cell classes including tumor epithelial, normal epithelial, spindle-shaped, necrotic, and inflammatory. Addition of further cellular components such as blood cells may result in performance improvements and also reveal more micro-level tissue communities. The proposed algorithm can potentially be used on large number of WSIs of different cohorts for separating tissue communities. Tissue phenotyping in a WSI can aid with understanding the contents of the WSI and form the basis of comprehensive digital profiling of spatial patterns in the tumor microenvironment associated with cancer subtypes in terms of survival and clinical outcomes.This new dataset will soon be made publicly available with two experimental settings including patch-level separation and patient-level separation between training and testing splits. Currently, we have used five distinct cell classes including tumor epithelial, normal epithelial, spindle-shaped, necrotic, and inflammatory. Addition of further cellular components such as blood cells may result in performance improvements and also reveal more micro-level tissue communities. The proposed algorithm can potentially be used on large number of WSIs of different cohorts for separating tissue communities. Tissue phenotyping in a WSI can aid with understanding the contents of the WSI and form the basis of comprehensive digital profiling of spatial patterns in the tumor microenvironment associated with cancer subtypes in terms of survival and clinical outcomes.</p>
        <p>https://github.com/rusty1s/pytorch -geometrichttps://github.com/rusty1s/pytorch -geometric</p>
        <p>https://warwick.ac.uk/fac/sci/dcs/research/tia/data/crchistolabelednucleihe/https://warwick.ac.uk/fac/sci/dcs/research/tia/data/crchistolabelednucleihe/</p>
        <p>This work was supported by the Medical Research Council [MR/P015476/1].This work was supported by the Medical Research Council [MR/P015476/1].</p>
        <p>Normal epithelial cell (N) T-D T-N T-T T-I T-S I-I I-S I-D I-N S-S S-D S-N D-D D-N N-N Tumor Inflammatory Benign Complex Stroma Stroma Necro�c flammatory troma enign Tumor Necro�c Complex StromaNormal epithelial cell (N) T-D T-N T-T T-I T-S I-I I-S I-D I-N S-S S-D S-N D-D D-N N-N Tumor Inflammatory Benign Complex Stroma Stroma Necro�c flammatory troma enign Tumor Necro�c Complex Stroma</p>
    </text>
</tei>
