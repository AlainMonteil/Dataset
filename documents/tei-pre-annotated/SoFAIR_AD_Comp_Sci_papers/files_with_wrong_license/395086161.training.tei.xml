<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T11:33+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>Rational design of compounds with specific properties requires understanding and fast evaluation of molecular properties throughout chemical compound space -the huge set of all potentially stable molecules. Recent advances in combining quantum-mechanical calculations with machine learning provide powerful tools for exploring wide swathes of chemical compound space. We present our perspective on this exciting and quickly developing field by discussing key advances in the development and applications of quantummechanics-based machine-learning methods to diverse compounds and properties, and outlining the challenges ahead. We argue that significant progress in the exploration and understanding of chemical compound space can be made through a systematic combination of rigorous physical theories, comprehensive synthetic data sets of microscopic and macroscopic properties, and modern machine-learning methods that account for physical and chemical knowledge.</p>
        <p>Due to an unfathomably large number of possible molecules and materials 1,2 , and the combinatorially many ways for them to undergo chemical transformations, our understanding of chemistry requires a first-principles approach with proper roots in quantum mechanics (QM) and statistical mechanics (SM). QM gives us the ability to calculate accurate microscopic properties (energies, atomic forces, electronic-energy levels, electrostatic multipoles and polarizabilities) for fixed molecular geometries, and SM allows us to sample QM energy surfaces in a given statistical ensemble and calculate macroscopic properties. Accurate QM and SM simulations are computationally demanding, even for a single molecule or simple material; hence, more efficient computational approaches are urgently needed to address the molecular processes over multiple length scales and timescales with sufficient accuracy in order to obtain insights into the evolution of properties throughout chemical compound space (CCS). Such efficient methods may eventually enable the long-held dream of in silico chemical and materials design.</p>
        <p>when charting CCS suggests that there is an analogy to constellations of stars in the universe. Constellations, like molecules, have names and, more importantly, have been useful for orientation and navigation. Similarly, property patterns throughout chemical space can be combined in 'constellations' , from which properties of new molecules of interest can be calculated using linear or non-linear combination of properties of known molecules or molecular fragments. Although relationships for stars and planets are rather well understood, a rigorous understanding of CCS in terms of molecular components has not yet been achieved but would be of utmost usefulness for rational compound design. In this Perspective, we argue that the recently developed machine learning (ML) approaches will significantly aid in achieving a deeper understanding of CCS. We give several examples that illustrate the substantial progress achieved in this field and outline the many remaining challenges yet to be addressed.</p>
        <p>The targeted exploration of CCS aiming to obtain compounds with desired properties is a longstanding endeavour. Many efforts in cheminformatics or materials informatics have relied on statistics and ML to search CCS for relevant pharmaceutical properties, such as receptor binding, toxicity 4,5 or materials stability [6][7][8] . Despite often being useful and computationally efficient, the main drawback of these approaches is that they are not transferable to molecules and properties outside of their domain of applicability, which results from a lack of underlying principles of physics, as also pointed out in ref. 9 .</p>
        <p>QM describes the electronic structure of any material compound, thereby, determining the behaviour of matter at large and dictating all the mutual relationships between observable microscopic properties 10 . In light of such a large domain of applicability of QM, it is not a surprise that fundamental contributions to density functional theory (DFT) -one of the most efficient formulations of QM -are highly cited 11 . The unbiased study of chemical space for the purpose of exploration as well as exploitation (computational compound design) strictly requires sampling algorithms with maximal efficiency.</p>
        <p>CCS is large but finite and accounts for the set of all feasible metastable atomic configurations resulting from solving Schrödinger's equation. Non-equilibrium molecular configurations provide smooth interpolations between points in this high-dimensional chemical space. While accounting for all possible conformations of all stereoisomers of all possible constitutions of all possible compositions, CCS also encodes repeating patterns, abundant signatures and low-dimensional building blocks. Nowadays, most quantum machine learning (QML) approaches decompose predicted properties into atomic contributions. For example, computing quantum properties, such as the atomization energy, as a series expansion in select fragments called ' AM-ons' has, by now, enabled learning properties for chemically diverse molecules. AM-on stands for 'atom in a molecule' and the suffix 'on' indicates that each AM-on can be considered as a building-block dictionary entry that is selected whenever relevant in the ensemble of fragments that constitute any larger query molecule 3 . The pervasiveness of the underpinning constituting patterns Although QM-based design of materials has already been successfully applied to some specific materials-design challenges [12][13][14] , it imposes a prohibitive computational cost. Consequently, the improvement in efficiency and robustness of electronic-structure calculations play an increasingly important role in current and future materials-design efforts [15][16][17][18] .</p>
        <p>ML has already enabled many applications in many fields 19,20 , including medical diagnostics [21][22][23] , particle physics 24 , bioinformatics 25 , brain-computer interfaces 26 , social-media analysis 27 , robotics 28 and team, social or board games [29][30][31] . Here, we focus on recent fundamental ML developments aimed at a quantum-based understanding of CCS (see Box 1 for an overview of the key concepts in the field of QML). The key idea is that any observable property for any system can be obtained from solving the relevant quantum-mechanical equations. A more comprehensive QM-based understanding of CCS is now foreseeable because of maturity, efficiency and reproducibility of electronic-structure methods, such as DFT and post-Hartree-Fock wave-function methods, and codes 32 . Furthermore, fast-paced developments in high-performance computing hardware have also helped to improve our QM-based understanding of CCS. The scientific codes in the electronic-structure community have matured to such an extent that a considerable fraction of the world's top high-performance computing centres busy themselves with QM calculations. Finally, conceptual adaptations of statistical mechanics and continuous advances in statistical learning have, nowadays, enabled the performance of intelligent data analysis on both small and large data sets, and extraction of valuable quantitative insights in a systematic manner. Many recent publications, including special journal issues and reviews of quantum-based ML approaches [33][34][35][36] , have highlighted the fact that combining quantum calculations with ML can lead to considerable leaps in exploring and understanding chemical and materials spaces. In addition to learning quantum-mechanical observables (by integrating over electronic degrees of freedom), evidence has been presented that it is equally possible to build ML models of SM ensemble averages (by integrating over relevant atomistic configurational degrees of freedom), such as free energy, entropy or kinetic pathways 37,38 .</p>
        <p>To distinguish the emerging field of physics-based ML from preceding efforts in cheminformatics, bioinformatics and materials informatics, we refer to the combinations of QM and SM approaches with ML as QML models. QML refers to the idea of applying modern statistical learning theory to predict electronic and atomistic properties and processes in molecules and materials. We also remark that the goals and reaches of QML models should not be confused with quantum ML</p>
        <p>Here, we give a compact explanation for various keywords discussed in this Perspective.</p>
        <p>• Machine learning (ML): methods based on statistical learning theory for obtaining numerical models from data samples that generalize well on unseen data. Generally, ML models improve with the availability of more data; hence, the models are said to 'learn from data'. ML models are inductive, meaning that they are typically not based on any underlying physical model, but can, in principle, reconstruct physical models from the provided data. in the context of exploring chemical compound space, available data are less abundant than in typical ML applications such as computer vision. it becomes, therefore, important to most efficiently make use of available data by combining prior knowledge about physics and chemistry with powerful ML models, as we will argue throughout this Perspective.</p>
        <p>• representation: the model that encodes the structure of and relations between atoms. it is crucial for quantifying geometric and chemical similarities of molecules. the representation needs to be unique and invariant to atom indexing, as well as to molecular translations and rotations in space (Box 2).</p>
        <p>• supervised, unsupervised and semi-supervised learning: ML with labels is called supervised learning. examples of supervised learning are classification or regression, in which the class label or regression value for every sample is given in the training data. On the contrary, in unsupervised learning, label information is not included in the training data set. Clustering and dimensionality reduction are typical unsupervised learning problems. semi-supervised learning assumes that most samples have no label and only for very few samples are labels provided for training.</p>
        <p>• Parametric and non-parametric models: parametric models assume a finite set of model parameters that need to be estimated (for example, by using a mean of a Gaussian), whereas non-parametric models do not rely on this assumption. Popular non-parametric models, such as Gaussian processes, can be viewed as having infinitely many parameters.</p>
        <p>• regression: in regression, the relationship between an input representation and continuous output variables is estimated. the most common simple-regression analysis is linear regression, in which a linear function is fitted to the data according to some loss function, such as mean squared error. a widely used classical model for non-linear regression is kernel-ridge regression that generalizes well to unseen data with limited scalability in larger data sets. • Deep neural networks: widely used and flexible non-linear regression models based on neural networks. Deep neural networks refer to structured architectures that have a large number of hidden layers, offering large flexibility and rich, multiscale representations. Due to their scalability, they are ideally suited to extract complex, non-linear relations from large data sets. • Cross validation: a common ML procedure used for ensuring generalization to unseen data and avoiding overfitting. • Learning curves: measure the performance of ML models upon increasing the number of data samples used for training the model. • Density functional theory (DFt): the workhorse method for electronicstructure calculations on molecules and materials. while DFt is, in principle, an exact theory, in practice, approximations are made for electronic quantum (exchange and correlation) effects. DFt implementations often provide a good compromise between accuracy and efficiency. Most current quantum machine learning data sets for molecules and materials are based on DFt calculations. • Hartree-Fock (HF): fundamental electronic-structure method used as a starting point for essentially all practical calculations of quantum correlation energy in molecular systems. HF provides an exact treatment of electronic-exchange effects due to Pauli repulsion. • Coupled cluster (CC) methods: a set of methods to obtain and systematically improve the calculated estimate of electronic-correlation energy based on the HF wave function. this is achieved by increasing the level of modelled electronic excitations: single excitations, double excitations and so on. However, higher-level treatment requires orders of magnitude more computational resources. in particular, the coupled cluster single double (triple) (CCsD(t)) method is the so-called 'gold standard' of computational quantum chemistry, including single, double and perturbative triple excitations (to the fourth order in perturbation theory). within converged basis sets, CCsD(t) typically yields so-called 'chemical accuracy' of ~1 kcal mol -1 in atomization energies of molecules with single reference character.</p>
        <p>algorithms executed on quantum computers. As such, QML models aim to provide a feedback mechanism between QM and/or SM, and (statistical) ML. Given sufficient reference data obtained from QM and SM simulations, queries of properly trained ML models can yield accurate properties within milliseconds 39 -as opposed to the many CPU hours or days necessary to solve the corresponding quantum and statistical mechanics problems for representative compounds. Because of the rigorous interpolation of QML in complex non-linear spaces and their consequently controlled predictive accuracy 40 , the door has now opened for an extensive analysis and study of these interpolated spaces, which was previously impossible due to the prohibitive computational cost of direct QM and SM simulations.</p>
        <p>Given the substantial progress in QML discussed in this Perspective, we argue that meaningful progress in the exploration and understanding of CCS can be made through systematic combination of rigorous physical theories, comprehensive data sets of QM and SM properties, and sophisticated ML methods that incorporate physical and chemical knowledge. The authors have witnessed the quick development of QML from the perspective of electronic-structure calculations and, hence, the focus in this Perspective is on combining QM and ML with the goal of enhanced exploration of CCS. Efforts to use ML to capture SM properties in analogous ways is the subject of active current research 41,42 .</p>
        <p>The overarching goal of QML is to develop reliable models with the accuracy of highlevel electronic-structure calculations. Depending on the application, the reference data can be obtained from high-level quantum chemistry, such as coupled cluster single double (triple) (CCSD(T)), or from DFT calculations. Although much work remains to be done to reach the 'dream' of exact QML models, many key advances have been recently achieved that we discuss in this section and connect to important remaining challenges for which we deem that urgent progress is needed.</p>
        <p>All QML advances hinge on the availability of trustworthy QM data. These data need to cover a certain important domain, for example, the CCS of organic drug-like compounds, as explored by Reymond and colleagues through their generated database (GDB) list of simplified molecular-input line-entry system (SMILES) strings [43][44][45][46] . QM calculations on these molecular graphs led to the publication of data sets that collect equilibrium structures and properties of many thousands of small molecules (QM7 and QM9) 47,48 , their molecular-dynamics trajectories (MD17) 49 and non-equilibrium molecular structures (ANI-1) 50 . One can also calculate equilibrium structures and properties of solids [51][52][53] , or generate equilibrium and non-equilibrium molecular dynamics (MD) data for a single element (for example, silicon) 54 . The ultimate goal of QML is to develop a universal and efficient model for the whole CCS that enables the accurate description of molecules and materials on equal footing and possibly leads to new insights on CCS underlying regularity and chemical relationships. Reorganizing the periodic table (in the sense of revisiting and generalizing Pettifor's concept of Mendeleev number) 55,56 represents a first and important step in this direction 53,57 . Initially, various models have been developed focusing either on molecular or materials data, but versatile models have been more recently proposed that can be applied to both molecules and solids [58][59][60] .</p>
        <p>CCS is commonly explored using cheminformatics-based approaches. In contrast, QML rigorously adheres to its roots in fundamental physics, such that it is consistent with the laws of QM and SM. One of the first QML applications in which ML techniques were used for non-linear interpolation of QM data aimed to construct reliable system-specific interatomic potentials or potential-energy surfaces, going beyond conventional force fields in terms of universality (atom-type specificity no longer required) and accuracy [61][62][63][64][65][66] . Further developments aimed at transferable QML models that are trained and applicable throughout CCS for the description of QM properties, as shown for the QM7 set of organic molecules 39 , highlighting the potential of QML for efficient and accurate exploration of CCS. This idea was rapidly demonstrated to be applicable to many electronic properties using neural networks as well as kernel-ridge regression 47,67,68 , or to search for polymers with useful properties 69 , explore chemical properties of crystalline solids 53,[70][71][72][73] and design materials for a variety of technological applications 74,75 .</p>
        <p>A crucial aspect that determines the reliability and applicability of any QML model is its generalization accuracy that is assessed on the calculated QM properties of a sufficiently large out-of-sample (hold-out) test data set. It is remarkable how quickly the generalization accuracy and data efficiency of QML models has improved during the past few years. As shown in fig. 1 on the example of the QM9 data set, the QML prediction errors have decreased by 40-fold -from 8 kcal mol -1 (0.340 eV) to 0.2 kcal mol -1 (0.008 eV) in 2018 (ref. 58 ), using exactly the same training. This noticeable increase in accuracy mainly stems from incorporation of physical prior knowledge into the QML models, such as proper description of permutational symmetries of atoms in a molecule 49,58,60,76 , as well as explicit inclusion of physically This plot shows the mean absolute error (MAE) in eV on atomization energies of small molecules in the quantum-mechanics-based data set for organic molecules with up to nine non-hydrogen atoms (QM9) 48 . The compared quantum machine learning (QML) models differ solely by representation and model architecture, and correspond to Coulomb matrix (CM) 39 , bag of bonds (BoB) 83 , bonds, angles, machine learning (BAML) 77 , histogram of distances, angles, dihedrals (HDAD) 137 , constant-size descriptors (ConstSize) 103 , deep tensor neural network (DTNN) 86 , spectrum of London and Axilrod-Teller-Muto (SLATM) 3 , atomic SLATM (aSLATM), smooth overlap of atomic positions (SOAP) 60 , Faber, Christensen, Huang, Lilienfeld (FCHL) 58 , message passing node and edge-based neural network with set-to-set readout function (enn-s2s) 162 , moment tensor model (MTM) 135 , many-body-based (MBD) kernel-ridge regression 78 , reactive neural network (NN) 87 , Hierarchically Interacting Particle Neural Network (HIP-NN) 163 , SchNet 59 and wavelets 164 . The black X on the left indicates the target value in the 'QM9 challenge', in which QML models should be developed to reach 1 kcal mol -1 (0.043 eV) accuracy on the QM9 data set using only information of 100 molecules for training.</p>
        <p>To date, this challenge has not been met. Adapted from ref. 165 , Springer Nature Limited.</p>
        <p>motivated pairwise and many-body terms for interatomic interactions into QML descriptors 77,78 . A discussion of several widely used representations of molecules in the context of kernel-based ML is shown in Box 2. A noticeable conclusion from fig. 1 is that the most advanced existing QML models are extremely data-efficient, achieving chemical accuracy of 1 kcal mol -1 for the QM9 data set of 134,000 organic molecules 48 using only 1,000 molecules (0.7%) for training. This result hints on the potential sparsity of CCS, implying a low complexity and dimensionality 79 of the property-prediction problem throughout CCS. In other words, this evidence suggests that (unknown) properties of query molecules can be predicted as non-linear combinations of (known) properties of only a few other molecules, which are not necessarily chemically similar. To search for better QML models, the authors, together with other researchers, agreed to award US$1,500 as of May 2020 to the scientist(s) who devise(s) a QML model that meets the Institute for Pure and Applied Mathematics (IPAM) QM9 challenge; that is, a QML model that reaches predictive accuracy of ~1 kcal mol -1 after training on only 100 QM9 molecules.</p>
        <p>A critical component of every QML model lies in the representation (sometimes also referred to as descriptor) of an atomic system composed of nuclei and electrons. Uniqueness of the representation is a necessary condition for QML models to converge down to arbitrary accuracy 80 , and an increase in similarity between representation and target function typically lowers the offset in learning curves 77 . In order to afford efficient learning, representations should also capture well-known translational, rotational and permutational invariances of atomistic systems, but can also be significantly improved by explicitly including other physical priors, such as temporal and spatial symmetries of interatomic interactions 49 or differential relationships of response properties 81 . An additional requirement is that atomistic representations should be as computationally efficient as possible in order to benefit from QML's computational efficiency over the numerical solvers used in conventional QM calculations. Although many and various representations have been proposed 39,58,70,78,[82][83][84][85] , there is still an ongoing debate on the advantages and limitations of different representations for different application domains. While kernel-based ML models require explicit formulation for the representation 39,67,82 , using one scale per kernel, deep neural networks, such as deep tensor neural network (DTNN)-based approaches 59,86,87 , can result in an implicit multiscale representation from a scalable learning process.</p>
        <p>In QM calculations, different properties of an atomistic system (such as electronic energy, atomic forces, multipole moments, polarizability and electronic-energy levels) can be evaluated as QM operators acting on the electronic wave function. The situation is more intricate in the case of QML models. Initially, separate QML models were used to describe different properties, for example, one model for total energy and a different one for the polarizability. Therefore, one of the first goals of neural networks was to develop transferable neural networks that can simultaneously predict multiple electronic properties as the one applied to the QM7 data set 47 . Kernel methods and deep neural networks have also been extended to reflect multi-property prediction 68,88 . However, beyond that, it would be very advantageous to view QML models as a coarse-grained surrogate for electronic interactions in an atomistic system, akin to a downfolded version of the wave function. In such a model, electronic properties in QML could be calculated similarly to explicit QM calculations, namely, as operators on manifolds. This idea of using response operators for ML in chemical space has been recently introduced by Christensen and colleagues 81 and various QML models of electron densities Box 2 | summary of various molecular representations a key aspect of quantum machine learning approaches is the definition of a molecular representation that enables one to measure similarity between molecules. there is no 'universal' representation that satisfies all desirable properties at once, being general, accurate, efficient and transferable at the same time. this has led to a flurry of developments of different molecular representations, each of which satisfies only part of the general requirements. although all the existing models are fundamentally based on the same information -atomic positions and nuclear charges -they provide a different mapping between discrete atomic information and continuous spatial degrees of freedom. in principle, both kernel methods and neural networks start with a molecular representation, although neural networks can also generate the representation as part of the learning process 59,86 . Here, we provide a brief summary of the different existing models for representing molecules.</p>
        <p>• atom-centred symmetry functions 166 : products of radial and angular symmetry functions are used to represent molecular environments. the advantage is a compact and physically inspired representation. the limitation is that the complexity grows quickly with the increase in the number of atom types. • Coulomb matrix 39 : inverse distance matrix that represents internuclear Coulomb repulsion between atoms. a very efficient, global and elegant representation. it does not satisfy permutation symmetry for equivalent atoms and can lead to discontinuities. • Bag of bonds 83 : in this case, the Coulomb matrix representation is vectorized, improving its similarity measure and efficiency. Permutation symmetry and discontinuities still pose a problem. • Many-body-based representation 78 : localized extension of bag of bonds with explicit treatment of different distance scales, including three-body and higher-body terms. it solves the permutation symmetry. However, it can become inefficient when using higher than three-body terms. • smooth overlap of atomic positions 60 : in this case, molecules are represented as a superposition of radial Gaussian functions and angular momentum terms. rigorously treats rotation and permutation symmetries and avoids discontinuities. Can become very expensive for accurate predictions and for several atom types. • sine matrix 84 : generalization of Coulomb matrix to periodic systems.</p>
        <p>• Many-body tensor representation 85 : a tensor representation for molecules and solids. Generally applicable to many different systems. Can become expensive to evaluate for large systems. • Partial radial distribution functions 70 : a representation based on atomic radial distribution functions for solids. Only tested for predicting electronic properties of simple solids. • wavelet scattering transform 164 : a multiscale representation for molecular properties based on wavelets. Naturally captures multiscale nature of molecular properties without imposing localization to those properties. expertise is needed in constructing an appropriate wavelet basis for new systems. • Moment tensor potentials 97 : atomic potential representation based on atomic moments.</p>
        <p>General and efficient and mainly tested on elemental solids. requires wide testing especially on multicomponent systems. • Faber, Christensen, Huang, Lilienfeld 58 : encodes both the chemical composition and structural degrees of freedom in the representation for enabling alchemical design. Can be applied to both molecules and solids. Can become expensive when accurate predictions are desired.</p>
        <p>and wave functions have, by now, also been proposed [89][90][91][92][93][94][95] .</p>
        <p>In general, the chemical space of molecules and materials can be explored by looking at compositional (that is, elements forming bonds) and configurational (that refers to the same kind of bonds that form different structures) degrees of freedom. Up to now, we have mainly discussed models that explore compositional degrees of freedom in CCS. However, configurational degrees of freedom are crucial to understand dynamics of molecules under given external conditions. As indicated above, the construction of reliable ML force fields from QM data was one of the first examples of successful applications of QML 61,64,65 and, by now, the use of QML models has become routine in order to enable MD calculations that go beyond the realm of classical, system-dependent force fields 49,59,60,82,96,97 . Recently, the focus has been shifting towards emphasizing data efficiency of QML force fields. For example, by sampling only a few hundred molecular conformations from an MD trajectory, the symmetrized gradient-domain machine learning (sGDML) model 76 can give global force fields for small molecules (≤25 atoms) that reach accuracy comparable to those achievable at coupled cluster level of theory -the 'gold standard' in quantum chemistry. In this way, sGDML reaches accuracy of 0.2 kcal mol -1 in energies and 1 kcal (mol Å) -1 in atomic forces, relative to coupled cluster calculations. This level of accuracy is crucial when modelling conformational transitions and vibrational spectroscopy of even small molecules such as ethanol and aspirin 98 . Hence, QML has already enabled us to obtain essentially exact dynamics for small molecules using computationally efficient MD simulations that correspond to a full QM treatment of both electrons and nuclei. Likewise, MD simulations of materials have largely benefited from the application of QML approaches. For example, QML-enabled simulations have been used to study the growth mechanism of tetrahedral amorphous carbon 99,100 , demonstrating the possibility to develop transferable DFT-level force fields for the investigation of complex processes in elemental solids.</p>
        <p>In light of the theoretical advances offered by QML, it is reasonable to wonder how QML-based predictions compare to experiments, if they could facilitate the analysis of the experimental measurements and possibly even guide the design of new experiments. It is encouraging to note that QML-based MD simulations can already reach the accuracy and efficiency necessary to predict experimental outcomes. For example, path-integral MD using the sGDML QML force field fitted with CCSD(T) atomic forces has been used to demonstrate that low-frequency excitations of ethanol arise from highly anharmonic combination of vibrational normal modes 101 , thus, resolving a long-standing experimental controversy (see ref. 101 for a detailed discussion) (fig. 2).</p>
        <p>Scalability of QML models has also been demonstrated by the applicability of models to large systems after being trained on small systems. Atom-by-atom-based training exploiting the locality of the chemical environment around each atom by on-the-fly training-set selection of only the most representative small fragments (such as AM-ons) was shown to yield promising results for energies, forces, NMR shifts and other QM properties for diverse systems of varying sizes reaching up to hundreds of atoms (not counting hydrogens) 3 . Albeit without the query-tailored selection of training fragments within the AM-on approach, other extensive atom-by-atom-based kernelridge regression and neural-network-based models have also demonstrated scalability (refs 86,87,[102][103][104] ).</p>
        <p>Another way to reduce complexity and increase accuracy of QML models consists of combining various levels of theory for training and testing 37,[105][106][107] . For example, the Δ-ML approach corresponds to generating QML models of corrections to a lower level efficient electronic-structure method in order to reach the accuracy of a much higher and more expensive level of theory 37 .</p>
        <p>Creating universal QML-based force fields trained and applicable across CCS still remains an open challenge due to the diversity of systems and non-local quantum interactions encountered when navigating simultaneously configurational and compositional space 59,81,86,87,102,[108][109][110] .</p>
        <p>Finally, we note that robust software codes are crucial for enabling widespread usage of ML techniques for chemical applications. Here, some pointers are provided to software packages of the discussed ML methods for quantum chemistry. General code for running QML is found in ref. 111 . Deep learning methods such as 
            <rs type="software">DTNN</rs> and 
            <rs type="software">SchNet</rs> can be readily implemented using the 
            <rs type="software">SchNetPack</rs> software 112 . The alternative accurate neural-network engine for molecular energies (ANI) neural-network package is also available 102 . The 
            <rs type="software">sGDML</rs> package, in which prior information has been included in the ML method (spatial and temporal conservation laws), is readily and easily usable in ref. 76 . The 
            <rs type="software">iNNvestigate</rs> toolbox that can explain non-linear learning methods such as deep learning is described in ref. 113 .
        </p>
        <p>In the previous section, we discussed how QML approaches can aid and extend the reach of QM calculations in several important directions. However, possibly the major appeal of QML is to provide new insights into QM properties of molecules and materials and, ultimately, enable efficient exploration of CCS and rational design of molecules and materials with tailored properties. Most commonly, ML methods are employed in fundamental and applied sciences to categorize and structure data, and to develop predictive models. Only recently, ML models have been used to learn and gain insights about the unknown underlying regularities hidden in data 86 . Given that the ML models achieve this by using rigorous statistical theory 114 , they can facilitate the formulation of new insights into chemical properties 86 or actionable hypotheses 115 that can be further validated and tested with high-level theory or experiments. In other words, ML modelling has become a powerful and indispensable part of the scientific discovery process itself.</p>
        <p>figure 2 illustrates six examples selected from our work and the literature of how such insights were gained from QML. The development of an accurate and data-efficient sGDML force-field model 49,101 (fig. 2a) enabled quantum MD simulations with essentially exact atomic forces computed at CCSD(T) level of theory. For the first time, it was possible to compute accurate thermodynamic and spectroscopic properties for molecules as large as aspirin without compromising the accuracy of atomic forces with the timescale accessible in MD simulations. Future work to improve the scalability of frameworks such as sGDML will enable us to perform fully predictive MD simulations in which both electrons and nuclei are treated rigorously with exact QM equations without unnecessary compromises between accuracy and efficiency of molecular simulations.</p>
        <p>Beyond energies and forces, a general QML model needs to predict accurate electronic response properties (akin to evaluating properties as expectation values of the QM wave functions). For example, the application of response operator theory to QML models is illustrated in fig. 2b.</p>
        <p>Here, the QML model of the binding curve of hydrogen fluoride improves qualitatively through the explicit inclusion of its derivative with respect to interatomic distance. The same formalism upon inclusion of the corresponding electric-field derivatives also improves dramatically the prediction of the electrostatic dipole moment 81 . The ultimate goal of QML should be creating a unified surrogate quantum model that can simultaneously learn many QM properties in a data-efficient and accurate manner.</p>
        <p>In other work by Gómez-Bombarelli and co-workers 116 , the optimization of new compounds was enabled through the use of generative models in latent space, a compressed variant of CCS with reduced dimensionality (fig. 2c), resulting in the prediction of promising light-harvesting materials candidates. Conceptually, this way of tackling the 'inverse design problem' (that is, the material is designed in order to exhibit a desired property) 117 through an intermediate step of effectively coarse-graining chemical space is intriguing. This inverse design of compounds constitutes an alternative approach to iteratively solving the 'forward design problem' , whereby compounds with target properties are designed, using gradient-based [118][119][120] , Monte Carlo 12 or genetic algorithms 13,117 , or combinations thereof 121 . Furthermore, the problem of generating meaningful compounds is solved elegantly in an implicit fashion by directly training on valid molecular graphs (SMILES strings), automatically ensuring that the 'grammar' of newly generated molecules is not being violated.</p>
        <p>Another way to obtain new insights is by analysing what the QML models have learned from the data, in the spirit of explainable artificial intelligence, in which ML models are dissected to analyse their inner mechanisms that lead to their respective predictions 114,[122][123][124] . An example of the application of this concept is provided by the analysis of the molecular representation learned by DTNN 86 . DTNN models and other flexible, non-parametric ML models are trained on QM molecular energies and, in the limit of infinite data, can learn the exact map of the solution of the Schrödinger equation for different molecular structures. Because the exact solution can only be formally achieved in the limit of an exact representation of the wave function, there is mathematically no other choice for DTNN than to attain an exact representation of the wave function. In practice, the representation is trained on a finite number of molecules, hence, DTNN learns the 'Schrödinger mapping' on a finite set of molecules and is, therefore, not necessarily in a one-to-one relation with the wave function. One can query the learned representation by adding a probe atom to a given molecule 86 . By visualizing the energy isosurface of the probe atom, one can immediately see that the obtained representation exhibits features that closely resemble electron densities or electrostatic potentials. This indicates that the model is able to infer QM features in the representation directly from a restricted set of QM energies (fig. 2d). Hence, the DTNN approach is attempting to solve an inverse design problem 12 by constructing a coarse-grained QM representation from a finite set of molecular energies or other QM properties (fig. 2d). Despite being trained only on total energies of molecules, the DTNN approach grasps fundamental chemical concepts such as bond saturation and different degrees of aromaticity. For example, the DTNN model predicts the C 6 O 3 H 6 molecule to be 'more aromatic' than benzene or toluene 86 . C 6 O 3 H 6 does have higher ring stability than both benzene and toluene, and DTNN predicts C 6 O 3 H 6 to be the molecule with the most stable aromatic carbon ring among all molecules in the QM9 database 86 . Interestingly, the mathematical construction of the DTNN model and other flexible non-parametric models 3,87 , based on atomic contributions, provide statistically rigorous partitioning of extensive molecular properties into atomic contributionsan interesting alternative to QM-based partitioning schemes 125 .</p>
        <p>We note that, although DTNN in principle can generate a 'Schrödinger map' between molecular Hamiltonians and molecular quantum properties, detailed analysis of the underlying representation learned by DTNN amounts to a complex inverse problem. To address this problem, a generalized SchNOrb architecture has been developed that learns the DFT wave function directly 92 . It would be desirable to unify both ML architectures (DTNN or SchNet and SchNOrb) to combine the direct 'Schrödinger map' (SchNOrb) with the inverse 'Schrödinger map' (DTNN or SchNet) and gain further understanding into the QM of molecules.</p>
        <p>QML is evidently also applicable to solids. For example, it has been used to calculate the formation energies of ~2 million elpasolite crystals (of ABC 2 D 6 sum formula with the components being main-group elements) 53 (fig. 2e). All the crystal candidates were ranked according to their estimated thermodynamic stability on the convex hull, resulting in the identification of nearly 100 potentially stable new crystals that were then added to the Materials Project database 51 . Furthermore, detailed analysis of oxidation states resulted in the discovery of an exotic crystal, NFAl 2 Ca 6 , in which Al carries an unusual negative oxidation state. This surprising finding was possible only through the systematic combination of QM calculations and ML.</p>
        <p>The fundamental nature of QML is not restricted to precalculated data sets. Within seminal work, Lee and co-workers have applied ML to experimental data in order to understand and control ligandprotein binding 126 (fig. 2f). In particular, random-matrix theory was used to identify the chemical groups and features that strongly affect binding and those that do not. Such analysis can provide invaluable information on how to exploit local chemical properties to steer a complex mechanism, such as drug-target binding.</p>
        <p>All of these examples demonstrate the great potential of QML for extracting statistical insights and new knowledge of quantum properties throughout CCS that cannot be directly obtained from conventional quantum calculations.</p>
        <p>The data-driven nature of QML approaches that are based on exploring increasingly larger swathes of CCS also offers the possibility of rationally designing molecules with multiple desired properties. For example, in a hypothetical drug-design scenario, one could be interested in finding a particularly stable molecule with a large polarizability α (that would stabilize the drug-protein van der Waals interaction) and a large electronic HOMO-LUMO gap E gap (that will afford stability with respect to external electrostatic fields). These three requirements would normally be considered contradictory to each other. Firstly, stability is typically inversely correlated with polarizability -stable molecules are normally thought to have small polarizability [127][128][129] . Secondly, the HOMO-LUMO gap is the leading-order contribution in the denominator of the polarizability formula, hence, it is often assumed that polarizable molecules should have small HOMO-LUMO gaps. One is then faced with a difficult question of whether the formulated design problem of low E, high α and high E gap is achievable. This question can be partially answered by analysing the pairwise correlation between different molecular properties for a large but finite set of drug-like molecules. These correlations are shown in fig. 3 for roughly 131,000 molecules in the QM9 data set 48 using the same analysis initially performed by Montavon and co-workers 47 . The first observation is that the correlation between most electronic properties is rather weak, if at all present. Most strikingly, above the lower bound of polarizability and atomization energy (both must be bounded from below), we observe no visible correlation. The same observation is made for polarizability versus the HOMO-LUMO gap. This pairwise comparison of three different properties suggests that one can find many drug-like molecules that satisfy the seemingly contrasting requirements of high stability, high polarizability and a large HOMO-LUMO gap. Similar freedom of design is observed for HOMO versus LUMO eigenvalues, as well as for HOMO-LUMO gap versus heat capacity. This data-driven analysis, spurred by the QML approach, illustrates a novel way to look at rational design in CCS, breaking conventional descriptor-property rules, as well as notions of restricted chemical diversity 47 .</p>
        <p>Developments in QML approaches can potentially change the way we perform and use atomistic simulations. This is due to the use of rigorous QM and SM priors and data instead of heuristic cheminformatics, a holistic view of CCS rather than the traditional encyclopedic view in which systems are studied one at a time, and because insights provided by new tools are relevant in different scientific fields (electronic-structure prediction, materials science, organic chemistry, molecular dynamics and drug discovery). figure 4 illustrates how this new approach could leverage conventional computational compound design applications and contribute substantially to ongoing experimental efforts, as also recently reviewed in the context of catalyst design 36 . As such, QML is clearly already taking the first steps in the direction of generally tackling the inverse design question in CCS 12,75,117 .</p>
        <p>We are confident that QML is not just limited to direct and inverse problems but can offer a fresh view on more fundamental aspects of molecules and materials. For example, QML represents a unique opportunity to rigorously test and assess known rules in chemistry, derived from human intuition and empiricism, up to an unprecedented degree of statistical confidence if sufficient data are made available. Furthermore, QML models could also help us discover and extract new concepts, which have, hitherto, escaped the notion of chemists. These developments may provide a further boost to attempts to gain a holistic understanding of CCS, its structure and what it holds in store for us in terms of interesting materials, properties or processes.</p>
        <p>Although QML has seen tremendous progress over the past few years, many more challenges remain to be addressed. In the following, we proceed by charting some of the challenges we consider as the most interesting and pressing.</p>
        <p>An important limitation for the QML field is the lack of large, comprehensive data sets. Although data sets like QM7 (refs 39,47 ), QM9 (ref. 48 ), Materials Project 51 , OQMD 52 , elpasolites 53 , MD17 (ref. 49 ), ANI-1 data set 50 , silicon structures 54 and others have served well for the development and testing of new ML techniques, there is an inherent danger to overfit to benchmarks -an issue that has driven the field of computer vision, for example, to exploring increasingly large and complex data sets 130,131 . It is, therefore, important to establish large, high-quality data resources that can enable the development of a new model to explore both composition and configuration of an increasingly wide portion of CCS 86,102 .</p>
        <p>Despite the advantage of having comprehensive big data in CCS, it remains crucial to develop efficient models that only rely on small amounts of data because of the combinatorial scaling in CCS. Clearly, learning with abundant data is straightforward, but it becomes more challenging to reliably learn from small data sets. In this case, it becomes crucial to include prior physics-based knowledge and invariance information to achieve data efficiency without compromising the robustness and accuracy of the QML model 49,76,101 .</p>
        <p>Furthermore, the new generation of models should ideally quantify the uncertainty of its own prediction 89,132,133 , possibly in combination with active learning strategies that may lead to improved sampling of CCS and effectively lead to smaller model uncertainties 134,135 . It is important to note that active learning actually induces non-stationarity in learning, since active learning by construction does not simply randomly sample from the underlying data distribution but actively biases the choice using the active learning score function 136 . In addition, models need to explain their prediction 114,122 , such that they can also be a source of insight 59,86 . In other words, future developments need to consider data generation, model building, explanation, insight extraction and sampling in a single, comprehensive framework. The recently introduced AM-on approach, which selects molecular fragments and trains QML models on the fly, represents a first step in this direction 3 .</p>
        <p>Current limitations and shortcomings of QML models are related to the prediction of intensive properties such as the eigenvalues of molecular orbitals 137 or excited-state These results have been obtained using the analysis proposed in ref. 47 based on data from the QM9 data set 48 .</p>
        <p>properties such as excitation energies 138,139 . Transferable yet accurate QML models of electron densities 140 and molecular orbitals in molecules and band structures in solids also remain a challenge. Another issue, lurking behind rigorous and robust statistical-learning procedures such as k-fold cross-validation and converged learning curves, is the selection bias encoded in many of the training sets used in the field. Stability or property distributions are typically unknown in CCS and, therefore, hamper the rigorous assessment of the degree to which any given data set is truly representative of broader chemical spaces. Similar problems of representability were also encountered in other fields of ML, for example, when trying to measure to what extent different search engines reflect all accessible website content on the internet. Practically, only a few random exemplary websites can be analysed while making a strong assumption that these selected websites are indeed representative of all the web page content on the internet 141,142 .</p>
        <p>Other challenges include the determination of the irreducible set of variables (that is, formal scaling of CCS is combinatorial in number of atoms and elemental species is only an upper bound but what is its effective dimensionality?) 79 . Assuring constant prediction errors throughout CCS is another challenge, as is reaching a quantitative understanding of the relation between the QML models' learning efficiency (as manifested in learning curve) and the dimensionalities of CCS as encoded in the training data.</p>
        <p>A very promising research direction is the integration of QML models across different levels of theory. By exploiting decades of research on the validity and applicability of the various approximations made when solving Schrödinger's equation, ample data obtained with computationally less demanding approximations can be combined with fewer but more accurate data points. As a result, the QML models must only learn the differences between the various levels of theory, which is substantially less demanding in terms of data needs. As such, these Δ-learning approaches allow us to invest the model complexity on the truly difficult aspects 37,105,106,[143][144][145] .</p>
        <p>Many studies so far have successfully explored structure-property relationships in restricted chemical spaces. However, the final goal is to enable global and universal exploration of CCS exploiting the appropriate framework offered by the combination of QM, SM and ML. Here, we have connected some of the ongoing efforts in this endeavour and have provided pointers into the broad activities of the scientific field that has emerged. We would like to stress that the tools available now have reached a level of maturity that should become helpful to a wider community of researchers and practitioners.</p>
        <p>In the following, we would like to outline three specific and outstanding open challenges that require further development of QML tools to find broad application.</p>
        <p>More observables. The use of QML to estimate statistical mechanics observables, for example, for the prediction of freeenergy profiles of rare events, remains an outstanding challenge. This will enable direct comparison to experimental gas-phase rate constants from the literature, as well as to vibrational or linear freeenergy-perturbation-based free-energy estimates. The comparison of the predictions to experimental results obtained in solution also requires the inclusion of solvent effects (that can be calculated using continuum solvent models, through addition of shells of solvent or through periodic boundary conditions). If necessary, one should also include nuclear quantum effects by performing path-integral simulations. These developments will serve the goal of establishing once and for all the validity of QML approaches by direct comparison to experiment, rather than to precalculated quantum results.</p>
        <p>Experimental design. QML forms the natural basis for software that can run assisted experiments (automatized or robot) or help scientists with experimental-design decisions. For example, QML approaches along these lines have been used to guide the design of new materials 53,116,146,147 . Latent-space applications and computational alchemy can be combined with state-ofthe-art optimizers, in essence, paving the way towards the experimental realization of aforementioned multi-property design tasks relevant to the identification of promising drug, photovoltaic, battery or catalyst candidates.</p>
        <p>Reaction design using QML. Computerbased reaction planning and discovery has a long-standing history in chemistry, dating back to the 1960s, including contributions by Corey and co-workers in 1972 (ref. 148 ) and Herges and Hoock in 1992 (ref. 149 ). A comprehensive review of the field 150 also discusses the 
            <rs type="software">Chematica</rs> software that identifies unexplored synthetic routes based on new combinations of already established reactions reported in the literature. Laino and colleagues 151 and Segler et al. 152 introduced literaturebased ML models for chemical reactions. However, these approaches can be problematic when it comes to combinations or reaction conditions for which previously published reactions are not representative. Moreover, the approach is inherently biased to established chemistry knowledge, limiting the possibility to discover entirely new reaction mechanisms and synthesis pathways. The latter point, however, is critical, for example, in the context of developing new catalysts and, more fundamentally, to fill any existing gaps in our understanding of potentially useful reactions. In order to computationally predict new reaction profiles, we must rely on universal first-principles numerical simulation of the relevant quantum and statistical mechanics, accounting for the electronic and atomic rearrangements that occur in a reaction pathway [153][154][155] . QM and SM account for the appropriate physics framework necessary to describe the electronic rearrangements occurring during a reaction and enable the user to dial in atomic configurations and chemical composition at will. When optimizing reactions through screens of prospective combinations of reactants, products and external conditions, the role of solvents and catalysts is crucial, as they can alter the ranking and even make the reactions possible. Therefore, one has to expand training sets to include libraries of solvents and simple catalysts, and apply extended QML models not only of energies and forces but also of statistical mechanical averages. Once trained, these QML models could be used to optimize reaction conditions (such as solvents, ions, temperature and pressure) in chemical space using gradient-free optimizers such as Monte Carlo, genetic or simplex algorithms. First steps in this direction were already taken in 2012 by Pozun and colleagues 156 .
        </p>
        <p>Over recent years, overwhelming evidence has been gathered by the community suggesting that QML models can be truly generalized throughout CCS. As such, our approach has changed, moving from globally fitting parameters in fixed functional forms, inspired by physics-informed models (such as universal force fields 157 or semi-empirical methods [158][159][160] ), to locally optimizing regression weights in generic basis-set expansions that can be converged in size. Resulting QML models enable rapid predictions of relevant quantum properties for new out-of-sample systems (after training) and achieve converged predictive power through sufficiently large training sets (as evinced by convergence properties of learning curves). Thanks to the tremendous reduction in computational cost of query tasks, QML models can shift the focus from individual instances in CCS towards entire ensembles of compounds. Recovery (or rejection) of known and discovery and elucidation of unknown structure-property relationships have, therefore, become feasible, realistic and valuable goals that were previously not accessible.</p>
        <p>Conceptual challenges include the definition of locality in CCS, that is, when the QML models are interpolating or, rather, extrapolating. Despite ensemble methods and Gaussian processes providing a first direction of uncertainty quantification in a limited domain of applicability, mathematically and physically more well-founded methods are still waiting to be discovered. Rigorous definitions of diversity 161 properly rooted in QM and SM might also be necessary to tackle the selection-bias problem and to maximize data efficiency. First-principles based diversity measures would have to properly account for all sorts of systems, including metal-organic frameworks, nanomaterials, organic materials, functional materials, inorganic crystals, metastable solids, liquid mixtures and biosystems.</p>
        <p>An educational challenge corresponds to the establishment of the academic curriculum for this interdisciplinary young field, in which research programmes in chemistry, physics and computer science need to be tightly interwoven. Conventional curriculae in traditional departments of chemistry, materials science, physics, computer science or biology do not cover the coursework necessary for students to appropriately reach a level by which they can meaningfully contribute to this line of research.</p>
        <p>Finally, we would like to stress that the progress made and described herein is dwarfed by the scope of the problem: gaining virtual control of CCS through physics-based understanding has remained elusive for all of humanity's past scientific efforts. One of the many rewards of reaching this goal would be the routine discovery and design of interesting molecules and materials with desired properties. As such, the community has, so far, just been scratching the surface of what is to come. To further push the frontier of this field of science, sustained and increasing investments are necessary in terms of computer power, interdisciplinary education and training, funding agencies and, most importantly, human interdisciplinary creativity.</p>
        <p>www.nature.com/natrevchem</p>
        <p>All authors thank F. A. Faber and J. Wagner for preparing the graphics in Fig. 1 and the cover image related to this article, respectively. O.A.v.L. acknowledges funding from the Swiss National Science foundation (nos. PP00P2_138932 and 407540_167186 NFP 75 Big Data) and from the European Research Council (ERC-CoG grant QML). This work was partly supported by the NCCR MARVEL, funded by the Swiss National Science Foundation. A.T. acknowledges financial support from the European Research Council (ERC-CoG grant BeStMo). K.-R.M. acknowledges partial financial support by the German Federal Ministry of Education and Research (BMBF) under grants 01IS14013A-E, 01GQ1115 and 01GQ0850; Deutsche Forschungsgesellschaft (DFG) under grant Math+, EXC 2046/1, project ID 390685689 and by the Institute for Information &amp; Communication Technology Promotion (IITP) grant funded by the Korea government (nos. 2017-0-00451 and 2017-0-01779). Correspondence to O.A.v.L., K.-R.M. and A.T.</p>
        <p>https://github.com/isayev/ ASE_ANI QM9 challenge: https://tinyurl.com/y2e589wj repository of data sets for quantum machine learning: http://quantum-machine.org schNetPack: 
            <rs type="url">https://github.com/atomistic-machine-learning/</rs> schnetpack symmetrized gradient-domain machine learning (
            <rs type="software">sGDML</rs>): http://quantum-machine.org/gdml/#code
        </p>
        <p>All authors contributed equally to the preparation of this manuscript.</p>
        <p>The authors declare no competing interests.</p>
        <p>Nature Reviews Chemistry thanks F. Noé, G. Csanyi and the other, anonymous, reviewer(s) for their contribution to the peer review of this work.</p>
        <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </text>
</tei>
