<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T11:31+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>Edge computing provides a promising paradigm to support the implementation of industrial Internet of Things (IIoT) by offloading computational-intensive tasks from resourcelimited machine-type devices (MTDs) to powerful edge servers. However, the performance gain of edge computing may be severely compromised due to limited spectrum resources, capacity-constrained batteries, and context unawareness. In this paper, we consider the optimization of channel selection which is critical for efficient and reliable task delivery. We aim at maximizing the long-term throughput subject to longterm constraints of energy budget and service reliability. We propose a learning-based channel selection framework with service reliability awareness, energy awareness, backlog awareness, and conflict awareness, by leveraging the combined power of machine learning, Lyapunov optimization, and matching theory. We provide rigorous theoretical analysis, and prove that the proposed framework can achieve guaranteed performance with a bounded deviation from the optimal performance with global state information (GSI) based on only local and causal information. Finally, simulations are conducted under both single-MTD and multi-MTD scenarios to verify the effectiveness and reliability of the proposed framework.</p>
        <p>T HE fourth industrial revolution aims to realize intercon- nected, responsive, intelligent and self-optimizing manufacturing processes and systems through seamless integration of advanced manufacturing techniques with industrial Internet of Things (IIoT) [1]. In this new paradigm, billions of machine-type devices (MTDs) will be deployed in the field for continuously performing various tasks such as monitoring, billing, and protection [2], [3]. Nevertheless, the tension between resource-limited MTDs and computationalintensive tasks has become the bottleneck for reliable service provisioning [4].</p>
        <p>Offloading computational-intensive tasks from resourcelimited MTDs to powerful servers provides a promising solution for accommodating the fast-growing computational demands. In conventional cloud computing, the remote cloud servers are generally located far away from MTDs, and the long-distance data transmission raises numerous issues including unstable connection, network congestion, and unbearable latency [5]. In comparison, edge computing [6], which shifts the computational capabilities from remote clouds to network edges within radio access network (RAN) [7], is a promising paradigm to reduce latency, relieve congestion, and prolong battery lifetime. It has attracted intensive research efforts from both industry and academia. In [8], Fan et. al considered the workload balancing problem in fog computing, and proposed a distributed device association algorithm to minimize the communication latency and the computational latency. They also extended their work to drone-assisted communication networks for IoT [9]. Markakis et. al developed a multiaccess edge computing based IoT framework for supporting next-generation emergency services, and provided several use cases of remote healthcare monitoring and management [10]. Omoniwa et. al proposed an edge computing-based IoT framework to enhance smart grid with improved scalability, security, response and less system cost [11].</p>
        <p>Unfortunately, although edge computing provides a promising way to exploit the abundant computational resources of edge servers, its performance gain may be severely compromised due to limited spectrum resources, capacity-constrained batteries, and context unawareness. First, to deliver a large volume of tasks from MTDs to the edge server on a realtime basis, channel selection has to be dynamically optimized in accordance with time-varying context parameters such as channel state information (CSI), energy state information (ESI), server load, and service reliability requirement. Conventional centralized optimization approaches [12], [13], rely on a common presumption that there exists a central node, e.g., the base station (BS), which has the perfect knowledge of all the context parameters. This presumption is too optimistic in real-world implementation considering the prohibitive cost of signaling overhead to collect information of the entire network. Therefore, a distributed optimization approach where each MTD individually optimizes its channel selection strategy based on only local information is more desirable. However, when the number of MTDs far more exceeds that of available channels, selection conflict w ill o ccur f requently i f multiple MTDs compete for the same channel, thus making the strategies of channel selection coupled across different MTDs. Second, given the limited battery capacity, a MTD will be out of service when the battery energy is exhausted. As a result, the short-term channel selection strategy also couples the long-term energy budget. Last but not least, industrial applications often require that certain service reliability should be guaranteed [14]. How to meet the stringent reliability requirement with limited resources and information brings another dimension of difficulty.</p>
        <p>Matching theory provides a flexible, l ow-complexity, and efficient t ool t o s olve t he c ombinatorial p roblem s uch as channel selection [15], task selection [16], and server selection [17]. However, it requires perfect knowledge of global state information (GSI) to construct the preference list, which specifies the fundamental matching criteria [18]. There exist some research attempts which study the optimization of channel selection based on matching and game theory [19], [20]. However, they rely on the assumption that the uncertain context parameters follow some well-known probability distribution, and may suffer from severe performance loss if the practical probability distributions of uncertain factors disagree from the presumed statistical models.</p>
        <p>In this paper, we propose a learning-based context-aware channel selection framework by combining machine learning, Lyapunov optimization, and matching theory. Specifically, we adopt the upper confidence b ound ( UCB) a lgorithm [ 21] to enable a MTD to learn the matching preferences and maximize the long-term optimality performance while maintaining a well-balanced tradeoff between exploitation and exploration. UCB was originally developed to solve the multi-armed bandit (MAB) problem [22], which involves sequential decision making based on only local information. It was designed for the single-player scenario and thereby inevitably leading to selection conflicts in the multi-player scenario where multiple MTDs are prone to select the same channel [23].</p>
        <p>We aim at maximizing the long-term network throughput subject to long-term constraints of energy budget and service reliability. The stochastic optimization problem is converted to a series of short-term deterministic problems by leveraging Lyapunov optimization [14]. We start from the simplified s ingle-MTD s cenario w ith p erfect G SI, and propose a Service-reliability-aware, Energy-aware, and data-Backlog-aware GSI (SEB-GSI) algorithm for channel selection. Then, we extend SEB-GSI to the nonideal case with only local information, and develop a UCB-based channel selection algorithm named SEB-UCB. It enables the MTD to dynamically balance throughput, energy consumption, and service reliability via online learning. Next, for the multi-MTD scenario with GSI, we formulate the optimization problem of channel selection as a one-to-one matching between MTDs and channels, and propose a matching-based solution named SEB-Matching GSI (SEB-MGSI). Afterwards, we emphasize the multi-MTD scenario with only local information, and develop a matching-learning based context-aware channel selection algorithm named SEB Conflict-aware MUCB (SEBC-MUCB), in which each MTD makes decision and learns the selection conflicts by continuously observing the relationship between matching preferences and matching results.</p>
        <p>The main contributions are summarized as follows: The simplified single-MTD scenario is firstly studied to provide some insight. Then, the more complicated multi-MTD scenario where selection conflicts exist is investigated. For both the single-MTD and the multi-MTD scenarios, the ideal case with perfect GSI is firstly studied as the performance benchmark. Then, the analysis is extended to the nonideal case with only local information where learning is considered. • Rigorous theoretical analysis and extensive performance evaluation: We analyze the optimality performance of the proposed framework from the perspective of network throughput and learning regret. We also provide a comprehensive analysis of computational complexity.</p>
        <p>Extensive simulations are carried out to validate its effectiveness and reliability under various scenarios and parameter settings.</p>
        <p>The remaining parts of this paper are organized as follows. The system model and the problem formulation are introduced in Section II. Section III and Section IV describe the learning-based context-aware channel selection for the single-MTD scenario and the multi-MTD scenario, respectively. A performance analysis from the perspective of optimality and complexity is given Section V. Practical implementation considerations and simulation results are provided in Section VI and Section VII. Section VIII concludes this paper.</p>
        <p>In this section, the system model and problem formulation are introduced.</p>
        <p>As shown in Fig. 1, we consider a single-cell scenario where an edge server is collocated with a BS. The BS provides connection service and the edge server provides computing service for K MTDs within the cell, the set of which is denoted by</p>
        <p>There exist J orthogonal subchannels, the set of which is defined as</p>
        <p>The bandwidth of subchannel c j is denoted by B j . Channel selection conflict occurs when more than one MTDs select the same subchannel at the same time, and only one MTD can succeed to access the subchannel under the coordination of the BS.</p>
        <p>A time-slotted model is adopted where the total optimization period is divided into T slots with equal length τ , the set of which is denoted by</p>
        <p>In this model, CSI remains unchanged within a slot and varies across different slots. In each slot, each MTD determines its channel selection strategy individually. Particularly, a MTD faces J +1 options, i.e., either selecting one of the J subchannels or remaining idle. Fig. 1 shows an example of channel selection with 4 MTDs and 2 subchannels. m 1 selects subchannel c 1 for data transmission while m 2 remains idle. Channel selection conflict occurs between m 3 and m 4 due to the simultaneous selection of subchannel c 2 .</p>
        <p>In the following, the models of task transmission, energy consumption, delay, and service reliability are introduced.</p>
        <p>1) Task Transmission Model: In the t-th slot, A k (t) new tasks with equal size γ k arrive at m k ∈ M, which are firstly stored in the local buffer and then are transmitted to the edge server. Hence, the total task size is γ k A k (t). Meanwhile, it has to retransmit Y k (t) amount of data, which have not been correctly delivered due to bit error. The task data stored in the local buffer of m k can be modeled as a queue, i.e., queue k. γ k A k (t) as well as Y k (t) can be seen as the amount of task data entering the queue and U k (t) represents the amount of task data leaving the queue. Define Q k (1) as the initial amount of data backlog. Q k (t) is the backlog of data queue k in the t-th slot, i.e., an accumulation of data that are yet to be processed. Q k (t) is dynamically evolved as</p>
        <p>The set of channel selection indicators consists of J + 1 binary elements, which is denoted by {x k,j,t }, where x k,j,t ∈ {0, 1}. When j = 1, 2, • • • , J, x k,j,t = 1 represents that m k selects subchannel c j for data transmission in the t-th slot and when j = J + 1, x k,j,t = 1 represents that m k remains idle.</p>
        <p>Considering the powerful computational capability of the edge server, the objective of each MTD is to offload as many tasks as possible, which equals to maximizing the total amount of task data that can be transmitted, i.e., the throughput.</p>
        <p>Uplink transmission is considered here. Denote H k,j,t as the uplink channel gain of subchannel c j between m k and the BS. Given x k,j,t , the achievable uplink transmission rate is given by</p>
        <p>where δ 2 is the noise power, and P TX is the transmission power. The throughput of m k in the t-th slot is given by</p>
        <p>The amount of data transmitted to the edge server can be</p>
        <p>x k,j,t z k,j,t .</p>
        <p>Denote the bit error rate (BER) for m k transmitting data through subchannel c j in the t-th slot as P e k,j,t . We consider the noncoherent binary phase shift keying (BPSK) modulation and the corresponding BER [24] of it can be derived as</p>
        <p>Here, BPSK is just used as an example to derive the queue evolution model, which can be naturally extended to other modulation schemes such as quadrature amplitude modulation (QAM) and orthogonal frequency division multiplexing (OFDM). Therefore, Y k (t + 1), the amount of data that has to be retransmitted in the next slot can be calculated as</p>
        <p>2) Energy Consumption Model: In the t-th slot, the energy consumption of m k for data transmission is the transmission power multiplied by the transmission delay, i.e.,</p>
        <p>The limited battery capacity exerts a direct impact on the total energy budget of m k over T slots, which is denoted by E k,max . Therefore, the long-term energy consumption of m k must satisfy</p>
        <p>3) Delay Model: In IIoT, the data size of computational results is generally smaller than that of the computational tasks. Therefore, for the sake of simplicity, we can neglect the downlink transmission delay. Some previous works, e.g., [25]- [27], also ignore the downlink transmission time. On the other hand, our work can be easily extended to the scenario where the downlink transmission time is considered. Therefore, the total offloading delay is the sum of the transmission delay and computational delay, which can be given by</p>
        <p>Given x k,j,t and z k,j,t , the transmission delay is calculated by dividing throughput z k,j,t with transmission rate R k,j,t , i.e.,</p>
        <p>Based on the computational intensity model in [28], assuming that the computational intensity of the task data transmitted by m k in the t-th slot is λ k,t (CPU cycles/bit), it requires z k,j,t λ k,t CPU cycles to process the task data. It is noted that although a linear relationship between workload and data size is employed, our work is compatible with other nonlinear models and can be used for different kinds of IIoT applications with different computing intensities. Denoting the available computational resources for m k in the t-th slot as ξ k,t , the computational delay is calculated as</p>
        <p>4) Service Reliability Requirement Model: We model the service reliability requirement in terms of delay. Denoting the task delay requirement as d k,t , the task offloading is unsuccessful if the offloaded task cannot be processed within the specified delay requirement, i.e., d total k,j,t &gt; d k,t . Denote X k,T as the number of successful task offloading for m k over T slots, which is given by</p>
        <p>I{x} is an indicator function with I{x} = 1 if event x is true and I{x} = 0 otherwise. The edge server performs computational resource optimization at the end of each slot and feeds back the result of whether the delay requirement of m k can be satisfied or not. The service reliability requirement is defined as</p>
        <p>where η k ∈ (0, 1] represents the minimum successful probability of task offloading.</p>
        <p>The objective is to maximize the long-term network throughput under the long-term constraints of energy budget and service reliability. Therefore, network throughput maximization problem is formulated as</p>
        <p>where C 1 and C 2 are the channel selection constraints, i.e., in each slot, each subchannel can be selected by at most one MTD, and each MTD can select only one subchannel at most or remains idle. C 3 and C 4 correspond to the constraints of energy consumption and service reliability, respectively. Here, we focus on optimizing channel selection strategy while the optimization of computational resource allocation is left to the future work. The reason is that the proposed algorithm is naturally compatible with any computational resource allocation scheme. Similarly, some previous works also only consider the channel selection problem [28]- [30]. On the other hand, the joint optimization of channel selection and computational resource allocation is a completely different problem, which requires different system modeling, problem formulation, and optimization design. Utilizing learning algorithms to solve the joint optimization problem of integer channel selection and continuous computational resource allocation is also a worthwhile research direction which will be investigated in the future work.</p>
        <p>In this section, we consider the single-MTD scenario with only one MTD, e.g., m k , and propose a learning-based context-aware channel selection algorithm.</p>
        <p>Problem P1 cannot be directly solved due to the long-term optimization objective and constraints. To provide a tractable solution, we leverage Lyapunov optimization to transform a coupled long-term stochastic optimization problem into a series of short-term deterministic problems [31], [32], which can be solved in low complexity while the data backlog, energy consumption, and service reliability are balanced over time.</p>
        <p>Based on the concept of virtual queue [33], the long-term energy budget and service reliability constraints, i.e., C 3 and C 4 , can be transformed to queue stability constraints. We define a virtual energy deficit queue N k (t) and a virtual service reliability deficit q ueue F k (t), w hich a re evolved as</p>
        <p>with</p>
        <p>represents the deviation of current energy consumption from the energy budget, while F k (t) reflects the deviation of service reliability from the specified requirement. Examples of queue evolution for MTDs are shown in Fig. 1. Taking m 1 as an example, the data queue Q 1 (t), the virtual energy deficit queue N 1 (t), and the virtual service reliability deficit queue F 1 (t) are dynamically updated at each slot based on ( 1) and (15). Comparing m 1 and m 2 , it is noted that the data backlog and the service reliability deficit of m 1 are larger while the energy deficit of m 2 is larger.</p>
        <p>Then, P1 can be transformed into a series of shortterm optimization subproblems. At each slot, if the energy consumption of m k until the t-th slot does not exceed the energy budget, an online multi-objective optimization problem is defined to maximize throughput and service reliability while minimizing energy consumption, which is given by</p>
        <p>For convenience, we write</p>
        <p>Here, θ k,j,t is a weighted sum of throughput, energy consumption and service reliability, where V k , α k N k (t), and β k F k (t) are the corresponding weights.</p>
        <p>P2 and P1 are not equal, and the results of P2 may not be feasible for P1. Nevertheless, we can prove that the results of P2 are within a bounded deviation from the optimal results in Section V. Furthermore, C 3 can be guaranteed by defining that if the energy budget of m k is exhausted, then it cannot transmit data and is forced to remain idle. In other words, at the t-th slot, P2 will be solved if and only if the energy budget is not exhausted. On the other hand, C 4 is satisfied in a best effort way due to service reliability awareness, i.e., a large deviation from the service reliability requirement will enforces m k to select the option with higher successful chances of task offloading, thereby trying the best to satisfy C 4 . It is noted that C 4 cannot be 100% guaranteed due to the lack of centralized optimization and coordination among all the MTDs.</p>
        <p>The local information is referred as the information that can be possessed by m k without additional information exchange with other entities in the network, e.g., the BS or the other MTDs. The nonlocal information refers to the information that can only be possessed by m k with additional information</p>
        <p>Phase 2: Decision making 6: Input: H k,j,t , δ 2 . 7: Calculate the accurate value of θ k,j,t with GSI, j = 1, 2, • • • , J + 1 . 8: Choose j by solving P2. 9: Observe z k,j,t , E k,j,t and whether the delay requirement can be satisfied or not. 10: Update U k (t) and Y k (t + 1) based on ( 4) and ( 6). 11: Update Q k (t + 1), N k (t + 1), and F k (t + 1) as ( 1) and ( 15). 12: Until t &gt; T .</p>
        <p>exchange. Otherwise, if information exchange is infeasible, nonlocal information is unknown to m k . Therefore, the information required to solve P2 can be classified into two categories, i.e.,</p>
        <p>• Local Information: information that can be possessed by m k without additional information exchange, e.g., the queue backlog Q k (t), the transmission power P T X , the total energy budget E k,max , the computational intensity of task data λ k,t , the task delay requirement d k,t , and the service reliability requirement η k . • Nonlocal Information: information that cannot be possessed by m k without additional information exchange, e.g., the uplink channel gain H k,j,t for any subchannel c j ∈ C, the available computational resources of the edge server ξ k,t , and the channel selection strategies of other MTDs {x k,j,t } (only required for the multi-MTD scenario). For the local information, the time-varying information is denoted by the symbol with subscript t or as a function of t, e.g., Q k (t), λ k,t , and d k,t . Otherwise, the local information is fixed, e.g., P T X , E k,max , and η k . The nonlocal information is expressed in the same way and all the nonlocal information is time-varying.</p>
        <p>Based on whether m k has the nonlocal information or not, we consider an ideal and nonideal case, respectively. In the ideal case, m k has the perfect knowledge of GSI, which includes both local and nonlocal information. In the nonideal case, m k only knows the local information while the nonlocal information is unavailable.</p>
        <p>For the ideal case with GSI, we propose a context-aware channel selection algorithm named SEB-GSI with service reliability awareness, energy awareness and backlog awareness. SEB-GSI does not require future non-causal information. The detailed procedures are summarized in Algorithm 1, which consists of two phases, i.e., initialization (Line 2 ∼ 3) and decision making (Line 5 ∼ 9). Algorithm 1 is provided to demonstrate how to initialize queues, determine the optimal option, and update queues.</p>
        <p>In the initialization phase, the initial length of all the queues and initial values of all the selection indicators are set as zero.</p>
        <p>Then, the decision making phase is executed in a slot-byslot fashion. At the beginning of the t-th slot, m k calculates the value of θ k,j,t towards option j, j = 1, 2, • • • , J + 1, based on the current GSI. The optimum option j can be found by solving P2, which is equivalent to a minimum seeking problem with computational complexity O(J). Afterwards, m k sets x k,j,t = 1, and updates all queues accordingly. In the next slot, the iteration continues until t &gt; T .</p>
        <p>The proposed SEB-UCB can adapt to the variations of the amount of data backlog, energy state and the service reliability state due to the endowed context awareness, which is achieved through the dynamic adjustment of channel selection strategy based on the values of F k (t), N k (t), and Q k (t). Details are given as follows:</p>
        <p>• Service reliability awareness: When the service reliability deviates severely from the service reliability requirement, a large weight F k (t) will be placed on the service reliability term which enforces m k to select the option with higher successful chances of task offloading, thereby enabling service reliability awareness. • Energy awareness: When the energy consumption significantly exceeds the current energy budget, a large weight N k (t) on the energy consumption term will enforce m k to select the option with less consumption, i.e., remaining idle, thereby enabling energy awareness. • Backlog awareness: A large data backlog Q k (t) will lead to a large throughput z k,j,t = τ R k,j,t based on (3), which motivates m k to choose the subchannel with higher data transmission rate, thereby enabling backlog awareness. Since F k (t), N k (t), and Q k (t) are updated without requiring future information, SEB-GSI optimizes the balance among throughput performance, energy consumption, and service reliability requirement in an online fashion.</p>
        <p>In the nonideal case where the nonlocal information is unavailable, the proposed SEB-GSI algorithm is infeasible because the accurate value of θ k,j,t cannot be obtained. To tackle this problem, we modify SEB-GSI based on the UCB1 framework [21], which is a low-complexity learning-based algorithm to deal with the sequential decision-making problem, and develop a learning-based context-aware channel selection algorithm named SEB-UCB. Instead of directly calculating θ k,j,t in SEB-GSI, SEB-UCB estimates θ k,j,t based on historical observations while simultaneously taking into account the uncertainty of estimation via confidence bound. It enables m k to learn the optimal option based only on local information and achieve a bounded deviation from the optimal performance obtained with GSI.</p>
        <p>The proposed SEB-UCB algorithm is summarized in Algorithm 2. In each time slot, m k makes decisions based on only two kinds of local information: θk,j,t-1 and xk,j,t-1 , where θk,j,t-1 represents the empirical estimation of θ k,j,t-1 up to</p>
        <p>as the initial amount of data backlog, N k (1) = 0, F k (1) = 0, θk,j,0 = 0, xk,j,0 = 0 and x k,j,t = 0, j = 1, 2, • • • , J + 1, ∀t ∈ T . 4: Repeat 5: Phase 2: Estimation and decision making 6: Calculate the estimation value of the MTD towards option j as (17). 7: Select the optimal option j based on (18). 8: Phase 3: Learning 9: Observe z k,j,t , E k,j,t and whether the delay requirement can be satisfied or not. 10: Update θk,j,t and xk,j,t based on (19) and (20). 11: Update U k (t) and Y k (t + 1) based on ( 4) and ( 6). 12: Update Q k (t + 1), N k (t + 1), and F k (t + 1) as ( 1) and (15). 13: Until t &gt; T . slot t, and xk,j,t-1 represents the number of times that m k has selected the j-th option up to slot t. The estimation of m k towards the option j in the t-th slot is estimated as</p>
        <p>where the first term represents the empirical performance of the option j, and the second term represents the confidence bound, which is designed to balance the tradeoff between exploration and exploitation. On one hand, the first term pushes m k to select a priori known optimal option up to slot t. On the other hand, the second term is inversely proportional to xk,j,t-1 , which allows m k to explore options with less number of selections in order to improve the accuracy of estimation. Here, ω is the weight of exploration compared with exploitation, i.e., a larger ω represents a higher preference for exploration.</p>
        <p>After estimating θ k,j,t for all the J + 1 options, m k chooses option j with the least estimation value, which is determined as</p>
        <p>Then, m k observes the corresponding results z k,j,t , E k,j,t associated with x k,j,t = 1 and whether the delay requirement can be satisfied or not. Accordingly, θk,j,t and xk,j,t are updated as θk,j,t = θk,j,t-1 xk,j,t-1 xk,j,t-1 + x k,j,t</p>
        <p>and</p>
        <p>Algorithm 3 SEB-MGSI</p>
        <p>as the initial amount of data backlog, N k (1) = 0, F k (1) = 0, θk,j,0 = 0, and x k,j,t = 0, j = 1, 2, • • • , J + 1, ∀m k ∈ M, ∀t ∈ T . 4: Repeat 5: Phase 2: Preference list construction 6: Each MTD calculates its preference value towards each option as (21). 7: Each MTD constructs its preference list F k and any m k ∈ M t transmits F k to the edge server for iterative matching. c j raises its price ρ k,j as (22).</p>
        <p>All the MTDs selecting c j update their preferences as (21) and renew their selection strategies. end if 23: end if 24: Observe z k,j,t , E k,j,t and whether the delay requirement can be satisfied or not. 25: Update U k (t) and Y k (t + 1) based on (4) and (6). 26: Update Q k (t + 1), N k (t + 1), and F k (t + 1) as ( 1) and (15). 27: Until t &gt; T .</p>
        <p>Based on z k,j,t , U k (t) and Y k (t+1) can be calculated based on (4) and (6). Next, the three queues, i.e., Q k (t+1), N k (t+1), and F k (t + 1), are updated as (1), (15).</p>
        <p>Finally, increase t to t + 1, and repeat lines 5 ∼ 12 until t &gt; T .</p>
        <p>In this section, we consider channel selection under the multi-MTD scenario, where the channel selection strategies of different MTDs are coupled. Both the SEB-GSI and the SEB-UCB algorithms proposed in the previous section are not suitable for this scenario because the coupling among MTDs are not considered. To tackle this problem, we start from the ideal case with perfect GSI, and develop a matching-based contextaware channel selection algorithm named SEB-MGSI. Next, we consider the more practical nonideal case with only local information, and develop a matching-learning based contextaware channel selection algorithm named SEBC-MUCB.</p>
        <p>A. The SEB-MGSI Algorithm for the Ideal Case When K MTDs are competing for the J subchannels, the channel selection problem involves a one-to-one matching between K MTDs and J subchannels. The definition of matching is given by Definition 1. (Matching): Denote φ as the one-to-one correspondence from set M∪C onto itself. Specifically, φ(m k ) = c j indicates that m k is matched with subchannel c j , i.e., x k,j,t = 1, j = 1, 2, • • • , J, and φ(m k ) = m k indicates that m k is not matched with any subchannel and has to remain idle, i.e., x k,J+1,t = 1.</p>
        <p>Remark 1. x k,J+1,t = 1 actually contains two situations, the first of which is that m k prefers to remain idle, and the second of which is m k being forced to remain idle due to the shortage of subchannel.</p>
        <p>The SEB-MGSI algorithm is developed based on pricingbased matching [16], which is summarized in Algorithm 3. It can be implemented in two phases: initialization (Line 2 ∼ 3), preference list construction (Line 5 ∼ 7) and iterative matching (Line 8 ∼ 22).</p>
        <p>1) Initialization: The initial length of all the queues and initial values of all the selection indicators are set as zero.</p>
        <p>2) Preference List Construction: In the second phase of preference list construction, Since the preference of m k towards any option j, j = 1, • • • , J +1, is inversely proportional to θ k,j,t , it can be simply expressed as</p>
        <p>where ρ k,j represents the cost of matching m k with c j , the initial value of which is set as zero.</p>
        <p>Denote the preference list of m k towards all the J + 1 options as F k , which is obtained by sorting all the L k,j,t , j = 1, 2, • • • , J + 1, in a descending order.</p>
        <p>If option J +1 ranks the first in F k , m k will skip the iterative matching process and remain idle during this slot. Otherwise, any m k ∈ M t updates F k by removing option J + 1, where M t ⊆ M is the set of MTDs selecting to transmit data in the t-th slot. Then any m k ∈ M t transmits it to the edge server for resolving matching conflicts based on the following procedures:</p>
        <p>3) Iterative Matching:</p>
        <p>Step 1:</p>
        <p>Here, Ω denotes the conflicting set of subchannels which are selected by more than one MTDs.</p>
        <p>Step 2: Pricing-based iterative matching Repeat</p>
        <p>• For any subchannel c j ∈ C, if it is selected by only one MTD, e.g., m k , then they are directly matched, i.e., φ(m k ) = c j . Otherwise, add c j into Ω.</p>
        <p>-Each subchannel c j ∈ Ω raises its price ρ k,j as</p>
        <p>as the initial amount of data backlog, N k (1) = 0, F k (1) = 0, θk,j,0 = 0, xk,j,0 = 0, and x k,j,t = 0, j = 1, 2, • • • , J + 1, ∀m k ∈ M, ∀t ∈ T . 4: Temporarily match ∀m k ∈ M with ∀c j ∈ C to observe the performances of throughput, energy consumption and delay. 5: Repeat 6: Phase 2: Pricing-based matching 7: Each MTD calculates its preference value towards each option as (23). 8: Each MTD constructs its preference list F k and the m k ∈ M k transmits F k to the edge server for iterative matching. 9: Each MTD performs the corresponding selection based on φ(m k ). 10: Phase 3: Learning 11: Observe z k,j,t , E k,j,t and whether the delay requirement can be satisfied or not. 12: Update θk,j,t and xk,j,t based on (19) and (20). 13: Update U k (t) and Y k (t + 1) based on ( 4) and ( 6). 14: Update Q k (t + 1), N k (t + 1), and F k (t + 1) as ( 1), (15). 15: Until t &gt; T .</p>
        <p>where ∆ρ j is the step size for price rising.</p>
        <p>-All the MTDs which have selected c j recalculate their preferences towards c j based on (21), and renew their selection strategies accordingly. If the cost of c j is too high, some MTDs will give it up and select other subchannels. -Repeat the pricing process until only one MTD remains, e.g., m k . Then, set φ(m k ) = c j and remove c j from Ω. -If any c j in F k has been matched with other MTDs and is unavailable to</p>
        <p>Finally, the MTDs select the subchannels based on the derived φ, observe the corresponding results z k,j,t , E k,j,t associated with x k,j,t = 1, and whether the delay requirement can be satisfied or not. Then, each MTD m k updates U k (t), Y k (t + 1), Q k (t + 1), N k (t + 1), and F k (t + 1) as ( 19), ( 20), ( 4), ( 6), ( 1) and (15). The iterations between the phase of preference list construction and the phase of iterative matching are terminated when t &gt; T .</p>
        <p>In the proposed pricing-based matching, the price of occupying c j for m k is inversely proportional to F k (t), thereby allowing MTDs with larger service reliability deficit to have a higher probability to be matched with a subchannel, which further enhances service reliability awareness.</p>
        <p>In the nonideal case where the nonlocal information required to construct preference lists of MTDs is unavailable, the matching-based SEB-GSI algorithm is infeasible. Following the idea of SEB-UCB developed in subsection III-C, an intuitive solution is to enable a MTD to estimate its preference list via online learning. We augment SEB-UCB by adding conflict awareness into the learning process, and develop the matching-learning based SEBC-MUCB algorithm. In SEBC-MUCB, a MTD can learn the impacts of decision coupling and matching conflicts by continuously observing the difference between its matching preference and actual matching results. SEBC-MUCB is summarized in Algorithm 4, which consists of three phases, i.e., initialization (Line 2 ∼ 4), pricingbased matching (Line 6 ∼ 9), and learning (Line 10 ∼ 14).</p>
        <p>In the first phase of initialization, firstly, the initial length of all the queues and initial values of all the selection indicators are set as zero. Then, for any m k ∈ M, it is temporarily matched with every c j ∈ C to observe the performances of throughput, energy consumption and delay.</p>
        <p>In the second phase of pricing-based matching, m k estimates its preference towards the j-th option as</p>
        <p>Here, the preference value of m k towards an option that has not been selected, e.g., xk,j,t-1 = 0, is defined as +∞ so that each option can be selected by m k at least once. Then, based on ( 23), m k constructs its preference list F k similarly as subsection IV-A and transmits it to the edge server. Next, MTDs are matched with subchannels based on the pricing-based matching. Eventually, each MTD selects the subchannel according to the obtained φ(m k ).</p>
        <p>In the third phase of learning, each MTD m k observes the corresponding results z k,j,t , E k,j,t associated with x k,j,t = 1 and whether the delay requirement can be satisfied or not. Then, each MTD m k updates θk,j,t , xk,j,t , U k (t), Y k (t + 1), Q k (t + 1), N k (t + 1), and F k (t + 1) as ( 19), ( 20), ( 4), ( 6), (1) and (15). The iterations between the phase of pricing-based matching and the phase of learning are terminated when t &gt; T .</p>
        <p>In this section, we provide a comprehensive performance analysis of the proposed algorithms from the perspective of optimality and complexity.</p>
        <p>We first present the bounded cumulative throughput performance of SEB-MGSI. Then, we quantify the performance loss due to learning in terms of learning regret and provide its upper bound. Finally, the bounded cumulative throughput performance of SEBC-MUCB is provided.</p>
        <p>To provide theoretical upper bound of the cumulative throughput performance, we describe a scenario where MTDs know the GSI for the future T slots. We define x * k,j,t , z * k,j,t and j * as the channel selection indicator, throughput and the optimum option derived with T -slot GSI. Specifically, x * k,j,t = 1 is satisfied when event j = j * is true and x * k,j,t = 0 otherwise. Accordingly, define ẍk,j,t , θk,j,t , zk,j,t and j as the channel selection indicator, the weighted sum of throughput, energy consumption and service reliability, throughput and the j optimum option achieved by the algorithms for the ideal case, i.e., SEB-MGSI for multi-MTD scenario and SEB-GSI for the single-MTD scenario. Define x ˘k,j,t , θ ˘k,j,t , z ˘k,j,t a nd a s the channel selection indicator, the weighted sum of throughput, energy consumption and service reliability, throughput and the optimum option achieved by the algorithms for the ideal case, i.e., SEBC-MUCB for multi-MTD scenario and SEB-UCB for the single-MTD scenario.</p>
        <p>Theorem 1. The cumulative throughput achieved by SEB-MGSI is be lower bounded as</p>
        <p>where B max is defined as</p>
        <p>Proof: See Appendix A. Learning regret represents the expected performance difference between the cumulative weighted sum of throughput, energy consumption and service reliability achieve by SEB-GSI and that achieved by SEBC-MUCB. Given K MTDs and J + 1 options, the learning regret R is defined as</p>
        <p>For the purpose of simplicity, we define</p>
        <p>where θk,j = E[θ k, j,t ] and θk,j = E[θ k, j,t ].</p>
        <p>Theorem 2. When ω = 1, the learning regret of the SEBC-MUCB is upper bounded as</p>
        <p>Proof: See Appendix B. Based on the definition of learning regret, the cumulative throughput achieved by SEBC-MUCB can be derived as the cumulative throughput achieved by SEB-MGSI minus learning regret.</p>
        <p>Theorem 3. The cumulative throughput achieved by SEBC-MUCB is lower bounded as</p>
        <p>Nk (t) Ëk,j,t</p>
        <p>x k, j,t ). x * k,j,t z * k,j,t -</p>
        <p>ẍk,j,t zk,j,t . (30)</p>
        <p>Theorem 5. When ω = 1, the learning regret of the SEB-UCB is upper bounded as</p>
        <p>Theorem 6. The cumulative throughput achieved by SEB-UCB is lower bounded as</p>
        <p>x k, j,t ). (32) Proof: Theorem 4, Theorem 5, and Theorem 6 can be proved as special cases of Theorem 1, Theorem 2, and Theorem 3, respectively, when K = 1. The detailed proof is ignored due to space limitation. Theorem 7. For SEBC-MUCB, after the initial 8(∆θ k, j, j )</p>
        <p>2 ln(t) times of selecting a non-optimal option, the probability of selecting a non-optimal option is upper bounded by 2t -4K . As t → +∞, the upper bound converges to 0.</p>
        <p>Proof: See Appendix D.</p>
        <p>The computational complexity of SEB-GSI consists of four parts. The first part is initialization with the complexity of O(J + 4), and the second part is calculating θ k,j,t of J + 1 options with the complexity of O(J + 1). The third part is seeking the minimum θ k,j,t with the complexity of O(J) and the fourth part is renewing queues with the complexity of O(3). Therefore, the computational complexity of FEB-GSI is O(J + 4) + O(J + 1) + O(J) + O(3).</p>
        <p>SEB-UCB: The computational complexity of SEB-UCB is composed of three parts. The computational complexity of the first phase is O(3J +6), and that of the second phase is O(J + 1) + O(J). The complexity of the third phase is O(2J + 5). Therefore, the computational complexity of SEB-UCB is O(3J + 3) + O(J + 1) + O(J) + O(2J + 5).</p>
        <p>SEB-MGSI: The computational complexity of SEB-MGSI is composed of three parts. The first p art i s i nitialization with the complexity of O(2J + 5), and the second part is the complexity of pricing-based matching. Assuming the matching conflicts c an b e r esolved w ithin i terations, t he c onflict can be solved with the complexity of O(J +1)+O((J +1) log(J + 1)) + O(I ) when K ≥ J. The complexity of renewing queues is O(3). Therefore, the computational complexity of SEB-MGSI is O(2J + 5) + O(J + 1) + O((J + 1) log(J + 1)) + O(I ) + O(3).</p>
        <p>SEBC-MUCB: The computational complexity of SEBC-MUCB consists of three parts. The complexity of the first and second phases are the same as that of SEB-UCB and SEB-GSI, respectively. The complexity of the third phase if O(2J + 5). Therefore, the complexity of SEBC-MUCB is O(3J + 6) + O(J + 1) + O((J + 1) log(J + 1)) + O(I ) + O(2J + 5) when K ≥ J.</p>
        <p>In real-world implementation, the convergence time and the performance loss due to learning can be further reduced. Theorem 2 indicates that the learning regret is related to both the numbers of MTDs and subchannels to be explored as well as the exploration cost. Two heuristic solutions are provided here, i.e., set division and task division.</p>
        <p>To reduce the numbers of MTDs and subchannels, one heuristic solution is to divide the set of subchannels C and the set of MTDs M into several subsets. Then, a subchannel set, e.g., C s ⊂ C, is exclusively licensed to a MTD subset M s ⊂ M, i.e., only MTDs belonging to the subset M s are allowed to use subchannels in C s . As a result, the numbers of competing MTDs and subchannels can be reduced since</p>
        <p>When implementing the set division-based heuristic solution, the BS has to obtain the precise knowledge of the set of subchannels C and the set of MTDs M. Since the sets of subchannels and MTDs do not vary every slot, the BS only needs to collet this information once at each optimization duration. The BS will collect the information of C and M, perform set division based on certain optimization rules, and inform the MTDs of the division results, i.</p>
        <p>To increase the convergence speed and reduce the exploration cost, another heuristic solution is to enable MTDs to utilize a smaller task for learning. The MTDs can divide a large task into several smaller tasks. Since the task size is small, both the transmission delay and computational delay can be reduced significantly. Furthermore, with smaller task, each slot can also be divided into several subslots, and in each subslot, the MTDs can make a channel selection decision and perform learning by observing the feedback from the edge server, thereby increasing the total number of exploration in each slot. This can dramatically improve the convergence speed and reduce the convergence time. When implementing the task division-based heuristic solution, a MTD has to divide a large task into several smaller tasks. In other words, the task should be dividable. Both task division and slot division can be performed by the MTD based on local information.</p>
        <p>Although the learning-based algorithm involves a lot of iterations, the iteration delay in each slot is negligible. The reason is that during each slot, a MTD only makes one decision and then waits for the reward associated with the decision. In other words, there is only one iteration of channel selection at each slot. Therefore, the delay for processing a task mainly consists of the transmission delay and the computational delay, while the iteration delay can be ignored.</p>
        <p>In this section, we validate the proposed algorithms via simulations under the scenarios of single-MTD and multi-MTD, respectively.</p>
        <p>In the single-MTD scenario, we consider one MTD and three subchannels over a total period of T = 10 3 time slots, i.e., K = 1 and J = 3. We set τ = 1 s, P TX = 1 W, E k,max = 700 J. We assume that A k (t) follows a uniform distribution within the interval [0.9 Āk , 1.1 Āk ] Mbits, where Āk = 20 Mbits represents the time-average amount of collected data. The initial value Q k (1) is randomly selected within the interval [0.8 Āk , 1.2 Āk ] Mbits. The computational complexity is set as λ k,t = 10 3 CPU cycles/bit. The available computational resource for m k in the t-th slot ξ k,t is randomly distributed within the interval [0.9 ξk , 1.1 ξk ] CPU cycles, where ξk = 18 × 10 9 CPU cycles represents the timeaverage amount of computational resource. U k (t) does not need to be initialized, the value of which depends on the selection strategies, CSI as well as local data backlog. The service reliability requirement is set as η k = 0.7. We set V k = 1, α k = 5, and β k = 3 to balance the tradeoff among throughput performance, energy consumption, and service reliability. The achievable transmission rate of subchannel s j in each slot follows a uniform distribution within the range [0.8 Rj , 1.2 Rj ], where Rj represents the average transmission rate. We set Rj = 10, 20, 30 Mbits when j = 1, 2, 3. The weight of exploration ω is set as 1. Two heuristic algorithms are used for comparison. One is the conventional UCB algorithm proposed in [34], and the other is the random selection algorithm in which m k randomly selects a subchannel at each slot. The SEB-GSI with perfect GSI is used as an upper performance benchmark. Fig. 2(a) and Fig. 2(b) show the cumulative network throughput and cumulative energy consumption performances over a total of 10 3 slots. Compared with UCB and random selection, the proposed SEB-UCB with only local information can improve throughput by 30% and 36% respectively, while satisfying the constraint of energy consumption. Particularly, there exists a performance floor after 700 slots. The reason is demonstrated in Fig. 2(b), which explicitly shows that the two heuristic algorithms use energy more aggressively at the beginning and then run out of the energy at t = 700 and t = 720, thereby leaving no energy for data transmission. It is noted that the energy consumption of the proposed algorithms will not increase after t = 1000 since the energy budget is exactly exhausted at t = 1000, i.e., the proposed algorithms can well exploit the available energy during the specified optimization duration compared with other heuristic algorithms. Besides, the SEB-UCB performs just slightly worse than the SEB-GSI algorithm with perfect GSI. The curve trends of both the network throughput and energy consumption performances track those of SEB-GSI strictly. Fig. 2(c) shows the data backlog performance. Simulation results demonstrate that SEB-UCB can provide bounded data backlog, while the backlogs of UCB and random selection increase linearly with time after 700 slots, which significantly degrades the queue stability performance and may even lead to severe data loss.</p>
        <p>For the multi-MTD scenario, we consider three MTDs and three subchannels, i.e., K = J = 3. We set E k,max = 730 J, η k = 0.73, V k = 1, α k = 20, and β k = 25, ∀m k ∈ M. The other simulation parameters remain the same as those in the single-MTD scenario.</p>
        <p>Five heuristic algorithms are used for comparison. The first one is the EBC-MUCB algorithm without service reliability awareness, i.e., the service reliability constraint is not considered. The second one is the SBC-MUCB algorithm without energy awareness, i.e., the energy consumption constraint is not considered. The third one is the conventional UCB algorithm, and the fourth one is random selection. The fifth one is the Lyapunov optimization-based access control and resource allocation (ACRA) algorithm developed in [14]. ACRA requires perfect GSI to find the optimum option. Here, we assume that only the CSI of the previous slot is available, i.e., the CSI is outdated information. In other words, optimization at the t-th slot is performed based on the CSI of the (t -1)-th slot. Fig. 3(a) shows the cumulative network throughput versus time slot. The proposed SEBC-MUCB outperforms UCB and random selection by 13.7% and 31.2%, respectively. Compared with SBC-MUCB and EBC-MUCB, SEBC-MUCB improves throughput by 3.46% and 3.96%, respectively, due to the additional consideration of energy awareness and service reliability awareness. Taking SBC-MUCB as an example, although it achieves a higher throughout at the beginning, it runs out of energy at t = 981 and is forced to be idle for the remaining slots, which significantly degrades the overall throughput performance.</p>
        <p>Fig. 3(b) shows the cumulative energy consumption versus time slot. Simulation results show that The energy consumption of SEBC-MUCB and EBC-MUCB algorithms has not exceeded the energy budget due to energy awareness. Different from the scenario of single-MTD, UCB consumes the least energy since the frequent selection conflicts force MTDs to remain idle so that the energy consumption becomes less.</p>
        <p>Fig. 3(c) demonstrates that SEBC-MUCB achieves the least data backlog among all the algorithms. In comparison, the data backlog of SBC-MUCB increases dramatically after t = 981 due to the ignorance of energy awareness. UCB performs worse than EBC-MUCB and SBC-MUCB since the frequent selection conflicts impede MTDs from data transmission and data backlog becomes very large. Fig. 4 shows the service reliability deficit versus time slot. The proposed SEBC-MUCB can meet the service reliability requirement and achieve the second least service reliability deficit. Although SBC-MUCB achieves the least service reliability deficit, its throughput and energy consumption performance are worse than SEBC-MUCB because only service reliability awareness is considered. The service reliability deficit of EBC-MUCB increases dramatically after t = 700 due to the negligence of service reliability awareness. UCB performs the worst since it has not been endowed with the capability of conflict resolution.</p>
        <p>From Fig. 3(a) to Fig. 4, we can find that although the energy consumption and the service reliability deficit of ACRA are nearly the same as those of SEBC-MUCB, the throughput performance and the data backlog performance are worse. SEBC-MUCB outperforms ACRA by 10.58% in terms of throughput, and 4783.76% in terms of data backlog due to the endowed capability of online learning. Particularly, the data backlog performance of ACRA is significantly degraded by employing the outdated CSI for optimization. Therefore, we can conclude that learning plays an important role for backlog reduction under the scenario where perfect GSI is unavailable. Fig. 5 shows the impact of parameter V k on the throughput performances of MTDs. Specifically, we set V 1 = V 2 = 1 for m 1 and m 2 , while V 3 increases from 10 -4 to 10 3 for m 3 . Simulation results demonstrate that as V 3 increases, the throughput of m 3 increases first and then decreases, while the throughput of m 1 shows the opposite trend. The rationale is that when V 3 increases from 10 -4 to 25 (log(V 3 ) increase from -4 to 1.4), m 3 puts a larger weight on the throughput, and becomes more active to explore channels for throughput improvement. This will cause more channel selection conflicts, thereby reducing the throughput of m 1 . However, when V 3 is too large (log(V 3 ) &gt; 1.4), m 3 over-evaluates throughput and has little concern on energy consumption. It will quickly run out of energy and is forced to remain idle, which significantly degrades the throughput performance. Meanwhile, other MTDs such as m 1 can benefit from the idle state of m 3 since the channel selection conflicts is relieved.</p>
        <p>In this paper, we proposed learning-based channel selection which incorporates service reliability awareness, energy awareness and backlog awareness. We started from single-MTD scenario and proposed distributed low-complexity SEB-GSI algorithm with CSI and SEB-UCB algorithm under information uncertainty. Then, we extended it to the multi-MTD scenario and developed SEBC-MUCB algorithm by integrating MAB, Lyapunov optimization and matching theory. Simulation results demonstrate that the proposed SEB-UCB can improve throughput by 30% and 36% compared with UCB and random selection. SEBC-MUCB outperforms UCB and random selection by 13.7% and 31.2% while stabilizing data backlog queue and satisfying energy consumption constraint as well as service reliability requirement. Due to the limited computational capability and battery capacity of MTDs, we only consider the scenario of task offloading, while local computing is ignored. Our future work will focus on the online cross-layer resource optimization including local computation, rate control, channel selection, and resource allocation in the edge server under information uncertainty. APPENDIX A PROOF OF THEOREM 1 Define q k (t), n k (t) and f k (t) as</p>
        <p>Taking ( 33) into ( 1) and ( 15), we can obtain</p>
        <p>Define the concatenated vector of the data backlog queue and virtual queues as</p>
        <p>Define the Lyapunov function and one-slot Lyapunov drift as</p>
        <p>Define the drift-minus-reward term as</p>
        <p>Taking (36) into (35), we can derive</p>
        <p>Based on (34), we have</p>
        <p>Taking (39) into (52)</p>
        <p>Define B k as</p>
        <p>Taking ( 40) and ( 41) into (37)</p>
        <p>Similarly as (36), T -slot Lyapunov drift can be defined as</p>
        <p>Therefore, the sum of DR 1 (G(t)) over T slots can be derived as</p>
        <p>The last term on the right-hand side of (48) satisfies</p>
        <p>Define q max , n max and f max as the maximum positive value for all MTDs to satisfy</p>
        <p>Based on (46), we can obtain</p>
        <p>47) into (45), we can bound the last term on the right-hand side of (48) as</p>
        <p>where B max = 1 2 (q 2 max + n 2 max + f 2 max ). We can see B max ≥ B k must be satisfied, (48) can thus be bounded as</p>
        <p>We denote x * k,j,t and z * k,j,t as the channel selection indicators and throughput performance obtained by employing exhaustive method with T -slot GSI. By applying SEB-MGSI into the left side and considering exhaustive method on the right-hand side, we obtain</p>
        <p>By dividing both sides of (50) by V k , we can derive that</p>
        <p>This completes the proof of Theorem 1.</p>
        <p>At each slot, either the optimal or the non-optimal subchannel will be selected. Denote the number of times that a non-optimal selection for m k , i.e., option j, has been selected up to the t-slot as χ k, j,t-1 . If option j is selected by m k in the t-th slot, then χ k, j,t = χ k, j,t-1 + 1. The learning regret R can be derived as</p>
        <p>Then, we recall the indicator function I{x} where I{x} = 1 if event x is true and I{x} = 0 otherwise. Besides, we make a crude approximation that the non-optimal selection are made at least m times. If a k, j,t = 1, we should have θ k, j,t ≥ θ k, j,t .</p>
        <p>(53)</p>
        <p>It indicates that the upper confidence bound of the selected option should be larger than that of the optimal option. Therefore, we have</p>
        <p>I{ θ k, j,t ≥ θ k, j,t , χ k, j,t-1 ≥ m},</p>
        <p>where the second item represents the crude approximation made above. We define the amount of times that option j has been selected by m k up to slot t as x k, j,t-1 . Denote B k, j,t as the confidence interval, which can be given as</p>
        <p>To write the inequality in a nicer form, we make a further approximation as follows, Similarly, the probability of the case (b) is also t -4K . By the union bound, the probability that one of the three cases happens is 2t -4K plus whatever the probability of case (c) being true. We can make case (c) always false by a wellchosen m. Note that θk,j and θk,j can be less than 1 through adjusting parameters. Case (c) can then be transformed as θk,jθk,j -1</p>
        <p>We can derive that when m &gt; 8(∆θ k, j, j ) 2 ln(t), case (c) is false.</p>
        <p>Since the expected value of an event is just its probability of occurrence, the expectation of ( 58) is E[χ k, j,T ] ≤ 8(∆θ k, j, j )</p>
        <p>2 ln(t) +</p>
        <p>This completes the proof of Theorem 2.</p>
        <p>From the concept of learning regret, we can derived -V k z k, j,t + α k Nk (t)E k, j,t + β k Fk (t)(η k -J j=1</p>
        <p>x k, j,t ) ≤ R k,t -V k z k, j,t + α k Nk (t)E k, j,t</p>
        <p>where R k,t represents the learning regret of m k in the t-th slot and it satisfies</p>
        <p>Then, we can get the following inequality must be satisfied x k, j,t ).</p>
        <p>(69)</p>
        <p>This completes the proof of Theorem 3.</p>
        <p>Based on (64), we can derive that after 8(∆θ k, j, j )</p>
        <p>2 ln(t)</p>
        <p>times of selecting a non-optimal option, the probability of selecting a non-optimal option at the t-th slot is upper bounded by 2t -4K . Specifically, as t → +∞, the upper bound converges to 0. This completes the proof of Theorem 7.</p>
        <p>+ B k, j,t-1 }, ∀m k ∈ M, j, j = 1, 2, • • • , J + 1. (56)</p>
        <p>Indeed, there will be at least one pair (x k, j,t-1 , x k, j,t-1 ) that can satisfy the inequality if (56) is satisfied. Therefore, we just need to count the number of such pairs which satisfy (56).</p>
        <p>+ B k, j,t-1 }, ∀m k ∈ M, j, j = 1, 2, • • • , J + (58) -B 2, j,t } × • • • × P{ 1 + Fk (t) θk, j,t-1 ≤ 1 + Fk (t) θk,j -B k, j,t }.</p>
        <p>This work was partially supported by the National Natural Science Foundation of China (NSFC) under Grant Number 61971189; the Science and Technology Project of State Grid Corporation of China under Grant Number SGSDDK00KJJS1900405; the Exploration Project of State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources (North China Electric Power University) under Grant Number LAPS2019-12; the European Regional Development Fund (FEDER), through the Competitiveness and Internationalization (COMPETE 2020), Regional Operational Program of the Agarve ( 2020), Fundao para a ciłncia e Tecnologia, i-Five: Extenso do acesso de espectro dinmico para rdio 5G, POCI-01-0145-FEDER-030500.</p>
    </text>
</tei>
