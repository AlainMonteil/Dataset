<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T11:23+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>In this paper, we propose enhancements to Beetle Antennae Search (BAS) algorithm, called BAS-ADAM, to smoothen the convergence behavior and avoid trapping in local-minima for a highly non-convex objective function. We achieve this by adaptively adjusting the step-size in each iteration using the Adaptive Moment Estimation (ADAM) update rule. The proposed algorithm also increases the convergence rate in a narrow valley. A key feature of the ADAM update rule is the ability to adjust the step-size for each dimension separately instead of using the same step-size. Since ADAM is traditionally used with gradient-based optimization algorithms, therefore we first propose a gradient estimation model without the need to differentiate the objective function. Resultantly, it demonstrates excellent performance and fast convergence rate in searching for the optimum of non-convex functions. The efficiency of the proposed algorithm was tested on three different benchmark problems, including the training of a high-dimensional neural network. The performance is compared with Particle Swarm Optimizer (PSO) and the original BAS algorithm.</p>
        <p>Optimization plays an integral part in the efficient operation of almost all real-world systems [1], [2]. Additionally, with the rise of machine learning in recent years, the development of numerically efficient and robust optimization algorithms has been a topic of great research interest [3]- [5]. Conventional optimization techniques use gradient-based methods to search for the optimum value [6]- [9]. Although these algorithms have proven to be quite stable [10], [11], however, they require the symbolic or numerical computation of the gradient direction. Most of the practical optimization problems are highly nonlinear with multimodal objective functions and non-convex constraints. Numerically evaluating the gradient for such function can be a computationally intensive task [12]. Additionally, the computation of gradient imposes several conditions about continuity and differentiability of the objective function [13]. Such conditions do not hold for the vast majority of the systems, e.g., integer programming [14]. In fact, for the vast majority of the optimization problem, specifically in the control system [15], an accurate model of the system might be unknown in advance and require real-time estimation of parameters [16], [17].</p>
        <p>The large majority of the gradient-based optimization is well-suited for computing systems with high computation power. However, their implementation on low-end embedded systems is challenging due to their limited computation power. To overcome such challenges, a new class of optimization algorithm called metaheuristic optimization has gained the attention of researchers [18]- [20]. These algorithms are mostly inspired by natural phenomena and do not require the computation of the gradient of the objective function. These algorithms have been shown in the literature to possess excellent convergence properties and high numerical efficiency. Even for problems in control systems where the model is unknown apriori [21], such algorithms have been employed for the parameter estimation, and tuning of controller gains [22]. One of the significant advantages offered by metaheuristic optimization is a relaxation on the conditions of continuity and differentiability. These algorithms can be effectively employed for solving discrete optimization problems. Additionally, because of their low complexity, they can be efficiently implemented on embedded systems with limited computational power. Given the advantages of metaheuristic algorithms, they have found their applications in several real-world systems [23]- [27].</p>
        <p>Almost all the metaheuristic optimization optimization algorithm proposed in literature [28]- [33] have found their inspiration in natural processes. Most of these algorithms have been inspired by the behavior of the animals, whereas others found their inspiration from the biological and chemical systems [34]. For example, biological evolution have given rise to a complete class of metaheuristic algorithm [35], [36] e.g. Genetic Algorithms (GAs) [37], [38]. Other commonly used metaheuristic algorithms inspired by the behavior of living organisms include Particle Swarm Optimization (PSO) [39], [40]. PSO was inspired by the swarming behavior commonly observed in birds and insects. Swarming behavior [41] has been of particular interest to researchers because it was observed that large groups of the birds and insects are able to coordinate by just following a set of straightforward rules. Although each member of the swarm is only aware of its limited surrounding environment, still their combined effort can solve a large-scale, complicated task. This behavior is termed as swarm intelligence [42], [43]. Swarm behavior can be considered as an optimization process in which a group of birds works together to maximize the survivability of the whole swarm. Swarm intelligence has inspired several other algorithms, e.g., Ant Colony Optimization (ACO) [44], which is based on the social behavior of ants. An ant colony can contain millions of ants, but their social behavior and swarm intelligence help them efficiently search for food, thus maximizing the productivity of the colony. Similarly, the Artificial Fish Swarm Algorithm [45] is based on the swarming behavior of fishes and other aquatic lives. Although several nature-inspired algorithm metaheuristic algorithms have been presented in literature, few of them are mentioned here:</p>
        <p>Food Source (Goal) (a)</p>
        <p>Food Source (Goal)</p>
        <p>BAS algorithm: Beetle Antennae Search (BAS) [46], [47], Cuckoo Search [48], [49], Invasive Weed Optimization (IWO) [50], Honey Bee Algorithm (HBA) [51], [52], and Firefly Algorithms (FAs) [53]. These metaheuristic algorithms have been shown to have good performance in real-world practical scenarios. However, their application in machine learning is still limited. The machine learning models are usually very large-scale, having a large number of parameters. The training of these models require searching very high-dimensional spaces, and conventional metaheuristic algorithm does not scale well to such high-dimensions [54].</p>
        <p>As already mentioned in the abstract, in this paper, we consider Beetle Antennae Search (BAS) algorithm [46], [47].</p>
        <p>Food foraging behavior observed in beetles inspired BAS. Beetle behavior is of particular research interest because unlike other insects, beetles usually do not work in a swarm and have the ability to search for food individually. Beetles can search for food using its antennae and sensitive sense of smell. Besides, the beetle antennae have several small fibers, and by sensing the difference of smell at each of the fiber, the beetle can develop a map of smell intensity of surrounding. This map helps in finding the direction of maximum smell change. Inspired by this concept, an estimation model can be developed, which helps in approximating the gradient direction. The estimation of an approximated gradient is a key feature of BAS, which distinguishes it from another metaheuristic algorithm. Since its introduction, BAS has found its application in several real-world systems [17], [55]- [64]. The working of the original BAS can be described like this; at each iteration, the value of the objective function is computed at each antennae fiber location, a vector is drawn from the fiber with the lowest value toward the fiber with the highest value, the vector represents the direction of the approximated gradient. The approximated gradient is then used to update the location of the beetle. The working of the original BAS is shown in Fig. 1(a).</p>
        <p>One of the key limitations of the BAS algorithm is the selection of a suitable value for initial step size and proper step size annealing. Careful tuning of these parameters is required to achieve a fast convergence rate and stable performance. The previous works on BAS [46], [47] use exponential decay and power-law annealing. However, these methods are not adaptive to the shape of the objective function, i.e., the step size change at the same rate. This behavior can results in slow convergence if the objective function has a narrow valley. From optimization literature, we know that for such objective functions, the gradient-based method, especially Stochastic Gradient Descent (SGD), shows poor performance since the estimated point can bounce back and forth between walls of the valley during iterations [65]. It increases the number of iteration required to reach the optimal point. To improve the convergence rate, several modifications to the SGD algorithm have been proposed in the literature, which adaptively adjusts the step size and direction. On such popular algorithm is Adaptive Moment Estimation (ADAM) [6]. The ADAM algorithm updates the value of step size based on all the past values of gradient and square of gradients. The idea of ADAM is borrowed from momentum SGD [65] but show more robustness and stability near-optimal points. For this reason, we choose the ADAM algorithm to adaptively update the step size during runtime instead of manually adjusting the parameters in the beginning. The working of the 
            <rs type="software">BAS-ADAM</rs> is shown in Fig. 1(b). It can be seen that it shows much faster convergence as compared to the original BAS.
        </p>
        <p>To demonstrate the fast convergence, efficiency, and effectiveness of the proposed BAS-ADAM algorithm, we performed several sets of experiments and compared its performance with other benchmark metaheuristic algorithm. In the literature on metaheuristic algorithms, the performance of algorithms is verified using low dimensional benchmark functions [51]. In this paper, we took the rigor of the testing process one step further and used the BAS-ADAM to train a hidden layer neural network with nonlinear activation functions. Additionally, we used two other benchmark optimization problems, which were similar to other works in metaheuristic literature. We solved these benchmark optimization problems using the PSO, a state of the art metaheuristic algorithm, original BAS, and BAS-ADAM. It is shown in results that the BAS-ADAM show superior performance as compared to original BAS and PSO in solving the benchmark optimization problems, including the training of neural networks.</p>
        <p>The rest of the paper is organized as follow; Section II present the details of the BAS-ADAM algorithm, Section III present the benchmark optimization problems we used in this paper, Section IV present the experimental results, and Section V concludes the paper.</p>
        <p>In this section, we will describe the technical details and mathematical formulation of the BAS-ADAM algorithm and outline its steps.</p>
        <p>Here we will describe the BAS algorithm [46] and present the gradient estimation model. Consider the optimization problem:</p>
        <p>where f (x) ∈ R 1 is the objective function and x ∈ R n is the domain of objective function. BAS algorithm treats f (x) as the smell intensity distribution in an n-dimensional space and tries to search for a point x * at which the value of smell intensity is maximum. The point x * corresponds to the position of the food source, and the objective of the beetle is to search this point. If the beetle is standing at point x t at time instant t, then to find the direction of the food source, the beetle measure the intensity of smell at each of its antennae fibers. For mathematical formulation, consider the beetle having a total of m antennae fibers. The location of each fiber is represented by a normally distributed normalized random position vector #» b relative to the beetle position x t . The set of m position vectors can be represented as</p>
        <p>Using the set B, the location of each antennae fiber can be written as</p>
        <p>where η t represents the length of the beetle antennae. The actual location of each antennae fibre can be written as a set X = {x b1 , x b2 , ..., x bm }.</p>
        <p>After creating the set X of the antennae fiber locations, we evaluate the objective function f at each of its points. Thus creating a set F of the objective values</p>
        <p>Now we will formulate the strategy to estimate the gradient direction using the element of setting X and F. Note that there is a one-to-one correspondence between the elements of X and F. Based on this correspondence, we first create a subset X l from the set X corresponding to the k(&lt; m) lowest value in set F. Similarly, we create a set X h corresponding to the k highest value in the set F. The value of k controls the robustness of the gradient estimation. In mathematical formulation, we create the following sets</p>
        <p>where notation min k and max k are used to represent k minimum and maximum value from the corresponding sets. Then we create the sets X l and X h using the values in sets F l and</p>
        <p>For a beetle analogy, X l and X h are sets of k antenna fiber locations, where the smell intensity is minimum and maximum, respectively. We calculate the centroid of sets X l and X h as</p>
        <p>The vectors x l ∈ R n and x h ∈ R n calculated in 5 corresponds to locations around antennae fibres at which the value of the objective function is minimum and maximum respectively. A vector starting from point x l to x h represents the direction of maximum value change, i.e., gradient direction. Therefore the estimated gradient direction can be denoted as</p>
        <p>where ∇ t represent the estimated gradient direction on time instant t. We will now use the estimated gradient direction to update the location of beetle from x t to x t+1 using ADAM update rule in next subsection.</p>
        <p>Based on the value of estimated gradient ∇ t , we can formulate an update rule as</p>
        <p>where δ t is the step size and proportional to the distance between x t and x t+1 . The step length δ t is a function of estimated gradient ∇ t and we defined it according to the ADAM update rule as</p>
        <p>where δ 0 is the initial step size, and its value is constant. mt and vt represent the first and second moment of the estimated gradient ∇ t and its value is calculated as follow,</p>
        <p>The factor of sign(f (x r ) -f (x l )) is multiplied to make sure that ∇ t always point toward the direction of increasing objective function value. (.) 2 functions represent a piecewise square operation of the elements of vector ∇ t . As noted in ADAM literature, the values of m t and v t are biased toward zero. The correction factor for this biasness can be applied as</p>
        <p>By putting the values of mt and vt in (8), we can calculate the value of δ t ( ∇ t ) and the value of x new . For further increasing the efficiency of the algorithm, the value of x t+1 is only updated if there is an improvement in the value of objective function, i.e., f (x t+1 ) &gt; f (x t ). For this we keep track of the best solution x best and corresponding objective function value f best = f (x best ). Therefore, the final update rule for the value of x t+1 can be written as</p>
        <p>The presented BAS-ADAM algorithm is given in Algorithm 1; it can be summarized as 1) Begin with an random starting point x 0 .</p>
        <p>2) Generate a set of m normalized random position vectors, B ⊂ R n . 3) Calculate the set for location of antennae fibres, X ⊂ R n . 4) Calculate the set of the objective function values F = {f (x b1 ), f (x b2 ), ..., f (x bm )}. 5) Calculate the sets F l and F h of k(&lt; m) lowest and highest values from set F using (3). 6) Calculate the set X l ⊂ X and X h ⊂ X according to the values in F l and F h . 7) Calculate the centroid x l and x h of the set X l and X h . 8) Calculate the value of estimated gradient ∇ t using (6). 9) Calculate the first and second moments of estimated gradient using (9). 10) Calculate the unbiased moments using (10). 11) Determine candidate for update point x new using (7).</p>
        <p>12) The value of x t+1 is only updated if there is improvement in objective function value at x new . 13) If t &lt; t max , where t max is maximum number of iterations, then go back to step 2.</p>
        <p>III. VALIDATION METHODOLOGY This section presents the validation methodology used to test the efficiency, convergence, and efficacy of the proposed BAS-ADAM algorithm. We selected a set of three benchmark problems. The first is to search for the optimum value of Michalewicz function [66]. The second is a linear regression optimization problem, and the 3rd problem involves training of a single hidden layer neural network.</p>
        <p>Michalewicz function [66] is a highly nonlinear, multimodal, non-convex function. This problem involves searching for the minima of the Michalewicz function. Since it is a multimodal function, there is a high chance that the Algorithm 1: BAS-ADAM Optimizer</p>
        <p>Input: An objective function f (x), where x ∈ R n , and values of parameters: x 0 , d 0 , η, γ, β 1 , β 2 , and t stop . Output: Optimal solution x * to the problem: max x f (x) and optimal value f (x * ).</p>
        <p>Generate a set of m random direction vectors,</p>
        <p>Calculate the set, X = {x b1 , x b2 , ..., x bm }, of the beetle antennae fibre location according to (2). Calculate the set, F = {f (x) : x ∈ X }, of objective function values at location in set X . Select k lowest and highest values from set F to create the set F l and F h using (3). Using F l and F h , create set X l and X h according to (4). Calculate the centroids x l and x h of the elements of set X l and X h using (5). Estimate the gradient direction, ∇ t , using (6). Calculate the first moment m t and second moments v t of the estimated gradient using (9). Correct the biasness in the calculated moments using (10). Calculate a condidate for update-value x new using (7).</p>
        <p>x best end t ← t + 1; end searching algorithm gets trap in local minima. Therefore it is heavily used in literature to test the performance of metaheuristic algorithms. Michalewicz function is defined as</p>
        <p>where d is the dimension of input x to the Michalewicz function, i.e., x ∈ R d . The value of m is directly proportional to the narrowness of the valleys for this function.</p>
        <p>For Michalewicz function, the objective function was fixed, and the optimum value is already known in the literature. However, our second problem involves solving a linear regression optimization problem in which the objective function is defined using randomly generated data points. Since linear regression is essentially the least-square optimization problem; therefore, the objective function is convex. The linear regression optimization problem can be defined like this: given a vector of n independent variables and one dependent variable ([x 1 , x 2 , ..., x n ], y), estimate the parameter {θ 0 , θ 1 , θ 2 , ..., θ n } which results in best fit to following equation. The criteria for the best fit is usually defined in the least square sense (14) where x 0 = 1 is used for ease of mathematical notation. The above equation can be simplified using matrix operations y = θ T x,</p>
        <p>If we are provided with a set of m datapoints for independent and dependent variables, i.e., {x 1 , x 2 , ...x m+1 } and {y 1 , y 2 , ...y m } respectively, we can define a vector of residual error values as</p>
        <p>based on this vector, we can define a cost function based on square-sum of the residual values as</p>
        <p>Therefore, linear regression can be written as the following optimization problem</p>
        <p>During experiments, we used n = 2, m = 300, i.e., 300 samples points. The randomly generated dataset is shown in Fig. 3. It can be seen from ( 1) that for n = 2, three parameters need to be estimated, i.e., θ = [θ 1 , θ 2 , θ 3 ] ∈ R 3 . In Section IV we will present the numerical results for this problem.</p>
        <p>As the third benchmark problem, we choose the training of a hidden layer neural network with nonlinear activation functions. Most of the metaheuristic algorithms show poor performance when it comes to the training of a machine learning model because these models are highly nonlinear and contain a large number of parameters. Without the information about the gradient direction, searching a high dimensional space becomes very challenging. Since our metaheuristic algorithm involves a rough estimation of the gradient direction, it is expected to show better performance for high dimensional search spaces. Additionally, we used the ADAM algorithm to adjust step size adaptively, therefore the proposed algorithm also does an excellent job in avoiding the local minimum.</p>
        <p>It is known from machine learning literature that hidden layer neural networks are excellent in end to end learning [67], i.e., they can model an unknown process by just observing the input-output data points. They can model an arbitrary nonlinear process without needing an apriori mathematical model. Therefore we used the point cloud of Fig. 3 same as linear regression. However, this time, instead of using a linear model of ( 14), we used a neural network. It is expected that the neural network will provide a better fit to the point cloud and therefore produce a lower value for the cost function. The architecture of the neural network we used in this paper has two inputs, ten hidden neurons, and one output. Now we will derive the objective function for this optimization problem. Let x ∈ R n and y ∈ R 1 be the input and output of the neural network, respectively. The feedforward equation of the neural network can be written as</p>
        <p>where o 1 ∈ R k is output of the hidden layer. φ(.) is an activation function, in our experiments we choose hyperbolic tangent sigmoid as the activation function, i.e., φ(.) = tansig(.). The matrices W 1 ∈ R n×k and W 2 ∈ R k×1 are trainable weights of the hidden layer and output layer respectively. Similarly, b 1 ∈ R k and b 2 ∈ R are the biases of hidden and output layer. These matrices can be written as follow</p>
        <p>(1) 13</p>
        <p>. . . w . . . w</p>
        <p>. Now let us consider a set of m samples of input and output data points. Similar to the approach we used in III-B, we can define the following cost function for training the neural network</p>
        <p>Using</p>
        <p>In our experiments we used a neural network with 10 hidden neurons, 2 inputs and 1 output. There are a total of 41 trainable parameters in such a neural network. In summary, the problem 3 have these final values for the optimization problem: n = 2, k = 10, φ(.) = tansig(.) and m = 300, i.e., 300 training samples. The results are presented in Section IV. IV. RESULTS &amp; DISCUSSION Now we will present and discuss the experimental results for the validation problems presented in Sections III-A, III-B and III-C. Additionally, we compared the performance of the proposed BAS-ADAM algorithm with the PSO and original BAS algorithm. For the PSO algorithm, we used its implementation provided by 
            <rs type="software">MATLAB</rs>'s global optimization toolbox [68], whereas for BAS-ADAM and original BAS, we wrote the 
            <rs type="software">code</rs> in 
            <rs type="software">MATLAB</rs>.
        </p>
        <p>For Michalewicz function, we used d = 2 and m = 10 in our experimentation. From literature [66] it is known that this function have a global minimum at x * ≈ [2.20, 1.57] and minimum value of the function is M(x * ) ≈ -1.8013.</p>
        <p>The performance of the BAS-ADAM, along with PSO and original BAS, is shown in Fig. 4. The Fig. 4(a) shows the decrease in value of residual error with increase in iterations.</p>
        <p>The second validation problem involves solving the linear regression optimization problem given in (15). It is a convex optimization problem with a single global optimum and no local optimum. We tuned the parameters for BAS and BAS-ADAM until we reached the best performance.</p>
        <p>The experimental results are shown in Fig. 5. The plot in Fig. 5(a) shows the decrease in value of error residual with iterations. The plot shows that BAS-ADAM shows the final rate of convergence, followed by PSO and original BAS. However, the final reached by original BAS, 16.6531 is much higher as compared to the values reached by 
            <rs type="software">BAS-ADAM</rs> and 
            <rs type="software">PSO</rs>. 
            <rs type="software">BAS-ADAM</rs> took about 33 iterations to reach near the optimum point, while PSO took around 43 iterations. These results again prove the faster rate of convergence and superior performance of the BAS-ADAM algorithm. Using the final estimated parameters from 
            <rs type="software">BAS-ADAM</rs>, we can plot a linear fit through the point cloud of Fig. 3. The fitted plane is shown in Fig. 5(b).
        </p>
        <p>Among the three validation problems, the training of a hidden layer neural network is the most challenging one. As mentioned in III-C, we used a neural network with ten hidden neurons to model the point cloud in Fig. 3. The topology of the neural network includes two inputs, one fully connected hidden layer with ten neurons and one output.</p>
        <p>Fig. 6 shows the experimental results for training the neural network using the three optimization algorithms. The plot of error residuals is shown in Fig. 6(a). According to the plot, the BAS-ADAM shows the best performance, followed by BAS and PSO. The BAS-ADAM is able to reach the objective function value of around 6.5, i.e., C(W * 1 , W * 2 , b * 1 , b * 2 ) ≈ 6.5. Whereas original BAS and PSO get stuck in a local minimum and reach a minimum value of around 16 and 80. It is also worth noting that although the problem of linear regression and neural network are modeling the same point cloud using linear regression and neural network, respectively. The reason for the poor performance of PSO and original BAS is the high dimensionality of the objective functions. The neural has a total of 41 trainable parameters. The huge search space decreases the efficiency of PSO, original BAS, and other similar metaheuristic optimization algorithms. Fig. 6(b) shows a nonlinear surface to model the point cloud of Fig. 3. The surface is drawn using the final estimated parameters for the BAS-ADAM algorithm.</p>
        <p>V. CONCLUSION In this paper, we presented a robust nature-inspired metaheuristic algorithm, called BAS-ADAM. The proposed algorithm is inspired by the BAS algorithm and improves its performance for the objective function, having very steep valleys. We achieve this by using the adaptive moment estimation (ADAM) technique widely applied in gradient-based optimization algorithms. The proposed algorithm estimated a gradient direction at each iteration using the antennae fibers of the beetle. The estimated gradient is then used as input to the ADAM algorithm, which computes its first and second moments. These moments are then used to adjust the step size for the next iterations. This technique offers a significant advantage as compared to original BAS because it automatically adapts the step size for each dimension according to the shape of the objective function. Therefore the BAS-ADAM shows much smoother convergence performance near the optimum points, as shown in the experiments. For original BAS, the step size is calculated using exponential decay rule and independent of the shape of the objective function. It is demonstrated through extensive experiments that the proposed algorithm offers fast and robust convergence as compared to other metaheuristic optimization algorithms. We selected three benchmark optimization problems to test the performance of the proposed algorithm. We repeated the same experiments with original BAS and PSO optimizers to present the comparative results. The experimental results show that, on average, BAS-ADAM takes fewer iterations and able to reach better optimum values as compared to original BAS and PSO. Additionally, we trained a hidden layer neural network, which shows the potential of the proposed algorithm in real-time machine learning applications.</p>
        <p>*</p>
    </text>
</tei>
