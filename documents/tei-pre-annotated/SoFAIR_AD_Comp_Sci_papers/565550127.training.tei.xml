<?xml version="1.0" encoding="UTF-8"?>
<tei xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc xml:id="_1"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-13T15:20+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text xml:lang="en">
        <p>or visit the DOI to the publisher's website.or visit the DOI to the publisher's website.</p>
        <p>• The final author version and the galley proof are versions of the publication after peer review.• The final author version and the galley proof are versions of the publication after peer review.</p>
        <p>• The final published version features the final layout of the paper including the volume, issue and page numbers.• The final published version features the final layout of the paper including the volume, issue and page numbers.</p>
        <p>Copyright and moral rights for the publications made accessible in the public portal are retained by the authors and/or other copyright owners and it is a condition of accessing publications that users recognise and abide by the legal requirements associated with these rights.Copyright and moral rights for the publications made accessible in the public portal are retained by the authors and/or other copyright owners and it is a condition of accessing publications that users recognise and abide by the legal requirements associated with these rights.</p>
        <p>• Users may download and print one copy of any publication from the public portal for the purpose of private study or research. • You may not further distribute the material or use it for any profit-making activity or commercial gain • You may freely distribute the URL identifying the publication in the public portal.• Users may download and print one copy of any publication from the public portal for the purpose of private study or research. • You may not further distribute the material or use it for any profit-making activity or commercial gain • You may freely distribute the URL identifying the publication in the public portal.</p>
        <p>If the publication is distributed under the terms of Article 25fa of the Dutch Copyright Act, indicated by the "Taverne" license above, please follow below link for the End UserIf the publication is distributed under the terms of Article 25fa of the Dutch Copyright Act, indicated by the "Taverne" license above, please follow below link for the End User</p>
        <p>perturbations. The multiple interactions encoded within networks can lead to network responses to perturbation that cannot be predicted from studying isolated nodes or pairs of nodes; these complex responses are referred to as emergent properties.perturbations. The multiple interactions encoded within networks can lead to network responses to perturbation that cannot be predicted from studying isolated nodes or pairs of nodes; these complex responses are referred to as emergent properties.</p>
        <p>A network graph with only one type of node is denoted a "unipartite graph." An example of a unipartite molecular graph is a co-expression network in which two genes are linked if their expression levels are highly correlated. The edges in such a graph have "edge weights" which represent the strength of the "interaction"; in this example, the correlation coefficient. If we have two types of nodes (say, squares and circles) and connections only between one type and the other, we can represent those connections using a "bipartite graph." An example would be a gene regulatory network in which we link transcription factors to the genes that they regulate. In expression quantitative trait locus (eQTL) networks (in which one type of node represents a single nucleotide polymorphism [SNP] and another type of node represents the expression level of a gene), the network does not represent physical interactions but rather statistical associations between the SNP dose and gene expression level.A network graph with only one type of node is denoted a "unipartite graph." An example of a unipartite molecular graph is a co-expression network in which two genes are linked if their expression levels are highly correlated. The edges in such a graph have "edge weights" which represent the strength of the "interaction"; in this example, the correlation coefficient. If we have two types of nodes (say, squares and circles) and connections only between one type and the other, we can represent those connections using a "bipartite graph." An example would be a gene regulatory network in which we link transcription factors to the genes that they regulate. In expression quantitative trait locus (eQTL) networks (in which one type of node represents a single nucleotide polymorphism [SNP] and another type of node represents the expression level of a gene), the network does not represent physical interactions but rather statistical associations between the SNP dose and gene expression level.</p>
        <p>For both unipartite and bipartite graphs, the edges are key components. Because the edges are so important, we often represent a network as a collection of edges, which can be summarized using an "adjacency matrix"; a matrix that depicts connections between the nodes in a graph (Figure 1b). The advantage of using such a representation is that it facilitates mathematical analysis of the network and its properties.For both unipartite and bipartite graphs, the edges are key components. Because the edges are so important, we often represent a network as a collection of edges, which can be summarized using an "adjacency matrix"; a matrix that depicts connections between the nodes in a graph (Figure 1b). The advantage of using such a representation is that it facilitates mathematical analysis of the network and its properties.</p>
        <p>When network science approaches are applied to the analysis of disease, the term "Network Medicine" has been used (Barabasi, 2007;Barabasi, Gulbahce, &amp; Loscalzo, 2011;Loscalzo, Barabasi, &amp; Silverman, 2017). In many applications, Network Medicine seeks to use cellular molecular pathways to explore the etiologies of human diseases. However, since many molecular pathways remain poorly defined, Network Medicine relies on inference or interaction networks between elements within human cells, and then uses the resulting networks to explore drivers of disease.When network science approaches are applied to the analysis of disease, the term "Network Medicine" has been used (Barabasi, 2007;Barabasi, Gulbahce, &amp; Loscalzo, 2011;Loscalzo, Barabasi, &amp; Silverman, 2017). In many applications, Network Medicine seeks to use cellular molecular pathways to explore the etiologies of human diseases. However, since many molecular pathways remain poorly defined, Network Medicine relies on inference or interaction networks between elements within human cells, and then uses the resulting networks to explore drivers of disease.</p>
        <p>A variety of different methods has been used to infer relevant cellular molecular networks. Protein-protein interaction networks, often referred to as the interactome (Vidal, Cusick, &amp; Barabasi, 2011), have been used to identify interconnected subsets of interacting proteins related to specific diseases, known as disease network modules. Methods such as weighted gene coexpression network analysis (Langfelder &amp; Horvath, 2008) use pairwise correlation in gene expression levels to identify modules of similarly expressed genes in distinct phenotypic states. Still, other methods integrate multiple different data types to infer regulatory interactions between transcription factors and their targets (Glass, Huttenhower, Quackenbush, &amp; Yuan, 2013;Sonawane et al., 2017). These modeling approaches based on Big Data can be thought of as "top-down" efforts to identify genes of interest agnostically in disease-related networks. However, "bottom-up" approaches to build disease networks by identifying the biological relationships and network connections for well-established susceptibility genes can also be used to create disease-related molecular networks.A variety of different methods has been used to infer relevant cellular molecular networks. Protein-protein interaction networks, often referred to as the interactome (Vidal, Cusick, &amp; Barabasi, 2011), have been used to identify interconnected subsets of interacting proteins related to specific diseases, known as disease network modules. Methods such as weighted gene coexpression network analysis (Langfelder &amp; Horvath, 2008) use pairwise correlation in gene expression levels to identify modules of similarly expressed genes in distinct phenotypic states. Still, other methods integrate multiple different data types to infer regulatory interactions between transcription factors and their targets (Glass, Huttenhower, Quackenbush, &amp; Yuan, 2013;Sonawane et al., 2017). These modeling approaches based on Big Data can be thought of as "top-down" efforts to identify genes of interest agnostically in disease-related networks. However, "bottom-up" approaches to build disease networks by identifying the biological relationships and network connections for well-established susceptibility genes can also be used to create disease-related molecular networks.</p>
        <p>Network Medicine applies these integrated approaches to state-of-the-art Omics data and computational biology tools and, thereby, has the potential to provide improvements in the diagnosis, prognosis, and treatment of complex diseases. We anticipate that improvements in disease diagnosis will have the most immediate impact on clinical medicine. However, substantial advancements in the analysis, interpretation, and validation of Network Medicine approaches will be required to turn this potential to transform medical care into reality.Network Medicine applies these integrated approaches to state-of-the-art Omics data and computational biology tools and, thereby, has the potential to provide improvements in the diagnosis, prognosis, and treatment of complex diseases. We anticipate that improvements in disease diagnosis will have the most immediate impact on clinical medicine. However, substantial advancements in the analysis, interpretation, and validation of Network Medicine approaches will be required to turn this potential to transform medical care into reality.</p>
        <p>In this review, we discuss the types of molecular data that are used in molecular network analyses, survey the analytical methods for inferring molecular networks, and review efforts to validate molecular networks. We will review several successful applications of molecular network analysis. Finally, we will consider knowledge gaps and future directions for this developing field.In this review, we discuss the types of molecular data that are used in molecular network analyses, survey the analytical methods for inferring molecular networks, and review efforts to validate molecular networks. We will review several successful applications of molecular network analysis. Finally, we will consider knowledge gaps and future directions for this developing field.</p>
        <p>Although computational biologists often do not have extensive training in molecular and cell biology, understanding the impact of sample collection and storage protocols on the Omics data utilized for building molecular networks is F I G U R E 1 (a) A bipartite graph, in this case showing eQTL associations. (b) A unipartite graph and its corresponding adjacency matrix essential. Different Omics data types are differentially affected by sample source, sample collection, subject characteristics, and sample storage. Obtaining DNA for assessments of genetic variation is robust to most of these variables, but other Omics data types (e.g., transcriptomics, metabolomics, proteomics, and epigenetics) can be profoundly altered. The most readily available sample source is peripheral blood; however, the relevance of blood Omics data for diseases based in other organ systems is variable. Whole tissue samples (e.g., lung, heart) can provide greater disease relevance, but the cellular alterations related to disease pathology need to be considered. Individual cell types provide more specific Omics data but are more difficult to obtain. Subject characteristics of relevance for Omics data include whether the sample donors were acutely ill or in a stable state. For example, mechanical ventilation of many GTEx donors had a substantial impact on lung gene expression (McCall, Illei, &amp; Halushka, 2016). For metabolomics, obtaining blood samples in the fasting state is preferred, although many metabolites can be assessed in nonfasting samples (Townsend et al., 2013). Key issues related to sample processing include the time from sample collection to freezer storage. Anticoagulant selection affects proteomic studies in blood samples (Lan et al., 2018), while collecting samples in DMSO can alter DNA methylation. Increasing numbers of freeze-thaw cycles are problematic for many Omics data types. The temperature of freezer storage (the colder, the better) can also influence sample quality and Omics results.Although computational biologists often do not have extensive training in molecular and cell biology, understanding the impact of sample collection and storage protocols on the Omics data utilized for building molecular networks is F I G U R E 1 (a) A bipartite graph, in this case showing eQTL associations. (b) A unipartite graph and its corresponding adjacency matrix essential. Different Omics data types are differentially affected by sample source, sample collection, subject characteristics, and sample storage. Obtaining DNA for assessments of genetic variation is robust to most of these variables, but other Omics data types (e.g., transcriptomics, metabolomics, proteomics, and epigenetics) can be profoundly altered. The most readily available sample source is peripheral blood; however, the relevance of blood Omics data for diseases based in other organ systems is variable. Whole tissue samples (e.g., lung, heart) can provide greater disease relevance, but the cellular alterations related to disease pathology need to be considered. Individual cell types provide more specific Omics data but are more difficult to obtain. Subject characteristics of relevance for Omics data include whether the sample donors were acutely ill or in a stable state. For example, mechanical ventilation of many GTEx donors had a substantial impact on lung gene expression (McCall, Illei, &amp; Halushka, 2016). For metabolomics, obtaining blood samples in the fasting state is preferred, although many metabolites can be assessed in nonfasting samples (Townsend et al., 2013). Key issues related to sample processing include the time from sample collection to freezer storage. Anticoagulant selection affects proteomic studies in blood samples (Lan et al., 2018), while collecting samples in DMSO can alter DNA methylation. Increasing numbers of freeze-thaw cycles are problematic for many Omics data types. The temperature of freezer storage (the colder, the better) can also influence sample quality and Omics results.</p>
        <p>Generating Omics data from appropriate biospecimens has become commoditized for genetic variation assessment, using either SNP genotyping panels or DNA sequencing (whole exome or whole genome). Metabolomics assessments can be performed with targeted panels; untargeted assays can also be performed, but identification of those analytes can be quite challenging (Gika, Virgiliou, Theodoridis, Plumb, &amp; Wilson, 2019). Epigenomic data are obtained using profiling techniques analyzing both DNA methylation and histone modifications. DNA methylation marks can be measured with predefined panels or based on DNA sequencing before and after bisulfite conversion of methylated cytosines. Chromatin accessibility and histone modifications can be assessed with a plethora of different Omics-driven approaches such as Nome-Seq, ATAC-Seq, and ChIP-Seq, which map nucleosomes and nonhistone proteins and detect DNA-associated proteins and histone modifications at the genome-wide level. Transcriptomics has largely moved from microarray analysis to RNA-Seq. Proteomics can be performed with predefined panels of analytes (e.g., Olink, SomaLogic) or with shotgun mass spectrometry. Each of these platforms has specific challenges that require domain expertise for appropriate interpretation. For example, DNA methylation panels are affected by SNPs located under assay probes (W. Zhou, Laird, &amp; Shen, 2017), and analytes in protein panels like SomaLogic can be affected by nonspecific binding (Joshi &amp; Mayr, 2018).Generating Omics data from appropriate biospecimens has become commoditized for genetic variation assessment, using either SNP genotyping panels or DNA sequencing (whole exome or whole genome). Metabolomics assessments can be performed with targeted panels; untargeted assays can also be performed, but identification of those analytes can be quite challenging (Gika, Virgiliou, Theodoridis, Plumb, &amp; Wilson, 2019). Epigenomic data are obtained using profiling techniques analyzing both DNA methylation and histone modifications. DNA methylation marks can be measured with predefined panels or based on DNA sequencing before and after bisulfite conversion of methylated cytosines. Chromatin accessibility and histone modifications can be assessed with a plethora of different Omics-driven approaches such as Nome-Seq, ATAC-Seq, and ChIP-Seq, which map nucleosomes and nonhistone proteins and detect DNA-associated proteins and histone modifications at the genome-wide level. Transcriptomics has largely moved from microarray analysis to RNA-Seq. Proteomics can be performed with predefined panels of analytes (e.g., Olink, SomaLogic) or with shotgun mass spectrometry. Each of these platforms has specific challenges that require domain expertise for appropriate interpretation. For example, DNA methylation panels are affected by SNPs located under assay probes (W. Zhou, Laird, &amp; Shen, 2017), and analytes in protein panels like SomaLogic can be affected by nonspecific binding (Joshi &amp; Mayr, 2018).</p>
        <p>The many challenges and sources of variability related to Omics data collection directly impact data analysis and interpretation of molecular networks built from those data sets. Even when every effort is made during data collection and generation, data will be affected by technical noise that can substantially (or even critically) impact the identification of biological signals.The many challenges and sources of variability related to Omics data collection directly impact data analysis and interpretation of molecular networks built from those data sets. Even when every effort is made during data collection and generation, data will be affected by technical noise that can substantially (or even critically) impact the identification of biological signals.</p>
        <p>Some of the most important sources of technical noise are batch effects, which introduce systematic technical variability in the data (W. W. B. Goh, Wang, &amp; Wong, 2017). Batch effects can result in both the absence of significant results when genuine biological differences exist (false negatives) and the presence of false positive results that solely stem from technical variation. Well-known batch effects include day of sample processing and/or data generation, reagent batches, and operators. The worst-case batch effects are confounding effects, that is, when the batch effect is completely confounded with the biological factor of interest. Examples of confounding batch effects are when all control and disease subject samples are processed on two different days or by two different operators, or when all male and female samples are processed separately in their respective batches. While it is possible to identify and correct for nonconfounding batch effects in data or explicitly to account for this source of variability in statistical tests as explicit covariates, they are best handled by careful experimental design using blocking, that is, assigning samples to different experimental batches in a balanced way. Exploratory data analysis and visualization approaches (such as hierarchical clustering or principal component analysis) can be effective to identify batch effects. In the absence of apparent visual clues, known genes that are susceptible to batch effects can also be used (Leek et al., 2010). Correction of batch effects can be effective in well-balanced study designs (i.e., when biological groups are evenly represented across batches) by using standard normalization (see below) followed by batch correction such as the popular ComBat method (Johnson, Li, &amp; Rabinovic, 2007), that relies on Bayesian inference to estimate the batch effects. Surrogate variable analysis (SVA; Leek &amp; Storey, 2007) uses factors defining the expected biological classes to estimate and correct for sources of variation that are not associated with the biological factor. Removed unwanted variation (RUV; Gagnon-Bartsch &amp; Speed, 2012) relies on invariant features, that is, features expected to remain unaffected by the biological factor of interest, to estimate and correct for unwanted batch effects. The application of batch correction methods does, of course, not guarantee that the undesired variation will be addressed. It is essential to check the corrected data and results to verify that these are not still influenced by the batch effects. Batch effects are particularly difficult to account for in clinical studies when the size of the cohort increases and collections span over a long duration, and when the phenotypes of the incoming patients are random (thus impeaching any design planning until the very end of the collection, leading to long and varying times from sample collection to processing). In addition to batch correction, it is essential to ensure comparability across samples by removing as much of the technical, unwanted variability and leaving relevant, biological variability untouched, a procedure called normalization. At times, simple methods such as centering (shifting each sample distribution toward a common value) and scaling (normalizing the range of the measurements across samples), can suffice. Generally, especially when handling Omics data, techniques that consider all data together and more profoundly affect the data need to be considered (e.g., quantile (Hicks et al., 2018) and variance stabilization normalizations (Anders &amp; Huber, 2010;Huber, von Heydebreck, Sueltmann, Poustka, &amp; Vingron, 2003)). In Figure 2, we show in a tractable example of how the lack of data normalization (for instance, centering and scaling) can substantially alter the resulting network. We analyzed the expression profiles of five genes (two of which, Genes 3 and 4, are co-expressed, panel a) across four samples using co-expression networks. The example demonstrates that using absolute gene expression values (heatmap b and network c) misleadingly groups Genes 3 and 5, and how centering and scaling the gene expression data (heatmap d and network e) can recover the anticipated clustering of Genes 3 and 4. These results are comparable to the positive control that uses correlation values between genes to construct heatmap f and network g.Some of the most important sources of technical noise are batch effects, which introduce systematic technical variability in the data (W. W. B. Goh, Wang, &amp; Wong, 2017). Batch effects can result in both the absence of significant results when genuine biological differences exist (false negatives) and the presence of false positive results that solely stem from technical variation. Well-known batch effects include day of sample processing and/or data generation, reagent batches, and operators. The worst-case batch effects are confounding effects, that is, when the batch effect is completely confounded with the biological factor of interest. Examples of confounding batch effects are when all control and disease subject samples are processed on two different days or by two different operators, or when all male and female samples are processed separately in their respective batches. While it is possible to identify and correct for nonconfounding batch effects in data or explicitly to account for this source of variability in statistical tests as explicit covariates, they are best handled by careful experimental design using blocking, that is, assigning samples to different experimental batches in a balanced way. Exploratory data analysis and visualization approaches (such as hierarchical clustering or principal component analysis) can be effective to identify batch effects. In the absence of apparent visual clues, known genes that are susceptible to batch effects can also be used (Leek et al., 2010). Correction of batch effects can be effective in well-balanced study designs (i.e., when biological groups are evenly represented across batches) by using standard normalization (see below) followed by batch correction such as the popular ComBat method (Johnson, Li, &amp; Rabinovic, 2007), that relies on Bayesian inference to estimate the batch effects. Surrogate variable analysis (SVA; Leek &amp; Storey, 2007) uses factors defining the expected biological classes to estimate and correct for sources of variation that are not associated with the biological factor. Removed unwanted variation (RUV; Gagnon-Bartsch &amp; Speed, 2012) relies on invariant features, that is, features expected to remain unaffected by the biological factor of interest, to estimate and correct for unwanted batch effects. The application of batch correction methods does, of course, not guarantee that the undesired variation will be addressed. It is essential to check the corrected data and results to verify that these are not still influenced by the batch effects. Batch effects are particularly difficult to account for in clinical studies when the size of the cohort increases and collections span over a long duration, and when the phenotypes of the incoming patients are random (thus impeaching any design planning until the very end of the collection, leading to long and varying times from sample collection to processing). In addition to batch correction, it is essential to ensure comparability across samples by removing as much of the technical, unwanted variability and leaving relevant, biological variability untouched, a procedure called normalization. At times, simple methods such as centering (shifting each sample distribution toward a common value) and scaling (normalizing the range of the measurements across samples), can suffice. Generally, especially when handling Omics data, techniques that consider all data together and more profoundly affect the data need to be considered (e.g., quantile (Hicks et al., 2018) and variance stabilization normalizations (Anders &amp; Huber, 2010;Huber, von Heydebreck, Sueltmann, Poustka, &amp; Vingron, 2003)). In Figure 2, we show in a tractable example of how the lack of data normalization (for instance, centering and scaling) can substantially alter the resulting network. We analyzed the expression profiles of five genes (two of which, Genes 3 and 4, are co-expressed, panel a) across four samples using co-expression networks. The example demonstrates that using absolute gene expression values (heatmap b and network c) misleadingly groups Genes 3 and 5, and how centering and scaling the gene expression data (heatmap d and network e) can recover the anticipated clustering of Genes 3 and 4. These results are comparable to the positive control that uses correlation values between genes to construct heatmap f and network g.</p>
        <p>Depending on the Omics technology at hand, a substantial proportion of data points can be missing. Missing data can be a particularly acute issue for mass spectrometry-based proteomics and metabolomics assays, where both the high number and the different types of missingness (technical/random and biological/nonrandom) can dramatically influence how to process the data and the outcomes of an analysis (Lazar, Gatto, Ferro, Bruley, &amp; Burger, 2016). Missing data can be ignored or statistical imputation approaches can be used to estimate them, but both approaches can lead to biased analytical results.Depending on the Omics technology at hand, a substantial proportion of data points can be missing. Missing data can be a particularly acute issue for mass spectrometry-based proteomics and metabolomics assays, where both the high number and the different types of missingness (technical/random and biological/nonrandom) can dramatically influence how to process the data and the outcomes of an analysis (Lazar, Gatto, Ferro, Bruley, &amp; Burger, 2016). Missing data can be ignored or statistical imputation approaches can be used to estimate them, but both approaches can lead to biased analytical results.</p>
        <p>In every step of a data analysis procedure, it is advisable to identify outliers (Bittremieux, Meysman, Martens, Valkenborg, &amp; Laukens, 2016;Kauffmann &amp; Huber, 2010;Norton, Vaquero-Garcia, Lahens, Grant, &amp; Barash, 2018;Stanfill et al., 2018), including samples or features with an abnormal number of missing values, samples that display substantially different distributions in their quantitative features, or samples that do not cluster with the rest of their group. Such cases need to be handled carefully; if the outlying nature of a sample cannot be corrected (through appropriate missing data imputation and data normalization, or after correction of mis-annotated samples), the offending sample might be better removed completely for the subsequent data analysis.In every step of a data analysis procedure, it is advisable to identify outliers (Bittremieux, Meysman, Martens, Valkenborg, &amp; Laukens, 2016;Kauffmann &amp; Huber, 2010;Norton, Vaquero-Garcia, Lahens, Grant, &amp; Barash, 2018;Stanfill et al., 2018), including samples or features with an abnormal number of missing values, samples that display substantially different distributions in their quantitative features, or samples that do not cluster with the rest of their group. Such cases need to be handled carefully; if the outlying nature of a sample cannot be corrected (through appropriate missing data imputation and data normalization, or after correction of mis-annotated samples), the offending sample might be better removed completely for the subsequent data analysis.</p>
        <p>Finally, it is important to highlight that the above steps also hold true when reusing publicly available data (when performing a meta-analysis combining several data sets, for example) or other resources providing large-scale genomic information (e.g., accessing protein-protein interaction from the STRING database; Szklarczyk et al., 2015). The question that one needs to answer when cleaning and preprocessing Omics data, is whether the data as they stand (raw or possibly heavily processed) are adequate to address the specific scientific question at hand.Finally, it is important to highlight that the above steps also hold true when reusing publicly available data (when performing a meta-analysis combining several data sets, for example) or other resources providing large-scale genomic information (e.g., accessing protein-protein interaction from the STRING database; Szklarczyk et al., 2015). The question that one needs to answer when cleaning and preprocessing Omics data, is whether the data as they stand (raw or possibly heavily processed) are adequate to address the specific scientific question at hand.</p>
        <p>Many different analytical approaches have been developed for molecular networks. Rather than providing an exhaustive list of such methods, we focus on describing several major classes of molecular network models, including protein-protein interaction networks, gene regulatory networks, correlation networks, Bayesian networks, RNA-RNA networks, and epigenomic networks, emphasizing the strengths and limitations of available analytical approaches.Many different analytical approaches have been developed for molecular networks. Rather than providing an exhaustive list of such methods, we focus on describing several major classes of molecular network models, including protein-protein interaction networks, gene regulatory networks, correlation networks, Bayesian networks, RNA-RNA networks, and epigenomic networks, emphasizing the strengths and limitations of available analytical approaches.</p>
        <p>Specific physical contacts of two or more proteins as a result of biochemical processes are called protein-protein interactions (PPIs). They are steered by noncovalent forces and often occur in a cell-type-specific, condition-specific, and organism-specific manner. Manifold wet laboratory technologies exist for their identification, such as affinity purification, Y2H (yeast two-hybrid), or TAP (tandem affinity purification; Rao, Srinivas, Sujini, &amp; Kumar, 2014). Through PPIs, differential protein complex formation and signal flow through the network can be studied in response to changing internal and external conditions or stimuli. PPI networks are often referred to as the "interactome," and huge databases have emerged over the last decade of systems biology that store and annotate them for subsequent interrogation using computational tools. Two examples: (a) The Integrated Interactions Database (IID) stores over 4.8 million PPIs annotated for tissue-specificity, subcellular localization, disease associations, and druggability (Kotlyar, Pastrello, The STRING database stores over 2 billion PPIs for 5,090 organisms and 24.6 million proteins (Szklarczyk et al., 2015). The STRING database also includes predicted interactions based, for example, on homology or text mining, and functional associations in addition to physical ones. PPI networks can be modeled as matrices or as undirected graphs where vertices correspond to proteins and edges to (physical or functional) interactions which can be weighted (usually with confidence scores or p values). Many approaches for clustering and crossspecies or cross-condition comparisons of such networks have been developed (cf. Bader &amp; Hogue, 2003;Malek, Ibragimov, Albrecht, &amp; Baumbach, 2016). Invaluable in a systems and Network Medicine context have proven so-called network enrichment methods, which usually aim at co-clustering an expression data set gathered for a set of patients suffering from a certain disease compared to a control group having a differential clinical outcome. Here, the aim is to identify subnetworks enriched with genes or proteins that are significantly altered in their behavior (e.g., differentially expressed, methylated, or mutated). Such subnetworks are candidate disease mechanisms and may be used as mechanistic markers for endophenotyping (Zanin et al., 2019). Many such network enrichment tools have been developed over the last decade and are now applied to the identification of disease mechanisms. Examples include DEGAS (Ulitsky, Krishnamurthy, Karp, &amp; Shamir, 2010), KeyPathwayMiner (List et al., 2016), HOTNET (Vandin, Clay, Upfal, &amp; Raphael, 2012), or GrandForest (Figures 3 and4). All such network module detection approaches come with different advantages and disadvantages that depend on biomedical assumptions regarding the underlying disease mechanisms and the available Omics data types (Batra et al., 2017;Nikolayeva, Guitart Pla, &amp; Schwikowski, 2018). Currently, available PPI networks are usually studied in the context of gene expression or genetic variation data. Few approaches exist for the analysis of alternative splicing in the context of PPIs (Emig et al., 2010), as this would require structural knowledge about the PPIs to identify spliced exons and corresponding protein domain variations. Such information is, however, only available for comparably small numbers (&lt;10,000) of PPIs, for example, in Instruct (Meyer, Das, Wang, &amp; Yu, 2013). Static PPI networks often do not allow for inferring causality, as they are undirected and have no annotation regarding activation or repression; this is in contrast to dynamic responses of PPIs to perturbation or to gene regulatory networks, which can be interrogated regarding their power to explain the emergence of different phenotypes on an expression level (S. J. Larsen, Rottger, Schmidt, &amp; Baumbach, 2019).Specific physical contacts of two or more proteins as a result of biochemical processes are called protein-protein interactions (PPIs). They are steered by noncovalent forces and often occur in a cell-type-specific, condition-specific, and organism-specific manner. Manifold wet laboratory technologies exist for their identification, such as affinity purification, Y2H (yeast two-hybrid), or TAP (tandem affinity purification; Rao, Srinivas, Sujini, &amp; Kumar, 2014). Through PPIs, differential protein complex formation and signal flow through the network can be studied in response to changing internal and external conditions or stimuli. PPI networks are often referred to as the "interactome," and huge databases have emerged over the last decade of systems biology that store and annotate them for subsequent interrogation using computational tools. Two examples: (a) The Integrated Interactions Database (IID) stores over 4.8 million PPIs annotated for tissue-specificity, subcellular localization, disease associations, and druggability (Kotlyar, Pastrello, The STRING database stores over 2 billion PPIs for 5,090 organisms and 24.6 million proteins (Szklarczyk et al., 2015). The STRING database also includes predicted interactions based, for example, on homology or text mining, and functional associations in addition to physical ones. PPI networks can be modeled as matrices or as undirected graphs where vertices correspond to proteins and edges to (physical or functional) interactions which can be weighted (usually with confidence scores or p values). Many approaches for clustering and crossspecies or cross-condition comparisons of such networks have been developed (cf. Bader &amp; Hogue, 2003;Malek, Ibragimov, Albrecht, &amp; Baumbach, 2016). Invaluable in a systems and Network Medicine context have proven so-called network enrichment methods, which usually aim at co-clustering an expression data set gathered for a set of patients suffering from a certain disease compared to a control group having a differential clinical outcome. Here, the aim is to identify subnetworks enriched with genes or proteins that are significantly altered in their behavior (e.g., differentially expressed, methylated, or mutated). Such subnetworks are candidate disease mechanisms and may be used as mechanistic markers for endophenotyping (Zanin et al., 2019). Many such network enrichment tools have been developed over the last decade and are now applied to the identification of disease mechanisms. Examples include DEGAS (Ulitsky, Krishnamurthy, Karp, &amp; Shamir, 2010), KeyPathwayMiner (List et al., 2016), HOTNET (Vandin, Clay, Upfal, &amp; Raphael, 2012), or GrandForest (Figures 3 and4). All such network module detection approaches come with different advantages and disadvantages that depend on biomedical assumptions regarding the underlying disease mechanisms and the available Omics data types (Batra et al., 2017;Nikolayeva, Guitart Pla, &amp; Schwikowski, 2018). Currently, available PPI networks are usually studied in the context of gene expression or genetic variation data. Few approaches exist for the analysis of alternative splicing in the context of PPIs (Emig et al., 2010), as this would require structural knowledge about the PPIs to identify spliced exons and corresponding protein domain variations. Such information is, however, only available for comparably small numbers (&lt;10,000) of PPIs, for example, in Instruct (Meyer, Das, Wang, &amp; Yu, 2013). Static PPI networks often do not allow for inferring causality, as they are undirected and have no annotation regarding activation or repression; this is in contrast to dynamic responses of PPIs to perturbation or to gene regulatory networks, which can be interrogated regarding their power to explain the emergence of different phenotypes on an expression level (S. J. Larsen, Rottger, Schmidt, &amp; Baumbach, 2019).</p>
        <p>Based on the hypothesis that proteins relevant for a particular disease will be localized (rather than randomly scattered) throughout the molecular interactome, multiple approaches have been developed to identify disease networkBased on the hypothesis that proteins relevant for a particular disease will be localized (rather than randomly scattered) throughout the molecular interactome, multiple approaches have been developed to identify disease network</p>
        <p>The main principle of PPI network enrichment for mechanistic biomarker extraction, supervised (left), and de novo/ unsupervised (right). In a supervised setting, one is interested in finding a set of proteins/genes that explain the difference between two or more classes (e.g., disease subtypes) by the alteration of a set of genes or proteins that form a subnetwork of the interactome. The labels do not necessarily need to be discrete but can be continuous observations or outcomes such as disease progression, growth responses, growth rate, treatment effects, or survival. In an unsupervised setting, no labels are given but the existence of subtypes (called endophenotypes) is assumed, which is characterized by given Omics data. This image is a screenshot from the 
            <rs type="software">GrandForest</rs> webtool (S.J. Larsen, Schmidt, &amp; Baumbach, 2020), which identifies disease classes and sub-types (de novo) while, conjointly, explaining this stratification with differential sub-network expression. The sub-networks then are enriched with mechanistic candidate biomarkers modules within the PPI network (L. Y. Lee &amp; Loscalzo, 2019). Seed genes can be selected based on genome-wide association studies (GWAS) or other reductionist experimental evidence to guide disease module identification using random walk or other approaches to interrogate the interactome (Erten, Bebek, Ewing, &amp; Koyuturk, 2011;Navlakha &amp; Kingsford, 2010). Alternatively, all of the genetic association evidence in a GWAS can be used to prioritize disease network modules (Ghiassian, Menche, &amp; Barabasi, 2015;Jia, Zheng, Long, Zheng, &amp; Zhao, 2011;Petti, Bizzarri, Verrienti, Falcone, &amp; Farina, 2019).
        </p>
        <p>Gene regulation involves the complex interplay of multiple biological molecules. The transcriptional process starts with the coordinated activity of multiple regulatory proteins, known as transcription factors (TFs), which bind to specific control regions in the DNA and then work together to recruit RNA polymerase (RNAP; Lambert et al., 2018). After recruitment, RNAP transcribes a gene, producing mRNA, which is then translated into protein. Additional factors, such as microRNAs and other epigenetic modifiers, are also involved in this process and can influence the amount of mRNA transcribed and the amount of protein translated (T. I. Lee &amp; Young, 2013). Gene regulatory networks model transcriptional processes by connecting regulators (such as TFs) to the genes encoding the downstream products of transcription and/or translation (mRNA and/or proteins, respectively; Sonawane et al., 2017). Importantly, a subset of the target genes in these networks encode TFs, creating a complex set of interactions that can be studied to understand the processes that control how a cell responds to environmental factors and to determine how the mechanisms controlling gene transcription are altered in the context of disease (Baumbach, Tauch, &amp; Rahmann, 2009;Baumbach, Wittkop, Kleindt, &amp; Tauch, 2009).Gene regulation involves the complex interplay of multiple biological molecules. The transcriptional process starts with the coordinated activity of multiple regulatory proteins, known as transcription factors (TFs), which bind to specific control regions in the DNA and then work together to recruit RNA polymerase (RNAP; Lambert et al., 2018). After recruitment, RNAP transcribes a gene, producing mRNA, which is then translated into protein. Additional factors, such as microRNAs and other epigenetic modifiers, are also involved in this process and can influence the amount of mRNA transcribed and the amount of protein translated (T. I. Lee &amp; Young, 2013). Gene regulatory networks model transcriptional processes by connecting regulators (such as TFs) to the genes encoding the downstream products of transcription and/or translation (mRNA and/or proteins, respectively; Sonawane et al., 2017). Importantly, a subset of the target genes in these networks encode TFs, creating a complex set of interactions that can be studied to understand the processes that control how a cell responds to environmental factors and to determine how the mechanisms controlling gene transcription are altered in the context of disease (Baumbach, Tauch, &amp; Rahmann, 2009;Baumbach, Wittkop, Kleindt, &amp; Tauch, 2009).</p>
        <p>The principle of the 
            <rs type="software">GrandForest</rs> webtool network enrichment approach. Given a (labeled) Omics data set (e.g., gene expression) and a PPI network, the tool learns decision trees just like in a classical Random Forest but restricts the decision tree growing to only pick proteins that are adjacent (in the network) to at least one previously picked feature protein. This way, all decision trees in the forest model by-design represent subnetworks of the interactome. They can be sorted by feature importance (e.g., using Gini index). The top m genes (user parameter) are located in the input network and the induced subnetwork is reported and visualized as a candidate mechanism driving the phenotype of interest. Importantly, 
            <rs type="software">GrandForest</rs> can identify subnetworks where many genes are not significant individually but become significant only as a mechanistic marker ensemble (S.J. Larsen et al., 2020) Much of the early work in modeling regulatory networks leveraged gene expression data to draw connections between TFs and genes based on linear (de la Fuente, Bing, Hoeschele, &amp; Mendes, 2004) or nonlinear (Faith et al., 2007;Margolin et al., 2006) correlations in their expression profiles (De Smet &amp; Marchal, 2010;Marbach et al., 2012). However, it soon became clear that gene regulatory networks estimated solely from gene expression data could not distinguish between direct and indirect regulatory events (Marbach et al., 2010), at least partially because gene co-regulation (i.e., a pair of genes regulated by the same TF) often has similar or stronger expression correlation than direct regulation of a gene by a TF (Ku, Duggal, Li, Girvan, &amp; Ott, 2012). This observation led to the development of network reconstruction algorithms that incorporate multiple sources of data (Chang et al., 2008;Conlon, Liu, Lieb, &amp; Liu, 2003;Hecker, Lambeck, Toepfer, van Someren, &amp; Guthke, 2009). For example, interactions between TFs and genes can be derived by scanning the control regions of genes for sequence patterns that correspond to potential TF binding sites. In isolation, these interactions lack biological context, generally contain many false-positives (spurious network edges), and are limited by the availability of information regarding the binding preferences of TFs. These estimates can be combined with epigenetic data assessing chromatin state in order to create context-specific networks (Beyer et al., 2006;Gerstein et al., 2012;Neph et al., 2012;Pique-Regi et al., 2011); however, the resulting models often suffer from a high number of false-negatives (missing network edges). One significant appeal of these approaches is their potential to incorporate distal information into gene regulatory networks, although currently, the effective and accurate association of enhancers with genes remains an outstanding problem in the field of computational biology.
        </p>
        <p>Statistical approaches have also been applied to model gene regulatory networks. These approaches fall into two main classes: (a) regression-based approaches, which estimate regulatory interactions by modeling each gene's expression level as a linear combination of the expression levels of its potential TF regulators (Haury, Mordelet, Vera-Licona, &amp; Vert, 2012); and (b) classification-based approaches, which add and remove regulatory interactions by comparing each gene's expression profile to the expression profiles of other genes that are, or are not, targeted by a particular TF (Ernst et al., 2008;Mordelet &amp; Vert, 2008). These statistical approaches, although powerful, essentially solve a series of independent problems, presenting challenges for assimilating their results into a single, coherent gene regulatory network. One method that overcomes this limitation is Passing Attributes between Networks for Data Assimilation (PANDA; Glass et al., 2013), which uses a message-passing approach (Frey &amp; Dueck, 2007) to integrate information regarding TF complexes, TF targeting of genes, and gene co-regulation. 
            <rs type="software">PANDA</rs> works by performing a series of network projections to optimize shared structures across these input data and to uncover TF and gene targeting patterns. 
            <rs type="software">PANDA</rs> has been successfully applied in multiple different disease contexts, including ovarian cancer (Glass, Quackenbush, Spentzos, Haibe-Kains, &amp; Yuan, 2015), colorectal cancer (Lopes-Ramos et al., 2018), dietinduced weight-loss (Vargas, Quackenbush, &amp; Glass, 2016), chronic obstructive pulmonary disease (COPD; Glass et al., 2014;Lao et al., 2015), and asthma (Qiu et al., 2018), as well as to study gene regulatory networks in multiple human tissues (Sonawane et al., 2017) and cell lines (Lopes-Ramos et al., 2017).
        </p>
        <p>Gene regulatory networks that are inferred from data are often directed, with edges that extend from a regulatorsuch as a transcription factor-to a target gene, as well as weighted, with scores reflecting the overall evidence for a regulatory relationship. These two features make regulatory networks excellent models of biological processes, which are, by definition, directed and also may have varying levels of importance depending on biological context (Sonawane et al., 2017). In principle, gene regulatory networks should also be signed to convey information regarding transcriptional activation or inhibition. Although these types of relationships have been carefully curated at a genome-wide level for some smaller organisms, such as E. coli (Gama-Castro et al., 2016), they cannot be easily measured using high throughput methods. Thus, due to the scale and complexity of higher-order mammalian systems, signs are generally only considered when investigating well-studied subsets of human gene regulatory relationships, such as those reported in pathway databases (Kanehisa, Furumichi, Tanabe, Sato, &amp; Morishima, 2017).Gene regulatory networks that are inferred from data are often directed, with edges that extend from a regulatorsuch as a transcription factor-to a target gene, as well as weighted, with scores reflecting the overall evidence for a regulatory relationship. These two features make regulatory networks excellent models of biological processes, which are, by definition, directed and also may have varying levels of importance depending on biological context (Sonawane et al., 2017). In principle, gene regulatory networks should also be signed to convey information regarding transcriptional activation or inhibition. Although these types of relationships have been carefully curated at a genome-wide level for some smaller organisms, such as E. coli (Gama-Castro et al., 2016), they cannot be easily measured using high throughput methods. Thus, due to the scale and complexity of higher-order mammalian systems, signs are generally only considered when investigating well-studied subsets of human gene regulatory relationships, such as those reported in pathway databases (Kanehisa, Furumichi, Tanabe, Sato, &amp; Morishima, 2017).</p>
        <p>Correlation-based networks and their graph theory-based properties have been successfully used to summarize and understand large data sets generated in biological and medical studies (Batushansky, Toubiana, &amp; Fait, 2016;D. Yu, Kim, Xiao, &amp; Hwang, 2013). Correlation networks are based on the calculation of pairwise correlation coefficients between the data associated with a pair of nodes (usually Pearson or Spearman coefficients, Kendall's tau, or Mutual Information). Since these correlation values are generally nonzero (i.e., the network is complete), it is necessary to impose a hard or soft threshold on the correlation coefficient values to remove spurious relationships and, thus, focus on significant associations between highly correlated nodes (Schwarz &amp; McGonigle, 2011;Zhan et al., 2017). Hardthresholding approaches create binary networks where sub-threshold inter-node correlations are suppressed (edge values set to 0), and supra-threshold correlations are compressed (edge values set to 1). Alternatively, soft-thresholding approaches replace thresholding with a continuous mapping of correlation values into edge weights, which has the effect of suppressing rather than removing weaker network connections. Pearson correlation is the most widely used statistic to measure the degree of the linear relationship between two normally distributed variables. Alternatives include Spearman and Kendall's tau correlations, which do not require any assumptions about the distribution of the data and measure the statistical association between two variables based on their ranks. These three measurements can take values ranging from -1 to +1. Finally, mutual information is a generalized correlation measure used to assess the nonlinear dependence between two random variables. It is always larger than or equal to zero: The larger the value, the greater the relationship between the two variables. Mutual information is zero when the two variables are independent.Correlation-based networks and their graph theory-based properties have been successfully used to summarize and understand large data sets generated in biological and medical studies (Batushansky, Toubiana, &amp; Fait, 2016;D. Yu, Kim, Xiao, &amp; Hwang, 2013). Correlation networks are based on the calculation of pairwise correlation coefficients between the data associated with a pair of nodes (usually Pearson or Spearman coefficients, Kendall's tau, or Mutual Information). Since these correlation values are generally nonzero (i.e., the network is complete), it is necessary to impose a hard or soft threshold on the correlation coefficient values to remove spurious relationships and, thus, focus on significant associations between highly correlated nodes (Schwarz &amp; McGonigle, 2011;Zhan et al., 2017). Hardthresholding approaches create binary networks where sub-threshold inter-node correlations are suppressed (edge values set to 0), and supra-threshold correlations are compressed (edge values set to 1). Alternatively, soft-thresholding approaches replace thresholding with a continuous mapping of correlation values into edge weights, which has the effect of suppressing rather than removing weaker network connections. Pearson correlation is the most widely used statistic to measure the degree of the linear relationship between two normally distributed variables. Alternatives include Spearman and Kendall's tau correlations, which do not require any assumptions about the distribution of the data and measure the statistical association between two variables based on their ranks. These three measurements can take values ranging from -1 to +1. Finally, mutual information is a generalized correlation measure used to assess the nonlinear dependence between two random variables. It is always larger than or equal to zero: The larger the value, the greater the relationship between the two variables. Mutual information is zero when the two variables are independent.</p>
        <p>Correlation networks are frequently used to analyze gene expression data (referred to as gene co-expression networks) and to gather biologically relevant information from genes with similar co-expression patterns (Fiscon, Conte, Farina, &amp; Paci, 2018). Gene co-expression networks are fertile fields for mining information about key genes and fundamental drivers of gene expression in a cellular system. Currently, two of the most promising algorithms for gene coexpression networks are 
            <rs type="software">SWItch Miner</rs> (SWIM; Paci et al., 2017) and Weighted Gene Correlation Network Analysis (WGCNA; Langfelder &amp; Horvath, 2008;B. Zhang &amp; Horvath, 2005). SWIM builds an unweighted correlation network (hard-thresholding) and exploits local and global graph properties to mine genes, called switch genes, which suggest association with drastic changes in cellular phenotype, such as in cancer development. WGCNA builds a correlation network that can be weighted (soft-thresholding) or unweighted (hard-thresholding) and identifies relevant genes by measuring the centrality of a gene within the network. WGCNA also permits incorporation of external sample information (like physiological, metabolic, and clinical traits) to screen for modules and intramodular hubs that relate to a sample trait, thus suggesting possible key roles of a specific network module in the phenotypic characterization. However, WGCNA considers only the right tail (i.e., positive correlation between gene pairs) of the correlation distribution.
        </p>
        <p>To date, the left tail (i.e., negative correlation between gene pairs) of the correlation distribution, and the interpretation of negative edges within a complex network representation of functional connectivity, has largely been ignored, apart from the SWIM methodology. Indeed, it is known that the human genome is pervasively transcribed (ENCODE Project Consortium et al., 2007), yet at any given spatial/temporal state a cell generally uses only a fraction of its gene functions. This observation suggests a crucial role of negative regulation to save cells from activation of specific pathways and cell functions in response to specific external stimuli or physiological and/or pathological changes. As an example, microRNAs are now universally recognized as key negative regulators in many intracellular processes as well as in cancer development and progression (Calin &amp; Croce, 2006;X. Zhou, Xu, Wang, Lin, &amp; Chen, 2015). The strength of SWIM is to emphasize the importance of negative regulation by explicitly considering also the left tail of the correlation distribution.To date, the left tail (i.e., negative correlation between gene pairs) of the correlation distribution, and the interpretation of negative edges within a complex network representation of functional connectivity, has largely been ignored, apart from the SWIM methodology. Indeed, it is known that the human genome is pervasively transcribed (ENCODE Project Consortium et al., 2007), yet at any given spatial/temporal state a cell generally uses only a fraction of its gene functions. This observation suggests a crucial role of negative regulation to save cells from activation of specific pathways and cell functions in response to specific external stimuli or physiological and/or pathological changes. As an example, microRNAs are now universally recognized as key negative regulators in many intracellular processes as well as in cancer development and progression (Calin &amp; Croce, 2006;X. Zhou, Xu, Wang, Lin, &amp; Chen, 2015). The strength of SWIM is to emphasize the importance of negative regulation by explicitly considering also the left tail of the correlation distribution.</p>
        <p>Correlation networks have also been successfully used to study complex diseases, comorbidity, and disease progression. Complex diseases (e.g., diabetes, stroke, cancer, etc.) are often considered as syndromes composed of overlapping individual diseases or phenotypes that manifest a similar pathological or physiological outcome. To understand how diseases are connected, the first Phenotypic Disease Network (PDN) was introduced as a map summarizing phenotypic connections (comorbidity correlations obtained from the disease history of more than 30 million patients) between diseases (nodes; Hidalgo, Blumm, Barabasi, &amp; Christakis, 2009). The authors showed that diseases progress preferentially along with the links of this map; in particular, this progression is different for patients of different genders and ethnicities, and patients affected by diseases that are connected to many other diseases in the PDN tend to die sooner than those affected by less connected diseases. Later, a phenomenological comorbidity network based on medical claims data of the entire population of Austria was proposed (Chmiel, Klimek, &amp; Thurner, 2014). This network was constructed from a two-layer multiplex network of two statistical measures quantifying relations between diseases. In contrast to the PDN proposed by Hidalgo et al. (Hidalgo et al., 2009), this network was based on a combination of measures (i.e., conditional probabilities for a comorbidity and respective contingency coefficients) that have been corrected for biases that result from the comparison of very rare and frequent diseases. The authors showed that the disease network undergoes dramatic structural changes across the lifetime and that patients predominantly develop diseases that are in close network proximity to disorders that they already suffer. A different approach was developed to investigate multiple disease-related phenotypes within one complex disease; Chu et al. (2014) developed a method for constructing networks of phenotypic variables (nodes) based on partial correlations between quantitative, disease-related phenotypes (edges). Specifically, using COPD as an example, these investigators described the application of network inference methods to explore the relationships between disease-related phenotypes, and they showed that the proposed approach allows detection of novel relationships that would not have been observed in a single variable analysis. A further example of a complex disease studied with correlation network analysis is provided by Nishihara et al. (2017), where the authors investigated the carcinogenic process in colorectal carcinoma. They proposed to model the complex process that encompasses a multitude of molecular events (e.g., somatic mutations, epigenetic alterations, and aberrant protein expression) with a biomarker correlation network wherein a node represents a tumor tissue biomarker (e.g., somatic mutation, methylation level, immune reaction, or protein expression) and an edge between two nodes occurs if the associated biomarkers exhibit a statistically significant Spearman correlation. Such a network analysis integrates multidimensional tumor biomarker data and allows identification of key molecular events and pathways that are central to an underlying biological process.Correlation networks have also been successfully used to study complex diseases, comorbidity, and disease progression. Complex diseases (e.g., diabetes, stroke, cancer, etc.) are often considered as syndromes composed of overlapping individual diseases or phenotypes that manifest a similar pathological or physiological outcome. To understand how diseases are connected, the first Phenotypic Disease Network (PDN) was introduced as a map summarizing phenotypic connections (comorbidity correlations obtained from the disease history of more than 30 million patients) between diseases (nodes; Hidalgo, Blumm, Barabasi, &amp; Christakis, 2009). The authors showed that diseases progress preferentially along with the links of this map; in particular, this progression is different for patients of different genders and ethnicities, and patients affected by diseases that are connected to many other diseases in the PDN tend to die sooner than those affected by less connected diseases. Later, a phenomenological comorbidity network based on medical claims data of the entire population of Austria was proposed (Chmiel, Klimek, &amp; Thurner, 2014). This network was constructed from a two-layer multiplex network of two statistical measures quantifying relations between diseases. In contrast to the PDN proposed by Hidalgo et al. (Hidalgo et al., 2009), this network was based on a combination of measures (i.e., conditional probabilities for a comorbidity and respective contingency coefficients) that have been corrected for biases that result from the comparison of very rare and frequent diseases. The authors showed that the disease network undergoes dramatic structural changes across the lifetime and that patients predominantly develop diseases that are in close network proximity to disorders that they already suffer. A different approach was developed to investigate multiple disease-related phenotypes within one complex disease; Chu et al. (2014) developed a method for constructing networks of phenotypic variables (nodes) based on partial correlations between quantitative, disease-related phenotypes (edges). Specifically, using COPD as an example, these investigators described the application of network inference methods to explore the relationships between disease-related phenotypes, and they showed that the proposed approach allows detection of novel relationships that would not have been observed in a single variable analysis. A further example of a complex disease studied with correlation network analysis is provided by Nishihara et al. (2017), where the authors investigated the carcinogenic process in colorectal carcinoma. They proposed to model the complex process that encompasses a multitude of molecular events (e.g., somatic mutations, epigenetic alterations, and aberrant protein expression) with a biomarker correlation network wherein a node represents a tumor tissue biomarker (e.g., somatic mutation, methylation level, immune reaction, or protein expression) and an edge between two nodes occurs if the associated biomarkers exhibit a statistically significant Spearman correlation. Such a network analysis integrates multidimensional tumor biomarker data and allows identification of key molecular events and pathways that are central to an underlying biological process.</p>
        <p>A limitation of gene co-expression correlation-based networks is that the effect of an expressed gene on a disease phenotype requires that its encoded protein binding and pathway partners be co-expressed (Kitsak et al., 2016). This requires knowledge of the PPI for optimal interpretation, as purely regulatory interactions may not be informative in this regard. Ideally, differentially expressed genes can be mapped to the PPI to create a "reticulotype" for a disease module of interest that is specific to an individual or a limited number of individuals with that disease phenotype. Such an approach moves the field ever closer to personalized precision medicine (L. Y. Lee &amp; Loscalzo, 2019).A limitation of gene co-expression correlation-based networks is that the effect of an expressed gene on a disease phenotype requires that its encoded protein binding and pathway partners be co-expressed (Kitsak et al., 2016). This requires knowledge of the PPI for optimal interpretation, as purely regulatory interactions may not be informative in this regard. Ideally, differentially expressed genes can be mapped to the PPI to create a "reticulotype" for a disease module of interest that is specific to an individual or a limited number of individuals with that disease phenotype. Such an approach moves the field ever closer to personalized precision medicine (L. Y. Lee &amp; Loscalzo, 2019).</p>
        <p>Bayesian networks are powerful models whose structure is determined directly from data that measure the values of variables across a series of samples, conditions, or states. More formally, Bayesian networks are directed acyclic graphs whose nodes are random probabilistic variables with values that describe variation across a set of states. The edges in a Bayesian network model the dependencies between variables, with the conditional probability distributions of each variable encoded by the network structure. In particular, the values taken by a node in a Bayesian network are modeled as a distribution that is conditioned on that node's parents, but independent of its nondescendants given its parents. Thus, the edges in these models ultimately can represent the influence of a number of both detected and undetected factors, providing an appealing framework with which to characterize relationships between variables despite imperfect knowledge and incomplete data, features commonly encountered in real-world Network Medicine applications.Bayesian networks are powerful models whose structure is determined directly from data that measure the values of variables across a series of samples, conditions, or states. More formally, Bayesian networks are directed acyclic graphs whose nodes are random probabilistic variables with values that describe variation across a set of states. The edges in a Bayesian network model the dependencies between variables, with the conditional probability distributions of each variable encoded by the network structure. In particular, the values taken by a node in a Bayesian network are modeled as a distribution that is conditioned on that node's parents, but independent of its nondescendants given its parents. Thus, the edges in these models ultimately can represent the influence of a number of both detected and undetected factors, providing an appealing framework with which to characterize relationships between variables despite imperfect knowledge and incomplete data, features commonly encountered in real-world Network Medicine applications.</p>
        <p>Two main classes of methods are used to reconstruct the structure of Bayesian networks: Constraint-based approaches (Natori, Uto, Nishiyama, Kawano, &amp; Ueno, 2015) and score-based algorithms (Andrews, Ramsey, &amp; Cooper, 2018). Whereas the former uses conditional independence tests to determine dependency structures in the data, the latter maximizes an objective function based on goodness-of-fit scores (Friedman, Linial, Nachman, &amp; Pe'er, 2000;Vignes et al., 2011). Score-based methods seek to identify the best network structure by optimizing a scoring function, and thus are more computationally expensive compared to constraint-based approaches, which relax this criterion. Although this relaxation results in lower accuracy models, it also allows for learning larger networks. It is important to note that with prior knowledge regarding the topological ordering of the network and the use of entropy to assess conditional independence and goodness of fit, constraint-based and score-based approaches learn the same network structure (Cowell, 2001). There are also hybrid methods which combine aspects of both constraint-based and score-based approaches (Scutari, Graafland, &amp; Gutierrez, 2019). Two important aspects to consider when modeling Bayesian networks include parameter estimation and structural learning. Parameter estimation involves learning the conditional probability distributions based on the data given a known network structure (Ji, Xia, &amp; Meng, 2015). Structural learning involves learning both the network structure and the parameters by combining a statistical criterion with an algorithm that determines how to apply that criterion to the data (Scanagatta, Salmeron, &amp; Stella, 2019).Two main classes of methods are used to reconstruct the structure of Bayesian networks: Constraint-based approaches (Natori, Uto, Nishiyama, Kawano, &amp; Ueno, 2015) and score-based algorithms (Andrews, Ramsey, &amp; Cooper, 2018). Whereas the former uses conditional independence tests to determine dependency structures in the data, the latter maximizes an objective function based on goodness-of-fit scores (Friedman, Linial, Nachman, &amp; Pe'er, 2000;Vignes et al., 2011). Score-based methods seek to identify the best network structure by optimizing a scoring function, and thus are more computationally expensive compared to constraint-based approaches, which relax this criterion. Although this relaxation results in lower accuracy models, it also allows for learning larger networks. It is important to note that with prior knowledge regarding the topological ordering of the network and the use of entropy to assess conditional independence and goodness of fit, constraint-based and score-based approaches learn the same network structure (Cowell, 2001). There are also hybrid methods which combine aspects of both constraint-based and score-based approaches (Scutari, Graafland, &amp; Gutierrez, 2019). Two important aspects to consider when modeling Bayesian networks include parameter estimation and structural learning. Parameter estimation involves learning the conditional probability distributions based on the data given a known network structure (Ji, Xia, &amp; Meng, 2015). Structural learning involves learning both the network structure and the parameters by combining a statistical criterion with an algorithm that determines how to apply that criterion to the data (Scanagatta, Salmeron, &amp; Stella, 2019).</p>
        <p>Bayesian networks often capture subtle relationships, producing realistic models of the pathways that control disease development and progression. Bayesian network analysis has been applied in a number of biological contexts. An early application in yeast gene expression data generated a highly predictive model of cell cycle mechanics (Friedman et al., 2000), demonstrating the power of the approach. Due to the size and complexity of the data, applications using human gene expression data often require constraining the model search space based on a preliminary set of network topologies (Hartemink, Gifford, Jaakkola, &amp; Young, 2002;Imoto et al., 2004;Le Phillip, Bahl, &amp; Ungar, 2004). With these modifications, Bayesian networks have been used to study a variety of related problems, such as the reconstruction of gene regulatory networks from the scientific literature (Gevaert, Van Vooren, &amp; De Moor, 2007) and gene expression data (Husmeier, 2003;Husmeier &amp; Werhli, 2007). More recent work in Bayesian networks includes the development of tools that support integrative and multi-modal data analysis, such as bootstrapping to reduce reliance on outliers, and the implementation of multiple search and validation algorithms (McGeachie, Chang, &amp; Weiss, 2014). These advances have led to the application of Bayesian networks to multiple different Omics data types, such as micro-RNA (McGeachie et al., 2017), metabolomics (Rogers et al., 2014), and microbiome data (McGeachie et al., 2016). An application of Bayesian networks to the integration of metabolomic, genomic, and methylation data implicated metabolic pathways in the pathophysiology of asthma control (McGeachie et al., 2015). Bayesian approaches have also been applied to model gene regulatory networks based on conditional mutual information (Aghdam, Ganjali, Zhang, &amp; Eslahchi, 2015;X. Zhang, Zhao, Hao, Zhao, &amp; Chen, 2015). Dynamic Bayesian networks have been utilized to create weighted directed networks, which can utilize longitudinal Omics data to create time-varying regulatory networks of activation or inhibition events (Z. Wang, Guo, &amp; Gong, 2018).Bayesian networks often capture subtle relationships, producing realistic models of the pathways that control disease development and progression. Bayesian network analysis has been applied in a number of biological contexts. An early application in yeast gene expression data generated a highly predictive model of cell cycle mechanics (Friedman et al., 2000), demonstrating the power of the approach. Due to the size and complexity of the data, applications using human gene expression data often require constraining the model search space based on a preliminary set of network topologies (Hartemink, Gifford, Jaakkola, &amp; Young, 2002;Imoto et al., 2004;Le Phillip, Bahl, &amp; Ungar, 2004). With these modifications, Bayesian networks have been used to study a variety of related problems, such as the reconstruction of gene regulatory networks from the scientific literature (Gevaert, Van Vooren, &amp; De Moor, 2007) and gene expression data (Husmeier, 2003;Husmeier &amp; Werhli, 2007). More recent work in Bayesian networks includes the development of tools that support integrative and multi-modal data analysis, such as bootstrapping to reduce reliance on outliers, and the implementation of multiple search and validation algorithms (McGeachie, Chang, &amp; Weiss, 2014). These advances have led to the application of Bayesian networks to multiple different Omics data types, such as micro-RNA (McGeachie et al., 2017), metabolomics (Rogers et al., 2014), and microbiome data (McGeachie et al., 2016). An application of Bayesian networks to the integration of metabolomic, genomic, and methylation data implicated metabolic pathways in the pathophysiology of asthma control (McGeachie et al., 2015). Bayesian approaches have also been applied to model gene regulatory networks based on conditional mutual information (Aghdam, Ganjali, Zhang, &amp; Eslahchi, 2015;X. Zhang, Zhao, Hao, Zhao, &amp; Chen, 2015). Dynamic Bayesian networks have been utilized to create weighted directed networks, which can utilize longitudinal Omics data to create time-varying regulatory networks of activation or inhibition events (Z. Wang, Guo, &amp; Gong, 2018).</p>
        <p>Despite their appeal and many successful applications, Bayesian network models have several well-known limitations. First, Bayesian networks are computationally complex and thus best applied to efforts to understand relationships between a relatively small number of variables. Resolving the structure of a Bayesian network is a nondeterministic polynomial time (NP)-hard problem (Chickering, 1996). To overcome this limitation, prior information can be used to "seed" the network structure and limit the search space (Djebbari &amp; Quackenbush, 2008). Second, Bayesian networks are structured as directed acyclic graphs. Thus, their application in modeling cellular processes, which often involve cyclic features such as feedback loops, requires modifications to the standard framework. Extensions to Bayesian networks that incorporate cyclic structures include factor graph approaches (Gat-Viks, Tanay, Raijman, &amp; Shamir, 2006) and dynamic Bayesian networks (Husmeier, 2003;Kim, Imoto, &amp; Miyano, 2003;J. Yu, Smith, Wang, Hartemink, &amp; Jarvis, 2004;Zou &amp; Conzen, 2005).Despite their appeal and many successful applications, Bayesian network models have several well-known limitations. First, Bayesian networks are computationally complex and thus best applied to efforts to understand relationships between a relatively small number of variables. Resolving the structure of a Bayesian network is a nondeterministic polynomial time (NP)-hard problem (Chickering, 1996). To overcome this limitation, prior information can be used to "seed" the network structure and limit the search space (Djebbari &amp; Quackenbush, 2008). Second, Bayesian networks are structured as directed acyclic graphs. Thus, their application in modeling cellular processes, which often involve cyclic features such as feedback loops, requires modifications to the standard framework. Extensions to Bayesian networks that incorporate cyclic structures include factor graph approaches (Gat-Viks, Tanay, Raijman, &amp; Shamir, 2006) and dynamic Bayesian networks (Husmeier, 2003;Kim, Imoto, &amp; Miyano, 2003;J. Yu, Smith, Wang, Hartemink, &amp; Jarvis, 2004;Zou &amp; Conzen, 2005).</p>
        <p>RNA plays a central role in physiological functions of every living organism, as described by Walter Gilbert in 1986 (Berget, Moore, &amp; Sharp, 1977;Chow, Gelinas, Broker, &amp; Roberts, 1977;Gilbert, 1986; R. C. Lee, Feinbaum, &amp; Ambros, 1993;Reinhart et al., 2000). Since then, high throughput genome-wide studies by the Encyclopedia of DNA Elements (ENCODE) and Functional Annotation of Mammals (FANTOM) projects have revealed that 98% of the human genome is pervasively transcribed and only 2% of the RNAs encode proteins (Lizio et al., 2019;Pazin, 2015). These results have triggered a plethora of studies on epigenetic functions of noncoding RNAs (ncRNAs) in human physiology and pathobiology in the last 20 years. The ncRNAs are classified, according to their length, into small RNAs (miRNAs, piRNA, siRNAs, snRNAs, snoRNAs, and tRNAs) and long noncoding RNAs (lncRNAs); the latter includes circular RNAs as well. All of these RNAs are intricately interconnected in biological regulatory networks (Holoch &amp; Moazed, 2015).RNA plays a central role in physiological functions of every living organism, as described by Walter Gilbert in 1986 (Berget, Moore, &amp; Sharp, 1977;Chow, Gelinas, Broker, &amp; Roberts, 1977;Gilbert, 1986; R. C. Lee, Feinbaum, &amp; Ambros, 1993;Reinhart et al., 2000). Since then, high throughput genome-wide studies by the Encyclopedia of DNA Elements (ENCODE) and Functional Annotation of Mammals (FANTOM) projects have revealed that 98% of the human genome is pervasively transcribed and only 2% of the RNAs encode proteins (Lizio et al., 2019;Pazin, 2015). These results have triggered a plethora of studies on epigenetic functions of noncoding RNAs (ncRNAs) in human physiology and pathobiology in the last 20 years. The ncRNAs are classified, according to their length, into small RNAs (miRNAs, piRNA, siRNAs, snRNAs, snoRNAs, and tRNAs) and long noncoding RNAs (lncRNAs); the latter includes circular RNAs as well. All of these RNAs are intricately interconnected in biological regulatory networks (Holoch &amp; Moazed, 2015).</p>
        <p>Ever-increasing evidence suggests that many genomic mutations reside in noncoding regions that perturb RNA-RNA interactions, leading to different diseases (Shah et al., 2018;Yuan &amp; Weidhaas, 2019). Such interactions are epitomized by the competing endogenous RNA (ceRNA) hypothesis, in which lncRNAs function as they bind to miRNAs and consequently regulate the expression of messenger RNAs (mRNAs; Anastasiadou, Jacob, &amp; Slack, 2018;Salmena, Poliseno, Tay, Kats, &amp; Pandolfi, 2011). Furthermore, ncRNAs interact not only with each other but also with proteins and DNA, which are interconnected in diverse regulatory networks. Therefore, a better understanding of RNA-RNA interactions is of fundamental importance in Network Medicine (Barabasi et al., 2011; L. Y. Lee &amp; Loscalzo, 2019;Tay, Rinn, &amp; Pandolfi, 2014).Ever-increasing evidence suggests that many genomic mutations reside in noncoding regions that perturb RNA-RNA interactions, leading to different diseases (Shah et al., 2018;Yuan &amp; Weidhaas, 2019). Such interactions are epitomized by the competing endogenous RNA (ceRNA) hypothesis, in which lncRNAs function as they bind to miRNAs and consequently regulate the expression of messenger RNAs (mRNAs; Anastasiadou, Jacob, &amp; Slack, 2018;Salmena, Poliseno, Tay, Kats, &amp; Pandolfi, 2011). Furthermore, ncRNAs interact not only with each other but also with proteins and DNA, which are interconnected in diverse regulatory networks. Therefore, a better understanding of RNA-RNA interactions is of fundamental importance in Network Medicine (Barabasi et al., 2011; L. Y. Lee &amp; Loscalzo, 2019;Tay, Rinn, &amp; Pandolfi, 2014).</p>
        <p>Data-driven methodologies help to shed light on ncRNA network involvement in human disease (Ristevski &amp; Chen, 2018). One of the most versatile data mining tools is the Gene Expression Omnibus database repository (GEO), containing high throughput gene expression data, and the BioPortal database repository, which provides biomedical ontologies (Clough &amp; Barrett, 2016). One way to study an RNA-RNA network in a particular disease takes into account the pipeline to analyze mRNA, miRNA, and lncRNA datasets from the GEO. Indeed, a recent study analyzed differential expression of these RNAs in spinal cord injury (SCI) and normal samples (L. Wang, Wang, Liu, &amp; Quan, 2019). The raw data analysis, performed either by using the 
            <rs type="software">Linear Models for Microarray Data (LIMMA)</rs> package or the Morpheus platform, was used respectively to identify statistically significant deregulated mRNAs and differentially expressed miRNAs and lncRNAs (Gentleman et al., 2004). Differential expression data were matched based on their complementarity to assess the predicted interactions between mRNA-lncRNA, mRNA-miRNA, and lncRNA-miRNA. After an accurate and unbiased analysis, the RNA interactions were placed in a network using 
            <rs type="software">Cytoscape</rs> software.
        </p>
        <p>From this analysis, a ceRNA network was unraveled, which included 93 mRNA, 9 miRNA, and 13 lncRNA nodes with a total of 202 edges. Additionally, the 
            <rs type="software">FunRich</rs> software was used to analyze biological functions, molecular pathways, clinical phenotypes, transcription factors and protein domains related to all mRNA, miRNA, and lncRNA nodes. Based on the degree of a node, as indicated by the number of mRNA, miRNA, and lncRNA neighbors, the authors identified three of the 13 lncRNA nodes and their corresponding three sub-ceRNA networks as potential biomarkers and therapeutic targets for SCI. Such pipeline data analysis provides further insights into how lncRNAs interact with other RNA species to form a molecular network. A similar approach could be employed for identification of RNA-RNA interactions in other human diseases.
        </p>
        <p>Among computational methods describing miRNA-sponge interactions (ceRNAs) through a network-based approach (Le, Zhang, Liu, &amp; Li, 2017), the method proposed by Paci, Colombo, and Farina (2014) has been ranked as most effective in identifying the number of ncRNA interactions associated with breast cancer. Specifically, based on a partial correlation model, the authors investigated the role of lncRNAs as miRNA sponges and built miRNA-mediated interaction (MMI) networks, where nodes represent ceRNAs (lncRNA or mRNA) and edges represent miRNAs that are mediating their interaction, in human breast invasive carcinoma (BRCA). The results revealed the lncRNA, PVT1 (Pvt1 Oncogene), as the first hub of the BRCA MMI-network. More than 80% of microRNAs sponged by PVT1 corresponds to the mir-200 family, whose importance in breast cancer is related to the epithelial-mesenchymal transition.Among computational methods describing miRNA-sponge interactions (ceRNAs) through a network-based approach (Le, Zhang, Liu, &amp; Li, 2017), the method proposed by Paci, Colombo, and Farina (2014) has been ranked as most effective in identifying the number of ncRNA interactions associated with breast cancer. Specifically, based on a partial correlation model, the authors investigated the role of lncRNAs as miRNA sponges and built miRNA-mediated interaction (MMI) networks, where nodes represent ceRNAs (lncRNA or mRNA) and edges represent miRNAs that are mediating their interaction, in human breast invasive carcinoma (BRCA). The results revealed the lncRNA, PVT1 (Pvt1 Oncogene), as the first hub of the BRCA MMI-network. More than 80% of microRNAs sponged by PVT1 corresponds to the mir-200 family, whose importance in breast cancer is related to the epithelial-mesenchymal transition.</p>
        <p>The above studies on RNA-RNA interactions demonstrate the importance of these networks for the identification of disease-driven RNA as potential diagnostic biomarkers and therapeutic targets. Notwithstanding the importance of an accurate and unbiased RNA-RNA network analysis in health and disease, the critical importance of experimental validation by cell-based approaches and animal models should not be underestimated.The above studies on RNA-RNA interactions demonstrate the importance of these networks for the identification of disease-driven RNA as potential diagnostic biomarkers and therapeutic targets. Notwithstanding the importance of an accurate and unbiased RNA-RNA network analysis in health and disease, the critical importance of experimental validation by cell-based approaches and animal models should not be underestimated.</p>
        <p>In the era of precision medicine, epigenomics has acquired a key role in revealing how epigenetic modifications can be utilized to identify diagnostic biomarkers and/or new therapeutic targets. Epigenomics analyzes overall epigenetic modifications within the genome of the cell.In the era of precision medicine, epigenomics has acquired a key role in revealing how epigenetic modifications can be utilized to identify diagnostic biomarkers and/or new therapeutic targets. Epigenomics analyzes overall epigenetic modifications within the genome of the cell.</p>
        <p>Epigenetic regulation is the result of different modification pathways that affect DNA either directly (DNA methylation) or indirectly, through post-translational modifications of histone proteins, nucleosome positioning, and chromatin accessibility of regulatory regions to DNA binding proteins (Z. Chen, Li, Subramaniam, Shyy, &amp; Chien, 2017). Accordingly, epigenetic modifications coordinately establish the transcriptional program of cells and, together with integration methods of genomic, transcriptomic, and proteomic data, are crucial to understand fully the regulatory mechanisms underlying complex diseases (Robinson &amp; Pelizzola, 2015). The epigenome is highly dynamic.Epigenetic regulation is the result of different modification pathways that affect DNA either directly (DNA methylation) or indirectly, through post-translational modifications of histone proteins, nucleosome positioning, and chromatin accessibility of regulatory regions to DNA binding proteins (Z. Chen, Li, Subramaniam, Shyy, &amp; Chien, 2017). Accordingly, epigenetic modifications coordinately establish the transcriptional program of cells and, together with integration methods of genomic, transcriptomic, and proteomic data, are crucial to understand fully the regulatory mechanisms underlying complex diseases (Robinson &amp; Pelizzola, 2015). The epigenome is highly dynamic.</p>
        <p>Epigenomic patterns are tightly regulated by both genetic and environmental factors that ultimately establish different clinical phenotypes (Allis &amp; Jenuwein, 2016). In recent years, a considerable amount of epigenetic data have been produced using several epigenetic analysis techniques aimed at finely characterizing both DNA methylation (Whole Genome Bisulfite Sequencing, MeDip, pyrosequencing, MSRE/MRE-Seq), chromatin accessibility and histone modifications (ChIP-Seq, Nome-Seq, ATAC-Seq), and chromosome conformation capture (3C, 4C, 5C, Hi-C). High-throughput sequencing technology has extended the body of epigenetic information at genome-wide scale. Major efforts are currently underway to establish data annotation protocols (for data standardization) and computational methods for epigenomic analysis by making use of databases and software tools for statistical analysis, data integration, and functional annotation.Epigenomic patterns are tightly regulated by both genetic and environmental factors that ultimately establish different clinical phenotypes (Allis &amp; Jenuwein, 2016). In recent years, a considerable amount of epigenetic data have been produced using several epigenetic analysis techniques aimed at finely characterizing both DNA methylation (Whole Genome Bisulfite Sequencing, MeDip, pyrosequencing, MSRE/MRE-Seq), chromatin accessibility and histone modifications (ChIP-Seq, Nome-Seq, ATAC-Seq), and chromosome conformation capture (3C, 4C, 5C, Hi-C). High-throughput sequencing technology has extended the body of epigenetic information at genome-wide scale. Major efforts are currently underway to establish data annotation protocols (for data standardization) and computational methods for epigenomic analysis by making use of databases and software tools for statistical analysis, data integration, and functional annotation.</p>
        <p>Several data repositories and browsers are currently available thanks to the endeavors of Big Data consortia. ENCODE, the International Human Epigenome Consortium (IHEC), NIH Roadmap, Blueprint, and others have made available epigenetic profiling datasets as well as standardization of protocols and sample preparation for both healthy and disease states of different cell lineages and tissues (Bernstein et al., 2010;Bujold et al., 2016;Davis et al., 2018;Martens &amp; Stunnenberg, 2013;The BLUEPRINT Consortium, 2016). In parallel, a remarkable number of epigenomic databases, tools, and data storage systems has allowed the storage and visualization of epigenomic datasets of different sample groups (Han &amp; He, 2016). Among these, the Human Epigenome 
            <rs type="software">Browser</rs> (X. Zhou et al., 2011) and 
            <rs type="software">UCSC Genome Browser</rs> (Kent et al., 2002) provide resources and tools for epigenetic data mining and annotation.
        </p>
        <p>In complex diseases, the epigenomic profile results from the interplay between genetic and environmental factors. Thus, integrating epigenomics data in different pathological contexts represents an important step toward effectively defining and treating multifactorial diseases. Epigenome-wide association studies (EWAS) identify epigenetic marks associated with a specific phenotype. Several web tools such as the Human EpiGenome Browser (X. Zhou et al., 2011) and coMET (Martin, Yet, Tsai, &amp; Bell, 2015) are used to visualize different epigenetic profiles by phenotype. A more comprehensive view of the functional implications of EWAS associations can be exploited using gene ontology, pathway, and network analysis tools. 
            <rs type="software">Ingenuity Pathway Analysis (IPA©</rs>, QIAGEN) explores biological networks, functions, and associated diseases of EWAS associations (Kramer, Green, Pollard Jr., &amp; Tugendreich, 2014), while Locus Overlap Analysis (LOLA) provides genomic region enrichment analysis to interpret functional genomics and epigenomics data (Sheffield &amp; Bock, 2016). Genomic Regions Enrichment 
            <rs type="software">of Annotations Tool (GREAT)</rs> is another powerful tool able to correlate data sets from ChIP-seq or, more generally, from DNA binding of cis-regulatory DNA regions with biological processes (McLean et al., 2010). Several network-based methods and tools such as 
            <rs type="software">eFORGE</rs> and 
            <rs type="software">ChromHMM</rs> are able to predict chromatin states from epigenetics data (Breeze et al., 2016;Ernst &amp; Kellis, 2017).
        </p>
        <p>Data integration approaches aimed at functionally annotating specific traits associated with epigenetic associations are now being developing by exploiting the possibility to predict chromatin states and establish links with gene expression (Claussnitzer et al., 2015). Few bioinformatics tools are currently available to combine and model multi-omics data and networks. Significance-based Modules Integrating the Transcriptome and Epigenome (SMITE) integrates transcriptomics and epigenomics data at high resolution, increasing confidence in finding gene modules underlying cellular pathophysiology (Wijetunga et al., 2017). SMITE may be used to identify novel gene modules in large epigenetic and transcriptomic data sets and provide a more useful characterization and visualization of functional modules inside a gene network. 
            <rs type="software">BioWardrobe</rs> is another user-friendly platform that stores, visualizes, and analyzes epigenomics and transcriptomics data, without requiring any particular programming skills (Kartashov &amp; Barski, 2015). This tool correlates differential gene expression with binding analysis and creates average tag-density profiles and heatmaps.
        </p>
        <p>Several studies represent valuable examples of the use of integrated epigenomic approaches to dissect complex disease. Claussnitzer revealed a mechanistic basis for the genetic association between FTO and human obesity (Claussnitzer et al., 2015), identifying the rs1421085 T-to-C single-nucleotide variant of the FTO gene as the singlenucleotide variant (SNV) responsible for dysregulation of target genes with a functional role in human obesity. The authors combined public resources for epigenomic annotations, chromosome conformation assays, and regulatory motif conservation. The data indicated that rs1421085 disrupts ARID5B repressor binding resulting in de-repression of IRX3/ IRX5 during early adipocyte differentiation. In another study based on the International Cancer Genome Consortium, Beekman et al. (2018) analyzed the epigenome of seven chronic lymphocytic leukemias (CLLs) and the chromatin landscape of another 100 additional cases previously characterized by whole-genome or whole-exome sequencing (WGS/WES), RNA-seq, and DNA methylation microarrays. These authors identified de novo reprogrammed regulatory regions associated with the development of CLL and its main clinical subtypes with diagnostic, prognostic, and potentially therapeutic value. The comprehensive dataset provided by the authors offered new insights into the biology and clinical behavior of CLL, representing a resource for the scientific community into the study of gene regulation, cell differentiation, and cancer genomics or epigenomics.Several studies represent valuable examples of the use of integrated epigenomic approaches to dissect complex disease. Claussnitzer revealed a mechanistic basis for the genetic association between FTO and human obesity (Claussnitzer et al., 2015), identifying the rs1421085 T-to-C single-nucleotide variant of the FTO gene as the singlenucleotide variant (SNV) responsible for dysregulation of target genes with a functional role in human obesity. The authors combined public resources for epigenomic annotations, chromosome conformation assays, and regulatory motif conservation. The data indicated that rs1421085 disrupts ARID5B repressor binding resulting in de-repression of IRX3/ IRX5 during early adipocyte differentiation. In another study based on the International Cancer Genome Consortium, Beekman et al. (2018) analyzed the epigenome of seven chronic lymphocytic leukemias (CLLs) and the chromatin landscape of another 100 additional cases previously characterized by whole-genome or whole-exome sequencing (WGS/WES), RNA-seq, and DNA methylation microarrays. These authors identified de novo reprogrammed regulatory regions associated with the development of CLL and its main clinical subtypes with diagnostic, prognostic, and potentially therapeutic value. The comprehensive dataset provided by the authors offered new insights into the biology and clinical behavior of CLL, representing a resource for the scientific community into the study of gene regulation, cell differentiation, and cancer genomics or epigenomics.</p>
        <p>A summary of the major molecular network types reviewed in this section is provided in Table 1.A summary of the major molecular network types reviewed in this section is provided in Table 1.</p>
        <p>As discussed in previous sections, the analysis of molecular networks combines data from different sources: Proteinprotein interaction networks are derived mostly from yeast two-hybrid systems and tandem affinity purification assays, whereas networks based on correlations between gene expression levels may not capture causal relationships (Celaj et al., 2017;Snider et al., 2015). Therefore, the conclusions drawn from the analysis of Omics data, whether based on publicly available datasets or correlations within a set of human samples, should be experimentally validated. If the disease under investigation has an animal model or a tissue or a cellular model (e.g., stem cells derived from patients), these could be interrogated to verify the existence of the network identified in silico. Specifically, if a subnetwork of interacting proteins exists, its experimental perturbation (pharmacologically, by siRNA, or genetically) should lead to a change in a disease-relevant phenotype.As discussed in previous sections, the analysis of molecular networks combines data from different sources: Proteinprotein interaction networks are derived mostly from yeast two-hybrid systems and tandem affinity purification assays, whereas networks based on correlations between gene expression levels may not capture causal relationships (Celaj et al., 2017;Snider et al., 2015). Therefore, the conclusions drawn from the analysis of Omics data, whether based on publicly available datasets or correlations within a set of human samples, should be experimentally validated. If the disease under investigation has an animal model or a tissue or a cellular model (e.g., stem cells derived from patients), these could be interrogated to verify the existence of the network identified in silico. Specifically, if a subnetwork of interacting proteins exists, its experimental perturbation (pharmacologically, by siRNA, or genetically) should lead to a change in a disease-relevant phenotype.</p>
        <p>The Network Medicine approach to build networks from pair-wise molecular interactions (Kyoto Encyclopedia of Genes and Genomes [KEGG]) and other high throughput approaches (e.g., brain imaging, connectomics, functional Magnetic Resonance Imaging [fMRI], etc.) can be combined with information gathered by high throughput techniques from cellular models (e.g., interactome or protein-protein interactions, kinase perturbation databases, phosphatase substrates, Reactome, druggome, etc.), in addition to extensive tissue protein expression databases, tissue atlases or annotated databases that consider protein functions (e.g., gene ontology). Consequently, experimental validation of network models represents an important step toward the development of precision medicine (Doncheva, Kacprowski, &amp; Albrecht, 2012;Loscalzo &amp; Barabasi, 2011). Two approaches have been considered to validate reliably the physiological relevance of target genes and pathways in a given network: Animal models and cell-based approaches. However, selecting the appropriate model system and perturbation for network validation can be challenging. Molecular networks may vary between cell types, so selecting a cell type relevant for the disease of interest is helpful. The relevance of a particular animal model for human disease needs to be considered. In addition, a subset of key network relationships, rather than the entire network, is typically considered for validation due to the expense and logistical challenges of performing large-scale cellular and animal model functional studies.The Network Medicine approach to build networks from pair-wise molecular interactions (Kyoto Encyclopedia of Genes and Genomes [KEGG]) and other high throughput approaches (e.g., brain imaging, connectomics, functional Magnetic Resonance Imaging [fMRI], etc.) can be combined with information gathered by high throughput techniques from cellular models (e.g., interactome or protein-protein interactions, kinase perturbation databases, phosphatase substrates, Reactome, druggome, etc.), in addition to extensive tissue protein expression databases, tissue atlases or annotated databases that consider protein functions (e.g., gene ontology). Consequently, experimental validation of network models represents an important step toward the development of precision medicine (Doncheva, Kacprowski, &amp; Albrecht, 2012;Loscalzo &amp; Barabasi, 2011). Two approaches have been considered to validate reliably the physiological relevance of target genes and pathways in a given network: Animal models and cell-based approaches. However, selecting the appropriate model system and perturbation for network validation can be challenging. Molecular networks may vary between cell types, so selecting a cell type relevant for the disease of interest is helpful. The relevance of a particular animal model for human disease needs to be considered. In addition, a subset of key network relationships, rather than the entire network, is typically considered for validation due to the expense and logistical challenges of performing large-scale cellular and animal model functional studies.</p>
        <p>An integral part of the Network Medicine approach should aim to define which gene-targeted animal model most effectively recapitulates a certain human disease. Although most complex diseases are polygenic, gene-targeted animal models focused on single genes often recapitulate key aspects of a complex disease. Table 2 provides examples of animal models of disease including attention deficit hyperactivity disorder (ADHD), anxiety/depression, memory dysfunction/ dementia, Type 1 and Type 2 diabetes, nephrotic syndrome, obesity, and cancer.An integral part of the Network Medicine approach should aim to define which gene-targeted animal model most effectively recapitulates a certain human disease. Although most complex diseases are polygenic, gene-targeted animal models focused on single genes often recapitulate key aspects of a complex disease. Table 2 provides examples of animal models of disease including attention deficit hyperactivity disorder (ADHD), anxiety/depression, memory dysfunction/ dementia, Type 1 and Type 2 diabetes, nephrotic syndrome, obesity, and cancer.</p>
        <p>Obtaining an accurate estimate of the number of genes responsible for a polygenic disease is problematic for several reasons: (a) in some instances (such as ADHD), the previously reported candidate gene associations (in contrast to large-scale genome-wide association studies) often have questionable validity; and (b) the number of genetic loci is not equivalent to the number of different genetic subgroups; there can be multiple functional variants at each locus, and even if discrete subgroups can be identified, they likely relate to multiple genetic variants. These limitations are also present in general when trying to infer molecular networks in human subjects. However, notwithstanding these limitations, it is interesting to analyze an estimate of the number of genes/genetic loci in each of these situations and compare it to the number of available genetic animal models. Epigenomic data can be integrated into gene regulatory networks to construct epigenomic regulatory networks. This additional layer of information can aid in the identification of biomarkers and therapeutic targets.Obtaining an accurate estimate of the number of genes responsible for a polygenic disease is problematic for several reasons: (a) in some instances (such as ADHD), the previously reported candidate gene associations (in contrast to large-scale genome-wide association studies) often have questionable validity; and (b) the number of genetic loci is not equivalent to the number of different genetic subgroups; there can be multiple functional variants at each locus, and even if discrete subgroups can be identified, they likely relate to multiple genetic variants. These limitations are also present in general when trying to infer molecular networks in human subjects. However, notwithstanding these limitations, it is interesting to analyze an estimate of the number of genes/genetic loci in each of these situations and compare it to the number of available genetic animal models. Epigenomic data can be integrated into gene regulatory networks to construct epigenomic regulatory networks. This additional layer of information can aid in the identification of biomarkers and therapeutic targets.</p>
        <p>b Correlation networks can also be constructed between other types of biological molecules using other types of Omics data. For example, a correlation network of metabolites can be constructed using metabolomics data.b Correlation networks can also be constructed between other types of biological molecules using other types of Omics data. For example, a correlation network of metabolites can be constructed using metabolomics data.</p>
        <p>Keeping in mind these limitations, as detailed in Table 2, many complex human diseases have a polygenic origin based on GWAS and next-generation sequencing data, and only few present a monogenic familial origin. In contrast, transgenic and knock-out animal models have a single gene perturbation. The disease phenotype of these genetic models often differs from the full phenotype of the human disease; the phenotype is often milder or even absent in some cases. However, of note, the number of available genetic animal models is approximately of the same order of the estimated number of genes responsible for the human disease, except for type II diabetes. Moreover, in some instances (such as Type 1 diabetes and nephrotic syndrome), a systematic report of the available animal models is not available, although the knockout mouse for each risk gene is available. Furthermore, a unique opportunity of a disease-or even patient-specific validation of a molecular network identified in silico is offered by patient-derived xenografts (PDXs) or avatars (Ben-David et al., 2017), which are based on cancer cells isolated from patients and injected into "nude" mice (mice without an immune system): These are an improved, individualized reproduction of the disease into animal models (though with several limitations; Willyard, 2018).Keeping in mind these limitations, as detailed in Table 2, many complex human diseases have a polygenic origin based on GWAS and next-generation sequencing data, and only few present a monogenic familial origin. In contrast, transgenic and knock-out animal models have a single gene perturbation. The disease phenotype of these genetic models often differs from the full phenotype of the human disease; the phenotype is often milder or even absent in some cases. However, of note, the number of available genetic animal models is approximately of the same order of the estimated number of genes responsible for the human disease, except for type II diabetes. Moreover, in some instances (such as Type 1 diabetes and nephrotic syndrome), a systematic report of the available animal models is not available, although the knockout mouse for each risk gene is available. Furthermore, a unique opportunity of a disease-or even patient-specific validation of a molecular network identified in silico is offered by patient-derived xenografts (PDXs) or avatars (Ben-David et al., 2017), which are based on cancer cells isolated from patients and injected into "nude" mice (mice without an immune system): These are an improved, individualized reproduction of the disease into animal models (though with several limitations; Willyard, 2018).</p>
        <p>In animal models, the effect of single-gene perturbations on molecular networks is then usually studied using Omics (e.g., proteomics, transcriptomics) analysis on relevant tissues. Strategies of gene-enrichment analysis or other techniques detailed above can be used to infer the disease network (how a molecular perturbation in a molecular network produces a specific phenotype). This information not only validates molecular networks inferred in patients but also gives a detailed view of which cells/tissues are most affected by the network perturbation and even tissue-by-tissue differences in molecular networks.In animal models, the effect of single-gene perturbations on molecular networks is then usually studied using Omics (e.g., proteomics, transcriptomics) analysis on relevant tissues. Strategies of gene-enrichment analysis or other techniques detailed above can be used to infer the disease network (how a molecular perturbation in a molecular network produces a specific phenotype). This information not only validates molecular networks inferred in patients but also gives a detailed view of which cells/tissues are most affected by the network perturbation and even tissue-by-tissue differences in molecular networks.</p>
        <p>In vitro cellular models most commonly used experimentally to validate network relationships inferred from Omics data include immortalized cell lines or primary cells isolated from different human tissues, stem cells, and induced pluripotent stem cells (iPS). Computational identification of hub genes that affect multiple molecular pathways in PPI and RNA-RNA interaction (RRI) networks necessitates functional validation to confirm biological mechanisms and suggest potential druggable targets. Experimental laboratory validation usually occurs in two-dimensional (2D) monolayer cell cultures. This unnatural system does not recapitulate the extracellular microenvironment in which the cells reside in the body, due to the lack of extracellular matrix (ECM) and local and circulating factors (e.g., neurohormones), critical components for physiological cell functions (Bonnans, Chou, &amp; Werb, 2014). Consequently, failures of clinical trials, especially in phase III, could be attributed to misleading experimental results obtained in 2D cell cultures. To reflect more realistic and natural cell responses to any therapeutic treatment, three-dimensional (3D) cell culture systems have been developed. Cells in a 3D culture may either grow as spheroids in suspension, as organoids surrounded by ECM, or on scaffolds, as described in Table 3 (Abbott, 2003;Edmondson, Broglie, Adcock, &amp; Yang, 2014;Muthuswamy, 2017). Organoids, arguably used interchangeably with spheroids, are a self-organized cell system that develop into 3D organlike units that resemble the function and structure of an organ (Muthuswamy, 2017). Therefore, organoid cultures established from patients are used for personalized reliable drug screening and for studying gene function, offering new therapeutic approaches in the field of personalized medicine. More dynamic types of cell cultures are Organ-on-chip (OOC) or Organ-Chips, a multi-channel 3D microfluidic cell culture chip made with silicone rubber polymer, which simulates the activities, mechanics, and physiological responses of entire organs and organ systems (Huh, Hamilton, &amp; Ingber, 2011). Unlike conventional cell culture plates, microfluidic devices have been developed to mimic entire organs and to recapitulate cellular interactions within a tissue unit by creating separate parenchymal and vascular compartments, therefore providing a more physiological microenvironment. Furthermore, in these devices a smaller culture volume is needed, providing a greater concentration of cell-secreted growth factors as compared with 96-well plates (Przybyla &amp; Voldman, 2012). Cells might be also seeded and grown on functionalized scaffolds made of synthetic biomaterials, such as polysaccharides, that are nontoxic, biocompatible, and biodegradable to achieve better cellular adhesion, differentiation, and proliferation able to form functional 3D human tissues for medical applications. Scaffolds mimic the extracellular matrix that sustains cell growth and can better recapitulate the microenvironment in which the cells are capable of exerting their physiological functions. Scaffold bioprinting has many potential medical applications, from organoids to human tissue fabrication for modeling pathobiology, drug development, and reconstitution and transplantation of damaged tissues and ultimately entire organs (Tissueengineered disease models, 2018). Integration of predictive molecular networks with empirical data derived from 3D culture systems could become a powerful approach for precision medicine. As mentioned above, 3D bioengineered models from patient-derived cells are geared toward more physiologic behavior that considers not only cell-cell but also cell-microenvironmental interactions. Molecular perturbations of these culture systems could be assessed for changes in gene expression, RNA-RNA interactions, or protein-protein interactions. However, application of Omics data in these 3D culture systems remains challenging. This challenge is mostly due to the complexity of nonlinear biological systems, characterized by common nodes (proteins or RNA) working in concert with other nodes in a network, thus affecting multiple molecular pathways. Perturbation of a single node by a drug or siRNA, short hairpin RNA (shRNA), CRISPR/Cas9, or any other RNA-based compound might influence multiple molecular network members and create feedback loop processes. This complexity derives not only from the number of genes and molecular pathways, but also from responses over time after in vitro or in vivo treatment; that is, with the aforementioned compounds. Moreover, a therapeutic treatment of an animal or 3D cellular model could be efficient and nontoxic at a certain range of a compound concentration; that is, lower concentrations might be less toxic than high doses of a therapeutic compound. Another characteristic of in vitro cellbased biological systems is their adaptability to any therapeutic treatment that might induce drug resistance. We also need to verify whether organotypic cultures manifest the emergent properties of disease/toxicity (Grego et al., 2017). These and other challenges may lead to failure for validation of even the most powerful predictive molecular network.In vitro cellular models most commonly used experimentally to validate network relationships inferred from Omics data include immortalized cell lines or primary cells isolated from different human tissues, stem cells, and induced pluripotent stem cells (iPS). Computational identification of hub genes that affect multiple molecular pathways in PPI and RNA-RNA interaction (RRI) networks necessitates functional validation to confirm biological mechanisms and suggest potential druggable targets. Experimental laboratory validation usually occurs in two-dimensional (2D) monolayer cell cultures. This unnatural system does not recapitulate the extracellular microenvironment in which the cells reside in the body, due to the lack of extracellular matrix (ECM) and local and circulating factors (e.g., neurohormones), critical components for physiological cell functions (Bonnans, Chou, &amp; Werb, 2014). Consequently, failures of clinical trials, especially in phase III, could be attributed to misleading experimental results obtained in 2D cell cultures. To reflect more realistic and natural cell responses to any therapeutic treatment, three-dimensional (3D) cell culture systems have been developed. Cells in a 3D culture may either grow as spheroids in suspension, as organoids surrounded by ECM, or on scaffolds, as described in Table 3 (Abbott, 2003;Edmondson, Broglie, Adcock, &amp; Yang, 2014;Muthuswamy, 2017). Organoids, arguably used interchangeably with spheroids, are a self-organized cell system that develop into 3D organlike units that resemble the function and structure of an organ (Muthuswamy, 2017). Therefore, organoid cultures established from patients are used for personalized reliable drug screening and for studying gene function, offering new therapeutic approaches in the field of personalized medicine. More dynamic types of cell cultures are Organ-on-chip (OOC) or Organ-Chips, a multi-channel 3D microfluidic cell culture chip made with silicone rubber polymer, which simulates the activities, mechanics, and physiological responses of entire organs and organ systems (Huh, Hamilton, &amp; Ingber, 2011). Unlike conventional cell culture plates, microfluidic devices have been developed to mimic entire organs and to recapitulate cellular interactions within a tissue unit by creating separate parenchymal and vascular compartments, therefore providing a more physiological microenvironment. Furthermore, in these devices a smaller culture volume is needed, providing a greater concentration of cell-secreted growth factors as compared with 96-well plates (Przybyla &amp; Voldman, 2012). Cells might be also seeded and grown on functionalized scaffolds made of synthetic biomaterials, such as polysaccharides, that are nontoxic, biocompatible, and biodegradable to achieve better cellular adhesion, differentiation, and proliferation able to form functional 3D human tissues for medical applications. Scaffolds mimic the extracellular matrix that sustains cell growth and can better recapitulate the microenvironment in which the cells are capable of exerting their physiological functions. Scaffold bioprinting has many potential medical applications, from organoids to human tissue fabrication for modeling pathobiology, drug development, and reconstitution and transplantation of damaged tissues and ultimately entire organs (Tissueengineered disease models, 2018). Integration of predictive molecular networks with empirical data derived from 3D culture systems could become a powerful approach for precision medicine. As mentioned above, 3D bioengineered models from patient-derived cells are geared toward more physiologic behavior that considers not only cell-cell but also cell-microenvironmental interactions. Molecular perturbations of these culture systems could be assessed for changes in gene expression, RNA-RNA interactions, or protein-protein interactions. However, application of Omics data in these 3D culture systems remains challenging. This challenge is mostly due to the complexity of nonlinear biological systems, characterized by common nodes (proteins or RNA) working in concert with other nodes in a network, thus affecting multiple molecular pathways. Perturbation of a single node by a drug or siRNA, short hairpin RNA (shRNA), CRISPR/Cas9, or any other RNA-based compound might influence multiple molecular network members and create feedback loop processes. This complexity derives not only from the number of genes and molecular pathways, but also from responses over time after in vitro or in vivo treatment; that is, with the aforementioned compounds. Moreover, a therapeutic treatment of an animal or 3D cellular model could be efficient and nontoxic at a certain range of a compound concentration; that is, lower concentrations might be less toxic than high doses of a therapeutic compound. Another characteristic of in vitro cellbased biological systems is their adaptability to any therapeutic treatment that might induce drug resistance. We also need to verify whether organotypic cultures manifest the emergent properties of disease/toxicity (Grego et al., 2017). These and other challenges may lead to failure for validation of even the most powerful predictive molecular network.</p>
        <p>The knowledge of molecular networks and especially causal network models combined with the experimental observations in 3D cell cultures could become an integrated and more accurate approach to predict human responses to any therapeutic treatment (Jaeger et al., 2014).The knowledge of molecular networks and especially causal network models combined with the experimental observations in 3D cell cultures could become an integrated and more accurate approach to predict human responses to any therapeutic treatment (Jaeger et al., 2014).</p>
        <p>Network Medicine allows the mapping of diseases into the theoretical problems of graphs. The study of networks requires a large amount of data to be analyzed and computed, in terms of properties of various nodes and relations existing among nodes and dynamicity related to the state of the network. Therefore, in addition to automatic analysis techniques (e.g., machine learning), it is possible to integrate this new approach with data visualization and visual analytics (Thomas &amp; Cook, 2005), depicting networks so that it is possible to understand clearly the region of interest and analyze the relationships between network layers (Marai, Pinaud, Buhler, Lex, &amp; Morris, 2019).Network Medicine allows the mapping of diseases into the theoretical problems of graphs. The study of networks requires a large amount of data to be analyzed and computed, in terms of properties of various nodes and relations existing among nodes and dynamicity related to the state of the network. Therefore, in addition to automatic analysis techniques (e.g., machine learning), it is possible to integrate this new approach with data visualization and visual analytics (Thomas &amp; Cook, 2005), depicting networks so that it is possible to understand clearly the region of interest and analyze the relationships between network layers (Marai, Pinaud, Buhler, Lex, &amp; Morris, 2019).</p>
        <p>Visual analytics is a field that has intersected in multiple ways with medical data analysis (Chittaro, 2001;Shneiderman, Plaisant, &amp; Hesse, 2013). With the birth of Network Medicine, several contributions have been proposed. They are focused on visualization of the molecular interactome (Chaurasia et al., 2009;Lu et al., 2004), disease modules and gene pathways (Cerami, Demir, Schultz, Taylor, &amp; Sander, 2010;Mlecnik et al., 2005), and phenotypes (Bottomly, McWeeney, &amp; Wilmot, 2016). Most of these approaches represent results using the node-edge diagram (Gladilin, 2017;Sharma et al., 2015), but generally, they have very basic visual interactions. Moreover, general-purpose frameworks Formation of spheroids in a small volume of cell suspension as a droplet.Visual analytics is a field that has intersected in multiple ways with medical data analysis (Chittaro, 2001;Shneiderman, Plaisant, &amp; Hesse, 2013). With the birth of Network Medicine, several contributions have been proposed. They are focused on visualization of the molecular interactome (Chaurasia et al., 2009;Lu et al., 2004), disease modules and gene pathways (Cerami, Demir, Schultz, Taylor, &amp; Sander, 2010;Mlecnik et al., 2005), and phenotypes (Bottomly, McWeeney, &amp; Wilmot, 2016). Most of these approaches represent results using the node-edge diagram (Gladilin, 2017;Sharma et al., 2015), but generally, they have very basic visual interactions. Moreover, general-purpose frameworks Formation of spheroids in a small volume of cell suspension as a droplet.</p>
        <p>Cell suspension is placed on 20-500 μm microchambers with various shapes: honeycomb, round, or square (Karp et al., 2007) Dynamic cell culture condition created by continuous stirring in appropriate glass containers for massive spheroid production (Ou &amp; Hosseinkhani, 2014) Organoids Examples of organoids and use:Cell suspension is placed on 20-500 μm microchambers with various shapes: honeycomb, round, or square (Karp et al., 2007) Dynamic cell culture condition created by continuous stirring in appropriate glass containers for massive spheroid production (Ou &amp; Hosseinkhani, 2014) Organoids Examples of organoids and use:</p>
        <p>• Human epithelial cells, breast cancer cells, acini-like structures that secreted milk proteins (Emerman, Enami, Pitelka, &amp; Nandi, 1977) • Exocrine pancreas cells used as a platform to study pancreatitis and pancreatic cancer (Huang et al., 2015) • Human derived organoids can be altered genetically, by the genome editing CRISPR/Cas9 technology, to study the role of genes in molecular pathways of interest (Fujii, Matano, Nanki, &amp; Sato, 2015) Organchips• Human epithelial cells, breast cancer cells, acini-like structures that secreted milk proteins (Emerman, Enami, Pitelka, &amp; Nandi, 1977) • Exocrine pancreas cells used as a platform to study pancreatitis and pancreatic cancer (Huang et al., 2015) • Human derived organoids can be altered genetically, by the genome editing CRISPR/Cas9 technology, to study the role of genes in molecular pathways of interest (Fujii, Matano, Nanki, &amp; Sato, 2015) Organchips</p>
        <p>• Human breathing lung alveolus chip, blood-brain barrier, kidney, skin, placenta, intestine, and so on (Huh et al., 2010;Kasendra et al., 2018;Sances et Abbreviations: PCL, poly-e-caprolactone; PEG: polyethylene glycol; PLA, polylactic acid. exist, in the form of environments or libraries, that allow visualization of large biological networks like 
            <rs type="software">Cytoscape</rs> (Smoot, Ono, Ruscheinski, Wang, &amp; Ideker, 2011), NetBioV (Tripathi, Dehmer, &amp; Emmert-Streib, 2014), or 
            <rs type="software">HitWalker 2</rs> (Bottomly et al., 2016). Gerasch et al. (2014) proposed a system for visually analyzing high-throughput Omics data in the context of networks; in particular, for differential analysis between groups of subjects and the analysis of time series data. Perer and Sun (2012) and Basole et al. (2015) proposed visual analytics solutions that analyze data from clinical patients, where the network reconstructs the time-evolving data of the clinical patient. In addition, Auriemma Citarella et al. ( 2019) analyzed the symptoms of the patients and the general information of the disease using information retrieval. However, they analyzed only the patients' data, without correlating them to the interactome. In this research, the symptoms of the patients can be considered as a layer in a multilayer network to have a more precise analysis. The work by Huan, Sivachenko, Harrison, and Chen (2008) presents 
            <rs type="software">PRoteoLEns</rs>, a JAVA-based visual analytics tool for creating, annotating, and exploring multi-scale biological networks. Nonetheless, the tool seems very proficient in exploring subparts of a biological network, but is not as effective in communicating a network overview. An improvement toward the analytics in the multilayer structure is represented by 
            <rs type="software">NEMESIS</rs> (Angelini, Blasilli, Farina, Lenti, &amp; Santucci, 2019), inspired by the work of Dietzsch, Heinrich, Nieselt, and Bartz (2009). 
            <rs type="software">NEMESIS</rs> is a visual analytics solution that provides the means for exploring interactively different facets of a complex body of data, inspecting both the data associated with topological properties of a single network and summary multidimensional information derived from other relevant networks.
        </p>
        <p>It is possible to model Network Medicine data as a multi-layer network, where each network (e.g., protein-protein interaction networks (Rolland et al., 2014), metabolic networks (Ravasz, Somera, Mongru, Oltvai, &amp; Barabasi, 2002), human disease networks (HDN; K. I. Goh et al., 2007), metabolic disease networks (MDN; Braun, Rietman, &amp; Vidal, 2008), and drug-target networks (DTN; Yildirim, Goh, Cusick, Barabasi, &amp; Vidal, 2007)) is a different layer. As explained by Kivela et al. (2014), a multilayer network has a set of nodes just like a typical network, but in addition, there are layers. Each connection is not a pair of nodes; instead, it is a tuple of node-layers. The difficulties in understanding these connections are related to the multiple points of view that this structure generates; in fact, the elements can be analyzed at the intra-layer level (effectively focusing on a single homogeneous network) or at the inter-layer level. In this structure, layers and their connectivity have major roles; in fact, each layer must be chosen for its usefulness and importance with respect to the problems being studied. Network Medicine seems the perfect domain where modeling the various elements at hand as a multi-layer network can provide enriched analysis and benefits, although with additional complexity to manage.It is possible to model Network Medicine data as a multi-layer network, where each network (e.g., protein-protein interaction networks (Rolland et al., 2014), metabolic networks (Ravasz, Somera, Mongru, Oltvai, &amp; Barabasi, 2002), human disease networks (HDN; K. I. Goh et al., 2007), metabolic disease networks (MDN; Braun, Rietman, &amp; Vidal, 2008), and drug-target networks (DTN; Yildirim, Goh, Cusick, Barabasi, &amp; Vidal, 2007)) is a different layer. As explained by Kivela et al. (2014), a multilayer network has a set of nodes just like a typical network, but in addition, there are layers. Each connection is not a pair of nodes; instead, it is a tuple of node-layers. The difficulties in understanding these connections are related to the multiple points of view that this structure generates; in fact, the elements can be analyzed at the intra-layer level (effectively focusing on a single homogeneous network) or at the inter-layer level. In this structure, layers and their connectivity have major roles; in fact, each layer must be chosen for its usefulness and importance with respect to the problems being studied. Network Medicine seems the perfect domain where modeling the various elements at hand as a multi-layer network can provide enriched analysis and benefits, although with additional complexity to manage.</p>
        <p>From a visualization perspective, it is important to look for appropriate visual representations apart from the classic node-edge diagram, adjacency matrix (Ghoniem, Fekete, &amp; Castagliola, 2005), or chord diagram (Crnovrsanin, Muelder, Faris, Felmlee, &amp; Ma, 2014), or using a hybrid approach (matrix and node-edge; Henry, Fekete, &amp; McGuffin, 2007). These representations should be able to provide scalability with respect to data size and should be able to support the analyst providing an explorable overview. The analyst must be supported by tools to examine interactions within a single layer of the multi-layer network and eventually explore the connection to other layers. In this sense, it becomes important to design navigation patterns through different visual representations, automatically selecting the best one for the specific task at hand (e.g., exploration of the network, communication between different types of evidence, or analysis of a subset of elements). Transitions between abstract visual paradigms (e.g., node-edge representation, adjacency matrix representation, and novel visual paradigms) should be managed while keeping the user selection, allowing rearrangement of the layout of the multi-layer network depending on the kind of analysis executed.From a visualization perspective, it is important to look for appropriate visual representations apart from the classic node-edge diagram, adjacency matrix (Ghoniem, Fekete, &amp; Castagliola, 2005), or chord diagram (Crnovrsanin, Muelder, Faris, Felmlee, &amp; Ma, 2014), or using a hybrid approach (matrix and node-edge; Henry, Fekete, &amp; McGuffin, 2007). These representations should be able to provide scalability with respect to data size and should be able to support the analyst providing an explorable overview. The analyst must be supported by tools to examine interactions within a single layer of the multi-layer network and eventually explore the connection to other layers. In this sense, it becomes important to design navigation patterns through different visual representations, automatically selecting the best one for the specific task at hand (e.g., exploration of the network, communication between different types of evidence, or analysis of a subset of elements). Transitions between abstract visual paradigms (e.g., node-edge representation, adjacency matrix representation, and novel visual paradigms) should be managed while keeping the user selection, allowing rearrangement of the layout of the multi-layer network depending on the kind of analysis executed.</p>
        <p>Where the complexity of the analysis again becomes manageable, the visualization can transition back to node-edge diagrams that are more readable for a low number of elements with respect to other abstract visual representations. Proposals on this topic are the automation of the change of visualizations with respect to granularity of the focus level (Landesberger et al., 2011;e.g., from matrix to node-edge) or detail to overview via selections and aggregations (DOSA; van den Elzen &amp; van Wijk, 2014).Where the complexity of the analysis again becomes manageable, the visualization can transition back to node-edge diagrams that are more readable for a low number of elements with respect to other abstract visual representations. Proposals on this topic are the automation of the change of visualizations with respect to granularity of the focus level (Landesberger et al., 2011;e.g., from matrix to node-edge) or detail to overview via selections and aggregations (DOSA; van den Elzen &amp; van Wijk, 2014).</p>
        <p>Among several visualization tasks to be supported, we can envision consolidating network data (e.g., interactome data), given the different sources that provide these data. Homogenization of data is necessary to perform deep studies aimed at uncovering new edges in single networks (e.g., protein-protein network) or among the networks (e.g., drugspatients). Identification of interesting areas of the multi-layer network, such as highly connected nodes (hubs), may indicate certain properties that are present or are of specific interest (e.g., disease modules). Studying the connectivity in the multi-layer network, it is possible to identify regularities that could provide biological insights, but also to manage visually the complexity of the multi-layer network layout. On this topic, interesting visual approaches include the gragnostics (Gove, 2019) approach proposing several metrics for network similarity (e.g., to recognize similarities between the different layers and finding new patterns) and methodologies for pruning uninteresting elements from the network, allowing more scalable visual representations (Auber, 2004;Singh, 2007).Among several visualization tasks to be supported, we can envision consolidating network data (e.g., interactome data), given the different sources that provide these data. Homogenization of data is necessary to perform deep studies aimed at uncovering new edges in single networks (e.g., protein-protein network) or among the networks (e.g., drugspatients). Identification of interesting areas of the multi-layer network, such as highly connected nodes (hubs), may indicate certain properties that are present or are of specific interest (e.g., disease modules). Studying the connectivity in the multi-layer network, it is possible to identify regularities that could provide biological insights, but also to manage visually the complexity of the multi-layer network layout. On this topic, interesting visual approaches include the gragnostics (Gove, 2019) approach proposing several metrics for network similarity (e.g., to recognize similarities between the different layers and finding new patterns) and methodologies for pruning uninteresting elements from the network, allowing more scalable visual representations (Auber, 2004;Singh, 2007).</p>
        <p>Eventually, these elements can even be used to model new layers of the multi-layer network, using them for fast filtering activities or pattern-matching based on machine learning techniques. Another interesting aspect is the network neighborhood; nearby nodes are often associated with the same phenomena. Genes that belong to the same disease are often arranged in a local neighborhood, so it is possible to find similar patterns in the proximity of a selected gene. Clustering approaches can be used to delineate these regions of interest.Eventually, these elements can even be used to model new layers of the multi-layer network, using them for fast filtering activities or pattern-matching based on machine learning techniques. Another interesting aspect is the network neighborhood; nearby nodes are often associated with the same phenomena. Genes that belong to the same disease are often arranged in a local neighborhood, so it is possible to find similar patterns in the proximity of a selected gene. Clustering approaches can be used to delineate these regions of interest.</p>
        <p>The link between the fields of visualization, visual analytics, and Network Medicine (summarized in Figure 5) can bring mutual improvements for different types of users: Physicians and medical personnel, as well as bioinformatics and visualization researchers and practitioners. Physicians and other medical personnel, provided with interpretable results coming from powerful automatic analysis methods, can form, test, and validate new hypotheses, eventually taking into account multiple relationships derived from the interconnected nature of a multilayer network. This effort can help to understand better a current disease under examination, test new drugs, and evaluate their effectiveness on patients, all in the same holistic and interconnected view, where visualization allows an investigator to steer the analysis and interpret and communicate the results.The link between the fields of visualization, visual analytics, and Network Medicine (summarized in Figure 5) can bring mutual improvements for different types of users: Physicians and medical personnel, as well as bioinformatics and visualization researchers and practitioners. Physicians and other medical personnel, provided with interpretable results coming from powerful automatic analysis methods, can form, test, and validate new hypotheses, eventually taking into account multiple relationships derived from the interconnected nature of a multilayer network. This effort can help to understand better a current disease under examination, test new drugs, and evaluate their effectiveness on patients, all in the same holistic and interconnected view, where visualization allows an investigator to steer the analysis and interpret and communicate the results.</p>
        <p>Despite the heavy computational cost of many of these data analysis techniques, network visualization approaches can help in conducting data exploration, fine-tuning and optimizing specific algorithms, and testing and comparing new automatic analysis techniques. Finally, for visualization researchers and practitioners, the requirements of Network Medicine can help in designing and testing new abstract visual paradigms, tailor interaction approaches to support exploration better, and investigate smoother transition techniques between views for exploration, analysis, communication, and interpretation of results, eventually advancing the state-of-the-art in the field of networks, and in particular multilayer network, representation. F I G U R E 5 The visual analytics cycle applied to Network Medicine. Data from different domains (e.g., cellular, molecular, and genetic networks) are input to two different processes, visual data exploration which exploits visualization paradigms (Node-Edge, Matrix, Chords, etc.) to represent these data and classic automated data analysis through different approaches (machine learning, network analysis algorithms, etc.). These two processes are interconnected, allowing an analyst to steer algorithms by interacting with the visual representation of results. The whole process generates new insights (e.g., relationships among networks) used as a feedback loop for new cycles of analysis Application of potent network-based algorithms represents the most fruitful way to reach useful clinical platforms for precision medicine and personalized therapy in complex diseases (Barabasi, 2007;Barabasi et al., 2011;Benincasa, Marfella, Della Mura, Schiano, &amp; Napoli, 2020, Infante et al., 2020;Menche et al., 2015). In this section, we will review several examples in which the application of network-based methods has provided pathobiological insights into conventionally defined complex diseases. In the future, Network Medicine has the potential to redefine diseases based on the molecular networks that determine their pathobiological mechanisms, instead of the conventional approach of disease diagnosis based on physiology and/or pathology.Despite the heavy computational cost of many of these data analysis techniques, network visualization approaches can help in conducting data exploration, fine-tuning and optimizing specific algorithms, and testing and comparing new automatic analysis techniques. Finally, for visualization researchers and practitioners, the requirements of Network Medicine can help in designing and testing new abstract visual paradigms, tailor interaction approaches to support exploration better, and investigate smoother transition techniques between views for exploration, analysis, communication, and interpretation of results, eventually advancing the state-of-the-art in the field of networks, and in particular multilayer network, representation. F I G U R E 5 The visual analytics cycle applied to Network Medicine. Data from different domains (e.g., cellular, molecular, and genetic networks) are input to two different processes, visual data exploration which exploits visualization paradigms (Node-Edge, Matrix, Chords, etc.) to represent these data and classic automated data analysis through different approaches (machine learning, network analysis algorithms, etc.). These two processes are interconnected, allowing an analyst to steer algorithms by interacting with the visual representation of results. The whole process generates new insights (e.g., relationships among networks) used as a feedback loop for new cycles of analysis Application of potent network-based algorithms represents the most fruitful way to reach useful clinical platforms for precision medicine and personalized therapy in complex diseases (Barabasi, 2007;Barabasi et al., 2011;Benincasa, Marfella, Della Mura, Schiano, &amp; Napoli, 2020, Infante et al., 2020;Menche et al., 2015). In this section, we will review several examples in which the application of network-based methods has provided pathobiological insights into conventionally defined complex diseases. In the future, Network Medicine has the potential to redefine diseases based on the molecular networks that determine their pathobiological mechanisms, instead of the conventional approach of disease diagnosis based on physiology and/or pathology.</p>
        <p>Pulmonary arterial hypertension (PAH) leads to fibrotic vasculopathy and endothelial dysfunction underlying heart remodeling (Chan &amp; Loscalzo, 2008). Combining network-based algorithms and modeling of epigenetic trajectories over time may be crucial to discover novel clinical biomarkers leading to precision medicine of PAH (Napoli, Benincasa, &amp; Loscalzo, 2019). Samokhin et al. (2018) have mapped fibrosis-related proteins to the human interactome and, by using the betweenness centrality (BC) analysis, revealed that the SMAD3 target neural precursor cell expressed developmentally down-regulated 9 (NEDD9) is a critical hyperaldosteronism-regulated node triggering the shift from an adaptive to maladaptive fibrotic response. Interestingly, NEDD9 reduction prevented fibrotic vascular remodeling in vivo, thus suggesting a putative novel drug target.Pulmonary arterial hypertension (PAH) leads to fibrotic vasculopathy and endothelial dysfunction underlying heart remodeling (Chan &amp; Loscalzo, 2008). Combining network-based algorithms and modeling of epigenetic trajectories over time may be crucial to discover novel clinical biomarkers leading to precision medicine of PAH (Napoli, Benincasa, &amp; Loscalzo, 2019). Samokhin et al. (2018) have mapped fibrosis-related proteins to the human interactome and, by using the betweenness centrality (BC) analysis, revealed that the SMAD3 target neural precursor cell expressed developmentally down-regulated 9 (NEDD9) is a critical hyperaldosteronism-regulated node triggering the shift from an adaptive to maladaptive fibrotic response. Interestingly, NEDD9 reduction prevented fibrotic vascular remodeling in vivo, thus suggesting a putative novel drug target.</p>
        <p>An integrated approach combining imaging modalities in the quantification of coronary atherosclerosis and novel circulating biomarkers could improve precision medicine of coronary heart disease (CHD; Infante et al., 2017). By providing additional linking proteins (seed connectors) to the seed protein pool, the Seed Connector algorithm (SCA) identified novel putative drug targets in CHD, such as the neuropilin-1 (NRP1) protein (R. S. Wang &amp; Loscalzo, 2018). Furthermore, a systems pharmacology-based platform measuring the distance between disease proteins and drug targets in the human PPI was developed (Cheng et al., 2018). Evidence from large-scale patient datasets indicated that carbamazepine and hydroxychloroquine were strongly associated with a higher and lower risk of CHD onset, respectively. Importantly, in silico applications may serve as useful tools for efficient screening of potentially new indications for approved drugs (drug repurposing), undesirable side effects, as well as potential mechanisms of drug action, thus enlarging opportunities for personalized therapy (Cheng et al., 2018;R. S. Wang &amp; Loscalzo, 2018). Sharma et al. (2018) performed a robust network-based controllability approach to construct a regulatory subnetwork in human pancreatic samples. By applying the control centrality (Cc) concept to identify high control centrality (HiCc) pathways, an enrichment of variants regulating gene expression (eQTL) was observed. Interestingly, the nuclear factor of activated T cells 4 (NFATC4) belonged to four HiCc pathways and may increase the expression of four putative downstream T2D genes, thereby implicating a potentially crucial node contributing to disease pathogenesis (Sharma et al., 2018).An integrated approach combining imaging modalities in the quantification of coronary atherosclerosis and novel circulating biomarkers could improve precision medicine of coronary heart disease (CHD; Infante et al., 2017). By providing additional linking proteins (seed connectors) to the seed protein pool, the Seed Connector algorithm (SCA) identified novel putative drug targets in CHD, such as the neuropilin-1 (NRP1) protein (R. S. Wang &amp; Loscalzo, 2018). Furthermore, a systems pharmacology-based platform measuring the distance between disease proteins and drug targets in the human PPI was developed (Cheng et al., 2018). Evidence from large-scale patient datasets indicated that carbamazepine and hydroxychloroquine were strongly associated with a higher and lower risk of CHD onset, respectively. Importantly, in silico applications may serve as useful tools for efficient screening of potentially new indications for approved drugs (drug repurposing), undesirable side effects, as well as potential mechanisms of drug action, thus enlarging opportunities for personalized therapy (Cheng et al., 2018;R. S. Wang &amp; Loscalzo, 2018). Sharma et al. (2018) performed a robust network-based controllability approach to construct a regulatory subnetwork in human pancreatic samples. By applying the control centrality (Cc) concept to identify high control centrality (HiCc) pathways, an enrichment of variants regulating gene expression (eQTL) was observed. Interestingly, the nuclear factor of activated T cells 4 (NFATC4) belonged to four HiCc pathways and may increase the expression of four putative downstream T2D genes, thereby implicating a potentially crucial node contributing to disease pathogenesis (Sharma et al., 2018).</p>
        <p>Recently, a PPI network-based approach unveiled molecular network neighborhoods for chronic obstructive pulmonary disease (COPD) and idiopathic pulmonary fibrosis (IPF), with a statistically significant region of intersection and network proximity (Halu et al., 2019). The shared network region involved 19 genes, including Rho GTPase activating protein 12 (ARHGAP12) and butyrylcholinesterase (BCHE) as key nodes. Thus, network-based strategies may also offer a potent means to dissect genes and pathways shared between phenotypically distinct diseases, such as COPD and IPF, thus offering novel insights into pathobiological mechanisms (Halu et al., 2019). In earlier work, by mapping the seed genes onto the human interactome via the DIAMOnD algorithm (Ghiassian et al., 2015), an asthma-associated network neighborhood was identified (Sharma et al., 2015). Interestingly, the asthma network module was strongly associated with two clinical phenotypes, asthma severity and poor asthma control, thus providing evidence for its putative importance in asthma pathogenesis, as well as in future precision medicine.Recently, a PPI network-based approach unveiled molecular network neighborhoods for chronic obstructive pulmonary disease (COPD) and idiopathic pulmonary fibrosis (IPF), with a statistically significant region of intersection and network proximity (Halu et al., 2019). The shared network region involved 19 genes, including Rho GTPase activating protein 12 (ARHGAP12) and butyrylcholinesterase (BCHE) as key nodes. Thus, network-based strategies may also offer a potent means to dissect genes and pathways shared between phenotypically distinct diseases, such as COPD and IPF, thus offering novel insights into pathobiological mechanisms (Halu et al., 2019). In earlier work, by mapping the seed genes onto the human interactome via the DIAMOnD algorithm (Ghiassian et al., 2015), an asthma-associated network neighborhood was identified (Sharma et al., 2015). Interestingly, the asthma network module was strongly associated with two clinical phenotypes, asthma severity and poor asthma control, thus providing evidence for its putative importance in asthma pathogenesis, as well as in future precision medicine.</p>
        <p>Clinically relevant molecular targets are often associated with only one or a few disease indications or medical specialties. This, however, may be solely because other disease areas or indications were never considered. Langhauser et al. (2018) investigated such a potential bias in a high prevalence unmet medical need cluster of disease phenotypes linked to cyclic GMP. Hitherto, the central cGMP-forming enzyme, soluble guanylate cyclase (sGC), had been targeted pharmacologically exclusively for smooth muscle modulation in cardiology (angina pectoris, heart failure, coronary heart disease) and pulmonology (PAH). The disease associations of sGC were reinvestigated in a nonhypothesis based manner to identify possibly previously unrecognized clinical indications by determining the protein-protein interactome-based proximity of the proteins within the sGC complex to the proteins associated with major common diseases (Guney, Menche, Vidal, &amp; Barabasi, 2016). To prioritize the diseases, four diseasomes were assessed based on disease-disease relationship scores. Only those links that correspond to nonspurious relationships between diseases were kept by including disease pairs that shared at least one gene (n &gt; 0); had a positive shared protein interaction score (z &gt; 0); showed symptom similarity (Jaccard index &gt;0.5); and were known to be comorbid (relative risk &gt;1) in the four diseasomes, respectively. The degree centrality of each disease within these diseasomes was calculated and then an average final centrality value was determined. To ensure that the incompleteness of the interactome data did not have a significant effect on the ranking of the diseases, the centrality of the diseases without using the interactome-based diseasome was also checked. Stroke remained as the most central disease across the diseasomes, an application that has so far not been explored clinically. Indeed, when investigating the neurological indication of this cluster with the highest unmet medical need, ischemic stroke, preclinically sGC activity was virtually absent post-stroke. Conversely, a heme-free form of sGC, apo-sGC, was now the predominant isoform suggesting it may be a mechanism-based target in stroke. Indeed, this repurposing hypothesis could be validated experimentally in vivo as specific activators of apo-sGC were directly neuroprotective, reduced cerebral infarct size and increased survival. Thus, common mechanism clusters of the diseasome allow direct drug repurposing across previously unrelated disease phenotypes redefining them in a mechanism-based manner.Clinically relevant molecular targets are often associated with only one or a few disease indications or medical specialties. This, however, may be solely because other disease areas or indications were never considered. Langhauser et al. (2018) investigated such a potential bias in a high prevalence unmet medical need cluster of disease phenotypes linked to cyclic GMP. Hitherto, the central cGMP-forming enzyme, soluble guanylate cyclase (sGC), had been targeted pharmacologically exclusively for smooth muscle modulation in cardiology (angina pectoris, heart failure, coronary heart disease) and pulmonology (PAH). The disease associations of sGC were reinvestigated in a nonhypothesis based manner to identify possibly previously unrecognized clinical indications by determining the protein-protein interactome-based proximity of the proteins within the sGC complex to the proteins associated with major common diseases (Guney, Menche, Vidal, &amp; Barabasi, 2016). To prioritize the diseases, four diseasomes were assessed based on disease-disease relationship scores. Only those links that correspond to nonspurious relationships between diseases were kept by including disease pairs that shared at least one gene (n &gt; 0); had a positive shared protein interaction score (z &gt; 0); showed symptom similarity (Jaccard index &gt;0.5); and were known to be comorbid (relative risk &gt;1) in the four diseasomes, respectively. The degree centrality of each disease within these diseasomes was calculated and then an average final centrality value was determined. To ensure that the incompleteness of the interactome data did not have a significant effect on the ranking of the diseases, the centrality of the diseases without using the interactome-based diseasome was also checked. Stroke remained as the most central disease across the diseasomes, an application that has so far not been explored clinically. Indeed, when investigating the neurological indication of this cluster with the highest unmet medical need, ischemic stroke, preclinically sGC activity was virtually absent post-stroke. Conversely, a heme-free form of sGC, apo-sGC, was now the predominant isoform suggesting it may be a mechanism-based target in stroke. Indeed, this repurposing hypothesis could be validated experimentally in vivo as specific activators of apo-sGC were directly neuroprotective, reduced cerebral infarct size and increased survival. Thus, common mechanism clusters of the diseasome allow direct drug repurposing across previously unrelated disease phenotypes redefining them in a mechanism-based manner.</p>
        <p>Drug discovery mainly focuses on single molecular targets. Mechanism-based disease definitions would, however, frequently be networks targeted by multiple compound synergy and network pharmacology. Beginning with a primary causal target, Casas et al. (2019) extended a validated seed protein to a second protein using guilt-byassociation analysis and then validated the prediction and synergy using both cellular in vitro and in vivo models. As a disease model, they chose ischemic stroke, and reactive oxygen species forming NADPH oxidase type 4 (Nox4) as a primary causal therapeutic target. For network analysis, they used classical PPIs but also metabolite-dependent interactions, assuming that signaling events may occur in a non-PPI manner. Based on this protein-metabolite network, they conducted a gene ontology-based semantic similarity ranking to find suitable synergistic co-targets for network pharmacology. They then identified the nitric oxide synthase (Nos) gene family as the closest target to Nox4. Indeed, when combining a NOS and a NOX inhibitor at subthreshold concentrations, they observed pharmacological synergy in a supra-additive manner suggesting a causal network comprised of Nox4 and Nos signaling. Thus, protein-metabolite network analysis can predict and pair synergistic mechanistic disease targets for network pharmacology, an approach that may reduce the risk of failure and increase the efficacy of single-target drug discovery and therapy approaches.Drug discovery mainly focuses on single molecular targets. Mechanism-based disease definitions would, however, frequently be networks targeted by multiple compound synergy and network pharmacology. Beginning with a primary causal target, Casas et al. (2019) extended a validated seed protein to a second protein using guilt-byassociation analysis and then validated the prediction and synergy using both cellular in vitro and in vivo models. As a disease model, they chose ischemic stroke, and reactive oxygen species forming NADPH oxidase type 4 (Nox4) as a primary causal therapeutic target. For network analysis, they used classical PPIs but also metabolite-dependent interactions, assuming that signaling events may occur in a non-PPI manner. Based on this protein-metabolite network, they conducted a gene ontology-based semantic similarity ranking to find suitable synergistic co-targets for network pharmacology. They then identified the nitric oxide synthase (Nos) gene family as the closest target to Nox4. Indeed, when combining a NOS and a NOX inhibitor at subthreshold concentrations, they observed pharmacological synergy in a supra-additive manner suggesting a causal network comprised of Nox4 and Nos signaling. Thus, protein-metabolite network analysis can predict and pair synergistic mechanistic disease targets for network pharmacology, an approach that may reduce the risk of failure and increase the efficacy of single-target drug discovery and therapy approaches.</p>
        <p>Drug-based networks (for which we propose the term "drugome") may be especially relevant for translational Network Medicine and network validation. These networks include pluripotent drugs (effective in more than one disease) or promiscuous drugs (having more than one binding target). Both drug interactions and resulting drug networks offer the possibility of discovering drug repurposing opportunities for clinical validation. Hu and Agarwal (2009) performed a systematic, large-scale analysis of genomic expression profiles of human diseases and drugs to create a disease-drug network. A network of 170,027 significant interactions was extracted from comparisons between publicly available transcriptomic profiles. The network included primarily disease-drug and drug-drug relationships. Among the diseasedrug links, connections with negative scores suggested new indications for existing drugs, while positive scoring connections may aid in drug side effect identification. Drug-drug relationships may aid in target and pathway deconvolution. The relevance of drug-drug networks is further enhanced by the recent observation of the detection of molecular interaction field similarities which provide further opportunities for drug repurposing as well as to identify potential molecular mechanisms responsible for side-effects. Chartier, Morency, Zylber, and Najmanovich (2017) performed a large-scale analysis to detect binding-site molecular interaction field similarities between the binding-sites of the primary target of registered drugs against a nonredundant dataset of all proteins with known structure. They found 140 unique drugs and 1,216 unique potential cross-reactivity protein targets. This expands the potential for drug repurposing for small molecules from the orthologous target to several so-called "off-targets."Drug-based networks (for which we propose the term "drugome") may be especially relevant for translational Network Medicine and network validation. These networks include pluripotent drugs (effective in more than one disease) or promiscuous drugs (having more than one binding target). Both drug interactions and resulting drug networks offer the possibility of discovering drug repurposing opportunities for clinical validation. Hu and Agarwal (2009) performed a systematic, large-scale analysis of genomic expression profiles of human diseases and drugs to create a disease-drug network. A network of 170,027 significant interactions was extracted from comparisons between publicly available transcriptomic profiles. The network included primarily disease-drug and drug-drug relationships. Among the diseasedrug links, connections with negative scores suggested new indications for existing drugs, while positive scoring connections may aid in drug side effect identification. Drug-drug relationships may aid in target and pathway deconvolution. The relevance of drug-drug networks is further enhanced by the recent observation of the detection of molecular interaction field similarities which provide further opportunities for drug repurposing as well as to identify potential molecular mechanisms responsible for side-effects. Chartier, Morency, Zylber, and Najmanovich (2017) performed a large-scale analysis to detect binding-site molecular interaction field similarities between the binding-sites of the primary target of registered drugs against a nonredundant dataset of all proteins with known structure. They found 140 unique drugs and 1,216 unique potential cross-reactivity protein targets. This expands the potential for drug repurposing for small molecules from the orthologous target to several so-called "off-targets."</p>
        <p>Network Medicine may effectively overcome the limitations of the current reductionist approach to medical research by using a "deep phenotyping" strategy that combines heterogeneous Big Data and clinical information, lifestyle, and nutritional habits to provide a map of the aberrant signaling pathways interlinked with each other layer of knowledge at the individual level. Epigenetic-sensitive changes represent a bridge between genome and environment during earlylife development, providing novel insights into the "epigenetic transgenerational effect" hypothesis, a topic that deserves further investigation in humans (Benincasa et al., 2019;Napoli et al., 2012;Napoli et al., 2019). The abovementioned network-oriented biomarkers could be useful to prevent, diagnose, and monitor complex diseases as well as to offer novel drug targets providing the opportunity of repurposing previously approved drugs for other diseases (Cheng et al., 2018). Moreover, Sanchez-Vega et al. (2018) emphasized the possibility that the high intra-and interindividual heterogeneity of a specific type of cancer could be dissected by the underlying pathway abnormalities leading to a molecular-based diagnostic platform that could be more effective than traditional approaches. Long-term clinical trials are needed to validate these molecular networks and machine learning predictive models, providing a huge opportunity for precision medicine and personalized therapy of complex diseases. Importantly, Network Medicine is now focusing on the ongoing "Foodome" project (https://www.barabasilab.com/projects) based on the relationship between specific food (bio)chemicals and consumption behaviors, linking this to health and disease outcomes. In the future, these efforts may unveil crucial information about the relationships between epigenetic sensors and lifestyle/ nutritional habits as one of the most important risk factors for diabetes, cardiovascular diseases, and cancer. These advances in Network Medicine have the potential to lead to important clinical applications (Figure 6) with more personalized and effective treatments.Network Medicine may effectively overcome the limitations of the current reductionist approach to medical research by using a "deep phenotyping" strategy that combines heterogeneous Big Data and clinical information, lifestyle, and nutritional habits to provide a map of the aberrant signaling pathways interlinked with each other layer of knowledge at the individual level. Epigenetic-sensitive changes represent a bridge between genome and environment during earlylife development, providing novel insights into the "epigenetic transgenerational effect" hypothesis, a topic that deserves further investigation in humans (Benincasa et al., 2019;Napoli et al., 2012;Napoli et al., 2019). The abovementioned network-oriented biomarkers could be useful to prevent, diagnose, and monitor complex diseases as well as to offer novel drug targets providing the opportunity of repurposing previously approved drugs for other diseases (Cheng et al., 2018). Moreover, Sanchez-Vega et al. (2018) emphasized the possibility that the high intra-and interindividual heterogeneity of a specific type of cancer could be dissected by the underlying pathway abnormalities leading to a molecular-based diagnostic platform that could be more effective than traditional approaches. Long-term clinical trials are needed to validate these molecular networks and machine learning predictive models, providing a huge opportunity for precision medicine and personalized therapy of complex diseases. Importantly, Network Medicine is now focusing on the ongoing "Foodome" project (https://www.barabasilab.com/projects) based on the relationship between specific food (bio)chemicals and consumption behaviors, linking this to health and disease outcomes. In the future, these efforts may unveil crucial information about the relationships between epigenetic sensors and lifestyle/ nutritional habits as one of the most important risk factors for diabetes, cardiovascular diseases, and cancer. These advances in Network Medicine have the potential to lead to important clinical applications (Figure 6) with more personalized and effective treatments.</p>
        <p>Although Network Medicine studies have already led to substantial progress, there are important knowledge gaps that have limited the impact of network-based analysis on clinical practice. We will review some of these key limitations and suggest future directions for Network Medicine research.Although Network Medicine studies have already led to substantial progress, there are important knowledge gaps that have limited the impact of network-based analysis on clinical practice. We will review some of these key limitations and suggest future directions for Network Medicine research.</p>
        <p>Notwithstanding huge advances in systematic protein-protein interaction mapping technologies (Y2H-or MS-based; Luck, Sheynkman, Zhang, &amp; Vidal, 2017;Rolland et al., 2014;Smits &amp; Vermeulen, 2016), it is estimated that the coverage of the human molecular interactome accounts for only about 20% of all potential pairwise interactions (Menche et al., 2015). Since many Network Medicine approaches are based on the topology of the molecular interactome (e.g., disease modules, connectivity patterns, centrality measures, etc.), interactome incompleteness is undeniably a hurdle. Attempts have been carried out to evaluate the impact of such incompleteness, leading to hypotheses that disease modules linked to &lt;25 disease genes are likely to be fragmented and are difficult to detect in the current molecular interactome model (Menche et al., 2015). In such a landscape, computational predictive mapping approaches can come to the rescue and complement experimental high-throughput methods, providing reliable de novo PPI detection (Kotlyar, Rossos, &amp; Jurisica, 2017). These approaches are based on genomic or functional data (Gandhi et al., 2006;X. Wang &amp; Jin, 2017), on protein structure and dynamics (often coupled with machine learning techniques; Ehrenberger, Cantley, &amp; Yaffe, 2015; Q. C. Zhang et al., 2012), or on techniques derived from social links inference methods, for example, based on the triad closure principle (TCP; Bianconi, Darst, Iacovacci, &amp; Fortunato, 2014), or on paths of length three (L3; Kovacs et al., 2019).Notwithstanding huge advances in systematic protein-protein interaction mapping technologies (Y2H-or MS-based; Luck, Sheynkman, Zhang, &amp; Vidal, 2017;Rolland et al., 2014;Smits &amp; Vermeulen, 2016), it is estimated that the coverage of the human molecular interactome accounts for only about 20% of all potential pairwise interactions (Menche et al., 2015). Since many Network Medicine approaches are based on the topology of the molecular interactome (e.g., disease modules, connectivity patterns, centrality measures, etc.), interactome incompleteness is undeniably a hurdle. Attempts have been carried out to evaluate the impact of such incompleteness, leading to hypotheses that disease modules linked to &lt;25 disease genes are likely to be fragmented and are difficult to detect in the current molecular interactome model (Menche et al., 2015). In such a landscape, computational predictive mapping approaches can come to the rescue and complement experimental high-throughput methods, providing reliable de novo PPI detection (Kotlyar, Rossos, &amp; Jurisica, 2017). These approaches are based on genomic or functional data (Gandhi et al., 2006;X. Wang &amp; Jin, 2017), on protein structure and dynamics (often coupled with machine learning techniques; Ehrenberger, Cantley, &amp; Yaffe, 2015; Q. C. Zhang et al., 2012), or on techniques derived from social links inference methods, for example, based on the triad closure principle (TCP; Bianconi, Darst, Iacovacci, &amp; Fortunato, 2014), or on paths of length three (L3; Kovacs et al., 2019).</p>
        <p>It is also worth mentioning the need to go beyond pairwise interactions, for example, by probing multi-protein interactions, to predict the behavior of larger protein complexes, operative scaffolds on which most cellular processes rely (Hur, Chen, &amp; Mueller, 2016), as well as the attempts to characterize the so-called "negatome", that is, the set of proteins that are unlikely to engage in physical interactions. The negatome is potentially useful for training PPI predictive algorithms and for assessing the false-positive rates of PPI detection attempts (Mao et al., 2014). Although the limitations of interactome incompleteness are problematic for protein-protein interaction networks, all network methods that rely on databases of molecular connections (e.g., transcription factor binding sites) will be susceptible to false-negative network connections due to incomplete mapping of molecular relationships and false-positive network connections due to technical artifacts. For example, protein metabolites (substrates and products) are often missing in metabolite databases. Casas et al. (2019) needed to include hydrogen peroxide as a metabolite of NOX to implicate NOS in ischemic stroke pathogenesis.It is also worth mentioning the need to go beyond pairwise interactions, for example, by probing multi-protein interactions, to predict the behavior of larger protein complexes, operative scaffolds on which most cellular processes rely (Hur, Chen, &amp; Mueller, 2016), as well as the attempts to characterize the so-called "negatome", that is, the set of proteins that are unlikely to engage in physical interactions. The negatome is potentially useful for training PPI predictive algorithms and for assessing the false-positive rates of PPI detection attempts (Mao et al., 2014). Although the limitations of interactome incompleteness are problematic for protein-protein interaction networks, all network methods that rely on databases of molecular connections (e.g., transcription factor binding sites) will be susceptible to false-negative network connections due to incomplete mapping of molecular relationships and false-positive network connections due to technical artifacts. For example, protein metabolites (substrates and products) are often missing in metabolite databases. Casas et al. (2019) needed to include hydrogen peroxide as a metabolite of NOX to implicate NOS in ischemic stroke pathogenesis.</p>
        <p>Although GWAS have identified thousands of associations between genetic variants and complex diseases that withstand stringent adjustments for multiple statistical testing, the functional variants within those GWAS loci and the genes that they influence are known in only a small minority of GWAS regions (Silverman, 2018). Most complex disease genetic variants are located in noncoding regions, and they often do not regulate the nearest gene (Baranski et al., 2018). These uncertainties limit the accuracy of selection of GWAS "seed" genes for protein-protein interaction network studies. Moreover, since GWAS evidence has been used to support findings from other types of molecular networks (e.g., correlation, gene regulatory), the application of GWAS results in these contexts is also limited by the lack of functional dissection of GWAS statistical associations. Thus, although GWAS can provide reasonably comprehensive assessments of the common genetic variants influencing a complex disease, applying these results to molecular network studies remains challenging. Finding functional variants and the genes that they influence within GWAS loci are active areas of research (Musunuru et al., 2018).Although GWAS have identified thousands of associations between genetic variants and complex diseases that withstand stringent adjustments for multiple statistical testing, the functional variants within those GWAS loci and the genes that they influence are known in only a small minority of GWAS regions (Silverman, 2018). Most complex disease genetic variants are located in noncoding regions, and they often do not regulate the nearest gene (Baranski et al., 2018). These uncertainties limit the accuracy of selection of GWAS "seed" genes for protein-protein interaction network studies. Moreover, since GWAS evidence has been used to support findings from other types of molecular networks (e.g., correlation, gene regulatory), the application of GWAS results in these contexts is also limited by the lack of functional dissection of GWAS statistical associations. Thus, although GWAS can provide reasonably comprehensive assessments of the common genetic variants influencing a complex disease, applying these results to molecular network studies remains challenging. Finding functional variants and the genes that they influence within GWAS loci are active areas of research (Musunuru et al., 2018).</p>
        <p>F I G U R E 6 The Network Medicine approach and its putative clinical applications. The main goal of Network Medicine is to provide holistic, network-based approaches for disease classification and drug target selection. This molecularbioinformatics approach has the potential to improve both the quality of care and the quality of life of patients affected by complex diseases 8.3 | Limited application to human samples and diseases: The gap between systems biology and network medicine There still are many hurdles to the successful and profitable deployment of Network Medicine approaches in the clinical context. Some of these bottlenecks and gridlocks include: (a) the strong focus on smaller biological systems typical of Systems Biology studies, which is often difficult to scale to the organism-level required in clinical practice, owing to the inherent limits of the conclusions to the specific experimental/biological context (e.g., signaling pathways, gene regulatory networks in cellular processes such as differentiation, etc.); (b) a large number of scientific hypotheses can be generated via network biology and Network Medicine methods, with a parallel need for robust testing and solid validation, that is, basic needs in the clinical context; (c) the difficulties in gathering supporting, coherent, and secured data in clinical settings; and (d) the nature and the structure of clinical and medical data, with their own complexity, schemas, ontologies, and access restrictions, and the necessity to link them unequivocally with clinical samples. From this perspective, meta-analyses can have the capability to increase statistical power and generalizability of single-study analysis (B. Chen &amp; Butte, 2013;Wolkenhauer, Auffray, Jaster, Steinhoff, &amp; Dammann, 2013;Wolkenhauer et al., 2009). Comparing different networks is a challenging task when nodes can differ between networks (recently reviewed by Tantardini, Ieva, Tajoli, and Piccardi (2019)), which can be addressed with approaches based on graphlets, spectral methods, and portrait divergence.F I G U R E 6 The Network Medicine approach and its putative clinical applications. The main goal of Network Medicine is to provide holistic, network-based approaches for disease classification and drug target selection. This molecularbioinformatics approach has the potential to improve both the quality of care and the quality of life of patients affected by complex diseases 8.3 | Limited application to human samples and diseases: The gap between systems biology and network medicine There still are many hurdles to the successful and profitable deployment of Network Medicine approaches in the clinical context. Some of these bottlenecks and gridlocks include: (a) the strong focus on smaller biological systems typical of Systems Biology studies, which is often difficult to scale to the organism-level required in clinical practice, owing to the inherent limits of the conclusions to the specific experimental/biological context (e.g., signaling pathways, gene regulatory networks in cellular processes such as differentiation, etc.); (b) a large number of scientific hypotheses can be generated via network biology and Network Medicine methods, with a parallel need for robust testing and solid validation, that is, basic needs in the clinical context; (c) the difficulties in gathering supporting, coherent, and secured data in clinical settings; and (d) the nature and the structure of clinical and medical data, with their own complexity, schemas, ontologies, and access restrictions, and the necessity to link them unequivocally with clinical samples. From this perspective, meta-analyses can have the capability to increase statistical power and generalizability of single-study analysis (B. Chen &amp; Butte, 2013;Wolkenhauer, Auffray, Jaster, Steinhoff, &amp; Dammann, 2013;Wolkenhauer et al., 2009). Comparing different networks is a challenging task when nodes can differ between networks (recently reviewed by Tantardini, Ieva, Tajoli, and Piccardi (2019)), which can be addressed with approaches based on graphlets, spectral methods, and portrait divergence.</p>
        <p>A complete validation process should eventually lead to the enactment of qualified, standardized, partially automated protocols and workflows, able and tailored to work in highly dynamical clinical settings. Furthermore, often neglected, key points reside in the fact that models and findings should not be byzantine from a clinical perspective (see also considerations about "black boxes" in the next paragraph), as well as in the structure of the healthcare system, that will be required to adapt drastically to operate with multidisciplinary teams, working with multi-omics data, largescale data storage facilities, standard analytical pipelines, and specific managerial frameworks. All of these processes demand specific education and complementary formations for hospital personnel in the context of larger training programs (Hood, 2013;Noell, Faner, &amp; Agusti, 2018).A complete validation process should eventually lead to the enactment of qualified, standardized, partially automated protocols and workflows, able and tailored to work in highly dynamical clinical settings. Furthermore, often neglected, key points reside in the fact that models and findings should not be byzantine from a clinical perspective (see also considerations about "black boxes" in the next paragraph), as well as in the structure of the healthcare system, that will be required to adapt drastically to operate with multidisciplinary teams, working with multi-omics data, largescale data storage facilities, standard analytical pipelines, and specific managerial frameworks. All of these processes demand specific education and complementary formations for hospital personnel in the context of larger training programs (Hood, 2013;Noell, Faner, &amp; Agusti, 2018).</p>
        <p>The development of CRISPR technology has literally transfigured the capability of genome editing and has opened unique scenarios to analyze pathways and biological networks at the level of single-nucleotide specificity (Jinek et al., 2012). To demonstrate the impact that new molecular technologies can exert on network biology and Network Medicine, Li, Nowak, Withers, Pertsemlidis, and Bleris (2018) used CRISPR for outlining the role of network edges compared to that of nodes; they targeted a number of miRNA sites in 71 genes involved in the p53 pathway, ablating numerous edges and thus demonstrating their essentiality for the pathway function and stability. From this perspective, CRISPR editing in biological network analysis seems to provide a finer resolution tool compared to more disruptive node removal techniques, potentially leading to the identification of previously hidden interactions and more opportunities for therapeutic intervention.The development of CRISPR technology has literally transfigured the capability of genome editing and has opened unique scenarios to analyze pathways and biological networks at the level of single-nucleotide specificity (Jinek et al., 2012). To demonstrate the impact that new molecular technologies can exert on network biology and Network Medicine, Li, Nowak, Withers, Pertsemlidis, and Bleris (2018) used CRISPR for outlining the role of network edges compared to that of nodes; they targeted a number of miRNA sites in 71 genes involved in the p53 pathway, ablating numerous edges and thus demonstrating their essentiality for the pathway function and stability. From this perspective, CRISPR editing in biological network analysis seems to provide a finer resolution tool compared to more disruptive node removal techniques, potentially leading to the identification of previously hidden interactions and more opportunities for therapeutic intervention.</p>
        <p>Advanced analytical approaches, such as machine learning (ML) and deep neural networks (DNNs), are becoming a powerful and essential phase of modern biology and medical investigative workflows. Several successful applications have already been enumerated, such as achievements in the predictions of protein binding interactions, in inferring gene regulatory networks, in predicting metabolic functions, in genome annotation, and in the discovery of key transcriptional regulators involved in cancer, among other diseases (Sonawane, Weiss, Glass, &amp; Sharma, 2019). Notwithstanding the many successes and the new opportunities offered, there remain daunting challenges to be faced, including the insatiable hunger for data of ML and DNN algorithms, for which, paradoxically, even the current biological data deluge is insufficient. Options to engage with such challenges with a focus on medicine and public health include the provision, availability and exploitation of larger, curated, formatted and open multi-omic datasets combined with robust, standardized, and curated clinical phenotypic data (Mooney &amp; Pejaver, 2018;Vanschoren, van Rijn, Bischl, &amp; Torgo, 2013); and, from the algorithmic side, the commitment in the development of new ML approaches able to deal with smaller datasets, which are already in progress in fields other than biology and medicine (Y. Zhang &amp; Ling, 2018). The use of simulated data displaying the same attributes of experimental data-as already largely implemented in the setup of GWAS analysis tools (Dudek, Motsinger, Velez, Williams, &amp; Ritchie, 2006)-is also viable, for example through the exploitation of the recent generative adversarial networks (GANs), a DNN architecture employing two neural networks that compete one against the other, one generating data that simulate the training (real) dataset (the generator), and the other recognizing if the simulated data belong to the training set (the adversary), until the "conflict" is resolved by simulating data that are indistinguishable from the real data (Ghasedi Dizaji, Wang, &amp; Huang, 2018).Advanced analytical approaches, such as machine learning (ML) and deep neural networks (DNNs), are becoming a powerful and essential phase of modern biology and medical investigative workflows. Several successful applications have already been enumerated, such as achievements in the predictions of protein binding interactions, in inferring gene regulatory networks, in predicting metabolic functions, in genome annotation, and in the discovery of key transcriptional regulators involved in cancer, among other diseases (Sonawane, Weiss, Glass, &amp; Sharma, 2019). Notwithstanding the many successes and the new opportunities offered, there remain daunting challenges to be faced, including the insatiable hunger for data of ML and DNN algorithms, for which, paradoxically, even the current biological data deluge is insufficient. Options to engage with such challenges with a focus on medicine and public health include the provision, availability and exploitation of larger, curated, formatted and open multi-omic datasets combined with robust, standardized, and curated clinical phenotypic data (Mooney &amp; Pejaver, 2018;Vanschoren, van Rijn, Bischl, &amp; Torgo, 2013); and, from the algorithmic side, the commitment in the development of new ML approaches able to deal with smaller datasets, which are already in progress in fields other than biology and medicine (Y. Zhang &amp; Ling, 2018). The use of simulated data displaying the same attributes of experimental data-as already largely implemented in the setup of GWAS analysis tools (Dudek, Motsinger, Velez, Williams, &amp; Ritchie, 2006)-is also viable, for example through the exploitation of the recent generative adversarial networks (GANs), a DNN architecture employing two neural networks that compete one against the other, one generating data that simulate the training (real) dataset (the generator), and the other recognizing if the simulated data belong to the training set (the adversary), until the "conflict" is resolved by simulating data that are indistinguishable from the real data (Ghasedi Dizaji, Wang, &amp; Huang, 2018).</p>
        <p>Finally, it is important to mention the fact that many advanced ML approaches work as "black boxes," hiding the importance and the correlation of a set of features from the outcome (i.e., its biological interpretation), thus hindering the deployment of predictive models because ultimately, humans do not understand-nor trust-them (Camacho, Collins, Powers, Costello, &amp; Collins, 2018). To overcome this issue, several efforts are being pursued in providing interpretable ML approaches able to balance interpretability, accuracy, and computational viability (Lakkaraju, Bach, &amp; Leskovec, 2016;M. K. Yu et al., 2018).Finally, it is important to mention the fact that many advanced ML approaches work as "black boxes," hiding the importance and the correlation of a set of features from the outcome (i.e., its biological interpretation), thus hindering the deployment of predictive models because ultimately, humans do not understand-nor trust-them (Camacho, Collins, Powers, Costello, &amp; Collins, 2018). To overcome this issue, several efforts are being pursued in providing interpretable ML approaches able to balance interpretability, accuracy, and computational viability (Lakkaraju, Bach, &amp; Leskovec, 2016;M. K. Yu et al., 2018).</p>
        <p>ofof</p>
        <p>SILVERMAN ET AL.SILVERMAN ET AL.</p>
        <p>This article was written by the Molecular Networks Working Group of the International Network Medicine Consortium. We thank the other consortium members for their comments and ideas relevant to this manuscript. E.K.S.: Supported by National Institutes of Health (USA) grants U01 HL089856, P01 HL114501, R01 HL133135, R01 HL 137927, and R01 HL147148. H.H.H.W.S.: Supported by REPO-TRIAL: This project has received funding from the European Union's Horizon 2020 Research and Innovation Program under grant agreement No. 777111. This reflects only the author's view and the European Commission is not responsible for any use that may be made of the information it contains. Supported by FeatureCloud: This project has received funding from the European Union's Horizon 2020 Research and Innovation Program under grant agreement No 826078. This reflects only the author's view and the European Commission is not responsible for any use that may be made of the information it contains. Supported by SAVEBRAIN: This project has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 Research and Innovation Program under grant agreement No. 737586. This reflects only the author's view and the European Commission is not responsible for any use that may be made of the information it contains. E.A.: None reported. L.A.: Supported by VALERE: Vanvitelli per la Ricerca, the Italian Association for Cancer Research (AIRC-17217), MIUR20152TE5PK, iCURE (CUP B21c17000030007), FASE 2: IDEAL (CUP B63D18000560007), MIUR, proof of concept, CUP:B64I19000290008. M.A.: None reported. L.B. and G.This article was written by the Molecular Networks Working Group of the International Network Medicine Consortium. We thank the other consortium members for their comments and ideas relevant to this manuscript. E.K.S.: Supported by National Institutes of Health (USA) grants U01 HL089856, P01 HL114501, R01 HL133135, R01 HL 137927, and R01 HL147148. H.H.H.W.S.: Supported by REPO-TRIAL: This project has received funding from the European Union's Horizon 2020 Research and Innovation Program under grant agreement No. 777111. This reflects only the author's view and the European Commission is not responsible for any use that may be made of the information it contains. Supported by FeatureCloud: This project has received funding from the European Union's Horizon 2020 Research and Innovation Program under grant agreement No 826078. This reflects only the author's view and the European Commission is not responsible for any use that may be made of the information it contains. Supported by SAVEBRAIN: This project has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 Research and Innovation Program under grant agreement No. 737586. This reflects only the author's view and the European Commission is not responsible for any use that may be made of the information it contains. E.A.: None reported. L.A.: Supported by VALERE: Vanvitelli per la Ricerca, the Italian Association for Cancer Research (AIRC-17217), MIUR20152TE5PK, iCURE (CUP B21c17000030007), FASE 2: IDEAL (CUP B63D18000560007), MIUR, proof of concept, CUP:B64I19000290008. M.A.: None reported. L.B. and G.</p>
        <p>V.: Supported by Plan Nacional de Salud (PNS) [SAF2016-76819-R to L.B. and PGC2018-094025-B-I00 to G.V.] from the Spanish Ministry of Science and Innovation and funds FEDER "Una Manera de Hacer Europa" and CIBERCV (to L.B.). We thank the support of the Generalitat of Catalunya (Secretaria d'Universitats i Recerca del Departament d'Economia i Coneixement de la Generalitat, 2017 SGR 1480) and the Fundación Investigación Cardiovascular-Fundación Jesus Serra for their continuous support. J.-L.B.: Supported by a WELBIO-Fonds National de la Recherche Scientifique grant funded by the Walloon Region (AGR-REN-X500220F-35045981). G.B.: As a PhD student of Translational Medicine, she is supported by an Educational Grant from the University of Campania "Luigi Vanvitelli", Naples, Italy. G.C.: None reported. F.C.: None reported. A.D.C.: Supported by VALERE: Vanvitelli per la Ricerca, the Italian Association for Cancer Research (AIRC-17217), MIUR20152TE5PK, iCURE (CUP B21c17000030007), FASE 2: IDEAL (CUP B63D18000560007), MIUR, proof of concept, CUP:B64I19000290008. L.F.: None reported. G.F.: None reported. L.G.: None reported. M.G.: Partially supported by grant number AR11916B32035A1F from Progetti per Avvio alla Ricerca -Tipo 1 Sapienza University of Rome, Italy. J.L.: Supported by National Institutes of Health (USA) grants U54 HL1191145, U01 HG007690, and P50 GM107618, and American Heart Association grant 700382. C.M.: PRIN 2017 n. 2017F8ZB89_002 Minister of Health (ERC LS_7). C.N.: Supported by grant number PRIN2017F8ZB89 from Italian Ministry of Research (PI: Prof Napoli). P.P.: None reported. M.P.: None reported. J.Q.: Supported by National Institutes of Health (USA) grants R01HL111759, P01HL105339, and 1R35CA220523. P.T.: Partially supported by the EU H2020 project "iPC Individualized Pediatric Cure", grant agreement No. 826121, and from COST project CA15120 OpenMultiMed. D.V.: None reported. K.G.: Supported by grant number K25HL133599 from the National Heart, Lung, and Blood Institute of the National Institutes of Health, USA. J.B.: Supported by H2020 grants RepoTrial (nr. 777111) and FeatureCloud (nr. 826078), as well as DFG Collaborative Research Centers Microbial Signatures (SFB1371) and Molecular Mechanisms in Plants (SFB924), and his VILLUM Young Investigator grant (nr. 13154). CONFLICT OF INTEREST E.K.S. received grant support from GSK and Bayer. J.L.-cofounder of Scipher Medicine, Inc. biotech start-up, uses network medicine strategies to define biomarkers of therapeutic efficacy and to repurpose drugs. The other authors have declared no conflicts of interest for this article.V.: Supported by Plan Nacional de Salud (PNS) [SAF2016-76819-R to L.B. and PGC2018-094025-B-I00 to G.V.] from the Spanish Ministry of Science and Innovation and funds FEDER "Una Manera de Hacer Europa" and CIBERCV (to L.B.). We thank the support of the Generalitat of Catalunya (Secretaria d'Universitats i Recerca del Departament d'Economia i Coneixement de la Generalitat, 2017 SGR 1480) and the Fundación Investigación Cardiovascular-Fundación Jesus Serra for their continuous support. J.-L.B.: Supported by a WELBIO-Fonds National de la Recherche Scientifique grant funded by the Walloon Region (AGR-REN-X500220F-35045981). G.B.: As a PhD student of Translational Medicine, she is supported by an Educational Grant from the University of Campania "Luigi Vanvitelli", Naples, Italy. G.C.: None reported. F.C.: None reported. A.D.C.: Supported by VALERE: Vanvitelli per la Ricerca, the Italian Association for Cancer Research (AIRC-17217), MIUR20152TE5PK, iCURE (CUP B21c17000030007), FASE 2: IDEAL (CUP B63D18000560007), MIUR, proof of concept, CUP:B64I19000290008. L.F.: None reported. G.F.: None reported. L.G.: None reported. M.G.: Partially supported by grant number AR11916B32035A1F from Progetti per Avvio alla Ricerca -Tipo 1 Sapienza University of Rome, Italy. J.L.: Supported by National Institutes of Health (USA) grants U54 HL1191145, U01 HG007690, and P50 GM107618, and American Heart Association grant 700382. C.M.: PRIN 2017 n. 2017F8ZB89_002 Minister of Health (ERC LS_7). C.N.: Supported by grant number PRIN2017F8ZB89 from Italian Ministry of Research (PI: Prof Napoli). P.P.: None reported. M.P.: None reported. J.Q.: Supported by National Institutes of Health (USA) grants R01HL111759, P01HL105339, and 1R35CA220523. P.T.: Partially supported by the EU H2020 project "iPC Individualized Pediatric Cure", grant agreement No. 826121, and from COST project CA15120 OpenMultiMed. D.V.: None reported. K.G.: Supported by grant number K25HL133599 from the National Heart, Lung, and Blood Institute of the National Institutes of Health, USA. J.B.: Supported by H2020 grants RepoTrial (nr. 777111) and FeatureCloud (nr. 826078), as well as DFG Collaborative Research Centers Microbial Signatures (SFB1371) and Molecular Mechanisms in Plants (SFB924), and his VILLUM Young Investigator grant (nr. 13154). CONFLICT OF INTEREST E.K.S. received grant support from GSK and Bayer. J.L.-cofounder of Scipher Medicine, Inc. biotech start-up, uses network medicine strategies to define biomarkers of therapeutic efficacy and to repurpose drugs. The other authors have declared no conflicts of interest for this article.</p>
        <p>Funding information DFG Collaborative Research Centers Microbial Signatures, Grant/Award Number: SFB1371; DFG Collaborative Research Centers Molecular Mechanisms in Plants, Grant/Award Number: SFB924; European Cooperation in Science and Technology, Grant/Award Number: CA15120; Horizon 2020 Framework Programme, Grant/Award Numbers: 737586, 777111, 826078, 826121; Italian Ministry of Research, Grant/Award Number: PRIN2017F8ZB89; Ministero dell'Istruzione, dell'Università e della Ricerca, Grant/Award Number: MIUR20152TE5PK; National Institutes of Health, Grant/Award Numbers: 1R35CA220523, K25HL133599, P01HL105339, P01HL114501, P50GM107618, R01HL111759, R01HL133135, R01HL137927, R01HL147148, U01HG007690, U01HL089856, U54HL1191145; Plan Nacional de Salud Spanish Ministry of Science and Innovation, Grant/Award Numbers: PGC2018-094025-B-100, SAF2016-76819-R; Progetti per Avvio alla Ricerca, Grant/Award Number: AR11916B32035A1F; VALERE: Vanvitelli per la Ricerca, the Italian Association for Cancer Research, Grant/Award Number: AIRC-17217; Villum Young Investigator Grant, Grant/Award Number: 13154; WELBIO-Fonds National de la Recherche Scientifique grant funded by the Walloon Region, Grant/Award Number: AGR-REN-X500220F-35045981Funding information DFG Collaborative Research Centers Microbial Signatures, Grant/Award Number: SFB1371; DFG Collaborative Research Centers Molecular Mechanisms in Plants, Grant/Award Number: SFB924; European Cooperation in Science and Technology, Grant/Award Number: CA15120; Horizon 2020 Framework Programme, Grant/Award Numbers: 737586, 777111, 826078, 826121; Italian Ministry of Research, Grant/Award Number: PRIN2017F8ZB89; Ministero dell'Istruzione, dell'Università e della Ricerca, Grant/Award Number: MIUR20152TE5PK; National Institutes of Health, Grant/Award Numbers: 1R35CA220523, K25HL133599, P01HL105339, P01HL114501, P50GM107618, R01HL111759, R01HL133135, R01HL137927, R01HL147148, U01HG007690, U01HL089856, U54HL1191145; Plan Nacional de Salud Spanish Ministry of Science and Innovation, Grant/Award Numbers: PGC2018-094025-B-100, SAF2016-76819-R; Progetti per Avvio alla Ricerca, Grant/Award Number: AR11916B32035A1F; VALERE: Vanvitelli per la Ricerca, the Italian Association for Cancer Research, Grant/Award Number: AIRC-17217; Villum Young Investigator Grant, Grant/Award Number: 13154; WELBIO-Fonds National de la Recherche Scientifique grant funded by the Walloon Region, Grant/Award Number: AGR-REN-X500220F-35045981</p>
        <p>AUTHOR CONTRIBUTIONS Edwin Silverman: Conceptualization; writing-original draft; writing-review and editing. Harald Schmidt: Conceptualization; writing-original draft; writing-review and editing. Eleni Anastasiadou: Writing-original draft; writing-review and editing. Lucia Altucci: Writing-original draft; writing-review and editing. Marco Angelini: Visualization; writingoriginal draft; writing-review and editing. Lina Badimon: Writing-original draft; writing-review and editing. Jean-Luc Balligand: Writing-original draft; writing-review and editing. Giuditta Benincasa: Writing-original draft; visualization; writing-review and editing. Giovambattista Capasso: Writing-original draft; writing-review and editing. Federica Conte: Writing-original draft; writing-review and editing. Antonella Di Costanzo: Writing-original draft; writing-review and editing. Lorenzo Farina: Writing-original draft; writing-review and editing. Giulia Fiscon: Writing-original draft; writing-review and editing. Laurent Gatto: Visualization; writing-original draft; writing-review and editing. Michele Gentili: Writing-review and editing. Joseph Loscalzo: Conceptualization; writing-original draft; writing-review and editing. Cinzia Marchese: Writing-original draft; writing-review and editing. Claudio Napoli: Conceptualization; visualization; writing-original draft; writing-review and editing. Paola Paci: Writing-original draft; writing-review and editing. Manuela Petti: Writing-original draft; writing-review and editing. John Quackenbush: Writing-original draft; writingreview and editing. Paolo Tieri: Writing-original draft; writing-review and editing. Davide Viggiano: Writing-original draft; writing-review and editing. Gemma Vilahur: Writing-original draft; writing-review and editing. Kimberly Glass: Writing-original draft; writing-review and editing. Jan Baumbach: Conceptualization; visualization; writing-original draft; writing-review and editing.AUTHOR CONTRIBUTIONS Edwin Silverman: Conceptualization; writing-original draft; writing-review and editing. Harald Schmidt: Conceptualization; writing-original draft; writing-review and editing. Eleni Anastasiadou: Writing-original draft; writing-review and editing. Lucia Altucci: Writing-original draft; writing-review and editing. Marco Angelini: Visualization; writingoriginal draft; writing-review and editing. Lina Badimon: Writing-original draft; writing-review and editing. Jean-Luc Balligand: Writing-original draft; writing-review and editing. Giuditta Benincasa: Writing-original draft; visualization; writing-review and editing. Giovambattista Capasso: Writing-original draft; writing-review and editing. Federica Conte: Writing-original draft; writing-review and editing. Antonella Di Costanzo: Writing-original draft; writing-review and editing. Lorenzo Farina: Writing-original draft; writing-review and editing. Giulia Fiscon: Writing-original draft; writing-review and editing. Laurent Gatto: Visualization; writing-original draft; writing-review and editing. Michele Gentili: Writing-review and editing. Joseph Loscalzo: Conceptualization; writing-original draft; writing-review and editing. Cinzia Marchese: Writing-original draft; writing-review and editing. Claudio Napoli: Conceptualization; visualization; writing-original draft; writing-review and editing. Paola Paci: Writing-original draft; writing-review and editing. Manuela Petti: Writing-original draft; writing-review and editing. John Quackenbush: Writing-original draft; writingreview and editing. Paolo Tieri: Writing-original draft; writing-review and editing. Davide Viggiano: Writing-original draft; writing-review and editing. Gemma Vilahur: Writing-original draft; writing-review and editing. Kimberly Glass: Writing-original draft; writing-review and editing. Jan Baumbach: Conceptualization; visualization; writing-original draft; writing-review and editing.</p>
    </text>
</tei>
